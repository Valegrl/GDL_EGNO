Running Mocap-Run with num_modes=2 for seed 3
Job ID: 3831015, Array Task ID: 3
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes2_seed3.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes2_seed3', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=3, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes2_seed3/saved_model.pth
train epoch 0 avg loss: 104.63641 (A-MSE: 93.62537) avg lploss: 0.00000
==> val epoch 0 avg loss: 79.62968 (A-MSE: 69.28217) avg lploss: 0.00000
==> test epoch 0 avg loss: 76.18138 (A-MSE: 66.32547) avg lploss: 0.00000
*** Best Val Loss: 79.62968 	 Best Test Loss: 76.18138 	 Best epoch 0
Validation loss decreased (inf --> 79.629682).  Saving model ...
train epoch 1 avg loss: 75.96420 (A-MSE: 66.05529) avg lploss: 0.00000
train epoch 2 avg loss: 60.33876 (A-MSE: 52.37139) avg lploss: 0.00000
train epoch 3 avg loss: 39.46222 (A-MSE: 34.15916) avg lploss: 0.00000
train epoch 4 avg loss: 23.95319 (A-MSE: 21.09331) avg lploss: 0.00000
train epoch 5 avg loss: 17.00817 (A-MSE: 14.95280) avg lploss: 0.00000
==> val epoch 5 avg loss: 14.62968 (A-MSE: 12.79429) avg lploss: 0.00000
==> test epoch 5 avg loss: 14.11209 (A-MSE: 12.34409) avg lploss: 0.00000
*** Best Val Loss: 14.62968 	 Best Test Loss: 14.11209 	 Best epoch 5
Validation loss decreased (79.629682 --> 14.629682).  Saving model ...
train epoch 6 avg loss: 14.34227 (A-MSE: 12.55790) avg lploss: 0.00000
train epoch 7 avg loss: 12.09226 (A-MSE: 10.62274) avg lploss: 0.00000
train epoch 8 avg loss: 10.26803 (A-MSE: 9.00484) avg lploss: 0.00000
train epoch 9 avg loss: 9.10746 (A-MSE: 7.95933) avg lploss: 0.00000
train epoch 10 avg loss: 8.37556 (A-MSE: 7.32950) avg lploss: 0.00000
==> val epoch 10 avg loss: 7.65811 (A-MSE: 6.62939) avg lploss: 0.00000
==> test epoch 10 avg loss: 7.54864 (A-MSE: 6.53504) avg lploss: 0.00000
*** Best Val Loss: 7.65811 	 Best Test Loss: 7.54864 	 Best epoch 10
Validation loss decreased (14.629682 --> 7.658115).  Saving model ...
train epoch 11 avg loss: 7.74198 (A-MSE: 6.76928) avg lploss: 0.00000
train epoch 12 avg loss: 7.12540 (A-MSE: 6.23544) avg lploss: 0.00000
train epoch 13 avg loss: 2164.09841 (A-MSE: 1790.85459) avg lploss: 0.00000
train epoch 14 avg loss: 161.41177 (A-MSE: 184.06351) avg lploss: 0.00000
train epoch 15 avg loss: 40.29882 (A-MSE: 36.39485) avg lploss: 0.00000
==> val epoch 15 avg loss: 29.63885 (A-MSE: 24.74715) avg lploss: 0.00000
==> test epoch 15 avg loss: 28.59677 (A-MSE: 23.94203) avg lploss: 0.00000
*** Best Val Loss: 7.65811 	 Best Test Loss: 7.54864 	 Best epoch 10
EarlyStopping counter: 1 out of 50
train epoch 16 avg loss: 25.71456 (A-MSE: 21.82962) avg lploss: 0.00000
train epoch 17 avg loss: 20.80604 (A-MSE: 17.52264) avg lploss: 0.00000
train epoch 18 avg loss: 18.25178 (A-MSE: 15.32105) avg lploss: 0.00000
train epoch 19 avg loss: 16.48835 (A-MSE: 13.98888) avg lploss: 0.00000
train epoch 20 avg loss: 15.75838 (A-MSE: 13.45097) avg lploss: 0.00000
==> val epoch 20 avg loss: 14.87687 (A-MSE: 12.54443) avg lploss: 0.00000
==> test epoch 20 avg loss: 14.20465 (A-MSE: 11.99178) avg lploss: 0.00000
*** Best Val Loss: 7.65811 	 Best Test Loss: 7.54864 	 Best epoch 10
EarlyStopping counter: 2 out of 50
train epoch 21 avg loss: 15.00352 (A-MSE: 12.79700) avg lploss: 0.00000
train epoch 22 avg loss: 14.76678 (A-MSE: 12.51908) avg lploss: 0.00000
train epoch 23 avg loss: 14.32607 (A-MSE: 12.12990) avg lploss: 0.00000
train epoch 24 avg loss: 13.64763 (A-MSE: 11.57985) avg lploss: 0.00000
train epoch 25 avg loss: 13.25122 (A-MSE: 11.23558) avg lploss: 0.00000
==> val epoch 25 avg loss: 12.55853 (A-MSE: 10.53013) avg lploss: 0.00000
==> test epoch 25 avg loss: 11.99762 (A-MSE: 10.04426) avg lploss: 0.00000
*** Best Val Loss: 7.65811 	 Best Test Loss: 7.54864 	 Best epoch 10
EarlyStopping counter: 3 out of 50
train epoch 26 avg loss: 12.82499 (A-MSE: 10.85535) avg lploss: 0.00000
train epoch 27 avg loss: 12.30289 (A-MSE: 10.37658) avg lploss: 0.00000
train epoch 28 avg loss: 11.69609 (A-MSE: 9.83706) avg lploss: 0.00000
train epoch 29 avg loss: 11.42480 (A-MSE: 9.60990) avg lploss: 0.00000
train epoch 30 avg loss: 10.99857 (A-MSE: 9.25887) avg lploss: 0.00000
==> val epoch 30 avg loss: 10.75558 (A-MSE: 9.12421) avg lploss: 0.00000
==> test epoch 30 avg loss: 10.49833 (A-MSE: 8.90674) avg lploss: 0.00000
*** Best Val Loss: 7.65811 	 Best Test Loss: 7.54864 	 Best epoch 10
EarlyStopping counter: 4 out of 50
train epoch 31 avg loss: 10.74166 (A-MSE: 8.99046) avg lploss: 0.00000
train epoch 32 avg loss: 10.06662 (A-MSE: 8.46945) avg lploss: 0.00000
train epoch 33 avg loss: 9.83769 (A-MSE: 8.22366) avg lploss: 0.00000
train epoch 34 avg loss: 9.66872 (A-MSE: 8.14302) avg lploss: 0.00000
train epoch 35 avg loss: 9.39241 (A-MSE: 7.91003) avg lploss: 0.00000
==> val epoch 35 avg loss: 8.81442 (A-MSE: 7.38227) avg lploss: 0.00000
==> test epoch 35 avg loss: 8.58409 (A-MSE: 7.18444) avg lploss: 0.00000
*** Best Val Loss: 7.65811 	 Best Test Loss: 7.54864 	 Best epoch 10
EarlyStopping counter: 5 out of 50
train epoch 36 avg loss: 8.95878 (A-MSE: 7.50415) avg lploss: 0.00000
train epoch 37 avg loss: 8.82416 (A-MSE: 7.37520) avg lploss: 0.00000
train epoch 38 avg loss: 8.56934 (A-MSE: 7.20196) avg lploss: 0.00000
train epoch 39 avg loss: 8.38416 (A-MSE: 7.02705) avg lploss: 0.00000
train epoch 40 avg loss: 7.98579 (A-MSE: 6.67107) avg lploss: 0.00000
==> val epoch 40 avg loss: 7.62008 (A-MSE: 6.38871) avg lploss: 0.00000
==> test epoch 40 avg loss: 7.52435 (A-MSE: 6.31835) avg lploss: 0.00000
*** Best Val Loss: 7.62008 	 Best Test Loss: 7.52435 	 Best epoch 40
Validation loss decreased (7.658115 --> 7.620079).  Saving model ...
train epoch 41 avg loss: 7.69546 (A-MSE: 6.45986) avg lploss: 0.00000
train epoch 42 avg loss: 7.71888 (A-MSE: 6.45652) avg lploss: 0.00000
train epoch 43 avg loss: 7.53488 (A-MSE: 6.34795) avg lploss: 0.00000
train epoch 44 avg loss: 7.46877 (A-MSE: 6.29429) avg lploss: 0.00000
train epoch 45 avg loss: 7.21167 (A-MSE: 6.06096) avg lploss: 0.00000
==> val epoch 45 avg loss: 7.25052 (A-MSE: 5.85621) avg lploss: 0.00000
==> test epoch 45 avg loss: 7.28113 (A-MSE: 5.89467) avg lploss: 0.00000
*** Best Val Loss: 7.25052 	 Best Test Loss: 7.28113 	 Best epoch 45
Validation loss decreased (7.620079 --> 7.250516).  Saving model ...
train epoch 46 avg loss: 6.84387 (A-MSE: 5.74750) avg lploss: 0.00000
train epoch 47 avg loss: 6.66527 (A-MSE: 5.63273) avg lploss: 0.00000
train epoch 48 avg loss: 6.53666 (A-MSE: 5.46080) avg lploss: 0.00000
train epoch 49 avg loss: 6.27670 (A-MSE: 5.30136) avg lploss: 0.00000
train epoch 50 avg loss: 6.12224 (A-MSE: 5.15607) avg lploss: 0.00000
==> val epoch 50 avg loss: 6.12787 (A-MSE: 5.07831) avg lploss: 0.00000
==> test epoch 50 avg loss: 6.28042 (A-MSE: 5.20742) avg lploss: 0.00000
*** Best Val Loss: 6.12787 	 Best Test Loss: 6.28042 	 Best epoch 50
Validation loss decreased (7.250516 --> 6.127872).  Saving model ...
train epoch 51 avg loss: 5.99142 (A-MSE: 5.05463) avg lploss: 0.00000
train epoch 52 avg loss: 5.74781 (A-MSE: 4.82288) avg lploss: 0.00000
train epoch 53 avg loss: 5.31936 (A-MSE: 4.47332) avg lploss: 0.00000
train epoch 54 avg loss: 5.17327 (A-MSE: 4.35629) avg lploss: 0.00000
train epoch 55 avg loss: 4.88422 (A-MSE: 4.06919) avg lploss: 0.00000
==> val epoch 55 avg loss: 4.66849 (A-MSE: 3.95109) avg lploss: 0.00000
==> test epoch 55 avg loss: 4.87001 (A-MSE: 4.11635) avg lploss: 0.00000
*** Best Val Loss: 4.66849 	 Best Test Loss: 4.87001 	 Best epoch 55
Validation loss decreased (6.127872 --> 4.668485).  Saving model ...
train epoch 56 avg loss: 4.65891 (A-MSE: 3.88465) avg lploss: 0.00000
train epoch 57 avg loss: 4.56416 (A-MSE: 3.84517) avg lploss: 0.00000
train epoch 58 avg loss: 4.62502 (A-MSE: 3.85481) avg lploss: 0.00000
train epoch 59 avg loss: 4.60449 (A-MSE: 3.87916) avg lploss: 0.00000
train epoch 60 avg loss: 4.48071 (A-MSE: 3.76078) avg lploss: 0.00000
==> val epoch 60 avg loss: 4.27627 (A-MSE: 3.46981) avg lploss: 0.00000
==> test epoch 60 avg loss: 4.44749 (A-MSE: 3.60550) avg lploss: 0.00000
*** Best Val Loss: 4.27627 	 Best Test Loss: 4.44749 	 Best epoch 60
Validation loss decreased (4.668485 --> 4.276269).  Saving model ...
train epoch 61 avg loss: 4.27674 (A-MSE: 3.60385) avg lploss: 0.00000
train epoch 62 avg loss: 4.00811 (A-MSE: 3.35075) avg lploss: 0.00000
train epoch 63 avg loss: 3.74015 (A-MSE: 3.14687) avg lploss: 0.00000
train epoch 64 avg loss: 3.95834 (A-MSE: 3.33347) avg lploss: 0.00000
train epoch 65 avg loss: 3.79135 (A-MSE: 3.19462) avg lploss: 0.00000
==> val epoch 65 avg loss: 3.97443 (A-MSE: 3.29847) avg lploss: 0.00000
==> test epoch 65 avg loss: 4.14118 (A-MSE: 3.43725) avg lploss: 0.00000
*** Best Val Loss: 3.97443 	 Best Test Loss: 4.14118 	 Best epoch 65
Validation loss decreased (4.276269 --> 3.974427).  Saving model ...
train epoch 66 avg loss: 3.68701 (A-MSE: 3.10729) avg lploss: 0.00000
train epoch 67 avg loss: 3.67613 (A-MSE: 3.09268) avg lploss: 0.00000
train epoch 68 avg loss: 3.70577 (A-MSE: 3.11043) avg lploss: 0.00000
train epoch 69 avg loss: 3.58336 (A-MSE: 3.02847) avg lploss: 0.00000
train epoch 70 avg loss: 3.45714 (A-MSE: 2.93943) avg lploss: 0.00000
==> val epoch 70 avg loss: 3.88996 (A-MSE: 3.24993) avg lploss: 0.00000
==> test epoch 70 avg loss: 3.99642 (A-MSE: 3.34251) avg lploss: 0.00000
*** Best Val Loss: 3.88996 	 Best Test Loss: 3.99642 	 Best epoch 70
Validation loss decreased (3.974427 --> 3.889956).  Saving model ...
train epoch 71 avg loss: 3.74519 (A-MSE: 3.14198) avg lploss: 0.00000
train epoch 72 avg loss: 3.69016 (A-MSE: 3.14276) avg lploss: 0.00000
train epoch 73 avg loss: 3.52510 (A-MSE: 2.98667) avg lploss: 0.00000
train epoch 74 avg loss: 3.33847 (A-MSE: 2.82605) avg lploss: 0.00000
train epoch 75 avg loss: 3.30764 (A-MSE: 2.78780) avg lploss: 0.00000
==> val epoch 75 avg loss: 3.36285 (A-MSE: 2.93320) avg lploss: 0.00000
==> test epoch 75 avg loss: 3.38124 (A-MSE: 2.95181) avg lploss: 0.00000
*** Best Val Loss: 3.36285 	 Best Test Loss: 3.38124 	 Best epoch 75
Validation loss decreased (3.889956 --> 3.362845).  Saving model ...
train epoch 76 avg loss: 3.20214 (A-MSE: 2.71186) avg lploss: 0.00000
train epoch 77 avg loss: 3.27115 (A-MSE: 2.78623) avg lploss: 0.00000
train epoch 78 avg loss: 3.27143 (A-MSE: 2.79014) avg lploss: 0.00000
train epoch 79 avg loss: 3.33710 (A-MSE: 2.85190) avg lploss: 0.00000
train epoch 80 avg loss: 3.28179 (A-MSE: 2.80107) avg lploss: 0.00000
==> val epoch 80 avg loss: 3.54464 (A-MSE: 3.06844) avg lploss: 0.00000
==> test epoch 80 avg loss: 3.67463 (A-MSE: 3.20268) avg lploss: 0.00000
*** Best Val Loss: 3.36285 	 Best Test Loss: 3.38124 	 Best epoch 75
EarlyStopping counter: 1 out of 50
train epoch 81 avg loss: 3.16875 (A-MSE: 2.69276) avg lploss: 0.00000
train epoch 82 avg loss: 3.09570 (A-MSE: 2.65517) avg lploss: 0.00000
train epoch 83 avg loss: 3.10083 (A-MSE: 2.64269) avg lploss: 0.00000
train epoch 84 avg loss: 3.14656 (A-MSE: 2.67127) avg lploss: 0.00000
train epoch 85 avg loss: 3.05913 (A-MSE: 2.61192) avg lploss: 0.00000
==> val epoch 85 avg loss: 3.54035 (A-MSE: 3.09969) avg lploss: 0.00000
==> test epoch 85 avg loss: 3.42218 (A-MSE: 3.00304) avg lploss: 0.00000
*** Best Val Loss: 3.36285 	 Best Test Loss: 3.38124 	 Best epoch 75
EarlyStopping counter: 2 out of 50
train epoch 86 avg loss: 3.35764 (A-MSE: 2.86460) avg lploss: 0.00000
train epoch 87 avg loss: 3.02380 (A-MSE: 2.57575) avg lploss: 0.00000
train epoch 88 avg loss: 3.02006 (A-MSE: 2.59833) avg lploss: 0.00000
train epoch 89 avg loss: 3.04622 (A-MSE: 2.59889) avg lploss: 0.00000
train epoch 90 avg loss: 2.92476 (A-MSE: 2.50171) avg lploss: 0.00000
==> val epoch 90 avg loss: 3.05002 (A-MSE: 2.67102) avg lploss: 0.00000
==> test epoch 90 avg loss: 3.09508 (A-MSE: 2.73222) avg lploss: 0.00000
*** Best Val Loss: 3.05002 	 Best Test Loss: 3.09508 	 Best epoch 90
Validation loss decreased (3.362845 --> 3.050019).  Saving model ...
train epoch 91 avg loss: 2.85804 (A-MSE: 2.43767) avg lploss: 0.00000
train epoch 92 avg loss: 3.00285 (A-MSE: 2.57522) avg lploss: 0.00000
train epoch 93 avg loss: 2.99776 (A-MSE: 2.56786) avg lploss: 0.00000
train epoch 94 avg loss: 2.95970 (A-MSE: 2.52678) avg lploss: 0.00000
train epoch 95 avg loss: 2.86699 (A-MSE: 2.45142) avg lploss: 0.00000
==> val epoch 95 avg loss: 3.07923 (A-MSE: 2.65037) avg lploss: 0.00000
==> test epoch 95 avg loss: 3.22890 (A-MSE: 2.81228) avg lploss: 0.00000
*** Best Val Loss: 3.05002 	 Best Test Loss: 3.09508 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 2.71209 (A-MSE: 2.31167) avg lploss: 0.00000
train epoch 97 avg loss: 2.78152 (A-MSE: 2.39536) avg lploss: 0.00000
train epoch 98 avg loss: 2.74583 (A-MSE: 2.35759) avg lploss: 0.00000
train epoch 99 avg loss: 2.85254 (A-MSE: 2.43648) avg lploss: 0.00000
train epoch 100 avg loss: 3.14996 (A-MSE: 2.70883) avg lploss: 0.00000
==> val epoch 100 avg loss: 3.57016 (A-MSE: 3.11969) avg lploss: 0.00000
==> test epoch 100 avg loss: 3.58238 (A-MSE: 3.15545) avg lploss: 0.00000
*** Best Val Loss: 3.05002 	 Best Test Loss: 3.09508 	 Best epoch 90
EarlyStopping counter: 2 out of 50
train epoch 101 avg loss: 2.91044 (A-MSE: 2.48500) avg lploss: 0.00000
train epoch 102 avg loss: 2.87927 (A-MSE: 2.45863) avg lploss: 0.00000
train epoch 103 avg loss: 2.80295 (A-MSE: 2.39837) avg lploss: 0.00000
train epoch 104 avg loss: 2.79444 (A-MSE: 2.39833) avg lploss: 0.00000
train epoch 105 avg loss: 2.74166 (A-MSE: 2.34150) avg lploss: 0.00000
==> val epoch 105 avg loss: 2.85037 (A-MSE: 2.55103) avg lploss: 0.00000
==> test epoch 105 avg loss: 2.88345 (A-MSE: 2.61446) avg lploss: 0.00000
*** Best Val Loss: 2.85037 	 Best Test Loss: 2.88345 	 Best epoch 105
Validation loss decreased (3.050019 --> 2.850370).  Saving model ...
train epoch 106 avg loss: 2.77171 (A-MSE: 2.38740) avg lploss: 0.00000
train epoch 107 avg loss: 2.71749 (A-MSE: 2.32499) avg lploss: 0.00000
train epoch 108 avg loss: 2.66392 (A-MSE: 2.27766) avg lploss: 0.00000
train epoch 109 avg loss: 2.62159 (A-MSE: 2.25131) avg lploss: 0.00000
train epoch 110 avg loss: 2.56624 (A-MSE: 2.20352) avg lploss: 0.00000
==> val epoch 110 avg loss: 2.62887 (A-MSE: 2.27472) avg lploss: 0.00000
==> test epoch 110 avg loss: 2.72593 (A-MSE: 2.39918) avg lploss: 0.00000
*** Best Val Loss: 2.62887 	 Best Test Loss: 2.72593 	 Best epoch 110
Validation loss decreased (2.850370 --> 2.628870).  Saving model ...
train epoch 111 avg loss: 2.55486 (A-MSE: 2.19720) avg lploss: 0.00000
train epoch 112 avg loss: 2.53126 (A-MSE: 2.17436) avg lploss: 0.00000
train epoch 113 avg loss: 2.47717 (A-MSE: 2.12585) avg lploss: 0.00000
train epoch 114 avg loss: 2.51403 (A-MSE: 2.15993) avg lploss: 0.00000
train epoch 115 avg loss: 2.53510 (A-MSE: 2.17432) avg lploss: 0.00000
==> val epoch 115 avg loss: 2.99033 (A-MSE: 2.63983) avg lploss: 0.00000
==> test epoch 115 avg loss: 3.18224 (A-MSE: 2.84227) avg lploss: 0.00000
*** Best Val Loss: 2.62887 	 Best Test Loss: 2.72593 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 2.59356 (A-MSE: 2.23218) avg lploss: 0.00000
train epoch 117 avg loss: 2.70050 (A-MSE: 2.31522) avg lploss: 0.00000
train epoch 118 avg loss: 2.49382 (A-MSE: 2.13864) avg lploss: 0.00000
train epoch 119 avg loss: 2.43478 (A-MSE: 2.10229) avg lploss: 0.00000
train epoch 120 avg loss: 2.75440 (A-MSE: 2.38208) avg lploss: 0.00000
==> val epoch 120 avg loss: 2.98106 (A-MSE: 2.63489) avg lploss: 0.00000
==> test epoch 120 avg loss: 3.01517 (A-MSE: 2.69284) avg lploss: 0.00000
*** Best Val Loss: 2.62887 	 Best Test Loss: 2.72593 	 Best epoch 110
EarlyStopping counter: 2 out of 50
train epoch 121 avg loss: 2.71381 (A-MSE: 2.32636) avg lploss: 0.00000
train epoch 122 avg loss: 2.56240 (A-MSE: 2.20023) avg lploss: 0.00000
train epoch 123 avg loss: 2.42262 (A-MSE: 2.07431) avg lploss: 0.00000
train epoch 124 avg loss: 2.51797 (A-MSE: 2.18294) avg lploss: 0.00000
train epoch 125 avg loss: 2.39090 (A-MSE: 2.05411) avg lploss: 0.00000
==> val epoch 125 avg loss: 2.67320 (A-MSE: 2.33176) avg lploss: 0.00000
==> test epoch 125 avg loss: 2.62905 (A-MSE: 2.32717) avg lploss: 0.00000
*** Best Val Loss: 2.62887 	 Best Test Loss: 2.72593 	 Best epoch 110
EarlyStopping counter: 3 out of 50
train epoch 126 avg loss: 2.41556 (A-MSE: 2.07537) avg lploss: 0.00000
train epoch 127 avg loss: 2.45010 (A-MSE: 2.10241) avg lploss: 0.00000
train epoch 128 avg loss: 2.39842 (A-MSE: 2.06111) avg lploss: 0.00000
train epoch 129 avg loss: 2.41748 (A-MSE: 2.08463) avg lploss: 0.00000
train epoch 130 avg loss: 2.44437 (A-MSE: 2.09923) avg lploss: 0.00000
==> val epoch 130 avg loss: 2.70506 (A-MSE: 2.41747) avg lploss: 0.00000
==> test epoch 130 avg loss: 2.80067 (A-MSE: 2.52888) avg lploss: 0.00000
*** Best Val Loss: 2.62887 	 Best Test Loss: 2.72593 	 Best epoch 110
EarlyStopping counter: 4 out of 50
train epoch 131 avg loss: 2.34946 (A-MSE: 2.01971) avg lploss: 0.00000
train epoch 132 avg loss: 2.35135 (A-MSE: 2.02417) avg lploss: 0.00000
train epoch 133 avg loss: 2.26149 (A-MSE: 1.94472) avg lploss: 0.00000
train epoch 134 avg loss: 2.29468 (A-MSE: 1.98079) avg lploss: 0.00000
train epoch 135 avg loss: 2.38422 (A-MSE: 2.04400) avg lploss: 0.00000
==> val epoch 135 avg loss: 2.71624 (A-MSE: 2.40221) avg lploss: 0.00000
==> test epoch 135 avg loss: 2.82928 (A-MSE: 2.53420) avg lploss: 0.00000
*** Best Val Loss: 2.62887 	 Best Test Loss: 2.72593 	 Best epoch 110
EarlyStopping counter: 5 out of 50
train epoch 136 avg loss: 2.40483 (A-MSE: 2.07354) avg lploss: 0.00000
train epoch 137 avg loss: 2.35441 (A-MSE: 2.02425) avg lploss: 0.00000
train epoch 138 avg loss: 2.43246 (A-MSE: 2.08827) avg lploss: 0.00000
train epoch 139 avg loss: 2.24378 (A-MSE: 1.92938) avg lploss: 0.00000
train epoch 140 avg loss: 2.22936 (A-MSE: 1.91177) avg lploss: 0.00000
==> val epoch 140 avg loss: 2.51257 (A-MSE: 2.21518) avg lploss: 0.00000
==> test epoch 140 avg loss: 2.68362 (A-MSE: 2.39914) avg lploss: 0.00000
*** Best Val Loss: 2.51257 	 Best Test Loss: 2.68362 	 Best epoch 140
Validation loss decreased (2.628870 --> 2.512571).  Saving model ...
train epoch 141 avg loss: 2.23092 (A-MSE: 1.92915) avg lploss: 0.00000
train epoch 142 avg loss: 2.39395 (A-MSE: 2.05999) avg lploss: 0.00000
train epoch 143 avg loss: 2.19793 (A-MSE: 1.88322) avg lploss: 0.00000
train epoch 144 avg loss: 2.12993 (A-MSE: 1.83757) avg lploss: 0.00000
train epoch 145 avg loss: 2.10417 (A-MSE: 1.80852) avg lploss: 0.00000
==> val epoch 145 avg loss: 2.48792 (A-MSE: 2.19571) avg lploss: 0.00000
==> test epoch 145 avg loss: 2.66992 (A-MSE: 2.39135) avg lploss: 0.00000
*** Best Val Loss: 2.48792 	 Best Test Loss: 2.66992 	 Best epoch 145
Validation loss decreased (2.512571 --> 2.487919).  Saving model ...
train epoch 146 avg loss: 2.08727 (A-MSE: 1.79371) avg lploss: 0.00000
train epoch 147 avg loss: 2.12066 (A-MSE: 1.82731) avg lploss: 0.00000
train epoch 148 avg loss: 2.20788 (A-MSE: 1.90735) avg lploss: 0.00000
train epoch 149 avg loss: 2.34903 (A-MSE: 2.02635) avg lploss: 0.00000
train epoch 150 avg loss: 2.21240 (A-MSE: 1.90526) avg lploss: 0.00000
==> val epoch 150 avg loss: 2.56514 (A-MSE: 2.25351) avg lploss: 0.00000
==> test epoch 150 avg loss: 2.68547 (A-MSE: 2.39364) avg lploss: 0.00000
*** Best Val Loss: 2.48792 	 Best Test Loss: 2.66992 	 Best epoch 145
EarlyStopping counter: 1 out of 50
train epoch 151 avg loss: 2.24303 (A-MSE: 1.93517) avg lploss: 0.00000
train epoch 152 avg loss: 2.24966 (A-MSE: 1.94265) avg lploss: 0.00000
train epoch 153 avg loss: 2.10116 (A-MSE: 1.80861) avg lploss: 0.00000
train epoch 154 avg loss: 2.10676 (A-MSE: 1.82277) avg lploss: 0.00000
train epoch 155 avg loss: 2.07933 (A-MSE: 1.79454) avg lploss: 0.00000
==> val epoch 155 avg loss: 2.44773 (A-MSE: 2.15794) avg lploss: 0.00000
==> test epoch 155 avg loss: 2.63749 (A-MSE: 2.35732) avg lploss: 0.00000
*** Best Val Loss: 2.44773 	 Best Test Loss: 2.63749 	 Best epoch 155
Validation loss decreased (2.487919 --> 2.447729).  Saving model ...
train epoch 156 avg loss: 2.13719 (A-MSE: 1.84589) avg lploss: 0.00000
train epoch 157 avg loss: 2.06491 (A-MSE: 1.78150) avg lploss: 0.00000
train epoch 158 avg loss: 2.14166 (A-MSE: 1.84924) avg lploss: 0.00000
train epoch 159 avg loss: 2.14091 (A-MSE: 1.84713) avg lploss: 0.00000
train epoch 160 avg loss: 1.98328 (A-MSE: 1.70739) avg lploss: 0.00000
==> val epoch 160 avg loss: 2.24783 (A-MSE: 1.99591) avg lploss: 0.00000
==> test epoch 160 avg loss: 2.27097 (A-MSE: 2.04697) avg lploss: 0.00000
*** Best Val Loss: 2.24783 	 Best Test Loss: 2.27097 	 Best epoch 160
Validation loss decreased (2.447729 --> 2.247832).  Saving model ...
train epoch 161 avg loss: 2.16055 (A-MSE: 1.87020) avg lploss: 0.00000
train epoch 162 avg loss: 2.26768 (A-MSE: 1.95419) avg lploss: 0.00000
train epoch 163 avg loss: 2.21303 (A-MSE: 1.90463) avg lploss: 0.00000
train epoch 164 avg loss: 2.14847 (A-MSE: 1.85162) avg lploss: 0.00000
train epoch 165 avg loss: 2.01953 (A-MSE: 1.73099) avg lploss: 0.00000
==> val epoch 165 avg loss: 2.21811 (A-MSE: 1.95563) avg lploss: 0.00000
==> test epoch 165 avg loss: 2.43218 (A-MSE: 2.17820) avg lploss: 0.00000
*** Best Val Loss: 2.21811 	 Best Test Loss: 2.43218 	 Best epoch 165
Validation loss decreased (2.247832 --> 2.218107).  Saving model ...
train epoch 166 avg loss: 1.95792 (A-MSE: 1.68844) avg lploss: 0.00000
train epoch 167 avg loss: 2.01456 (A-MSE: 1.73498) avg lploss: 0.00000
train epoch 168 avg loss: 2.06397 (A-MSE: 1.77805) avg lploss: 0.00000
train epoch 169 avg loss: 1.93735 (A-MSE: 1.66626) avg lploss: 0.00000
train epoch 170 avg loss: 2.02699 (A-MSE: 1.74702) avg lploss: 0.00000
==> val epoch 170 avg loss: 2.19707 (A-MSE: 1.94000) avg lploss: 0.00000
==> test epoch 170 avg loss: 2.26626 (A-MSE: 2.03424) avg lploss: 0.00000
*** Best Val Loss: 2.19707 	 Best Test Loss: 2.26626 	 Best epoch 170
Validation loss decreased (2.218107 --> 2.197072).  Saving model ...
train epoch 171 avg loss: 1.95632 (A-MSE: 1.69045) avg lploss: 0.00000
train epoch 172 avg loss: 1.95487 (A-MSE: 1.68199) avg lploss: 0.00000
train epoch 173 avg loss: 1.90033 (A-MSE: 1.63732) avg lploss: 0.00000
train epoch 174 avg loss: 1.91329 (A-MSE: 1.65556) avg lploss: 0.00000
train epoch 175 avg loss: 1.92031 (A-MSE: 1.65374) avg lploss: 0.00000
==> val epoch 175 avg loss: 2.21149 (A-MSE: 1.94871) avg lploss: 0.00000
==> test epoch 175 avg loss: 2.42312 (A-MSE: 2.16531) avg lploss: 0.00000
*** Best Val Loss: 2.19707 	 Best Test Loss: 2.26626 	 Best epoch 170
EarlyStopping counter: 1 out of 50
train epoch 176 avg loss: 1.86530 (A-MSE: 1.61228) avg lploss: 0.00000
train epoch 177 avg loss: 2.05345 (A-MSE: 1.76735) avg lploss: 0.00000
train epoch 178 avg loss: 1.87686 (A-MSE: 1.61894) avg lploss: 0.00000
train epoch 179 avg loss: 1.88497 (A-MSE: 1.63407) avg lploss: 0.00000
train epoch 180 avg loss: 1.99881 (A-MSE: 1.72024) avg lploss: 0.00000
==> val epoch 180 avg loss: 2.11881 (A-MSE: 1.86319) avg lploss: 0.00000
==> test epoch 180 avg loss: 2.13910 (A-MSE: 1.91410) avg lploss: 0.00000
*** Best Val Loss: 2.11881 	 Best Test Loss: 2.13910 	 Best epoch 180
Validation loss decreased (2.197072 --> 2.118807).  Saving model ...
train epoch 181 avg loss: 1.83365 (A-MSE: 1.57939) avg lploss: 0.00000
train epoch 182 avg loss: 1.92521 (A-MSE: 1.66678) avg lploss: 0.00000
train epoch 183 avg loss: 1.85490 (A-MSE: 1.60498) avg lploss: 0.00000
train epoch 184 avg loss: 1.87944 (A-MSE: 1.60667) avg lploss: 0.00000
train epoch 185 avg loss: 1.78023 (A-MSE: 1.53514) avg lploss: 0.00000
==> val epoch 185 avg loss: 1.97099 (A-MSE: 1.74322) avg lploss: 0.00000
==> test epoch 185 avg loss: 2.08757 (A-MSE: 1.87435) avg lploss: 0.00000
*** Best Val Loss: 1.97099 	 Best Test Loss: 2.08757 	 Best epoch 185
Validation loss decreased (2.118807 --> 1.970985).  Saving model ...
train epoch 186 avg loss: 1.87996 (A-MSE: 1.62182) avg lploss: 0.00000
train epoch 187 avg loss: 1.95190 (A-MSE: 1.68012) avg lploss: 0.00000
train epoch 188 avg loss: 1.88339 (A-MSE: 1.62035) avg lploss: 0.00000
train epoch 189 avg loss: 1.71934 (A-MSE: 1.48023) avg lploss: 0.00000
train epoch 190 avg loss: 1.74840 (A-MSE: 1.50447) avg lploss: 0.00000
==> val epoch 190 avg loss: 1.98011 (A-MSE: 1.74258) avg lploss: 0.00000
==> test epoch 190 avg loss: 2.08051 (A-MSE: 1.86459) avg lploss: 0.00000
*** Best Val Loss: 1.97099 	 Best Test Loss: 2.08757 	 Best epoch 185
EarlyStopping counter: 1 out of 50
train epoch 191 avg loss: 1.76185 (A-MSE: 1.52066) avg lploss: 0.00000
train epoch 192 avg loss: 1.77335 (A-MSE: 1.52733) avg lploss: 0.00000
train epoch 193 avg loss: 1.75324 (A-MSE: 1.51463) avg lploss: 0.00000
train epoch 194 avg loss: 1.78958 (A-MSE: 1.53965) avg lploss: 0.00000
train epoch 195 avg loss: 1.86938 (A-MSE: 1.62136) avg lploss: 0.00000
==> val epoch 195 avg loss: 2.27531 (A-MSE: 2.00528) avg lploss: 0.00000
==> test epoch 195 avg loss: 2.48229 (A-MSE: 2.21193) avg lploss: 0.00000
*** Best Val Loss: 1.97099 	 Best Test Loss: 2.08757 	 Best epoch 185
EarlyStopping counter: 2 out of 50
train epoch 196 avg loss: 1.86673 (A-MSE: 1.60342) avg lploss: 0.00000
train epoch 197 avg loss: 1.69909 (A-MSE: 1.46111) avg lploss: 0.00000
train epoch 198 avg loss: 1.69259 (A-MSE: 1.46459) avg lploss: 0.00000
train epoch 199 avg loss: 1.75837 (A-MSE: 1.51757) avg lploss: 0.00000
train epoch 200 avg loss: 1.77268 (A-MSE: 1.53244) avg lploss: 0.00000
==> val epoch 200 avg loss: 2.19224 (A-MSE: 1.93581) avg lploss: 0.00000
==> test epoch 200 avg loss: 2.42240 (A-MSE: 2.16277) avg lploss: 0.00000
*** Best Val Loss: 1.97099 	 Best Test Loss: 2.08757 	 Best epoch 185
EarlyStopping counter: 3 out of 50
train epoch 201 avg loss: 1.76643 (A-MSE: 1.52557) avg lploss: 0.00000
train epoch 202 avg loss: 1.82719 (A-MSE: 1.57512) avg lploss: 0.00000
train epoch 203 avg loss: 1.69680 (A-MSE: 1.46559) avg lploss: 0.00000
train epoch 204 avg loss: 1.72517 (A-MSE: 1.48977) avg lploss: 0.00000
train epoch 205 avg loss: 1.68273 (A-MSE: 1.45895) avg lploss: 0.00000
==> val epoch 205 avg loss: 1.97505 (A-MSE: 1.73147) avg lploss: 0.00000
==> test epoch 205 avg loss: 2.13962 (A-MSE: 1.90980) avg lploss: 0.00000
*** Best Val Loss: 1.97099 	 Best Test Loss: 2.08757 	 Best epoch 185
EarlyStopping counter: 4 out of 50
train epoch 206 avg loss: 1.74258 (A-MSE: 1.51302) avg lploss: 0.00000
train epoch 207 avg loss: 1.62402 (A-MSE: 1.40545) avg lploss: 0.00000
train epoch 208 avg loss: 1.58631 (A-MSE: 1.37022) avg lploss: 0.00000
train epoch 209 avg loss: 1.56386 (A-MSE: 1.35200) avg lploss: 0.00000
train epoch 210 avg loss: 1.60322 (A-MSE: 1.38261) avg lploss: 0.00000
==> val epoch 210 avg loss: 1.85808 (A-MSE: 1.64847) avg lploss: 0.00000
==> test epoch 210 avg loss: 1.90234 (A-MSE: 1.71907) avg lploss: 0.00000
*** Best Val Loss: 1.85808 	 Best Test Loss: 1.90234 	 Best epoch 210
Validation loss decreased (1.970985 --> 1.858083).  Saving model ...
train epoch 211 avg loss: 1.59298 (A-MSE: 1.38019) avg lploss: 0.00000
train epoch 212 avg loss: 1.63576 (A-MSE: 1.41650) avg lploss: 0.00000
train epoch 213 avg loss: 1.68910 (A-MSE: 1.46588) avg lploss: 0.00000
train epoch 214 avg loss: 1.61391 (A-MSE: 1.40049) avg lploss: 0.00000
train epoch 215 avg loss: 1.62691 (A-MSE: 1.40900) avg lploss: 0.00000
==> val epoch 215 avg loss: 2.19174 (A-MSE: 1.93782) avg lploss: 0.00000
==> test epoch 215 avg loss: 2.45177 (A-MSE: 2.18921) avg lploss: 0.00000
*** Best Val Loss: 1.85808 	 Best Test Loss: 1.90234 	 Best epoch 210
EarlyStopping counter: 1 out of 50
train epoch 216 avg loss: 1.65112 (A-MSE: 1.43650) avg lploss: 0.00000
train epoch 217 avg loss: 1.64648 (A-MSE: 1.42266) avg lploss: 0.00000
train epoch 218 avg loss: 1.61808 (A-MSE: 1.40331) avg lploss: 0.00000
train epoch 219 avg loss: 1.64573 (A-MSE: 1.42111) avg lploss: 0.00000
train epoch 220 avg loss: 1.66061 (A-MSE: 1.44470) avg lploss: 0.00000
==> val epoch 220 avg loss: 1.88081 (A-MSE: 1.63302) avg lploss: 0.00000
==> test epoch 220 avg loss: 2.04225 (A-MSE: 1.80083) avg lploss: 0.00000
*** Best Val Loss: 1.85808 	 Best Test Loss: 1.90234 	 Best epoch 210
EarlyStopping counter: 2 out of 50
train epoch 221 avg loss: 1.58880 (A-MSE: 1.37300) avg lploss: 0.00000
train epoch 222 avg loss: 1.57259 (A-MSE: 1.36065) avg lploss: 0.00000
train epoch 223 avg loss: 1.49418 (A-MSE: 1.29288) avg lploss: 0.00000
train epoch 224 avg loss: 1.71808 (A-MSE: 1.49201) avg lploss: 0.00000
train epoch 225 avg loss: 1.74463 (A-MSE: 1.50908) avg lploss: 0.00000
==> val epoch 225 avg loss: 1.97432 (A-MSE: 1.73435) avg lploss: 0.00000
==> test epoch 225 avg loss: 2.13143 (A-MSE: 1.89724) avg lploss: 0.00000
*** Best Val Loss: 1.85808 	 Best Test Loss: 1.90234 	 Best epoch 210
EarlyStopping counter: 3 out of 50
train epoch 226 avg loss: 1.51673 (A-MSE: 1.30934) avg lploss: 0.00000
train epoch 227 avg loss: 1.50840 (A-MSE: 1.30271) avg lploss: 0.00000
train epoch 228 avg loss: 1.47899 (A-MSE: 1.28215) avg lploss: 0.00000
train epoch 229 avg loss: 1.49754 (A-MSE: 1.30069) avg lploss: 0.00000
train epoch 230 avg loss: 1.56074 (A-MSE: 1.36634) avg lploss: 0.00000
==> val epoch 230 avg loss: 1.72058 (A-MSE: 1.50186) avg lploss: 0.00000
==> test epoch 230 avg loss: 1.77995 (A-MSE: 1.58035) avg lploss: 0.00000
*** Best Val Loss: 1.72058 	 Best Test Loss: 1.77995 	 Best epoch 230
Validation loss decreased (1.858083 --> 1.720583).  Saving model ...
train epoch 231 avg loss: 1.50475 (A-MSE: 1.29683) avg lploss: 0.00000
train epoch 232 avg loss: 1.52516 (A-MSE: 1.32482) avg lploss: 0.00000
train epoch 233 avg loss: 1.44642 (A-MSE: 1.25268) avg lploss: 0.00000
train epoch 234 avg loss: 1.47624 (A-MSE: 1.28042) avg lploss: 0.00000
train epoch 235 avg loss: 1.46743 (A-MSE: 1.27656) avg lploss: 0.00000
==> val epoch 235 avg loss: 1.89569 (A-MSE: 1.67328) avg lploss: 0.00000
==> test epoch 235 avg loss: 2.09773 (A-MSE: 1.87917) avg lploss: 0.00000
*** Best Val Loss: 1.72058 	 Best Test Loss: 1.77995 	 Best epoch 230
EarlyStopping counter: 1 out of 50
train epoch 236 avg loss: 1.55837 (A-MSE: 1.35080) avg lploss: 0.00000
train epoch 237 avg loss: 1.51721 (A-MSE: 1.31481) avg lploss: 0.00000
train epoch 238 avg loss: 1.49669 (A-MSE: 1.30335) avg lploss: 0.00000
train epoch 239 avg loss: 1.46562 (A-MSE: 1.27527) avg lploss: 0.00000
train epoch 240 avg loss: 1.46732 (A-MSE: 1.27461) avg lploss: 0.00000
==> val epoch 240 avg loss: 1.77404 (A-MSE: 1.56973) avg lploss: 0.00000
==> test epoch 240 avg loss: 1.87951 (A-MSE: 1.68749) avg lploss: 0.00000
*** Best Val Loss: 1.72058 	 Best Test Loss: 1.77995 	 Best epoch 230
EarlyStopping counter: 2 out of 50
train epoch 241 avg loss: 1.39550 (A-MSE: 1.21472) avg lploss: 0.00000
train epoch 242 avg loss: 1.44176 (A-MSE: 1.26034) avg lploss: 0.00000
train epoch 243 avg loss: 1.40696 (A-MSE: 1.22242) avg lploss: 0.00000
train epoch 244 avg loss: 1.44247 (A-MSE: 1.25617) avg lploss: 0.00000
train epoch 245 avg loss: 1.44198 (A-MSE: 1.25363) avg lploss: 0.00000
==> val epoch 245 avg loss: 1.80698 (A-MSE: 1.61940) avg lploss: 0.00000
==> test epoch 245 avg loss: 2.00731 (A-MSE: 1.81704) avg lploss: 0.00000
*** Best Val Loss: 1.72058 	 Best Test Loss: 1.77995 	 Best epoch 230
EarlyStopping counter: 3 out of 50
train epoch 246 avg loss: 1.48918 (A-MSE: 1.29802) avg lploss: 0.00000
train epoch 247 avg loss: 1.38703 (A-MSE: 1.20364) avg lploss: 0.00000
train epoch 248 avg loss: 1.36415 (A-MSE: 1.18403) avg lploss: 0.00000
train epoch 249 avg loss: 1.37077 (A-MSE: 1.19041) avg lploss: 0.00000
train epoch 250 avg loss: 1.40967 (A-MSE: 1.22547) avg lploss: 0.00000
==> val epoch 250 avg loss: 1.71807 (A-MSE: 1.51526) avg lploss: 0.00000
==> test epoch 250 avg loss: 1.80832 (A-MSE: 1.61661) avg lploss: 0.00000
*** Best Val Loss: 1.71807 	 Best Test Loss: 1.80832 	 Best epoch 250
Validation loss decreased (1.720583 --> 1.718073).  Saving model ...
train epoch 251 avg loss: 1.33557 (A-MSE: 1.16497) avg lploss: 0.00000
train epoch 252 avg loss: 1.32424 (A-MSE: 1.15707) avg lploss: 0.00000
train epoch 253 avg loss: 1.31777 (A-MSE: 1.14687) avg lploss: 0.00000
train epoch 254 avg loss: 1.31704 (A-MSE: 1.14833) avg lploss: 0.00000
train epoch 255 avg loss: 1.31852 (A-MSE: 1.14732) avg lploss: 0.00000
==> val epoch 255 avg loss: 1.62344 (A-MSE: 1.43836) avg lploss: 0.00000
==> test epoch 255 avg loss: 1.68740 (A-MSE: 1.52213) avg lploss: 0.00000
*** Best Val Loss: 1.62344 	 Best Test Loss: 1.68740 	 Best epoch 255
Validation loss decreased (1.718073 --> 1.623439).  Saving model ...
train epoch 256 avg loss: 1.29072 (A-MSE: 1.12467) avg lploss: 0.00000
train epoch 257 avg loss: 1.36257 (A-MSE: 1.19304) avg lploss: 0.00000
train epoch 258 avg loss: 1.31106 (A-MSE: 1.14848) avg lploss: 0.00000
train epoch 259 avg loss: 1.27032 (A-MSE: 1.10383) avg lploss: 0.00000
train epoch 260 avg loss: 1.32942 (A-MSE: 1.16189) avg lploss: 0.00000
==> val epoch 260 avg loss: 2.19567 (A-MSE: 1.95734) avg lploss: 0.00000
==> test epoch 260 avg loss: 2.39657 (A-MSE: 2.15449) avg lploss: 0.00000
*** Best Val Loss: 1.62344 	 Best Test Loss: 1.68740 	 Best epoch 255
EarlyStopping counter: 1 out of 50
train epoch 261 avg loss: 1.52384 (A-MSE: 1.32828) avg lploss: 0.00000
train epoch 262 avg loss: 1.44804 (A-MSE: 1.25830) avg lploss: 0.00000
train epoch 263 avg loss: 1.41020 (A-MSE: 1.22838) avg lploss: 0.00000
train epoch 264 avg loss: 1.36470 (A-MSE: 1.18804) avg lploss: 0.00000
train epoch 265 avg loss: 1.52133 (A-MSE: 1.32393) avg lploss: 0.00000
==> val epoch 265 avg loss: 1.83578 (A-MSE: 1.65733) avg lploss: 0.00000
==> test epoch 265 avg loss: 1.96940 (A-MSE: 1.79875) avg lploss: 0.00000
*** Best Val Loss: 1.62344 	 Best Test Loss: 1.68740 	 Best epoch 255
EarlyStopping counter: 2 out of 50
train epoch 266 avg loss: 1.33812 (A-MSE: 1.16634) avg lploss: 0.00000
train epoch 267 avg loss: 1.36890 (A-MSE: 1.19194) avg lploss: 0.00000
train epoch 268 avg loss: 1.27725 (A-MSE: 1.10746) avg lploss: 0.00000
train epoch 269 avg loss: 1.20310 (A-MSE: 1.04718) avg lploss: 0.00000
train epoch 270 avg loss: 1.30789 (A-MSE: 1.13796) avg lploss: 0.00000
==> val epoch 270 avg loss: 1.49857 (A-MSE: 1.31768) avg lploss: 0.00000
==> test epoch 270 avg loss: 1.63748 (A-MSE: 1.46527) avg lploss: 0.00000
*** Best Val Loss: 1.49857 	 Best Test Loss: 1.63748 	 Best epoch 270
Validation loss decreased (1.623439 --> 1.498571).  Saving model ...
train epoch 271 avg loss: 1.21404 (A-MSE: 1.06087) avg lploss: 0.00000
train epoch 272 avg loss: 1.23985 (A-MSE: 1.08133) avg lploss: 0.00000
train epoch 273 avg loss: 1.24928 (A-MSE: 1.09232) avg lploss: 0.00000
train epoch 274 avg loss: 1.35435 (A-MSE: 1.18571) avg lploss: 0.00000
train epoch 275 avg loss: 1.26827 (A-MSE: 1.10983) avg lploss: 0.00000
==> val epoch 275 avg loss: 1.51544 (A-MSE: 1.35236) avg lploss: 0.00000
==> test epoch 275 avg loss: 1.61366 (A-MSE: 1.45938) avg lploss: 0.00000
*** Best Val Loss: 1.49857 	 Best Test Loss: 1.63748 	 Best epoch 270
EarlyStopping counter: 1 out of 50
train epoch 276 avg loss: 1.24612 (A-MSE: 1.09127) avg lploss: 0.00000
train epoch 277 avg loss: 1.25386 (A-MSE: 1.09413) avg lploss: 0.00000
train epoch 278 avg loss: 1.18086 (A-MSE: 1.03125) avg lploss: 0.00000
train epoch 279 avg loss: 1.16228 (A-MSE: 1.01598) avg lploss: 0.00000
train epoch 280 avg loss: 1.14624 (A-MSE: 0.99925) avg lploss: 0.00000
==> val epoch 280 avg loss: 1.54177 (A-MSE: 1.36259) avg lploss: 0.00000
==> test epoch 280 avg loss: 1.73933 (A-MSE: 1.55553) avg lploss: 0.00000
*** Best Val Loss: 1.49857 	 Best Test Loss: 1.63748 	 Best epoch 270
EarlyStopping counter: 2 out of 50
train epoch 281 avg loss: 1.20483 (A-MSE: 1.05388) avg lploss: 0.00000
train epoch 282 avg loss: 1.28027 (A-MSE: 1.12443) avg lploss: 0.00000
train epoch 283 avg loss: 1.38533 (A-MSE: 1.21250) avg lploss: 0.00000
train epoch 284 avg loss: 1.19820 (A-MSE: 1.04968) avg lploss: 0.00000
train epoch 285 avg loss: 1.22302 (A-MSE: 1.06774) avg lploss: 0.00000
==> val epoch 285 avg loss: 1.54763 (A-MSE: 1.37434) avg lploss: 0.00000
==> test epoch 285 avg loss: 1.74974 (A-MSE: 1.57723) avg lploss: 0.00000
*** Best Val Loss: 1.49857 	 Best Test Loss: 1.63748 	 Best epoch 270
EarlyStopping counter: 3 out of 50
train epoch 286 avg loss: 1.19840 (A-MSE: 1.05577) avg lploss: 0.00000
train epoch 287 avg loss: 1.19622 (A-MSE: 1.04632) avg lploss: 0.00000
train epoch 288 avg loss: 1.21493 (A-MSE: 1.06639) avg lploss: 0.00000
train epoch 289 avg loss: 1.19301 (A-MSE: 1.04593) avg lploss: 0.00000
train epoch 290 avg loss: 1.07903 (A-MSE: 0.94463) avg lploss: 0.00000
==> val epoch 290 avg loss: 1.41410 (A-MSE: 1.26347) avg lploss: 0.00000
==> test epoch 290 avg loss: 1.58564 (A-MSE: 1.43456) avg lploss: 0.00000
*** Best Val Loss: 1.41410 	 Best Test Loss: 1.58564 	 Best epoch 290
Validation loss decreased (1.498571 --> 1.414105).  Saving model ...
train epoch 291 avg loss: 1.11005 (A-MSE: 0.97408) avg lploss: 0.00000
train epoch 292 avg loss: 1.06393 (A-MSE: 0.93327) avg lploss: 0.00000
train epoch 293 avg loss: 1.15231 (A-MSE: 1.01214) avg lploss: 0.00000
train epoch 294 avg loss: 1.15351 (A-MSE: 1.01150) avg lploss: 0.00000
train epoch 295 avg loss: 1.08389 (A-MSE: 0.94912) avg lploss: 0.00000
==> val epoch 295 avg loss: 1.34234 (A-MSE: 1.19511) avg lploss: 0.00000
==> test epoch 295 avg loss: 1.44233 (A-MSE: 1.30573) avg lploss: 0.00000
*** Best Val Loss: 1.34234 	 Best Test Loss: 1.44233 	 Best epoch 295
Validation loss decreased (1.414105 --> 1.342341).  Saving model ...
train epoch 296 avg loss: 1.09680 (A-MSE: 0.96679) avg lploss: 0.00000
train epoch 297 avg loss: 1.12017 (A-MSE: 0.98026) avg lploss: 0.00000
train epoch 298 avg loss: 1.07464 (A-MSE: 0.94645) avg lploss: 0.00000
train epoch 299 avg loss: 1.05259 (A-MSE: 0.92492) avg lploss: 0.00000
train epoch 300 avg loss: 1.17944 (A-MSE: 1.03260) avg lploss: 0.00000
==> val epoch 300 avg loss: 1.68754 (A-MSE: 1.47527) avg lploss: 0.00000
==> test epoch 300 avg loss: 1.86282 (A-MSE: 1.64798) avg lploss: 0.00000
*** Best Val Loss: 1.34234 	 Best Test Loss: 1.44233 	 Best epoch 295
EarlyStopping counter: 1 out of 50
train epoch 301 avg loss: 1.13288 (A-MSE: 0.99403) avg lploss: 0.00000
train epoch 302 avg loss: 1.15294 (A-MSE: 1.01226) avg lploss: 0.00000
train epoch 303 avg loss: 1.16411 (A-MSE: 1.01706) avg lploss: 0.00000
train epoch 304 avg loss: 1.10313 (A-MSE: 0.97514) avg lploss: 0.00000
train epoch 305 avg loss: 1.11797 (A-MSE: 0.98224) avg lploss: 0.00000
==> val epoch 305 avg loss: 1.38208 (A-MSE: 1.23168) avg lploss: 0.00000
==> test epoch 305 avg loss: 1.60106 (A-MSE: 1.45301) avg lploss: 0.00000
*** Best Val Loss: 1.34234 	 Best Test Loss: 1.44233 	 Best epoch 295
EarlyStopping counter: 2 out of 50
train epoch 306 avg loss: 1.11654 (A-MSE: 0.97820) avg lploss: 0.00000
train epoch 307 avg loss: 1.06920 (A-MSE: 0.93929) avg lploss: 0.00000
train epoch 308 avg loss: 1.06609 (A-MSE: 0.93976) avg lploss: 0.00000
train epoch 309 avg loss: 1.10541 (A-MSE: 0.97406) avg lploss: 0.00000
train epoch 310 avg loss: 1.07634 (A-MSE: 0.94150) avg lploss: 0.00000
==> val epoch 310 avg loss: 1.53340 (A-MSE: 1.36841) avg lploss: 0.00000
==> test epoch 310 avg loss: 1.69424 (A-MSE: 1.53528) avg lploss: 0.00000
*** Best Val Loss: 1.34234 	 Best Test Loss: 1.44233 	 Best epoch 295
EarlyStopping counter: 3 out of 50
train epoch 311 avg loss: 1.01987 (A-MSE: 0.89729) avg lploss: 0.00000
train epoch 312 avg loss: 1.11244 (A-MSE: 0.97646) avg lploss: 0.00000
train epoch 313 avg loss: 1.07495 (A-MSE: 0.95281) avg lploss: 0.00000
train epoch 314 avg loss: 1.07186 (A-MSE: 0.94414) avg lploss: 0.00000
train epoch 315 avg loss: 1.05496 (A-MSE: 0.92673) avg lploss: 0.00000
==> val epoch 315 avg loss: 1.39190 (A-MSE: 1.22617) avg lploss: 0.00000
==> test epoch 315 avg loss: 1.55724 (A-MSE: 1.39851) avg lploss: 0.00000
*** Best Val Loss: 1.34234 	 Best Test Loss: 1.44233 	 Best epoch 295
EarlyStopping counter: 4 out of 50
train epoch 316 avg loss: 0.98809 (A-MSE: 0.87399) avg lploss: 0.00000
train epoch 317 avg loss: 1.00495 (A-MSE: 0.88618) avg lploss: 0.00000
train epoch 318 avg loss: 1.03194 (A-MSE: 0.91505) avg lploss: 0.00000
train epoch 319 avg loss: 1.03989 (A-MSE: 0.91334) avg lploss: 0.00000
train epoch 320 avg loss: 1.03141 (A-MSE: 0.90969) avg lploss: 0.00000
==> val epoch 320 avg loss: 1.30952 (A-MSE: 1.17762) avg lploss: 0.00000
==> test epoch 320 avg loss: 1.46549 (A-MSE: 1.34109) avg lploss: 0.00000
*** Best Val Loss: 1.30952 	 Best Test Loss: 1.46549 	 Best epoch 320
Validation loss decreased (1.342341 --> 1.309523).  Saving model ...
train epoch 321 avg loss: 0.98140 (A-MSE: 0.86878) avg lploss: 0.00000
train epoch 322 avg loss: 1.16222 (A-MSE: 1.02502) avg lploss: 0.00000
train epoch 323 avg loss: 1.22095 (A-MSE: 1.07905) avg lploss: 0.00000
train epoch 324 avg loss: 0.99808 (A-MSE: 0.88337) avg lploss: 0.00000
train epoch 325 avg loss: 0.95117 (A-MSE: 0.84059) avg lploss: 0.00000
==> val epoch 325 avg loss: 1.36586 (A-MSE: 1.20911) avg lploss: 0.00000
==> test epoch 325 avg loss: 1.54303 (A-MSE: 1.39087) avg lploss: 0.00000
*** Best Val Loss: 1.30952 	 Best Test Loss: 1.46549 	 Best epoch 320
EarlyStopping counter: 1 out of 50
train epoch 326 avg loss: 0.94370 (A-MSE: 0.83368) avg lploss: 0.00000
train epoch 327 avg loss: 0.98424 (A-MSE: 0.87095) avg lploss: 0.00000
train epoch 328 avg loss: 0.93845 (A-MSE: 0.83175) avg lploss: 0.00000
train epoch 329 avg loss: 0.96577 (A-MSE: 0.85177) avg lploss: 0.00000
train epoch 330 avg loss: 0.95112 (A-MSE: 0.84569) avg lploss: 0.00000
==> val epoch 330 avg loss: 1.46197 (A-MSE: 1.28704) avg lploss: 0.00000
==> test epoch 330 avg loss: 1.61703 (A-MSE: 1.45126) avg lploss: 0.00000
*** Best Val Loss: 1.30952 	 Best Test Loss: 1.46549 	 Best epoch 320
EarlyStopping counter: 2 out of 50
train epoch 331 avg loss: 0.96510 (A-MSE: 0.85324) avg lploss: 0.00000
train epoch 332 avg loss: 0.95249 (A-MSE: 0.84232) avg lploss: 0.00000
train epoch 333 avg loss: 0.90936 (A-MSE: 0.80730) avg lploss: 0.00000
train epoch 334 avg loss: 0.88216 (A-MSE: 0.78810) avg lploss: 0.00000
train epoch 335 avg loss: 0.96602 (A-MSE: 0.85277) avg lploss: 0.00000
==> val epoch 335 avg loss: 1.28523 (A-MSE: 1.15769) avg lploss: 0.00000
==> test epoch 335 avg loss: 1.45420 (A-MSE: 1.33453) avg lploss: 0.00000
*** Best Val Loss: 1.28523 	 Best Test Loss: 1.45420 	 Best epoch 335
Validation loss decreased (1.309523 --> 1.285225).  Saving model ...
train epoch 336 avg loss: 0.98050 (A-MSE: 0.86801) avg lploss: 0.00000
train epoch 337 avg loss: 0.96151 (A-MSE: 0.85016) avg lploss: 0.00000
train epoch 338 avg loss: 0.91678 (A-MSE: 0.80947) avg lploss: 0.00000
train epoch 339 avg loss: 0.88744 (A-MSE: 0.78885) avg lploss: 0.00000
train epoch 340 avg loss: 0.85202 (A-MSE: 0.75809) avg lploss: 0.00000
==> val epoch 340 avg loss: 1.18478 (A-MSE: 1.06016) avg lploss: 0.00000
==> test epoch 340 avg loss: 1.31406 (A-MSE: 1.20115) avg lploss: 0.00000
*** Best Val Loss: 1.18478 	 Best Test Loss: 1.31406 	 Best epoch 340
Validation loss decreased (1.285225 --> 1.184784).  Saving model ...
train epoch 341 avg loss: 0.87007 (A-MSE: 0.77814) avg lploss: 0.00000
train epoch 342 avg loss: 1.07361 (A-MSE: 0.94589) avg lploss: 0.00000
train epoch 343 avg loss: 0.96916 (A-MSE: 0.85722) avg lploss: 0.00000
train epoch 344 avg loss: 0.87075 (A-MSE: 0.77513) avg lploss: 0.00000
train epoch 345 avg loss: 0.89217 (A-MSE: 0.79004) avg lploss: 0.00000
==> val epoch 345 avg loss: 1.48402 (A-MSE: 1.32485) avg lploss: 0.00000
==> test epoch 345 avg loss: 1.63035 (A-MSE: 1.48702) avg lploss: 0.00000
*** Best Val Loss: 1.18478 	 Best Test Loss: 1.31406 	 Best epoch 340
EarlyStopping counter: 1 out of 50
train epoch 346 avg loss: 1.00873 (A-MSE: 0.89941) avg lploss: 0.00000
train epoch 347 avg loss: 0.99392 (A-MSE: 0.87991) avg lploss: 0.00000
train epoch 348 avg loss: 0.89985 (A-MSE: 0.79933) avg lploss: 0.00000
train epoch 349 avg loss: 0.90009 (A-MSE: 0.80024) avg lploss: 0.00000
train epoch 350 avg loss: 0.95882 (A-MSE: 0.84991) avg lploss: 0.00000
==> val epoch 350 avg loss: 1.37597 (A-MSE: 1.22055) avg lploss: 0.00000
==> test epoch 350 avg loss: 1.56137 (A-MSE: 1.40820) avg lploss: 0.00000
*** Best Val Loss: 1.18478 	 Best Test Loss: 1.31406 	 Best epoch 340
EarlyStopping counter: 2 out of 50
train epoch 351 avg loss: 0.91585 (A-MSE: 0.80888) avg lploss: 0.00000
train epoch 352 avg loss: 0.87694 (A-MSE: 0.77983) avg lploss: 0.00000
train epoch 353 avg loss: 0.84822 (A-MSE: 0.76177) avg lploss: 0.00000
train epoch 354 avg loss: 0.88863 (A-MSE: 0.78982) avg lploss: 0.00000
train epoch 355 avg loss: 0.82476 (A-MSE: 0.73370) avg lploss: 0.00000
==> val epoch 355 avg loss: 1.20458 (A-MSE: 1.06896) avg lploss: 0.00000
==> test epoch 355 avg loss: 1.40323 (A-MSE: 1.27018) avg lploss: 0.00000
*** Best Val Loss: 1.18478 	 Best Test Loss: 1.31406 	 Best epoch 340
EarlyStopping counter: 3 out of 50
train epoch 356 avg loss: 0.84339 (A-MSE: 0.75204) avg lploss: 0.00000
train epoch 357 avg loss: 0.84736 (A-MSE: 0.75319) avg lploss: 0.00000
train epoch 358 avg loss: 0.79747 (A-MSE: 0.71293) avg lploss: 0.00000
train epoch 359 avg loss: 0.92442 (A-MSE: 0.81675) avg lploss: 0.00000
train epoch 360 avg loss: 0.95481 (A-MSE: 0.84263) avg lploss: 0.00000
==> val epoch 360 avg loss: 1.66962 (A-MSE: 1.45062) avg lploss: 0.00000
==> test epoch 360 avg loss: 1.89840 (A-MSE: 1.67581) avg lploss: 0.00000
*** Best Val Loss: 1.18478 	 Best Test Loss: 1.31406 	 Best epoch 340
EarlyStopping counter: 4 out of 50
train epoch 361 avg loss: 0.92240 (A-MSE: 0.81627) avg lploss: 0.00000
train epoch 362 avg loss: 0.83930 (A-MSE: 0.74189) avg lploss: 0.00000
train epoch 363 avg loss: 0.82276 (A-MSE: 0.72941) avg lploss: 0.00000
train epoch 364 avg loss: 0.82339 (A-MSE: 0.73146) avg lploss: 0.00000
train epoch 365 avg loss: 0.82474 (A-MSE: 0.72792) avg lploss: 0.00000
==> val epoch 365 avg loss: 1.15891 (A-MSE: 1.03467) avg lploss: 0.00000
==> test epoch 365 avg loss: 1.32145 (A-MSE: 1.20158) avg lploss: 0.00000
*** Best Val Loss: 1.15891 	 Best Test Loss: 1.32145 	 Best epoch 365
Validation loss decreased (1.184784 --> 1.158914).  Saving model ...
train epoch 366 avg loss: 0.83124 (A-MSE: 0.74220) avg lploss: 0.00000
train epoch 367 avg loss: 0.80485 (A-MSE: 0.71610) avg lploss: 0.00000
train epoch 368 avg loss: 0.84430 (A-MSE: 0.74839) avg lploss: 0.00000
train epoch 369 avg loss: 0.84064 (A-MSE: 0.75011) avg lploss: 0.00000
train epoch 370 avg loss: 0.80344 (A-MSE: 0.71466) avg lploss: 0.00000
==> val epoch 370 avg loss: 1.38245 (A-MSE: 1.23640) avg lploss: 0.00000
==> test epoch 370 avg loss: 1.61141 (A-MSE: 1.46212) avg lploss: 0.00000
*** Best Val Loss: 1.15891 	 Best Test Loss: 1.32145 	 Best epoch 365
EarlyStopping counter: 1 out of 50
train epoch 371 avg loss: 0.79059 (A-MSE: 0.70071) avg lploss: 0.00000
train epoch 372 avg loss: 0.75302 (A-MSE: 0.66799) avg lploss: 0.00000
train epoch 373 avg loss: 0.81831 (A-MSE: 0.72462) avg lploss: 0.00000
train epoch 374 avg loss: 0.75020 (A-MSE: 0.67072) avg lploss: 0.00000
train epoch 375 avg loss: 0.74218 (A-MSE: 0.66112) avg lploss: 0.00000
==> val epoch 375 avg loss: 1.05513 (A-MSE: 0.95442) avg lploss: 0.00000
==> test epoch 375 avg loss: 1.20154 (A-MSE: 1.10342) avg lploss: 0.00000
*** Best Val Loss: 1.05513 	 Best Test Loss: 1.20154 	 Best epoch 375
Validation loss decreased (1.158914 --> 1.055129).  Saving model ...
train epoch 376 avg loss: 0.83666 (A-MSE: 0.74473) avg lploss: 0.00000
train epoch 377 avg loss: 0.84350 (A-MSE: 0.74806) avg lploss: 0.00000
train epoch 378 avg loss: 0.79834 (A-MSE: 0.71183) avg lploss: 0.00000
train epoch 379 avg loss: 0.85474 (A-MSE: 0.76211) avg lploss: 0.00000
train epoch 380 avg loss: 0.74571 (A-MSE: 0.66287) avg lploss: 0.00000
==> val epoch 380 avg loss: 1.32239 (A-MSE: 1.16961) avg lploss: 0.00000
==> test epoch 380 avg loss: 1.47242 (A-MSE: 1.32673) avg lploss: 0.00000
*** Best Val Loss: 1.05513 	 Best Test Loss: 1.20154 	 Best epoch 375
EarlyStopping counter: 1 out of 50
train epoch 381 avg loss: 0.79327 (A-MSE: 0.70353) avg lploss: 0.00000
train epoch 382 avg loss: 0.79432 (A-MSE: 0.71154) avg lploss: 0.00000
train epoch 383 avg loss: 0.88757 (A-MSE: 0.78754) avg lploss: 0.00000
train epoch 384 avg loss: 0.77860 (A-MSE: 0.69039) avg lploss: 0.00000
train epoch 385 avg loss: 0.79044 (A-MSE: 0.70301) avg lploss: 0.00000
==> val epoch 385 avg loss: 1.31849 (A-MSE: 1.14264) avg lploss: 0.00000
==> test epoch 385 avg loss: 1.45592 (A-MSE: 1.28414) avg lploss: 0.00000
*** Best Val Loss: 1.05513 	 Best Test Loss: 1.20154 	 Best epoch 375
EarlyStopping counter: 2 out of 50
train epoch 386 avg loss: 0.76589 (A-MSE: 0.67998) avg lploss: 0.00000
train epoch 387 avg loss: 0.80712 (A-MSE: 0.71487) avg lploss: 0.00000
train epoch 388 avg loss: 0.84020 (A-MSE: 0.74621) avg lploss: 0.00000
train epoch 389 avg loss: 0.79214 (A-MSE: 0.70264) avg lploss: 0.00000
train epoch 390 avg loss: 0.83041 (A-MSE: 0.73940) avg lploss: 0.00000
==> val epoch 390 avg loss: 1.06701 (A-MSE: 0.95671) avg lploss: 0.00000
==> test epoch 390 avg loss: 1.16585 (A-MSE: 1.06371) avg lploss: 0.00000
*** Best Val Loss: 1.05513 	 Best Test Loss: 1.20154 	 Best epoch 375
EarlyStopping counter: 3 out of 50
train epoch 391 avg loss: 0.71710 (A-MSE: 0.63194) avg lploss: 0.00000
train epoch 392 avg loss: 0.71112 (A-MSE: 0.63334) avg lploss: 0.00000
train epoch 393 avg loss: 0.75836 (A-MSE: 0.67433) avg lploss: 0.00000
train epoch 394 avg loss: 0.75292 (A-MSE: 0.66898) avg lploss: 0.00000
train epoch 395 avg loss: 0.75235 (A-MSE: 0.66996) avg lploss: 0.00000
==> val epoch 395 avg loss: 1.14510 (A-MSE: 1.02511) avg lploss: 0.00000
==> test epoch 395 avg loss: 1.34434 (A-MSE: 1.21984) avg lploss: 0.00000
*** Best Val Loss: 1.05513 	 Best Test Loss: 1.20154 	 Best epoch 375
EarlyStopping counter: 4 out of 50
train epoch 396 avg loss: 0.72493 (A-MSE: 0.64624) avg lploss: 0.00000
train epoch 397 avg loss: 0.69188 (A-MSE: 0.61580) avg lploss: 0.00000
train epoch 398 avg loss: 0.70527 (A-MSE: 0.62994) avg lploss: 0.00000
train epoch 399 avg loss: 0.72166 (A-MSE: 0.64016) avg lploss: 0.00000
train epoch 400 avg loss: 0.77759 (A-MSE: 0.69062) avg lploss: 0.00000
==> val epoch 400 avg loss: 1.04496 (A-MSE: 0.93645) avg lploss: 0.00000
==> test epoch 400 avg loss: 1.13772 (A-MSE: 1.03927) avg lploss: 0.00000
*** Best Val Loss: 1.04496 	 Best Test Loss: 1.13772 	 Best epoch 400
Validation loss decreased (1.055129 --> 1.044956).  Saving model ...
train epoch 401 avg loss: 0.74610 (A-MSE: 0.66405) avg lploss: 0.00000
train epoch 402 avg loss: 0.70268 (A-MSE: 0.62296) avg lploss: 0.00000
train epoch 403 avg loss: 0.69596 (A-MSE: 0.61475) avg lploss: 0.00000
train epoch 404 avg loss: 0.69192 (A-MSE: 0.61962) avg lploss: 0.00000
train epoch 405 avg loss: 0.67144 (A-MSE: 0.59880) avg lploss: 0.00000
==> val epoch 405 avg loss: 1.14982 (A-MSE: 1.01972) avg lploss: 0.00000
==> test epoch 405 avg loss: 1.30531 (A-MSE: 1.17943) avg lploss: 0.00000
*** Best Val Loss: 1.04496 	 Best Test Loss: 1.13772 	 Best epoch 400
EarlyStopping counter: 1 out of 50
train epoch 406 avg loss: 0.69572 (A-MSE: 0.61868) avg lploss: 0.00000
train epoch 407 avg loss: 0.66332 (A-MSE: 0.58993) avg lploss: 0.00000
train epoch 408 avg loss: 0.70070 (A-MSE: 0.62086) avg lploss: 0.00000
train epoch 409 avg loss: 0.76653 (A-MSE: 0.67560) avg lploss: 0.00000
train epoch 410 avg loss: 0.74615 (A-MSE: 0.66948) avg lploss: 0.00000
==> val epoch 410 avg loss: 1.06371 (A-MSE: 0.95716) avg lploss: 0.00000
==> test epoch 410 avg loss: 1.19054 (A-MSE: 1.08821) avg lploss: 0.00000
*** Best Val Loss: 1.04496 	 Best Test Loss: 1.13772 	 Best epoch 400
EarlyStopping counter: 2 out of 50
train epoch 411 avg loss: 0.72291 (A-MSE: 0.64400) avg lploss: 0.00000
train epoch 412 avg loss: 0.69436 (A-MSE: 0.61065) avg lploss: 0.00000
train epoch 413 avg loss: 0.69196 (A-MSE: 0.61392) avg lploss: 0.00000
train epoch 414 avg loss: 0.71675 (A-MSE: 0.63667) avg lploss: 0.00000
train epoch 415 avg loss: 0.67112 (A-MSE: 0.59759) avg lploss: 0.00000
==> val epoch 415 avg loss: 1.21326 (A-MSE: 1.06426) avg lploss: 0.00000
==> test epoch 415 avg loss: 1.38812 (A-MSE: 1.23746) avg lploss: 0.00000
*** Best Val Loss: 1.04496 	 Best Test Loss: 1.13772 	 Best epoch 400
EarlyStopping counter: 3 out of 50
train epoch 416 avg loss: 0.68235 (A-MSE: 0.60635) avg lploss: 0.00000
train epoch 417 avg loss: 0.61876 (A-MSE: 0.55068) avg lploss: 0.00000
train epoch 418 avg loss: 0.65272 (A-MSE: 0.57965) avg lploss: 0.00000
train epoch 419 avg loss: 0.65263 (A-MSE: 0.58105) avg lploss: 0.00000
train epoch 420 avg loss: 0.69066 (A-MSE: 0.61045) avg lploss: 0.00000
==> val epoch 420 avg loss: 1.03100 (A-MSE: 0.91316) avg lploss: 0.00000
==> test epoch 420 avg loss: 1.20605 (A-MSE: 1.08291) avg lploss: 0.00000
*** Best Val Loss: 1.03100 	 Best Test Loss: 1.20605 	 Best epoch 420
Validation loss decreased (1.044956 --> 1.030996).  Saving model ...
train epoch 421 avg loss: 0.65965 (A-MSE: 0.58467) avg lploss: 0.00000
train epoch 422 avg loss: 0.67695 (A-MSE: 0.59980) avg lploss: 0.00000
train epoch 423 avg loss: 0.63112 (A-MSE: 0.56215) avg lploss: 0.00000
train epoch 424 avg loss: 0.63526 (A-MSE: 0.56667) avg lploss: 0.00000
train epoch 425 avg loss: 0.63185 (A-MSE: 0.56051) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.99348 (A-MSE: 0.90028) avg lploss: 0.00000
==> test epoch 425 avg loss: 1.16915 (A-MSE: 1.07096) avg lploss: 0.00000
*** Best Val Loss: 0.99348 	 Best Test Loss: 1.16915 	 Best epoch 425
Validation loss decreased (1.030996 --> 0.993482).  Saving model ...
train epoch 426 avg loss: 0.61114 (A-MSE: 0.54146) avg lploss: 0.00000
train epoch 427 avg loss: 0.62233 (A-MSE: 0.55051) avg lploss: 0.00000
train epoch 428 avg loss: 0.70287 (A-MSE: 0.62337) avg lploss: 0.00000
train epoch 429 avg loss: 0.68182 (A-MSE: 0.60571) avg lploss: 0.00000
train epoch 430 avg loss: 0.64101 (A-MSE: 0.56679) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.88872 (A-MSE: 0.81523) avg lploss: 0.00000
==> test epoch 430 avg loss: 1.02086 (A-MSE: 0.94993) avg lploss: 0.00000
*** Best Val Loss: 0.88872 	 Best Test Loss: 1.02086 	 Best epoch 430
Validation loss decreased (0.993482 --> 0.888721).  Saving model ...
train epoch 431 avg loss: 0.64481 (A-MSE: 0.57706) avg lploss: 0.00000
train epoch 432 avg loss: 0.70432 (A-MSE: 0.62552) avg lploss: 0.00000
train epoch 433 avg loss: 0.61428 (A-MSE: 0.54524) avg lploss: 0.00000
train epoch 434 avg loss: 0.63740 (A-MSE: 0.56570) avg lploss: 0.00000
train epoch 435 avg loss: 0.64877 (A-MSE: 0.57962) avg lploss: 0.00000
==> val epoch 435 avg loss: 1.23198 (A-MSE: 1.11771) avg lploss: 0.00000
==> test epoch 435 avg loss: 1.36791 (A-MSE: 1.25450) avg lploss: 0.00000
*** Best Val Loss: 0.88872 	 Best Test Loss: 1.02086 	 Best epoch 430
EarlyStopping counter: 1 out of 50
train epoch 436 avg loss: 0.74666 (A-MSE: 0.66089) avg lploss: 0.00000
train epoch 437 avg loss: 0.79998 (A-MSE: 0.70626) avg lploss: 0.00000
train epoch 438 avg loss: 0.76542 (A-MSE: 0.68186) avg lploss: 0.00000
train epoch 439 avg loss: 0.72224 (A-MSE: 0.64048) avg lploss: 0.00000
train epoch 440 avg loss: 0.69506 (A-MSE: 0.61018) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.88466 (A-MSE: 0.80659) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.99563 (A-MSE: 0.91776) avg lploss: 0.00000
*** Best Val Loss: 0.88466 	 Best Test Loss: 0.99563 	 Best epoch 440
Validation loss decreased (0.888721 --> 0.884660).  Saving model ...
train epoch 441 avg loss: 0.65225 (A-MSE: 0.57800) avg lploss: 0.00000
train epoch 442 avg loss: 0.63484 (A-MSE: 0.56324) avg lploss: 0.00000
train epoch 443 avg loss: 0.64881 (A-MSE: 0.57510) avg lploss: 0.00000
train epoch 444 avg loss: 0.62163 (A-MSE: 0.54985) avg lploss: 0.00000
train epoch 445 avg loss: 0.61578 (A-MSE: 0.54405) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.95193 (A-MSE: 0.85316) avg lploss: 0.00000
==> test epoch 445 avg loss: 1.09179 (A-MSE: 0.98921) avg lploss: 0.00000
*** Best Val Loss: 0.88466 	 Best Test Loss: 0.99563 	 Best epoch 440
EarlyStopping counter: 1 out of 50
train epoch 446 avg loss: 0.58977 (A-MSE: 0.52220) avg lploss: 0.00000
train epoch 447 avg loss: 0.63995 (A-MSE: 0.56714) avg lploss: 0.00000
train epoch 448 avg loss: 0.61562 (A-MSE: 0.54524) avg lploss: 0.00000
train epoch 449 avg loss: 0.56598 (A-MSE: 0.50217) avg lploss: 0.00000
train epoch 450 avg loss: 0.57879 (A-MSE: 0.51262) avg lploss: 0.00000
==> val epoch 450 avg loss: 1.12270 (A-MSE: 0.99277) avg lploss: 0.00000
==> test epoch 450 avg loss: 1.27348 (A-MSE: 1.13780) avg lploss: 0.00000
*** Best Val Loss: 0.88466 	 Best Test Loss: 0.99563 	 Best epoch 440
EarlyStopping counter: 2 out of 50
train epoch 451 avg loss: 0.64809 (A-MSE: 0.57341) avg lploss: 0.00000
train epoch 452 avg loss: 0.62363 (A-MSE: 0.55025) avg lploss: 0.00000
train epoch 453 avg loss: 0.62503 (A-MSE: 0.55437) avg lploss: 0.00000
train epoch 454 avg loss: 0.58821 (A-MSE: 0.52273) avg lploss: 0.00000
train epoch 455 avg loss: 0.57270 (A-MSE: 0.50737) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.84041 (A-MSE: 0.75341) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.99544 (A-MSE: 0.90011) avg lploss: 0.00000
*** Best Val Loss: 0.84041 	 Best Test Loss: 0.99544 	 Best epoch 455
Validation loss decreased (0.884660 --> 0.840408).  Saving model ...
train epoch 456 avg loss: 0.57323 (A-MSE: 0.50966) avg lploss: 0.00000
train epoch 457 avg loss: 0.56833 (A-MSE: 0.50331) avg lploss: 0.00000
train epoch 458 avg loss: 0.55686 (A-MSE: 0.49097) avg lploss: 0.00000
train epoch 459 avg loss: 0.56743 (A-MSE: 0.50243) avg lploss: 0.00000
train epoch 460 avg loss: 0.55672 (A-MSE: 0.49490) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.98385 (A-MSE: 0.86561) avg lploss: 0.00000
==> test epoch 460 avg loss: 1.12678 (A-MSE: 1.00323) avg lploss: 0.00000
*** Best Val Loss: 0.84041 	 Best Test Loss: 0.99544 	 Best epoch 455
EarlyStopping counter: 1 out of 50
train epoch 461 avg loss: 0.61110 (A-MSE: 0.53897) avg lploss: 0.00000
train epoch 462 avg loss: 0.57114 (A-MSE: 0.50783) avg lploss: 0.00000
train epoch 463 avg loss: 0.54651 (A-MSE: 0.48182) avg lploss: 0.00000
train epoch 464 avg loss: 0.57924 (A-MSE: 0.51268) avg lploss: 0.00000
train epoch 465 avg loss: 0.53022 (A-MSE: 0.46839) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.83615 (A-MSE: 0.74789) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.97531 (A-MSE: 0.88046) avg lploss: 0.00000
*** Best Val Loss: 0.83615 	 Best Test Loss: 0.97531 	 Best epoch 465
Validation loss decreased (0.840408 --> 0.836147).  Saving model ...
train epoch 466 avg loss: 0.60255 (A-MSE: 0.53551) avg lploss: 0.00000
train epoch 467 avg loss: 0.60521 (A-MSE: 0.53435) avg lploss: 0.00000
train epoch 468 avg loss: 0.59109 (A-MSE: 0.52297) avg lploss: 0.00000
train epoch 469 avg loss: 0.64424 (A-MSE: 0.56893) avg lploss: 0.00000
train epoch 470 avg loss: 0.62968 (A-MSE: 0.55050) avg lploss: 0.00000
==> val epoch 470 avg loss: 1.19411 (A-MSE: 1.04083) avg lploss: 0.00000
==> test epoch 470 avg loss: 1.40663 (A-MSE: 1.24041) avg lploss: 0.00000
*** Best Val Loss: 0.83615 	 Best Test Loss: 0.97531 	 Best epoch 465
EarlyStopping counter: 1 out of 50
train epoch 471 avg loss: 0.63706 (A-MSE: 0.56538) avg lploss: 0.00000
train epoch 472 avg loss: 0.58238 (A-MSE: 0.51533) avg lploss: 0.00000
train epoch 473 avg loss: 0.61586 (A-MSE: 0.54109) avg lploss: 0.00000
train epoch 474 avg loss: 0.63227 (A-MSE: 0.55587) avg lploss: 0.00000
train epoch 475 avg loss: 0.62699 (A-MSE: 0.55424) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.87310 (A-MSE: 0.77544) avg lploss: 0.00000
==> test epoch 475 avg loss: 1.04320 (A-MSE: 0.93714) avg lploss: 0.00000
*** Best Val Loss: 0.83615 	 Best Test Loss: 0.97531 	 Best epoch 465
EarlyStopping counter: 2 out of 50
train epoch 476 avg loss: 0.55308 (A-MSE: 0.48799) avg lploss: 0.00000
train epoch 477 avg loss: 0.58777 (A-MSE: 0.51836) avg lploss: 0.00000
train epoch 478 avg loss: 0.57842 (A-MSE: 0.50795) avg lploss: 0.00000
train epoch 479 avg loss: 0.59500 (A-MSE: 0.52405) avg lploss: 0.00000
train epoch 480 avg loss: 0.56857 (A-MSE: 0.49958) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.83946 (A-MSE: 0.74981) avg lploss: 0.00000
==> test epoch 480 avg loss: 1.00232 (A-MSE: 0.90206) avg lploss: 0.00000
*** Best Val Loss: 0.83615 	 Best Test Loss: 0.97531 	 Best epoch 465
EarlyStopping counter: 3 out of 50
train epoch 481 avg loss: 0.54207 (A-MSE: 0.47603) avg lploss: 0.00000
train epoch 482 avg loss: 0.51875 (A-MSE: 0.46054) avg lploss: 0.00000
train epoch 483 avg loss: 0.50619 (A-MSE: 0.44753) avg lploss: 0.00000
train epoch 484 avg loss: 0.54635 (A-MSE: 0.48302) avg lploss: 0.00000
train epoch 485 avg loss: 0.52122 (A-MSE: 0.46122) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.79079 (A-MSE: 0.70540) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.93956 (A-MSE: 0.84628) avg lploss: 0.00000
*** Best Val Loss: 0.79079 	 Best Test Loss: 0.93956 	 Best epoch 485
Validation loss decreased (0.836147 --> 0.790788).  Saving model ...
train epoch 486 avg loss: 0.52534 (A-MSE: 0.46404) avg lploss: 0.00000
train epoch 487 avg loss: 0.50268 (A-MSE: 0.44321) avg lploss: 0.00000
train epoch 488 avg loss: 0.54528 (A-MSE: 0.48280) avg lploss: 0.00000
train epoch 489 avg loss: 0.51485 (A-MSE: 0.45329) avg lploss: 0.00000
train epoch 490 avg loss: 0.50975 (A-MSE: 0.44892) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.86092 (A-MSE: 0.76671) avg lploss: 0.00000
==> test epoch 490 avg loss: 1.03350 (A-MSE: 0.92583) avg lploss: 0.00000
*** Best Val Loss: 0.79079 	 Best Test Loss: 0.93956 	 Best epoch 485
EarlyStopping counter: 1 out of 50
train epoch 491 avg loss: 0.55733 (A-MSE: 0.49249) avg lploss: 0.00000
train epoch 492 avg loss: 0.52196 (A-MSE: 0.46231) avg lploss: 0.00000
train epoch 493 avg loss: 0.53348 (A-MSE: 0.46984) avg lploss: 0.00000
train epoch 494 avg loss: 0.49406 (A-MSE: 0.43527) avg lploss: 0.00000
train epoch 495 avg loss: 0.50352 (A-MSE: 0.44136) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.92941 (A-MSE: 0.82249) avg lploss: 0.00000
==> test epoch 495 avg loss: 1.09328 (A-MSE: 0.97287) avg lploss: 0.00000
*** Best Val Loss: 0.79079 	 Best Test Loss: 0.93956 	 Best epoch 485
EarlyStopping counter: 2 out of 50
train epoch 496 avg loss: 0.48010 (A-MSE: 0.42855) avg lploss: 0.00000
train epoch 497 avg loss: 0.56402 (A-MSE: 0.49230) avg lploss: 0.00000
train epoch 498 avg loss: 0.55620 (A-MSE: 0.48950) avg lploss: 0.00000
train epoch 499 avg loss: 0.66225 (A-MSE: 0.58610) avg lploss: 0.00000
train epoch 500 avg loss: 0.60022 (A-MSE: 0.53004) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.78410 (A-MSE: 0.71142) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.89915 (A-MSE: 0.82383) avg lploss: 0.00000
*** Best Val Loss: 0.78410 	 Best Test Loss: 0.89915 	 Best epoch 500
Validation loss decreased (0.790788 --> 0.784102).  Saving model ...
train epoch 501 avg loss: 0.53617 (A-MSE: 0.47612) avg lploss: 0.00000
train epoch 502 avg loss: 0.54226 (A-MSE: 0.47892) avg lploss: 0.00000
train epoch 503 avg loss: 0.57540 (A-MSE: 0.50902) avg lploss: 0.00000
train epoch 504 avg loss: 0.58495 (A-MSE: 0.51618) avg lploss: 0.00000
train epoch 505 avg loss: 0.55918 (A-MSE: 0.49131) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.94359 (A-MSE: 0.82016) avg lploss: 0.00000
==> test epoch 505 avg loss: 1.10288 (A-MSE: 0.97073) avg lploss: 0.00000
*** Best Val Loss: 0.78410 	 Best Test Loss: 0.89915 	 Best epoch 500
EarlyStopping counter: 1 out of 50
train epoch 506 avg loss: 0.54678 (A-MSE: 0.47654) avg lploss: 0.00000
train epoch 507 avg loss: 0.50773 (A-MSE: 0.44567) avg lploss: 0.00000
train epoch 508 avg loss: 0.49548 (A-MSE: 0.43660) avg lploss: 0.00000
train epoch 509 avg loss: 0.49274 (A-MSE: 0.43379) avg lploss: 0.00000
train epoch 510 avg loss: 0.46407 (A-MSE: 0.40989) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.86523 (A-MSE: 0.77220) avg lploss: 0.00000
==> test epoch 510 avg loss: 1.02832 (A-MSE: 0.92397) avg lploss: 0.00000
*** Best Val Loss: 0.78410 	 Best Test Loss: 0.89915 	 Best epoch 500
EarlyStopping counter: 2 out of 50
train epoch 511 avg loss: 0.49634 (A-MSE: 0.43760) avg lploss: 0.00000
train epoch 512 avg loss: 0.52588 (A-MSE: 0.46178) avg lploss: 0.00000
train epoch 513 avg loss: 0.50741 (A-MSE: 0.44584) avg lploss: 0.00000
train epoch 514 avg loss: 0.53215 (A-MSE: 0.46876) avg lploss: 0.00000
train epoch 515 avg loss: 0.51049 (A-MSE: 0.45218) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.79358 (A-MSE: 0.71823) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.94016 (A-MSE: 0.85159) avg lploss: 0.00000
*** Best Val Loss: 0.78410 	 Best Test Loss: 0.89915 	 Best epoch 500
EarlyStopping counter: 3 out of 50
train epoch 516 avg loss: 0.50036 (A-MSE: 0.44233) avg lploss: 0.00000
train epoch 517 avg loss: 0.49985 (A-MSE: 0.44141) avg lploss: 0.00000
train epoch 518 avg loss: 0.52231 (A-MSE: 0.46154) avg lploss: 0.00000
train epoch 519 avg loss: 0.53489 (A-MSE: 0.47197) avg lploss: 0.00000
train epoch 520 avg loss: 0.51896 (A-MSE: 0.45529) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.74779 (A-MSE: 0.66323) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.88410 (A-MSE: 0.79579) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
Validation loss decreased (0.784102 --> 0.747790).  Saving model ...
train epoch 521 avg loss: 0.48316 (A-MSE: 0.42584) avg lploss: 0.00000
train epoch 522 avg loss: 0.47793 (A-MSE: 0.41928) avg lploss: 0.00000
train epoch 523 avg loss: 0.49587 (A-MSE: 0.43423) avg lploss: 0.00000
train epoch 524 avg loss: 0.48635 (A-MSE: 0.43192) avg lploss: 0.00000
train epoch 525 avg loss: 0.51005 (A-MSE: 0.44687) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.79104 (A-MSE: 0.70480) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.93734 (A-MSE: 0.84099) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 1 out of 50
train epoch 526 avg loss: 0.51347 (A-MSE: 0.45638) avg lploss: 0.00000
train epoch 527 avg loss: 0.61012 (A-MSE: 0.53670) avg lploss: 0.00000
train epoch 528 avg loss: 0.57327 (A-MSE: 0.50838) avg lploss: 0.00000
train epoch 529 avg loss: 0.54307 (A-MSE: 0.47557) avg lploss: 0.00000
train epoch 530 avg loss: 0.50764 (A-MSE: 0.44908) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.89846 (A-MSE: 0.78078) avg lploss: 0.00000
==> test epoch 530 avg loss: 1.07008 (A-MSE: 0.94035) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 2 out of 50
train epoch 531 avg loss: 0.46292 (A-MSE: 0.40551) avg lploss: 0.00000
train epoch 532 avg loss: 0.53336 (A-MSE: 0.46952) avg lploss: 0.00000
train epoch 533 avg loss: 0.47519 (A-MSE: 0.41790) avg lploss: 0.00000
train epoch 534 avg loss: 0.45926 (A-MSE: 0.40886) avg lploss: 0.00000
train epoch 535 avg loss: 0.47920 (A-MSE: 0.42049) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.79924 (A-MSE: 0.71118) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.92516 (A-MSE: 0.82324) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 3 out of 50
train epoch 536 avg loss: 0.44410 (A-MSE: 0.39352) avg lploss: 0.00000
train epoch 537 avg loss: 0.43439 (A-MSE: 0.38135) avg lploss: 0.00000
train epoch 538 avg loss: 0.48534 (A-MSE: 0.42396) avg lploss: 0.00000
train epoch 539 avg loss: 0.50942 (A-MSE: 0.44754) avg lploss: 0.00000
train epoch 540 avg loss: 0.52809 (A-MSE: 0.46516) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.93145 (A-MSE: 0.81772) avg lploss: 0.00000
==> test epoch 540 avg loss: 1.12367 (A-MSE: 0.99755) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 4 out of 50
train epoch 541 avg loss: 0.47928 (A-MSE: 0.42426) avg lploss: 0.00000
train epoch 542 avg loss: 0.51064 (A-MSE: 0.45188) avg lploss: 0.00000
train epoch 543 avg loss: 0.47351 (A-MSE: 0.41723) avg lploss: 0.00000
train epoch 544 avg loss: 0.44551 (A-MSE: 0.39149) avg lploss: 0.00000
train epoch 545 avg loss: 0.43902 (A-MSE: 0.38188) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.77453 (A-MSE: 0.69938) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.90472 (A-MSE: 0.82042) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 5 out of 50
train epoch 546 avg loss: 0.45142 (A-MSE: 0.39849) avg lploss: 0.00000
train epoch 547 avg loss: 0.43860 (A-MSE: 0.38771) avg lploss: 0.00000
train epoch 548 avg loss: 0.42644 (A-MSE: 0.37492) avg lploss: 0.00000
train epoch 549 avg loss: 0.45621 (A-MSE: 0.40338) avg lploss: 0.00000
train epoch 550 avg loss: 0.45072 (A-MSE: 0.39813) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.76494 (A-MSE: 0.68463) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.89380 (A-MSE: 0.80585) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 6 out of 50
train epoch 551 avg loss: 0.44326 (A-MSE: 0.39059) avg lploss: 0.00000
train epoch 552 avg loss: 0.45318 (A-MSE: 0.40133) avg lploss: 0.00000
train epoch 553 avg loss: 0.46983 (A-MSE: 0.41186) avg lploss: 0.00000
train epoch 554 avg loss: 0.43752 (A-MSE: 0.38654) avg lploss: 0.00000
train epoch 555 avg loss: 0.46949 (A-MSE: 0.41075) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.88041 (A-MSE: 0.76186) avg lploss: 0.00000
==> test epoch 555 avg loss: 1.03185 (A-MSE: 0.90148) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 7 out of 50
train epoch 556 avg loss: 0.42808 (A-MSE: 0.37569) avg lploss: 0.00000
train epoch 557 avg loss: 0.44199 (A-MSE: 0.38923) avg lploss: 0.00000
train epoch 558 avg loss: 0.41900 (A-MSE: 0.37053) avg lploss: 0.00000
train epoch 559 avg loss: 0.43268 (A-MSE: 0.38035) avg lploss: 0.00000
train epoch 560 avg loss: 0.46753 (A-MSE: 0.41227) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.85139 (A-MSE: 0.75334) avg lploss: 0.00000
==> test epoch 560 avg loss: 1.00466 (A-MSE: 0.89319) avg lploss: 0.00000
*** Best Val Loss: 0.74779 	 Best Test Loss: 0.88410 	 Best epoch 520
EarlyStopping counter: 8 out of 50
train epoch 561 avg loss: 0.43031 (A-MSE: 0.38142) avg lploss: 0.00000
train epoch 562 avg loss: 0.45103 (A-MSE: 0.39718) avg lploss: 0.00000
train epoch 563 avg loss: 0.48544 (A-MSE: 0.42794) avg lploss: 0.00000
train epoch 564 avg loss: 0.44292 (A-MSE: 0.39129) avg lploss: 0.00000
train epoch 565 avg loss: 0.48994 (A-MSE: 0.42801) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.73921 (A-MSE: 0.66600) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.86029 (A-MSE: 0.78165) avg lploss: 0.00000
*** Best Val Loss: 0.73921 	 Best Test Loss: 0.86029 	 Best epoch 565
Validation loss decreased (0.747790 --> 0.739208).  Saving model ...
train epoch 566 avg loss: 0.44349 (A-MSE: 0.39133) avg lploss: 0.00000
train epoch 567 avg loss: 0.38756 (A-MSE: 0.34158) avg lploss: 0.00000
train epoch 568 avg loss: 0.38684 (A-MSE: 0.34084) avg lploss: 0.00000
train epoch 569 avg loss: 0.38642 (A-MSE: 0.34009) avg lploss: 0.00000
train epoch 570 avg loss: 0.40440 (A-MSE: 0.35491) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.64450 (A-MSE: 0.57764) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.77683 (A-MSE: 0.69769) avg lploss: 0.00000
*** Best Val Loss: 0.64450 	 Best Test Loss: 0.77683 	 Best epoch 570
Validation loss decreased (0.739208 --> 0.644501).  Saving model ...
train epoch 571 avg loss: 0.39880 (A-MSE: 0.35497) avg lploss: 0.00000
train epoch 572 avg loss: 0.43453 (A-MSE: 0.38293) avg lploss: 0.00000
train epoch 573 avg loss: 0.42282 (A-MSE: 0.37235) avg lploss: 0.00000
train epoch 574 avg loss: 0.47126 (A-MSE: 0.41798) avg lploss: 0.00000
train epoch 575 avg loss: 0.44889 (A-MSE: 0.39628) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.82948 (A-MSE: 0.72520) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.99218 (A-MSE: 0.87587) avg lploss: 0.00000
*** Best Val Loss: 0.64450 	 Best Test Loss: 0.77683 	 Best epoch 570
EarlyStopping counter: 1 out of 50
train epoch 576 avg loss: 0.40975 (A-MSE: 0.36259) avg lploss: 0.00000
train epoch 577 avg loss: 0.39138 (A-MSE: 0.34476) avg lploss: 0.00000
train epoch 578 avg loss: 0.38070 (A-MSE: 0.33506) avg lploss: 0.00000
train epoch 579 avg loss: 0.39084 (A-MSE: 0.34495) avg lploss: 0.00000
train epoch 580 avg loss: 0.42779 (A-MSE: 0.37808) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.77228 (A-MSE: 0.68845) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.86324 (A-MSE: 0.77555) avg lploss: 0.00000
*** Best Val Loss: 0.64450 	 Best Test Loss: 0.77683 	 Best epoch 570
EarlyStopping counter: 2 out of 50
train epoch 581 avg loss: 0.45405 (A-MSE: 0.40133) avg lploss: 0.00000
train epoch 582 avg loss: 0.42377 (A-MSE: 0.37370) avg lploss: 0.00000
train epoch 583 avg loss: 0.38910 (A-MSE: 0.34638) avg lploss: 0.00000
train epoch 584 avg loss: 0.39929 (A-MSE: 0.35579) avg lploss: 0.00000
train epoch 585 avg loss: 0.38402 (A-MSE: 0.33961) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.65850 (A-MSE: 0.58525) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.80009 (A-MSE: 0.71596) avg lploss: 0.00000
*** Best Val Loss: 0.64450 	 Best Test Loss: 0.77683 	 Best epoch 570
EarlyStopping counter: 3 out of 50
train epoch 586 avg loss: 0.39483 (A-MSE: 0.34779) avg lploss: 0.00000
train epoch 587 avg loss: 0.40121 (A-MSE: 0.35361) avg lploss: 0.00000
train epoch 588 avg loss: 0.47678 (A-MSE: 0.42410) avg lploss: 0.00000
train epoch 589 avg loss: 0.40469 (A-MSE: 0.35501) avg lploss: 0.00000
train epoch 590 avg loss: 0.40504 (A-MSE: 0.35659) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.67113 (A-MSE: 0.60874) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.77289 (A-MSE: 0.70486) avg lploss: 0.00000
*** Best Val Loss: 0.64450 	 Best Test Loss: 0.77683 	 Best epoch 570
EarlyStopping counter: 4 out of 50
train epoch 591 avg loss: 0.38938 (A-MSE: 0.34255) avg lploss: 0.00000
train epoch 592 avg loss: 0.38911 (A-MSE: 0.34564) avg lploss: 0.00000
train epoch 593 avg loss: 0.42845 (A-MSE: 0.37968) avg lploss: 0.00000
train epoch 594 avg loss: 0.38902 (A-MSE: 0.34259) avg lploss: 0.00000
train epoch 595 avg loss: 0.41166 (A-MSE: 0.36446) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.76209 (A-MSE: 0.66803) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.88037 (A-MSE: 0.78198) avg lploss: 0.00000
*** Best Val Loss: 0.64450 	 Best Test Loss: 0.77683 	 Best epoch 570
EarlyStopping counter: 5 out of 50
train epoch 596 avg loss: 0.46830 (A-MSE: 0.41116) avg lploss: 0.00000
train epoch 597 avg loss: 0.43250 (A-MSE: 0.38054) avg lploss: 0.00000
train epoch 598 avg loss: 0.42332 (A-MSE: 0.37261) avg lploss: 0.00000
train epoch 599 avg loss: 0.45085 (A-MSE: 0.39574) avg lploss: 0.00000
train epoch 600 avg loss: 0.38255 (A-MSE: 0.33595) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.64399 (A-MSE: 0.57327) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.76260 (A-MSE: 0.68685) avg lploss: 0.00000
*** Best Val Loss: 0.64399 	 Best Test Loss: 0.76260 	 Best epoch 600
Validation loss decreased (0.644501 --> 0.643989).  Saving model ...
train epoch 601 avg loss: 0.34574 (A-MSE: 0.30480) avg lploss: 0.00000
train epoch 602 avg loss: 0.40763 (A-MSE: 0.36076) avg lploss: 0.00000
train epoch 603 avg loss: 0.40852 (A-MSE: 0.35877) avg lploss: 0.00000
train epoch 604 avg loss: 0.37541 (A-MSE: 0.33156) avg lploss: 0.00000
train epoch 605 avg loss: 0.43413 (A-MSE: 0.37955) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.87029 (A-MSE: 0.75862) avg lploss: 0.00000
==> test epoch 605 avg loss: 1.00460 (A-MSE: 0.88817) avg lploss: 0.00000
*** Best Val Loss: 0.64399 	 Best Test Loss: 0.76260 	 Best epoch 600
EarlyStopping counter: 1 out of 50
train epoch 606 avg loss: 0.42490 (A-MSE: 0.37572) avg lploss: 0.00000
train epoch 607 avg loss: 0.35557 (A-MSE: 0.31442) avg lploss: 0.00000
train epoch 608 avg loss: 0.38037 (A-MSE: 0.33356) avg lploss: 0.00000
train epoch 609 avg loss: 0.38567 (A-MSE: 0.33967) avg lploss: 0.00000
train epoch 610 avg loss: 0.37189 (A-MSE: 0.32615) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.66196 (A-MSE: 0.58388) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.79814 (A-MSE: 0.71207) avg lploss: 0.00000
*** Best Val Loss: 0.64399 	 Best Test Loss: 0.76260 	 Best epoch 600
EarlyStopping counter: 2 out of 50
train epoch 611 avg loss: 0.36564 (A-MSE: 0.32108) avg lploss: 0.00000
train epoch 612 avg loss: 0.38663 (A-MSE: 0.34102) avg lploss: 0.00000
train epoch 613 avg loss: 0.38174 (A-MSE: 0.33358) avg lploss: 0.00000
train epoch 614 avg loss: 0.43900 (A-MSE: 0.38764) avg lploss: 0.00000
train epoch 615 avg loss: 0.42279 (A-MSE: 0.37123) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.68737 (A-MSE: 0.60815) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.81647 (A-MSE: 0.73019) avg lploss: 0.00000
*** Best Val Loss: 0.64399 	 Best Test Loss: 0.76260 	 Best epoch 600
EarlyStopping counter: 3 out of 50
train epoch 616 avg loss: 0.36454 (A-MSE: 0.32297) avg lploss: 0.00000
train epoch 617 avg loss: 0.34973 (A-MSE: 0.30959) avg lploss: 0.00000
train epoch 618 avg loss: 0.34298 (A-MSE: 0.30119) avg lploss: 0.00000
train epoch 619 avg loss: 0.34757 (A-MSE: 0.30552) avg lploss: 0.00000
train epoch 620 avg loss: 0.37474 (A-MSE: 0.33021) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.85988 (A-MSE: 0.73744) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.99834 (A-MSE: 0.86687) avg lploss: 0.00000
*** Best Val Loss: 0.64399 	 Best Test Loss: 0.76260 	 Best epoch 600
EarlyStopping counter: 4 out of 50
train epoch 621 avg loss: 0.34772 (A-MSE: 0.30815) avg lploss: 0.00000
train epoch 622 avg loss: 0.38712 (A-MSE: 0.34114) avg lploss: 0.00000
train epoch 623 avg loss: 0.38154 (A-MSE: 0.33181) avg lploss: 0.00000
train epoch 624 avg loss: 0.35729 (A-MSE: 0.31566) avg lploss: 0.00000
train epoch 625 avg loss: 0.36874 (A-MSE: 0.32689) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.56030 (A-MSE: 0.49815) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.64098 (A-MSE: 0.57600) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
Validation loss decreased (0.643989 --> 0.560303).  Saving model ...
train epoch 626 avg loss: 0.35179 (A-MSE: 0.31038) avg lploss: 0.00000
train epoch 627 avg loss: 0.34136 (A-MSE: 0.30197) avg lploss: 0.00000
train epoch 628 avg loss: 0.38610 (A-MSE: 0.33878) avg lploss: 0.00000
train epoch 629 avg loss: 0.39966 (A-MSE: 0.35132) avg lploss: 0.00000
train epoch 630 avg loss: 0.39300 (A-MSE: 0.34829) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.60491 (A-MSE: 0.53623) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.70814 (A-MSE: 0.63089) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 1 out of 50
train epoch 631 avg loss: 0.41409 (A-MSE: 0.36523) avg lploss: 0.00000
train epoch 632 avg loss: 0.40506 (A-MSE: 0.35663) avg lploss: 0.00000
train epoch 633 avg loss: 0.35308 (A-MSE: 0.31018) avg lploss: 0.00000
train epoch 634 avg loss: 0.34058 (A-MSE: 0.29902) avg lploss: 0.00000
train epoch 635 avg loss: 0.34909 (A-MSE: 0.30822) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.65675 (A-MSE: 0.57804) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.77508 (A-MSE: 0.69178) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 2 out of 50
train epoch 636 avg loss: 0.33967 (A-MSE: 0.30081) avg lploss: 0.00000
train epoch 637 avg loss: 0.31202 (A-MSE: 0.27556) avg lploss: 0.00000
train epoch 638 avg loss: 0.38636 (A-MSE: 0.33931) avg lploss: 0.00000
train epoch 639 avg loss: 0.38795 (A-MSE: 0.34234) avg lploss: 0.00000
train epoch 640 avg loss: 0.33877 (A-MSE: 0.30057) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.76040 (A-MSE: 0.65216) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.87659 (A-MSE: 0.76536) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 3 out of 50
train epoch 641 avg loss: 0.37703 (A-MSE: 0.33154) avg lploss: 0.00000
train epoch 642 avg loss: 0.35172 (A-MSE: 0.31253) avg lploss: 0.00000
train epoch 643 avg loss: 0.33812 (A-MSE: 0.29704) avg lploss: 0.00000
train epoch 644 avg loss: 0.35142 (A-MSE: 0.31047) avg lploss: 0.00000
train epoch 645 avg loss: 0.36747 (A-MSE: 0.32091) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.59780 (A-MSE: 0.52952) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.70161 (A-MSE: 0.63209) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 4 out of 50
train epoch 646 avg loss: 0.33947 (A-MSE: 0.29947) avg lploss: 0.00000
train epoch 647 avg loss: 0.30190 (A-MSE: 0.26726) avg lploss: 0.00000
train epoch 648 avg loss: 0.31187 (A-MSE: 0.27594) avg lploss: 0.00000
train epoch 649 avg loss: 0.33240 (A-MSE: 0.29125) avg lploss: 0.00000
train epoch 650 avg loss: 0.38315 (A-MSE: 0.33721) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.62694 (A-MSE: 0.55613) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.68461 (A-MSE: 0.62069) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 5 out of 50
train epoch 651 avg loss: 0.34681 (A-MSE: 0.30604) avg lploss: 0.00000
train epoch 652 avg loss: 0.31379 (A-MSE: 0.27767) avg lploss: 0.00000
train epoch 653 avg loss: 0.36065 (A-MSE: 0.31593) avg lploss: 0.00000
train epoch 654 avg loss: 0.32697 (A-MSE: 0.29033) avg lploss: 0.00000
train epoch 655 avg loss: 0.31493 (A-MSE: 0.27738) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.57707 (A-MSE: 0.51880) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.67453 (A-MSE: 0.61896) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 6 out of 50
train epoch 656 avg loss: 0.34831 (A-MSE: 0.30655) avg lploss: 0.00000
train epoch 657 avg loss: 0.36703 (A-MSE: 0.32419) avg lploss: 0.00000
train epoch 658 avg loss: 0.40876 (A-MSE: 0.36095) avg lploss: 0.00000
train epoch 659 avg loss: 0.34201 (A-MSE: 0.30275) avg lploss: 0.00000
train epoch 660 avg loss: 0.32601 (A-MSE: 0.28707) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.62993 (A-MSE: 0.56955) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.71320 (A-MSE: 0.65324) avg lploss: 0.00000
*** Best Val Loss: 0.56030 	 Best Test Loss: 0.64098 	 Best epoch 625
EarlyStopping counter: 7 out of 50
train epoch 661 avg loss: 0.33246 (A-MSE: 0.29473) avg lploss: 0.00000
train epoch 662 avg loss: 0.29878 (A-MSE: 0.26303) avg lploss: 0.00000
train epoch 663 avg loss: 0.30398 (A-MSE: 0.26819) avg lploss: 0.00000
train epoch 664 avg loss: 0.32123 (A-MSE: 0.28431) avg lploss: 0.00000
train epoch 665 avg loss: 0.34172 (A-MSE: 0.30282) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.54641 (A-MSE: 0.48000) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.63224 (A-MSE: 0.56596) avg lploss: 0.00000
*** Best Val Loss: 0.54641 	 Best Test Loss: 0.63224 	 Best epoch 665
Validation loss decreased (0.560303 --> 0.546411).  Saving model ...
train epoch 666 avg loss: 0.30061 (A-MSE: 0.26521) avg lploss: 0.00000
train epoch 667 avg loss: 0.30785 (A-MSE: 0.27158) avg lploss: 0.00000
train epoch 668 avg loss: 0.34117 (A-MSE: 0.29967) avg lploss: 0.00000
train epoch 669 avg loss: 0.31432 (A-MSE: 0.27751) avg lploss: 0.00000
train epoch 670 avg loss: 0.29002 (A-MSE: 0.25674) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.57137 (A-MSE: 0.51196) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.69989 (A-MSE: 0.63055) avg lploss: 0.00000
*** Best Val Loss: 0.54641 	 Best Test Loss: 0.63224 	 Best epoch 665
EarlyStopping counter: 1 out of 50
train epoch 671 avg loss: 0.32428 (A-MSE: 0.28560) avg lploss: 0.00000
train epoch 672 avg loss: 0.31127 (A-MSE: 0.27346) avg lploss: 0.00000
train epoch 673 avg loss: 0.30470 (A-MSE: 0.27029) avg lploss: 0.00000
train epoch 674 avg loss: 0.32536 (A-MSE: 0.28595) avg lploss: 0.00000
train epoch 675 avg loss: 0.28939 (A-MSE: 0.25736) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.53576 (A-MSE: 0.48094) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.64284 (A-MSE: 0.58084) avg lploss: 0.00000
*** Best Val Loss: 0.53576 	 Best Test Loss: 0.64284 	 Best epoch 675
Validation loss decreased (0.546411 --> 0.535762).  Saving model ...
train epoch 676 avg loss: 0.28236 (A-MSE: 0.24959) avg lploss: 0.00000
train epoch 677 avg loss: 0.30327 (A-MSE: 0.26805) avg lploss: 0.00000
train epoch 678 avg loss: 0.30695 (A-MSE: 0.27150) avg lploss: 0.00000
train epoch 679 avg loss: 0.28154 (A-MSE: 0.24946) avg lploss: 0.00000
train epoch 680 avg loss: 0.27709 (A-MSE: 0.24594) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.62508 (A-MSE: 0.53980) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.75211 (A-MSE: 0.66393) avg lploss: 0.00000
*** Best Val Loss: 0.53576 	 Best Test Loss: 0.64284 	 Best epoch 675
EarlyStopping counter: 1 out of 50
train epoch 681 avg loss: 0.34105 (A-MSE: 0.29895) avg lploss: 0.00000
train epoch 682 avg loss: 0.34095 (A-MSE: 0.30018) avg lploss: 0.00000
train epoch 683 avg loss: 0.33052 (A-MSE: 0.29112) avg lploss: 0.00000
train epoch 684 avg loss: 0.29057 (A-MSE: 0.25805) avg lploss: 0.00000
train epoch 685 avg loss: 0.35747 (A-MSE: 0.31550) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.55893 (A-MSE: 0.49993) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.62731 (A-MSE: 0.56939) avg lploss: 0.00000
*** Best Val Loss: 0.53576 	 Best Test Loss: 0.64284 	 Best epoch 675
EarlyStopping counter: 2 out of 50
train epoch 686 avg loss: 0.33825 (A-MSE: 0.29570) avg lploss: 0.00000
train epoch 687 avg loss: 0.29758 (A-MSE: 0.26081) avg lploss: 0.00000
train epoch 688 avg loss: 0.30683 (A-MSE: 0.27119) avg lploss: 0.00000
train epoch 689 avg loss: 0.28156 (A-MSE: 0.25068) avg lploss: 0.00000
train epoch 690 avg loss: 0.29377 (A-MSE: 0.25729) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.49151 (A-MSE: 0.43813) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.56899 (A-MSE: 0.51495) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
Validation loss decreased (0.535762 --> 0.491514).  Saving model ...
train epoch 691 avg loss: 0.29105 (A-MSE: 0.25813) avg lploss: 0.00000
train epoch 692 avg loss: 0.28588 (A-MSE: 0.25271) avg lploss: 0.00000
train epoch 693 avg loss: 0.27937 (A-MSE: 0.24583) avg lploss: 0.00000
train epoch 694 avg loss: 0.27733 (A-MSE: 0.24648) avg lploss: 0.00000
train epoch 695 avg loss: 0.25750 (A-MSE: 0.22797) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.53734 (A-MSE: 0.48165) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.62547 (A-MSE: 0.57000) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 1 out of 50
train epoch 696 avg loss: 0.27406 (A-MSE: 0.24143) avg lploss: 0.00000
train epoch 697 avg loss: 0.26535 (A-MSE: 0.23489) avg lploss: 0.00000
train epoch 698 avg loss: 0.34076 (A-MSE: 0.30079) avg lploss: 0.00000
train epoch 699 avg loss: 0.41857 (A-MSE: 0.36949) avg lploss: 0.00000
train epoch 700 avg loss: 0.34055 (A-MSE: 0.30004) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.49530 (A-MSE: 0.44261) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.58208 (A-MSE: 0.52964) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 2 out of 50
train epoch 701 avg loss: 0.29269 (A-MSE: 0.25958) avg lploss: 0.00000
train epoch 702 avg loss: 0.29091 (A-MSE: 0.25483) avg lploss: 0.00000
train epoch 703 avg loss: 0.32638 (A-MSE: 0.28390) avg lploss: 0.00000
train epoch 704 avg loss: 0.30866 (A-MSE: 0.27041) avg lploss: 0.00000
train epoch 705 avg loss: 0.31177 (A-MSE: 0.27502) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.53717 (A-MSE: 0.47762) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.61651 (A-MSE: 0.55743) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 3 out of 50
train epoch 706 avg loss: 0.33305 (A-MSE: 0.29125) avg lploss: 0.00000
train epoch 707 avg loss: 0.29770 (A-MSE: 0.26259) avg lploss: 0.00000
train epoch 708 avg loss: 0.27432 (A-MSE: 0.24401) avg lploss: 0.00000
train epoch 709 avg loss: 0.29693 (A-MSE: 0.26221) avg lploss: 0.00000
train epoch 710 avg loss: 0.34657 (A-MSE: 0.30783) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.57193 (A-MSE: 0.49635) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.66705 (A-MSE: 0.59131) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 4 out of 50
train epoch 711 avg loss: 0.34940 (A-MSE: 0.31014) avg lploss: 0.00000
train epoch 712 avg loss: 0.28351 (A-MSE: 0.25216) avg lploss: 0.00000
train epoch 713 avg loss: 0.27281 (A-MSE: 0.23797) avg lploss: 0.00000
train epoch 714 avg loss: 0.28167 (A-MSE: 0.24753) avg lploss: 0.00000
train epoch 715 avg loss: 0.29617 (A-MSE: 0.26235) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.56610 (A-MSE: 0.49583) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.66244 (A-MSE: 0.59126) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 5 out of 50
train epoch 716 avg loss: 0.25225 (A-MSE: 0.22493) avg lploss: 0.00000
train epoch 717 avg loss: 0.31638 (A-MSE: 0.27967) avg lploss: 0.00000
train epoch 718 avg loss: 0.30495 (A-MSE: 0.26886) avg lploss: 0.00000
train epoch 719 avg loss: 0.26395 (A-MSE: 0.23377) avg lploss: 0.00000
train epoch 720 avg loss: 0.27272 (A-MSE: 0.24056) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.55495 (A-MSE: 0.48770) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.65768 (A-MSE: 0.58995) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 6 out of 50
train epoch 721 avg loss: 0.28372 (A-MSE: 0.25024) avg lploss: 0.00000
train epoch 722 avg loss: 0.25319 (A-MSE: 0.22285) avg lploss: 0.00000
train epoch 723 avg loss: 0.24356 (A-MSE: 0.21416) avg lploss: 0.00000
train epoch 724 avg loss: 0.27270 (A-MSE: 0.24215) avg lploss: 0.00000
train epoch 725 avg loss: 0.27901 (A-MSE: 0.24669) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.59484 (A-MSE: 0.51435) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.67485 (A-MSE: 0.59644) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 7 out of 50
train epoch 726 avg loss: 0.25186 (A-MSE: 0.22107) avg lploss: 0.00000
train epoch 727 avg loss: 0.25660 (A-MSE: 0.22709) avg lploss: 0.00000
train epoch 728 avg loss: 0.24005 (A-MSE: 0.21216) avg lploss: 0.00000
train epoch 729 avg loss: 0.27155 (A-MSE: 0.23841) avg lploss: 0.00000
train epoch 730 avg loss: 0.28028 (A-MSE: 0.24917) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.74177 (A-MSE: 0.63387) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.81828 (A-MSE: 0.71778) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 8 out of 50
train epoch 731 avg loss: 0.30387 (A-MSE: 0.26863) avg lploss: 0.00000
train epoch 732 avg loss: 0.28825 (A-MSE: 0.25627) avg lploss: 0.00000
train epoch 733 avg loss: 0.26735 (A-MSE: 0.23789) avg lploss: 0.00000
train epoch 734 avg loss: 0.26616 (A-MSE: 0.23561) avg lploss: 0.00000
train epoch 735 avg loss: 0.27386 (A-MSE: 0.24308) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.54664 (A-MSE: 0.48225) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.64386 (A-MSE: 0.57489) avg lploss: 0.00000
*** Best Val Loss: 0.49151 	 Best Test Loss: 0.56899 	 Best epoch 690
EarlyStopping counter: 9 out of 50
train epoch 736 avg loss: 0.28589 (A-MSE: 0.25412) avg lploss: 0.00000
train epoch 737 avg loss: 0.29674 (A-MSE: 0.26295) avg lploss: 0.00000
train epoch 738 avg loss: 0.28828 (A-MSE: 0.25232) avg lploss: 0.00000
train epoch 739 avg loss: 0.31289 (A-MSE: 0.27378) avg lploss: 0.00000
train epoch 740 avg loss: 0.26005 (A-MSE: 0.22834) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.43858 (A-MSE: 0.38945) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.50741 (A-MSE: 0.45955) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
Validation loss decreased (0.491514 --> 0.438578).  Saving model ...
train epoch 741 avg loss: 0.25974 (A-MSE: 0.22776) avg lploss: 0.00000
train epoch 742 avg loss: 0.28345 (A-MSE: 0.25041) avg lploss: 0.00000
train epoch 743 avg loss: 0.24469 (A-MSE: 0.21603) avg lploss: 0.00000
train epoch 744 avg loss: 0.23375 (A-MSE: 0.20558) avg lploss: 0.00000
train epoch 745 avg loss: 0.25474 (A-MSE: 0.22631) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.55860 (A-MSE: 0.49913) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.65986 (A-MSE: 0.59930) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 1 out of 50
train epoch 746 avg loss: 0.26012 (A-MSE: 0.23039) avg lploss: 0.00000
train epoch 747 avg loss: 0.26265 (A-MSE: 0.23171) avg lploss: 0.00000
train epoch 748 avg loss: 0.25892 (A-MSE: 0.23034) avg lploss: 0.00000
train epoch 749 avg loss: 0.28837 (A-MSE: 0.25273) avg lploss: 0.00000
train epoch 750 avg loss: 0.28386 (A-MSE: 0.24947) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.45497 (A-MSE: 0.40574) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.51670 (A-MSE: 0.47230) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 2 out of 50
train epoch 751 avg loss: 0.26965 (A-MSE: 0.23732) avg lploss: 0.00000
train epoch 752 avg loss: 0.26738 (A-MSE: 0.23599) avg lploss: 0.00000
train epoch 753 avg loss: 0.24202 (A-MSE: 0.21608) avg lploss: 0.00000
train epoch 754 avg loss: 0.23496 (A-MSE: 0.20638) avg lploss: 0.00000
train epoch 755 avg loss: 0.24576 (A-MSE: 0.21534) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.46680 (A-MSE: 0.41142) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.50864 (A-MSE: 0.46096) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 3 out of 50
train epoch 756 avg loss: 0.23957 (A-MSE: 0.21176) avg lploss: 0.00000
train epoch 757 avg loss: 0.23429 (A-MSE: 0.20793) avg lploss: 0.00000
train epoch 758 avg loss: 0.24231 (A-MSE: 0.21437) avg lploss: 0.00000
train epoch 759 avg loss: 0.24645 (A-MSE: 0.21711) avg lploss: 0.00000
train epoch 760 avg loss: 0.28937 (A-MSE: 0.25494) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.59006 (A-MSE: 0.53257) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.67054 (A-MSE: 0.61248) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 4 out of 50
train epoch 761 avg loss: 0.29075 (A-MSE: 0.25537) avg lploss: 0.00000
train epoch 762 avg loss: 0.24075 (A-MSE: 0.21394) avg lploss: 0.00000
train epoch 763 avg loss: 0.25332 (A-MSE: 0.22609) avg lploss: 0.00000
train epoch 764 avg loss: 0.23852 (A-MSE: 0.21024) avg lploss: 0.00000
train epoch 765 avg loss: 0.23833 (A-MSE: 0.20974) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.47756 (A-MSE: 0.41268) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.56788 (A-MSE: 0.49996) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 5 out of 50
train epoch 766 avg loss: 0.24595 (A-MSE: 0.21527) avg lploss: 0.00000
train epoch 767 avg loss: 0.22989 (A-MSE: 0.20361) avg lploss: 0.00000
train epoch 768 avg loss: 0.22697 (A-MSE: 0.19968) avg lploss: 0.00000
train epoch 769 avg loss: 0.23499 (A-MSE: 0.20605) avg lploss: 0.00000
train epoch 770 avg loss: 0.25193 (A-MSE: 0.22343) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.45552 (A-MSE: 0.40943) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.51197 (A-MSE: 0.46927) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 6 out of 50
train epoch 771 avg loss: 0.23776 (A-MSE: 0.21192) avg lploss: 0.00000
train epoch 772 avg loss: 0.23761 (A-MSE: 0.20975) avg lploss: 0.00000
train epoch 773 avg loss: 0.25329 (A-MSE: 0.22510) avg lploss: 0.00000
train epoch 774 avg loss: 0.24134 (A-MSE: 0.21545) avg lploss: 0.00000
train epoch 775 avg loss: 0.28969 (A-MSE: 0.25433) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.51708 (A-MSE: 0.45311) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.58540 (A-MSE: 0.52510) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 7 out of 50
train epoch 776 avg loss: 0.25637 (A-MSE: 0.22666) avg lploss: 0.00000
train epoch 777 avg loss: 0.22018 (A-MSE: 0.19427) avg lploss: 0.00000
train epoch 778 avg loss: 0.25268 (A-MSE: 0.22300) avg lploss: 0.00000
train epoch 779 avg loss: 0.26906 (A-MSE: 0.23588) avg lploss: 0.00000
train epoch 780 avg loss: 0.33136 (A-MSE: 0.29050) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.69460 (A-MSE: 0.59753) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.75503 (A-MSE: 0.66772) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 8 out of 50
train epoch 781 avg loss: 0.31652 (A-MSE: 0.27917) avg lploss: 0.00000
train epoch 782 avg loss: 0.26422 (A-MSE: 0.23226) avg lploss: 0.00000
train epoch 783 avg loss: 0.24454 (A-MSE: 0.21522) avg lploss: 0.00000
train epoch 784 avg loss: 0.22047 (A-MSE: 0.19494) avg lploss: 0.00000
train epoch 785 avg loss: 0.22369 (A-MSE: 0.19783) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.46759 (A-MSE: 0.41145) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.53415 (A-MSE: 0.47971) avg lploss: 0.00000
*** Best Val Loss: 0.43858 	 Best Test Loss: 0.50741 	 Best epoch 740
EarlyStopping counter: 9 out of 50
train epoch 786 avg loss: 0.21941 (A-MSE: 0.19418) avg lploss: 0.00000
train epoch 787 avg loss: 0.22956 (A-MSE: 0.20135) avg lploss: 0.00000
train epoch 788 avg loss: 0.25995 (A-MSE: 0.22958) avg lploss: 0.00000
train epoch 789 avg loss: 0.23265 (A-MSE: 0.20572) avg lploss: 0.00000
train epoch 790 avg loss: 0.21491 (A-MSE: 0.18964) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.40968 (A-MSE: 0.36810) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.48747 (A-MSE: 0.44874) avg lploss: 0.00000
*** Best Val Loss: 0.40968 	 Best Test Loss: 0.48747 	 Best epoch 790
Validation loss decreased (0.438578 --> 0.409678).  Saving model ...
train epoch 791 avg loss: 0.20367 (A-MSE: 0.18028) avg lploss: 0.00000
train epoch 792 avg loss: 0.23541 (A-MSE: 0.20807) avg lploss: 0.00000
train epoch 793 avg loss: 0.22883 (A-MSE: 0.20364) avg lploss: 0.00000
train epoch 794 avg loss: 0.21647 (A-MSE: 0.19103) avg lploss: 0.00000
train epoch 795 avg loss: 0.23049 (A-MSE: 0.20410) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.55865 (A-MSE: 0.48285) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.61699 (A-MSE: 0.54546) avg lploss: 0.00000
*** Best Val Loss: 0.40968 	 Best Test Loss: 0.48747 	 Best epoch 790
EarlyStopping counter: 1 out of 50
train epoch 796 avg loss: 0.25519 (A-MSE: 0.22327) avg lploss: 0.00000
train epoch 797 avg loss: 0.25491 (A-MSE: 0.22537) avg lploss: 0.00000
train epoch 798 avg loss: 0.23851 (A-MSE: 0.21098) avg lploss: 0.00000
train epoch 799 avg loss: 0.22464 (A-MSE: 0.19831) avg lploss: 0.00000
train epoch 800 avg loss: 0.26268 (A-MSE: 0.23016) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.51851 (A-MSE: 0.46240) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.61033 (A-MSE: 0.55607) avg lploss: 0.00000
*** Best Val Loss: 0.40968 	 Best Test Loss: 0.48747 	 Best epoch 790
EarlyStopping counter: 2 out of 50
train epoch 801 avg loss: 0.23114 (A-MSE: 0.20336) avg lploss: 0.00000
train epoch 802 avg loss: 0.21439 (A-MSE: 0.18853) avg lploss: 0.00000
train epoch 803 avg loss: 0.23651 (A-MSE: 0.20744) avg lploss: 0.00000
train epoch 804 avg loss: 0.21886 (A-MSE: 0.19340) avg lploss: 0.00000
train epoch 805 avg loss: 0.22862 (A-MSE: 0.20121) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.40518 (A-MSE: 0.36241) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.45681 (A-MSE: 0.41533) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
Validation loss decreased (0.409678 --> 0.405178).  Saving model ...
train epoch 806 avg loss: 0.22177 (A-MSE: 0.19788) avg lploss: 0.00000
train epoch 807 avg loss: 0.22806 (A-MSE: 0.20265) avg lploss: 0.00000
train epoch 808 avg loss: 0.27578 (A-MSE: 0.24306) avg lploss: 0.00000
train epoch 809 avg loss: 0.24776 (A-MSE: 0.21916) avg lploss: 0.00000
train epoch 810 avg loss: 0.23878 (A-MSE: 0.21136) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.45468 (A-MSE: 0.40774) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.51074 (A-MSE: 0.46803) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 1 out of 50
train epoch 811 avg loss: 0.22234 (A-MSE: 0.19666) avg lploss: 0.00000
train epoch 812 avg loss: 0.23294 (A-MSE: 0.20515) avg lploss: 0.00000
train epoch 813 avg loss: 0.20684 (A-MSE: 0.18341) avg lploss: 0.00000
train epoch 814 avg loss: 0.22381 (A-MSE: 0.19803) avg lploss: 0.00000
train epoch 815 avg loss: 0.21362 (A-MSE: 0.18870) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.64495 (A-MSE: 0.53739) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.71987 (A-MSE: 0.62004) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 2 out of 50
train epoch 816 avg loss: 0.25692 (A-MSE: 0.22697) avg lploss: 0.00000
train epoch 817 avg loss: 0.20687 (A-MSE: 0.18269) avg lploss: 0.00000
train epoch 818 avg loss: 0.21604 (A-MSE: 0.19168) avg lploss: 0.00000
train epoch 819 avg loss: 0.22594 (A-MSE: 0.20026) avg lploss: 0.00000
train epoch 820 avg loss: 0.27339 (A-MSE: 0.24018) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.46388 (A-MSE: 0.40636) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.48538 (A-MSE: 0.43580) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 3 out of 50
train epoch 821 avg loss: 0.28752 (A-MSE: 0.25197) avg lploss: 0.00000
train epoch 822 avg loss: 0.25476 (A-MSE: 0.22719) avg lploss: 0.00000
train epoch 823 avg loss: 0.22009 (A-MSE: 0.19448) avg lploss: 0.00000
train epoch 824 avg loss: 0.20774 (A-MSE: 0.18217) avg lploss: 0.00000
train epoch 825 avg loss: 0.23474 (A-MSE: 0.20672) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.44724 (A-MSE: 0.39106) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.49196 (A-MSE: 0.43952) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 4 out of 50
train epoch 826 avg loss: 0.19238 (A-MSE: 0.17066) avg lploss: 0.00000
train epoch 827 avg loss: 0.19261 (A-MSE: 0.17086) avg lploss: 0.00000
train epoch 828 avg loss: 0.21151 (A-MSE: 0.18810) avg lploss: 0.00000
train epoch 829 avg loss: 0.19774 (A-MSE: 0.17449) avg lploss: 0.00000
train epoch 830 avg loss: 0.21363 (A-MSE: 0.18883) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.41542 (A-MSE: 0.36269) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.46086 (A-MSE: 0.41400) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 5 out of 50
train epoch 831 avg loss: 0.21663 (A-MSE: 0.19221) avg lploss: 0.00000
train epoch 832 avg loss: 0.23066 (A-MSE: 0.20194) avg lploss: 0.00000
train epoch 833 avg loss: 0.22210 (A-MSE: 0.19682) avg lploss: 0.00000
train epoch 834 avg loss: 0.23418 (A-MSE: 0.20610) avg lploss: 0.00000
train epoch 835 avg loss: 0.23651 (A-MSE: 0.20616) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.51168 (A-MSE: 0.45010) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.56270 (A-MSE: 0.50747) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 6 out of 50
train epoch 836 avg loss: 0.21036 (A-MSE: 0.18677) avg lploss: 0.00000
train epoch 837 avg loss: 0.20207 (A-MSE: 0.17731) avg lploss: 0.00000
train epoch 838 avg loss: 0.21157 (A-MSE: 0.18628) avg lploss: 0.00000
train epoch 839 avg loss: 0.20825 (A-MSE: 0.18329) avg lploss: 0.00000
train epoch 840 avg loss: 0.20360 (A-MSE: 0.17918) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.45528 (A-MSE: 0.39678) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.50871 (A-MSE: 0.45546) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 7 out of 50
train epoch 841 avg loss: 0.21363 (A-MSE: 0.18959) avg lploss: 0.00000
train epoch 842 avg loss: 0.20067 (A-MSE: 0.17728) avg lploss: 0.00000
train epoch 843 avg loss: 0.21403 (A-MSE: 0.18953) avg lploss: 0.00000
train epoch 844 avg loss: 0.20908 (A-MSE: 0.18467) avg lploss: 0.00000
train epoch 845 avg loss: 0.20784 (A-MSE: 0.18361) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.43126 (A-MSE: 0.37448) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.47102 (A-MSE: 0.41825) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 8 out of 50
train epoch 846 avg loss: 0.22095 (A-MSE: 0.19266) avg lploss: 0.00000
train epoch 847 avg loss: 0.25908 (A-MSE: 0.22833) avg lploss: 0.00000
train epoch 848 avg loss: 0.22295 (A-MSE: 0.19537) avg lploss: 0.00000
train epoch 849 avg loss: 0.19782 (A-MSE: 0.17703) avg lploss: 0.00000
train epoch 850 avg loss: 0.19717 (A-MSE: 0.17472) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.46684 (A-MSE: 0.40841) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.52552 (A-MSE: 0.47109) avg lploss: 0.00000
*** Best Val Loss: 0.40518 	 Best Test Loss: 0.45681 	 Best epoch 805
EarlyStopping counter: 9 out of 50
train epoch 851 avg loss: 0.19535 (A-MSE: 0.17335) avg lploss: 0.00000
train epoch 852 avg loss: 0.20246 (A-MSE: 0.18022) avg lploss: 0.00000
train epoch 853 avg loss: 0.19972 (A-MSE: 0.17523) avg lploss: 0.00000
train epoch 854 avg loss: 0.22477 (A-MSE: 0.19747) avg lploss: 0.00000
train epoch 855 avg loss: 0.22436 (A-MSE: 0.19600) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.37752 (A-MSE: 0.33682) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.42650 (A-MSE: 0.38505) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
Validation loss decreased (0.405178 --> 0.377520).  Saving model ...
train epoch 856 avg loss: 0.23535 (A-MSE: 0.20584) avg lploss: 0.00000
train epoch 857 avg loss: 0.24867 (A-MSE: 0.21786) avg lploss: 0.00000
train epoch 858 avg loss: 0.20315 (A-MSE: 0.17942) avg lploss: 0.00000
train epoch 859 avg loss: 0.21605 (A-MSE: 0.19073) avg lploss: 0.00000
train epoch 860 avg loss: 0.24556 (A-MSE: 0.21646) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.56019 (A-MSE: 0.48382) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.63707 (A-MSE: 0.56739) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 1 out of 50
train epoch 861 avg loss: 0.22722 (A-MSE: 0.19851) avg lploss: 0.00000
train epoch 862 avg loss: 0.21246 (A-MSE: 0.18606) avg lploss: 0.00000
train epoch 863 avg loss: 0.22675 (A-MSE: 0.19737) avg lploss: 0.00000
train epoch 864 avg loss: 0.23362 (A-MSE: 0.20645) avg lploss: 0.00000
train epoch 865 avg loss: 0.23657 (A-MSE: 0.21083) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.51945 (A-MSE: 0.44612) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.56483 (A-MSE: 0.49649) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 2 out of 50
train epoch 866 avg loss: 0.21106 (A-MSE: 0.18545) avg lploss: 0.00000
train epoch 867 avg loss: 0.20976 (A-MSE: 0.18569) avg lploss: 0.00000
train epoch 868 avg loss: 0.20907 (A-MSE: 0.18510) avg lploss: 0.00000
train epoch 869 avg loss: 0.19268 (A-MSE: 0.16934) avg lploss: 0.00000
train epoch 870 avg loss: 0.20890 (A-MSE: 0.18311) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.43224 (A-MSE: 0.38433) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.47210 (A-MSE: 0.42969) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 3 out of 50
train epoch 871 avg loss: 0.21399 (A-MSE: 0.19023) avg lploss: 0.00000
train epoch 872 avg loss: 0.23891 (A-MSE: 0.21044) avg lploss: 0.00000
train epoch 873 avg loss: 0.21900 (A-MSE: 0.19248) avg lploss: 0.00000
train epoch 874 avg loss: 0.22248 (A-MSE: 0.19542) avg lploss: 0.00000
train epoch 875 avg loss: 0.22107 (A-MSE: 0.19558) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.58604 (A-MSE: 0.51612) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.64725 (A-MSE: 0.58412) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 4 out of 50
train epoch 876 avg loss: 0.26852 (A-MSE: 0.23532) avg lploss: 0.00000
train epoch 877 avg loss: 0.22908 (A-MSE: 0.20177) avg lploss: 0.00000
train epoch 878 avg loss: 0.22438 (A-MSE: 0.19933) avg lploss: 0.00000
train epoch 879 avg loss: 0.19501 (A-MSE: 0.17213) avg lploss: 0.00000
train epoch 880 avg loss: 0.19326 (A-MSE: 0.17079) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.41914 (A-MSE: 0.37489) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.47976 (A-MSE: 0.43451) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 5 out of 50
train epoch 881 avg loss: 0.22565 (A-MSE: 0.19714) avg lploss: 0.00000
train epoch 882 avg loss: 0.25514 (A-MSE: 0.22395) avg lploss: 0.00000
train epoch 883 avg loss: 0.23097 (A-MSE: 0.20363) avg lploss: 0.00000
train epoch 884 avg loss: 0.21653 (A-MSE: 0.19247) avg lploss: 0.00000
train epoch 885 avg loss: 0.21252 (A-MSE: 0.18517) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.47858 (A-MSE: 0.42891) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.55313 (A-MSE: 0.50108) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 6 out of 50
train epoch 886 avg loss: 0.19367 (A-MSE: 0.17101) avg lploss: 0.00000
train epoch 887 avg loss: 0.21577 (A-MSE: 0.19129) avg lploss: 0.00000
train epoch 888 avg loss: 0.23018 (A-MSE: 0.20278) avg lploss: 0.00000
train epoch 889 avg loss: 0.22031 (A-MSE: 0.19406) avg lploss: 0.00000
train epoch 890 avg loss: 0.22430 (A-MSE: 0.19443) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.42964 (A-MSE: 0.37846) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.45988 (A-MSE: 0.42048) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 7 out of 50
train epoch 891 avg loss: 0.21613 (A-MSE: 0.19006) avg lploss: 0.00000
train epoch 892 avg loss: 0.20134 (A-MSE: 0.17738) avg lploss: 0.00000
train epoch 893 avg loss: 0.24245 (A-MSE: 0.21251) avg lploss: 0.00000
train epoch 894 avg loss: 0.22238 (A-MSE: 0.19441) avg lploss: 0.00000
train epoch 895 avg loss: 0.23507 (A-MSE: 0.20753) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.48398 (A-MSE: 0.41816) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.54932 (A-MSE: 0.48923) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 8 out of 50
train epoch 896 avg loss: 0.21419 (A-MSE: 0.18806) avg lploss: 0.00000
train epoch 897 avg loss: 0.20368 (A-MSE: 0.18036) avg lploss: 0.00000
train epoch 898 avg loss: 0.18716 (A-MSE: 0.16520) avg lploss: 0.00000
train epoch 899 avg loss: 0.18047 (A-MSE: 0.15901) avg lploss: 0.00000
train epoch 900 avg loss: 0.17755 (A-MSE: 0.15719) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.42765 (A-MSE: 0.38618) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.48168 (A-MSE: 0.44328) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 9 out of 50
train epoch 901 avg loss: 0.17584 (A-MSE: 0.15613) avg lploss: 0.00000
train epoch 902 avg loss: 0.16809 (A-MSE: 0.14903) avg lploss: 0.00000
train epoch 903 avg loss: 0.16816 (A-MSE: 0.14877) avg lploss: 0.00000
train epoch 904 avg loss: 0.22217 (A-MSE: 0.19543) avg lploss: 0.00000
train epoch 905 avg loss: 0.23442 (A-MSE: 0.20778) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.52823 (A-MSE: 0.47192) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.60484 (A-MSE: 0.55107) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 10 out of 50
train epoch 906 avg loss: 0.22469 (A-MSE: 0.19747) avg lploss: 0.00000
train epoch 907 avg loss: 0.19280 (A-MSE: 0.17060) avg lploss: 0.00000
train epoch 908 avg loss: 0.18587 (A-MSE: 0.16390) avg lploss: 0.00000
train epoch 909 avg loss: 0.20101 (A-MSE: 0.17666) avg lploss: 0.00000
train epoch 910 avg loss: 0.19013 (A-MSE: 0.16846) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.46925 (A-MSE: 0.41777) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.52988 (A-MSE: 0.48001) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 11 out of 50
train epoch 911 avg loss: 0.19520 (A-MSE: 0.17330) avg lploss: 0.00000
train epoch 912 avg loss: 0.18413 (A-MSE: 0.16108) avg lploss: 0.00000
train epoch 913 avg loss: 0.20336 (A-MSE: 0.17867) avg lploss: 0.00000
train epoch 914 avg loss: 0.18355 (A-MSE: 0.16146) avg lploss: 0.00000
train epoch 915 avg loss: 0.18143 (A-MSE: 0.16016) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.44128 (A-MSE: 0.38977) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.51127 (A-MSE: 0.46396) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 12 out of 50
train epoch 916 avg loss: 0.20321 (A-MSE: 0.17952) avg lploss: 0.00000
train epoch 917 avg loss: 0.20408 (A-MSE: 0.18046) avg lploss: 0.00000
train epoch 918 avg loss: 0.18385 (A-MSE: 0.16281) avg lploss: 0.00000
train epoch 919 avg loss: 0.19740 (A-MSE: 0.17297) avg lploss: 0.00000
train epoch 920 avg loss: 0.21306 (A-MSE: 0.18829) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.52685 (A-MSE: 0.45609) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.59293 (A-MSE: 0.51908) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 13 out of 50
train epoch 921 avg loss: 0.19907 (A-MSE: 0.17585) avg lploss: 0.00000
train epoch 922 avg loss: 0.20228 (A-MSE: 0.18005) avg lploss: 0.00000
train epoch 923 avg loss: 0.19170 (A-MSE: 0.16777) avg lploss: 0.00000
train epoch 924 avg loss: 0.19782 (A-MSE: 0.17388) avg lploss: 0.00000
train epoch 925 avg loss: 0.23400 (A-MSE: 0.20693) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.52822 (A-MSE: 0.46168) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.58302 (A-MSE: 0.51622) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 14 out of 50
train epoch 926 avg loss: 0.20958 (A-MSE: 0.18580) avg lploss: 0.00000
train epoch 927 avg loss: 0.18399 (A-MSE: 0.16265) avg lploss: 0.00000
train epoch 928 avg loss: 0.17769 (A-MSE: 0.15733) avg lploss: 0.00000
train epoch 929 avg loss: 0.21868 (A-MSE: 0.19351) avg lploss: 0.00000
train epoch 930 avg loss: 0.20200 (A-MSE: 0.17744) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.59523 (A-MSE: 0.50212) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.65527 (A-MSE: 0.56936) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 15 out of 50
train epoch 931 avg loss: 0.18676 (A-MSE: 0.16423) avg lploss: 0.00000
train epoch 932 avg loss: 0.17923 (A-MSE: 0.15785) avg lploss: 0.00000
train epoch 933 avg loss: 0.18342 (A-MSE: 0.16296) avg lploss: 0.00000
train epoch 934 avg loss: 0.16994 (A-MSE: 0.15044) avg lploss: 0.00000
train epoch 935 avg loss: 0.21661 (A-MSE: 0.18921) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.44355 (A-MSE: 0.38560) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.46766 (A-MSE: 0.41844) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 16 out of 50
train epoch 936 avg loss: 0.26086 (A-MSE: 0.22851) avg lploss: 0.00000
train epoch 937 avg loss: 0.21643 (A-MSE: 0.19109) avg lploss: 0.00000
train epoch 938 avg loss: 0.22173 (A-MSE: 0.19604) avg lploss: 0.00000
train epoch 939 avg loss: 0.20415 (A-MSE: 0.17867) avg lploss: 0.00000
train epoch 940 avg loss: 0.21425 (A-MSE: 0.18978) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.46288 (A-MSE: 0.41146) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.54997 (A-MSE: 0.50103) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 17 out of 50
train epoch 941 avg loss: 0.21990 (A-MSE: 0.19001) avg lploss: 0.00000
train epoch 942 avg loss: 0.19910 (A-MSE: 0.17712) avg lploss: 0.00000
train epoch 943 avg loss: 0.20080 (A-MSE: 0.17645) avg lploss: 0.00000
train epoch 944 avg loss: 0.17712 (A-MSE: 0.15765) avg lploss: 0.00000
train epoch 945 avg loss: 0.17988 (A-MSE: 0.15847) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.43309 (A-MSE: 0.37349) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.45397 (A-MSE: 0.40186) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 18 out of 50
train epoch 946 avg loss: 0.17465 (A-MSE: 0.15495) avg lploss: 0.00000
train epoch 947 avg loss: 0.16054 (A-MSE: 0.14338) avg lploss: 0.00000
train epoch 948 avg loss: 0.17253 (A-MSE: 0.15283) avg lploss: 0.00000
train epoch 949 avg loss: 0.17923 (A-MSE: 0.15763) avg lploss: 0.00000
train epoch 950 avg loss: 0.18633 (A-MSE: 0.16472) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.49941 (A-MSE: 0.45746) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.54330 (A-MSE: 0.50224) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 19 out of 50
train epoch 951 avg loss: 0.19791 (A-MSE: 0.17553) avg lploss: 0.00000
train epoch 952 avg loss: 0.16980 (A-MSE: 0.15111) avg lploss: 0.00000
train epoch 953 avg loss: 0.16470 (A-MSE: 0.14617) avg lploss: 0.00000
train epoch 954 avg loss: 0.16383 (A-MSE: 0.14363) avg lploss: 0.00000
train epoch 955 avg loss: 0.16196 (A-MSE: 0.14242) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.38716 (A-MSE: 0.34515) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.45626 (A-MSE: 0.41794) avg lploss: 0.00000
*** Best Val Loss: 0.37752 	 Best Test Loss: 0.42650 	 Best epoch 855
EarlyStopping counter: 20 out of 50
train epoch 956 avg loss: 0.16224 (A-MSE: 0.14395) avg lploss: 0.00000
train epoch 957 avg loss: 0.19972 (A-MSE: 0.17463) avg lploss: 0.00000
train epoch 958 avg loss: 0.19592 (A-MSE: 0.17314) avg lploss: 0.00000
train epoch 959 avg loss: 0.21531 (A-MSE: 0.18906) avg lploss: 0.00000
train epoch 960 avg loss: 0.18294 (A-MSE: 0.16036) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.35451 (A-MSE: 0.32626) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.41172 (A-MSE: 0.38160) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
Validation loss decreased (0.377520 --> 0.354514).  Saving model ...
train epoch 961 avg loss: 0.17521 (A-MSE: 0.15479) avg lploss: 0.00000
train epoch 962 avg loss: 0.19212 (A-MSE: 0.16985) avg lploss: 0.00000
train epoch 963 avg loss: 0.17711 (A-MSE: 0.15633) avg lploss: 0.00000
train epoch 964 avg loss: 0.16011 (A-MSE: 0.14248) avg lploss: 0.00000
train epoch 965 avg loss: 0.15151 (A-MSE: 0.13493) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.39480 (A-MSE: 0.34760) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.46028 (A-MSE: 0.41559) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 1 out of 50
train epoch 966 avg loss: 0.15083 (A-MSE: 0.13338) avg lploss: 0.00000
train epoch 967 avg loss: 0.17787 (A-MSE: 0.15659) avg lploss: 0.00000
train epoch 968 avg loss: 0.15819 (A-MSE: 0.13997) avg lploss: 0.00000
train epoch 969 avg loss: 0.18365 (A-MSE: 0.16245) avg lploss: 0.00000
train epoch 970 avg loss: 0.17903 (A-MSE: 0.15892) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.43146 (A-MSE: 0.38679) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.50358 (A-MSE: 0.46022) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 2 out of 50
train epoch 971 avg loss: 0.20020 (A-MSE: 0.17661) avg lploss: 0.00000
train epoch 972 avg loss: 0.20633 (A-MSE: 0.18063) avg lploss: 0.00000
train epoch 973 avg loss: 0.18568 (A-MSE: 0.16565) avg lploss: 0.00000
train epoch 974 avg loss: 0.21374 (A-MSE: 0.18682) avg lploss: 0.00000
train epoch 975 avg loss: 0.24046 (A-MSE: 0.21171) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.43284 (A-MSE: 0.38491) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.50841 (A-MSE: 0.45990) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 3 out of 50
train epoch 976 avg loss: 0.20578 (A-MSE: 0.18231) avg lploss: 0.00000
train epoch 977 avg loss: 0.19759 (A-MSE: 0.17660) avg lploss: 0.00000
train epoch 978 avg loss: 0.23894 (A-MSE: 0.21160) avg lploss: 0.00000
train epoch 979 avg loss: 0.19248 (A-MSE: 0.16934) avg lploss: 0.00000
train epoch 980 avg loss: 0.16472 (A-MSE: 0.14565) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.37469 (A-MSE: 0.33594) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.44269 (A-MSE: 0.40453) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 4 out of 50
train epoch 981 avg loss: 0.15982 (A-MSE: 0.14178) avg lploss: 0.00000
train epoch 982 avg loss: 0.17431 (A-MSE: 0.15300) avg lploss: 0.00000
train epoch 983 avg loss: 0.17273 (A-MSE: 0.15217) avg lploss: 0.00000
train epoch 984 avg loss: 0.22197 (A-MSE: 0.19574) avg lploss: 0.00000
train epoch 985 avg loss: 0.20488 (A-MSE: 0.18083) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.53242 (A-MSE: 0.46623) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.58491 (A-MSE: 0.52829) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 5 out of 50
train epoch 986 avg loss: 0.20274 (A-MSE: 0.17949) avg lploss: 0.00000
train epoch 987 avg loss: 0.18769 (A-MSE: 0.16643) avg lploss: 0.00000
train epoch 988 avg loss: 0.17166 (A-MSE: 0.15062) avg lploss: 0.00000
train epoch 989 avg loss: 0.17289 (A-MSE: 0.15211) avg lploss: 0.00000
train epoch 990 avg loss: 0.14628 (A-MSE: 0.12848) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.39018 (A-MSE: 0.35061) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.44040 (A-MSE: 0.40463) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 6 out of 50
train epoch 991 avg loss: 0.14864 (A-MSE: 0.13201) avg lploss: 0.00000
train epoch 992 avg loss: 0.16445 (A-MSE: 0.14428) avg lploss: 0.00000
train epoch 993 avg loss: 0.17205 (A-MSE: 0.15062) avg lploss: 0.00000
train epoch 994 avg loss: 0.18170 (A-MSE: 0.16070) avg lploss: 0.00000
train epoch 995 avg loss: 0.17601 (A-MSE: 0.15540) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.39128 (A-MSE: 0.34663) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.44648 (A-MSE: 0.40483) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 7 out of 50
train epoch 996 avg loss: 0.15952 (A-MSE: 0.14078) avg lploss: 0.00000
train epoch 997 avg loss: 0.16498 (A-MSE: 0.14559) avg lploss: 0.00000
train epoch 998 avg loss: 0.15511 (A-MSE: 0.13821) avg lploss: 0.00000
train epoch 999 avg loss: 0.15488 (A-MSE: 0.13707) avg lploss: 0.00000
train epoch 1000 avg loss: 0.14721 (A-MSE: 0.12969) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.37847 (A-MSE: 0.33330) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.42362 (A-MSE: 0.38256) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 8 out of 50
train epoch 1001 avg loss: 0.14653 (A-MSE: 0.13045) avg lploss: 0.00000
train epoch 1002 avg loss: 0.14772 (A-MSE: 0.13143) avg lploss: 0.00000
train epoch 1003 avg loss: 0.15059 (A-MSE: 0.13420) avg lploss: 0.00000
train epoch 1004 avg loss: 0.17555 (A-MSE: 0.15574) avg lploss: 0.00000
train epoch 1005 avg loss: 0.15760 (A-MSE: 0.13969) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.42906 (A-MSE: 0.37140) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.49996 (A-MSE: 0.44087) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 9 out of 50
train epoch 1006 avg loss: 0.17604 (A-MSE: 0.15375) avg lploss: 0.00000
train epoch 1007 avg loss: 0.18203 (A-MSE: 0.16130) avg lploss: 0.00000
train epoch 1008 avg loss: 0.17441 (A-MSE: 0.15276) avg lploss: 0.00000
train epoch 1009 avg loss: 0.17905 (A-MSE: 0.15820) avg lploss: 0.00000
train epoch 1010 avg loss: 0.17041 (A-MSE: 0.15123) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.40705 (A-MSE: 0.35558) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.44999 (A-MSE: 0.39917) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 10 out of 50
train epoch 1011 avg loss: 0.16471 (A-MSE: 0.14633) avg lploss: 0.00000
train epoch 1012 avg loss: 0.15490 (A-MSE: 0.13676) avg lploss: 0.00000
train epoch 1013 avg loss: 0.14670 (A-MSE: 0.13019) avg lploss: 0.00000
train epoch 1014 avg loss: 0.14974 (A-MSE: 0.13267) avg lploss: 0.00000
train epoch 1015 avg loss: 0.16937 (A-MSE: 0.14922) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.37314 (A-MSE: 0.32734) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.42559 (A-MSE: 0.38300) avg lploss: 0.00000
*** Best Val Loss: 0.35451 	 Best Test Loss: 0.41172 	 Best epoch 960
EarlyStopping counter: 11 out of 50
train epoch 1016 avg loss: 0.18278 (A-MSE: 0.16047) avg lploss: 0.00000
train epoch 1017 avg loss: 0.16174 (A-MSE: 0.14387) avg lploss: 0.00000
train epoch 1018 avg loss: 0.16313 (A-MSE: 0.14283) avg lploss: 0.00000
train epoch 1019 avg loss: 0.16268 (A-MSE: 0.14452) avg lploss: 0.00000
train epoch 1020 avg loss: 0.20429 (A-MSE: 0.17798) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.35066 (A-MSE: 0.32449) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.42092 (A-MSE: 0.38944) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
Validation loss decreased (0.354514 --> 0.350655).  Saving model ...
train epoch 1021 avg loss: 0.17742 (A-MSE: 0.15718) avg lploss: 0.00000
train epoch 1022 avg loss: 0.16062 (A-MSE: 0.14153) avg lploss: 0.00000
train epoch 1023 avg loss: 0.14201 (A-MSE: 0.12516) avg lploss: 0.00000
train epoch 1024 avg loss: 0.14445 (A-MSE: 0.12681) avg lploss: 0.00000
train epoch 1025 avg loss: 0.16121 (A-MSE: 0.14253) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.40807 (A-MSE: 0.37137) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.46941 (A-MSE: 0.43644) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 1 out of 50
train epoch 1026 avg loss: 0.16177 (A-MSE: 0.14183) avg lploss: 0.00000
train epoch 1027 avg loss: 0.17602 (A-MSE: 0.15569) avg lploss: 0.00000
train epoch 1028 avg loss: 0.15096 (A-MSE: 0.13482) avg lploss: 0.00000
train epoch 1029 avg loss: 0.18375 (A-MSE: 0.16125) avg lploss: 0.00000
train epoch 1030 avg loss: 0.19827 (A-MSE: 0.17445) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.40723 (A-MSE: 0.35912) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.46154 (A-MSE: 0.42008) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 2 out of 50
train epoch 1031 avg loss: 0.16738 (A-MSE: 0.14625) avg lploss: 0.00000
train epoch 1032 avg loss: 0.19568 (A-MSE: 0.17264) avg lploss: 0.00000
train epoch 1033 avg loss: 0.17631 (A-MSE: 0.15688) avg lploss: 0.00000
train epoch 1034 avg loss: 0.17526 (A-MSE: 0.15328) avg lploss: 0.00000
train epoch 1035 avg loss: 0.17720 (A-MSE: 0.15561) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.38756 (A-MSE: 0.34372) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.44623 (A-MSE: 0.40072) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 3 out of 50
train epoch 1036 avg loss: 0.16711 (A-MSE: 0.14735) avg lploss: 0.00000
train epoch 1037 avg loss: 0.15915 (A-MSE: 0.14105) avg lploss: 0.00000
train epoch 1038 avg loss: 0.15786 (A-MSE: 0.13967) avg lploss: 0.00000
train epoch 1039 avg loss: 0.16539 (A-MSE: 0.14591) avg lploss: 0.00000
train epoch 1040 avg loss: 0.16442 (A-MSE: 0.14502) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.38770 (A-MSE: 0.35058) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.44822 (A-MSE: 0.40943) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 4 out of 50
train epoch 1041 avg loss: 0.15977 (A-MSE: 0.14074) avg lploss: 0.00000
train epoch 1042 avg loss: 0.15709 (A-MSE: 0.13863) avg lploss: 0.00000
train epoch 1043 avg loss: 0.15888 (A-MSE: 0.14132) avg lploss: 0.00000
train epoch 1044 avg loss: 0.15053 (A-MSE: 0.13337) avg lploss: 0.00000
train epoch 1045 avg loss: 0.15332 (A-MSE: 0.13638) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.40269 (A-MSE: 0.35871) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.46138 (A-MSE: 0.41629) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 5 out of 50
train epoch 1046 avg loss: 0.15916 (A-MSE: 0.14043) avg lploss: 0.00000
train epoch 1047 avg loss: 0.16128 (A-MSE: 0.14286) avg lploss: 0.00000
train epoch 1048 avg loss: 0.16259 (A-MSE: 0.14428) avg lploss: 0.00000
train epoch 1049 avg loss: 0.15513 (A-MSE: 0.13727) avg lploss: 0.00000
train epoch 1050 avg loss: 0.16530 (A-MSE: 0.14579) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.41056 (A-MSE: 0.35304) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.45989 (A-MSE: 0.40806) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 6 out of 50
train epoch 1051 avg loss: 0.15431 (A-MSE: 0.13495) avg lploss: 0.00000
train epoch 1052 avg loss: 0.15238 (A-MSE: 0.13512) avg lploss: 0.00000
train epoch 1053 avg loss: 0.17331 (A-MSE: 0.15343) avg lploss: 0.00000
train epoch 1054 avg loss: 0.15641 (A-MSE: 0.13724) avg lploss: 0.00000
train epoch 1055 avg loss: 0.14299 (A-MSE: 0.12705) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.40601 (A-MSE: 0.35755) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.49480 (A-MSE: 0.45221) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 7 out of 50
train epoch 1056 avg loss: 0.14932 (A-MSE: 0.13201) avg lploss: 0.00000
train epoch 1057 avg loss: 0.15328 (A-MSE: 0.13733) avg lploss: 0.00000
train epoch 1058 avg loss: 0.14776 (A-MSE: 0.13130) avg lploss: 0.00000
train epoch 1059 avg loss: 0.15675 (A-MSE: 0.13792) avg lploss: 0.00000
train epoch 1060 avg loss: 0.14818 (A-MSE: 0.13131) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.40874 (A-MSE: 0.36416) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.46372 (A-MSE: 0.42388) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 8 out of 50
train epoch 1061 avg loss: 0.16059 (A-MSE: 0.14193) avg lploss: 0.00000
train epoch 1062 avg loss: 0.16361 (A-MSE: 0.14513) avg lploss: 0.00000
train epoch 1063 avg loss: 0.15190 (A-MSE: 0.13331) avg lploss: 0.00000
train epoch 1064 avg loss: 0.15793 (A-MSE: 0.14017) avg lploss: 0.00000
train epoch 1065 avg loss: 0.18720 (A-MSE: 0.16420) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.38226 (A-MSE: 0.33521) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.45355 (A-MSE: 0.40500) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 9 out of 50
train epoch 1066 avg loss: 0.16354 (A-MSE: 0.14491) avg lploss: 0.00000
train epoch 1067 avg loss: 0.15318 (A-MSE: 0.13652) avg lploss: 0.00000
train epoch 1068 avg loss: 0.14524 (A-MSE: 0.12904) avg lploss: 0.00000
train epoch 1069 avg loss: 0.17500 (A-MSE: 0.15347) avg lploss: 0.00000
train epoch 1070 avg loss: 0.17800 (A-MSE: 0.15814) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.37519 (A-MSE: 0.33656) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.43504 (A-MSE: 0.40154) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 10 out of 50
train epoch 1071 avg loss: 0.17911 (A-MSE: 0.16033) avg lploss: 0.00000
train epoch 1072 avg loss: 0.14759 (A-MSE: 0.13125) avg lploss: 0.00000
train epoch 1073 avg loss: 0.15186 (A-MSE: 0.13536) avg lploss: 0.00000
train epoch 1074 avg loss: 0.15662 (A-MSE: 0.13974) avg lploss: 0.00000
train epoch 1075 avg loss: 0.16956 (A-MSE: 0.15001) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.41052 (A-MSE: 0.36460) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.51478 (A-MSE: 0.46386) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 11 out of 50
train epoch 1076 avg loss: 0.15238 (A-MSE: 0.13417) avg lploss: 0.00000
train epoch 1077 avg loss: 0.14024 (A-MSE: 0.12510) avg lploss: 0.00000
train epoch 1078 avg loss: 0.13834 (A-MSE: 0.12327) avg lploss: 0.00000
train epoch 1079 avg loss: 0.13227 (A-MSE: 0.11710) avg lploss: 0.00000
train epoch 1080 avg loss: 0.12822 (A-MSE: 0.11271) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.40263 (A-MSE: 0.36367) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.47751 (A-MSE: 0.43379) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 12 out of 50
train epoch 1081 avg loss: 0.13785 (A-MSE: 0.12161) avg lploss: 0.00000
train epoch 1082 avg loss: 0.17160 (A-MSE: 0.15157) avg lploss: 0.00000
train epoch 1083 avg loss: 0.19583 (A-MSE: 0.17418) avg lploss: 0.00000
train epoch 1084 avg loss: 0.17956 (A-MSE: 0.15736) avg lploss: 0.00000
train epoch 1085 avg loss: 0.16264 (A-MSE: 0.14416) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.42992 (A-MSE: 0.38029) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.46640 (A-MSE: 0.41708) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 13 out of 50
train epoch 1086 avg loss: 0.14687 (A-MSE: 0.12970) avg lploss: 0.00000
train epoch 1087 avg loss: 0.16990 (A-MSE: 0.15046) avg lploss: 0.00000
train epoch 1088 avg loss: 0.14002 (A-MSE: 0.12353) avg lploss: 0.00000
train epoch 1089 avg loss: 0.14124 (A-MSE: 0.12532) avg lploss: 0.00000
train epoch 1090 avg loss: 0.16781 (A-MSE: 0.14863) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.45419 (A-MSE: 0.39954) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.52541 (A-MSE: 0.46794) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.42092 	 Best epoch 1020
EarlyStopping counter: 14 out of 50
train epoch 1091 avg loss: 0.16382 (A-MSE: 0.14526) avg lploss: 0.00000
train epoch 1092 avg loss: 0.14045 (A-MSE: 0.12492) avg lploss: 0.00000
train epoch 1093 avg loss: 0.15525 (A-MSE: 0.13716) avg lploss: 0.00000
train epoch 1094 avg loss: 0.14761 (A-MSE: 0.13045) avg lploss: 0.00000
train epoch 1095 avg loss: 0.17313 (A-MSE: 0.15169) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.34677 (A-MSE: 0.30927) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.41736 (A-MSE: 0.37927) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
Validation loss decreased (0.350655 --> 0.346771).  Saving model ...
train epoch 1096 avg loss: 0.15503 (A-MSE: 0.13746) avg lploss: 0.00000
train epoch 1097 avg loss: 0.15814 (A-MSE: 0.14006) avg lploss: 0.00000
train epoch 1098 avg loss: 0.17034 (A-MSE: 0.15036) avg lploss: 0.00000
train epoch 1099 avg loss: 0.14944 (A-MSE: 0.13197) avg lploss: 0.00000
train epoch 1100 avg loss: 0.14422 (A-MSE: 0.12739) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.44376 (A-MSE: 0.40182) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.53438 (A-MSE: 0.48790) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 1 out of 50
train epoch 1101 avg loss: 0.14662 (A-MSE: 0.12949) avg lploss: 0.00000
train epoch 1102 avg loss: 0.14399 (A-MSE: 0.12666) avg lploss: 0.00000
train epoch 1103 avg loss: 0.15056 (A-MSE: 0.13149) avg lploss: 0.00000
train epoch 1104 avg loss: 0.16230 (A-MSE: 0.14313) avg lploss: 0.00000
train epoch 1105 avg loss: 0.14097 (A-MSE: 0.12457) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.44068 (A-MSE: 0.37612) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.51267 (A-MSE: 0.45322) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 2 out of 50
train epoch 1106 avg loss: 0.16109 (A-MSE: 0.14294) avg lploss: 0.00000
train epoch 1107 avg loss: 0.16260 (A-MSE: 0.14310) avg lploss: 0.00000
train epoch 1108 avg loss: 0.16707 (A-MSE: 0.14760) avg lploss: 0.00000
train epoch 1109 avg loss: 0.15580 (A-MSE: 0.13798) avg lploss: 0.00000
train epoch 1110 avg loss: 0.15487 (A-MSE: 0.13626) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.37537 (A-MSE: 0.33924) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.44897 (A-MSE: 0.41379) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 3 out of 50
train epoch 1111 avg loss: 0.14329 (A-MSE: 0.12655) avg lploss: 0.00000
train epoch 1112 avg loss: 0.13269 (A-MSE: 0.11694) avg lploss: 0.00000
train epoch 1113 avg loss: 0.13341 (A-MSE: 0.11757) avg lploss: 0.00000
train epoch 1114 avg loss: 0.13192 (A-MSE: 0.11760) avg lploss: 0.00000
train epoch 1115 avg loss: 0.13657 (A-MSE: 0.12078) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.36562 (A-MSE: 0.32840) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.46295 (A-MSE: 0.42281) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 4 out of 50
train epoch 1116 avg loss: 0.14459 (A-MSE: 0.12752) avg lploss: 0.00000
train epoch 1117 avg loss: 0.12664 (A-MSE: 0.11180) avg lploss: 0.00000
train epoch 1118 avg loss: 0.13507 (A-MSE: 0.12010) avg lploss: 0.00000
train epoch 1119 avg loss: 0.13598 (A-MSE: 0.11995) avg lploss: 0.00000
train epoch 1120 avg loss: 0.14681 (A-MSE: 0.12838) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.49816 (A-MSE: 0.44075) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.55283 (A-MSE: 0.49728) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 5 out of 50
train epoch 1121 avg loss: 0.17422 (A-MSE: 0.15438) avg lploss: 0.00000
train epoch 1122 avg loss: 0.17079 (A-MSE: 0.15019) avg lploss: 0.00000
train epoch 1123 avg loss: 0.14766 (A-MSE: 0.12887) avg lploss: 0.00000
train epoch 1124 avg loss: 0.13284 (A-MSE: 0.11842) avg lploss: 0.00000
train epoch 1125 avg loss: 0.13847 (A-MSE: 0.12250) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.42212 (A-MSE: 0.37377) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.48436 (A-MSE: 0.43618) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 6 out of 50
train epoch 1126 avg loss: 0.13461 (A-MSE: 0.12038) avg lploss: 0.00000
train epoch 1127 avg loss: 0.12807 (A-MSE: 0.11293) avg lploss: 0.00000
train epoch 1128 avg loss: 0.13927 (A-MSE: 0.12247) avg lploss: 0.00000
train epoch 1129 avg loss: 0.15594 (A-MSE: 0.13767) avg lploss: 0.00000
train epoch 1130 avg loss: 0.14477 (A-MSE: 0.12714) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.38739 (A-MSE: 0.34245) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.43967 (A-MSE: 0.39467) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 7 out of 50
train epoch 1131 avg loss: 0.14342 (A-MSE: 0.12752) avg lploss: 0.00000
train epoch 1132 avg loss: 0.15307 (A-MSE: 0.13653) avg lploss: 0.00000
train epoch 1133 avg loss: 0.14326 (A-MSE: 0.12705) avg lploss: 0.00000
train epoch 1134 avg loss: 0.15138 (A-MSE: 0.13405) avg lploss: 0.00000
train epoch 1135 avg loss: 0.15008 (A-MSE: 0.13425) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.38959 (A-MSE: 0.34876) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.46805 (A-MSE: 0.42021) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 8 out of 50
train epoch 1136 avg loss: 0.16322 (A-MSE: 0.14234) avg lploss: 0.00000
train epoch 1137 avg loss: 0.15749 (A-MSE: 0.13867) avg lploss: 0.00000
train epoch 1138 avg loss: 0.13731 (A-MSE: 0.12091) avg lploss: 0.00000
train epoch 1139 avg loss: 0.14250 (A-MSE: 0.12616) avg lploss: 0.00000
train epoch 1140 avg loss: 0.12949 (A-MSE: 0.11498) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.39761 (A-MSE: 0.35923) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.43731 (A-MSE: 0.39988) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 9 out of 50
train epoch 1141 avg loss: 0.12859 (A-MSE: 0.11441) avg lploss: 0.00000
train epoch 1142 avg loss: 0.12727 (A-MSE: 0.11159) avg lploss: 0.00000
train epoch 1143 avg loss: 0.12433 (A-MSE: 0.10941) avg lploss: 0.00000
train epoch 1144 avg loss: 0.11835 (A-MSE: 0.10545) avg lploss: 0.00000
train epoch 1145 avg loss: 0.12843 (A-MSE: 0.11380) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.40841 (A-MSE: 0.36375) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.48694 (A-MSE: 0.44081) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 10 out of 50
train epoch 1146 avg loss: 0.13717 (A-MSE: 0.12245) avg lploss: 0.00000
train epoch 1147 avg loss: 0.13831 (A-MSE: 0.12271) avg lploss: 0.00000
train epoch 1148 avg loss: 0.16522 (A-MSE: 0.14655) avg lploss: 0.00000
train epoch 1149 avg loss: 0.17145 (A-MSE: 0.15140) avg lploss: 0.00000
train epoch 1150 avg loss: 0.18829 (A-MSE: 0.16634) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.36316 (A-MSE: 0.33099) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.41534 (A-MSE: 0.38291) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 11 out of 50
train epoch 1151 avg loss: 0.15879 (A-MSE: 0.13955) avg lploss: 0.00000
train epoch 1152 avg loss: 0.13814 (A-MSE: 0.12356) avg lploss: 0.00000
train epoch 1153 avg loss: 0.12958 (A-MSE: 0.11492) avg lploss: 0.00000
train epoch 1154 avg loss: 0.14249 (A-MSE: 0.12633) avg lploss: 0.00000
train epoch 1155 avg loss: 0.17462 (A-MSE: 0.15363) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.37597 (A-MSE: 0.33230) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.45605 (A-MSE: 0.41254) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 12 out of 50
train epoch 1156 avg loss: 0.16802 (A-MSE: 0.14839) avg lploss: 0.00000
train epoch 1157 avg loss: 0.14437 (A-MSE: 0.12781) avg lploss: 0.00000
train epoch 1158 avg loss: 0.13599 (A-MSE: 0.12008) avg lploss: 0.00000
train epoch 1159 avg loss: 0.12547 (A-MSE: 0.11238) avg lploss: 0.00000
train epoch 1160 avg loss: 0.14805 (A-MSE: 0.13101) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.40707 (A-MSE: 0.35588) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.49723 (A-MSE: 0.45103) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 13 out of 50
train epoch 1161 avg loss: 0.13907 (A-MSE: 0.12389) avg lploss: 0.00000
train epoch 1162 avg loss: 0.17656 (A-MSE: 0.15554) avg lploss: 0.00000
train epoch 1163 avg loss: 0.15871 (A-MSE: 0.13960) avg lploss: 0.00000
train epoch 1164 avg loss: 0.16574 (A-MSE: 0.14504) avg lploss: 0.00000
train epoch 1165 avg loss: 0.15282 (A-MSE: 0.13556) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.39547 (A-MSE: 0.34222) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.47223 (A-MSE: 0.41790) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 14 out of 50
train epoch 1166 avg loss: 0.15423 (A-MSE: 0.13580) avg lploss: 0.00000
train epoch 1167 avg loss: 0.13167 (A-MSE: 0.11802) avg lploss: 0.00000
train epoch 1168 avg loss: 0.11989 (A-MSE: 0.10623) avg lploss: 0.00000
train epoch 1169 avg loss: 0.12895 (A-MSE: 0.11503) avg lploss: 0.00000
train epoch 1170 avg loss: 0.15011 (A-MSE: 0.13420) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.41368 (A-MSE: 0.35617) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.47223 (A-MSE: 0.41761) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 15 out of 50
train epoch 1171 avg loss: 0.15409 (A-MSE: 0.13723) avg lploss: 0.00000
train epoch 1172 avg loss: 0.14389 (A-MSE: 0.12638) avg lploss: 0.00000
train epoch 1173 avg loss: 0.13907 (A-MSE: 0.12226) avg lploss: 0.00000
train epoch 1174 avg loss: 0.13122 (A-MSE: 0.11646) avg lploss: 0.00000
train epoch 1175 avg loss: 0.14867 (A-MSE: 0.13236) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.38064 (A-MSE: 0.33873) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.41067 (A-MSE: 0.37158) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 16 out of 50
train epoch 1176 avg loss: 0.14094 (A-MSE: 0.12548) avg lploss: 0.00000
train epoch 1177 avg loss: 0.12663 (A-MSE: 0.11298) avg lploss: 0.00000
train epoch 1178 avg loss: 0.11294 (A-MSE: 0.09942) avg lploss: 0.00000
train epoch 1179 avg loss: 0.12921 (A-MSE: 0.11416) avg lploss: 0.00000
train epoch 1180 avg loss: 0.15116 (A-MSE: 0.13326) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.38934 (A-MSE: 0.34541) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.46353 (A-MSE: 0.42524) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 17 out of 50
train epoch 1181 avg loss: 0.14207 (A-MSE: 0.12549) avg lploss: 0.00000
train epoch 1182 avg loss: 0.15020 (A-MSE: 0.13254) avg lploss: 0.00000
train epoch 1183 avg loss: 0.15182 (A-MSE: 0.13472) avg lploss: 0.00000
train epoch 1184 avg loss: 0.14182 (A-MSE: 0.12710) avg lploss: 0.00000
train epoch 1185 avg loss: 0.12503 (A-MSE: 0.11019) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.38985 (A-MSE: 0.34712) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.47413 (A-MSE: 0.42529) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 18 out of 50
train epoch 1186 avg loss: 0.11650 (A-MSE: 0.10371) avg lploss: 0.00000
train epoch 1187 avg loss: 0.10797 (A-MSE: 0.09561) avg lploss: 0.00000
train epoch 1188 avg loss: 0.11116 (A-MSE: 0.09838) avg lploss: 0.00000
train epoch 1189 avg loss: 0.11606 (A-MSE: 0.10270) avg lploss: 0.00000
train epoch 1190 avg loss: 0.11586 (A-MSE: 0.10262) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.36852 (A-MSE: 0.32405) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.44140 (A-MSE: 0.39447) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 19 out of 50
train epoch 1191 avg loss: 0.11981 (A-MSE: 0.10670) avg lploss: 0.00000
train epoch 1192 avg loss: 0.13350 (A-MSE: 0.11693) avg lploss: 0.00000
train epoch 1193 avg loss: 0.12872 (A-MSE: 0.11385) avg lploss: 0.00000
train epoch 1194 avg loss: 0.13060 (A-MSE: 0.11519) avg lploss: 0.00000
train epoch 1195 avg loss: 0.14583 (A-MSE: 0.12746) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.35113 (A-MSE: 0.31487) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.44334 (A-MSE: 0.40979) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 20 out of 50
train epoch 1196 avg loss: 0.12665 (A-MSE: 0.11354) avg lploss: 0.00000
train epoch 1197 avg loss: 0.10865 (A-MSE: 0.09602) avg lploss: 0.00000
train epoch 1198 avg loss: 0.12155 (A-MSE: 0.10718) avg lploss: 0.00000
train epoch 1199 avg loss: 0.13646 (A-MSE: 0.12097) avg lploss: 0.00000
train epoch 1200 avg loss: 0.14171 (A-MSE: 0.12465) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.36820 (A-MSE: 0.32890) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.42830 (A-MSE: 0.39178) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 21 out of 50
train epoch 1201 avg loss: 0.12797 (A-MSE: 0.11454) avg lploss: 0.00000
train epoch 1202 avg loss: 0.12921 (A-MSE: 0.11334) avg lploss: 0.00000
train epoch 1203 avg loss: 0.13004 (A-MSE: 0.11633) avg lploss: 0.00000
train epoch 1204 avg loss: 0.11549 (A-MSE: 0.10211) avg lploss: 0.00000
train epoch 1205 avg loss: 0.12288 (A-MSE: 0.10910) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.41216 (A-MSE: 0.35862) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.48791 (A-MSE: 0.43341) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 22 out of 50
train epoch 1206 avg loss: 0.12935 (A-MSE: 0.11406) avg lploss: 0.00000
train epoch 1207 avg loss: 0.13215 (A-MSE: 0.11563) avg lploss: 0.00000
train epoch 1208 avg loss: 0.12676 (A-MSE: 0.11235) avg lploss: 0.00000
train epoch 1209 avg loss: 0.11358 (A-MSE: 0.10182) avg lploss: 0.00000
train epoch 1210 avg loss: 0.11628 (A-MSE: 0.10232) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.38969 (A-MSE: 0.34719) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.45273 (A-MSE: 0.41016) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 23 out of 50
train epoch 1211 avg loss: 0.14501 (A-MSE: 0.12686) avg lploss: 0.00000
train epoch 1212 avg loss: 0.14046 (A-MSE: 0.12465) avg lploss: 0.00000
train epoch 1213 avg loss: 0.16211 (A-MSE: 0.14375) avg lploss: 0.00000
train epoch 1214 avg loss: 0.16931 (A-MSE: 0.15083) avg lploss: 0.00000
train epoch 1215 avg loss: 0.14899 (A-MSE: 0.13157) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.37946 (A-MSE: 0.34065) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.44640 (A-MSE: 0.40434) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 24 out of 50
train epoch 1216 avg loss: 0.13489 (A-MSE: 0.12024) avg lploss: 0.00000
train epoch 1217 avg loss: 0.11123 (A-MSE: 0.09911) avg lploss: 0.00000
train epoch 1218 avg loss: 0.10722 (A-MSE: 0.09527) avg lploss: 0.00000
train epoch 1219 avg loss: 0.12460 (A-MSE: 0.10975) avg lploss: 0.00000
train epoch 1220 avg loss: 0.12325 (A-MSE: 0.10973) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.37076 (A-MSE: 0.33070) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.42504 (A-MSE: 0.38485) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 25 out of 50
train epoch 1221 avg loss: 0.11635 (A-MSE: 0.10287) avg lploss: 0.00000
train epoch 1222 avg loss: 0.13109 (A-MSE: 0.11554) avg lploss: 0.00000
train epoch 1223 avg loss: 0.11484 (A-MSE: 0.10255) avg lploss: 0.00000
train epoch 1224 avg loss: 0.12206 (A-MSE: 0.10759) avg lploss: 0.00000
train epoch 1225 avg loss: 0.15104 (A-MSE: 0.13345) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.49430 (A-MSE: 0.44462) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.59728 (A-MSE: 0.54645) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 26 out of 50
train epoch 1226 avg loss: 0.12418 (A-MSE: 0.11046) avg lploss: 0.00000
train epoch 1227 avg loss: 0.14925 (A-MSE: 0.13171) avg lploss: 0.00000
train epoch 1228 avg loss: 0.13355 (A-MSE: 0.11899) avg lploss: 0.00000
train epoch 1229 avg loss: 0.12143 (A-MSE: 0.10866) avg lploss: 0.00000
train epoch 1230 avg loss: 0.12108 (A-MSE: 0.10683) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.39473 (A-MSE: 0.34933) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.47563 (A-MSE: 0.42805) avg lploss: 0.00000
*** Best Val Loss: 0.34677 	 Best Test Loss: 0.41736 	 Best epoch 1095
EarlyStopping counter: 27 out of 50
train epoch 1231 avg loss: 0.12848 (A-MSE: 0.11527) avg lploss: 0.00000
train epoch 1232 avg loss: 0.11922 (A-MSE: 0.10467) avg lploss: 0.00000
train epoch 1233 avg loss: 0.11333 (A-MSE: 0.10070) avg lploss: 0.00000
train epoch 1234 avg loss: 0.12224 (A-MSE: 0.10788) avg lploss: 0.00000
train epoch 1235 avg loss: 0.13164 (A-MSE: 0.11616) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.34615 (A-MSE: 0.30887) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.43415 (A-MSE: 0.39344) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.43415 	 Best epoch 1235
Validation loss decreased (0.346771 --> 0.346146).  Saving model ...
train epoch 1236 avg loss: 0.11908 (A-MSE: 0.10421) avg lploss: 0.00000
train epoch 1237 avg loss: 0.12373 (A-MSE: 0.11087) avg lploss: 0.00000
train epoch 1238 avg loss: 0.12327 (A-MSE: 0.10905) avg lploss: 0.00000
train epoch 1239 avg loss: 0.12384 (A-MSE: 0.11002) avg lploss: 0.00000
train epoch 1240 avg loss: 0.12739 (A-MSE: 0.11207) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.46949 (A-MSE: 0.39061) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.52518 (A-MSE: 0.45024) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.43415 	 Best epoch 1235
EarlyStopping counter: 1 out of 50
train epoch 1241 avg loss: 0.12972 (A-MSE: 0.11498) avg lploss: 0.00000
train epoch 1242 avg loss: 0.13202 (A-MSE: 0.11708) avg lploss: 0.00000
train epoch 1243 avg loss: 0.11133 (A-MSE: 0.09790) avg lploss: 0.00000
train epoch 1244 avg loss: 0.13047 (A-MSE: 0.11428) avg lploss: 0.00000
train epoch 1245 avg loss: 0.12617 (A-MSE: 0.10978) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.40697 (A-MSE: 0.36204) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.49274 (A-MSE: 0.44559) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.43415 	 Best epoch 1235
EarlyStopping counter: 2 out of 50
train epoch 1246 avg loss: 0.12366 (A-MSE: 0.10927) avg lploss: 0.00000
train epoch 1247 avg loss: 0.11690 (A-MSE: 0.10383) avg lploss: 0.00000
train epoch 1248 avg loss: 0.11764 (A-MSE: 0.10472) avg lploss: 0.00000
train epoch 1249 avg loss: 0.12232 (A-MSE: 0.10890) avg lploss: 0.00000
train epoch 1250 avg loss: 0.11695 (A-MSE: 0.10432) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.34189 (A-MSE: 0.30464) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.41211 (A-MSE: 0.37344) avg lploss: 0.00000
*** Best Val Loss: 0.34189 	 Best Test Loss: 0.41211 	 Best epoch 1250
Validation loss decreased (0.346146 --> 0.341890).  Saving model ...
train epoch 1251 avg loss: 0.11641 (A-MSE: 0.10313) avg lploss: 0.00000
train epoch 1252 avg loss: 0.12048 (A-MSE: 0.10654) avg lploss: 0.00000
train epoch 1253 avg loss: 0.10429 (A-MSE: 0.09321) avg lploss: 0.00000
train epoch 1254 avg loss: 0.10061 (A-MSE: 0.08894) avg lploss: 0.00000
train epoch 1255 avg loss: 0.11426 (A-MSE: 0.10259) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.42544 (A-MSE: 0.36261) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.49146 (A-MSE: 0.42907) avg lploss: 0.00000
*** Best Val Loss: 0.34189 	 Best Test Loss: 0.41211 	 Best epoch 1250
EarlyStopping counter: 1 out of 50
train epoch 1256 avg loss: 0.10181 (A-MSE: 0.08988) avg lploss: 0.00000
train epoch 1257 avg loss: 0.10306 (A-MSE: 0.09118) avg lploss: 0.00000
train epoch 1258 avg loss: 0.09995 (A-MSE: 0.08848) avg lploss: 0.00000
train epoch 1259 avg loss: 0.10860 (A-MSE: 0.09673) avg lploss: 0.00000
train epoch 1260 avg loss: 0.12794 (A-MSE: 0.11366) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.43276 (A-MSE: 0.38458) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.54079 (A-MSE: 0.48464) avg lploss: 0.00000
*** Best Val Loss: 0.34189 	 Best Test Loss: 0.41211 	 Best epoch 1250
EarlyStopping counter: 2 out of 50
train epoch 1261 avg loss: 0.11674 (A-MSE: 0.10280) avg lploss: 0.00000
train epoch 1262 avg loss: 0.11181 (A-MSE: 0.09912) avg lploss: 0.00000
train epoch 1263 avg loss: 0.14207 (A-MSE: 0.12720) avg lploss: 0.00000
train epoch 1264 avg loss: 0.14309 (A-MSE: 0.12641) avg lploss: 0.00000
train epoch 1265 avg loss: 0.12978 (A-MSE: 0.11466) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.45408 (A-MSE: 0.40258) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.55130 (A-MSE: 0.49877) avg lploss: 0.00000
*** Best Val Loss: 0.34189 	 Best Test Loss: 0.41211 	 Best epoch 1250
EarlyStopping counter: 3 out of 50
train epoch 1266 avg loss: 0.11629 (A-MSE: 0.10304) avg lploss: 0.00000
train epoch 1267 avg loss: 0.12441 (A-MSE: 0.11003) avg lploss: 0.00000
train epoch 1268 avg loss: 0.11132 (A-MSE: 0.10021) avg lploss: 0.00000
train epoch 1269 avg loss: 0.10678 (A-MSE: 0.09407) avg lploss: 0.00000
train epoch 1270 avg loss: 0.10624 (A-MSE: 0.09438) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.39861 (A-MSE: 0.34854) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.47292 (A-MSE: 0.42127) avg lploss: 0.00000
*** Best Val Loss: 0.34189 	 Best Test Loss: 0.41211 	 Best epoch 1250
EarlyStopping counter: 4 out of 50
train epoch 1271 avg loss: 0.11341 (A-MSE: 0.10106) avg lploss: 0.00000
train epoch 1272 avg loss: 0.11528 (A-MSE: 0.10223) avg lploss: 0.00000
train epoch 1273 avg loss: 0.11968 (A-MSE: 0.10680) avg lploss: 0.00000
train epoch 1274 avg loss: 0.11698 (A-MSE: 0.10299) avg lploss: 0.00000
train epoch 1275 avg loss: 0.11773 (A-MSE: 0.10354) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.34098 (A-MSE: 0.30641) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.40188 (A-MSE: 0.36474) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
Validation loss decreased (0.341890 --> 0.340977).  Saving model ...
train epoch 1276 avg loss: 0.10404 (A-MSE: 0.09176) avg lploss: 0.00000
train epoch 1277 avg loss: 0.10617 (A-MSE: 0.09321) avg lploss: 0.00000
train epoch 1278 avg loss: 0.13027 (A-MSE: 0.11442) avg lploss: 0.00000
train epoch 1279 avg loss: 0.12749 (A-MSE: 0.11271) avg lploss: 0.00000
train epoch 1280 avg loss: 0.11476 (A-MSE: 0.10241) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.38995 (A-MSE: 0.34154) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.44832 (A-MSE: 0.39870) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 1 out of 50
train epoch 1281 avg loss: 0.10850 (A-MSE: 0.09634) avg lploss: 0.00000
train epoch 1282 avg loss: 0.10627 (A-MSE: 0.09341) avg lploss: 0.00000
train epoch 1283 avg loss: 0.11811 (A-MSE: 0.10569) avg lploss: 0.00000
train epoch 1284 avg loss: 0.12388 (A-MSE: 0.10951) avg lploss: 0.00000
train epoch 1285 avg loss: 0.10604 (A-MSE: 0.09342) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.35112 (A-MSE: 0.31185) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.42777 (A-MSE: 0.38355) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 2 out of 50
train epoch 1286 avg loss: 0.10765 (A-MSE: 0.09499) avg lploss: 0.00000
train epoch 1287 avg loss: 0.12038 (A-MSE: 0.10611) avg lploss: 0.00000
train epoch 1288 avg loss: 0.10277 (A-MSE: 0.09110) avg lploss: 0.00000
train epoch 1289 avg loss: 0.09694 (A-MSE: 0.08649) avg lploss: 0.00000
train epoch 1290 avg loss: 0.10521 (A-MSE: 0.09396) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.53932 (A-MSE: 0.46636) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.64034 (A-MSE: 0.56618) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 3 out of 50
train epoch 1291 avg loss: 0.13884 (A-MSE: 0.12312) avg lploss: 0.00000
train epoch 1292 avg loss: 0.10747 (A-MSE: 0.09540) avg lploss: 0.00000
train epoch 1293 avg loss: 0.11470 (A-MSE: 0.10073) avg lploss: 0.00000
train epoch 1294 avg loss: 0.13208 (A-MSE: 0.11704) avg lploss: 0.00000
train epoch 1295 avg loss: 0.16997 (A-MSE: 0.14989) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.41165 (A-MSE: 0.35761) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.51665 (A-MSE: 0.45752) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 4 out of 50
train epoch 1296 avg loss: 0.14046 (A-MSE: 0.12450) avg lploss: 0.00000
train epoch 1297 avg loss: 0.14682 (A-MSE: 0.12929) avg lploss: 0.00000
train epoch 1298 avg loss: 0.13113 (A-MSE: 0.11605) avg lploss: 0.00000
train epoch 1299 avg loss: 0.12975 (A-MSE: 0.11430) avg lploss: 0.00000
train epoch 1300 avg loss: 0.12498 (A-MSE: 0.11069) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.37097 (A-MSE: 0.33218) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.43862 (A-MSE: 0.40003) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 5 out of 50
train epoch 1301 avg loss: 0.11126 (A-MSE: 0.09858) avg lploss: 0.00000
train epoch 1302 avg loss: 0.10636 (A-MSE: 0.09467) avg lploss: 0.00000
train epoch 1303 avg loss: 0.11196 (A-MSE: 0.10064) avg lploss: 0.00000
train epoch 1304 avg loss: 0.11608 (A-MSE: 0.10231) avg lploss: 0.00000
train epoch 1305 avg loss: 0.11643 (A-MSE: 0.10344) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.39877 (A-MSE: 0.35843) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.48373 (A-MSE: 0.43873) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 6 out of 50
train epoch 1306 avg loss: 0.12549 (A-MSE: 0.11292) avg lploss: 0.00000
train epoch 1307 avg loss: 0.13250 (A-MSE: 0.11835) avg lploss: 0.00000
train epoch 1308 avg loss: 0.13210 (A-MSE: 0.11691) avg lploss: 0.00000
train epoch 1309 avg loss: 0.11002 (A-MSE: 0.09675) avg lploss: 0.00000
train epoch 1310 avg loss: 0.10181 (A-MSE: 0.09174) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.39172 (A-MSE: 0.34400) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.46703 (A-MSE: 0.41553) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 7 out of 50
train epoch 1311 avg loss: 0.09972 (A-MSE: 0.08852) avg lploss: 0.00000
train epoch 1312 avg loss: 0.10230 (A-MSE: 0.09038) avg lploss: 0.00000
train epoch 1313 avg loss: 0.10175 (A-MSE: 0.09025) avg lploss: 0.00000
train epoch 1314 avg loss: 0.10229 (A-MSE: 0.09063) avg lploss: 0.00000
train epoch 1315 avg loss: 0.12189 (A-MSE: 0.10630) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.48179 (A-MSE: 0.41822) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.54944 (A-MSE: 0.48357) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 8 out of 50
train epoch 1316 avg loss: 0.11458 (A-MSE: 0.10258) avg lploss: 0.00000
train epoch 1317 avg loss: 0.13095 (A-MSE: 0.11538) avg lploss: 0.00000
train epoch 1318 avg loss: 0.11033 (A-MSE: 0.09749) avg lploss: 0.00000
train epoch 1319 avg loss: 0.11974 (A-MSE: 0.10529) avg lploss: 0.00000
train epoch 1320 avg loss: 0.11305 (A-MSE: 0.09990) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.35814 (A-MSE: 0.31277) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.42423 (A-MSE: 0.37908) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 9 out of 50
train epoch 1321 avg loss: 0.11338 (A-MSE: 0.10049) avg lploss: 0.00000
train epoch 1322 avg loss: 0.11392 (A-MSE: 0.10192) avg lploss: 0.00000
train epoch 1323 avg loss: 0.13048 (A-MSE: 0.11559) avg lploss: 0.00000
train epoch 1324 avg loss: 0.12089 (A-MSE: 0.10780) avg lploss: 0.00000
train epoch 1325 avg loss: 0.11086 (A-MSE: 0.09730) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.42650 (A-MSE: 0.36946) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.46563 (A-MSE: 0.41463) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 10 out of 50
train epoch 1326 avg loss: 0.10337 (A-MSE: 0.09128) avg lploss: 0.00000
train epoch 1327 avg loss: 0.09341 (A-MSE: 0.08302) avg lploss: 0.00000
train epoch 1328 avg loss: 0.11489 (A-MSE: 0.10273) avg lploss: 0.00000
train epoch 1329 avg loss: 0.13398 (A-MSE: 0.11877) avg lploss: 0.00000
train epoch 1330 avg loss: 0.13091 (A-MSE: 0.11639) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.40407 (A-MSE: 0.35923) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.50729 (A-MSE: 0.45965) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 11 out of 50
train epoch 1331 avg loss: 0.10873 (A-MSE: 0.09775) avg lploss: 0.00000
train epoch 1332 avg loss: 0.09993 (A-MSE: 0.08928) avg lploss: 0.00000
train epoch 1333 avg loss: 0.09914 (A-MSE: 0.08781) avg lploss: 0.00000
train epoch 1334 avg loss: 0.10662 (A-MSE: 0.09463) avg lploss: 0.00000
train epoch 1335 avg loss: 0.10784 (A-MSE: 0.09486) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.40106 (A-MSE: 0.34983) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.47260 (A-MSE: 0.41593) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 12 out of 50
train epoch 1336 avg loss: 0.09327 (A-MSE: 0.08269) avg lploss: 0.00000
train epoch 1337 avg loss: 0.10308 (A-MSE: 0.09130) avg lploss: 0.00000
train epoch 1338 avg loss: 0.10414 (A-MSE: 0.09217) avg lploss: 0.00000
train epoch 1339 avg loss: 0.09202 (A-MSE: 0.08222) avg lploss: 0.00000
train epoch 1340 avg loss: 0.10137 (A-MSE: 0.09000) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.38041 (A-MSE: 0.33250) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.45267 (A-MSE: 0.40664) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 13 out of 50
train epoch 1341 avg loss: 0.09625 (A-MSE: 0.08517) avg lploss: 0.00000
train epoch 1342 avg loss: 0.09191 (A-MSE: 0.08119) avg lploss: 0.00000
train epoch 1343 avg loss: 0.10389 (A-MSE: 0.09242) avg lploss: 0.00000
train epoch 1344 avg loss: 0.11896 (A-MSE: 0.10514) avg lploss: 0.00000
train epoch 1345 avg loss: 0.13043 (A-MSE: 0.11613) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.41453 (A-MSE: 0.36364) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.48862 (A-MSE: 0.43837) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 14 out of 50
train epoch 1346 avg loss: 0.13386 (A-MSE: 0.11837) avg lploss: 0.00000
train epoch 1347 avg loss: 0.12588 (A-MSE: 0.11191) avg lploss: 0.00000
train epoch 1348 avg loss: 0.11120 (A-MSE: 0.09915) avg lploss: 0.00000
train epoch 1349 avg loss: 0.10518 (A-MSE: 0.09304) avg lploss: 0.00000
train epoch 1350 avg loss: 0.11133 (A-MSE: 0.09894) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.40677 (A-MSE: 0.34892) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.47566 (A-MSE: 0.42042) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 15 out of 50
train epoch 1351 avg loss: 0.09614 (A-MSE: 0.08551) avg lploss: 0.00000
train epoch 1352 avg loss: 0.09152 (A-MSE: 0.08135) avg lploss: 0.00000
train epoch 1353 avg loss: 0.14529 (A-MSE: 0.12870) avg lploss: 0.00000
train epoch 1354 avg loss: 0.14896 (A-MSE: 0.13172) avg lploss: 0.00000
train epoch 1355 avg loss: 0.12685 (A-MSE: 0.11236) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.39563 (A-MSE: 0.34242) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.45450 (A-MSE: 0.39744) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 16 out of 50
train epoch 1356 avg loss: 0.10966 (A-MSE: 0.09855) avg lploss: 0.00000
train epoch 1357 avg loss: 0.11738 (A-MSE: 0.10369) avg lploss: 0.00000
train epoch 1358 avg loss: 0.11086 (A-MSE: 0.09864) avg lploss: 0.00000
train epoch 1359 avg loss: 0.10647 (A-MSE: 0.09447) avg lploss: 0.00000
train epoch 1360 avg loss: 0.09990 (A-MSE: 0.08934) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.38738 (A-MSE: 0.34199) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.48860 (A-MSE: 0.44068) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 17 out of 50
train epoch 1361 avg loss: 0.09793 (A-MSE: 0.08717) avg lploss: 0.00000
train epoch 1362 avg loss: 0.09402 (A-MSE: 0.08350) avg lploss: 0.00000
train epoch 1363 avg loss: 0.09909 (A-MSE: 0.08741) avg lploss: 0.00000
train epoch 1364 avg loss: 0.10115 (A-MSE: 0.08912) avg lploss: 0.00000
train epoch 1365 avg loss: 0.09949 (A-MSE: 0.08811) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.37587 (A-MSE: 0.32545) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.45797 (A-MSE: 0.40709) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 18 out of 50
train epoch 1366 avg loss: 0.09641 (A-MSE: 0.08592) avg lploss: 0.00000
train epoch 1367 avg loss: 0.08814 (A-MSE: 0.07899) avg lploss: 0.00000
train epoch 1368 avg loss: 0.08794 (A-MSE: 0.07817) avg lploss: 0.00000
train epoch 1369 avg loss: 0.08856 (A-MSE: 0.07881) avg lploss: 0.00000
train epoch 1370 avg loss: 0.08552 (A-MSE: 0.07593) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.40850 (A-MSE: 0.35507) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.49103 (A-MSE: 0.43636) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 19 out of 50
train epoch 1371 avg loss: 0.08670 (A-MSE: 0.07715) avg lploss: 0.00000
train epoch 1372 avg loss: 0.09384 (A-MSE: 0.08290) avg lploss: 0.00000
train epoch 1373 avg loss: 0.09290 (A-MSE: 0.08100) avg lploss: 0.00000
train epoch 1374 avg loss: 0.09296 (A-MSE: 0.08246) avg lploss: 0.00000
train epoch 1375 avg loss: 0.08726 (A-MSE: 0.07775) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.40273 (A-MSE: 0.35693) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.47488 (A-MSE: 0.42594) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 20 out of 50
train epoch 1376 avg loss: 0.09162 (A-MSE: 0.08090) avg lploss: 0.00000
train epoch 1377 avg loss: 0.08023 (A-MSE: 0.07125) avg lploss: 0.00000
train epoch 1378 avg loss: 0.08889 (A-MSE: 0.07915) avg lploss: 0.00000
train epoch 1379 avg loss: 0.09981 (A-MSE: 0.08833) avg lploss: 0.00000
train epoch 1380 avg loss: 0.11508 (A-MSE: 0.10066) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.37019 (A-MSE: 0.32746) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.45087 (A-MSE: 0.40281) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 21 out of 50
train epoch 1381 avg loss: 0.09001 (A-MSE: 0.07996) avg lploss: 0.00000
train epoch 1382 avg loss: 0.09179 (A-MSE: 0.08125) avg lploss: 0.00000
train epoch 1383 avg loss: 0.08905 (A-MSE: 0.07985) avg lploss: 0.00000
train epoch 1384 avg loss: 0.08472 (A-MSE: 0.07472) avg lploss: 0.00000
train epoch 1385 avg loss: 0.08440 (A-MSE: 0.07580) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.38283 (A-MSE: 0.33162) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.46984 (A-MSE: 0.41433) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 22 out of 50
train epoch 1386 avg loss: 0.09377 (A-MSE: 0.08331) avg lploss: 0.00000
train epoch 1387 avg loss: 0.11772 (A-MSE: 0.10419) avg lploss: 0.00000
train epoch 1388 avg loss: 0.13318 (A-MSE: 0.11811) avg lploss: 0.00000
train epoch 1389 avg loss: 0.11859 (A-MSE: 0.10606) avg lploss: 0.00000
train epoch 1390 avg loss: 0.11669 (A-MSE: 0.10365) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.38053 (A-MSE: 0.33622) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.44213 (A-MSE: 0.40220) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 23 out of 50
train epoch 1391 avg loss: 0.11089 (A-MSE: 0.09822) avg lploss: 0.00000
train epoch 1392 avg loss: 0.11757 (A-MSE: 0.10369) avg lploss: 0.00000
train epoch 1393 avg loss: 0.10875 (A-MSE: 0.09624) avg lploss: 0.00000
train epoch 1394 avg loss: 0.09522 (A-MSE: 0.08420) avg lploss: 0.00000
train epoch 1395 avg loss: 0.09025 (A-MSE: 0.07997) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.41057 (A-MSE: 0.36159) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.50287 (A-MSE: 0.44634) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 24 out of 50
train epoch 1396 avg loss: 0.09460 (A-MSE: 0.08360) avg lploss: 0.00000
train epoch 1397 avg loss: 0.10658 (A-MSE: 0.09391) avg lploss: 0.00000
train epoch 1398 avg loss: 0.10687 (A-MSE: 0.09693) avg lploss: 0.00000
train epoch 1399 avg loss: 0.10056 (A-MSE: 0.08924) avg lploss: 0.00000
train epoch 1400 avg loss: 0.09369 (A-MSE: 0.08324) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.37588 (A-MSE: 0.32657) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.43687 (A-MSE: 0.38779) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 25 out of 50
train epoch 1401 avg loss: 0.09127 (A-MSE: 0.08149) avg lploss: 0.00000
train epoch 1402 avg loss: 0.11442 (A-MSE: 0.10178) avg lploss: 0.00000
train epoch 1403 avg loss: 0.14130 (A-MSE: 0.12410) avg lploss: 0.00000
train epoch 1404 avg loss: 0.11730 (A-MSE: 0.10379) avg lploss: 0.00000
train epoch 1405 avg loss: 0.11758 (A-MSE: 0.10486) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.52696 (A-MSE: 0.45116) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.59129 (A-MSE: 0.51468) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 26 out of 50
train epoch 1406 avg loss: 0.11476 (A-MSE: 0.10081) avg lploss: 0.00000
train epoch 1407 avg loss: 0.09326 (A-MSE: 0.08330) avg lploss: 0.00000
train epoch 1408 avg loss: 0.11081 (A-MSE: 0.09795) avg lploss: 0.00000
train epoch 1409 avg loss: 0.10816 (A-MSE: 0.09552) avg lploss: 0.00000
train epoch 1410 avg loss: 0.09671 (A-MSE: 0.08615) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.39272 (A-MSE: 0.34443) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.45950 (A-MSE: 0.41227) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 27 out of 50
train epoch 1411 avg loss: 0.10664 (A-MSE: 0.09344) avg lploss: 0.00000
train epoch 1412 avg loss: 0.10860 (A-MSE: 0.09601) avg lploss: 0.00000
train epoch 1413 avg loss: 0.09922 (A-MSE: 0.08845) avg lploss: 0.00000
train epoch 1414 avg loss: 0.12210 (A-MSE: 0.10868) avg lploss: 0.00000
train epoch 1415 avg loss: 0.15532 (A-MSE: 0.13531) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.38944 (A-MSE: 0.33958) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.45460 (A-MSE: 0.40792) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 28 out of 50
train epoch 1416 avg loss: 0.13440 (A-MSE: 0.11995) avg lploss: 0.00000
train epoch 1417 avg loss: 0.11050 (A-MSE: 0.09860) avg lploss: 0.00000
train epoch 1418 avg loss: 0.09730 (A-MSE: 0.08500) avg lploss: 0.00000
train epoch 1419 avg loss: 0.09648 (A-MSE: 0.08485) avg lploss: 0.00000
train epoch 1420 avg loss: 0.08682 (A-MSE: 0.07661) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.42555 (A-MSE: 0.37660) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.49528 (A-MSE: 0.44282) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 29 out of 50
train epoch 1421 avg loss: 0.08780 (A-MSE: 0.07788) avg lploss: 0.00000
train epoch 1422 avg loss: 0.08175 (A-MSE: 0.07260) avg lploss: 0.00000
train epoch 1423 avg loss: 0.09444 (A-MSE: 0.08438) avg lploss: 0.00000
train epoch 1424 avg loss: 0.10336 (A-MSE: 0.09091) avg lploss: 0.00000
train epoch 1425 avg loss: 0.10019 (A-MSE: 0.08872) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.39507 (A-MSE: 0.34207) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.48120 (A-MSE: 0.42731) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 30 out of 50
train epoch 1426 avg loss: 0.09648 (A-MSE: 0.08567) avg lploss: 0.00000
train epoch 1427 avg loss: 0.10496 (A-MSE: 0.09339) avg lploss: 0.00000
train epoch 1428 avg loss: 0.10256 (A-MSE: 0.09045) avg lploss: 0.00000
train epoch 1429 avg loss: 0.09475 (A-MSE: 0.08423) avg lploss: 0.00000
train epoch 1430 avg loss: 0.09010 (A-MSE: 0.07993) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.35597 (A-MSE: 0.31765) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.43474 (A-MSE: 0.38893) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 31 out of 50
train epoch 1431 avg loss: 0.08598 (A-MSE: 0.07605) avg lploss: 0.00000
train epoch 1432 avg loss: 0.08765 (A-MSE: 0.07750) avg lploss: 0.00000
train epoch 1433 avg loss: 0.12015 (A-MSE: 0.10919) avg lploss: 0.00000
train epoch 1434 avg loss: 0.12119 (A-MSE: 0.10816) avg lploss: 0.00000
train epoch 1435 avg loss: 0.12388 (A-MSE: 0.10941) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.36832 (A-MSE: 0.33507) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.42370 (A-MSE: 0.38850) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 32 out of 50
train epoch 1436 avg loss: 0.11241 (A-MSE: 0.09949) avg lploss: 0.00000
train epoch 1437 avg loss: 0.10582 (A-MSE: 0.09404) avg lploss: 0.00000
train epoch 1438 avg loss: 0.08860 (A-MSE: 0.07917) avg lploss: 0.00000
train epoch 1439 avg loss: 0.09272 (A-MSE: 0.08337) avg lploss: 0.00000
train epoch 1440 avg loss: 0.08576 (A-MSE: 0.07514) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.37164 (A-MSE: 0.32921) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.45837 (A-MSE: 0.40707) avg lploss: 0.00000
*** Best Val Loss: 0.34098 	 Best Test Loss: 0.40188 	 Best epoch 1275
EarlyStopping counter: 33 out of 50
train epoch 1441 avg loss: 0.07996 (A-MSE: 0.07178) avg lploss: 0.00000
train epoch 1442 avg loss: 0.09332 (A-MSE: 0.08170) avg lploss: 0.00000
train epoch 1443 avg loss: 0.08680 (A-MSE: 0.07652) avg lploss: 0.00000
train epoch 1444 avg loss: 0.08547 (A-MSE: 0.07579) avg lploss: 0.00000
train epoch 1445 avg loss: 0.08965 (A-MSE: 0.08022) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.32894 (A-MSE: 0.29202) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.40551 (A-MSE: 0.36456) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
Validation loss decreased (0.340977 --> 0.328944).  Saving model ...
train epoch 1446 avg loss: 0.09900 (A-MSE: 0.08714) avg lploss: 0.00000
train epoch 1447 avg loss: 0.08803 (A-MSE: 0.07864) avg lploss: 0.00000
train epoch 1448 avg loss: 0.08925 (A-MSE: 0.07891) avg lploss: 0.00000
train epoch 1449 avg loss: 0.11258 (A-MSE: 0.09916) avg lploss: 0.00000
train epoch 1450 avg loss: 0.09901 (A-MSE: 0.08853) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.38757 (A-MSE: 0.33940) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.45859 (A-MSE: 0.41246) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 1 out of 50
train epoch 1451 avg loss: 0.09207 (A-MSE: 0.08184) avg lploss: 0.00000
train epoch 1452 avg loss: 0.09051 (A-MSE: 0.08002) avg lploss: 0.00000
train epoch 1453 avg loss: 0.08867 (A-MSE: 0.07848) avg lploss: 0.00000
train epoch 1454 avg loss: 0.09019 (A-MSE: 0.07995) avg lploss: 0.00000
train epoch 1455 avg loss: 0.08262 (A-MSE: 0.07355) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.35739 (A-MSE: 0.31910) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.43976 (A-MSE: 0.39647) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 2 out of 50
train epoch 1456 avg loss: 0.08377 (A-MSE: 0.07464) avg lploss: 0.00000
train epoch 1457 avg loss: 0.07876 (A-MSE: 0.06982) avg lploss: 0.00000
train epoch 1458 avg loss: 0.08340 (A-MSE: 0.07379) avg lploss: 0.00000
train epoch 1459 avg loss: 0.08774 (A-MSE: 0.07837) avg lploss: 0.00000
train epoch 1460 avg loss: 0.08131 (A-MSE: 0.07279) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.42871 (A-MSE: 0.38257) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.50992 (A-MSE: 0.45663) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 3 out of 50
train epoch 1461 avg loss: 0.08559 (A-MSE: 0.07664) avg lploss: 0.00000
train epoch 1462 avg loss: 0.08197 (A-MSE: 0.07329) avg lploss: 0.00000
train epoch 1463 avg loss: 0.09549 (A-MSE: 0.08491) avg lploss: 0.00000
train epoch 1464 avg loss: 0.09495 (A-MSE: 0.08356) avg lploss: 0.00000
train epoch 1465 avg loss: 0.09172 (A-MSE: 0.08196) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.37948 (A-MSE: 0.33593) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.43821 (A-MSE: 0.39051) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 4 out of 50
train epoch 1466 avg loss: 0.09195 (A-MSE: 0.08204) avg lploss: 0.00000
train epoch 1467 avg loss: 0.09134 (A-MSE: 0.08086) avg lploss: 0.00000
train epoch 1468 avg loss: 0.08241 (A-MSE: 0.07266) avg lploss: 0.00000
train epoch 1469 avg loss: 0.10064 (A-MSE: 0.08866) avg lploss: 0.00000
train epoch 1470 avg loss: 0.11583 (A-MSE: 0.10286) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.34122 (A-MSE: 0.30185) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.43481 (A-MSE: 0.39379) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 5 out of 50
train epoch 1471 avg loss: 0.11592 (A-MSE: 0.10214) avg lploss: 0.00000
train epoch 1472 avg loss: 0.10731 (A-MSE: 0.09628) avg lploss: 0.00000
train epoch 1473 avg loss: 0.11762 (A-MSE: 0.10354) avg lploss: 0.00000
train epoch 1474 avg loss: 0.09924 (A-MSE: 0.08856) avg lploss: 0.00000
train epoch 1475 avg loss: 0.09554 (A-MSE: 0.08515) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.43956 (A-MSE: 0.38202) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.52245 (A-MSE: 0.46075) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 6 out of 50
train epoch 1476 avg loss: 0.08079 (A-MSE: 0.07207) avg lploss: 0.00000
train epoch 1477 avg loss: 0.07461 (A-MSE: 0.06630) avg lploss: 0.00000
train epoch 1478 avg loss: 0.07914 (A-MSE: 0.07008) avg lploss: 0.00000
train epoch 1479 avg loss: 0.08398 (A-MSE: 0.07439) avg lploss: 0.00000
train epoch 1480 avg loss: 0.08476 (A-MSE: 0.07488) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.36826 (A-MSE: 0.32720) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.45389 (A-MSE: 0.40772) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 7 out of 50
train epoch 1481 avg loss: 0.08673 (A-MSE: 0.07690) avg lploss: 0.00000
train epoch 1482 avg loss: 0.08988 (A-MSE: 0.07974) avg lploss: 0.00000
train epoch 1483 avg loss: 0.07915 (A-MSE: 0.07084) avg lploss: 0.00000
train epoch 1484 avg loss: 0.07398 (A-MSE: 0.06573) avg lploss: 0.00000
train epoch 1485 avg loss: 0.07968 (A-MSE: 0.07123) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.44436 (A-MSE: 0.38941) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.53391 (A-MSE: 0.47352) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 8 out of 50
train epoch 1486 avg loss: 0.09720 (A-MSE: 0.08640) avg lploss: 0.00000
train epoch 1487 avg loss: 0.09836 (A-MSE: 0.08730) avg lploss: 0.00000
train epoch 1488 avg loss: 0.10004 (A-MSE: 0.08989) avg lploss: 0.00000
train epoch 1489 avg loss: 0.09749 (A-MSE: 0.08679) avg lploss: 0.00000
train epoch 1490 avg loss: 0.08818 (A-MSE: 0.07869) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.44824 (A-MSE: 0.39341) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.56542 (A-MSE: 0.50336) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 9 out of 50
train epoch 1491 avg loss: 0.08056 (A-MSE: 0.07180) avg lploss: 0.00000
train epoch 1492 avg loss: 0.08169 (A-MSE: 0.07262) avg lploss: 0.00000
train epoch 1493 avg loss: 0.09127 (A-MSE: 0.08064) avg lploss: 0.00000
train epoch 1494 avg loss: 0.07843 (A-MSE: 0.07031) avg lploss: 0.00000
train epoch 1495 avg loss: 0.07812 (A-MSE: 0.06990) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.39603 (A-MSE: 0.34734) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.49298 (A-MSE: 0.44137) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 10 out of 50
train epoch 1496 avg loss: 0.08272 (A-MSE: 0.07318) avg lploss: 0.00000
train epoch 1497 avg loss: 0.09036 (A-MSE: 0.08030) avg lploss: 0.00000
train epoch 1498 avg loss: 0.09300 (A-MSE: 0.08271) avg lploss: 0.00000
train epoch 1499 avg loss: 0.08106 (A-MSE: 0.07181) avg lploss: 0.00000
train epoch 1500 avg loss: 0.10074 (A-MSE: 0.08900) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.35441 (A-MSE: 0.31042) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.44257 (A-MSE: 0.39701) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 11 out of 50
train epoch 1501 avg loss: 0.10386 (A-MSE: 0.09201) avg lploss: 0.00000
train epoch 1502 avg loss: 0.10039 (A-MSE: 0.08848) avg lploss: 0.00000
train epoch 1503 avg loss: 0.09917 (A-MSE: 0.08846) avg lploss: 0.00000
train epoch 1504 avg loss: 0.11868 (A-MSE: 0.10484) avg lploss: 0.00000
train epoch 1505 avg loss: 0.10530 (A-MSE: 0.09190) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.38877 (A-MSE: 0.34497) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.46530 (A-MSE: 0.41779) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 12 out of 50
train epoch 1506 avg loss: 0.08606 (A-MSE: 0.07712) avg lploss: 0.00000
train epoch 1507 avg loss: 0.10407 (A-MSE: 0.09311) avg lploss: 0.00000
train epoch 1508 avg loss: 0.11266 (A-MSE: 0.09887) avg lploss: 0.00000
train epoch 1509 avg loss: 0.09380 (A-MSE: 0.08329) avg lploss: 0.00000
train epoch 1510 avg loss: 0.08571 (A-MSE: 0.07609) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.41172 (A-MSE: 0.36318) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.48448 (A-MSE: 0.43124) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 13 out of 50
train epoch 1511 avg loss: 0.08827 (A-MSE: 0.07903) avg lploss: 0.00000
train epoch 1512 avg loss: 0.09418 (A-MSE: 0.08449) avg lploss: 0.00000
train epoch 1513 avg loss: 0.08274 (A-MSE: 0.07270) avg lploss: 0.00000
train epoch 1514 avg loss: 0.08262 (A-MSE: 0.07399) avg lploss: 0.00000
train epoch 1515 avg loss: 0.09314 (A-MSE: 0.08283) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.35958 (A-MSE: 0.31719) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.43233 (A-MSE: 0.38662) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 14 out of 50
train epoch 1516 avg loss: 0.07643 (A-MSE: 0.06827) avg lploss: 0.00000
train epoch 1517 avg loss: 0.07684 (A-MSE: 0.06900) avg lploss: 0.00000
train epoch 1518 avg loss: 0.08454 (A-MSE: 0.07582) avg lploss: 0.00000
train epoch 1519 avg loss: 0.09552 (A-MSE: 0.08501) avg lploss: 0.00000
train epoch 1520 avg loss: 0.09589 (A-MSE: 0.08561) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.37424 (A-MSE: 0.33271) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.45864 (A-MSE: 0.41022) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 15 out of 50
train epoch 1521 avg loss: 0.10076 (A-MSE: 0.08783) avg lploss: 0.00000
train epoch 1522 avg loss: 0.10618 (A-MSE: 0.09383) avg lploss: 0.00000
train epoch 1523 avg loss: 0.09178 (A-MSE: 0.08103) avg lploss: 0.00000
train epoch 1524 avg loss: 0.07196 (A-MSE: 0.06434) avg lploss: 0.00000
train epoch 1525 avg loss: 0.08169 (A-MSE: 0.07369) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.38000 (A-MSE: 0.32963) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.46986 (A-MSE: 0.41297) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 16 out of 50
train epoch 1526 avg loss: 0.08847 (A-MSE: 0.07859) avg lploss: 0.00000
train epoch 1527 avg loss: 0.07282 (A-MSE: 0.06442) avg lploss: 0.00000
train epoch 1528 avg loss: 0.07452 (A-MSE: 0.06687) avg lploss: 0.00000
train epoch 1529 avg loss: 0.07304 (A-MSE: 0.06542) avg lploss: 0.00000
train epoch 1530 avg loss: 0.08710 (A-MSE: 0.07669) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.46638 (A-MSE: 0.41105) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.55514 (A-MSE: 0.49773) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 17 out of 50
train epoch 1531 avg loss: 0.09644 (A-MSE: 0.08555) avg lploss: 0.00000
train epoch 1532 avg loss: 0.08757 (A-MSE: 0.07758) avg lploss: 0.00000
train epoch 1533 avg loss: 0.08138 (A-MSE: 0.07284) avg lploss: 0.00000
train epoch 1534 avg loss: 0.07996 (A-MSE: 0.07048) avg lploss: 0.00000
train epoch 1535 avg loss: 0.09421 (A-MSE: 0.08379) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.37540 (A-MSE: 0.32631) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.43512 (A-MSE: 0.38825) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 18 out of 50
train epoch 1536 avg loss: 0.09374 (A-MSE: 0.08338) avg lploss: 0.00000
train epoch 1537 avg loss: 0.09437 (A-MSE: 0.08493) avg lploss: 0.00000
train epoch 1538 avg loss: 0.11115 (A-MSE: 0.09772) avg lploss: 0.00000
train epoch 1539 avg loss: 0.08973 (A-MSE: 0.07934) avg lploss: 0.00000
train epoch 1540 avg loss: 0.08857 (A-MSE: 0.07795) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.42413 (A-MSE: 0.37064) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.50918 (A-MSE: 0.45034) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 19 out of 50
train epoch 1541 avg loss: 0.08706 (A-MSE: 0.07739) avg lploss: 0.00000
train epoch 1542 avg loss: 0.07921 (A-MSE: 0.07065) avg lploss: 0.00000
train epoch 1543 avg loss: 0.08760 (A-MSE: 0.07777) avg lploss: 0.00000
train epoch 1544 avg loss: 0.06823 (A-MSE: 0.06082) avg lploss: 0.00000
train epoch 1545 avg loss: 0.06458 (A-MSE: 0.05757) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.40687 (A-MSE: 0.35992) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.47851 (A-MSE: 0.42867) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 20 out of 50
train epoch 1546 avg loss: 0.08691 (A-MSE: 0.07645) avg lploss: 0.00000
train epoch 1547 avg loss: 0.09813 (A-MSE: 0.08689) avg lploss: 0.00000
train epoch 1548 avg loss: 0.07763 (A-MSE: 0.06960) avg lploss: 0.00000
train epoch 1549 avg loss: 0.07933 (A-MSE: 0.07012) avg lploss: 0.00000
train epoch 1550 avg loss: 0.08331 (A-MSE: 0.07440) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.42089 (A-MSE: 0.37787) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.51745 (A-MSE: 0.46738) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 21 out of 50
train epoch 1551 avg loss: 0.10918 (A-MSE: 0.09768) avg lploss: 0.00000
train epoch 1552 avg loss: 0.09086 (A-MSE: 0.08108) avg lploss: 0.00000
train epoch 1553 avg loss: 0.08192 (A-MSE: 0.07158) avg lploss: 0.00000
train epoch 1554 avg loss: 0.08106 (A-MSE: 0.07213) avg lploss: 0.00000
train epoch 1555 avg loss: 0.09238 (A-MSE: 0.08247) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.38452 (A-MSE: 0.34853) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.47546 (A-MSE: 0.43317) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 22 out of 50
train epoch 1556 avg loss: 0.09666 (A-MSE: 0.08702) avg lploss: 0.00000
train epoch 1557 avg loss: 0.10032 (A-MSE: 0.08939) avg lploss: 0.00000
train epoch 1558 avg loss: 0.08695 (A-MSE: 0.07698) avg lploss: 0.00000
train epoch 1559 avg loss: 0.08539 (A-MSE: 0.07545) avg lploss: 0.00000
train epoch 1560 avg loss: 0.11299 (A-MSE: 0.10002) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.37595 (A-MSE: 0.33158) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.44921 (A-MSE: 0.40282) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 23 out of 50
train epoch 1561 avg loss: 0.09775 (A-MSE: 0.08683) avg lploss: 0.00000
train epoch 1562 avg loss: 0.08372 (A-MSE: 0.07435) avg lploss: 0.00000
train epoch 1563 avg loss: 0.08288 (A-MSE: 0.07317) avg lploss: 0.00000
train epoch 1564 avg loss: 0.07521 (A-MSE: 0.06717) avg lploss: 0.00000
train epoch 1565 avg loss: 0.07127 (A-MSE: 0.06321) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.39970 (A-MSE: 0.34699) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.47743 (A-MSE: 0.42148) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 24 out of 50
train epoch 1566 avg loss: 0.07495 (A-MSE: 0.06688) avg lploss: 0.00000
train epoch 1567 avg loss: 0.07973 (A-MSE: 0.07060) avg lploss: 0.00000
train epoch 1568 avg loss: 0.07811 (A-MSE: 0.06980) avg lploss: 0.00000
train epoch 1569 avg loss: 0.08015 (A-MSE: 0.07120) avg lploss: 0.00000
train epoch 1570 avg loss: 0.07357 (A-MSE: 0.06539) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.34508 (A-MSE: 0.30392) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.42623 (A-MSE: 0.38498) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 25 out of 50
train epoch 1571 avg loss: 0.08514 (A-MSE: 0.07557) avg lploss: 0.00000
train epoch 1572 avg loss: 0.08292 (A-MSE: 0.07456) avg lploss: 0.00000
train epoch 1573 avg loss: 0.07367 (A-MSE: 0.06543) avg lploss: 0.00000
train epoch 1574 avg loss: 0.07137 (A-MSE: 0.06368) avg lploss: 0.00000
train epoch 1575 avg loss: 0.06666 (A-MSE: 0.05920) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.41488 (A-MSE: 0.36043) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.48538 (A-MSE: 0.42794) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 26 out of 50
train epoch 1576 avg loss: 0.07601 (A-MSE: 0.06705) avg lploss: 0.00000
train epoch 1577 avg loss: 0.09220 (A-MSE: 0.08268) avg lploss: 0.00000
train epoch 1578 avg loss: 0.09118 (A-MSE: 0.08046) avg lploss: 0.00000
train epoch 1579 avg loss: 0.07612 (A-MSE: 0.06798) avg lploss: 0.00000
train epoch 1580 avg loss: 0.08145 (A-MSE: 0.07266) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.34349 (A-MSE: 0.30417) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.41027 (A-MSE: 0.37208) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 27 out of 50
train epoch 1581 avg loss: 0.07133 (A-MSE: 0.06363) avg lploss: 0.00000
train epoch 1582 avg loss: 0.06690 (A-MSE: 0.05994) avg lploss: 0.00000
train epoch 1583 avg loss: 0.06464 (A-MSE: 0.05755) avg lploss: 0.00000
train epoch 1584 avg loss: 0.07493 (A-MSE: 0.06663) avg lploss: 0.00000
train epoch 1585 avg loss: 0.07623 (A-MSE: 0.06774) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.36457 (A-MSE: 0.32747) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.43349 (A-MSE: 0.39024) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 28 out of 50
train epoch 1586 avg loss: 0.06866 (A-MSE: 0.06161) avg lploss: 0.00000
train epoch 1587 avg loss: 0.06847 (A-MSE: 0.06061) avg lploss: 0.00000
train epoch 1588 avg loss: 0.06927 (A-MSE: 0.06177) avg lploss: 0.00000
train epoch 1589 avg loss: 0.07827 (A-MSE: 0.06937) avg lploss: 0.00000
train epoch 1590 avg loss: 0.07534 (A-MSE: 0.06704) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.37077 (A-MSE: 0.32450) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.42773 (A-MSE: 0.37954) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 29 out of 50
train epoch 1591 avg loss: 0.07999 (A-MSE: 0.07026) avg lploss: 0.00000
train epoch 1592 avg loss: 0.07944 (A-MSE: 0.07120) avg lploss: 0.00000
train epoch 1593 avg loss: 0.07161 (A-MSE: 0.06370) avg lploss: 0.00000
train epoch 1594 avg loss: 0.06699 (A-MSE: 0.05895) avg lploss: 0.00000
train epoch 1595 avg loss: 0.07654 (A-MSE: 0.06784) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.36952 (A-MSE: 0.32424) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.42894 (A-MSE: 0.38395) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 30 out of 50
train epoch 1596 avg loss: 0.06232 (A-MSE: 0.05524) avg lploss: 0.00000
train epoch 1597 avg loss: 0.06662 (A-MSE: 0.05856) avg lploss: 0.00000
train epoch 1598 avg loss: 0.06554 (A-MSE: 0.05830) avg lploss: 0.00000
train epoch 1599 avg loss: 0.06225 (A-MSE: 0.05542) avg lploss: 0.00000
train epoch 1600 avg loss: 0.06084 (A-MSE: 0.05431) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.34839 (A-MSE: 0.30654) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.43874 (A-MSE: 0.39160) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 31 out of 50
train epoch 1601 avg loss: 0.06723 (A-MSE: 0.05953) avg lploss: 0.00000
train epoch 1602 avg loss: 0.06414 (A-MSE: 0.05729) avg lploss: 0.00000
train epoch 1603 avg loss: 0.06371 (A-MSE: 0.05679) avg lploss: 0.00000
train epoch 1604 avg loss: 0.06772 (A-MSE: 0.06011) avg lploss: 0.00000
train epoch 1605 avg loss: 0.07036 (A-MSE: 0.06272) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.38312 (A-MSE: 0.33747) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.47469 (A-MSE: 0.42053) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 32 out of 50
train epoch 1606 avg loss: 0.07191 (A-MSE: 0.06349) avg lploss: 0.00000
train epoch 1607 avg loss: 0.07850 (A-MSE: 0.07036) avg lploss: 0.00000
train epoch 1608 avg loss: 0.07950 (A-MSE: 0.06982) avg lploss: 0.00000
train epoch 1609 avg loss: 0.07255 (A-MSE: 0.06522) avg lploss: 0.00000
train epoch 1610 avg loss: 0.06991 (A-MSE: 0.06217) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.39814 (A-MSE: 0.34807) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.47868 (A-MSE: 0.42200) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 33 out of 50
train epoch 1611 avg loss: 0.07058 (A-MSE: 0.06266) avg lploss: 0.00000
train epoch 1612 avg loss: 0.06641 (A-MSE: 0.05934) avg lploss: 0.00000
train epoch 1613 avg loss: 0.07911 (A-MSE: 0.07001) avg lploss: 0.00000
train epoch 1614 avg loss: 0.06948 (A-MSE: 0.06142) avg lploss: 0.00000
train epoch 1615 avg loss: 0.06828 (A-MSE: 0.06158) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.40021 (A-MSE: 0.35559) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.47418 (A-MSE: 0.42540) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 34 out of 50
train epoch 1616 avg loss: 0.07362 (A-MSE: 0.06544) avg lploss: 0.00000
train epoch 1617 avg loss: 0.06923 (A-MSE: 0.06208) avg lploss: 0.00000
train epoch 1618 avg loss: 0.07170 (A-MSE: 0.06455) avg lploss: 0.00000
train epoch 1619 avg loss: 0.07495 (A-MSE: 0.06642) avg lploss: 0.00000
train epoch 1620 avg loss: 0.06886 (A-MSE: 0.06099) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.39358 (A-MSE: 0.35068) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.46859 (A-MSE: 0.42010) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 35 out of 50
train epoch 1621 avg loss: 0.07563 (A-MSE: 0.06741) avg lploss: 0.00000
train epoch 1622 avg loss: 0.07629 (A-MSE: 0.06795) avg lploss: 0.00000
train epoch 1623 avg loss: 0.07726 (A-MSE: 0.06822) avg lploss: 0.00000
train epoch 1624 avg loss: 0.08071 (A-MSE: 0.07216) avg lploss: 0.00000
train epoch 1625 avg loss: 0.06767 (A-MSE: 0.06075) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.37483 (A-MSE: 0.32859) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.45562 (A-MSE: 0.40668) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 36 out of 50
train epoch 1626 avg loss: 0.07696 (A-MSE: 0.06787) avg lploss: 0.00000
train epoch 1627 avg loss: 0.07032 (A-MSE: 0.06269) avg lploss: 0.00000
train epoch 1628 avg loss: 0.07333 (A-MSE: 0.06525) avg lploss: 0.00000
train epoch 1629 avg loss: 0.07536 (A-MSE: 0.06729) avg lploss: 0.00000
train epoch 1630 avg loss: 0.08608 (A-MSE: 0.07593) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.51542 (A-MSE: 0.44629) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.60459 (A-MSE: 0.52834) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 37 out of 50
train epoch 1631 avg loss: 0.10446 (A-MSE: 0.09313) avg lploss: 0.00000
train epoch 1632 avg loss: 0.08677 (A-MSE: 0.07763) avg lploss: 0.00000
train epoch 1633 avg loss: 0.08477 (A-MSE: 0.07478) avg lploss: 0.00000
train epoch 1634 avg loss: 0.08923 (A-MSE: 0.07885) avg lploss: 0.00000
train epoch 1635 avg loss: 0.07504 (A-MSE: 0.06645) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.43710 (A-MSE: 0.37477) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.51696 (A-MSE: 0.45306) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 38 out of 50
train epoch 1636 avg loss: 0.07001 (A-MSE: 0.06180) avg lploss: 0.00000
train epoch 1637 avg loss: 0.06667 (A-MSE: 0.05900) avg lploss: 0.00000
train epoch 1638 avg loss: 0.06348 (A-MSE: 0.05683) avg lploss: 0.00000
train epoch 1639 avg loss: 0.06541 (A-MSE: 0.05805) avg lploss: 0.00000
train epoch 1640 avg loss: 0.06475 (A-MSE: 0.05712) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.40785 (A-MSE: 0.35756) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.47797 (A-MSE: 0.42514) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 39 out of 50
train epoch 1641 avg loss: 0.06291 (A-MSE: 0.05675) avg lploss: 0.00000
train epoch 1642 avg loss: 0.07452 (A-MSE: 0.06623) avg lploss: 0.00000
train epoch 1643 avg loss: 0.06848 (A-MSE: 0.06144) avg lploss: 0.00000
train epoch 1644 avg loss: 0.07455 (A-MSE: 0.06662) avg lploss: 0.00000
train epoch 1645 avg loss: 0.06256 (A-MSE: 0.05530) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.35677 (A-MSE: 0.31583) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.43573 (A-MSE: 0.38890) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 40 out of 50
train epoch 1646 avg loss: 0.06022 (A-MSE: 0.05379) avg lploss: 0.00000
train epoch 1647 avg loss: 0.07498 (A-MSE: 0.06605) avg lploss: 0.00000
train epoch 1648 avg loss: 0.06767 (A-MSE: 0.05946) avg lploss: 0.00000
train epoch 1649 avg loss: 0.07091 (A-MSE: 0.06369) avg lploss: 0.00000
train epoch 1650 avg loss: 0.06682 (A-MSE: 0.05944) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.42843 (A-MSE: 0.37020) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.50085 (A-MSE: 0.44110) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 41 out of 50
train epoch 1651 avg loss: 0.07830 (A-MSE: 0.07011) avg lploss: 0.00000
train epoch 1652 avg loss: 0.10602 (A-MSE: 0.09286) avg lploss: 0.00000
train epoch 1653 avg loss: 0.09497 (A-MSE: 0.08311) avg lploss: 0.00000
train epoch 1654 avg loss: 0.10254 (A-MSE: 0.09129) avg lploss: 0.00000
train epoch 1655 avg loss: 0.09079 (A-MSE: 0.08083) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.40935 (A-MSE: 0.35815) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.47604 (A-MSE: 0.42461) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 42 out of 50
train epoch 1656 avg loss: 0.07450 (A-MSE: 0.06654) avg lploss: 0.00000
train epoch 1657 avg loss: 0.08322 (A-MSE: 0.07487) avg lploss: 0.00000
train epoch 1658 avg loss: 0.08657 (A-MSE: 0.07690) avg lploss: 0.00000
train epoch 1659 avg loss: 0.07424 (A-MSE: 0.06550) avg lploss: 0.00000
train epoch 1660 avg loss: 0.06617 (A-MSE: 0.05908) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.44134 (A-MSE: 0.37588) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.54187 (A-MSE: 0.47106) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 43 out of 50
train epoch 1661 avg loss: 0.06217 (A-MSE: 0.05508) avg lploss: 0.00000
train epoch 1662 avg loss: 0.06175 (A-MSE: 0.05473) avg lploss: 0.00000
train epoch 1663 avg loss: 0.07215 (A-MSE: 0.06398) avg lploss: 0.00000
train epoch 1664 avg loss: 0.07132 (A-MSE: 0.06331) avg lploss: 0.00000
train epoch 1665 avg loss: 0.07351 (A-MSE: 0.06488) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.36751 (A-MSE: 0.32842) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.47705 (A-MSE: 0.42692) avg lploss: 0.00000
*** Best Val Loss: 0.32894 	 Best Test Loss: 0.40551 	 Best epoch 1445
EarlyStopping counter: 44 out of 50
train epoch 1666 avg loss: 0.07361 (A-MSE: 0.06505) avg lploss: 0.00000
train epoch 1667 avg loss: 0.06125 (A-MSE: 0.05477) avg lploss: 0.00000
train epoch 1668 avg loss: 0.06407 (A-MSE: 0.05713) avg lploss: 0.00000
train epoch 1669 avg loss: 0.06373 (A-MSE: 0.05676) avg lploss: 0.00000
train epoch 1670 avg loss: 0.05722 (A-MSE: 0.05110) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.32859 (A-MSE: 0.29287) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.39197 (A-MSE: 0.35346) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
Validation loss decreased (0.328944 --> 0.328591).  Saving model ...
train epoch 1671 avg loss: 0.08341 (A-MSE: 0.07432) avg lploss: 0.00000
train epoch 1672 avg loss: 0.06806 (A-MSE: 0.06056) avg lploss: 0.00000
train epoch 1673 avg loss: 0.08133 (A-MSE: 0.07272) avg lploss: 0.00000
train epoch 1674 avg loss: 0.10872 (A-MSE: 0.09636) avg lploss: 0.00000
train epoch 1675 avg loss: 0.08205 (A-MSE: 0.07239) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.35380 (A-MSE: 0.31519) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.44092 (A-MSE: 0.39354) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 1 out of 50
train epoch 1676 avg loss: 0.06368 (A-MSE: 0.05615) avg lploss: 0.00000
train epoch 1677 avg loss: 0.05919 (A-MSE: 0.05269) avg lploss: 0.00000
train epoch 1678 avg loss: 0.07549 (A-MSE: 0.06738) avg lploss: 0.00000
train epoch 1679 avg loss: 0.07851 (A-MSE: 0.06920) avg lploss: 0.00000
train epoch 1680 avg loss: 0.06881 (A-MSE: 0.06085) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.37950 (A-MSE: 0.33280) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.44087 (A-MSE: 0.39233) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 2 out of 50
train epoch 1681 avg loss: 0.05745 (A-MSE: 0.05179) avg lploss: 0.00000
train epoch 1682 avg loss: 0.06287 (A-MSE: 0.05557) avg lploss: 0.00000
train epoch 1683 avg loss: 0.08152 (A-MSE: 0.07205) avg lploss: 0.00000
train epoch 1684 avg loss: 0.08069 (A-MSE: 0.07190) avg lploss: 0.00000
train epoch 1685 avg loss: 0.08051 (A-MSE: 0.07106) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.40273 (A-MSE: 0.35491) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.46762 (A-MSE: 0.41678) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 3 out of 50
train epoch 1686 avg loss: 0.07578 (A-MSE: 0.06732) avg lploss: 0.00000
train epoch 1687 avg loss: 0.06815 (A-MSE: 0.06051) avg lploss: 0.00000
train epoch 1688 avg loss: 0.06598 (A-MSE: 0.05843) avg lploss: 0.00000
train epoch 1689 avg loss: 0.06221 (A-MSE: 0.05496) avg lploss: 0.00000
train epoch 1690 avg loss: 0.06618 (A-MSE: 0.05926) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.36428 (A-MSE: 0.32061) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.44656 (A-MSE: 0.39921) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 4 out of 50
train epoch 1691 avg loss: 0.05597 (A-MSE: 0.04946) avg lploss: 0.00000
train epoch 1692 avg loss: 0.06941 (A-MSE: 0.06203) avg lploss: 0.00000
train epoch 1693 avg loss: 0.08523 (A-MSE: 0.07585) avg lploss: 0.00000
train epoch 1694 avg loss: 0.07001 (A-MSE: 0.06230) avg lploss: 0.00000
train epoch 1695 avg loss: 0.07315 (A-MSE: 0.06515) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.37753 (A-MSE: 0.33218) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.43762 (A-MSE: 0.38579) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 5 out of 50
train epoch 1696 avg loss: 0.07263 (A-MSE: 0.06476) avg lploss: 0.00000
train epoch 1697 avg loss: 0.09196 (A-MSE: 0.08218) avg lploss: 0.00000
train epoch 1698 avg loss: 0.07573 (A-MSE: 0.06790) avg lploss: 0.00000
train epoch 1699 avg loss: 0.06570 (A-MSE: 0.05870) avg lploss: 0.00000
train epoch 1700 avg loss: 0.07753 (A-MSE: 0.06914) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.42478 (A-MSE: 0.37271) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.47526 (A-MSE: 0.42347) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 6 out of 50
train epoch 1701 avg loss: 0.08168 (A-MSE: 0.07317) avg lploss: 0.00000
train epoch 1702 avg loss: 0.07655 (A-MSE: 0.06841) avg lploss: 0.00000
train epoch 1703 avg loss: 0.07381 (A-MSE: 0.06450) avg lploss: 0.00000
train epoch 1704 avg loss: 0.14300 (A-MSE: 0.12757) avg lploss: 0.00000
train epoch 1705 avg loss: 0.09781 (A-MSE: 0.08633) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.38095 (A-MSE: 0.33563) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.47485 (A-MSE: 0.41987) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 7 out of 50
train epoch 1706 avg loss: 0.07481 (A-MSE: 0.06658) avg lploss: 0.00000
train epoch 1707 avg loss: 0.06801 (A-MSE: 0.05995) avg lploss: 0.00000
train epoch 1708 avg loss: 0.07324 (A-MSE: 0.06460) avg lploss: 0.00000
train epoch 1709 avg loss: 0.07338 (A-MSE: 0.06557) avg lploss: 0.00000
train epoch 1710 avg loss: 0.05458 (A-MSE: 0.04850) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.36862 (A-MSE: 0.32377) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.44679 (A-MSE: 0.39627) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 8 out of 50
train epoch 1711 avg loss: 0.06010 (A-MSE: 0.05374) avg lploss: 0.00000
train epoch 1712 avg loss: 0.05829 (A-MSE: 0.05210) avg lploss: 0.00000
train epoch 1713 avg loss: 0.05196 (A-MSE: 0.04646) avg lploss: 0.00000
train epoch 1714 avg loss: 0.04882 (A-MSE: 0.04350) avg lploss: 0.00000
train epoch 1715 avg loss: 0.06008 (A-MSE: 0.05302) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.40101 (A-MSE: 0.34944) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.48589 (A-MSE: 0.42894) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 9 out of 50
train epoch 1716 avg loss: 0.05724 (A-MSE: 0.05104) avg lploss: 0.00000
train epoch 1717 avg loss: 0.06117 (A-MSE: 0.05395) avg lploss: 0.00000
train epoch 1718 avg loss: 0.05792 (A-MSE: 0.05103) avg lploss: 0.00000
train epoch 1719 avg loss: 0.05195 (A-MSE: 0.04590) avg lploss: 0.00000
train epoch 1720 avg loss: 0.05083 (A-MSE: 0.04518) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.34224 (A-MSE: 0.30187) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.44043 (A-MSE: 0.39312) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 10 out of 50
train epoch 1721 avg loss: 0.07540 (A-MSE: 0.06758) avg lploss: 0.00000
train epoch 1722 avg loss: 0.06022 (A-MSE: 0.05401) avg lploss: 0.00000
train epoch 1723 avg loss: 0.06239 (A-MSE: 0.05582) avg lploss: 0.00000
train epoch 1724 avg loss: 0.06432 (A-MSE: 0.05685) avg lploss: 0.00000
train epoch 1725 avg loss: 0.05956 (A-MSE: 0.05273) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.39242 (A-MSE: 0.33897) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.45926 (A-MSE: 0.40564) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 11 out of 50
train epoch 1726 avg loss: 0.05911 (A-MSE: 0.05275) avg lploss: 0.00000
train epoch 1727 avg loss: 0.05702 (A-MSE: 0.05072) avg lploss: 0.00000
train epoch 1728 avg loss: 0.05505 (A-MSE: 0.04911) avg lploss: 0.00000
train epoch 1729 avg loss: 0.06020 (A-MSE: 0.05404) avg lploss: 0.00000
train epoch 1730 avg loss: 0.06113 (A-MSE: 0.05439) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.35445 (A-MSE: 0.31599) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.42837 (A-MSE: 0.38359) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 12 out of 50
train epoch 1731 avg loss: 0.06311 (A-MSE: 0.05584) avg lploss: 0.00000
train epoch 1732 avg loss: 0.05858 (A-MSE: 0.05237) avg lploss: 0.00000
train epoch 1733 avg loss: 0.05820 (A-MSE: 0.05153) avg lploss: 0.00000
train epoch 1734 avg loss: 0.05918 (A-MSE: 0.05255) avg lploss: 0.00000
train epoch 1735 avg loss: 0.06336 (A-MSE: 0.05582) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.38693 (A-MSE: 0.34418) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.46702 (A-MSE: 0.41678) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 13 out of 50
train epoch 1736 avg loss: 0.06003 (A-MSE: 0.05378) avg lploss: 0.00000
train epoch 1737 avg loss: 0.06007 (A-MSE: 0.05271) avg lploss: 0.00000
train epoch 1738 avg loss: 0.05677 (A-MSE: 0.05083) avg lploss: 0.00000
train epoch 1739 avg loss: 0.05387 (A-MSE: 0.04838) avg lploss: 0.00000
train epoch 1740 avg loss: 0.06411 (A-MSE: 0.05688) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.42675 (A-MSE: 0.37832) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.49987 (A-MSE: 0.44669) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 14 out of 50
train epoch 1741 avg loss: 0.06083 (A-MSE: 0.05489) avg lploss: 0.00000
train epoch 1742 avg loss: 0.06481 (A-MSE: 0.05695) avg lploss: 0.00000
train epoch 1743 avg loss: 0.06028 (A-MSE: 0.05318) avg lploss: 0.00000
train epoch 1744 avg loss: 0.05598 (A-MSE: 0.04950) avg lploss: 0.00000
train epoch 1745 avg loss: 0.05699 (A-MSE: 0.05036) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.40397 (A-MSE: 0.35423) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.47476 (A-MSE: 0.41771) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 15 out of 50
train epoch 1746 avg loss: 0.05350 (A-MSE: 0.04752) avg lploss: 0.00000
train epoch 1747 avg loss: 0.06422 (A-MSE: 0.05756) avg lploss: 0.00000
train epoch 1748 avg loss: 0.05285 (A-MSE: 0.04762) avg lploss: 0.00000
train epoch 1749 avg loss: 0.04668 (A-MSE: 0.04120) avg lploss: 0.00000
train epoch 1750 avg loss: 0.05060 (A-MSE: 0.04556) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.39309 (A-MSE: 0.35103) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.48392 (A-MSE: 0.43382) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 16 out of 50
train epoch 1751 avg loss: 0.05189 (A-MSE: 0.04626) avg lploss: 0.00000
train epoch 1752 avg loss: 0.06468 (A-MSE: 0.05729) avg lploss: 0.00000
train epoch 1753 avg loss: 0.05976 (A-MSE: 0.05343) avg lploss: 0.00000
train epoch 1754 avg loss: 0.05959 (A-MSE: 0.05233) avg lploss: 0.00000
train epoch 1755 avg loss: 0.06892 (A-MSE: 0.06176) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.40756 (A-MSE: 0.35776) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.48621 (A-MSE: 0.43220) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 17 out of 50
train epoch 1756 avg loss: 0.06311 (A-MSE: 0.05620) avg lploss: 0.00000
train epoch 1757 avg loss: 0.06308 (A-MSE: 0.05625) avg lploss: 0.00000
train epoch 1758 avg loss: 0.06867 (A-MSE: 0.06054) avg lploss: 0.00000
train epoch 1759 avg loss: 0.07682 (A-MSE: 0.06754) avg lploss: 0.00000
train epoch 1760 avg loss: 0.08435 (A-MSE: 0.07524) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.42526 (A-MSE: 0.37084) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.50776 (A-MSE: 0.45041) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 18 out of 50
train epoch 1761 avg loss: 0.07372 (A-MSE: 0.06535) avg lploss: 0.00000
train epoch 1762 avg loss: 0.06777 (A-MSE: 0.06033) avg lploss: 0.00000
train epoch 1763 avg loss: 0.06419 (A-MSE: 0.05709) avg lploss: 0.00000
train epoch 1764 avg loss: 0.06056 (A-MSE: 0.05369) avg lploss: 0.00000
train epoch 1765 avg loss: 0.06181 (A-MSE: 0.05522) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.39043 (A-MSE: 0.34318) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.47625 (A-MSE: 0.42010) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 19 out of 50
train epoch 1766 avg loss: 0.06429 (A-MSE: 0.05742) avg lploss: 0.00000
train epoch 1767 avg loss: 0.06610 (A-MSE: 0.05877) avg lploss: 0.00000
train epoch 1768 avg loss: 0.05734 (A-MSE: 0.05099) avg lploss: 0.00000
train epoch 1769 avg loss: 0.05566 (A-MSE: 0.04942) avg lploss: 0.00000
train epoch 1770 avg loss: 0.05653 (A-MSE: 0.05030) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.41990 (A-MSE: 0.36982) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.51384 (A-MSE: 0.45140) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 20 out of 50
train epoch 1771 avg loss: 0.06548 (A-MSE: 0.05778) avg lploss: 0.00000
train epoch 1772 avg loss: 0.08694 (A-MSE: 0.07637) avg lploss: 0.00000
train epoch 1773 avg loss: 0.08816 (A-MSE: 0.07728) avg lploss: 0.00000
train epoch 1774 avg loss: 0.07862 (A-MSE: 0.06970) avg lploss: 0.00000
train epoch 1775 avg loss: 0.07395 (A-MSE: 0.06663) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.38564 (A-MSE: 0.34132) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.48390 (A-MSE: 0.42919) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 21 out of 50
train epoch 1776 avg loss: 0.06714 (A-MSE: 0.06002) avg lploss: 0.00000
train epoch 1777 avg loss: 0.06568 (A-MSE: 0.05804) avg lploss: 0.00000
train epoch 1778 avg loss: 0.05738 (A-MSE: 0.05121) avg lploss: 0.00000
train epoch 1779 avg loss: 0.05241 (A-MSE: 0.04697) avg lploss: 0.00000
train epoch 1780 avg loss: 0.05046 (A-MSE: 0.04511) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.37009 (A-MSE: 0.32831) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.44707 (A-MSE: 0.39894) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 22 out of 50
train epoch 1781 avg loss: 0.05214 (A-MSE: 0.04670) avg lploss: 0.00000
train epoch 1782 avg loss: 0.04840 (A-MSE: 0.04322) avg lploss: 0.00000
train epoch 1783 avg loss: 0.05483 (A-MSE: 0.04850) avg lploss: 0.00000
train epoch 1784 avg loss: 0.05022 (A-MSE: 0.04523) avg lploss: 0.00000
train epoch 1785 avg loss: 0.05651 (A-MSE: 0.04950) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.37324 (A-MSE: 0.33126) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.47170 (A-MSE: 0.41902) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 23 out of 50
train epoch 1786 avg loss: 0.05752 (A-MSE: 0.05107) avg lploss: 0.00000
train epoch 1787 avg loss: 0.05541 (A-MSE: 0.04933) avg lploss: 0.00000
train epoch 1788 avg loss: 0.05457 (A-MSE: 0.04861) avg lploss: 0.00000
train epoch 1789 avg loss: 0.05848 (A-MSE: 0.05299) avg lploss: 0.00000
train epoch 1790 avg loss: 0.05655 (A-MSE: 0.04992) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.35228 (A-MSE: 0.31164) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.44467 (A-MSE: 0.39584) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 24 out of 50
train epoch 1791 avg loss: 0.06339 (A-MSE: 0.05699) avg lploss: 0.00000
train epoch 1792 avg loss: 0.06325 (A-MSE: 0.05637) avg lploss: 0.00000
train epoch 1793 avg loss: 0.07646 (A-MSE: 0.06735) avg lploss: 0.00000
train epoch 1794 avg loss: 0.06056 (A-MSE: 0.05450) avg lploss: 0.00000
train epoch 1795 avg loss: 0.06240 (A-MSE: 0.05517) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.40272 (A-MSE: 0.35257) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.51837 (A-MSE: 0.45608) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 25 out of 50
train epoch 1796 avg loss: 0.06875 (A-MSE: 0.06096) avg lploss: 0.00000
train epoch 1797 avg loss: 0.06322 (A-MSE: 0.05584) avg lploss: 0.00000
train epoch 1798 avg loss: 0.05730 (A-MSE: 0.05039) avg lploss: 0.00000
train epoch 1799 avg loss: 0.05666 (A-MSE: 0.05034) avg lploss: 0.00000
train epoch 1800 avg loss: 0.06057 (A-MSE: 0.05410) avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.39751 (A-MSE: 0.35216) avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.47298 (A-MSE: 0.41510) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 26 out of 50
train epoch 1801 avg loss: 0.07195 (A-MSE: 0.06382) avg lploss: 0.00000
train epoch 1802 avg loss: 0.05828 (A-MSE: 0.05173) avg lploss: 0.00000
train epoch 1803 avg loss: 0.06677 (A-MSE: 0.05921) avg lploss: 0.00000
train epoch 1804 avg loss: 0.06798 (A-MSE: 0.06064) avg lploss: 0.00000
train epoch 1805 avg loss: 0.05867 (A-MSE: 0.05215) avg lploss: 0.00000
==> val epoch 1805 avg loss: 0.35916 (A-MSE: 0.31984) avg lploss: 0.00000
==> test epoch 1805 avg loss: 0.45179 (A-MSE: 0.40388) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 27 out of 50
train epoch 1806 avg loss: 0.05267 (A-MSE: 0.04688) avg lploss: 0.00000
train epoch 1807 avg loss: 0.05573 (A-MSE: 0.04940) avg lploss: 0.00000
train epoch 1808 avg loss: 0.05578 (A-MSE: 0.05012) avg lploss: 0.00000
train epoch 1809 avg loss: 0.06051 (A-MSE: 0.05373) avg lploss: 0.00000
train epoch 1810 avg loss: 0.05362 (A-MSE: 0.04784) avg lploss: 0.00000
==> val epoch 1810 avg loss: 0.38651 (A-MSE: 0.34074) avg lploss: 0.00000
==> test epoch 1810 avg loss: 0.49192 (A-MSE: 0.43375) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 28 out of 50
train epoch 1811 avg loss: 0.04857 (A-MSE: 0.04363) avg lploss: 0.00000
train epoch 1812 avg loss: 0.05553 (A-MSE: 0.04878) avg lploss: 0.00000
train epoch 1813 avg loss: 0.05712 (A-MSE: 0.05152) avg lploss: 0.00000
train epoch 1814 avg loss: 0.05775 (A-MSE: 0.05221) avg lploss: 0.00000
train epoch 1815 avg loss: 0.05919 (A-MSE: 0.05248) avg lploss: 0.00000
==> val epoch 1815 avg loss: 0.37188 (A-MSE: 0.33161) avg lploss: 0.00000
==> test epoch 1815 avg loss: 0.44188 (A-MSE: 0.39185) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 29 out of 50
train epoch 1816 avg loss: 0.05852 (A-MSE: 0.05243) avg lploss: 0.00000
train epoch 1817 avg loss: 0.05892 (A-MSE: 0.05221) avg lploss: 0.00000
train epoch 1818 avg loss: 0.04889 (A-MSE: 0.04399) avg lploss: 0.00000
train epoch 1819 avg loss: 0.04649 (A-MSE: 0.04142) avg lploss: 0.00000
train epoch 1820 avg loss: 0.04970 (A-MSE: 0.04463) avg lploss: 0.00000
==> val epoch 1820 avg loss: 0.36880 (A-MSE: 0.32813) avg lploss: 0.00000
==> test epoch 1820 avg loss: 0.44497 (A-MSE: 0.39655) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 30 out of 50
train epoch 1821 avg loss: 0.05134 (A-MSE: 0.04611) avg lploss: 0.00000
train epoch 1822 avg loss: 0.04918 (A-MSE: 0.04382) avg lploss: 0.00000
train epoch 1823 avg loss: 0.05044 (A-MSE: 0.04510) avg lploss: 0.00000
train epoch 1824 avg loss: 0.05496 (A-MSE: 0.04932) avg lploss: 0.00000
train epoch 1825 avg loss: 0.05644 (A-MSE: 0.05032) avg lploss: 0.00000
==> val epoch 1825 avg loss: 0.36160 (A-MSE: 0.32106) avg lploss: 0.00000
==> test epoch 1825 avg loss: 0.42580 (A-MSE: 0.37742) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 31 out of 50
train epoch 1826 avg loss: 0.05607 (A-MSE: 0.05013) avg lploss: 0.00000
train epoch 1827 avg loss: 0.05851 (A-MSE: 0.05235) avg lploss: 0.00000
train epoch 1828 avg loss: 0.05216 (A-MSE: 0.04664) avg lploss: 0.00000
train epoch 1829 avg loss: 0.05259 (A-MSE: 0.04722) avg lploss: 0.00000
train epoch 1830 avg loss: 0.05052 (A-MSE: 0.04539) avg lploss: 0.00000
==> val epoch 1830 avg loss: 0.34856 (A-MSE: 0.31245) avg lploss: 0.00000
==> test epoch 1830 avg loss: 0.42296 (A-MSE: 0.37861) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 32 out of 50
train epoch 1831 avg loss: 0.04899 (A-MSE: 0.04369) avg lploss: 0.00000
train epoch 1832 avg loss: 0.04683 (A-MSE: 0.04160) avg lploss: 0.00000
train epoch 1833 avg loss: 0.04651 (A-MSE: 0.04170) avg lploss: 0.00000
train epoch 1834 avg loss: 0.06640 (A-MSE: 0.05838) avg lploss: 0.00000
train epoch 1835 avg loss: 0.04978 (A-MSE: 0.04420) avg lploss: 0.00000
==> val epoch 1835 avg loss: 0.36614 (A-MSE: 0.32148) avg lploss: 0.00000
==> test epoch 1835 avg loss: 0.46071 (A-MSE: 0.40805) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 33 out of 50
train epoch 1836 avg loss: 0.05448 (A-MSE: 0.04872) avg lploss: 0.00000
train epoch 1837 avg loss: 0.04571 (A-MSE: 0.04100) avg lploss: 0.00000
train epoch 1838 avg loss: 0.04775 (A-MSE: 0.04237) avg lploss: 0.00000
train epoch 1839 avg loss: 0.04867 (A-MSE: 0.04350) avg lploss: 0.00000
train epoch 1840 avg loss: 0.05100 (A-MSE: 0.04580) avg lploss: 0.00000
==> val epoch 1840 avg loss: 0.38000 (A-MSE: 0.33741) avg lploss: 0.00000
==> test epoch 1840 avg loss: 0.45272 (A-MSE: 0.40270) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 34 out of 50
train epoch 1841 avg loss: 0.06728 (A-MSE: 0.05942) avg lploss: 0.00000
train epoch 1842 avg loss: 0.06045 (A-MSE: 0.05381) avg lploss: 0.00000
train epoch 1843 avg loss: 0.05553 (A-MSE: 0.04919) avg lploss: 0.00000
train epoch 1844 avg loss: 0.05999 (A-MSE: 0.05389) avg lploss: 0.00000
train epoch 1845 avg loss: 0.04830 (A-MSE: 0.04267) avg lploss: 0.00000
==> val epoch 1845 avg loss: 0.33974 (A-MSE: 0.30369) avg lploss: 0.00000
==> test epoch 1845 avg loss: 0.43767 (A-MSE: 0.39132) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 35 out of 50
train epoch 1846 avg loss: 0.05120 (A-MSE: 0.04544) avg lploss: 0.00000
train epoch 1847 avg loss: 0.05864 (A-MSE: 0.05203) avg lploss: 0.00000
train epoch 1848 avg loss: 0.05582 (A-MSE: 0.04981) avg lploss: 0.00000
train epoch 1849 avg loss: 0.04846 (A-MSE: 0.04338) avg lploss: 0.00000
train epoch 1850 avg loss: 0.05221 (A-MSE: 0.04653) avg lploss: 0.00000
==> val epoch 1850 avg loss: 0.36226 (A-MSE: 0.32343) avg lploss: 0.00000
==> test epoch 1850 avg loss: 0.42039 (A-MSE: 0.37442) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 36 out of 50
train epoch 1851 avg loss: 0.04656 (A-MSE: 0.04149) avg lploss: 0.00000
train epoch 1852 avg loss: 0.04827 (A-MSE: 0.04346) avg lploss: 0.00000
train epoch 1853 avg loss: 0.04961 (A-MSE: 0.04428) avg lploss: 0.00000
train epoch 1854 avg loss: 0.05365 (A-MSE: 0.04725) avg lploss: 0.00000
train epoch 1855 avg loss: 0.05530 (A-MSE: 0.04938) avg lploss: 0.00000
==> val epoch 1855 avg loss: 0.40032 (A-MSE: 0.35931) avg lploss: 0.00000
==> test epoch 1855 avg loss: 0.47404 (A-MSE: 0.42245) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 37 out of 50
train epoch 1856 avg loss: 0.05405 (A-MSE: 0.04900) avg lploss: 0.00000
train epoch 1857 avg loss: 0.05046 (A-MSE: 0.04479) avg lploss: 0.00000
train epoch 1858 avg loss: 0.05125 (A-MSE: 0.04559) avg lploss: 0.00000
train epoch 1859 avg loss: 0.05565 (A-MSE: 0.04956) avg lploss: 0.00000
train epoch 1860 avg loss: 0.06613 (A-MSE: 0.05825) avg lploss: 0.00000
==> val epoch 1860 avg loss: 0.44826 (A-MSE: 0.39074) avg lploss: 0.00000
==> test epoch 1860 avg loss: 0.52177 (A-MSE: 0.45712) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 38 out of 50
train epoch 1861 avg loss: 0.06851 (A-MSE: 0.06078) avg lploss: 0.00000
train epoch 1862 avg loss: 0.06478 (A-MSE: 0.05815) avg lploss: 0.00000
train epoch 1863 avg loss: 0.06174 (A-MSE: 0.05467) avg lploss: 0.00000
train epoch 1864 avg loss: 0.05495 (A-MSE: 0.04943) avg lploss: 0.00000
train epoch 1865 avg loss: 0.05524 (A-MSE: 0.04884) avg lploss: 0.00000
==> val epoch 1865 avg loss: 0.40831 (A-MSE: 0.36103) avg lploss: 0.00000
==> test epoch 1865 avg loss: 0.50355 (A-MSE: 0.44525) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 39 out of 50
train epoch 1866 avg loss: 0.06207 (A-MSE: 0.05520) avg lploss: 0.00000
train epoch 1867 avg loss: 0.05811 (A-MSE: 0.05215) avg lploss: 0.00000
train epoch 1868 avg loss: 0.05471 (A-MSE: 0.04908) avg lploss: 0.00000
train epoch 1869 avg loss: 0.05072 (A-MSE: 0.04523) avg lploss: 0.00000
train epoch 1870 avg loss: 0.05245 (A-MSE: 0.04679) avg lploss: 0.00000
==> val epoch 1870 avg loss: 0.37121 (A-MSE: 0.32711) avg lploss: 0.00000
==> test epoch 1870 avg loss: 0.44251 (A-MSE: 0.38905) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 40 out of 50
train epoch 1871 avg loss: 0.05460 (A-MSE: 0.04853) avg lploss: 0.00000
train epoch 1872 avg loss: 0.05299 (A-MSE: 0.04718) avg lploss: 0.00000
train epoch 1873 avg loss: 0.05590 (A-MSE: 0.04972) avg lploss: 0.00000
train epoch 1874 avg loss: 0.05053 (A-MSE: 0.04489) avg lploss: 0.00000
train epoch 1875 avg loss: 0.04457 (A-MSE: 0.04010) avg lploss: 0.00000
==> val epoch 1875 avg loss: 0.40028 (A-MSE: 0.35363) avg lploss: 0.00000
==> test epoch 1875 avg loss: 0.49134 (A-MSE: 0.43578) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 41 out of 50
train epoch 1876 avg loss: 0.04470 (A-MSE: 0.03988) avg lploss: 0.00000
train epoch 1877 avg loss: 0.04256 (A-MSE: 0.03808) avg lploss: 0.00000
train epoch 1878 avg loss: 0.05037 (A-MSE: 0.04519) avg lploss: 0.00000
train epoch 1879 avg loss: 0.07154 (A-MSE: 0.06392) avg lploss: 0.00000
train epoch 1880 avg loss: 0.07271 (A-MSE: 0.06574) avg lploss: 0.00000
==> val epoch 1880 avg loss: 0.39331 (A-MSE: 0.34908) avg lploss: 0.00000
==> test epoch 1880 avg loss: 0.48145 (A-MSE: 0.42678) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 42 out of 50
train epoch 1881 avg loss: 0.05689 (A-MSE: 0.05047) avg lploss: 0.00000
train epoch 1882 avg loss: 0.05889 (A-MSE: 0.05264) avg lploss: 0.00000
train epoch 1883 avg loss: 0.05493 (A-MSE: 0.04889) avg lploss: 0.00000
train epoch 1884 avg loss: 0.05159 (A-MSE: 0.04594) avg lploss: 0.00000
train epoch 1885 avg loss: 0.04656 (A-MSE: 0.04167) avg lploss: 0.00000
==> val epoch 1885 avg loss: 0.39655 (A-MSE: 0.34104) avg lploss: 0.00000
==> test epoch 1885 avg loss: 0.47260 (A-MSE: 0.41057) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 43 out of 50
train epoch 1886 avg loss: 0.04246 (A-MSE: 0.03774) avg lploss: 0.00000
train epoch 1887 avg loss: 0.04332 (A-MSE: 0.03865) avg lploss: 0.00000
train epoch 1888 avg loss: 0.04829 (A-MSE: 0.04248) avg lploss: 0.00000
train epoch 1889 avg loss: 0.05049 (A-MSE: 0.04545) avg lploss: 0.00000
train epoch 1890 avg loss: 0.04729 (A-MSE: 0.04177) avg lploss: 0.00000
==> val epoch 1890 avg loss: 0.41476 (A-MSE: 0.36792) avg lploss: 0.00000
==> test epoch 1890 avg loss: 0.49107 (A-MSE: 0.43485) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 44 out of 50
train epoch 1891 avg loss: 0.04771 (A-MSE: 0.04198) avg lploss: 0.00000
train epoch 1892 avg loss: 0.04807 (A-MSE: 0.04300) avg lploss: 0.00000
train epoch 1893 avg loss: 0.04703 (A-MSE: 0.04204) avg lploss: 0.00000
train epoch 1894 avg loss: 0.04334 (A-MSE: 0.03868) avg lploss: 0.00000
train epoch 1895 avg loss: 0.04812 (A-MSE: 0.04305) avg lploss: 0.00000
==> val epoch 1895 avg loss: 0.37382 (A-MSE: 0.33064) avg lploss: 0.00000
==> test epoch 1895 avg loss: 0.44518 (A-MSE: 0.39170) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 45 out of 50
train epoch 1896 avg loss: 0.05175 (A-MSE: 0.04612) avg lploss: 0.00000
train epoch 1897 avg loss: 0.05507 (A-MSE: 0.04868) avg lploss: 0.00000
train epoch 1898 avg loss: 0.05442 (A-MSE: 0.04890) avg lploss: 0.00000
train epoch 1899 avg loss: 0.04938 (A-MSE: 0.04404) avg lploss: 0.00000
train epoch 1900 avg loss: 0.05181 (A-MSE: 0.04653) avg lploss: 0.00000
==> val epoch 1900 avg loss: 0.37345 (A-MSE: 0.33630) avg lploss: 0.00000
==> test epoch 1900 avg loss: 0.48171 (A-MSE: 0.43313) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 46 out of 50
train epoch 1901 avg loss: 0.06212 (A-MSE: 0.05628) avg lploss: 0.00000
train epoch 1902 avg loss: 0.06359 (A-MSE: 0.05631) avg lploss: 0.00000
train epoch 1903 avg loss: 0.05907 (A-MSE: 0.05257) avg lploss: 0.00000
train epoch 1904 avg loss: 0.06344 (A-MSE: 0.05688) avg lploss: 0.00000
train epoch 1905 avg loss: 0.05923 (A-MSE: 0.05300) avg lploss: 0.00000
==> val epoch 1905 avg loss: 0.38828 (A-MSE: 0.34643) avg lploss: 0.00000
==> test epoch 1905 avg loss: 0.48001 (A-MSE: 0.42933) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 47 out of 50
train epoch 1906 avg loss: 0.05053 (A-MSE: 0.04543) avg lploss: 0.00000
train epoch 1907 avg loss: 0.05303 (A-MSE: 0.04678) avg lploss: 0.00000
train epoch 1908 avg loss: 0.05769 (A-MSE: 0.05172) avg lploss: 0.00000
train epoch 1909 avg loss: 0.05338 (A-MSE: 0.04824) avg lploss: 0.00000
train epoch 1910 avg loss: 0.05063 (A-MSE: 0.04494) avg lploss: 0.00000
==> val epoch 1910 avg loss: 0.35601 (A-MSE: 0.31648) avg lploss: 0.00000
==> test epoch 1910 avg loss: 0.44827 (A-MSE: 0.39950) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 48 out of 50
train epoch 1911 avg loss: 0.04787 (A-MSE: 0.04290) avg lploss: 0.00000
train epoch 1912 avg loss: 0.05021 (A-MSE: 0.04475) avg lploss: 0.00000
train epoch 1913 avg loss: 0.05006 (A-MSE: 0.04471) avg lploss: 0.00000
train epoch 1914 avg loss: 0.05434 (A-MSE: 0.04783) avg lploss: 0.00000
train epoch 1915 avg loss: 0.04830 (A-MSE: 0.04324) avg lploss: 0.00000
==> val epoch 1915 avg loss: 0.36025 (A-MSE: 0.31969) avg lploss: 0.00000
==> test epoch 1915 avg loss: 0.44407 (A-MSE: 0.39398) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 49 out of 50
train epoch 1916 avg loss: 0.04290 (A-MSE: 0.03811) avg lploss: 0.00000
train epoch 1917 avg loss: 0.04463 (A-MSE: 0.03950) avg lploss: 0.00000
train epoch 1918 avg loss: 0.04866 (A-MSE: 0.04358) avg lploss: 0.00000
train epoch 1919 avg loss: 0.05901 (A-MSE: 0.05297) avg lploss: 0.00000
train epoch 1920 avg loss: 0.05422 (A-MSE: 0.04817) avg lploss: 0.00000
==> val epoch 1920 avg loss: 0.39406 (A-MSE: 0.34362) avg lploss: 0.00000
==> test epoch 1920 avg loss: 0.48706 (A-MSE: 0.43054) avg lploss: 0.00000
*** Best Val Loss: 0.32859 	 Best Test Loss: 0.39197 	 Best epoch 1670
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.057217
best_lp = 0.000000
best_val = 0.328591
best_test = 0.391972
best_epoch = 1670
best_train = 0.057217, best_lp = 0.000000, best_val = 0.328591, best_test = 0.391972, best_epoch = 1670
Training completed for seed 3 with num_modes=2
