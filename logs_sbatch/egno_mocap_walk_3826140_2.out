Date              = Sat Dec  6 08:06:12 CET 2025
Hostname          = mel2099
Array Task ID     = 2
Running config: configs/mocap_walk_seed3.json
Namespace(batch_size=12, case='walk', config_by_file='configs/mocap_walk_seed3.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_walk_seed3', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/mocap', pooling_layer=3, seed=3, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 198 samples!
Got Split!
Got 600 samples!
Got Split!
Got 600 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/mocap/mocap_walk_seed3/saved_model.pth
train epoch 0 avg loss: 13.95817 (A-MSE: 12.47357) avg lploss: 0.00000
==> val epoch 0 avg loss: 12.96649 (A-MSE: 11.43375) avg lploss: 0.00000
==> test epoch 0 avg loss: 12.99583 (A-MSE: 11.46942) avg lploss: 0.00000
*** Best Val Loss: 12.96649 	 Best Test Loss: 12.99583 	 Best epoch 0
Validation loss decreased (inf --> 12.966490).  Saving model ...
train epoch 1 avg loss: 11.26886 (A-MSE: 9.92465) avg lploss: 0.00000
train epoch 2 avg loss: 9.33851 (A-MSE: 8.13153) avg lploss: 0.00000
train epoch 3 avg loss: 437.38969 (A-MSE: 770.29061) avg lploss: 0.00000
train epoch 4 avg loss: 8.35246 (A-MSE: 7.26068) avg lploss: 0.00000
train epoch 5 avg loss: 8.28826 (A-MSE: 7.22158) avg lploss: 0.00000
==> val epoch 5 avg loss: 8.58371 (A-MSE: 7.46402) avg lploss: 0.00000
==> test epoch 5 avg loss: 8.55455 (A-MSE: 7.44479) avg lploss: 0.00000
*** Best Val Loss: 8.58371 	 Best Test Loss: 8.55455 	 Best epoch 5
Validation loss decreased (12.966490 --> 8.583710).  Saving model ...
train epoch 6 avg loss: 8.08188 (A-MSE: 7.04381) avg lploss: 0.00000
train epoch 7 avg loss: 7.83169 (A-MSE: 6.81046) avg lploss: 0.00000
train epoch 8 avg loss: 7.50721 (A-MSE: 6.51202) avg lploss: 0.00000
train epoch 9 avg loss: 6.89502 (A-MSE: 5.96025) avg lploss: 0.00000
train epoch 10 avg loss: 6.38189 (A-MSE: 5.51453) avg lploss: 0.00000
==> val epoch 10 avg loss: 7.09747 (A-MSE: 6.08671) avg lploss: 0.00000
==> test epoch 10 avg loss: 6.97462 (A-MSE: 5.98574) avg lploss: 0.00000
*** Best Val Loss: 7.09747 	 Best Test Loss: 6.97462 	 Best epoch 10
Validation loss decreased (8.583710 --> 7.097472).  Saving model ...
train epoch 11 avg loss: 5.95306 (A-MSE: 5.12818) avg lploss: 0.00000
train epoch 12 avg loss: 5.25223 (A-MSE: 4.52420) avg lploss: 0.00000
train epoch 13 avg loss: 4.52170 (A-MSE: 3.88697) avg lploss: 0.00000
train epoch 14 avg loss: 3.97892 (A-MSE: 3.42314) avg lploss: 0.00000
train epoch 15 avg loss: 3.52930 (A-MSE: 3.02322) avg lploss: 0.00000
==> val epoch 15 avg loss: 3.62586 (A-MSE: 3.06994) avg lploss: 0.00000
==> test epoch 15 avg loss: 3.48231 (A-MSE: 2.93995) avg lploss: 0.00000
*** Best Val Loss: 3.62586 	 Best Test Loss: 3.48231 	 Best epoch 15
Validation loss decreased (7.097472 --> 3.625865).  Saving model ...
train epoch 16 avg loss: 3.11032 (A-MSE: 2.65965) avg lploss: 0.00000
train epoch 17 avg loss: 2.82216 (A-MSE: 2.41245) avg lploss: 0.00000
train epoch 18 avg loss: 2.72024 (A-MSE: 2.32432) avg lploss: 0.00000
train epoch 19 avg loss: 2.56420 (A-MSE: 2.19176) avg lploss: 0.00000
train epoch 20 avg loss: 2.41012 (A-MSE: 2.05743) avg lploss: 0.00000
==> val epoch 20 avg loss: 2.72660 (A-MSE: 2.27557) avg lploss: 0.00000
==> test epoch 20 avg loss: 2.59469 (A-MSE: 2.15416) avg lploss: 0.00000
*** Best Val Loss: 2.72660 	 Best Test Loss: 2.59469 	 Best epoch 20
Validation loss decreased (3.625865 --> 2.726603).  Saving model ...
train epoch 21 avg loss: 2.42877 (A-MSE: 2.07007) avg lploss: 0.00000
train epoch 22 avg loss: 2.32252 (A-MSE: 1.98678) avg lploss: 0.00000
train epoch 23 avg loss: 2.25162 (A-MSE: 1.92026) avg lploss: 0.00000
train epoch 24 avg loss: 2.25330 (A-MSE: 1.93560) avg lploss: 0.00000
train epoch 25 avg loss: 2.21815 (A-MSE: 1.89579) avg lploss: 0.00000
==> val epoch 25 avg loss: 2.84228 (A-MSE: 2.37535) avg lploss: 0.00000
==> test epoch 25 avg loss: 2.76018 (A-MSE: 2.30334) avg lploss: 0.00000
*** Best Val Loss: 2.72660 	 Best Test Loss: 2.59469 	 Best epoch 20
EarlyStopping counter: 1 out of 50
train epoch 26 avg loss: 2.21026 (A-MSE: 1.88903) avg lploss: 0.00000
train epoch 27 avg loss: 2.02867 (A-MSE: 1.73187) avg lploss: 0.00000
train epoch 28 avg loss: 2.01180 (A-MSE: 1.72562) avg lploss: 0.00000
train epoch 29 avg loss: 2.11663 (A-MSE: 1.80960) avg lploss: 0.00000
train epoch 30 avg loss: 1.95390 (A-MSE: 1.67084) avg lploss: 0.00000
==> val epoch 30 avg loss: 2.14759 (A-MSE: 1.80378) avg lploss: 0.00000
==> test epoch 30 avg loss: 2.01640 (A-MSE: 1.68606) avg lploss: 0.00000
*** Best Val Loss: 2.14759 	 Best Test Loss: 2.01640 	 Best epoch 30
Validation loss decreased (2.726603 --> 2.147590).  Saving model ...
train epoch 31 avg loss: 1.91539 (A-MSE: 1.63807) avg lploss: 0.00000
train epoch 32 avg loss: 1.90633 (A-MSE: 1.63264) avg lploss: 0.00000
train epoch 33 avg loss: 1.86374 (A-MSE: 1.59838) avg lploss: 0.00000
train epoch 34 avg loss: 1.84130 (A-MSE: 1.57216) avg lploss: 0.00000
train epoch 35 avg loss: 1.80429 (A-MSE: 1.54288) avg lploss: 0.00000
==> val epoch 35 avg loss: 1.95651 (A-MSE: 1.69882) avg lploss: 0.00000
==> test epoch 35 avg loss: 1.79883 (A-MSE: 1.55443) avg lploss: 0.00000
*** Best Val Loss: 1.95651 	 Best Test Loss: 1.79883 	 Best epoch 35
Validation loss decreased (2.147590 --> 1.956508).  Saving model ...
train epoch 36 avg loss: 1.74283 (A-MSE: 1.49166) avg lploss: 0.00000
train epoch 37 avg loss: 1.72770 (A-MSE: 1.47812) avg lploss: 0.00000
train epoch 38 avg loss: 1.69401 (A-MSE: 1.44523) avg lploss: 0.00000
train epoch 39 avg loss: 1.61642 (A-MSE: 1.38211) avg lploss: 0.00000
train epoch 40 avg loss: 1.61120 (A-MSE: 1.37086) avg lploss: 0.00000
==> val epoch 40 avg loss: 1.77972 (A-MSE: 1.48892) avg lploss: 0.00000
==> test epoch 40 avg loss: 1.66064 (A-MSE: 1.38321) avg lploss: 0.00000
*** Best Val Loss: 1.77972 	 Best Test Loss: 1.66064 	 Best epoch 40
Validation loss decreased (1.956508 --> 1.779722).  Saving model ...
train epoch 41 avg loss: 1.57654 (A-MSE: 1.34343) avg lploss: 0.00000
train epoch 42 avg loss: 1.53627 (A-MSE: 1.30977) avg lploss: 0.00000
train epoch 43 avg loss: 1.49067 (A-MSE: 1.26951) avg lploss: 0.00000
train epoch 44 avg loss: 1.52110 (A-MSE: 1.29623) avg lploss: 0.00000
train epoch 45 avg loss: 1.47229 (A-MSE: 1.25935) avg lploss: 0.00000
==> val epoch 45 avg loss: 1.63812 (A-MSE: 1.38597) avg lploss: 0.00000
==> test epoch 45 avg loss: 1.49159 (A-MSE: 1.25491) avg lploss: 0.00000
*** Best Val Loss: 1.63812 	 Best Test Loss: 1.49159 	 Best epoch 45
Validation loss decreased (1.779722 --> 1.638118).  Saving model ...
train epoch 46 avg loss: 1.40057 (A-MSE: 1.19009) avg lploss: 0.00000
train epoch 47 avg loss: 1.41809 (A-MSE: 1.20869) avg lploss: 0.00000
train epoch 48 avg loss: 1.42880 (A-MSE: 1.21922) avg lploss: 0.00000
train epoch 49 avg loss: 1.44617 (A-MSE: 1.23387) avg lploss: 0.00000
train epoch 50 avg loss: 1.35478 (A-MSE: 1.15613) avg lploss: 0.00000
==> val epoch 50 avg loss: 1.56288 (A-MSE: 1.29823) avg lploss: 0.00000
==> test epoch 50 avg loss: 1.43535 (A-MSE: 1.18688) avg lploss: 0.00000
*** Best Val Loss: 1.56288 	 Best Test Loss: 1.43535 	 Best epoch 50
Validation loss decreased (1.638118 --> 1.562884).  Saving model ...
train epoch 51 avg loss: 1.30001 (A-MSE: 1.10640) avg lploss: 0.00000
train epoch 52 avg loss: 1.31001 (A-MSE: 1.11356) avg lploss: 0.00000
train epoch 53 avg loss: 1.28567 (A-MSE: 1.09888) avg lploss: 0.00000
train epoch 54 avg loss: 1.24765 (A-MSE: 1.06789) avg lploss: 0.00000
train epoch 55 avg loss: 1.19830 (A-MSE: 1.02544) avg lploss: 0.00000
==> val epoch 55 avg loss: 1.43235 (A-MSE: 1.19041) avg lploss: 0.00000
==> test epoch 55 avg loss: 1.32809 (A-MSE: 1.10110) avg lploss: 0.00000
*** Best Val Loss: 1.43235 	 Best Test Loss: 1.32809 	 Best epoch 55
Validation loss decreased (1.562884 --> 1.432346).  Saving model ...
train epoch 56 avg loss: 1.27315 (A-MSE: 1.08494) avg lploss: 0.00000
train epoch 57 avg loss: 1.19834 (A-MSE: 1.02864) avg lploss: 0.00000
train epoch 58 avg loss: 1.14791 (A-MSE: 0.98118) avg lploss: 0.00000
train epoch 59 avg loss: 1.07167 (A-MSE: 0.91811) avg lploss: 0.00000
train epoch 60 avg loss: 1.07506 (A-MSE: 0.91927) avg lploss: 0.00000
==> val epoch 60 avg loss: 1.20013 (A-MSE: 1.05463) avg lploss: 0.00000
==> test epoch 60 avg loss: 1.10290 (A-MSE: 0.97046) avg lploss: 0.00000
*** Best Val Loss: 1.20013 	 Best Test Loss: 1.10290 	 Best epoch 60
Validation loss decreased (1.432346 --> 1.200132).  Saving model ...
train epoch 61 avg loss: 1.01696 (A-MSE: 0.87623) avg lploss: 0.00000
train epoch 62 avg loss: 0.99090 (A-MSE: 0.84850) avg lploss: 0.00000
train epoch 63 avg loss: 1.00209 (A-MSE: 0.85906) avg lploss: 0.00000
train epoch 64 avg loss: 1.00810 (A-MSE: 0.86657) avg lploss: 0.00000
train epoch 65 avg loss: 1.14148 (A-MSE: 0.98073) avg lploss: 0.00000
==> val epoch 65 avg loss: 1.29519 (A-MSE: 1.10495) avg lploss: 0.00000
==> test epoch 65 avg loss: 1.18009 (A-MSE: 1.00219) avg lploss: 0.00000
*** Best Val Loss: 1.20013 	 Best Test Loss: 1.10290 	 Best epoch 60
EarlyStopping counter: 1 out of 50
train epoch 66 avg loss: 1.01856 (A-MSE: 0.87542) avg lploss: 0.00000
train epoch 67 avg loss: 0.97427 (A-MSE: 0.83915) avg lploss: 0.00000
train epoch 68 avg loss: 0.89764 (A-MSE: 0.76847) avg lploss: 0.00000
train epoch 69 avg loss: 0.92757 (A-MSE: 0.79918) avg lploss: 0.00000
train epoch 70 avg loss: 0.89302 (A-MSE: 0.76434) avg lploss: 0.00000
==> val epoch 70 avg loss: 1.01018 (A-MSE: 0.84894) avg lploss: 0.00000
==> test epoch 70 avg loss: 0.93855 (A-MSE: 0.78821) avg lploss: 0.00000
*** Best Val Loss: 1.01018 	 Best Test Loss: 0.93855 	 Best epoch 70
Validation loss decreased (1.200132 --> 1.010184).  Saving model ...
train epoch 71 avg loss: 0.94182 (A-MSE: 0.81080) avg lploss: 0.00000
train epoch 72 avg loss: 0.87633 (A-MSE: 0.74987) avg lploss: 0.00000
train epoch 73 avg loss: 0.87218 (A-MSE: 0.75282) avg lploss: 0.00000
train epoch 74 avg loss: 0.87571 (A-MSE: 0.75001) avg lploss: 0.00000
train epoch 75 avg loss: 0.80565 (A-MSE: 0.69157) avg lploss: 0.00000
==> val epoch 75 avg loss: 0.96992 (A-MSE: 0.81091) avg lploss: 0.00000
==> test epoch 75 avg loss: 0.87288 (A-MSE: 0.72513) avg lploss: 0.00000
*** Best Val Loss: 0.96992 	 Best Test Loss: 0.87288 	 Best epoch 75
Validation loss decreased (1.010184 --> 0.969924).  Saving model ...
train epoch 76 avg loss: 0.80803 (A-MSE: 0.69198) avg lploss: 0.00000
train epoch 77 avg loss: 0.78821 (A-MSE: 0.67953) avg lploss: 0.00000
train epoch 78 avg loss: 0.79626 (A-MSE: 0.68206) avg lploss: 0.00000
train epoch 79 avg loss: 0.78475 (A-MSE: 0.68025) avg lploss: 0.00000
train epoch 80 avg loss: 0.76145 (A-MSE: 0.65258) avg lploss: 0.00000
==> val epoch 80 avg loss: 0.89878 (A-MSE: 0.77346) avg lploss: 0.00000
==> test epoch 80 avg loss: 0.80652 (A-MSE: 0.69206) avg lploss: 0.00000
*** Best Val Loss: 0.89878 	 Best Test Loss: 0.80652 	 Best epoch 80
Validation loss decreased (0.969924 --> 0.898781).  Saving model ...
train epoch 81 avg loss: 0.75521 (A-MSE: 0.64965) avg lploss: 0.00000
train epoch 82 avg loss: 0.79573 (A-MSE: 0.68484) avg lploss: 0.00000
train epoch 83 avg loss: 0.82968 (A-MSE: 0.71438) avg lploss: 0.00000
train epoch 84 avg loss: 0.70517 (A-MSE: 0.60697) avg lploss: 0.00000
train epoch 85 avg loss: 0.70207 (A-MSE: 0.60688) avg lploss: 0.00000
==> val epoch 85 avg loss: 0.86387 (A-MSE: 0.73361) avg lploss: 0.00000
==> test epoch 85 avg loss: 0.76400 (A-MSE: 0.64563) avg lploss: 0.00000
*** Best Val Loss: 0.86387 	 Best Test Loss: 0.76400 	 Best epoch 85
Validation loss decreased (0.898781 --> 0.863867).  Saving model ...
train epoch 86 avg loss: 0.69560 (A-MSE: 0.60059) avg lploss: 0.00000
train epoch 87 avg loss: 0.73288 (A-MSE: 0.63254) avg lploss: 0.00000
train epoch 88 avg loss: 0.71323 (A-MSE: 0.61207) avg lploss: 0.00000
train epoch 89 avg loss: 0.69179 (A-MSE: 0.59839) avg lploss: 0.00000
train epoch 90 avg loss: 0.66476 (A-MSE: 0.57595) avg lploss: 0.00000
==> val epoch 90 avg loss: 0.91156 (A-MSE: 0.75839) avg lploss: 0.00000
==> test epoch 90 avg loss: 0.81353 (A-MSE: 0.67194) avg lploss: 0.00000
*** Best Val Loss: 0.86387 	 Best Test Loss: 0.76400 	 Best epoch 85
EarlyStopping counter: 1 out of 50
train epoch 91 avg loss: 0.68148 (A-MSE: 0.58811) avg lploss: 0.00000
train epoch 92 avg loss: 0.64590 (A-MSE: 0.55844) avg lploss: 0.00000
train epoch 93 avg loss: 0.81362 (A-MSE: 0.70363) avg lploss: 0.00000
train epoch 94 avg loss: 0.68366 (A-MSE: 0.58923) avg lploss: 0.00000
train epoch 95 avg loss: 0.63034 (A-MSE: 0.54498) avg lploss: 0.00000
==> val epoch 95 avg loss: 0.78150 (A-MSE: 0.65296) avg lploss: 0.00000
==> test epoch 95 avg loss: 0.71994 (A-MSE: 0.60106) avg lploss: 0.00000
*** Best Val Loss: 0.78150 	 Best Test Loss: 0.71994 	 Best epoch 95
Validation loss decreased (0.863867 --> 0.781502).  Saving model ...
train epoch 96 avg loss: 0.65448 (A-MSE: 0.56506) avg lploss: 0.00000
train epoch 97 avg loss: 0.65064 (A-MSE: 0.56332) avg lploss: 0.00000
train epoch 98 avg loss: 0.62689 (A-MSE: 0.54235) avg lploss: 0.00000
train epoch 99 avg loss: 0.65184 (A-MSE: 0.56488) avg lploss: 0.00000
train epoch 100 avg loss: 0.60946 (A-MSE: 0.52892) avg lploss: 0.00000
==> val epoch 100 avg loss: 0.73294 (A-MSE: 0.61684) avg lploss: 0.00000
==> test epoch 100 avg loss: 0.66813 (A-MSE: 0.56195) avg lploss: 0.00000
*** Best Val Loss: 0.73294 	 Best Test Loss: 0.66813 	 Best epoch 100
Validation loss decreased (0.781502 --> 0.732943).  Saving model ...
train epoch 101 avg loss: 0.65092 (A-MSE: 0.56509) avg lploss: 0.00000
train epoch 102 avg loss: 0.65007 (A-MSE: 0.56414) avg lploss: 0.00000
train epoch 103 avg loss: 0.61735 (A-MSE: 0.53413) avg lploss: 0.00000
train epoch 104 avg loss: 0.62759 (A-MSE: 0.54666) avg lploss: 0.00000
train epoch 105 avg loss: 0.59890 (A-MSE: 0.51894) avg lploss: 0.00000
==> val epoch 105 avg loss: 0.74862 (A-MSE: 0.63379) avg lploss: 0.00000
==> test epoch 105 avg loss: 0.68640 (A-MSE: 0.58070) avg lploss: 0.00000
*** Best Val Loss: 0.73294 	 Best Test Loss: 0.66813 	 Best epoch 100
EarlyStopping counter: 1 out of 50
train epoch 106 avg loss: 0.59984 (A-MSE: 0.51768) avg lploss: 0.00000
train epoch 107 avg loss: 0.58819 (A-MSE: 0.51089) avg lploss: 0.00000
train epoch 108 avg loss: 0.57769 (A-MSE: 0.50257) avg lploss: 0.00000
train epoch 109 avg loss: 0.61872 (A-MSE: 0.53820) avg lploss: 0.00000
train epoch 110 avg loss: 0.60617 (A-MSE: 0.52417) avg lploss: 0.00000
==> val epoch 110 avg loss: 0.91075 (A-MSE: 0.76432) avg lploss: 0.00000
==> test epoch 110 avg loss: 0.82102 (A-MSE: 0.68669) avg lploss: 0.00000
*** Best Val Loss: 0.73294 	 Best Test Loss: 0.66813 	 Best epoch 100
EarlyStopping counter: 2 out of 50
train epoch 111 avg loss: 0.64265 (A-MSE: 0.55822) avg lploss: 0.00000
train epoch 112 avg loss: 0.59402 (A-MSE: 0.51400) avg lploss: 0.00000
train epoch 113 avg loss: 0.62913 (A-MSE: 0.54602) avg lploss: 0.00000
train epoch 114 avg loss: 0.56289 (A-MSE: 0.48957) avg lploss: 0.00000
train epoch 115 avg loss: 0.56805 (A-MSE: 0.49550) avg lploss: 0.00000
==> val epoch 115 avg loss: 0.80938 (A-MSE: 0.68878) avg lploss: 0.00000
==> test epoch 115 avg loss: 0.71024 (A-MSE: 0.60233) avg lploss: 0.00000
*** Best Val Loss: 0.73294 	 Best Test Loss: 0.66813 	 Best epoch 100
EarlyStopping counter: 3 out of 50
train epoch 116 avg loss: 0.58894 (A-MSE: 0.51183) avg lploss: 0.00000
train epoch 117 avg loss: 0.54419 (A-MSE: 0.47319) avg lploss: 0.00000
train epoch 118 avg loss: 0.53787 (A-MSE: 0.46896) avg lploss: 0.00000
train epoch 119 avg loss: 0.60484 (A-MSE: 0.52354) avg lploss: 0.00000
train epoch 120 avg loss: 0.53034 (A-MSE: 0.46329) avg lploss: 0.00000
==> val epoch 120 avg loss: 0.62406 (A-MSE: 0.52874) avg lploss: 0.00000
==> test epoch 120 avg loss: 0.56817 (A-MSE: 0.48189) avg lploss: 0.00000
*** Best Val Loss: 0.62406 	 Best Test Loss: 0.56817 	 Best epoch 120
Validation loss decreased (0.732943 --> 0.624057).  Saving model ...
train epoch 121 avg loss: 0.52788 (A-MSE: 0.46004) avg lploss: 0.00000
train epoch 122 avg loss: 0.63545 (A-MSE: 0.55159) avg lploss: 0.00000
train epoch 123 avg loss: 0.58906 (A-MSE: 0.51266) avg lploss: 0.00000
train epoch 124 avg loss: 0.52866 (A-MSE: 0.46058) avg lploss: 0.00000
train epoch 125 avg loss: 0.54693 (A-MSE: 0.47566) avg lploss: 0.00000
==> val epoch 125 avg loss: 0.69037 (A-MSE: 0.59072) avg lploss: 0.00000
==> test epoch 125 avg loss: 0.64669 (A-MSE: 0.55422) avg lploss: 0.00000
*** Best Val Loss: 0.62406 	 Best Test Loss: 0.56817 	 Best epoch 120
EarlyStopping counter: 1 out of 50
train epoch 126 avg loss: 0.56347 (A-MSE: 0.49084) avg lploss: 0.00000
train epoch 127 avg loss: 0.51778 (A-MSE: 0.45252) avg lploss: 0.00000
train epoch 128 avg loss: 0.57286 (A-MSE: 0.50181) avg lploss: 0.00000
train epoch 129 avg loss: 0.54959 (A-MSE: 0.47882) avg lploss: 0.00000
train epoch 130 avg loss: 0.49112 (A-MSE: 0.42924) avg lploss: 0.00000
==> val epoch 130 avg loss: 0.57737 (A-MSE: 0.49541) avg lploss: 0.00000
==> test epoch 130 avg loss: 0.50641 (A-MSE: 0.43541) avg lploss: 0.00000
*** Best Val Loss: 0.57737 	 Best Test Loss: 0.50641 	 Best epoch 130
Validation loss decreased (0.624057 --> 0.577367).  Saving model ...
train epoch 131 avg loss: 0.47213 (A-MSE: 0.41260) avg lploss: 0.00000
train epoch 132 avg loss: 0.50284 (A-MSE: 0.43887) avg lploss: 0.00000
train epoch 133 avg loss: 0.51520 (A-MSE: 0.45031) avg lploss: 0.00000
train epoch 134 avg loss: 0.49519 (A-MSE: 0.43236) avg lploss: 0.00000
train epoch 135 avg loss: 0.52995 (A-MSE: 0.46102) avg lploss: 0.00000
==> val epoch 135 avg loss: 0.62168 (A-MSE: 0.52384) avg lploss: 0.00000
==> test epoch 135 avg loss: 0.56459 (A-MSE: 0.47515) avg lploss: 0.00000
*** Best Val Loss: 0.57737 	 Best Test Loss: 0.50641 	 Best epoch 130
EarlyStopping counter: 1 out of 50
train epoch 136 avg loss: 0.47377 (A-MSE: 0.41239) avg lploss: 0.00000
train epoch 137 avg loss: 0.46522 (A-MSE: 0.40764) avg lploss: 0.00000
train epoch 138 avg loss: 0.47446 (A-MSE: 0.41308) avg lploss: 0.00000
train epoch 139 avg loss: 0.52377 (A-MSE: 0.45791) avg lploss: 0.00000
train epoch 140 avg loss: 0.54538 (A-MSE: 0.47531) avg lploss: 0.00000
==> val epoch 140 avg loss: 0.61053 (A-MSE: 0.51404) avg lploss: 0.00000
==> test epoch 140 avg loss: 0.56329 (A-MSE: 0.47443) avg lploss: 0.00000
*** Best Val Loss: 0.57737 	 Best Test Loss: 0.50641 	 Best epoch 130
EarlyStopping counter: 2 out of 50
train epoch 141 avg loss: 0.47736 (A-MSE: 0.41621) avg lploss: 0.00000
train epoch 142 avg loss: 0.51414 (A-MSE: 0.45029) avg lploss: 0.00000
train epoch 143 avg loss: 0.53402 (A-MSE: 0.46537) avg lploss: 0.00000
train epoch 144 avg loss: 0.50107 (A-MSE: 0.43696) avg lploss: 0.00000
train epoch 145 avg loss: 0.44519 (A-MSE: 0.38821) avg lploss: 0.00000
==> val epoch 145 avg loss: 0.54988 (A-MSE: 0.46380) avg lploss: 0.00000
==> test epoch 145 avg loss: 0.48720 (A-MSE: 0.41074) avg lploss: 0.00000
*** Best Val Loss: 0.54988 	 Best Test Loss: 0.48720 	 Best epoch 145
Validation loss decreased (0.577367 --> 0.549882).  Saving model ...
train epoch 146 avg loss: 0.48558 (A-MSE: 0.42409) avg lploss: 0.00000
train epoch 147 avg loss: 0.46567 (A-MSE: 0.40570) avg lploss: 0.00000
train epoch 148 avg loss: 0.45214 (A-MSE: 0.39516) avg lploss: 0.00000
train epoch 149 avg loss: 0.50384 (A-MSE: 0.43900) avg lploss: 0.00000
train epoch 150 avg loss: 0.49343 (A-MSE: 0.43022) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.58722 (A-MSE: 0.49603) avg lploss: 0.00000
==> test epoch 150 avg loss: 0.51654 (A-MSE: 0.43567) avg lploss: 0.00000
*** Best Val Loss: 0.54988 	 Best Test Loss: 0.48720 	 Best epoch 145
EarlyStopping counter: 1 out of 50
train epoch 151 avg loss: 0.54134 (A-MSE: 0.47332) avg lploss: 0.00000
train epoch 152 avg loss: 0.46326 (A-MSE: 0.40376) avg lploss: 0.00000
train epoch 153 avg loss: 0.46898 (A-MSE: 0.40895) avg lploss: 0.00000
train epoch 154 avg loss: 0.46319 (A-MSE: 0.40361) avg lploss: 0.00000
train epoch 155 avg loss: 0.48143 (A-MSE: 0.42070) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.58799 (A-MSE: 0.49813) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.51478 (A-MSE: 0.43602) avg lploss: 0.00000
*** Best Val Loss: 0.54988 	 Best Test Loss: 0.48720 	 Best epoch 145
EarlyStopping counter: 2 out of 50
train epoch 156 avg loss: 0.50806 (A-MSE: 0.44319) avg lploss: 0.00000
train epoch 157 avg loss: 0.53807 (A-MSE: 0.46500) avg lploss: 0.00000
train epoch 158 avg loss: 0.48214 (A-MSE: 0.42302) avg lploss: 0.00000
train epoch 159 avg loss: 0.43114 (A-MSE: 0.37702) avg lploss: 0.00000
train epoch 160 avg loss: 0.42173 (A-MSE: 0.36844) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.56207 (A-MSE: 0.47289) avg lploss: 0.00000
==> test epoch 160 avg loss: 0.49238 (A-MSE: 0.41465) avg lploss: 0.00000
*** Best Val Loss: 0.54988 	 Best Test Loss: 0.48720 	 Best epoch 145
EarlyStopping counter: 3 out of 50
train epoch 161 avg loss: 0.45749 (A-MSE: 0.39972) avg lploss: 0.00000
train epoch 162 avg loss: 0.46117 (A-MSE: 0.40316) avg lploss: 0.00000
train epoch 163 avg loss: 0.43655 (A-MSE: 0.38171) avg lploss: 0.00000
train epoch 164 avg loss: 0.41318 (A-MSE: 0.36212) avg lploss: 0.00000
train epoch 165 avg loss: 0.40878 (A-MSE: 0.35742) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.52694 (A-MSE: 0.45580) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.45328 (A-MSE: 0.39135) avg lploss: 0.00000
*** Best Val Loss: 0.52694 	 Best Test Loss: 0.45328 	 Best epoch 165
Validation loss decreased (0.549882 --> 0.526935).  Saving model ...
train epoch 166 avg loss: 0.44131 (A-MSE: 0.38403) avg lploss: 0.00000
train epoch 167 avg loss: 0.42297 (A-MSE: 0.36962) avg lploss: 0.00000
train epoch 168 avg loss: 0.42574 (A-MSE: 0.37236) avg lploss: 0.00000
train epoch 169 avg loss: 0.55547 (A-MSE: 0.48583) avg lploss: 0.00000
train epoch 170 avg loss: 0.46112 (A-MSE: 0.40013) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.54853 (A-MSE: 0.47134) avg lploss: 0.00000
==> test epoch 170 avg loss: 0.47417 (A-MSE: 0.40849) avg lploss: 0.00000
*** Best Val Loss: 0.52694 	 Best Test Loss: 0.45328 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 0.46783 (A-MSE: 0.40959) avg lploss: 0.00000
train epoch 172 avg loss: 0.43842 (A-MSE: 0.38289) avg lploss: 0.00000
train epoch 173 avg loss: 0.41884 (A-MSE: 0.36494) avg lploss: 0.00000
train epoch 174 avg loss: 0.40537 (A-MSE: 0.35404) avg lploss: 0.00000
train epoch 175 avg loss: 0.47249 (A-MSE: 0.41358) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.55219 (A-MSE: 0.47065) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.48993 (A-MSE: 0.41900) avg lploss: 0.00000
*** Best Val Loss: 0.52694 	 Best Test Loss: 0.45328 	 Best epoch 165
EarlyStopping counter: 2 out of 50
train epoch 176 avg loss: 0.43579 (A-MSE: 0.37951) avg lploss: 0.00000
train epoch 177 avg loss: 0.40465 (A-MSE: 0.35390) avg lploss: 0.00000
train epoch 178 avg loss: 0.43228 (A-MSE: 0.37616) avg lploss: 0.00000
train epoch 179 avg loss: 0.45616 (A-MSE: 0.39726) avg lploss: 0.00000
train epoch 180 avg loss: 0.39308 (A-MSE: 0.34400) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.45611 (A-MSE: 0.39248) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.40950 (A-MSE: 0.35313) avg lploss: 0.00000
*** Best Val Loss: 0.45611 	 Best Test Loss: 0.40950 	 Best epoch 180
Validation loss decreased (0.526935 --> 0.456112).  Saving model ...
train epoch 181 avg loss: 0.38901 (A-MSE: 0.33965) avg lploss: 0.00000
train epoch 182 avg loss: 0.40955 (A-MSE: 0.35888) avg lploss: 0.00000
train epoch 183 avg loss: 0.39022 (A-MSE: 0.34153) avg lploss: 0.00000
train epoch 184 avg loss: 0.42583 (A-MSE: 0.37122) avg lploss: 0.00000
train epoch 185 avg loss: 0.39038 (A-MSE: 0.34122) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.43225 (A-MSE: 0.37039) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.39112 (A-MSE: 0.33557) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
Validation loss decreased (0.456112 --> 0.432252).  Saving model ...
train epoch 186 avg loss: 0.67117 (A-MSE: 0.58497) avg lploss: 0.00000
train epoch 187 avg loss: 0.58405 (A-MSE: 0.50764) avg lploss: 0.00000
train epoch 188 avg loss: 0.48609 (A-MSE: 0.42243) avg lploss: 0.00000
train epoch 189 avg loss: 0.41786 (A-MSE: 0.36657) avg lploss: 0.00000
train epoch 190 avg loss: 0.38869 (A-MSE: 0.34019) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.51938 (A-MSE: 0.44358) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.43723 (A-MSE: 0.37366) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 1 out of 50
train epoch 191 avg loss: 0.38832 (A-MSE: 0.34030) avg lploss: 0.00000
train epoch 192 avg loss: 0.44891 (A-MSE: 0.39198) avg lploss: 0.00000
train epoch 193 avg loss: 0.39174 (A-MSE: 0.34050) avg lploss: 0.00000
train epoch 194 avg loss: 0.41175 (A-MSE: 0.36083) avg lploss: 0.00000
train epoch 195 avg loss: 0.47759 (A-MSE: 0.41853) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.52091 (A-MSE: 0.44878) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.48250 (A-MSE: 0.41463) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 2 out of 50
train epoch 196 avg loss: 0.40462 (A-MSE: 0.35362) avg lploss: 0.00000
train epoch 197 avg loss: 0.45514 (A-MSE: 0.39850) avg lploss: 0.00000
train epoch 198 avg loss: 0.44592 (A-MSE: 0.38757) avg lploss: 0.00000
train epoch 199 avg loss: 0.38135 (A-MSE: 0.33335) avg lploss: 0.00000
train epoch 200 avg loss: 0.38369 (A-MSE: 0.33554) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.45557 (A-MSE: 0.38753) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.40001 (A-MSE: 0.34038) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 3 out of 50
train epoch 201 avg loss: 0.38253 (A-MSE: 0.33522) avg lploss: 0.00000
train epoch 202 avg loss: 0.40370 (A-MSE: 0.35201) avg lploss: 0.00000
train epoch 203 avg loss: 0.37394 (A-MSE: 0.32517) avg lploss: 0.00000
train epoch 204 avg loss: 0.35154 (A-MSE: 0.30740) avg lploss: 0.00000
train epoch 205 avg loss: 0.42078 (A-MSE: 0.36771) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.50157 (A-MSE: 0.43274) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.48865 (A-MSE: 0.42096) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 4 out of 50
train epoch 206 avg loss: 0.43267 (A-MSE: 0.37769) avg lploss: 0.00000
train epoch 207 avg loss: 0.41647 (A-MSE: 0.35884) avg lploss: 0.00000
train epoch 208 avg loss: 0.36955 (A-MSE: 0.32262) avg lploss: 0.00000
train epoch 209 avg loss: 0.44589 (A-MSE: 0.38756) avg lploss: 0.00000
train epoch 210 avg loss: 0.43821 (A-MSE: 0.38139) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.43605 (A-MSE: 0.37809) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.37676 (A-MSE: 0.32754) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 5 out of 50
train epoch 211 avg loss: 0.37826 (A-MSE: 0.32970) avg lploss: 0.00000
train epoch 212 avg loss: 0.42173 (A-MSE: 0.36721) avg lploss: 0.00000
train epoch 213 avg loss: 0.40656 (A-MSE: 0.35464) avg lploss: 0.00000
train epoch 214 avg loss: 0.39040 (A-MSE: 0.33989) avg lploss: 0.00000
train epoch 215 avg loss: 0.41066 (A-MSE: 0.35969) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.46553 (A-MSE: 0.39697) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.43254 (A-MSE: 0.36970) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 6 out of 50
train epoch 216 avg loss: 0.35432 (A-MSE: 0.30954) avg lploss: 0.00000
train epoch 217 avg loss: 0.35561 (A-MSE: 0.31032) avg lploss: 0.00000
train epoch 218 avg loss: 0.36719 (A-MSE: 0.32180) avg lploss: 0.00000
train epoch 219 avg loss: 0.36558 (A-MSE: 0.31943) avg lploss: 0.00000
train epoch 220 avg loss: 0.34703 (A-MSE: 0.30298) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.43778 (A-MSE: 0.37777) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.41185 (A-MSE: 0.35524) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 7 out of 50
train epoch 221 avg loss: 0.35129 (A-MSE: 0.30649) avg lploss: 0.00000
train epoch 222 avg loss: 0.33859 (A-MSE: 0.29661) avg lploss: 0.00000
train epoch 223 avg loss: 0.37818 (A-MSE: 0.33023) avg lploss: 0.00000
train epoch 224 avg loss: 0.37226 (A-MSE: 0.32600) avg lploss: 0.00000
train epoch 225 avg loss: 0.36515 (A-MSE: 0.31897) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.56512 (A-MSE: 0.47955) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.48880 (A-MSE: 0.41562) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 8 out of 50
train epoch 226 avg loss: 0.44037 (A-MSE: 0.38439) avg lploss: 0.00000
train epoch 227 avg loss: 0.37919 (A-MSE: 0.32932) avg lploss: 0.00000
train epoch 228 avg loss: 0.36060 (A-MSE: 0.31627) avg lploss: 0.00000
train epoch 229 avg loss: 0.38030 (A-MSE: 0.33116) avg lploss: 0.00000
train epoch 230 avg loss: 0.36431 (A-MSE: 0.31824) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.57444 (A-MSE: 0.48990) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.48932 (A-MSE: 0.41567) avg lploss: 0.00000
*** Best Val Loss: 0.43225 	 Best Test Loss: 0.39112 	 Best epoch 185
EarlyStopping counter: 9 out of 50
train epoch 231 avg loss: 0.39271 (A-MSE: 0.34173) avg lploss: 0.00000
train epoch 232 avg loss: 0.43236 (A-MSE: 0.37834) avg lploss: 0.00000
train epoch 233 avg loss: 0.38502 (A-MSE: 0.33529) avg lploss: 0.00000
train epoch 234 avg loss: 0.33263 (A-MSE: 0.29040) avg lploss: 0.00000
train epoch 235 avg loss: 0.35151 (A-MSE: 0.30547) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.42021 (A-MSE: 0.36202) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.34893 (A-MSE: 0.30086) avg lploss: 0.00000
*** Best Val Loss: 0.42021 	 Best Test Loss: 0.34893 	 Best epoch 235
Validation loss decreased (0.432252 --> 0.420214).  Saving model ...
train epoch 236 avg loss: 0.35733 (A-MSE: 0.31119) avg lploss: 0.00000
train epoch 237 avg loss: 0.33600 (A-MSE: 0.29240) avg lploss: 0.00000
train epoch 238 avg loss: 0.34541 (A-MSE: 0.30188) avg lploss: 0.00000
train epoch 239 avg loss: 0.36097 (A-MSE: 0.31492) avg lploss: 0.00000
train epoch 240 avg loss: 0.38461 (A-MSE: 0.33630) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.41203 (A-MSE: 0.35366) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.38473 (A-MSE: 0.33035) avg lploss: 0.00000
*** Best Val Loss: 0.41203 	 Best Test Loss: 0.38473 	 Best epoch 240
Validation loss decreased (0.420214 --> 0.412033).  Saving model ...
train epoch 241 avg loss: 0.37141 (A-MSE: 0.32177) avg lploss: 0.00000
train epoch 242 avg loss: 0.33292 (A-MSE: 0.29031) avg lploss: 0.00000
train epoch 243 avg loss: 0.33768 (A-MSE: 0.29534) avg lploss: 0.00000
train epoch 244 avg loss: 0.34328 (A-MSE: 0.29888) avg lploss: 0.00000
train epoch 245 avg loss: 0.29918 (A-MSE: 0.26096) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.37713 (A-MSE: 0.32428) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.31143 (A-MSE: 0.26788) avg lploss: 0.00000
*** Best Val Loss: 0.37713 	 Best Test Loss: 0.31143 	 Best epoch 245
Validation loss decreased (0.412033 --> 0.377133).  Saving model ...
train epoch 246 avg loss: 0.31271 (A-MSE: 0.27002) avg lploss: 0.00000
train epoch 247 avg loss: 0.33212 (A-MSE: 0.29037) avg lploss: 0.00000
train epoch 248 avg loss: 0.31146 (A-MSE: 0.27214) avg lploss: 0.00000
train epoch 249 avg loss: 0.31628 (A-MSE: 0.27704) avg lploss: 0.00000
train epoch 250 avg loss: 0.30901 (A-MSE: 0.27010) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.43661 (A-MSE: 0.36804) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.35347 (A-MSE: 0.29735) avg lploss: 0.00000
*** Best Val Loss: 0.37713 	 Best Test Loss: 0.31143 	 Best epoch 245
EarlyStopping counter: 1 out of 50
train epoch 251 avg loss: 0.31067 (A-MSE: 0.27025) avg lploss: 0.00000
train epoch 252 avg loss: 0.33055 (A-MSE: 0.28767) avg lploss: 0.00000
train epoch 253 avg loss: 0.33776 (A-MSE: 0.29507) avg lploss: 0.00000
train epoch 254 avg loss: 0.32882 (A-MSE: 0.28480) avg lploss: 0.00000
train epoch 255 avg loss: 0.31124 (A-MSE: 0.27173) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.39972 (A-MSE: 0.34276) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.33075 (A-MSE: 0.28335) avg lploss: 0.00000
*** Best Val Loss: 0.37713 	 Best Test Loss: 0.31143 	 Best epoch 245
EarlyStopping counter: 2 out of 50
train epoch 256 avg loss: 0.29565 (A-MSE: 0.25787) avg lploss: 0.00000
train epoch 257 avg loss: 0.34830 (A-MSE: 0.30163) avg lploss: 0.00000
train epoch 258 avg loss: 0.33272 (A-MSE: 0.29042) avg lploss: 0.00000
train epoch 259 avg loss: 0.36466 (A-MSE: 0.31800) avg lploss: 0.00000
train epoch 260 avg loss: 0.33766 (A-MSE: 0.29481) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.37526 (A-MSE: 0.32033) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.32385 (A-MSE: 0.27620) avg lploss: 0.00000
*** Best Val Loss: 0.37526 	 Best Test Loss: 0.32385 	 Best epoch 260
Validation loss decreased (0.377133 --> 0.375264).  Saving model ...
train epoch 261 avg loss: 0.30385 (A-MSE: 0.26503) avg lploss: 0.00000
train epoch 262 avg loss: 0.32482 (A-MSE: 0.28229) avg lploss: 0.00000
train epoch 263 avg loss: 0.31307 (A-MSE: 0.27143) avg lploss: 0.00000
train epoch 264 avg loss: 0.31341 (A-MSE: 0.27243) avg lploss: 0.00000
train epoch 265 avg loss: 0.27817 (A-MSE: 0.24250) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.34362 (A-MSE: 0.29282) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.29068 (A-MSE: 0.24701) avg lploss: 0.00000
*** Best Val Loss: 0.34362 	 Best Test Loss: 0.29068 	 Best epoch 265
Validation loss decreased (0.375264 --> 0.343622).  Saving model ...
train epoch 266 avg loss: 0.28667 (A-MSE: 0.25052) avg lploss: 0.00000
train epoch 267 avg loss: 0.34482 (A-MSE: 0.30054) avg lploss: 0.00000
train epoch 268 avg loss: 0.29465 (A-MSE: 0.25633) avg lploss: 0.00000
train epoch 269 avg loss: 0.28603 (A-MSE: 0.25045) avg lploss: 0.00000
train epoch 270 avg loss: 0.32249 (A-MSE: 0.28048) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.42789 (A-MSE: 0.36798) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.36182 (A-MSE: 0.31133) avg lploss: 0.00000
*** Best Val Loss: 0.34362 	 Best Test Loss: 0.29068 	 Best epoch 265
EarlyStopping counter: 1 out of 50
train epoch 271 avg loss: 0.32212 (A-MSE: 0.28018) avg lploss: 0.00000
train epoch 272 avg loss: 0.29887 (A-MSE: 0.26082) avg lploss: 0.00000
train epoch 273 avg loss: 0.30852 (A-MSE: 0.26685) avg lploss: 0.00000
train epoch 274 avg loss: 0.33647 (A-MSE: 0.29278) avg lploss: 0.00000
train epoch 275 avg loss: 0.33213 (A-MSE: 0.29077) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.47075 (A-MSE: 0.39794) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.38681 (A-MSE: 0.32661) avg lploss: 0.00000
*** Best Val Loss: 0.34362 	 Best Test Loss: 0.29068 	 Best epoch 265
EarlyStopping counter: 2 out of 50
train epoch 276 avg loss: 0.33409 (A-MSE: 0.28976) avg lploss: 0.00000
train epoch 277 avg loss: 0.31889 (A-MSE: 0.27454) avg lploss: 0.00000
train epoch 278 avg loss: 0.27916 (A-MSE: 0.24482) avg lploss: 0.00000
train epoch 279 avg loss: 0.31611 (A-MSE: 0.27209) avg lploss: 0.00000
train epoch 280 avg loss: 0.28505 (A-MSE: 0.24924) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.38846 (A-MSE: 0.32893) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.31892 (A-MSE: 0.26904) avg lploss: 0.00000
*** Best Val Loss: 0.34362 	 Best Test Loss: 0.29068 	 Best epoch 265
EarlyStopping counter: 3 out of 50
train epoch 281 avg loss: 0.27817 (A-MSE: 0.24137) avg lploss: 0.00000
train epoch 282 avg loss: 0.28466 (A-MSE: 0.24864) avg lploss: 0.00000
train epoch 283 avg loss: 0.32674 (A-MSE: 0.28558) avg lploss: 0.00000
train epoch 284 avg loss: 0.30535 (A-MSE: 0.26636) avg lploss: 0.00000
train epoch 285 avg loss: 0.31774 (A-MSE: 0.27683) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.41820 (A-MSE: 0.35926) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.34943 (A-MSE: 0.29984) avg lploss: 0.00000
*** Best Val Loss: 0.34362 	 Best Test Loss: 0.29068 	 Best epoch 265
EarlyStopping counter: 4 out of 50
train epoch 286 avg loss: 0.29238 (A-MSE: 0.25079) avg lploss: 0.00000
train epoch 287 avg loss: 0.30044 (A-MSE: 0.26243) avg lploss: 0.00000
train epoch 288 avg loss: 0.25680 (A-MSE: 0.22431) avg lploss: 0.00000
train epoch 289 avg loss: 0.29496 (A-MSE: 0.25765) avg lploss: 0.00000
train epoch 290 avg loss: 0.27841 (A-MSE: 0.24328) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.32490 (A-MSE: 0.27724) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.26530 (A-MSE: 0.22627) avg lploss: 0.00000
*** Best Val Loss: 0.32490 	 Best Test Loss: 0.26530 	 Best epoch 290
Validation loss decreased (0.343622 --> 0.324899).  Saving model ...
train epoch 291 avg loss: 0.28450 (A-MSE: 0.24805) avg lploss: 0.00000
train epoch 292 avg loss: 0.26750 (A-MSE: 0.23305) avg lploss: 0.00000
train epoch 293 avg loss: 0.26324 (A-MSE: 0.23033) avg lploss: 0.00000
train epoch 294 avg loss: 0.38836 (A-MSE: 0.34076) avg lploss: 0.00000
train epoch 295 avg loss: 0.29753 (A-MSE: 0.25965) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.36817 (A-MSE: 0.31893) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.30249 (A-MSE: 0.26132) avg lploss: 0.00000
*** Best Val Loss: 0.32490 	 Best Test Loss: 0.26530 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 0.29419 (A-MSE: 0.25533) avg lploss: 0.00000
train epoch 297 avg loss: 0.32027 (A-MSE: 0.27797) avg lploss: 0.00000
train epoch 298 avg loss: 0.32033 (A-MSE: 0.27912) avg lploss: 0.00000
train epoch 299 avg loss: 0.32268 (A-MSE: 0.28064) avg lploss: 0.00000
train epoch 300 avg loss: 0.29721 (A-MSE: 0.25838) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.34757 (A-MSE: 0.29650) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.32591 (A-MSE: 0.27728) avg lploss: 0.00000
*** Best Val Loss: 0.32490 	 Best Test Loss: 0.26530 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 0.28663 (A-MSE: 0.24910) avg lploss: 0.00000
train epoch 302 avg loss: 0.27573 (A-MSE: 0.23959) avg lploss: 0.00000
train epoch 303 avg loss: 0.29744 (A-MSE: 0.25761) avg lploss: 0.00000
train epoch 304 avg loss: 0.27978 (A-MSE: 0.24435) avg lploss: 0.00000
train epoch 305 avg loss: 0.26678 (A-MSE: 0.23297) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.35964 (A-MSE: 0.30737) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.30194 (A-MSE: 0.25826) avg lploss: 0.00000
*** Best Val Loss: 0.32490 	 Best Test Loss: 0.26530 	 Best epoch 290
EarlyStopping counter: 3 out of 50
train epoch 306 avg loss: 0.27224 (A-MSE: 0.23697) avg lploss: 0.00000
train epoch 307 avg loss: 0.27141 (A-MSE: 0.23566) avg lploss: 0.00000
train epoch 308 avg loss: 0.28765 (A-MSE: 0.24894) avg lploss: 0.00000
train epoch 309 avg loss: 0.24125 (A-MSE: 0.21099) avg lploss: 0.00000
train epoch 310 avg loss: 0.27633 (A-MSE: 0.23971) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.29556 (A-MSE: 0.25278) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.25565 (A-MSE: 0.21802) avg lploss: 0.00000
*** Best Val Loss: 0.29556 	 Best Test Loss: 0.25565 	 Best epoch 310
Validation loss decreased (0.324899 --> 0.295559).  Saving model ...
train epoch 311 avg loss: 0.31317 (A-MSE: 0.26755) avg lploss: 0.00000
train epoch 312 avg loss: 0.28237 (A-MSE: 0.24624) avg lploss: 0.00000
train epoch 313 avg loss: 0.26552 (A-MSE: 0.23183) avg lploss: 0.00000
train epoch 314 avg loss: 0.25645 (A-MSE: 0.22402) avg lploss: 0.00000
train epoch 315 avg loss: 0.27522 (A-MSE: 0.23954) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.33291 (A-MSE: 0.28160) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.29467 (A-MSE: 0.24909) avg lploss: 0.00000
*** Best Val Loss: 0.29556 	 Best Test Loss: 0.25565 	 Best epoch 310
EarlyStopping counter: 1 out of 50
train epoch 316 avg loss: 0.29272 (A-MSE: 0.25520) avg lploss: 0.00000
train epoch 317 avg loss: 0.25247 (A-MSE: 0.21941) avg lploss: 0.00000
train epoch 318 avg loss: 0.27566 (A-MSE: 0.23896) avg lploss: 0.00000
train epoch 319 avg loss: 0.27702 (A-MSE: 0.24109) avg lploss: 0.00000
train epoch 320 avg loss: 0.24293 (A-MSE: 0.21149) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.37668 (A-MSE: 0.31295) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.35024 (A-MSE: 0.29173) avg lploss: 0.00000
*** Best Val Loss: 0.29556 	 Best Test Loss: 0.25565 	 Best epoch 310
EarlyStopping counter: 2 out of 50
train epoch 321 avg loss: 0.28117 (A-MSE: 0.24324) avg lploss: 0.00000
train epoch 322 avg loss: 0.26894 (A-MSE: 0.23354) avg lploss: 0.00000
train epoch 323 avg loss: 0.25787 (A-MSE: 0.22500) avg lploss: 0.00000
train epoch 324 avg loss: 0.27455 (A-MSE: 0.23853) avg lploss: 0.00000
train epoch 325 avg loss: 0.24607 (A-MSE: 0.21530) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.28343 (A-MSE: 0.24283) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.25681 (A-MSE: 0.21959) avg lploss: 0.00000
*** Best Val Loss: 0.28343 	 Best Test Loss: 0.25681 	 Best epoch 325
Validation loss decreased (0.295559 --> 0.283429).  Saving model ...
train epoch 326 avg loss: 0.23310 (A-MSE: 0.20294) avg lploss: 0.00000
train epoch 327 avg loss: 0.24362 (A-MSE: 0.21270) avg lploss: 0.00000
train epoch 328 avg loss: 0.27845 (A-MSE: 0.24229) avg lploss: 0.00000
train epoch 329 avg loss: 0.25873 (A-MSE: 0.22537) avg lploss: 0.00000
train epoch 330 avg loss: 0.25041 (A-MSE: 0.21747) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.34047 (A-MSE: 0.28826) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.27684 (A-MSE: 0.23417) avg lploss: 0.00000
*** Best Val Loss: 0.28343 	 Best Test Loss: 0.25681 	 Best epoch 325
EarlyStopping counter: 1 out of 50
train epoch 331 avg loss: 0.25487 (A-MSE: 0.21900) avg lploss: 0.00000
train epoch 332 avg loss: 0.24282 (A-MSE: 0.21153) avg lploss: 0.00000
train epoch 333 avg loss: 0.23269 (A-MSE: 0.20197) avg lploss: 0.00000
train epoch 334 avg loss: 0.24975 (A-MSE: 0.21726) avg lploss: 0.00000
train epoch 335 avg loss: 0.29331 (A-MSE: 0.25178) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.48097 (A-MSE: 0.39813) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.43148 (A-MSE: 0.35814) avg lploss: 0.00000
*** Best Val Loss: 0.28343 	 Best Test Loss: 0.25681 	 Best epoch 325
EarlyStopping counter: 2 out of 50
train epoch 336 avg loss: 0.30242 (A-MSE: 0.26324) avg lploss: 0.00000
train epoch 337 avg loss: 0.24209 (A-MSE: 0.21100) avg lploss: 0.00000
train epoch 338 avg loss: 0.27501 (A-MSE: 0.23878) avg lploss: 0.00000
train epoch 339 avg loss: 0.27689 (A-MSE: 0.24026) avg lploss: 0.00000
train epoch 340 avg loss: 0.25140 (A-MSE: 0.21860) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.27452 (A-MSE: 0.23755) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.23191 (A-MSE: 0.20018) avg lploss: 0.00000
*** Best Val Loss: 0.27452 	 Best Test Loss: 0.23191 	 Best epoch 340
Validation loss decreased (0.283429 --> 0.274518).  Saving model ...
train epoch 341 avg loss: 0.24495 (A-MSE: 0.21353) avg lploss: 0.00000
train epoch 342 avg loss: 0.21610 (A-MSE: 0.18837) avg lploss: 0.00000
train epoch 343 avg loss: 0.24331 (A-MSE: 0.20987) avg lploss: 0.00000
train epoch 344 avg loss: 0.24615 (A-MSE: 0.21472) avg lploss: 0.00000
train epoch 345 avg loss: 0.21369 (A-MSE: 0.18598) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.31505 (A-MSE: 0.26747) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.25702 (A-MSE: 0.21830) avg lploss: 0.00000
*** Best Val Loss: 0.27452 	 Best Test Loss: 0.23191 	 Best epoch 340
EarlyStopping counter: 1 out of 50
train epoch 346 avg loss: 0.22035 (A-MSE: 0.19110) avg lploss: 0.00000
train epoch 347 avg loss: 0.24101 (A-MSE: 0.21007) avg lploss: 0.00000
train epoch 348 avg loss: 0.24597 (A-MSE: 0.21289) avg lploss: 0.00000
train epoch 349 avg loss: 0.22744 (A-MSE: 0.19809) avg lploss: 0.00000
train epoch 350 avg loss: 0.21753 (A-MSE: 0.18877) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.32698 (A-MSE: 0.27764) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.27301 (A-MSE: 0.23081) avg lploss: 0.00000
*** Best Val Loss: 0.27452 	 Best Test Loss: 0.23191 	 Best epoch 340
EarlyStopping counter: 2 out of 50
train epoch 351 avg loss: 0.21334 (A-MSE: 0.18478) avg lploss: 0.00000
train epoch 352 avg loss: 0.22775 (A-MSE: 0.19814) avg lploss: 0.00000
train epoch 353 avg loss: 0.24179 (A-MSE: 0.20989) avg lploss: 0.00000
train epoch 354 avg loss: 0.26313 (A-MSE: 0.22790) avg lploss: 0.00000
train epoch 355 avg loss: 0.23614 (A-MSE: 0.20525) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.27574 (A-MSE: 0.23593) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.23812 (A-MSE: 0.20380) avg lploss: 0.00000
*** Best Val Loss: 0.27452 	 Best Test Loss: 0.23191 	 Best epoch 340
EarlyStopping counter: 3 out of 50
train epoch 356 avg loss: 0.22119 (A-MSE: 0.19179) avg lploss: 0.00000
train epoch 357 avg loss: 0.26454 (A-MSE: 0.22607) avg lploss: 0.00000
train epoch 358 avg loss: 0.25147 (A-MSE: 0.21965) avg lploss: 0.00000
train epoch 359 avg loss: 0.20992 (A-MSE: 0.18225) avg lploss: 0.00000
train epoch 360 avg loss: 0.19490 (A-MSE: 0.16985) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.28296 (A-MSE: 0.24302) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.23575 (A-MSE: 0.20213) avg lploss: 0.00000
*** Best Val Loss: 0.27452 	 Best Test Loss: 0.23191 	 Best epoch 340
EarlyStopping counter: 4 out of 50
train epoch 361 avg loss: 0.21640 (A-MSE: 0.18766) avg lploss: 0.00000
train epoch 362 avg loss: 0.22605 (A-MSE: 0.19599) avg lploss: 0.00000
train epoch 363 avg loss: 0.22426 (A-MSE: 0.19485) avg lploss: 0.00000
train epoch 364 avg loss: 0.22858 (A-MSE: 0.19786) avg lploss: 0.00000
train epoch 365 avg loss: 0.20822 (A-MSE: 0.18021) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.27339 (A-MSE: 0.23087) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.25005 (A-MSE: 0.21177) avg lploss: 0.00000
*** Best Val Loss: 0.27339 	 Best Test Loss: 0.25005 	 Best epoch 365
Validation loss decreased (0.274518 --> 0.273386).  Saving model ...
train epoch 366 avg loss: 0.22125 (A-MSE: 0.19354) avg lploss: 0.00000
train epoch 367 avg loss: 0.22004 (A-MSE: 0.19155) avg lploss: 0.00000
train epoch 368 avg loss: 0.21917 (A-MSE: 0.19031) avg lploss: 0.00000
train epoch 369 avg loss: 0.23070 (A-MSE: 0.20169) avg lploss: 0.00000
train epoch 370 avg loss: 0.32240 (A-MSE: 0.28238) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.30210 (A-MSE: 0.25351) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.26817 (A-MSE: 0.22550) avg lploss: 0.00000
*** Best Val Loss: 0.27339 	 Best Test Loss: 0.25005 	 Best epoch 365
EarlyStopping counter: 1 out of 50
train epoch 371 avg loss: 0.23750 (A-MSE: 0.20490) avg lploss: 0.00000
train epoch 372 avg loss: 0.24125 (A-MSE: 0.21060) avg lploss: 0.00000
train epoch 373 avg loss: 0.23284 (A-MSE: 0.20233) avg lploss: 0.00000
train epoch 374 avg loss: 0.21013 (A-MSE: 0.18181) avg lploss: 0.00000
train epoch 375 avg loss: 0.23786 (A-MSE: 0.20661) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.29233 (A-MSE: 0.25349) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.26203 (A-MSE: 0.22774) avg lploss: 0.00000
*** Best Val Loss: 0.27339 	 Best Test Loss: 0.25005 	 Best epoch 365
EarlyStopping counter: 2 out of 50
train epoch 376 avg loss: 0.22203 (A-MSE: 0.19296) avg lploss: 0.00000
train epoch 377 avg loss: 0.21374 (A-MSE: 0.18651) avg lploss: 0.00000
train epoch 378 avg loss: 0.20785 (A-MSE: 0.18122) avg lploss: 0.00000
train epoch 379 avg loss: 0.20903 (A-MSE: 0.18101) avg lploss: 0.00000
train epoch 380 avg loss: 0.19705 (A-MSE: 0.17241) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.25108 (A-MSE: 0.21477) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.20815 (A-MSE: 0.17735) avg lploss: 0.00000
*** Best Val Loss: 0.25108 	 Best Test Loss: 0.20815 	 Best epoch 380
Validation loss decreased (0.273386 --> 0.251082).  Saving model ...
train epoch 381 avg loss: 0.18683 (A-MSE: 0.16260) avg lploss: 0.00000
train epoch 382 avg loss: 0.19286 (A-MSE: 0.16832) avg lploss: 0.00000
train epoch 383 avg loss: 0.18966 (A-MSE: 0.16432) avg lploss: 0.00000
train epoch 384 avg loss: 0.20703 (A-MSE: 0.17900) avg lploss: 0.00000
train epoch 385 avg loss: 0.23924 (A-MSE: 0.20620) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.26345 (A-MSE: 0.22465) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.22486 (A-MSE: 0.19135) avg lploss: 0.00000
*** Best Val Loss: 0.25108 	 Best Test Loss: 0.20815 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.22130 (A-MSE: 0.19125) avg lploss: 0.00000
train epoch 387 avg loss: 0.24171 (A-MSE: 0.21028) avg lploss: 0.00000
train epoch 388 avg loss: 0.21097 (A-MSE: 0.18332) avg lploss: 0.00000
train epoch 389 avg loss: 0.20417 (A-MSE: 0.17708) avg lploss: 0.00000
train epoch 390 avg loss: 0.20693 (A-MSE: 0.17892) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.26518 (A-MSE: 0.22415) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.23083 (A-MSE: 0.19542) avg lploss: 0.00000
*** Best Val Loss: 0.25108 	 Best Test Loss: 0.20815 	 Best epoch 380
EarlyStopping counter: 2 out of 50
train epoch 391 avg loss: 0.20577 (A-MSE: 0.17831) avg lploss: 0.00000
train epoch 392 avg loss: 0.19308 (A-MSE: 0.16729) avg lploss: 0.00000
train epoch 393 avg loss: 0.18293 (A-MSE: 0.15839) avg lploss: 0.00000
train epoch 394 avg loss: 0.17992 (A-MSE: 0.15574) avg lploss: 0.00000
train epoch 395 avg loss: 0.19986 (A-MSE: 0.17420) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.24736 (A-MSE: 0.21053) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.20151 (A-MSE: 0.17111) avg lploss: 0.00000
*** Best Val Loss: 0.24736 	 Best Test Loss: 0.20151 	 Best epoch 395
Validation loss decreased (0.251082 --> 0.247363).  Saving model ...
train epoch 396 avg loss: 0.18103 (A-MSE: 0.15744) avg lploss: 0.00000
train epoch 397 avg loss: 0.17964 (A-MSE: 0.15564) avg lploss: 0.00000
train epoch 398 avg loss: 0.17385 (A-MSE: 0.15033) avg lploss: 0.00000
train epoch 399 avg loss: 0.24357 (A-MSE: 0.21289) avg lploss: 0.00000
train epoch 400 avg loss: 0.23792 (A-MSE: 0.20722) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.28335 (A-MSE: 0.23957) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.23925 (A-MSE: 0.20250) avg lploss: 0.00000
*** Best Val Loss: 0.24736 	 Best Test Loss: 0.20151 	 Best epoch 395
EarlyStopping counter: 1 out of 50
train epoch 401 avg loss: 0.18602 (A-MSE: 0.16207) avg lploss: 0.00000
train epoch 402 avg loss: 0.18250 (A-MSE: 0.15905) avg lploss: 0.00000
train epoch 403 avg loss: 0.18776 (A-MSE: 0.16310) avg lploss: 0.00000
train epoch 404 avg loss: 0.21122 (A-MSE: 0.18328) avg lploss: 0.00000
train epoch 405 avg loss: 0.19901 (A-MSE: 0.17322) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.28784 (A-MSE: 0.24558) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.24502 (A-MSE: 0.20955) avg lploss: 0.00000
*** Best Val Loss: 0.24736 	 Best Test Loss: 0.20151 	 Best epoch 395
EarlyStopping counter: 2 out of 50
train epoch 406 avg loss: 0.17676 (A-MSE: 0.15377) avg lploss: 0.00000
train epoch 407 avg loss: 0.16842 (A-MSE: 0.14632) avg lploss: 0.00000
train epoch 408 avg loss: 0.18247 (A-MSE: 0.15893) avg lploss: 0.00000
train epoch 409 avg loss: 0.18151 (A-MSE: 0.15839) avg lploss: 0.00000
train epoch 410 avg loss: 0.20556 (A-MSE: 0.17846) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.26856 (A-MSE: 0.22648) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.23138 (A-MSE: 0.19409) avg lploss: 0.00000
*** Best Val Loss: 0.24736 	 Best Test Loss: 0.20151 	 Best epoch 395
EarlyStopping counter: 3 out of 50
train epoch 411 avg loss: 0.20246 (A-MSE: 0.17649) avg lploss: 0.00000
train epoch 412 avg loss: 0.21303 (A-MSE: 0.18621) avg lploss: 0.00000
train epoch 413 avg loss: 0.17558 (A-MSE: 0.15283) avg lploss: 0.00000
train epoch 414 avg loss: 0.23107 (A-MSE: 0.20090) avg lploss: 0.00000
train epoch 415 avg loss: 0.31414 (A-MSE: 0.27241) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.46348 (A-MSE: 0.40267) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.42244 (A-MSE: 0.36686) avg lploss: 0.00000
*** Best Val Loss: 0.24736 	 Best Test Loss: 0.20151 	 Best epoch 395
EarlyStopping counter: 4 out of 50
train epoch 416 avg loss: 0.27855 (A-MSE: 0.24191) avg lploss: 0.00000
train epoch 417 avg loss: 0.23279 (A-MSE: 0.20161) avg lploss: 0.00000
train epoch 418 avg loss: 0.18746 (A-MSE: 0.16268) avg lploss: 0.00000
train epoch 419 avg loss: 0.17944 (A-MSE: 0.15553) avg lploss: 0.00000
train epoch 420 avg loss: 0.17207 (A-MSE: 0.15013) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.24444 (A-MSE: 0.20788) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.21462 (A-MSE: 0.18281) avg lploss: 0.00000
*** Best Val Loss: 0.24444 	 Best Test Loss: 0.21462 	 Best epoch 420
Validation loss decreased (0.247363 --> 0.244435).  Saving model ...
train epoch 421 avg loss: 0.17061 (A-MSE: 0.14787) avg lploss: 0.00000
train epoch 422 avg loss: 0.18737 (A-MSE: 0.16101) avg lploss: 0.00000
train epoch 423 avg loss: 0.19245 (A-MSE: 0.16767) avg lploss: 0.00000
train epoch 424 avg loss: 0.17124 (A-MSE: 0.14824) avg lploss: 0.00000
train epoch 425 avg loss: 0.17198 (A-MSE: 0.15077) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.23961 (A-MSE: 0.20602) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.19457 (A-MSE: 0.16640) avg lploss: 0.00000
*** Best Val Loss: 0.23961 	 Best Test Loss: 0.19457 	 Best epoch 425
Validation loss decreased (0.244435 --> 0.239613).  Saving model ...
train epoch 426 avg loss: 0.16070 (A-MSE: 0.14003) avg lploss: 0.00000
train epoch 427 avg loss: 0.17118 (A-MSE: 0.14696) avg lploss: 0.00000
train epoch 428 avg loss: 0.15197 (A-MSE: 0.13169) avg lploss: 0.00000
train epoch 429 avg loss: 0.16064 (A-MSE: 0.13959) avg lploss: 0.00000
train epoch 430 avg loss: 0.16250 (A-MSE: 0.14055) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.22198 (A-MSE: 0.18932) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.18819 (A-MSE: 0.16028) avg lploss: 0.00000
*** Best Val Loss: 0.22198 	 Best Test Loss: 0.18819 	 Best epoch 430
Validation loss decreased (0.239613 --> 0.221983).  Saving model ...
train epoch 431 avg loss: 0.15918 (A-MSE: 0.13813) avg lploss: 0.00000
train epoch 432 avg loss: 0.20712 (A-MSE: 0.18174) avg lploss: 0.00000
train epoch 433 avg loss: 0.18613 (A-MSE: 0.16160) avg lploss: 0.00000
train epoch 434 avg loss: 0.17995 (A-MSE: 0.15677) avg lploss: 0.00000
train epoch 435 avg loss: 0.17293 (A-MSE: 0.14994) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.21860 (A-MSE: 0.18929) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.19076 (A-MSE: 0.16613) avg lploss: 0.00000
*** Best Val Loss: 0.21860 	 Best Test Loss: 0.19076 	 Best epoch 435
Validation loss decreased (0.221983 --> 0.218602).  Saving model ...
train epoch 436 avg loss: 0.18808 (A-MSE: 0.16396) avg lploss: 0.00000
train epoch 437 avg loss: 0.20477 (A-MSE: 0.17821) avg lploss: 0.00000
train epoch 438 avg loss: 0.19497 (A-MSE: 0.16888) avg lploss: 0.00000
train epoch 439 avg loss: 0.16424 (A-MSE: 0.14307) avg lploss: 0.00000
train epoch 440 avg loss: 0.17589 (A-MSE: 0.15400) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.27218 (A-MSE: 0.22952) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.22827 (A-MSE: 0.19155) avg lploss: 0.00000
*** Best Val Loss: 0.21860 	 Best Test Loss: 0.19076 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 0.15571 (A-MSE: 0.13552) avg lploss: 0.00000
train epoch 442 avg loss: 0.18723 (A-MSE: 0.16229) avg lploss: 0.00000
train epoch 443 avg loss: 0.17687 (A-MSE: 0.15364) avg lploss: 0.00000
train epoch 444 avg loss: 0.15330 (A-MSE: 0.13275) avg lploss: 0.00000
train epoch 445 avg loss: 0.16029 (A-MSE: 0.13891) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.23024 (A-MSE: 0.19763) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.19180 (A-MSE: 0.16456) avg lploss: 0.00000
*** Best Val Loss: 0.21860 	 Best Test Loss: 0.19076 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 0.14108 (A-MSE: 0.12287) avg lploss: 0.00000
train epoch 447 avg loss: 0.15025 (A-MSE: 0.12882) avg lploss: 0.00000
train epoch 448 avg loss: 0.15359 (A-MSE: 0.13278) avg lploss: 0.00000
train epoch 449 avg loss: 0.16901 (A-MSE: 0.14849) avg lploss: 0.00000
train epoch 450 avg loss: 0.16176 (A-MSE: 0.13942) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.25316 (A-MSE: 0.21606) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.21977 (A-MSE: 0.18816) avg lploss: 0.00000
*** Best Val Loss: 0.21860 	 Best Test Loss: 0.19076 	 Best epoch 435
EarlyStopping counter: 3 out of 50
train epoch 451 avg loss: 0.14717 (A-MSE: 0.12878) avg lploss: 0.00000
train epoch 452 avg loss: 0.14156 (A-MSE: 0.12284) avg lploss: 0.00000
train epoch 453 avg loss: 0.18173 (A-MSE: 0.15781) avg lploss: 0.00000
train epoch 454 avg loss: 0.15466 (A-MSE: 0.13331) avg lploss: 0.00000
train epoch 455 avg loss: 0.13384 (A-MSE: 0.11642) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.19486 (A-MSE: 0.16691) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.16398 (A-MSE: 0.14036) avg lploss: 0.00000
*** Best Val Loss: 0.19486 	 Best Test Loss: 0.16398 	 Best epoch 455
Validation loss decreased (0.218602 --> 0.194865).  Saving model ...
train epoch 456 avg loss: 0.13197 (A-MSE: 0.11450) avg lploss: 0.00000
train epoch 457 avg loss: 0.14074 (A-MSE: 0.12312) avg lploss: 0.00000
train epoch 458 avg loss: 0.14566 (A-MSE: 0.12713) avg lploss: 0.00000
train epoch 459 avg loss: 0.15615 (A-MSE: 0.13497) avg lploss: 0.00000
train epoch 460 avg loss: 0.17340 (A-MSE: 0.15256) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.29337 (A-MSE: 0.25810) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.25262 (A-MSE: 0.22321) avg lploss: 0.00000
*** Best Val Loss: 0.19486 	 Best Test Loss: 0.16398 	 Best epoch 455
EarlyStopping counter: 1 out of 50
train epoch 461 avg loss: 0.18934 (A-MSE: 0.16493) avg lploss: 0.00000
train epoch 462 avg loss: 0.15994 (A-MSE: 0.13899) avg lploss: 0.00000
train epoch 463 avg loss: 0.15113 (A-MSE: 0.13215) avg lploss: 0.00000
train epoch 464 avg loss: 0.16109 (A-MSE: 0.13979) avg lploss: 0.00000
train epoch 465 avg loss: 0.15876 (A-MSE: 0.13821) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.27573 (A-MSE: 0.23330) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.23137 (A-MSE: 0.19462) avg lploss: 0.00000
*** Best Val Loss: 0.19486 	 Best Test Loss: 0.16398 	 Best epoch 455
EarlyStopping counter: 2 out of 50
train epoch 466 avg loss: 0.13424 (A-MSE: 0.11688) avg lploss: 0.00000
train epoch 467 avg loss: 0.13975 (A-MSE: 0.12035) avg lploss: 0.00000
train epoch 468 avg loss: 0.16296 (A-MSE: 0.14146) avg lploss: 0.00000
train epoch 469 avg loss: 0.17368 (A-MSE: 0.15027) avg lploss: 0.00000
train epoch 470 avg loss: 0.18003 (A-MSE: 0.15625) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.21101 (A-MSE: 0.18035) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.18285 (A-MSE: 0.15575) avg lploss: 0.00000
*** Best Val Loss: 0.19486 	 Best Test Loss: 0.16398 	 Best epoch 455
EarlyStopping counter: 3 out of 50
train epoch 471 avg loss: 0.17214 (A-MSE: 0.14897) avg lploss: 0.00000
train epoch 472 avg loss: 0.15445 (A-MSE: 0.13313) avg lploss: 0.00000
train epoch 473 avg loss: 0.14329 (A-MSE: 0.12427) avg lploss: 0.00000
train epoch 474 avg loss: 0.13581 (A-MSE: 0.11835) avg lploss: 0.00000
train epoch 475 avg loss: 0.12446 (A-MSE: 0.10847) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.19446 (A-MSE: 0.16535) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.17965 (A-MSE: 0.15313) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
Validation loss decreased (0.194865 --> 0.194459).  Saving model ...
train epoch 476 avg loss: 0.13674 (A-MSE: 0.11830) avg lploss: 0.00000
train epoch 477 avg loss: 0.14156 (A-MSE: 0.12312) avg lploss: 0.00000
train epoch 478 avg loss: 0.22630 (A-MSE: 0.19709) avg lploss: 0.00000
train epoch 479 avg loss: 0.82660 (A-MSE: 0.72705) avg lploss: 0.00000
train epoch 480 avg loss: 0.52299 (A-MSE: 0.44382) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.45840 (A-MSE: 0.42926) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.39461 (A-MSE: 0.36721) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
EarlyStopping counter: 1 out of 50
train epoch 481 avg loss: 0.38220 (A-MSE: 0.33204) avg lploss: 0.00000
train epoch 482 avg loss: 0.23524 (A-MSE: 0.20180) avg lploss: 0.00000
train epoch 483 avg loss: 0.20791 (A-MSE: 0.18107) avg lploss: 0.00000
train epoch 484 avg loss: 0.17032 (A-MSE: 0.14737) avg lploss: 0.00000
train epoch 485 avg loss: 0.17817 (A-MSE: 0.15423) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.19767 (A-MSE: 0.17033) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.16644 (A-MSE: 0.14286) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
EarlyStopping counter: 2 out of 50
train epoch 486 avg loss: 0.14679 (A-MSE: 0.12686) avg lploss: 0.00000
train epoch 487 avg loss: 0.15487 (A-MSE: 0.13471) avg lploss: 0.00000
train epoch 488 avg loss: 0.17787 (A-MSE: 0.15577) avg lploss: 0.00000
train epoch 489 avg loss: 0.18868 (A-MSE: 0.16369) avg lploss: 0.00000
train epoch 490 avg loss: 0.13851 (A-MSE: 0.12073) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.19961 (A-MSE: 0.17068) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.17957 (A-MSE: 0.15321) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
EarlyStopping counter: 3 out of 50
train epoch 491 avg loss: 0.13717 (A-MSE: 0.11927) avg lploss: 0.00000
train epoch 492 avg loss: 0.17658 (A-MSE: 0.15068) avg lploss: 0.00000
train epoch 493 avg loss: 0.16257 (A-MSE: 0.14120) avg lploss: 0.00000
train epoch 494 avg loss: 0.15365 (A-MSE: 0.13267) avg lploss: 0.00000
train epoch 495 avg loss: 0.13476 (A-MSE: 0.11709) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.22012 (A-MSE: 0.19150) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.18443 (A-MSE: 0.16016) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
EarlyStopping counter: 4 out of 50
train epoch 496 avg loss: 0.14074 (A-MSE: 0.12238) avg lploss: 0.00000
train epoch 497 avg loss: 0.12967 (A-MSE: 0.11254) avg lploss: 0.00000
train epoch 498 avg loss: 0.12958 (A-MSE: 0.11245) avg lploss: 0.00000
train epoch 499 avg loss: 0.13439 (A-MSE: 0.11668) avg lploss: 0.00000
train epoch 500 avg loss: 0.14395 (A-MSE: 0.12639) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.19601 (A-MSE: 0.16660) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.17327 (A-MSE: 0.14638) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
EarlyStopping counter: 5 out of 50
train epoch 501 avg loss: 0.13260 (A-MSE: 0.11522) avg lploss: 0.00000
train epoch 502 avg loss: 0.12046 (A-MSE: 0.10505) avg lploss: 0.00000
train epoch 503 avg loss: 0.12145 (A-MSE: 0.10514) avg lploss: 0.00000
train epoch 504 avg loss: 0.12957 (A-MSE: 0.11143) avg lploss: 0.00000
train epoch 505 avg loss: 0.12599 (A-MSE: 0.11037) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.24838 (A-MSE: 0.21927) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.21939 (A-MSE: 0.19321) avg lploss: 0.00000
*** Best Val Loss: 0.19446 	 Best Test Loss: 0.17965 	 Best epoch 475
EarlyStopping counter: 6 out of 50
train epoch 506 avg loss: 0.13711 (A-MSE: 0.11915) avg lploss: 0.00000
train epoch 507 avg loss: 0.13806 (A-MSE: 0.12095) avg lploss: 0.00000
train epoch 508 avg loss: 0.13163 (A-MSE: 0.11403) avg lploss: 0.00000
train epoch 509 avg loss: 0.13197 (A-MSE: 0.11528) avg lploss: 0.00000
train epoch 510 avg loss: 0.12234 (A-MSE: 0.10613) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.17483 (A-MSE: 0.15246) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.14390 (A-MSE: 0.12444) avg lploss: 0.00000
*** Best Val Loss: 0.17483 	 Best Test Loss: 0.14390 	 Best epoch 510
Validation loss decreased (0.194459 --> 0.174827).  Saving model ...
train epoch 511 avg loss: 0.13078 (A-MSE: 0.11338) avg lploss: 0.00000
train epoch 512 avg loss: 0.11248 (A-MSE: 0.09809) avg lploss: 0.00000
train epoch 513 avg loss: 0.14017 (A-MSE: 0.12273) avg lploss: 0.00000
train epoch 514 avg loss: 0.18669 (A-MSE: 0.16290) avg lploss: 0.00000
train epoch 515 avg loss: 0.17492 (A-MSE: 0.15323) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.22466 (A-MSE: 0.18844) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.19217 (A-MSE: 0.16036) avg lploss: 0.00000
*** Best Val Loss: 0.17483 	 Best Test Loss: 0.14390 	 Best epoch 510
EarlyStopping counter: 1 out of 50
train epoch 516 avg loss: 0.13887 (A-MSE: 0.11979) avg lploss: 0.00000
train epoch 517 avg loss: 0.13022 (A-MSE: 0.11283) avg lploss: 0.00000
train epoch 518 avg loss: 0.11207 (A-MSE: 0.09743) avg lploss: 0.00000
train epoch 519 avg loss: 0.11007 (A-MSE: 0.09537) avg lploss: 0.00000
train epoch 520 avg loss: 0.11356 (A-MSE: 0.09896) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.19345 (A-MSE: 0.16740) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.16633 (A-MSE: 0.14274) avg lploss: 0.00000
*** Best Val Loss: 0.17483 	 Best Test Loss: 0.14390 	 Best epoch 510
EarlyStopping counter: 2 out of 50
train epoch 521 avg loss: 0.11422 (A-MSE: 0.09929) avg lploss: 0.00000
train epoch 522 avg loss: 0.12319 (A-MSE: 0.10710) avg lploss: 0.00000
train epoch 523 avg loss: 0.12144 (A-MSE: 0.10598) avg lploss: 0.00000
train epoch 524 avg loss: 0.12904 (A-MSE: 0.11220) avg lploss: 0.00000
train epoch 525 avg loss: 0.12330 (A-MSE: 0.10742) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.16000 (A-MSE: 0.13809) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.13653 (A-MSE: 0.11671) avg lploss: 0.00000
*** Best Val Loss: 0.16000 	 Best Test Loss: 0.13653 	 Best epoch 525
Validation loss decreased (0.174827 --> 0.160004).  Saving model ...
train epoch 526 avg loss: 0.11341 (A-MSE: 0.09840) avg lploss: 0.00000
train epoch 527 avg loss: 0.11660 (A-MSE: 0.10132) avg lploss: 0.00000
train epoch 528 avg loss: 0.11017 (A-MSE: 0.09642) avg lploss: 0.00000
train epoch 529 avg loss: 0.12583 (A-MSE: 0.10932) avg lploss: 0.00000
train epoch 530 avg loss: 0.12570 (A-MSE: 0.11018) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.20147 (A-MSE: 0.16780) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.17142 (A-MSE: 0.14216) avg lploss: 0.00000
*** Best Val Loss: 0.16000 	 Best Test Loss: 0.13653 	 Best epoch 525
EarlyStopping counter: 1 out of 50
train epoch 531 avg loss: 0.12419 (A-MSE: 0.10762) avg lploss: 0.00000
train epoch 532 avg loss: 0.12103 (A-MSE: 0.10499) avg lploss: 0.00000
train epoch 533 avg loss: 0.11868 (A-MSE: 0.10309) avg lploss: 0.00000
train epoch 534 avg loss: 0.11438 (A-MSE: 0.09962) avg lploss: 0.00000
train epoch 535 avg loss: 0.12736 (A-MSE: 0.11161) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.20021 (A-MSE: 0.17685) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.17092 (A-MSE: 0.15024) avg lploss: 0.00000
*** Best Val Loss: 0.16000 	 Best Test Loss: 0.13653 	 Best epoch 525
EarlyStopping counter: 2 out of 50
train epoch 536 avg loss: 0.10594 (A-MSE: 0.09221) avg lploss: 0.00000
train epoch 537 avg loss: 0.10918 (A-MSE: 0.09377) avg lploss: 0.00000
train epoch 538 avg loss: 0.15381 (A-MSE: 0.13266) avg lploss: 0.00000
train epoch 539 avg loss: 0.13551 (A-MSE: 0.11862) avg lploss: 0.00000
train epoch 540 avg loss: 0.14226 (A-MSE: 0.12332) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.18660 (A-MSE: 0.16085) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.16069 (A-MSE: 0.13805) avg lploss: 0.00000
*** Best Val Loss: 0.16000 	 Best Test Loss: 0.13653 	 Best epoch 525
EarlyStopping counter: 3 out of 50
train epoch 541 avg loss: 0.11911 (A-MSE: 0.10342) avg lploss: 0.00000
train epoch 542 avg loss: 0.11049 (A-MSE: 0.09604) avg lploss: 0.00000
train epoch 543 avg loss: 0.10361 (A-MSE: 0.09013) avg lploss: 0.00000
train epoch 544 avg loss: 0.12571 (A-MSE: 0.10965) avg lploss: 0.00000
train epoch 545 avg loss: 0.14593 (A-MSE: 0.12736) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.17967 (A-MSE: 0.15389) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.14948 (A-MSE: 0.12704) avg lploss: 0.00000
*** Best Val Loss: 0.16000 	 Best Test Loss: 0.13653 	 Best epoch 525
EarlyStopping counter: 4 out of 50
train epoch 546 avg loss: 0.12399 (A-MSE: 0.10771) avg lploss: 0.00000
train epoch 547 avg loss: 0.12863 (A-MSE: 0.11236) avg lploss: 0.00000
train epoch 548 avg loss: 0.12197 (A-MSE: 0.10690) avg lploss: 0.00000
train epoch 549 avg loss: 0.12744 (A-MSE: 0.11113) avg lploss: 0.00000
train epoch 550 avg loss: 0.11202 (A-MSE: 0.09779) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.15395 (A-MSE: 0.13504) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.12410 (A-MSE: 0.10787) avg lploss: 0.00000
*** Best Val Loss: 0.15395 	 Best Test Loss: 0.12410 	 Best epoch 550
Validation loss decreased (0.160004 --> 0.153947).  Saving model ...
train epoch 551 avg loss: 0.10291 (A-MSE: 0.08975) avg lploss: 0.00000
train epoch 552 avg loss: 0.09803 (A-MSE: 0.08531) avg lploss: 0.00000
train epoch 553 avg loss: 0.11413 (A-MSE: 0.09939) avg lploss: 0.00000
train epoch 554 avg loss: 0.10066 (A-MSE: 0.08744) avg lploss: 0.00000
train epoch 555 avg loss: 0.11126 (A-MSE: 0.09676) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.15813 (A-MSE: 0.13794) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.13087 (A-MSE: 0.11283) avg lploss: 0.00000
*** Best Val Loss: 0.15395 	 Best Test Loss: 0.12410 	 Best epoch 550
EarlyStopping counter: 1 out of 50
train epoch 556 avg loss: 0.10666 (A-MSE: 0.09279) avg lploss: 0.00000
train epoch 557 avg loss: 0.09699 (A-MSE: 0.08456) avg lploss: 0.00000
train epoch 558 avg loss: 0.10123 (A-MSE: 0.08818) avg lploss: 0.00000
train epoch 559 avg loss: 0.11992 (A-MSE: 0.10435) avg lploss: 0.00000
train epoch 560 avg loss: 0.11997 (A-MSE: 0.10343) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.18474 (A-MSE: 0.15909) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.15921 (A-MSE: 0.13580) avg lploss: 0.00000
*** Best Val Loss: 0.15395 	 Best Test Loss: 0.12410 	 Best epoch 550
EarlyStopping counter: 2 out of 50
train epoch 561 avg loss: 0.11471 (A-MSE: 0.09960) avg lploss: 0.00000
train epoch 562 avg loss: 0.11179 (A-MSE: 0.09736) avg lploss: 0.00000
train epoch 563 avg loss: 0.10159 (A-MSE: 0.08827) avg lploss: 0.00000
train epoch 564 avg loss: 0.12762 (A-MSE: 0.11018) avg lploss: 0.00000
train epoch 565 avg loss: 0.15464 (A-MSE: 0.13378) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.18455 (A-MSE: 0.16218) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.16101 (A-MSE: 0.14098) avg lploss: 0.00000
*** Best Val Loss: 0.15395 	 Best Test Loss: 0.12410 	 Best epoch 550
EarlyStopping counter: 3 out of 50
train epoch 566 avg loss: 0.12670 (A-MSE: 0.11094) avg lploss: 0.00000
train epoch 567 avg loss: 0.11719 (A-MSE: 0.10198) avg lploss: 0.00000
train epoch 568 avg loss: 0.10498 (A-MSE: 0.09119) avg lploss: 0.00000
train epoch 569 avg loss: 0.12549 (A-MSE: 0.10918) avg lploss: 0.00000
train epoch 570 avg loss: 0.10873 (A-MSE: 0.09479) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.14903 (A-MSE: 0.12982) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.12356 (A-MSE: 0.10679) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
Validation loss decreased (0.153947 --> 0.149032).  Saving model ...
train epoch 571 avg loss: 0.09344 (A-MSE: 0.08140) avg lploss: 0.00000
train epoch 572 avg loss: 0.09774 (A-MSE: 0.08509) avg lploss: 0.00000
train epoch 573 avg loss: 0.12018 (A-MSE: 0.10467) avg lploss: 0.00000
train epoch 574 avg loss: 0.12465 (A-MSE: 0.10913) avg lploss: 0.00000
train epoch 575 avg loss: 0.11753 (A-MSE: 0.10206) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.15633 (A-MSE: 0.13595) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.13601 (A-MSE: 0.11736) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 1 out of 50
train epoch 576 avg loss: 0.12208 (A-MSE: 0.10658) avg lploss: 0.00000
train epoch 577 avg loss: 0.10794 (A-MSE: 0.09432) avg lploss: 0.00000
train epoch 578 avg loss: 0.10679 (A-MSE: 0.09346) avg lploss: 0.00000
train epoch 579 avg loss: 0.11525 (A-MSE: 0.10114) avg lploss: 0.00000
train epoch 580 avg loss: 0.10588 (A-MSE: 0.09264) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.18782 (A-MSE: 0.16273) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.15356 (A-MSE: 0.13240) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 2 out of 50
train epoch 581 avg loss: 0.10462 (A-MSE: 0.09126) avg lploss: 0.00000
train epoch 582 avg loss: 0.10705 (A-MSE: 0.09354) avg lploss: 0.00000
train epoch 583 avg loss: 0.17838 (A-MSE: 0.15401) avg lploss: 0.00000
train epoch 584 avg loss: 0.13363 (A-MSE: 0.11658) avg lploss: 0.00000
train epoch 585 avg loss: 0.12143 (A-MSE: 0.10609) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.22774 (A-MSE: 0.19225) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.19694 (A-MSE: 0.16508) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 3 out of 50
train epoch 586 avg loss: 0.11574 (A-MSE: 0.10000) avg lploss: 0.00000
train epoch 587 avg loss: 0.11662 (A-MSE: 0.10167) avg lploss: 0.00000
train epoch 588 avg loss: 0.12208 (A-MSE: 0.10661) avg lploss: 0.00000
train epoch 589 avg loss: 0.10305 (A-MSE: 0.09070) avg lploss: 0.00000
train epoch 590 avg loss: 0.10753 (A-MSE: 0.09381) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.17079 (A-MSE: 0.14802) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.14273 (A-MSE: 0.12231) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 4 out of 50
train epoch 591 avg loss: 0.11846 (A-MSE: 0.10322) avg lploss: 0.00000
train epoch 592 avg loss: 0.10490 (A-MSE: 0.09156) avg lploss: 0.00000
train epoch 593 avg loss: 0.10558 (A-MSE: 0.09233) avg lploss: 0.00000
train epoch 594 avg loss: 0.10065 (A-MSE: 0.08761) avg lploss: 0.00000
train epoch 595 avg loss: 0.10031 (A-MSE: 0.08760) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.17569 (A-MSE: 0.15062) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.14949 (A-MSE: 0.12731) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 5 out of 50
train epoch 596 avg loss: 0.10577 (A-MSE: 0.09199) avg lploss: 0.00000
train epoch 597 avg loss: 0.10356 (A-MSE: 0.09087) avg lploss: 0.00000
train epoch 598 avg loss: 0.10610 (A-MSE: 0.09245) avg lploss: 0.00000
train epoch 599 avg loss: 0.10627 (A-MSE: 0.09319) avg lploss: 0.00000
train epoch 600 avg loss: 0.10358 (A-MSE: 0.09094) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.16435 (A-MSE: 0.14464) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.13412 (A-MSE: 0.11711) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 6 out of 50
train epoch 601 avg loss: 0.10666 (A-MSE: 0.09283) avg lploss: 0.00000
train epoch 602 avg loss: 0.10599 (A-MSE: 0.09301) avg lploss: 0.00000
train epoch 603 avg loss: 0.11135 (A-MSE: 0.09737) avg lploss: 0.00000
train epoch 604 avg loss: 0.15640 (A-MSE: 0.13800) avg lploss: 0.00000
train epoch 605 avg loss: 0.16179 (A-MSE: 0.14144) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.20861 (A-MSE: 0.17491) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.18563 (A-MSE: 0.15485) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 7 out of 50
train epoch 606 avg loss: 0.12357 (A-MSE: 0.10736) avg lploss: 0.00000
train epoch 607 avg loss: 0.11172 (A-MSE: 0.09707) avg lploss: 0.00000
train epoch 608 avg loss: 0.10928 (A-MSE: 0.09439) avg lploss: 0.00000
train epoch 609 avg loss: 0.15331 (A-MSE: 0.13421) avg lploss: 0.00000
train epoch 610 avg loss: 0.12302 (A-MSE: 0.10832) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.19359 (A-MSE: 0.16620) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.16418 (A-MSE: 0.13959) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 8 out of 50
train epoch 611 avg loss: 0.11180 (A-MSE: 0.09744) avg lploss: 0.00000
train epoch 612 avg loss: 0.10635 (A-MSE: 0.09257) avg lploss: 0.00000
train epoch 613 avg loss: 0.10448 (A-MSE: 0.09125) avg lploss: 0.00000
train epoch 614 avg loss: 0.09318 (A-MSE: 0.08073) avg lploss: 0.00000
train epoch 615 avg loss: 0.09460 (A-MSE: 0.08255) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.15035 (A-MSE: 0.12892) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.13392 (A-MSE: 0.11412) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 9 out of 50
train epoch 616 avg loss: 0.10812 (A-MSE: 0.09445) avg lploss: 0.00000
train epoch 617 avg loss: 0.12094 (A-MSE: 0.10569) avg lploss: 0.00000
train epoch 618 avg loss: 0.13064 (A-MSE: 0.11444) avg lploss: 0.00000
train epoch 619 avg loss: 0.11739 (A-MSE: 0.10261) avg lploss: 0.00000
train epoch 620 avg loss: 0.10802 (A-MSE: 0.09361) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.15323 (A-MSE: 0.13256) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.13189 (A-MSE: 0.11341) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 10 out of 50
train epoch 621 avg loss: 0.09959 (A-MSE: 0.08708) avg lploss: 0.00000
train epoch 622 avg loss: 0.10367 (A-MSE: 0.09017) avg lploss: 0.00000
train epoch 623 avg loss: 0.10482 (A-MSE: 0.09071) avg lploss: 0.00000
train epoch 624 avg loss: 0.09965 (A-MSE: 0.08661) avg lploss: 0.00000
train epoch 625 avg loss: 0.12157 (A-MSE: 0.10621) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.15879 (A-MSE: 0.13751) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.13596 (A-MSE: 0.11642) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 11 out of 50
train epoch 626 avg loss: 0.11175 (A-MSE: 0.09657) avg lploss: 0.00000
train epoch 627 avg loss: 0.11008 (A-MSE: 0.09609) avg lploss: 0.00000
train epoch 628 avg loss: 0.10214 (A-MSE: 0.08914) avg lploss: 0.00000
train epoch 629 avg loss: 0.09972 (A-MSE: 0.08729) avg lploss: 0.00000
train epoch 630 avg loss: 0.10354 (A-MSE: 0.09050) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.15241 (A-MSE: 0.13273) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.12602 (A-MSE: 0.10873) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 12 out of 50
train epoch 631 avg loss: 0.09258 (A-MSE: 0.08044) avg lploss: 0.00000
train epoch 632 avg loss: 0.09360 (A-MSE: 0.08172) avg lploss: 0.00000
train epoch 633 avg loss: 0.09592 (A-MSE: 0.08366) avg lploss: 0.00000
train epoch 634 avg loss: 0.09341 (A-MSE: 0.08177) avg lploss: 0.00000
train epoch 635 avg loss: 0.10159 (A-MSE: 0.08922) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.17915 (A-MSE: 0.15509) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.14946 (A-MSE: 0.12891) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 13 out of 50
train epoch 636 avg loss: 0.10338 (A-MSE: 0.09046) avg lploss: 0.00000
train epoch 637 avg loss: 0.10377 (A-MSE: 0.09032) avg lploss: 0.00000
train epoch 638 avg loss: 0.10269 (A-MSE: 0.08908) avg lploss: 0.00000
train epoch 639 avg loss: 0.10353 (A-MSE: 0.09093) avg lploss: 0.00000
train epoch 640 avg loss: 0.10742 (A-MSE: 0.09329) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.15141 (A-MSE: 0.13179) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.13411 (A-MSE: 0.11614) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 14 out of 50
train epoch 641 avg loss: 0.11140 (A-MSE: 0.09673) avg lploss: 0.00000
train epoch 642 avg loss: 0.11681 (A-MSE: 0.10281) avg lploss: 0.00000
train epoch 643 avg loss: 0.14139 (A-MSE: 0.12244) avg lploss: 0.00000
train epoch 644 avg loss: 0.10836 (A-MSE: 0.09430) avg lploss: 0.00000
train epoch 645 avg loss: 0.09629 (A-MSE: 0.08371) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.15378 (A-MSE: 0.13334) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.12746 (A-MSE: 0.10937) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 15 out of 50
train epoch 646 avg loss: 0.08916 (A-MSE: 0.07758) avg lploss: 0.00000
train epoch 647 avg loss: 0.10269 (A-MSE: 0.08994) avg lploss: 0.00000
train epoch 648 avg loss: 0.11720 (A-MSE: 0.10222) avg lploss: 0.00000
train epoch 649 avg loss: 0.11193 (A-MSE: 0.09827) avg lploss: 0.00000
train epoch 650 avg loss: 0.11122 (A-MSE: 0.09654) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.17854 (A-MSE: 0.15487) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.14986 (A-MSE: 0.12896) avg lploss: 0.00000
*** Best Val Loss: 0.14903 	 Best Test Loss: 0.12356 	 Best epoch 570
EarlyStopping counter: 16 out of 50
train epoch 651 avg loss: 0.10635 (A-MSE: 0.09243) avg lploss: 0.00000
train epoch 652 avg loss: 0.11309 (A-MSE: 0.09886) avg lploss: 0.00000
train epoch 653 avg loss: 0.12425 (A-MSE: 0.10873) avg lploss: 0.00000
train epoch 654 avg loss: 0.11351 (A-MSE: 0.09929) avg lploss: 0.00000
train epoch 655 avg loss: 0.09396 (A-MSE: 0.08210) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.14683 (A-MSE: 0.12797) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.12434 (A-MSE: 0.10772) avg lploss: 0.00000
*** Best Val Loss: 0.14683 	 Best Test Loss: 0.12434 	 Best epoch 655
Validation loss decreased (0.149032 --> 0.146834).  Saving model ...
train epoch 656 avg loss: 0.09264 (A-MSE: 0.08117) avg lploss: 0.00000
train epoch 657 avg loss: 0.10324 (A-MSE: 0.09010) avg lploss: 0.00000
train epoch 658 avg loss: 0.10052 (A-MSE: 0.08724) avg lploss: 0.00000
train epoch 659 avg loss: 0.09597 (A-MSE: 0.08373) avg lploss: 0.00000
train epoch 660 avg loss: 0.09306 (A-MSE: 0.08120) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.14149 (A-MSE: 0.12304) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.11671 (A-MSE: 0.10072) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
Validation loss decreased (0.146834 --> 0.141486).  Saving model ...
train epoch 661 avg loss: 0.09753 (A-MSE: 0.08539) avg lploss: 0.00000
train epoch 662 avg loss: 0.10400 (A-MSE: 0.09060) avg lploss: 0.00000
train epoch 663 avg loss: 0.09657 (A-MSE: 0.08377) avg lploss: 0.00000
train epoch 664 avg loss: 0.09452 (A-MSE: 0.08257) avg lploss: 0.00000
train epoch 665 avg loss: 0.09502 (A-MSE: 0.08325) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.15936 (A-MSE: 0.13877) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.12993 (A-MSE: 0.11220) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 1 out of 50
train epoch 666 avg loss: 0.10146 (A-MSE: 0.08748) avg lploss: 0.00000
train epoch 667 avg loss: 0.10222 (A-MSE: 0.08939) avg lploss: 0.00000
train epoch 668 avg loss: 0.11333 (A-MSE: 0.09913) avg lploss: 0.00000
train epoch 669 avg loss: 0.10112 (A-MSE: 0.08866) avg lploss: 0.00000
train epoch 670 avg loss: 0.09048 (A-MSE: 0.07816) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.14567 (A-MSE: 0.12739) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.11935 (A-MSE: 0.10360) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 2 out of 50
train epoch 671 avg loss: 0.08988 (A-MSE: 0.07816) avg lploss: 0.00000
train epoch 672 avg loss: 0.08867 (A-MSE: 0.07723) avg lploss: 0.00000
train epoch 673 avg loss: 0.09673 (A-MSE: 0.08443) avg lploss: 0.00000
train epoch 674 avg loss: 0.10311 (A-MSE: 0.09040) avg lploss: 0.00000
train epoch 675 avg loss: 0.10725 (A-MSE: 0.09413) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.15321 (A-MSE: 0.13394) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.11859 (A-MSE: 0.10244) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 3 out of 50
train epoch 676 avg loss: 0.10055 (A-MSE: 0.08799) avg lploss: 0.00000
train epoch 677 avg loss: 0.10088 (A-MSE: 0.08826) avg lploss: 0.00000
train epoch 678 avg loss: 0.09513 (A-MSE: 0.08295) avg lploss: 0.00000
train epoch 679 avg loss: 0.10375 (A-MSE: 0.09036) avg lploss: 0.00000
train epoch 680 avg loss: 0.20084 (A-MSE: 0.17839) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.39928 (A-MSE: 0.36046) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.37817 (A-MSE: 0.34089) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 4 out of 50
train epoch 681 avg loss: 0.60744 (A-MSE: 0.54232) avg lploss: 0.00000
train epoch 682 avg loss: 0.39235 (A-MSE: 0.33916) avg lploss: 0.00000
train epoch 683 avg loss: 0.20889 (A-MSE: 0.18186) avg lploss: 0.00000
train epoch 684 avg loss: 0.13776 (A-MSE: 0.12017) avg lploss: 0.00000
train epoch 685 avg loss: 0.12805 (A-MSE: 0.11130) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.22629 (A-MSE: 0.19434) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.18972 (A-MSE: 0.16243) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 5 out of 50
train epoch 686 avg loss: 0.11382 (A-MSE: 0.09838) avg lploss: 0.00000
train epoch 687 avg loss: 0.11221 (A-MSE: 0.09737) avg lploss: 0.00000
train epoch 688 avg loss: 0.11865 (A-MSE: 0.10345) avg lploss: 0.00000
train epoch 689 avg loss: 0.11175 (A-MSE: 0.09733) avg lploss: 0.00000
train epoch 690 avg loss: 0.13482 (A-MSE: 0.11743) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.15702 (A-MSE: 0.13676) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.12899 (A-MSE: 0.11155) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 6 out of 50
train epoch 691 avg loss: 0.10712 (A-MSE: 0.09365) avg lploss: 0.00000
train epoch 692 avg loss: 0.10200 (A-MSE: 0.08851) avg lploss: 0.00000
train epoch 693 avg loss: 0.09889 (A-MSE: 0.08590) avg lploss: 0.00000
train epoch 694 avg loss: 0.10528 (A-MSE: 0.09212) avg lploss: 0.00000
train epoch 695 avg loss: 0.09828 (A-MSE: 0.08568) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.17229 (A-MSE: 0.14669) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.14018 (A-MSE: 0.11807) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 7 out of 50
train epoch 696 avg loss: 0.10152 (A-MSE: 0.08773) avg lploss: 0.00000
train epoch 697 avg loss: 0.09921 (A-MSE: 0.08674) avg lploss: 0.00000
train epoch 698 avg loss: 0.09801 (A-MSE: 0.08470) avg lploss: 0.00000
train epoch 699 avg loss: 0.09391 (A-MSE: 0.08158) avg lploss: 0.00000
train epoch 700 avg loss: 0.10073 (A-MSE: 0.08766) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.15288 (A-MSE: 0.13348) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.12557 (A-MSE: 0.10878) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 8 out of 50
train epoch 701 avg loss: 0.08576 (A-MSE: 0.07421) avg lploss: 0.00000
train epoch 702 avg loss: 0.08686 (A-MSE: 0.07625) avg lploss: 0.00000
train epoch 703 avg loss: 0.09321 (A-MSE: 0.08140) avg lploss: 0.00000
train epoch 704 avg loss: 0.09703 (A-MSE: 0.08434) avg lploss: 0.00000
train epoch 705 avg loss: 0.10253 (A-MSE: 0.08939) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.15883 (A-MSE: 0.13842) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.12159 (A-MSE: 0.10493) avg lploss: 0.00000
*** Best Val Loss: 0.14149 	 Best Test Loss: 0.11671 	 Best epoch 660
EarlyStopping counter: 9 out of 50
train epoch 706 avg loss: 0.09106 (A-MSE: 0.07922) avg lploss: 0.00000
train epoch 707 avg loss: 0.08356 (A-MSE: 0.07276) avg lploss: 0.00000
train epoch 708 avg loss: 0.08554 (A-MSE: 0.07467) avg lploss: 0.00000
train epoch 709 avg loss: 0.08409 (A-MSE: 0.07270) avg lploss: 0.00000
train epoch 710 avg loss: 0.08966 (A-MSE: 0.07795) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.13985 (A-MSE: 0.12128) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.10891 (A-MSE: 0.09343) avg lploss: 0.00000
*** Best Val Loss: 0.13985 	 Best Test Loss: 0.10891 	 Best epoch 710
Validation loss decreased (0.141486 --> 0.139852).  Saving model ...
train epoch 711 avg loss: 0.08569 (A-MSE: 0.07482) avg lploss: 0.00000
train epoch 712 avg loss: 0.07660 (A-MSE: 0.06629) avg lploss: 0.00000
train epoch 713 avg loss: 0.08385 (A-MSE: 0.07309) avg lploss: 0.00000
train epoch 714 avg loss: 0.08228 (A-MSE: 0.07181) avg lploss: 0.00000
train epoch 715 avg loss: 0.08256 (A-MSE: 0.07212) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.14126 (A-MSE: 0.12226) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.11360 (A-MSE: 0.09732) avg lploss: 0.00000
*** Best Val Loss: 0.13985 	 Best Test Loss: 0.10891 	 Best epoch 710
EarlyStopping counter: 1 out of 50
train epoch 716 avg loss: 0.07830 (A-MSE: 0.06820) avg lploss: 0.00000
train epoch 717 avg loss: 0.08278 (A-MSE: 0.07192) avg lploss: 0.00000
train epoch 718 avg loss: 0.07856 (A-MSE: 0.06890) avg lploss: 0.00000
train epoch 719 avg loss: 0.08714 (A-MSE: 0.07614) avg lploss: 0.00000
train epoch 720 avg loss: 0.09037 (A-MSE: 0.07845) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.18371 (A-MSE: 0.16050) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.15326 (A-MSE: 0.13343) avg lploss: 0.00000
*** Best Val Loss: 0.13985 	 Best Test Loss: 0.10891 	 Best epoch 710
EarlyStopping counter: 2 out of 50
train epoch 721 avg loss: 0.09318 (A-MSE: 0.08098) avg lploss: 0.00000
train epoch 722 avg loss: 0.07881 (A-MSE: 0.06896) avg lploss: 0.00000
train epoch 723 avg loss: 0.07681 (A-MSE: 0.06684) avg lploss: 0.00000
train epoch 724 avg loss: 0.08146 (A-MSE: 0.07083) avg lploss: 0.00000
train epoch 725 avg loss: 0.07724 (A-MSE: 0.06695) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.12853 (A-MSE: 0.11352) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.10268 (A-MSE: 0.08984) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
Validation loss decreased (0.139852 --> 0.128532).  Saving model ...
train epoch 726 avg loss: 0.09979 (A-MSE: 0.08639) avg lploss: 0.00000
train epoch 727 avg loss: 0.09391 (A-MSE: 0.08233) avg lploss: 0.00000
train epoch 728 avg loss: 0.09982 (A-MSE: 0.08675) avg lploss: 0.00000
train epoch 729 avg loss: 0.09170 (A-MSE: 0.07988) avg lploss: 0.00000
train epoch 730 avg loss: 0.09371 (A-MSE: 0.08219) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.15034 (A-MSE: 0.12918) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.12559 (A-MSE: 0.10738) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 1 out of 50
train epoch 731 avg loss: 0.08787 (A-MSE: 0.07645) avg lploss: 0.00000
train epoch 732 avg loss: 0.08361 (A-MSE: 0.07287) avg lploss: 0.00000
train epoch 733 avg loss: 0.08784 (A-MSE: 0.07647) avg lploss: 0.00000
train epoch 734 avg loss: 0.10946 (A-MSE: 0.09542) avg lploss: 0.00000
train epoch 735 avg loss: 0.09310 (A-MSE: 0.08105) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.14905 (A-MSE: 0.12991) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.11645 (A-MSE: 0.10089) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 2 out of 50
train epoch 736 avg loss: 0.07966 (A-MSE: 0.06970) avg lploss: 0.00000
train epoch 737 avg loss: 0.08041 (A-MSE: 0.06997) avg lploss: 0.00000
train epoch 738 avg loss: 0.07624 (A-MSE: 0.06620) avg lploss: 0.00000
train epoch 739 avg loss: 0.07647 (A-MSE: 0.06626) avg lploss: 0.00000
train epoch 740 avg loss: 0.07733 (A-MSE: 0.06725) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.15203 (A-MSE: 0.13225) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.11617 (A-MSE: 0.09990) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 3 out of 50
train epoch 741 avg loss: 0.07955 (A-MSE: 0.06876) avg lploss: 0.00000
train epoch 742 avg loss: 0.08188 (A-MSE: 0.07138) avg lploss: 0.00000
train epoch 743 avg loss: 0.08550 (A-MSE: 0.07463) avg lploss: 0.00000
train epoch 744 avg loss: 0.07943 (A-MSE: 0.06934) avg lploss: 0.00000
train epoch 745 avg loss: 0.08305 (A-MSE: 0.07187) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.17130 (A-MSE: 0.14867) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.13333 (A-MSE: 0.11455) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 4 out of 50
train epoch 746 avg loss: 0.08772 (A-MSE: 0.07633) avg lploss: 0.00000
train epoch 747 avg loss: 0.09954 (A-MSE: 0.08664) avg lploss: 0.00000
train epoch 748 avg loss: 0.08967 (A-MSE: 0.07774) avg lploss: 0.00000
train epoch 749 avg loss: 0.08436 (A-MSE: 0.07328) avg lploss: 0.00000
train epoch 750 avg loss: 0.08508 (A-MSE: 0.07398) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.13456 (A-MSE: 0.11631) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.10396 (A-MSE: 0.08873) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 5 out of 50
train epoch 751 avg loss: 0.08456 (A-MSE: 0.07342) avg lploss: 0.00000
train epoch 752 avg loss: 0.08833 (A-MSE: 0.07642) avg lploss: 0.00000
train epoch 753 avg loss: 0.07578 (A-MSE: 0.06627) avg lploss: 0.00000
train epoch 754 avg loss: 0.09307 (A-MSE: 0.08131) avg lploss: 0.00000
train epoch 755 avg loss: 0.07692 (A-MSE: 0.06682) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.14755 (A-MSE: 0.13051) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.12343 (A-MSE: 0.10881) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 6 out of 50
train epoch 756 avg loss: 0.09031 (A-MSE: 0.07886) avg lploss: 0.00000
train epoch 757 avg loss: 0.10013 (A-MSE: 0.08717) avg lploss: 0.00000
train epoch 758 avg loss: 0.10216 (A-MSE: 0.08920) avg lploss: 0.00000
train epoch 759 avg loss: 0.09921 (A-MSE: 0.08661) avg lploss: 0.00000
train epoch 760 avg loss: 0.09545 (A-MSE: 0.08286) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.15292 (A-MSE: 0.13642) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.12803 (A-MSE: 0.11322) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 7 out of 50
train epoch 761 avg loss: 0.09869 (A-MSE: 0.08698) avg lploss: 0.00000
train epoch 762 avg loss: 0.08429 (A-MSE: 0.07381) avg lploss: 0.00000
train epoch 763 avg loss: 0.08084 (A-MSE: 0.07015) avg lploss: 0.00000
train epoch 764 avg loss: 0.08432 (A-MSE: 0.07403) avg lploss: 0.00000
train epoch 765 avg loss: 0.09437 (A-MSE: 0.08198) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.15691 (A-MSE: 0.13493) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.11803 (A-MSE: 0.09952) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 8 out of 50
train epoch 766 avg loss: 0.09102 (A-MSE: 0.07909) avg lploss: 0.00000
train epoch 767 avg loss: 0.09763 (A-MSE: 0.08547) avg lploss: 0.00000
train epoch 768 avg loss: 0.10197 (A-MSE: 0.08908) avg lploss: 0.00000
train epoch 769 avg loss: 0.09562 (A-MSE: 0.08369) avg lploss: 0.00000
train epoch 770 avg loss: 0.09996 (A-MSE: 0.08721) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.15259 (A-MSE: 0.13453) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.12231 (A-MSE: 0.10745) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 9 out of 50
train epoch 771 avg loss: 0.09375 (A-MSE: 0.08204) avg lploss: 0.00000
train epoch 772 avg loss: 0.08327 (A-MSE: 0.07257) avg lploss: 0.00000
train epoch 773 avg loss: 0.08793 (A-MSE: 0.07656) avg lploss: 0.00000
train epoch 774 avg loss: 0.08400 (A-MSE: 0.07323) avg lploss: 0.00000
train epoch 775 avg loss: 0.07255 (A-MSE: 0.06325) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.12916 (A-MSE: 0.11196) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.09708 (A-MSE: 0.08256) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 10 out of 50
train epoch 776 avg loss: 0.07376 (A-MSE: 0.06403) avg lploss: 0.00000
train epoch 777 avg loss: 0.07292 (A-MSE: 0.06350) avg lploss: 0.00000
train epoch 778 avg loss: 0.07966 (A-MSE: 0.06913) avg lploss: 0.00000
train epoch 779 avg loss: 0.08181 (A-MSE: 0.07160) avg lploss: 0.00000
train epoch 780 avg loss: 0.10203 (A-MSE: 0.08908) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.13221 (A-MSE: 0.11750) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.10453 (A-MSE: 0.09107) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 11 out of 50
train epoch 781 avg loss: 0.10348 (A-MSE: 0.09103) avg lploss: 0.00000
train epoch 782 avg loss: 0.08709 (A-MSE: 0.07545) avg lploss: 0.00000
train epoch 783 avg loss: 0.08477 (A-MSE: 0.07410) avg lploss: 0.00000
train epoch 784 avg loss: 0.08160 (A-MSE: 0.07084) avg lploss: 0.00000
train epoch 785 avg loss: 0.07740 (A-MSE: 0.06700) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.13171 (A-MSE: 0.11549) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.10653 (A-MSE: 0.09240) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 12 out of 50
train epoch 786 avg loss: 0.07481 (A-MSE: 0.06494) avg lploss: 0.00000
train epoch 787 avg loss: 0.08053 (A-MSE: 0.07033) avg lploss: 0.00000
train epoch 788 avg loss: 0.08028 (A-MSE: 0.07007) avg lploss: 0.00000
train epoch 789 avg loss: 0.08074 (A-MSE: 0.07019) avg lploss: 0.00000
train epoch 790 avg loss: 0.08098 (A-MSE: 0.07053) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.14228 (A-MSE: 0.12529) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.11038 (A-MSE: 0.09663) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 13 out of 50
train epoch 791 avg loss: 0.08102 (A-MSE: 0.07062) avg lploss: 0.00000
train epoch 792 avg loss: 0.08404 (A-MSE: 0.07343) avg lploss: 0.00000
train epoch 793 avg loss: 0.08136 (A-MSE: 0.07108) avg lploss: 0.00000
train epoch 794 avg loss: 0.08645 (A-MSE: 0.07495) avg lploss: 0.00000
train epoch 795 avg loss: 0.07665 (A-MSE: 0.06715) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.13772 (A-MSE: 0.11889) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.10618 (A-MSE: 0.08948) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 14 out of 50
train epoch 796 avg loss: 0.07572 (A-MSE: 0.06608) avg lploss: 0.00000
train epoch 797 avg loss: 0.09545 (A-MSE: 0.08459) avg lploss: 0.00000
train epoch 798 avg loss: 0.09299 (A-MSE: 0.08105) avg lploss: 0.00000
train epoch 799 avg loss: 0.07915 (A-MSE: 0.06899) avg lploss: 0.00000
train epoch 800 avg loss: 0.08066 (A-MSE: 0.06984) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.14315 (A-MSE: 0.12627) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.11021 (A-MSE: 0.09616) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 15 out of 50
train epoch 801 avg loss: 0.08027 (A-MSE: 0.07007) avg lploss: 0.00000
train epoch 802 avg loss: 0.07866 (A-MSE: 0.06860) avg lploss: 0.00000
train epoch 803 avg loss: 0.08442 (A-MSE: 0.07359) avg lploss: 0.00000
train epoch 804 avg loss: 0.07271 (A-MSE: 0.06322) avg lploss: 0.00000
train epoch 805 avg loss: 0.07650 (A-MSE: 0.06646) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.14372 (A-MSE: 0.12479) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.10305 (A-MSE: 0.08790) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 16 out of 50
train epoch 806 avg loss: 0.07663 (A-MSE: 0.06699) avg lploss: 0.00000
train epoch 807 avg loss: 0.07465 (A-MSE: 0.06505) avg lploss: 0.00000
train epoch 808 avg loss: 0.07095 (A-MSE: 0.06137) avg lploss: 0.00000
train epoch 809 avg loss: 0.07118 (A-MSE: 0.06220) avg lploss: 0.00000
train epoch 810 avg loss: 0.09011 (A-MSE: 0.07826) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.13705 (A-MSE: 0.12107) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.10579 (A-MSE: 0.09206) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 17 out of 50
train epoch 811 avg loss: 0.07473 (A-MSE: 0.06539) avg lploss: 0.00000
train epoch 812 avg loss: 0.06955 (A-MSE: 0.06055) avg lploss: 0.00000
train epoch 813 avg loss: 0.07778 (A-MSE: 0.06847) avg lploss: 0.00000
train epoch 814 avg loss: 0.07194 (A-MSE: 0.06249) avg lploss: 0.00000
train epoch 815 avg loss: 0.07881 (A-MSE: 0.06857) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.16545 (A-MSE: 0.14404) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.13260 (A-MSE: 0.11458) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 18 out of 50
train epoch 816 avg loss: 0.07398 (A-MSE: 0.06456) avg lploss: 0.00000
train epoch 817 avg loss: 0.07292 (A-MSE: 0.06390) avg lploss: 0.00000
train epoch 818 avg loss: 0.07892 (A-MSE: 0.06885) avg lploss: 0.00000
train epoch 819 avg loss: 0.08095 (A-MSE: 0.07092) avg lploss: 0.00000
train epoch 820 avg loss: 0.07161 (A-MSE: 0.06221) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.17049 (A-MSE: 0.14745) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.13267 (A-MSE: 0.11335) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 19 out of 50
train epoch 821 avg loss: 0.07383 (A-MSE: 0.06459) avg lploss: 0.00000
train epoch 822 avg loss: 0.08006 (A-MSE: 0.07003) avg lploss: 0.00000
train epoch 823 avg loss: 0.08026 (A-MSE: 0.07029) avg lploss: 0.00000
train epoch 824 avg loss: 0.09764 (A-MSE: 0.08526) avg lploss: 0.00000
train epoch 825 avg loss: 0.09079 (A-MSE: 0.07970) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.14470 (A-MSE: 0.12533) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.11189 (A-MSE: 0.09604) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 20 out of 50
train epoch 826 avg loss: 0.08239 (A-MSE: 0.07222) avg lploss: 0.00000
train epoch 827 avg loss: 0.08591 (A-MSE: 0.07495) avg lploss: 0.00000
train epoch 828 avg loss: 0.07636 (A-MSE: 0.06581) avg lploss: 0.00000
train epoch 829 avg loss: 0.09072 (A-MSE: 0.07893) avg lploss: 0.00000
train epoch 830 avg loss: 0.08055 (A-MSE: 0.07027) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.15661 (A-MSE: 0.13627) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.11653 (A-MSE: 0.09987) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 21 out of 50
train epoch 831 avg loss: 0.07762 (A-MSE: 0.06764) avg lploss: 0.00000
train epoch 832 avg loss: 0.07058 (A-MSE: 0.06155) avg lploss: 0.00000
train epoch 833 avg loss: 0.07942 (A-MSE: 0.06934) avg lploss: 0.00000
train epoch 834 avg loss: 0.07533 (A-MSE: 0.06588) avg lploss: 0.00000
train epoch 835 avg loss: 0.07790 (A-MSE: 0.06815) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.15823 (A-MSE: 0.13848) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.13026 (A-MSE: 0.11240) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 22 out of 50
train epoch 836 avg loss: 0.06941 (A-MSE: 0.06052) avg lploss: 0.00000
train epoch 837 avg loss: 0.07337 (A-MSE: 0.06391) avg lploss: 0.00000
train epoch 838 avg loss: 0.06719 (A-MSE: 0.05891) avg lploss: 0.00000
train epoch 839 avg loss: 0.06585 (A-MSE: 0.05746) avg lploss: 0.00000
train epoch 840 avg loss: 0.06704 (A-MSE: 0.05837) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.17726 (A-MSE: 0.15384) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.13926 (A-MSE: 0.11842) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 23 out of 50
train epoch 841 avg loss: 0.07450 (A-MSE: 0.06478) avg lploss: 0.00000
train epoch 842 avg loss: 0.06873 (A-MSE: 0.05997) avg lploss: 0.00000
train epoch 843 avg loss: 0.07111 (A-MSE: 0.06167) avg lploss: 0.00000
train epoch 844 avg loss: 0.06701 (A-MSE: 0.05852) avg lploss: 0.00000
train epoch 845 avg loss: 0.07915 (A-MSE: 0.06986) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.13604 (A-MSE: 0.11951) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.10332 (A-MSE: 0.08953) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 24 out of 50
train epoch 846 avg loss: 0.08159 (A-MSE: 0.07141) avg lploss: 0.00000
train epoch 847 avg loss: 0.07639 (A-MSE: 0.06599) avg lploss: 0.00000
train epoch 848 avg loss: 0.08863 (A-MSE: 0.07612) avg lploss: 0.00000
train epoch 849 avg loss: 0.07755 (A-MSE: 0.06801) avg lploss: 0.00000
train epoch 850 avg loss: 0.08214 (A-MSE: 0.07125) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.16066 (A-MSE: 0.14081) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.11194 (A-MSE: 0.09495) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 25 out of 50
train epoch 851 avg loss: 0.07056 (A-MSE: 0.06105) avg lploss: 0.00000
train epoch 852 avg loss: 0.06812 (A-MSE: 0.05940) avg lploss: 0.00000
train epoch 853 avg loss: 0.08792 (A-MSE: 0.07633) avg lploss: 0.00000
train epoch 854 avg loss: 0.12706 (A-MSE: 0.11043) avg lploss: 0.00000
train epoch 855 avg loss: 0.11540 (A-MSE: 0.10032) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.16302 (A-MSE: 0.14133) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.12587 (A-MSE: 0.10796) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 26 out of 50
train epoch 856 avg loss: 0.07922 (A-MSE: 0.06872) avg lploss: 0.00000
train epoch 857 avg loss: 0.07160 (A-MSE: 0.06239) avg lploss: 0.00000
train epoch 858 avg loss: 0.07958 (A-MSE: 0.06915) avg lploss: 0.00000
train epoch 859 avg loss: 0.09162 (A-MSE: 0.07998) avg lploss: 0.00000
train epoch 860 avg loss: 0.06687 (A-MSE: 0.05808) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.13789 (A-MSE: 0.11667) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.10415 (A-MSE: 0.08599) avg lploss: 0.00000
*** Best Val Loss: 0.12853 	 Best Test Loss: 0.10268 	 Best epoch 725
EarlyStopping counter: 27 out of 50
train epoch 861 avg loss: 0.07905 (A-MSE: 0.06898) avg lploss: 0.00000
train epoch 862 avg loss: 0.06814 (A-MSE: 0.05925) avg lploss: 0.00000
train epoch 863 avg loss: 0.06625 (A-MSE: 0.05754) avg lploss: 0.00000
train epoch 864 avg loss: 0.06621 (A-MSE: 0.05801) avg lploss: 0.00000
train epoch 865 avg loss: 0.08020 (A-MSE: 0.07010) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.11278 (A-MSE: 0.09901) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.08366 (A-MSE: 0.07238) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
Validation loss decreased (0.128532 --> 0.112779).  Saving model ...
train epoch 866 avg loss: 0.07163 (A-MSE: 0.06249) avg lploss: 0.00000
train epoch 867 avg loss: 0.06133 (A-MSE: 0.05346) avg lploss: 0.00000
train epoch 868 avg loss: 0.06119 (A-MSE: 0.05313) avg lploss: 0.00000
train epoch 869 avg loss: 0.06970 (A-MSE: 0.06070) avg lploss: 0.00000
train epoch 870 avg loss: 0.06998 (A-MSE: 0.06125) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.12556 (A-MSE: 0.10939) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.08586 (A-MSE: 0.07408) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 1 out of 50
train epoch 871 avg loss: 0.06321 (A-MSE: 0.05502) avg lploss: 0.00000
train epoch 872 avg loss: 0.07051 (A-MSE: 0.06206) avg lploss: 0.00000
train epoch 873 avg loss: 0.07823 (A-MSE: 0.06882) avg lploss: 0.00000
train epoch 874 avg loss: 0.07452 (A-MSE: 0.06483) avg lploss: 0.00000
train epoch 875 avg loss: 0.06397 (A-MSE: 0.05583) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.14641 (A-MSE: 0.12534) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.11038 (A-MSE: 0.09281) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 2 out of 50
train epoch 876 avg loss: 0.06561 (A-MSE: 0.05702) avg lploss: 0.00000
train epoch 877 avg loss: 0.06959 (A-MSE: 0.06055) avg lploss: 0.00000
train epoch 878 avg loss: 0.06909 (A-MSE: 0.06005) avg lploss: 0.00000
train epoch 879 avg loss: 0.06373 (A-MSE: 0.05549) avg lploss: 0.00000
train epoch 880 avg loss: 0.06751 (A-MSE: 0.05896) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.15381 (A-MSE: 0.13378) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.11849 (A-MSE: 0.10153) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 3 out of 50
train epoch 881 avg loss: 0.08174 (A-MSE: 0.07170) avg lploss: 0.00000
train epoch 882 avg loss: 0.07298 (A-MSE: 0.06385) avg lploss: 0.00000
train epoch 883 avg loss: 0.07078 (A-MSE: 0.06128) avg lploss: 0.00000
train epoch 884 avg loss: 0.06717 (A-MSE: 0.05860) avg lploss: 0.00000
train epoch 885 avg loss: 0.06791 (A-MSE: 0.05925) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.13054 (A-MSE: 0.11347) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.09744 (A-MSE: 0.08346) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 4 out of 50
train epoch 886 avg loss: 0.07614 (A-MSE: 0.06659) avg lploss: 0.00000
train epoch 887 avg loss: 0.08315 (A-MSE: 0.07214) avg lploss: 0.00000
train epoch 888 avg loss: 0.07466 (A-MSE: 0.06531) avg lploss: 0.00000
train epoch 889 avg loss: 0.07107 (A-MSE: 0.06237) avg lploss: 0.00000
train epoch 890 avg loss: 0.06411 (A-MSE: 0.05614) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.13321 (A-MSE: 0.11588) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.09689 (A-MSE: 0.08388) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 5 out of 50
train epoch 891 avg loss: 0.07967 (A-MSE: 0.06934) avg lploss: 0.00000
train epoch 892 avg loss: 0.07393 (A-MSE: 0.06460) avg lploss: 0.00000
train epoch 893 avg loss: 0.07584 (A-MSE: 0.06600) avg lploss: 0.00000
train epoch 894 avg loss: 0.06295 (A-MSE: 0.05506) avg lploss: 0.00000
train epoch 895 avg loss: 0.06349 (A-MSE: 0.05511) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.14366 (A-MSE: 0.12430) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.10800 (A-MSE: 0.09235) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 6 out of 50
train epoch 896 avg loss: 0.06502 (A-MSE: 0.05665) avg lploss: 0.00000
train epoch 897 avg loss: 0.06314 (A-MSE: 0.05513) avg lploss: 0.00000
train epoch 898 avg loss: 0.06710 (A-MSE: 0.05887) avg lploss: 0.00000
train epoch 899 avg loss: 0.06605 (A-MSE: 0.05704) avg lploss: 0.00000
train epoch 900 avg loss: 0.06170 (A-MSE: 0.05407) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.14333 (A-MSE: 0.12577) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.10551 (A-MSE: 0.09204) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 7 out of 50
train epoch 901 avg loss: 0.06137 (A-MSE: 0.05349) avg lploss: 0.00000
train epoch 902 avg loss: 0.06018 (A-MSE: 0.05232) avg lploss: 0.00000
train epoch 903 avg loss: 0.05876 (A-MSE: 0.05146) avg lploss: 0.00000
train epoch 904 avg loss: 0.05776 (A-MSE: 0.05025) avg lploss: 0.00000
train epoch 905 avg loss: 0.06017 (A-MSE: 0.05300) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.13686 (A-MSE: 0.11973) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.09544 (A-MSE: 0.08327) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 8 out of 50
train epoch 906 avg loss: 0.07427 (A-MSE: 0.06518) avg lploss: 0.00000
train epoch 907 avg loss: 0.07709 (A-MSE: 0.06720) avg lploss: 0.00000
train epoch 908 avg loss: 0.07688 (A-MSE: 0.06774) avg lploss: 0.00000
train epoch 909 avg loss: 0.07287 (A-MSE: 0.06371) avg lploss: 0.00000
train epoch 910 avg loss: 0.06357 (A-MSE: 0.05496) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.14839 (A-MSE: 0.12823) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.10812 (A-MSE: 0.09317) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 9 out of 50
train epoch 911 avg loss: 0.05819 (A-MSE: 0.05042) avg lploss: 0.00000
train epoch 912 avg loss: 0.07135 (A-MSE: 0.06235) avg lploss: 0.00000
train epoch 913 avg loss: 0.08706 (A-MSE: 0.07585) avg lploss: 0.00000
train epoch 914 avg loss: 0.07626 (A-MSE: 0.06657) avg lploss: 0.00000
train epoch 915 avg loss: 0.06510 (A-MSE: 0.05657) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.14602 (A-MSE: 0.12387) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.10437 (A-MSE: 0.08762) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 10 out of 50
train epoch 916 avg loss: 0.06973 (A-MSE: 0.06077) avg lploss: 0.00000
train epoch 917 avg loss: 0.07294 (A-MSE: 0.06367) avg lploss: 0.00000
train epoch 918 avg loss: 0.08433 (A-MSE: 0.07438) avg lploss: 0.00000
train epoch 919 avg loss: 0.08201 (A-MSE: 0.07147) avg lploss: 0.00000
train epoch 920 avg loss: 0.07731 (A-MSE: 0.06767) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.16623 (A-MSE: 0.13770) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.12154 (A-MSE: 0.10095) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 11 out of 50
train epoch 921 avg loss: 0.06660 (A-MSE: 0.05794) avg lploss: 0.00000
train epoch 922 avg loss: 0.06817 (A-MSE: 0.05910) avg lploss: 0.00000
train epoch 923 avg loss: 0.07299 (A-MSE: 0.06362) avg lploss: 0.00000
train epoch 924 avg loss: 0.07322 (A-MSE: 0.06406) avg lploss: 0.00000
train epoch 925 avg loss: 0.07302 (A-MSE: 0.06358) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.14134 (A-MSE: 0.12072) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.10980 (A-MSE: 0.09434) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 12 out of 50
train epoch 926 avg loss: 0.07456 (A-MSE: 0.06464) avg lploss: 0.00000
train epoch 927 avg loss: 0.06738 (A-MSE: 0.05853) avg lploss: 0.00000
train epoch 928 avg loss: 0.06318 (A-MSE: 0.05494) avg lploss: 0.00000
train epoch 929 avg loss: 0.05589 (A-MSE: 0.04866) avg lploss: 0.00000
train epoch 930 avg loss: 0.06083 (A-MSE: 0.05292) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.14102 (A-MSE: 0.12112) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.09396 (A-MSE: 0.08082) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 13 out of 50
train epoch 931 avg loss: 0.06746 (A-MSE: 0.05884) avg lploss: 0.00000
train epoch 932 avg loss: 0.06080 (A-MSE: 0.05284) avg lploss: 0.00000
train epoch 933 avg loss: 0.06295 (A-MSE: 0.05529) avg lploss: 0.00000
train epoch 934 avg loss: 0.06701 (A-MSE: 0.05864) avg lploss: 0.00000
train epoch 935 avg loss: 0.06112 (A-MSE: 0.05308) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.14559 (A-MSE: 0.12404) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.10997 (A-MSE: 0.09395) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 14 out of 50
train epoch 936 avg loss: 0.05882 (A-MSE: 0.05132) avg lploss: 0.00000
train epoch 937 avg loss: 0.06557 (A-MSE: 0.05759) avg lploss: 0.00000
train epoch 938 avg loss: 0.07184 (A-MSE: 0.06274) avg lploss: 0.00000
train epoch 939 avg loss: 0.07585 (A-MSE: 0.06596) avg lploss: 0.00000
train epoch 940 avg loss: 0.06567 (A-MSE: 0.05748) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.15103 (A-MSE: 0.12822) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.10403 (A-MSE: 0.08867) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 15 out of 50
train epoch 941 avg loss: 0.06585 (A-MSE: 0.05737) avg lploss: 0.00000
train epoch 942 avg loss: 0.07070 (A-MSE: 0.06176) avg lploss: 0.00000
train epoch 943 avg loss: 0.06887 (A-MSE: 0.05996) avg lploss: 0.00000
train epoch 944 avg loss: 0.05992 (A-MSE: 0.05192) avg lploss: 0.00000
train epoch 945 avg loss: 0.05518 (A-MSE: 0.04835) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.15771 (A-MSE: 0.13754) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.11253 (A-MSE: 0.09678) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 16 out of 50
train epoch 946 avg loss: 0.06373 (A-MSE: 0.05629) avg lploss: 0.00000
train epoch 947 avg loss: 0.06304 (A-MSE: 0.05451) avg lploss: 0.00000
train epoch 948 avg loss: 0.05667 (A-MSE: 0.04923) avg lploss: 0.00000
train epoch 949 avg loss: 0.05509 (A-MSE: 0.04802) avg lploss: 0.00000
train epoch 950 avg loss: 0.06181 (A-MSE: 0.05426) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.13494 (A-MSE: 0.12019) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.08906 (A-MSE: 0.07809) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 17 out of 50
train epoch 951 avg loss: 0.06278 (A-MSE: 0.05461) avg lploss: 0.00000
train epoch 952 avg loss: 0.06249 (A-MSE: 0.05446) avg lploss: 0.00000
train epoch 953 avg loss: 0.05850 (A-MSE: 0.05093) avg lploss: 0.00000
train epoch 954 avg loss: 0.06504 (A-MSE: 0.05751) avg lploss: 0.00000
train epoch 955 avg loss: 0.06287 (A-MSE: 0.05452) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.14541 (A-MSE: 0.12774) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.10629 (A-MSE: 0.09338) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 18 out of 50
train epoch 956 avg loss: 0.06477 (A-MSE: 0.05657) avg lploss: 0.00000
train epoch 957 avg loss: 0.07723 (A-MSE: 0.06668) avg lploss: 0.00000
train epoch 958 avg loss: 0.07494 (A-MSE: 0.06553) avg lploss: 0.00000
train epoch 959 avg loss: 0.05806 (A-MSE: 0.05053) avg lploss: 0.00000
train epoch 960 avg loss: 0.05752 (A-MSE: 0.05019) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.16189 (A-MSE: 0.14081) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.12150 (A-MSE: 0.10408) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 19 out of 50
train epoch 961 avg loss: 0.06493 (A-MSE: 0.05655) avg lploss: 0.00000
train epoch 962 avg loss: 0.06484 (A-MSE: 0.05615) avg lploss: 0.00000
train epoch 963 avg loss: 0.05977 (A-MSE: 0.05211) avg lploss: 0.00000
train epoch 964 avg loss: 0.06148 (A-MSE: 0.05363) avg lploss: 0.00000
train epoch 965 avg loss: 0.05993 (A-MSE: 0.05222) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.16262 (A-MSE: 0.14315) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.10473 (A-MSE: 0.09090) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 20 out of 50
train epoch 966 avg loss: 0.06363 (A-MSE: 0.05588) avg lploss: 0.00000
train epoch 967 avg loss: 0.06952 (A-MSE: 0.06103) avg lploss: 0.00000
train epoch 968 avg loss: 0.06922 (A-MSE: 0.06032) avg lploss: 0.00000
train epoch 969 avg loss: 0.06981 (A-MSE: 0.06148) avg lploss: 0.00000
train epoch 970 avg loss: 0.05766 (A-MSE: 0.04996) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.12991 (A-MSE: 0.11287) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.08656 (A-MSE: 0.07357) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 21 out of 50
train epoch 971 avg loss: 0.06033 (A-MSE: 0.05271) avg lploss: 0.00000
train epoch 972 avg loss: 0.06223 (A-MSE: 0.05402) avg lploss: 0.00000
train epoch 973 avg loss: 0.05865 (A-MSE: 0.05141) avg lploss: 0.00000
train epoch 974 avg loss: 0.05819 (A-MSE: 0.05075) avg lploss: 0.00000
train epoch 975 avg loss: 0.05960 (A-MSE: 0.05235) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.13317 (A-MSE: 0.11397) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.08915 (A-MSE: 0.07623) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 22 out of 50
train epoch 976 avg loss: 0.05924 (A-MSE: 0.05156) avg lploss: 0.00000
train epoch 977 avg loss: 0.06508 (A-MSE: 0.05714) avg lploss: 0.00000
train epoch 978 avg loss: 0.06421 (A-MSE: 0.05559) avg lploss: 0.00000
train epoch 979 avg loss: 0.05662 (A-MSE: 0.04933) avg lploss: 0.00000
train epoch 980 avg loss: 0.06524 (A-MSE: 0.05688) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.14429 (A-MSE: 0.12419) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.09487 (A-MSE: 0.08129) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 23 out of 50
train epoch 981 avg loss: 0.06665 (A-MSE: 0.05806) avg lploss: 0.00000
train epoch 982 avg loss: 0.06324 (A-MSE: 0.05547) avg lploss: 0.00000
train epoch 983 avg loss: 0.05957 (A-MSE: 0.05191) avg lploss: 0.00000
train epoch 984 avg loss: 0.06222 (A-MSE: 0.05455) avg lploss: 0.00000
train epoch 985 avg loss: 0.06506 (A-MSE: 0.05700) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.13612 (A-MSE: 0.11582) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.09080 (A-MSE: 0.07856) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 24 out of 50
train epoch 986 avg loss: 0.05762 (A-MSE: 0.05005) avg lploss: 0.00000
train epoch 987 avg loss: 0.05498 (A-MSE: 0.04816) avg lploss: 0.00000
train epoch 988 avg loss: 0.04908 (A-MSE: 0.04287) avg lploss: 0.00000
train epoch 989 avg loss: 0.05045 (A-MSE: 0.04373) avg lploss: 0.00000
train epoch 990 avg loss: 0.05613 (A-MSE: 0.04911) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.12775 (A-MSE: 0.11020) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.08340 (A-MSE: 0.07128) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 25 out of 50
train epoch 991 avg loss: 0.05798 (A-MSE: 0.05035) avg lploss: 0.00000
train epoch 992 avg loss: 0.07910 (A-MSE: 0.06888) avg lploss: 0.00000
train epoch 993 avg loss: 0.07381 (A-MSE: 0.06447) avg lploss: 0.00000
train epoch 994 avg loss: 0.07315 (A-MSE: 0.06374) avg lploss: 0.00000
train epoch 995 avg loss: 0.06880 (A-MSE: 0.06081) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.14248 (A-MSE: 0.12179) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.09724 (A-MSE: 0.08124) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 26 out of 50
train epoch 996 avg loss: 0.06270 (A-MSE: 0.05428) avg lploss: 0.00000
train epoch 997 avg loss: 0.07663 (A-MSE: 0.06673) avg lploss: 0.00000
train epoch 998 avg loss: 0.06636 (A-MSE: 0.05828) avg lploss: 0.00000
train epoch 999 avg loss: 0.05968 (A-MSE: 0.05175) avg lploss: 0.00000
train epoch 1000 avg loss: 0.05488 (A-MSE: 0.04776) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.13150 (A-MSE: 0.11182) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.08268 (A-MSE: 0.07215) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 27 out of 50
train epoch 1001 avg loss: 0.05185 (A-MSE: 0.04524) avg lploss: 0.00000
train epoch 1002 avg loss: 0.05065 (A-MSE: 0.04428) avg lploss: 0.00000
train epoch 1003 avg loss: 0.05057 (A-MSE: 0.04429) avg lploss: 0.00000
train epoch 1004 avg loss: 0.06282 (A-MSE: 0.05455) avg lploss: 0.00000
train epoch 1005 avg loss: 0.06263 (A-MSE: 0.05525) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.12809 (A-MSE: 0.11055) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.08803 (A-MSE: 0.07445) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 28 out of 50
train epoch 1006 avg loss: 0.06198 (A-MSE: 0.05415) avg lploss: 0.00000
train epoch 1007 avg loss: 0.06042 (A-MSE: 0.05307) avg lploss: 0.00000
train epoch 1008 avg loss: 0.05864 (A-MSE: 0.05090) avg lploss: 0.00000
train epoch 1009 avg loss: 0.05406 (A-MSE: 0.04731) avg lploss: 0.00000
train epoch 1010 avg loss: 0.05589 (A-MSE: 0.04876) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.14201 (A-MSE: 0.12265) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.08969 (A-MSE: 0.07612) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 29 out of 50
train epoch 1011 avg loss: 0.05516 (A-MSE: 0.04808) avg lploss: 0.00000
train epoch 1012 avg loss: 0.05842 (A-MSE: 0.05061) avg lploss: 0.00000
train epoch 1013 avg loss: 0.05916 (A-MSE: 0.05207) avg lploss: 0.00000
train epoch 1014 avg loss: 0.05359 (A-MSE: 0.04723) avg lploss: 0.00000
train epoch 1015 avg loss: 0.05706 (A-MSE: 0.04972) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.12967 (A-MSE: 0.11244) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.08156 (A-MSE: 0.07167) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 30 out of 50
train epoch 1016 avg loss: 0.05937 (A-MSE: 0.05124) avg lploss: 0.00000
train epoch 1017 avg loss: 0.05010 (A-MSE: 0.04349) avg lploss: 0.00000
train epoch 1018 avg loss: 0.05745 (A-MSE: 0.05042) avg lploss: 0.00000
train epoch 1019 avg loss: 0.07982 (A-MSE: 0.06960) avg lploss: 0.00000
train epoch 1020 avg loss: 0.06769 (A-MSE: 0.05981) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.14329 (A-MSE: 0.12378) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.10517 (A-MSE: 0.09009) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 31 out of 50
train epoch 1021 avg loss: 0.05662 (A-MSE: 0.04962) avg lploss: 0.00000
train epoch 1022 avg loss: 0.06108 (A-MSE: 0.05317) avg lploss: 0.00000
train epoch 1023 avg loss: 0.05608 (A-MSE: 0.04900) avg lploss: 0.00000
train epoch 1024 avg loss: 0.05493 (A-MSE: 0.04794) avg lploss: 0.00000
train epoch 1025 avg loss: 0.05463 (A-MSE: 0.04795) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.14229 (A-MSE: 0.11858) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.09069 (A-MSE: 0.07649) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 32 out of 50
train epoch 1026 avg loss: 0.06074 (A-MSE: 0.05319) avg lploss: 0.00000
train epoch 1027 avg loss: 0.06301 (A-MSE: 0.05525) avg lploss: 0.00000
train epoch 1028 avg loss: 0.05925 (A-MSE: 0.05165) avg lploss: 0.00000
train epoch 1029 avg loss: 0.04919 (A-MSE: 0.04292) avg lploss: 0.00000
train epoch 1030 avg loss: 0.05000 (A-MSE: 0.04331) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.16384 (A-MSE: 0.13843) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.10550 (A-MSE: 0.09154) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 33 out of 50
train epoch 1031 avg loss: 0.05018 (A-MSE: 0.04402) avg lploss: 0.00000
train epoch 1032 avg loss: 0.05103 (A-MSE: 0.04435) avg lploss: 0.00000
train epoch 1033 avg loss: 0.05322 (A-MSE: 0.04634) avg lploss: 0.00000
train epoch 1034 avg loss: 0.05321 (A-MSE: 0.04634) avg lploss: 0.00000
train epoch 1035 avg loss: 0.06641 (A-MSE: 0.05775) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.17161 (A-MSE: 0.14488) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.12281 (A-MSE: 0.10410) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 34 out of 50
train epoch 1036 avg loss: 0.07469 (A-MSE: 0.06511) avg lploss: 0.00000
train epoch 1037 avg loss: 0.06961 (A-MSE: 0.06038) avg lploss: 0.00000
train epoch 1038 avg loss: 0.06898 (A-MSE: 0.06061) avg lploss: 0.00000
train epoch 1039 avg loss: 0.05612 (A-MSE: 0.04887) avg lploss: 0.00000
train epoch 1040 avg loss: 0.04975 (A-MSE: 0.04340) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.13659 (A-MSE: 0.11697) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.08792 (A-MSE: 0.07547) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 35 out of 50
train epoch 1041 avg loss: 0.04981 (A-MSE: 0.04329) avg lploss: 0.00000
train epoch 1042 avg loss: 0.05746 (A-MSE: 0.05058) avg lploss: 0.00000
train epoch 1043 avg loss: 0.06015 (A-MSE: 0.05258) avg lploss: 0.00000
train epoch 1044 avg loss: 0.05928 (A-MSE: 0.05196) avg lploss: 0.00000
train epoch 1045 avg loss: 0.05636 (A-MSE: 0.04935) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.13342 (A-MSE: 0.11530) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.08532 (A-MSE: 0.07362) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 36 out of 50
train epoch 1046 avg loss: 0.05504 (A-MSE: 0.04780) avg lploss: 0.00000
train epoch 1047 avg loss: 0.05372 (A-MSE: 0.04698) avg lploss: 0.00000
train epoch 1048 avg loss: 0.04852 (A-MSE: 0.04259) avg lploss: 0.00000
train epoch 1049 avg loss: 0.04787 (A-MSE: 0.04230) avg lploss: 0.00000
train epoch 1050 avg loss: 0.04746 (A-MSE: 0.04119) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.13821 (A-MSE: 0.11859) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.09097 (A-MSE: 0.07825) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 37 out of 50
train epoch 1051 avg loss: 0.04763 (A-MSE: 0.04144) avg lploss: 0.00000
train epoch 1052 avg loss: 0.04646 (A-MSE: 0.04078) avg lploss: 0.00000
train epoch 1053 avg loss: 0.04273 (A-MSE: 0.03723) avg lploss: 0.00000
train epoch 1054 avg loss: 0.04411 (A-MSE: 0.03863) avg lploss: 0.00000
train epoch 1055 avg loss: 0.04511 (A-MSE: 0.03941) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.14581 (A-MSE: 0.11902) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.08264 (A-MSE: 0.07045) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 38 out of 50
train epoch 1056 avg loss: 0.05039 (A-MSE: 0.04393) avg lploss: 0.00000
train epoch 1057 avg loss: 0.04643 (A-MSE: 0.04094) avg lploss: 0.00000
train epoch 1058 avg loss: 0.04825 (A-MSE: 0.04217) avg lploss: 0.00000
train epoch 1059 avg loss: 0.06629 (A-MSE: 0.05822) avg lploss: 0.00000
train epoch 1060 avg loss: 0.06182 (A-MSE: 0.05373) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.15186 (A-MSE: 0.12642) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.10633 (A-MSE: 0.08669) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 39 out of 50
train epoch 1061 avg loss: 0.05599 (A-MSE: 0.04913) avg lploss: 0.00000
train epoch 1062 avg loss: 0.05862 (A-MSE: 0.05089) avg lploss: 0.00000
train epoch 1063 avg loss: 0.05030 (A-MSE: 0.04407) avg lploss: 0.00000
train epoch 1064 avg loss: 0.05416 (A-MSE: 0.04743) avg lploss: 0.00000
train epoch 1065 avg loss: 0.04783 (A-MSE: 0.04174) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.15046 (A-MSE: 0.13065) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.09696 (A-MSE: 0.08287) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 40 out of 50
train epoch 1066 avg loss: 0.05391 (A-MSE: 0.04717) avg lploss: 0.00000
train epoch 1067 avg loss: 0.05410 (A-MSE: 0.04734) avg lploss: 0.00000
train epoch 1068 avg loss: 0.04659 (A-MSE: 0.04051) avg lploss: 0.00000
train epoch 1069 avg loss: 0.07168 (A-MSE: 0.06332) avg lploss: 0.00000
train epoch 1070 avg loss: 0.05469 (A-MSE: 0.04734) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.14532 (A-MSE: 0.12394) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.09737 (A-MSE: 0.08370) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 41 out of 50
train epoch 1071 avg loss: 0.05072 (A-MSE: 0.04486) avg lploss: 0.00000
train epoch 1072 avg loss: 0.05068 (A-MSE: 0.04442) avg lploss: 0.00000
train epoch 1073 avg loss: 0.05312 (A-MSE: 0.04678) avg lploss: 0.00000
train epoch 1074 avg loss: 0.06062 (A-MSE: 0.05245) avg lploss: 0.00000
train epoch 1075 avg loss: 0.05177 (A-MSE: 0.04513) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.16373 (A-MSE: 0.13604) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.09893 (A-MSE: 0.08268) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 42 out of 50
train epoch 1076 avg loss: 0.04563 (A-MSE: 0.03991) avg lploss: 0.00000
train epoch 1077 avg loss: 0.05289 (A-MSE: 0.04525) avg lploss: 0.00000
train epoch 1078 avg loss: 0.04966 (A-MSE: 0.04365) avg lploss: 0.00000
train epoch 1079 avg loss: 0.04682 (A-MSE: 0.04105) avg lploss: 0.00000
train epoch 1080 avg loss: 0.05177 (A-MSE: 0.04483) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.13360 (A-MSE: 0.11503) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.09172 (A-MSE: 0.07969) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 43 out of 50
train epoch 1081 avg loss: 0.05374 (A-MSE: 0.04719) avg lploss: 0.00000
train epoch 1082 avg loss: 0.05966 (A-MSE: 0.05205) avg lploss: 0.00000
train epoch 1083 avg loss: 0.06163 (A-MSE: 0.05374) avg lploss: 0.00000
train epoch 1084 avg loss: 0.05653 (A-MSE: 0.04918) avg lploss: 0.00000
train epoch 1085 avg loss: 0.05373 (A-MSE: 0.04682) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.12778 (A-MSE: 0.11131) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.08349 (A-MSE: 0.07267) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 44 out of 50
train epoch 1086 avg loss: 0.04664 (A-MSE: 0.04059) avg lploss: 0.00000
train epoch 1087 avg loss: 0.05033 (A-MSE: 0.04417) avg lploss: 0.00000
train epoch 1088 avg loss: 0.04765 (A-MSE: 0.04147) avg lploss: 0.00000
train epoch 1089 avg loss: 0.04395 (A-MSE: 0.03844) avg lploss: 0.00000
train epoch 1090 avg loss: 0.05007 (A-MSE: 0.04394) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.14715 (A-MSE: 0.12109) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.08216 (A-MSE: 0.07113) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 45 out of 50
train epoch 1091 avg loss: 0.04865 (A-MSE: 0.04237) avg lploss: 0.00000
train epoch 1092 avg loss: 0.04250 (A-MSE: 0.03722) avg lploss: 0.00000
train epoch 1093 avg loss: 0.05145 (A-MSE: 0.04467) avg lploss: 0.00000
train epoch 1094 avg loss: 0.04642 (A-MSE: 0.04065) avg lploss: 0.00000
train epoch 1095 avg loss: 0.04815 (A-MSE: 0.04217) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.14989 (A-MSE: 0.12704) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.10144 (A-MSE: 0.08728) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 46 out of 50
train epoch 1096 avg loss: 0.05525 (A-MSE: 0.04834) avg lploss: 0.00000
train epoch 1097 avg loss: 0.05614 (A-MSE: 0.04929) avg lploss: 0.00000
train epoch 1098 avg loss: 0.06177 (A-MSE: 0.05434) avg lploss: 0.00000
train epoch 1099 avg loss: 0.05404 (A-MSE: 0.04737) avg lploss: 0.00000
train epoch 1100 avg loss: 0.04648 (A-MSE: 0.04054) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.13394 (A-MSE: 0.11324) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.08550 (A-MSE: 0.07409) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 47 out of 50
train epoch 1101 avg loss: 0.04773 (A-MSE: 0.04186) avg lploss: 0.00000
train epoch 1102 avg loss: 0.04520 (A-MSE: 0.03964) avg lploss: 0.00000
train epoch 1103 avg loss: 0.04533 (A-MSE: 0.03958) avg lploss: 0.00000
train epoch 1104 avg loss: 0.04702 (A-MSE: 0.04116) avg lploss: 0.00000
train epoch 1105 avg loss: 0.04529 (A-MSE: 0.03955) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.13556 (A-MSE: 0.11749) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.08791 (A-MSE: 0.07657) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 48 out of 50
train epoch 1106 avg loss: 0.04485 (A-MSE: 0.03930) avg lploss: 0.00000
train epoch 1107 avg loss: 0.05022 (A-MSE: 0.04361) avg lploss: 0.00000
train epoch 1108 avg loss: 0.04520 (A-MSE: 0.03890) avg lploss: 0.00000
train epoch 1109 avg loss: 0.04830 (A-MSE: 0.04205) avg lploss: 0.00000
train epoch 1110 avg loss: 0.04750 (A-MSE: 0.04135) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.15852 (A-MSE: 0.13979) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.10842 (A-MSE: 0.09519) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 49 out of 50
train epoch 1111 avg loss: 0.04564 (A-MSE: 0.03992) avg lploss: 0.00000
train epoch 1112 avg loss: 0.05151 (A-MSE: 0.04517) avg lploss: 0.00000
train epoch 1113 avg loss: 0.05651 (A-MSE: 0.04934) avg lploss: 0.00000
train epoch 1114 avg loss: 0.05833 (A-MSE: 0.05060) avg lploss: 0.00000
train epoch 1115 avg loss: 0.06504 (A-MSE: 0.05686) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.15065 (A-MSE: 0.12562) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.09179 (A-MSE: 0.07865) avg lploss: 0.00000
*** Best Val Loss: 0.11278 	 Best Test Loss: 0.08366 	 Best epoch 865
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.080200
best_lp = 0.000000
best_val = 0.112779
best_test = 0.083658
best_epoch = 865
best_train = 0.080200, best_lp = 0.000000, best_val = 0.112779, best_test = 0.083658, best_epoch = 865
Job completed at Sat Dec  6 08:19:58 CET 2025
