Running Mocap-Run with num_modes=1 for seed 5
Job ID: 3830606, Array Task ID: 5
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes1_seed5.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes1_seed5', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=1, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=5, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes1_seed5/saved_model.pth
train epoch 0 avg loss: 4178.37034 (A-MSE: 4281.58665) avg lploss: 0.00000
==> val epoch 0 avg loss: 96.51651 (A-MSE: 85.17542) avg lploss: 0.00000
==> test epoch 0 avg loss: 91.85157 (A-MSE: 81.06605) avg lploss: 0.00000
*** Best Val Loss: 96.51651 	 Best Test Loss: 91.85157 	 Best epoch 0
Validation loss decreased (inf --> 96.516515).  Saving model ...
train epoch 1 avg loss: 120.27795 (A-MSE: 107.84760) avg lploss: 0.00000
train epoch 2 avg loss: 93.74119 (A-MSE: 82.61694) avg lploss: 0.00000
train epoch 3 avg loss: 90.72535 (A-MSE: 80.00561) avg lploss: 0.00000
train epoch 4 avg loss: 87.56477 (A-MSE: 77.21504) avg lploss: 0.00000
train epoch 5 avg loss: 82.27284 (A-MSE: 72.60948) avg lploss: 0.00000
==> val epoch 5 avg loss: 79.86147 (A-MSE: 70.36268) avg lploss: 0.00000
==> test epoch 5 avg loss: 75.55628 (A-MSE: 66.58987) avg lploss: 0.00000
*** Best Val Loss: 79.86147 	 Best Test Loss: 75.55628 	 Best epoch 5
Validation loss decreased (96.516515 --> 79.861467).  Saving model ...
train epoch 6 avg loss: 74.13827 (A-MSE: 65.21916) avg lploss: 0.00000
train epoch 7 avg loss: 61.25948 (A-MSE: 53.56914) avg lploss: 0.00000
train epoch 8 avg loss: 45.72513 (A-MSE: 39.84476) avg lploss: 0.00000
train epoch 9 avg loss: 37.72169 (A-MSE: 32.65849) avg lploss: 0.00000
train epoch 10 avg loss: 33.48824 (A-MSE: 29.03738) avg lploss: 0.00000
==> val epoch 10 avg loss: 33.88774 (A-MSE: 29.47219) avg lploss: 0.00000
==> test epoch 10 avg loss: 32.16808 (A-MSE: 28.00968) avg lploss: 0.00000
*** Best Val Loss: 33.88774 	 Best Test Loss: 32.16808 	 Best epoch 10
Validation loss decreased (79.861467 --> 33.887736).  Saving model ...
train epoch 11 avg loss: 31.38946 (A-MSE: 27.18657) avg lploss: 0.00000
train epoch 12 avg loss: 29.10749 (A-MSE: 25.20094) avg lploss: 0.00000
train epoch 13 avg loss: 27.30615 (A-MSE: 23.69063) avg lploss: 0.00000
train epoch 14 avg loss: 26.07809 (A-MSE: 22.60402) avg lploss: 0.00000
train epoch 15 avg loss: 24.86890 (A-MSE: 21.59343) avg lploss: 0.00000
==> val epoch 15 avg loss: 22.76207 (A-MSE: 19.60732) avg lploss: 0.00000
==> test epoch 15 avg loss: 21.61066 (A-MSE: 18.59556) avg lploss: 0.00000
*** Best Val Loss: 22.76207 	 Best Test Loss: 21.61066 	 Best epoch 15
Validation loss decreased (33.887736 --> 22.762072).  Saving model ...
train epoch 16 avg loss: 23.47804 (A-MSE: 20.39886) avg lploss: 0.00000
train epoch 17 avg loss: 22.21167 (A-MSE: 19.31894) avg lploss: 0.00000
train epoch 18 avg loss: 21.22359 (A-MSE: 18.48550) avg lploss: 0.00000
train epoch 19 avg loss: 19.97708 (A-MSE: 17.40442) avg lploss: 0.00000
train epoch 20 avg loss: 19.30596 (A-MSE: 16.82276) avg lploss: 0.00000
==> val epoch 20 avg loss: 18.07165 (A-MSE: 15.83303) avg lploss: 0.00000
==> test epoch 20 avg loss: 16.90038 (A-MSE: 14.74470) avg lploss: 0.00000
*** Best Val Loss: 18.07165 	 Best Test Loss: 16.90038 	 Best epoch 20
Validation loss decreased (22.762072 --> 18.071649).  Saving model ...
train epoch 21 avg loss: 18.40839 (A-MSE: 16.08299) avg lploss: 0.00000
train epoch 22 avg loss: 17.75496 (A-MSE: 15.56052) avg lploss: 0.00000
train epoch 23 avg loss: 17.33751 (A-MSE: 15.11030) avg lploss: 0.00000
train epoch 24 avg loss: 16.91541 (A-MSE: 14.80262) avg lploss: 0.00000
train epoch 25 avg loss: 16.52068 (A-MSE: 14.47967) avg lploss: 0.00000
==> val epoch 25 avg loss: 16.34286 (A-MSE: 14.12880) avg lploss: 0.00000
==> test epoch 25 avg loss: 15.56068 (A-MSE: 13.43264) avg lploss: 0.00000
*** Best Val Loss: 16.34286 	 Best Test Loss: 15.56068 	 Best epoch 25
Validation loss decreased (18.071649 --> 16.342862).  Saving model ...
train epoch 26 avg loss: 16.27744 (A-MSE: 14.25091) avg lploss: 0.00000
train epoch 27 avg loss: 16.16823 (A-MSE: 14.13901) avg lploss: 0.00000
train epoch 28 avg loss: 15.85079 (A-MSE: 13.86854) avg lploss: 0.00000
train epoch 29 avg loss: 15.27867 (A-MSE: 13.38437) avg lploss: 0.00000
train epoch 30 avg loss: 14.79772 (A-MSE: 12.95077) avg lploss: 0.00000
==> val epoch 30 avg loss: 13.92081 (A-MSE: 12.08178) avg lploss: 0.00000
==> test epoch 30 avg loss: 13.35077 (A-MSE: 11.57228) avg lploss: 0.00000
*** Best Val Loss: 13.92081 	 Best Test Loss: 13.35077 	 Best epoch 30
Validation loss decreased (16.342862 --> 13.920805).  Saving model ...
train epoch 31 avg loss: 14.65648 (A-MSE: 12.85601) avg lploss: 0.00000
train epoch 32 avg loss: 14.99955 (A-MSE: 13.15051) avg lploss: 0.00000
train epoch 33 avg loss: 14.44757 (A-MSE: 12.63173) avg lploss: 0.00000
train epoch 34 avg loss: 14.09532 (A-MSE: 12.37050) avg lploss: 0.00000
train epoch 35 avg loss: 13.73206 (A-MSE: 12.04325) avg lploss: 0.00000
==> val epoch 35 avg loss: 13.10460 (A-MSE: 11.42647) avg lploss: 0.00000
==> test epoch 35 avg loss: 12.47119 (A-MSE: 10.86380) avg lploss: 0.00000
*** Best Val Loss: 13.10460 	 Best Test Loss: 12.47119 	 Best epoch 35
Validation loss decreased (13.920805 --> 13.104604).  Saving model ...
train epoch 36 avg loss: 13.67006 (A-MSE: 11.98409) avg lploss: 0.00000
train epoch 37 avg loss: 13.41071 (A-MSE: 11.75647) avg lploss: 0.00000
train epoch 38 avg loss: 13.16142 (A-MSE: 11.51896) avg lploss: 0.00000
train epoch 39 avg loss: 13.31676 (A-MSE: 11.69983) avg lploss: 0.00000
train epoch 40 avg loss: 12.84985 (A-MSE: 11.28933) avg lploss: 0.00000
==> val epoch 40 avg loss: 12.60808 (A-MSE: 10.85907) avg lploss: 0.00000
==> test epoch 40 avg loss: 12.03809 (A-MSE: 10.37567) avg lploss: 0.00000
*** Best Val Loss: 12.60808 	 Best Test Loss: 12.03809 	 Best epoch 40
Validation loss decreased (13.104604 --> 12.608075).  Saving model ...
train epoch 41 avg loss: 13.05389 (A-MSE: 11.46507) avg lploss: 0.00000
train epoch 42 avg loss: 12.32793 (A-MSE: 10.79749) avg lploss: 0.00000
train epoch 43 avg loss: 12.38528 (A-MSE: 10.87016) avg lploss: 0.00000
train epoch 44 avg loss: 12.60356 (A-MSE: 11.05321) avg lploss: 0.00000
train epoch 45 avg loss: 11.90450 (A-MSE: 10.45349) avg lploss: 0.00000
==> val epoch 45 avg loss: 11.68504 (A-MSE: 9.99645) avg lploss: 0.00000
==> test epoch 45 avg loss: 11.11145 (A-MSE: 9.51639) avg lploss: 0.00000
*** Best Val Loss: 11.68504 	 Best Test Loss: 11.11145 	 Best epoch 45
Validation loss decreased (12.608075 --> 11.685045).  Saving model ...
train epoch 46 avg loss: 11.64093 (A-MSE: 10.22678) avg lploss: 0.00000
train epoch 47 avg loss: 11.39749 (A-MSE: 10.00197) avg lploss: 0.00000
train epoch 48 avg loss: 11.61145 (A-MSE: 10.20392) avg lploss: 0.00000
train epoch 49 avg loss: 11.56000 (A-MSE: 10.19367) avg lploss: 0.00000
train epoch 50 avg loss: 11.35079 (A-MSE: 9.97624) avg lploss: 0.00000
==> val epoch 50 avg loss: 10.84709 (A-MSE: 9.59057) avg lploss: 0.00000
==> test epoch 50 avg loss: 10.14832 (A-MSE: 8.96844) avg lploss: 0.00000
*** Best Val Loss: 10.84709 	 Best Test Loss: 10.14832 	 Best epoch 50
Validation loss decreased (11.685045 --> 10.847092).  Saving model ...
train epoch 51 avg loss: 11.17336 (A-MSE: 9.80523) avg lploss: 0.00000
train epoch 52 avg loss: 11.07259 (A-MSE: 9.71688) avg lploss: 0.00000
train epoch 53 avg loss: 10.64045 (A-MSE: 9.36524) avg lploss: 0.00000
train epoch 54 avg loss: 10.45431 (A-MSE: 9.17441) avg lploss: 0.00000
train epoch 55 avg loss: 10.53928 (A-MSE: 9.28108) avg lploss: 0.00000
==> val epoch 55 avg loss: 9.96243 (A-MSE: 8.71758) avg lploss: 0.00000
==> test epoch 55 avg loss: 9.40792 (A-MSE: 8.25381) avg lploss: 0.00000
*** Best Val Loss: 9.96243 	 Best Test Loss: 9.40792 	 Best epoch 55
Validation loss decreased (10.847092 --> 9.962430).  Saving model ...
train epoch 56 avg loss: 10.79128 (A-MSE: 9.50254) avg lploss: 0.00000
train epoch 57 avg loss: 10.54783 (A-MSE: 9.28082) avg lploss: 0.00000
train epoch 58 avg loss: 10.76948 (A-MSE: 9.47911) avg lploss: 0.00000
train epoch 59 avg loss: 10.62427 (A-MSE: 9.37567) avg lploss: 0.00000
train epoch 60 avg loss: 10.20690 (A-MSE: 8.95407) avg lploss: 0.00000
==> val epoch 60 avg loss: 10.06191 (A-MSE: 8.90581) avg lploss: 0.00000
==> test epoch 60 avg loss: 9.55624 (A-MSE: 8.46043) avg lploss: 0.00000
*** Best Val Loss: 9.96243 	 Best Test Loss: 9.40792 	 Best epoch 55
EarlyStopping counter: 1 out of 50
train epoch 61 avg loss: 10.15994 (A-MSE: 8.93956) avg lploss: 0.00000
train epoch 62 avg loss: 10.13051 (A-MSE: 8.90150) avg lploss: 0.00000
train epoch 63 avg loss: 10.26414 (A-MSE: 9.03068) avg lploss: 0.00000
train epoch 64 avg loss: 10.33222 (A-MSE: 9.11526) avg lploss: 0.00000
train epoch 65 avg loss: 9.76080 (A-MSE: 8.57187) avg lploss: 0.00000
==> val epoch 65 avg loss: 9.40333 (A-MSE: 8.05652) avg lploss: 0.00000
==> test epoch 65 avg loss: 9.01245 (A-MSE: 7.76750) avg lploss: 0.00000
*** Best Val Loss: 9.40333 	 Best Test Loss: 9.01245 	 Best epoch 65
Validation loss decreased (9.962430 --> 9.403329).  Saving model ...
train epoch 66 avg loss: 9.69455 (A-MSE: 8.53860) avg lploss: 0.00000
train epoch 67 avg loss: 9.78946 (A-MSE: 8.62691) avg lploss: 0.00000
train epoch 68 avg loss: 9.87459 (A-MSE: 8.67038) avg lploss: 0.00000
train epoch 69 avg loss: 9.45854 (A-MSE: 8.29203) avg lploss: 0.00000
train epoch 70 avg loss: 9.38844 (A-MSE: 8.30062) avg lploss: 0.00000
==> val epoch 70 avg loss: 9.04556 (A-MSE: 7.95031) avg lploss: 0.00000
==> test epoch 70 avg loss: 8.68572 (A-MSE: 7.67054) avg lploss: 0.00000
*** Best Val Loss: 9.04556 	 Best Test Loss: 8.68572 	 Best epoch 70
Validation loss decreased (9.403329 --> 9.045565).  Saving model ...
train epoch 71 avg loss: 9.24906 (A-MSE: 8.13663) avg lploss: 0.00000
train epoch 72 avg loss: 9.29293 (A-MSE: 8.17310) avg lploss: 0.00000
train epoch 73 avg loss: 8.96763 (A-MSE: 7.89464) avg lploss: 0.00000
train epoch 74 avg loss: 8.95181 (A-MSE: 7.88208) avg lploss: 0.00000
train epoch 75 avg loss: 9.04966 (A-MSE: 7.99857) avg lploss: 0.00000
==> val epoch 75 avg loss: 9.81112 (A-MSE: 8.45263) avg lploss: 0.00000
==> test epoch 75 avg loss: 9.31794 (A-MSE: 8.07758) avg lploss: 0.00000
*** Best Val Loss: 9.04556 	 Best Test Loss: 8.68572 	 Best epoch 70
EarlyStopping counter: 1 out of 50
train epoch 76 avg loss: 9.11796 (A-MSE: 8.01559) avg lploss: 0.00000
train epoch 77 avg loss: 8.95555 (A-MSE: 7.87958) avg lploss: 0.00000
train epoch 78 avg loss: 8.78869 (A-MSE: 7.73250) avg lploss: 0.00000
train epoch 79 avg loss: 8.68958 (A-MSE: 7.65790) avg lploss: 0.00000
train epoch 80 avg loss: 8.68275 (A-MSE: 7.65197) avg lploss: 0.00000
==> val epoch 80 avg loss: 8.89141 (A-MSE: 7.78364) avg lploss: 0.00000
==> test epoch 80 avg loss: 8.45661 (A-MSE: 7.43622) avg lploss: 0.00000
*** Best Val Loss: 8.89141 	 Best Test Loss: 8.45661 	 Best epoch 80
Validation loss decreased (9.045565 --> 8.891410).  Saving model ...
train epoch 81 avg loss: 8.52665 (A-MSE: 7.50525) avg lploss: 0.00000
train epoch 82 avg loss: 8.61798 (A-MSE: 7.59455) avg lploss: 0.00000
train epoch 83 avg loss: 8.32542 (A-MSE: 7.35102) avg lploss: 0.00000
train epoch 84 avg loss: 8.39234 (A-MSE: 7.37226) avg lploss: 0.00000
train epoch 85 avg loss: 8.46396 (A-MSE: 7.47674) avg lploss: 0.00000
==> val epoch 85 avg loss: 8.86335 (A-MSE: 7.61204) avg lploss: 0.00000
==> test epoch 85 avg loss: 8.51872 (A-MSE: 7.38011) avg lploss: 0.00000
*** Best Val Loss: 8.86335 	 Best Test Loss: 8.51872 	 Best epoch 85
Validation loss decreased (8.891410 --> 8.863347).  Saving model ...
train epoch 86 avg loss: 8.35815 (A-MSE: 7.37766) avg lploss: 0.00000
train epoch 87 avg loss: 7.87331 (A-MSE: 6.93582) avg lploss: 0.00000
train epoch 88 avg loss: 7.89220 (A-MSE: 6.96428) avg lploss: 0.00000
train epoch 89 avg loss: 7.74789 (A-MSE: 6.82939) avg lploss: 0.00000
train epoch 90 avg loss: 7.74811 (A-MSE: 6.86865) avg lploss: 0.00000
==> val epoch 90 avg loss: 8.08683 (A-MSE: 7.13951) avg lploss: 0.00000
==> test epoch 90 avg loss: 7.67888 (A-MSE: 6.84736) avg lploss: 0.00000
*** Best Val Loss: 8.08683 	 Best Test Loss: 7.67888 	 Best epoch 90
Validation loss decreased (8.863347 --> 8.086833).  Saving model ...
train epoch 91 avg loss: 7.65191 (A-MSE: 6.71305) avg lploss: 0.00000
train epoch 92 avg loss: 7.37466 (A-MSE: 6.52901) avg lploss: 0.00000
train epoch 93 avg loss: 7.27219 (A-MSE: 6.39796) avg lploss: 0.00000
train epoch 94 avg loss: 7.50870 (A-MSE: 6.62368) avg lploss: 0.00000
train epoch 95 avg loss: 7.37257 (A-MSE: 6.49255) avg lploss: 0.00000
==> val epoch 95 avg loss: 7.50259 (A-MSE: 6.60225) avg lploss: 0.00000
==> test epoch 95 avg loss: 7.26690 (A-MSE: 6.46139) avg lploss: 0.00000
*** Best Val Loss: 7.50259 	 Best Test Loss: 7.26690 	 Best epoch 95
Validation loss decreased (8.086833 --> 7.502585).  Saving model ...
train epoch 96 avg loss: 7.04104 (A-MSE: 6.18414) avg lploss: 0.00000
train epoch 97 avg loss: 6.62168 (A-MSE: 5.84691) avg lploss: 0.00000
train epoch 98 avg loss: 6.77791 (A-MSE: 5.94576) avg lploss: 0.00000
train epoch 99 avg loss: 6.81190 (A-MSE: 6.01720) avg lploss: 0.00000
train epoch 100 avg loss: 6.74177 (A-MSE: 5.89319) avg lploss: 0.00000
==> val epoch 100 avg loss: 6.90082 (A-MSE: 6.34714) avg lploss: 0.00000
==> test epoch 100 avg loss: 6.73077 (A-MSE: 6.28622) avg lploss: 0.00000
*** Best Val Loss: 6.90082 	 Best Test Loss: 6.73077 	 Best epoch 100
Validation loss decreased (7.502585 --> 6.900825).  Saving model ...
train epoch 101 avg loss: 6.47471 (A-MSE: 5.69619) avg lploss: 0.00000
train epoch 102 avg loss: 6.35943 (A-MSE: 5.56750) avg lploss: 0.00000
train epoch 103 avg loss: 6.18240 (A-MSE: 5.41791) avg lploss: 0.00000
train epoch 104 avg loss: 6.44995 (A-MSE: 5.62425) avg lploss: 0.00000
train epoch 105 avg loss: 6.16851 (A-MSE: 5.37743) avg lploss: 0.00000
==> val epoch 105 avg loss: 7.31438 (A-MSE: 6.56448) avg lploss: 0.00000
==> test epoch 105 avg loss: 7.61431 (A-MSE: 7.03885) avg lploss: 0.00000
*** Best Val Loss: 6.90082 	 Best Test Loss: 6.73077 	 Best epoch 100
EarlyStopping counter: 1 out of 50
train epoch 106 avg loss: 6.94674 (A-MSE: 6.09780) avg lploss: 0.00000
train epoch 107 avg loss: 6.24896 (A-MSE: 5.41678) avg lploss: 0.00000
train epoch 108 avg loss: 5.47343 (A-MSE: 4.77298) avg lploss: 0.00000
train epoch 109 avg loss: 5.62890 (A-MSE: 4.89775) avg lploss: 0.00000
train epoch 110 avg loss: 6.11050 (A-MSE: 5.31719) avg lploss: 0.00000
==> val epoch 110 avg loss: 6.00522 (A-MSE: 5.40940) avg lploss: 0.00000
==> test epoch 110 avg loss: 5.75851 (A-MSE: 5.30143) avg lploss: 0.00000
*** Best Val Loss: 6.00522 	 Best Test Loss: 5.75851 	 Best epoch 110
Validation loss decreased (6.900825 --> 6.005220).  Saving model ...
train epoch 111 avg loss: 5.37184 (A-MSE: 4.67204) avg lploss: 0.00000
train epoch 112 avg loss: 5.06591 (A-MSE: 4.39307) avg lploss: 0.00000
train epoch 113 avg loss: 5.91359 (A-MSE: 5.14739) avg lploss: 0.00000
train epoch 114 avg loss: 5.58761 (A-MSE: 4.85590) avg lploss: 0.00000
train epoch 115 avg loss: 5.61156 (A-MSE: 4.84655) avg lploss: 0.00000
==> val epoch 115 avg loss: 6.69512 (A-MSE: 6.08709) avg lploss: 0.00000
==> test epoch 115 avg loss: 7.08313 (A-MSE: 6.61634) avg lploss: 0.00000
*** Best Val Loss: 6.00522 	 Best Test Loss: 5.75851 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 5.22722 (A-MSE: 4.54128) avg lploss: 0.00000
train epoch 117 avg loss: 4.73804 (A-MSE: 4.09735) avg lploss: 0.00000
train epoch 118 avg loss: 5.36386 (A-MSE: 4.64790) avg lploss: 0.00000
train epoch 119 avg loss: 5.04572 (A-MSE: 4.35836) avg lploss: 0.00000
train epoch 120 avg loss: 4.78084 (A-MSE: 4.13595) avg lploss: 0.00000
==> val epoch 120 avg loss: 5.72224 (A-MSE: 4.87721) avg lploss: 0.00000
==> test epoch 120 avg loss: 5.68245 (A-MSE: 4.97447) avg lploss: 0.00000
*** Best Val Loss: 5.72224 	 Best Test Loss: 5.68245 	 Best epoch 120
Validation loss decreased (6.005220 --> 5.722245).  Saving model ...
train epoch 121 avg loss: 4.36311 (A-MSE: 3.73652) avg lploss: 0.00000
train epoch 122 avg loss: 4.22976 (A-MSE: 3.63259) avg lploss: 0.00000
train epoch 123 avg loss: 4.76362 (A-MSE: 4.11369) avg lploss: 0.00000
train epoch 124 avg loss: 4.84566 (A-MSE: 4.18919) avg lploss: 0.00000
train epoch 125 avg loss: 4.63306 (A-MSE: 3.98362) avg lploss: 0.00000
==> val epoch 125 avg loss: 5.39274 (A-MSE: 4.64061) avg lploss: 0.00000
==> test epoch 125 avg loss: 5.18987 (A-MSE: 4.56443) avg lploss: 0.00000
*** Best Val Loss: 5.39274 	 Best Test Loss: 5.18987 	 Best epoch 125
Validation loss decreased (5.722245 --> 5.392740).  Saving model ...
train epoch 126 avg loss: 4.18492 (A-MSE: 3.58467) avg lploss: 0.00000
train epoch 127 avg loss: 4.37210 (A-MSE: 3.73281) avg lploss: 0.00000
train epoch 128 avg loss: 4.36178 (A-MSE: 3.75300) avg lploss: 0.00000
train epoch 129 avg loss: 4.09570 (A-MSE: 3.51319) avg lploss: 0.00000
train epoch 130 avg loss: 4.66043 (A-MSE: 4.00578) avg lploss: 0.00000
==> val epoch 130 avg loss: 4.82930 (A-MSE: 4.23470) avg lploss: 0.00000
==> test epoch 130 avg loss: 5.05544 (A-MSE: 4.57882) avg lploss: 0.00000
*** Best Val Loss: 4.82930 	 Best Test Loss: 5.05544 	 Best epoch 130
Validation loss decreased (5.392740 --> 4.829297).  Saving model ...
train epoch 131 avg loss: 4.28574 (A-MSE: 3.67419) avg lploss: 0.00000
train epoch 132 avg loss: 3.89373 (A-MSE: 3.33641) avg lploss: 0.00000
train epoch 133 avg loss: 3.80799 (A-MSE: 3.25359) avg lploss: 0.00000
train epoch 134 avg loss: 3.79184 (A-MSE: 3.23320) avg lploss: 0.00000
train epoch 135 avg loss: 4.20539 (A-MSE: 3.63149) avg lploss: 0.00000
==> val epoch 135 avg loss: 6.23954 (A-MSE: 5.36930) avg lploss: 0.00000
==> test epoch 135 avg loss: 6.43155 (A-MSE: 5.68854) avg lploss: 0.00000
*** Best Val Loss: 4.82930 	 Best Test Loss: 5.05544 	 Best epoch 130
EarlyStopping counter: 1 out of 50
train epoch 136 avg loss: 4.34757 (A-MSE: 3.70333) avg lploss: 0.00000
train epoch 137 avg loss: 4.23193 (A-MSE: 3.63153) avg lploss: 0.00000
train epoch 138 avg loss: 3.79799 (A-MSE: 3.25326) avg lploss: 0.00000
train epoch 139 avg loss: 3.68733 (A-MSE: 3.16504) avg lploss: 0.00000
train epoch 140 avg loss: 3.69209 (A-MSE: 3.15699) avg lploss: 0.00000
==> val epoch 140 avg loss: 4.21915 (A-MSE: 3.50307) avg lploss: 0.00000
==> test epoch 140 avg loss: 4.34346 (A-MSE: 3.75816) avg lploss: 0.00000
*** Best Val Loss: 4.21915 	 Best Test Loss: 4.34346 	 Best epoch 140
Validation loss decreased (4.829297 --> 4.219149).  Saving model ...
train epoch 141 avg loss: 3.61725 (A-MSE: 3.07399) avg lploss: 0.00000
train epoch 142 avg loss: 3.63821 (A-MSE: 3.11081) avg lploss: 0.00000
train epoch 143 avg loss: 3.59011 (A-MSE: 3.06554) avg lploss: 0.00000
train epoch 144 avg loss: 3.71907 (A-MSE: 3.18951) avg lploss: 0.00000
train epoch 145 avg loss: 3.47225 (A-MSE: 2.96790) avg lploss: 0.00000
==> val epoch 145 avg loss: 4.32966 (A-MSE: 3.63139) avg lploss: 0.00000
==> test epoch 145 avg loss: 4.74616 (A-MSE: 4.17349) avg lploss: 0.00000
*** Best Val Loss: 4.21915 	 Best Test Loss: 4.34346 	 Best epoch 140
EarlyStopping counter: 1 out of 50
train epoch 146 avg loss: 3.59932 (A-MSE: 3.06685) avg lploss: 0.00000
train epoch 147 avg loss: 3.50214 (A-MSE: 3.00097) avg lploss: 0.00000
train epoch 148 avg loss: 3.44075 (A-MSE: 2.93614) avg lploss: 0.00000
train epoch 149 avg loss: 3.28462 (A-MSE: 2.80223) avg lploss: 0.00000
train epoch 150 avg loss: 3.65183 (A-MSE: 3.13889) avg lploss: 0.00000
==> val epoch 150 avg loss: 5.41454 (A-MSE: 4.70437) avg lploss: 0.00000
==> test epoch 150 avg loss: 5.03958 (A-MSE: 4.44592) avg lploss: 0.00000
*** Best Val Loss: 4.21915 	 Best Test Loss: 4.34346 	 Best epoch 140
EarlyStopping counter: 2 out of 50
train epoch 151 avg loss: 3.70339 (A-MSE: 3.16889) avg lploss: 0.00000
train epoch 152 avg loss: 3.30855 (A-MSE: 2.83637) avg lploss: 0.00000
train epoch 153 avg loss: 3.15848 (A-MSE: 2.68277) avg lploss: 0.00000
train epoch 154 avg loss: 3.31134 (A-MSE: 2.82263) avg lploss: 0.00000
train epoch 155 avg loss: 3.11006 (A-MSE: 2.66076) avg lploss: 0.00000
==> val epoch 155 avg loss: 4.18722 (A-MSE: 3.57522) avg lploss: 0.00000
==> test epoch 155 avg loss: 4.19085 (A-MSE: 3.69610) avg lploss: 0.00000
*** Best Val Loss: 4.18722 	 Best Test Loss: 4.19085 	 Best epoch 155
Validation loss decreased (4.219149 --> 4.187220).  Saving model ...
train epoch 156 avg loss: 3.04212 (A-MSE: 2.59519) avg lploss: 0.00000
train epoch 157 avg loss: 3.00675 (A-MSE: 2.54379) avg lploss: 0.00000
train epoch 158 avg loss: 3.24639 (A-MSE: 2.77859) avg lploss: 0.00000
train epoch 159 avg loss: 3.15673 (A-MSE: 2.69423) avg lploss: 0.00000
train epoch 160 avg loss: 3.60676 (A-MSE: 3.11719) avg lploss: 0.00000
==> val epoch 160 avg loss: 4.60209 (A-MSE: 3.84450) avg lploss: 0.00000
==> test epoch 160 avg loss: 4.99207 (A-MSE: 4.34993) avg lploss: 0.00000
*** Best Val Loss: 4.18722 	 Best Test Loss: 4.19085 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 3.42040 (A-MSE: 2.94038) avg lploss: 0.00000
train epoch 162 avg loss: 3.09584 (A-MSE: 2.63260) avg lploss: 0.00000
train epoch 163 avg loss: 2.95316 (A-MSE: 2.51433) avg lploss: 0.00000
train epoch 164 avg loss: 2.93896 (A-MSE: 2.48884) avg lploss: 0.00000
train epoch 165 avg loss: 2.67235 (A-MSE: 2.26009) avg lploss: 0.00000
==> val epoch 165 avg loss: 3.57125 (A-MSE: 3.03638) avg lploss: 0.00000
==> test epoch 165 avg loss: 3.79357 (A-MSE: 3.38133) avg lploss: 0.00000
*** Best Val Loss: 3.57125 	 Best Test Loss: 3.79357 	 Best epoch 165
Validation loss decreased (4.187220 --> 3.571246).  Saving model ...
train epoch 166 avg loss: 2.69666 (A-MSE: 2.30416) avg lploss: 0.00000
train epoch 167 avg loss: 2.64080 (A-MSE: 2.24444) avg lploss: 0.00000
train epoch 168 avg loss: 2.67605 (A-MSE: 2.28131) avg lploss: 0.00000
train epoch 169 avg loss: 2.69893 (A-MSE: 2.29044) avg lploss: 0.00000
train epoch 170 avg loss: 2.63107 (A-MSE: 2.22691) avg lploss: 0.00000
==> val epoch 170 avg loss: 3.28453 (A-MSE: 2.81798) avg lploss: 0.00000
==> test epoch 170 avg loss: 3.56095 (A-MSE: 3.19250) avg lploss: 0.00000
*** Best Val Loss: 3.28453 	 Best Test Loss: 3.56095 	 Best epoch 170
Validation loss decreased (3.571246 --> 3.284532).  Saving model ...
train epoch 171 avg loss: 2.57282 (A-MSE: 2.18408) avg lploss: 0.00000
train epoch 172 avg loss: 2.70344 (A-MSE: 2.31849) avg lploss: 0.00000
train epoch 173 avg loss: 2.63711 (A-MSE: 2.22635) avg lploss: 0.00000
train epoch 174 avg loss: 2.51681 (A-MSE: 2.14334) avg lploss: 0.00000
train epoch 175 avg loss: 2.80155 (A-MSE: 2.39981) avg lploss: 0.00000
==> val epoch 175 avg loss: 4.57862 (A-MSE: 3.84342) avg lploss: 0.00000
==> test epoch 175 avg loss: 5.00712 (A-MSE: 4.35743) avg lploss: 0.00000
*** Best Val Loss: 3.28453 	 Best Test Loss: 3.56095 	 Best epoch 170
EarlyStopping counter: 1 out of 50
train epoch 176 avg loss: 2.74454 (A-MSE: 2.33984) avg lploss: 0.00000
train epoch 177 avg loss: 2.34789 (A-MSE: 2.00187) avg lploss: 0.00000
train epoch 178 avg loss: 2.39796 (A-MSE: 2.04568) avg lploss: 0.00000
train epoch 179 avg loss: 2.40063 (A-MSE: 2.05384) avg lploss: 0.00000
train epoch 180 avg loss: 2.41147 (A-MSE: 2.05271) avg lploss: 0.00000
==> val epoch 180 avg loss: 3.96047 (A-MSE: 3.33011) avg lploss: 0.00000
==> test epoch 180 avg loss: 4.18611 (A-MSE: 3.66586) avg lploss: 0.00000
*** Best Val Loss: 3.28453 	 Best Test Loss: 3.56095 	 Best epoch 170
EarlyStopping counter: 2 out of 50
train epoch 181 avg loss: 2.67575 (A-MSE: 2.30015) avg lploss: 0.00000
train epoch 182 avg loss: 2.65326 (A-MSE: 2.27092) avg lploss: 0.00000
train epoch 183 avg loss: 2.36454 (A-MSE: 1.99629) avg lploss: 0.00000
train epoch 184 avg loss: 2.20011 (A-MSE: 1.88311) avg lploss: 0.00000
train epoch 185 avg loss: 2.10558 (A-MSE: 1.79462) avg lploss: 0.00000
==> val epoch 185 avg loss: 3.00018 (A-MSE: 2.54236) avg lploss: 0.00000
==> test epoch 185 avg loss: 3.11604 (A-MSE: 2.73854) avg lploss: 0.00000
*** Best Val Loss: 3.00018 	 Best Test Loss: 3.11604 	 Best epoch 185
Validation loss decreased (3.284532 --> 3.000185).  Saving model ...
train epoch 186 avg loss: 2.32115 (A-MSE: 1.96955) avg lploss: 0.00000
train epoch 187 avg loss: 2.40955 (A-MSE: 2.07574) avg lploss: 0.00000
train epoch 188 avg loss: 2.67406 (A-MSE: 2.30882) avg lploss: 0.00000
train epoch 189 avg loss: 2.48737 (A-MSE: 2.13297) avg lploss: 0.00000
train epoch 190 avg loss: 2.38704 (A-MSE: 2.04164) avg lploss: 0.00000
==> val epoch 190 avg loss: 2.84164 (A-MSE: 2.43426) avg lploss: 0.00000
==> test epoch 190 avg loss: 3.12090 (A-MSE: 2.78688) avg lploss: 0.00000
*** Best Val Loss: 2.84164 	 Best Test Loss: 3.12090 	 Best epoch 190
Validation loss decreased (3.000185 --> 2.841637).  Saving model ...
train epoch 191 avg loss: 2.15010 (A-MSE: 1.83494) avg lploss: 0.00000
train epoch 192 avg loss: 1.96390 (A-MSE: 1.65773) avg lploss: 0.00000
train epoch 193 avg loss: 1.97073 (A-MSE: 1.68517) avg lploss: 0.00000
train epoch 194 avg loss: 2.09234 (A-MSE: 1.77808) avg lploss: 0.00000
train epoch 195 avg loss: 2.00813 (A-MSE: 1.71636) avg lploss: 0.00000
==> val epoch 195 avg loss: 3.20859 (A-MSE: 2.78453) avg lploss: 0.00000
==> test epoch 195 avg loss: 3.56598 (A-MSE: 3.22047) avg lploss: 0.00000
*** Best Val Loss: 2.84164 	 Best Test Loss: 3.12090 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 1.95914 (A-MSE: 1.67748) avg lploss: 0.00000
train epoch 197 avg loss: 1.95832 (A-MSE: 1.66474) avg lploss: 0.00000
train epoch 198 avg loss: 2.07540 (A-MSE: 1.77432) avg lploss: 0.00000
train epoch 199 avg loss: 1.89454 (A-MSE: 1.62239) avg lploss: 0.00000
train epoch 200 avg loss: 2.35271 (A-MSE: 2.03946) avg lploss: 0.00000
==> val epoch 200 avg loss: 3.79244 (A-MSE: 3.24363) avg lploss: 0.00000
==> test epoch 200 avg loss: 4.09892 (A-MSE: 3.61568) avg lploss: 0.00000
*** Best Val Loss: 2.84164 	 Best Test Loss: 3.12090 	 Best epoch 190
EarlyStopping counter: 2 out of 50
train epoch 201 avg loss: 2.31351 (A-MSE: 1.98691) avg lploss: 0.00000
train epoch 202 avg loss: 2.41667 (A-MSE: 2.10766) avg lploss: 0.00000
train epoch 203 avg loss: 1.88981 (A-MSE: 1.59513) avg lploss: 0.00000
train epoch 204 avg loss: 1.88012 (A-MSE: 1.61649) avg lploss: 0.00000
train epoch 205 avg loss: 1.77849 (A-MSE: 1.50598) avg lploss: 0.00000
==> val epoch 205 avg loss: 2.41700 (A-MSE: 2.18180) avg lploss: 0.00000
==> test epoch 205 avg loss: 2.60722 (A-MSE: 2.42216) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
Validation loss decreased (2.841637 --> 2.416999).  Saving model ...
train epoch 206 avg loss: 1.83527 (A-MSE: 1.57647) avg lploss: 0.00000
train epoch 207 avg loss: 2.01717 (A-MSE: 1.74238) avg lploss: 0.00000
train epoch 208 avg loss: 2.25955 (A-MSE: 1.94475) avg lploss: 0.00000
train epoch 209 avg loss: 1.97248 (A-MSE: 1.70928) avg lploss: 0.00000
train epoch 210 avg loss: 1.81008 (A-MSE: 1.53436) avg lploss: 0.00000
==> val epoch 210 avg loss: 2.79266 (A-MSE: 2.43630) avg lploss: 0.00000
==> test epoch 210 avg loss: 3.07873 (A-MSE: 2.76876) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 1 out of 50
train epoch 211 avg loss: 1.86051 (A-MSE: 1.61454) avg lploss: 0.00000
train epoch 212 avg loss: 1.66405 (A-MSE: 1.41620) avg lploss: 0.00000
train epoch 213 avg loss: 1.82119 (A-MSE: 1.55543) avg lploss: 0.00000
train epoch 214 avg loss: 1.78529 (A-MSE: 1.53893) avg lploss: 0.00000
train epoch 215 avg loss: 1.79543 (A-MSE: 1.54831) avg lploss: 0.00000
==> val epoch 215 avg loss: 2.51951 (A-MSE: 2.13390) avg lploss: 0.00000
==> test epoch 215 avg loss: 2.74455 (A-MSE: 2.41899) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 2 out of 50
train epoch 216 avg loss: 1.62379 (A-MSE: 1.38387) avg lploss: 0.00000
train epoch 217 avg loss: 1.77382 (A-MSE: 1.52476) avg lploss: 0.00000
train epoch 218 avg loss: 1.80569 (A-MSE: 1.54495) avg lploss: 0.00000
train epoch 219 avg loss: 1.62332 (A-MSE: 1.39474) avg lploss: 0.00000
train epoch 220 avg loss: 1.99496 (A-MSE: 1.72957) avg lploss: 0.00000
==> val epoch 220 avg loss: 2.92407 (A-MSE: 2.47795) avg lploss: 0.00000
==> test epoch 220 avg loss: 3.21015 (A-MSE: 2.80357) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 3 out of 50
train epoch 221 avg loss: 1.98881 (A-MSE: 1.69771) avg lploss: 0.00000
train epoch 222 avg loss: 1.92437 (A-MSE: 1.67224) avg lploss: 0.00000
train epoch 223 avg loss: 1.85951 (A-MSE: 1.59772) avg lploss: 0.00000
train epoch 224 avg loss: 1.88499 (A-MSE: 1.63068) avg lploss: 0.00000
train epoch 225 avg loss: 2.08623 (A-MSE: 1.81313) avg lploss: 0.00000
==> val epoch 225 avg loss: 2.87008 (A-MSE: 2.46277) avg lploss: 0.00000
==> test epoch 225 avg loss: 3.07422 (A-MSE: 2.74015) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 4 out of 50
train epoch 226 avg loss: 1.80260 (A-MSE: 1.55268) avg lploss: 0.00000
train epoch 227 avg loss: 1.77476 (A-MSE: 1.52428) avg lploss: 0.00000
train epoch 228 avg loss: 1.62438 (A-MSE: 1.40600) avg lploss: 0.00000
train epoch 229 avg loss: 1.66481 (A-MSE: 1.42763) avg lploss: 0.00000
train epoch 230 avg loss: 1.55579 (A-MSE: 1.33429) avg lploss: 0.00000
==> val epoch 230 avg loss: 3.25505 (A-MSE: 2.79425) avg lploss: 0.00000
==> test epoch 230 avg loss: 3.72555 (A-MSE: 3.30103) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 5 out of 50
train epoch 231 avg loss: 1.90671 (A-MSE: 1.65639) avg lploss: 0.00000
train epoch 232 avg loss: 1.73360 (A-MSE: 1.49976) avg lploss: 0.00000
train epoch 233 avg loss: 1.62847 (A-MSE: 1.40897) avg lploss: 0.00000
train epoch 234 avg loss: 1.53434 (A-MSE: 1.30882) avg lploss: 0.00000
train epoch 235 avg loss: 1.50733 (A-MSE: 1.30182) avg lploss: 0.00000
==> val epoch 235 avg loss: 2.42160 (A-MSE: 2.12013) avg lploss: 0.00000
==> test epoch 235 avg loss: 2.71008 (A-MSE: 2.46714) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 6 out of 50
train epoch 236 avg loss: 1.45698 (A-MSE: 1.24539) avg lploss: 0.00000
train epoch 237 avg loss: 1.44358 (A-MSE: 1.23991) avg lploss: 0.00000
train epoch 238 avg loss: 1.47326 (A-MSE: 1.26096) avg lploss: 0.00000
train epoch 239 avg loss: 1.53408 (A-MSE: 1.32616) avg lploss: 0.00000
train epoch 240 avg loss: 1.49660 (A-MSE: 1.28381) avg lploss: 0.00000
==> val epoch 240 avg loss: 3.09537 (A-MSE: 2.62913) avg lploss: 0.00000
==> test epoch 240 avg loss: 3.51391 (A-MSE: 3.11543) avg lploss: 0.00000
*** Best Val Loss: 2.41700 	 Best Test Loss: 2.60722 	 Best epoch 205
EarlyStopping counter: 7 out of 50
train epoch 241 avg loss: 1.64592 (A-MSE: 1.42759) avg lploss: 0.00000
train epoch 242 avg loss: 1.70710 (A-MSE: 1.48583) avg lploss: 0.00000
train epoch 243 avg loss: 1.48706 (A-MSE: 1.26783) avg lploss: 0.00000
train epoch 244 avg loss: 1.59705 (A-MSE: 1.38627) avg lploss: 0.00000
train epoch 245 avg loss: 1.50790 (A-MSE: 1.29388) avg lploss: 0.00000
==> val epoch 245 avg loss: 1.98442 (A-MSE: 1.72318) avg lploss: 0.00000
==> test epoch 245 avg loss: 2.17242 (A-MSE: 1.96506) avg lploss: 0.00000
*** Best Val Loss: 1.98442 	 Best Test Loss: 2.17242 	 Best epoch 245
Validation loss decreased (2.416999 --> 1.984420).  Saving model ...
train epoch 246 avg loss: 1.42844 (A-MSE: 1.22601) avg lploss: 0.00000
train epoch 247 avg loss: 1.46178 (A-MSE: 1.25881) avg lploss: 0.00000
train epoch 248 avg loss: 1.50199 (A-MSE: 1.29467) avg lploss: 0.00000
train epoch 249 avg loss: 1.38596 (A-MSE: 1.19102) avg lploss: 0.00000
train epoch 250 avg loss: 1.35180 (A-MSE: 1.17106) avg lploss: 0.00000
==> val epoch 250 avg loss: 2.48500 (A-MSE: 2.16681) avg lploss: 0.00000
==> test epoch 250 avg loss: 2.75196 (A-MSE: 2.50227) avg lploss: 0.00000
*** Best Val Loss: 1.98442 	 Best Test Loss: 2.17242 	 Best epoch 245
EarlyStopping counter: 1 out of 50
train epoch 251 avg loss: 1.40436 (A-MSE: 1.21489) avg lploss: 0.00000
train epoch 252 avg loss: 1.67866 (A-MSE: 1.46189) avg lploss: 0.00000
train epoch 253 avg loss: 1.72989 (A-MSE: 1.49926) avg lploss: 0.00000
train epoch 254 avg loss: 1.66478 (A-MSE: 1.44953) avg lploss: 0.00000
train epoch 255 avg loss: 1.95970 (A-MSE: 1.71042) avg lploss: 0.00000
==> val epoch 255 avg loss: 2.62681 (A-MSE: 2.17934) avg lploss: 0.00000
==> test epoch 255 avg loss: 2.72676 (A-MSE: 2.35832) avg lploss: 0.00000
*** Best Val Loss: 1.98442 	 Best Test Loss: 2.17242 	 Best epoch 245
EarlyStopping counter: 2 out of 50
train epoch 256 avg loss: 1.59792 (A-MSE: 1.36891) avg lploss: 0.00000
train epoch 257 avg loss: 1.34944 (A-MSE: 1.16290) avg lploss: 0.00000
train epoch 258 avg loss: 1.35443 (A-MSE: 1.17101) avg lploss: 0.00000
train epoch 259 avg loss: 1.38998 (A-MSE: 1.20405) avg lploss: 0.00000
train epoch 260 avg loss: 1.31334 (A-MSE: 1.13396) avg lploss: 0.00000
==> val epoch 260 avg loss: 2.35245 (A-MSE: 2.02525) avg lploss: 0.00000
==> test epoch 260 avg loss: 2.58521 (A-MSE: 2.32540) avg lploss: 0.00000
*** Best Val Loss: 1.98442 	 Best Test Loss: 2.17242 	 Best epoch 245
EarlyStopping counter: 3 out of 50
train epoch 261 avg loss: 1.32147 (A-MSE: 1.13525) avg lploss: 0.00000
train epoch 262 avg loss: 1.24737 (A-MSE: 1.07463) avg lploss: 0.00000
train epoch 263 avg loss: 1.31873 (A-MSE: 1.14203) avg lploss: 0.00000
train epoch 264 avg loss: 1.40673 (A-MSE: 1.22767) avg lploss: 0.00000
train epoch 265 avg loss: 1.53991 (A-MSE: 1.32022) avg lploss: 0.00000
==> val epoch 265 avg loss: 3.02288 (A-MSE: 2.67696) avg lploss: 0.00000
==> test epoch 265 avg loss: 3.35144 (A-MSE: 3.05956) avg lploss: 0.00000
*** Best Val Loss: 1.98442 	 Best Test Loss: 2.17242 	 Best epoch 245
EarlyStopping counter: 4 out of 50
train epoch 266 avg loss: 1.35690 (A-MSE: 1.18534) avg lploss: 0.00000
train epoch 267 avg loss: 1.33624 (A-MSE: 1.15611) avg lploss: 0.00000
train epoch 268 avg loss: 1.27955 (A-MSE: 1.11111) avg lploss: 0.00000
train epoch 269 avg loss: 1.30581 (A-MSE: 1.12503) avg lploss: 0.00000
train epoch 270 avg loss: 1.51577 (A-MSE: 1.31741) avg lploss: 0.00000
==> val epoch 270 avg loss: 1.89154 (A-MSE: 1.64669) avg lploss: 0.00000
==> test epoch 270 avg loss: 2.06172 (A-MSE: 1.85971) avg lploss: 0.00000
*** Best Val Loss: 1.89154 	 Best Test Loss: 2.06172 	 Best epoch 270
Validation loss decreased (1.984420 --> 1.891541).  Saving model ...
train epoch 271 avg loss: 1.34127 (A-MSE: 1.15841) avg lploss: 0.00000
train epoch 272 avg loss: 1.26477 (A-MSE: 1.09194) avg lploss: 0.00000
train epoch 273 avg loss: 1.29534 (A-MSE: 1.12090) avg lploss: 0.00000
train epoch 274 avg loss: 1.22492 (A-MSE: 1.05974) avg lploss: 0.00000
train epoch 275 avg loss: 1.19554 (A-MSE: 1.03937) avg lploss: 0.00000
==> val epoch 275 avg loss: 1.85564 (A-MSE: 1.62004) avg lploss: 0.00000
==> test epoch 275 avg loss: 2.01385 (A-MSE: 1.81950) avg lploss: 0.00000
*** Best Val Loss: 1.85564 	 Best Test Loss: 2.01385 	 Best epoch 275
Validation loss decreased (1.891541 --> 1.855641).  Saving model ...
train epoch 276 avg loss: 1.28591 (A-MSE: 1.11344) avg lploss: 0.00000
train epoch 277 avg loss: 1.28264 (A-MSE: 1.10548) avg lploss: 0.00000
train epoch 278 avg loss: 1.19292 (A-MSE: 1.03414) avg lploss: 0.00000
train epoch 279 avg loss: 1.23749 (A-MSE: 1.07183) avg lploss: 0.00000
train epoch 280 avg loss: 1.22328 (A-MSE: 1.06649) avg lploss: 0.00000
==> val epoch 280 avg loss: 2.25617 (A-MSE: 2.00911) avg lploss: 0.00000
==> test epoch 280 avg loss: 2.66509 (A-MSE: 2.44969) avg lploss: 0.00000
*** Best Val Loss: 1.85564 	 Best Test Loss: 2.01385 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 1.20751 (A-MSE: 1.04096) avg lploss: 0.00000
train epoch 282 avg loss: 1.44713 (A-MSE: 1.26179) avg lploss: 0.00000
train epoch 283 avg loss: 1.36134 (A-MSE: 1.18311) avg lploss: 0.00000
train epoch 284 avg loss: 1.26565 (A-MSE: 1.10635) avg lploss: 0.00000
train epoch 285 avg loss: 1.32034 (A-MSE: 1.14280) avg lploss: 0.00000
==> val epoch 285 avg loss: 2.28850 (A-MSE: 2.01439) avg lploss: 0.00000
==> test epoch 285 avg loss: 2.49307 (A-MSE: 2.26910) avg lploss: 0.00000
*** Best Val Loss: 1.85564 	 Best Test Loss: 2.01385 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 1.38769 (A-MSE: 1.19912) avg lploss: 0.00000
train epoch 287 avg loss: 1.26740 (A-MSE: 1.10263) avg lploss: 0.00000
train epoch 288 avg loss: 1.22391 (A-MSE: 1.05748) avg lploss: 0.00000
train epoch 289 avg loss: 1.14788 (A-MSE: 0.99739) avg lploss: 0.00000
train epoch 290 avg loss: 1.13366 (A-MSE: 0.97515) avg lploss: 0.00000
==> val epoch 290 avg loss: 1.95453 (A-MSE: 1.73884) avg lploss: 0.00000
==> test epoch 290 avg loss: 2.20638 (A-MSE: 2.02283) avg lploss: 0.00000
*** Best Val Loss: 1.85564 	 Best Test Loss: 2.01385 	 Best epoch 275
EarlyStopping counter: 3 out of 50
train epoch 291 avg loss: 1.21500 (A-MSE: 1.06823) avg lploss: 0.00000
train epoch 292 avg loss: 1.29054 (A-MSE: 1.11774) avg lploss: 0.00000
train epoch 293 avg loss: 1.20321 (A-MSE: 1.04701) avg lploss: 0.00000
train epoch 294 avg loss: 1.08722 (A-MSE: 0.93788) avg lploss: 0.00000
train epoch 295 avg loss: 1.08691 (A-MSE: 0.94427) avg lploss: 0.00000
==> val epoch 295 avg loss: 1.83833 (A-MSE: 1.62630) avg lploss: 0.00000
==> test epoch 295 avg loss: 2.05541 (A-MSE: 1.88747) avg lploss: 0.00000
*** Best Val Loss: 1.83833 	 Best Test Loss: 2.05541 	 Best epoch 295
Validation loss decreased (1.855641 --> 1.838331).  Saving model ...
train epoch 296 avg loss: 1.06506 (A-MSE: 0.92043) avg lploss: 0.00000
train epoch 297 avg loss: 1.17392 (A-MSE: 1.02468) avg lploss: 0.00000
train epoch 298 avg loss: 1.22396 (A-MSE: 1.06213) avg lploss: 0.00000
train epoch 299 avg loss: 1.21112 (A-MSE: 1.05117) avg lploss: 0.00000
train epoch 300 avg loss: 1.13769 (A-MSE: 0.99878) avg lploss: 0.00000
==> val epoch 300 avg loss: 2.10603 (A-MSE: 1.77954) avg lploss: 0.00000
==> test epoch 300 avg loss: 2.12128 (A-MSE: 1.87429) avg lploss: 0.00000
*** Best Val Loss: 1.83833 	 Best Test Loss: 2.05541 	 Best epoch 295
EarlyStopping counter: 1 out of 50
train epoch 301 avg loss: 1.19043 (A-MSE: 1.03659) avg lploss: 0.00000
train epoch 302 avg loss: 1.19414 (A-MSE: 1.03937) avg lploss: 0.00000
train epoch 303 avg loss: 1.14425 (A-MSE: 0.99652) avg lploss: 0.00000
train epoch 304 avg loss: 1.08724 (A-MSE: 0.93688) avg lploss: 0.00000
train epoch 305 avg loss: 1.02118 (A-MSE: 0.88165) avg lploss: 0.00000
==> val epoch 305 avg loss: 1.81784 (A-MSE: 1.61425) avg lploss: 0.00000
==> test epoch 305 avg loss: 2.00847 (A-MSE: 1.84437) avg lploss: 0.00000
*** Best Val Loss: 1.81784 	 Best Test Loss: 2.00847 	 Best epoch 305
Validation loss decreased (1.838331 --> 1.817836).  Saving model ...
train epoch 306 avg loss: 1.12894 (A-MSE: 0.99075) avg lploss: 0.00000
train epoch 307 avg loss: 1.11176 (A-MSE: 0.97141) avg lploss: 0.00000
train epoch 308 avg loss: 1.10860 (A-MSE: 0.96154) avg lploss: 0.00000
train epoch 309 avg loss: 1.17528 (A-MSE: 1.02147) avg lploss: 0.00000
train epoch 310 avg loss: 1.10795 (A-MSE: 0.96531) avg lploss: 0.00000
==> val epoch 310 avg loss: 1.68672 (A-MSE: 1.49607) avg lploss: 0.00000
==> test epoch 310 avg loss: 1.93908 (A-MSE: 1.77837) avg lploss: 0.00000
*** Best Val Loss: 1.68672 	 Best Test Loss: 1.93908 	 Best epoch 310
Validation loss decreased (1.817836 --> 1.686723).  Saving model ...
train epoch 311 avg loss: 1.04327 (A-MSE: 0.90410) avg lploss: 0.00000
train epoch 312 avg loss: 1.08612 (A-MSE: 0.94183) avg lploss: 0.00000
train epoch 313 avg loss: 1.17886 (A-MSE: 1.02780) avg lploss: 0.00000
train epoch 314 avg loss: 1.17193 (A-MSE: 1.02165) avg lploss: 0.00000
train epoch 315 avg loss: 1.25108 (A-MSE: 1.08904) avg lploss: 0.00000
==> val epoch 315 avg loss: 2.00396 (A-MSE: 1.71888) avg lploss: 0.00000
==> test epoch 315 avg loss: 2.20130 (A-MSE: 1.96902) avg lploss: 0.00000
*** Best Val Loss: 1.68672 	 Best Test Loss: 1.93908 	 Best epoch 310
EarlyStopping counter: 1 out of 50
train epoch 316 avg loss: 1.03972 (A-MSE: 0.89790) avg lploss: 0.00000
train epoch 317 avg loss: 1.03083 (A-MSE: 0.90197) avg lploss: 0.00000
train epoch 318 avg loss: 1.05133 (A-MSE: 0.90679) avg lploss: 0.00000
train epoch 319 avg loss: 1.21382 (A-MSE: 1.06064) avg lploss: 0.00000
train epoch 320 avg loss: 1.12037 (A-MSE: 0.97730) avg lploss: 0.00000
==> val epoch 320 avg loss: 2.02276 (A-MSE: 1.74658) avg lploss: 0.00000
==> test epoch 320 avg loss: 2.31804 (A-MSE: 2.08468) avg lploss: 0.00000
*** Best Val Loss: 1.68672 	 Best Test Loss: 1.93908 	 Best epoch 310
EarlyStopping counter: 2 out of 50
train epoch 321 avg loss: 1.03340 (A-MSE: 0.89494) avg lploss: 0.00000
train epoch 322 avg loss: 1.01952 (A-MSE: 0.88860) avg lploss: 0.00000
train epoch 323 avg loss: 1.03991 (A-MSE: 0.90988) avg lploss: 0.00000
train epoch 324 avg loss: 1.01414 (A-MSE: 0.87718) avg lploss: 0.00000
train epoch 325 avg loss: 1.04178 (A-MSE: 0.90346) avg lploss: 0.00000
==> val epoch 325 avg loss: 1.78490 (A-MSE: 1.54643) avg lploss: 0.00000
==> test epoch 325 avg loss: 2.01718 (A-MSE: 1.82764) avg lploss: 0.00000
*** Best Val Loss: 1.68672 	 Best Test Loss: 1.93908 	 Best epoch 310
EarlyStopping counter: 3 out of 50
train epoch 326 avg loss: 0.96779 (A-MSE: 0.83437) avg lploss: 0.00000
train epoch 327 avg loss: 0.96768 (A-MSE: 0.84384) avg lploss: 0.00000
train epoch 328 avg loss: 0.97302 (A-MSE: 0.84910) avg lploss: 0.00000
train epoch 329 avg loss: 0.96804 (A-MSE: 0.84261) avg lploss: 0.00000
train epoch 330 avg loss: 0.94422 (A-MSE: 0.82257) avg lploss: 0.00000
==> val epoch 330 avg loss: 2.02295 (A-MSE: 1.76678) avg lploss: 0.00000
==> test epoch 330 avg loss: 2.36440 (A-MSE: 2.14805) avg lploss: 0.00000
*** Best Val Loss: 1.68672 	 Best Test Loss: 1.93908 	 Best epoch 310
EarlyStopping counter: 4 out of 50
train epoch 331 avg loss: 1.00281 (A-MSE: 0.87192) avg lploss: 0.00000
train epoch 332 avg loss: 0.99912 (A-MSE: 0.87548) avg lploss: 0.00000
train epoch 333 avg loss: 0.98248 (A-MSE: 0.85186) avg lploss: 0.00000
train epoch 334 avg loss: 0.97827 (A-MSE: 0.85047) avg lploss: 0.00000
train epoch 335 avg loss: 0.96566 (A-MSE: 0.84212) avg lploss: 0.00000
==> val epoch 335 avg loss: 1.70697 (A-MSE: 1.50680) avg lploss: 0.00000
==> test epoch 335 avg loss: 1.92636 (A-MSE: 1.76514) avg lploss: 0.00000
*** Best Val Loss: 1.68672 	 Best Test Loss: 1.93908 	 Best epoch 310
EarlyStopping counter: 5 out of 50
train epoch 336 avg loss: 0.98706 (A-MSE: 0.85477) avg lploss: 0.00000
train epoch 337 avg loss: 0.96689 (A-MSE: 0.84899) avg lploss: 0.00000
train epoch 338 avg loss: 1.11230 (A-MSE: 0.96372) avg lploss: 0.00000
train epoch 339 avg loss: 0.97164 (A-MSE: 0.85229) avg lploss: 0.00000
train epoch 340 avg loss: 0.95971 (A-MSE: 0.83567) avg lploss: 0.00000
==> val epoch 340 avg loss: 1.63664 (A-MSE: 1.42555) avg lploss: 0.00000
==> test epoch 340 avg loss: 1.92801 (A-MSE: 1.74125) avg lploss: 0.00000
*** Best Val Loss: 1.63664 	 Best Test Loss: 1.92801 	 Best epoch 340
Validation loss decreased (1.686723 --> 1.636638).  Saving model ...
train epoch 341 avg loss: 0.96461 (A-MSE: 0.84194) avg lploss: 0.00000
train epoch 342 avg loss: 0.95662 (A-MSE: 0.83405) avg lploss: 0.00000
train epoch 343 avg loss: 0.97710 (A-MSE: 0.85240) avg lploss: 0.00000
train epoch 344 avg loss: 1.00348 (A-MSE: 0.87438) avg lploss: 0.00000
train epoch 345 avg loss: 0.99055 (A-MSE: 0.86455) avg lploss: 0.00000
==> val epoch 345 avg loss: 1.57792 (A-MSE: 1.40692) avg lploss: 0.00000
==> test epoch 345 avg loss: 1.70922 (A-MSE: 1.57017) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
Validation loss decreased (1.636638 --> 1.577921).  Saving model ...
train epoch 346 avg loss: 1.04216 (A-MSE: 0.91702) avg lploss: 0.00000
train epoch 347 avg loss: 1.05198 (A-MSE: 0.91524) avg lploss: 0.00000
train epoch 348 avg loss: 0.94209 (A-MSE: 0.81651) avg lploss: 0.00000
train epoch 349 avg loss: 1.00322 (A-MSE: 0.87757) avg lploss: 0.00000
train epoch 350 avg loss: 1.06977 (A-MSE: 0.93748) avg lploss: 0.00000
==> val epoch 350 avg loss: 1.89503 (A-MSE: 1.64479) avg lploss: 0.00000
==> test epoch 350 avg loss: 1.97048 (A-MSE: 1.76965) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
EarlyStopping counter: 1 out of 50
train epoch 351 avg loss: 1.01239 (A-MSE: 0.88232) avg lploss: 0.00000
train epoch 352 avg loss: 1.03022 (A-MSE: 0.89141) avg lploss: 0.00000
train epoch 353 avg loss: 0.96239 (A-MSE: 0.83916) avg lploss: 0.00000
train epoch 354 avg loss: 0.92272 (A-MSE: 0.80826) avg lploss: 0.00000
train epoch 355 avg loss: 0.96898 (A-MSE: 0.84447) avg lploss: 0.00000
==> val epoch 355 avg loss: 1.68506 (A-MSE: 1.49285) avg lploss: 0.00000
==> test epoch 355 avg loss: 1.96881 (A-MSE: 1.80733) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
EarlyStopping counter: 2 out of 50
train epoch 356 avg loss: 0.85443 (A-MSE: 0.74300) avg lploss: 0.00000
train epoch 357 avg loss: 0.94381 (A-MSE: 0.81753) avg lploss: 0.00000
train epoch 358 avg loss: 0.89691 (A-MSE: 0.78386) avg lploss: 0.00000
train epoch 359 avg loss: 0.89178 (A-MSE: 0.77672) avg lploss: 0.00000
train epoch 360 avg loss: 0.94822 (A-MSE: 0.83437) avg lploss: 0.00000
==> val epoch 360 avg loss: 1.67982 (A-MSE: 1.47500) avg lploss: 0.00000
==> test epoch 360 avg loss: 1.96116 (A-MSE: 1.78130) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
EarlyStopping counter: 3 out of 50
train epoch 361 avg loss: 0.98719 (A-MSE: 0.85553) avg lploss: 0.00000
train epoch 362 avg loss: 1.08160 (A-MSE: 0.95931) avg lploss: 0.00000
train epoch 363 avg loss: 1.03396 (A-MSE: 0.89955) avg lploss: 0.00000
train epoch 364 avg loss: 0.96925 (A-MSE: 0.84710) avg lploss: 0.00000
train epoch 365 avg loss: 0.93307 (A-MSE: 0.82236) avg lploss: 0.00000
==> val epoch 365 avg loss: 1.71092 (A-MSE: 1.49165) avg lploss: 0.00000
==> test epoch 365 avg loss: 1.92318 (A-MSE: 1.74568) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
EarlyStopping counter: 4 out of 50
train epoch 366 avg loss: 1.00285 (A-MSE: 0.86855) avg lploss: 0.00000
train epoch 367 avg loss: 0.94863 (A-MSE: 0.83164) avg lploss: 0.00000
train epoch 368 avg loss: 0.91114 (A-MSE: 0.79145) avg lploss: 0.00000
train epoch 369 avg loss: 0.83930 (A-MSE: 0.73162) avg lploss: 0.00000
train epoch 370 avg loss: 0.82328 (A-MSE: 0.71205) avg lploss: 0.00000
==> val epoch 370 avg loss: 1.69296 (A-MSE: 1.47886) avg lploss: 0.00000
==> test epoch 370 avg loss: 1.91822 (A-MSE: 1.73475) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
EarlyStopping counter: 5 out of 50
train epoch 371 avg loss: 0.93640 (A-MSE: 0.82127) avg lploss: 0.00000
train epoch 372 avg loss: 1.03231 (A-MSE: 0.89992) avg lploss: 0.00000
train epoch 373 avg loss: 0.96667 (A-MSE: 0.84491) avg lploss: 0.00000
train epoch 374 avg loss: 0.81949 (A-MSE: 0.72044) avg lploss: 0.00000
train epoch 375 avg loss: 0.88409 (A-MSE: 0.77168) avg lploss: 0.00000
==> val epoch 375 avg loss: 1.63245 (A-MSE: 1.41808) avg lploss: 0.00000
==> test epoch 375 avg loss: 1.82646 (A-MSE: 1.64853) avg lploss: 0.00000
*** Best Val Loss: 1.57792 	 Best Test Loss: 1.70922 	 Best epoch 345
EarlyStopping counter: 6 out of 50
train epoch 376 avg loss: 0.97229 (A-MSE: 0.84679) avg lploss: 0.00000
train epoch 377 avg loss: 0.90361 (A-MSE: 0.78919) avg lploss: 0.00000
train epoch 378 avg loss: 0.94532 (A-MSE: 0.82708) avg lploss: 0.00000
train epoch 379 avg loss: 0.84294 (A-MSE: 0.73599) avg lploss: 0.00000
train epoch 380 avg loss: 0.83796 (A-MSE: 0.72706) avg lploss: 0.00000
==> val epoch 380 avg loss: 1.44611 (A-MSE: 1.26679) avg lploss: 0.00000
==> test epoch 380 avg loss: 1.58587 (A-MSE: 1.45591) avg lploss: 0.00000
*** Best Val Loss: 1.44611 	 Best Test Loss: 1.58587 	 Best epoch 380
Validation loss decreased (1.577921 --> 1.446111).  Saving model ...
train epoch 381 avg loss: 0.78927 (A-MSE: 0.69086) avg lploss: 0.00000
train epoch 382 avg loss: 0.80443 (A-MSE: 0.69718) avg lploss: 0.00000
train epoch 383 avg loss: 0.82871 (A-MSE: 0.72384) avg lploss: 0.00000
train epoch 384 avg loss: 0.85493 (A-MSE: 0.75243) avg lploss: 0.00000
train epoch 385 avg loss: 0.89219 (A-MSE: 0.77481) avg lploss: 0.00000
==> val epoch 385 avg loss: 2.24004 (A-MSE: 1.99901) avg lploss: 0.00000
==> test epoch 385 avg loss: 2.47323 (A-MSE: 2.27671) avg lploss: 0.00000
*** Best Val Loss: 1.44611 	 Best Test Loss: 1.58587 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.94770 (A-MSE: 0.83157) avg lploss: 0.00000
train epoch 387 avg loss: 0.84863 (A-MSE: 0.74289) avg lploss: 0.00000
train epoch 388 avg loss: 0.84539 (A-MSE: 0.73403) avg lploss: 0.00000
train epoch 389 avg loss: 0.81043 (A-MSE: 0.70845) avg lploss: 0.00000
train epoch 390 avg loss: 0.93036 (A-MSE: 0.80204) avg lploss: 0.00000
==> val epoch 390 avg loss: 1.57931 (A-MSE: 1.36307) avg lploss: 0.00000
==> test epoch 390 avg loss: 1.68787 (A-MSE: 1.52147) avg lploss: 0.00000
*** Best Val Loss: 1.44611 	 Best Test Loss: 1.58587 	 Best epoch 380
EarlyStopping counter: 2 out of 50
train epoch 391 avg loss: 0.86880 (A-MSE: 0.75603) avg lploss: 0.00000
train epoch 392 avg loss: 0.98046 (A-MSE: 0.86679) avg lploss: 0.00000
train epoch 393 avg loss: 0.83106 (A-MSE: 0.72497) avg lploss: 0.00000
train epoch 394 avg loss: 0.77702 (A-MSE: 0.67476) avg lploss: 0.00000
train epoch 395 avg loss: 0.83003 (A-MSE: 0.72286) avg lploss: 0.00000
==> val epoch 395 avg loss: 1.70667 (A-MSE: 1.51285) avg lploss: 0.00000
==> test epoch 395 avg loss: 1.86782 (A-MSE: 1.71744) avg lploss: 0.00000
*** Best Val Loss: 1.44611 	 Best Test Loss: 1.58587 	 Best epoch 380
EarlyStopping counter: 3 out of 50
train epoch 396 avg loss: 0.91670 (A-MSE: 0.79902) avg lploss: 0.00000
train epoch 397 avg loss: 0.79185 (A-MSE: 0.68946) avg lploss: 0.00000
train epoch 398 avg loss: 0.82174 (A-MSE: 0.71289) avg lploss: 0.00000
train epoch 399 avg loss: 0.77895 (A-MSE: 0.68606) avg lploss: 0.00000
train epoch 400 avg loss: 0.80506 (A-MSE: 0.69900) avg lploss: 0.00000
==> val epoch 400 avg loss: 1.63384 (A-MSE: 1.46834) avg lploss: 0.00000
==> test epoch 400 avg loss: 1.86342 (A-MSE: 1.72485) avg lploss: 0.00000
*** Best Val Loss: 1.44611 	 Best Test Loss: 1.58587 	 Best epoch 380
EarlyStopping counter: 4 out of 50
train epoch 401 avg loss: 0.76074 (A-MSE: 0.66502) avg lploss: 0.00000
train epoch 402 avg loss: 0.80602 (A-MSE: 0.70210) avg lploss: 0.00000
train epoch 403 avg loss: 0.79119 (A-MSE: 0.69668) avg lploss: 0.00000
train epoch 404 avg loss: 0.85846 (A-MSE: 0.75214) avg lploss: 0.00000
train epoch 405 avg loss: 0.89370 (A-MSE: 0.77762) avg lploss: 0.00000
==> val epoch 405 avg loss: 1.41545 (A-MSE: 1.22603) avg lploss: 0.00000
==> test epoch 405 avg loss: 1.46387 (A-MSE: 1.31952) avg lploss: 0.00000
*** Best Val Loss: 1.41545 	 Best Test Loss: 1.46387 	 Best epoch 405
Validation loss decreased (1.446111 --> 1.415446).  Saving model ...
train epoch 406 avg loss: 0.82446 (A-MSE: 0.72167) avg lploss: 0.00000
train epoch 407 avg loss: 0.83181 (A-MSE: 0.72407) avg lploss: 0.00000
train epoch 408 avg loss: 0.77320 (A-MSE: 0.67294) avg lploss: 0.00000
train epoch 409 avg loss: 0.72693 (A-MSE: 0.63127) avg lploss: 0.00000
train epoch 410 avg loss: 0.80467 (A-MSE: 0.70675) avg lploss: 0.00000
==> val epoch 410 avg loss: 1.42536 (A-MSE: 1.24276) avg lploss: 0.00000
==> test epoch 410 avg loss: 1.47489 (A-MSE: 1.33945) avg lploss: 0.00000
*** Best Val Loss: 1.41545 	 Best Test Loss: 1.46387 	 Best epoch 405
EarlyStopping counter: 1 out of 50
train epoch 411 avg loss: 0.86425 (A-MSE: 0.74881) avg lploss: 0.00000
train epoch 412 avg loss: 0.79815 (A-MSE: 0.70128) avg lploss: 0.00000
train epoch 413 avg loss: 0.76855 (A-MSE: 0.66542) avg lploss: 0.00000
train epoch 414 avg loss: 0.81980 (A-MSE: 0.71528) avg lploss: 0.00000
train epoch 415 avg loss: 0.80318 (A-MSE: 0.70287) avg lploss: 0.00000
==> val epoch 415 avg loss: 1.50269 (A-MSE: 1.33028) avg lploss: 0.00000
==> test epoch 415 avg loss: 1.59599 (A-MSE: 1.46655) avg lploss: 0.00000
*** Best Val Loss: 1.41545 	 Best Test Loss: 1.46387 	 Best epoch 405
EarlyStopping counter: 2 out of 50
train epoch 416 avg loss: 0.80713 (A-MSE: 0.70121) avg lploss: 0.00000
train epoch 417 avg loss: 0.82226 (A-MSE: 0.72335) avg lploss: 0.00000
train epoch 418 avg loss: 0.78010 (A-MSE: 0.67523) avg lploss: 0.00000
train epoch 419 avg loss: 0.79276 (A-MSE: 0.69378) avg lploss: 0.00000
train epoch 420 avg loss: 0.75886 (A-MSE: 0.66371) avg lploss: 0.00000
==> val epoch 420 avg loss: 1.44726 (A-MSE: 1.27035) avg lploss: 0.00000
==> test epoch 420 avg loss: 1.55346 (A-MSE: 1.41675) avg lploss: 0.00000
*** Best Val Loss: 1.41545 	 Best Test Loss: 1.46387 	 Best epoch 405
EarlyStopping counter: 3 out of 50
train epoch 421 avg loss: 0.70295 (A-MSE: 0.61603) avg lploss: 0.00000
train epoch 422 avg loss: 0.78869 (A-MSE: 0.69303) avg lploss: 0.00000
train epoch 423 avg loss: 0.80684 (A-MSE: 0.70342) avg lploss: 0.00000
train epoch 424 avg loss: 0.84843 (A-MSE: 0.73989) avg lploss: 0.00000
train epoch 425 avg loss: 0.71476 (A-MSE: 0.62137) avg lploss: 0.00000
==> val epoch 425 avg loss: 1.39519 (A-MSE: 1.22567) avg lploss: 0.00000
==> test epoch 425 avg loss: 1.53795 (A-MSE: 1.40687) avg lploss: 0.00000
*** Best Val Loss: 1.39519 	 Best Test Loss: 1.53795 	 Best epoch 425
Validation loss decreased (1.415446 --> 1.395186).  Saving model ...
train epoch 426 avg loss: 0.71884 (A-MSE: 0.62898) avg lploss: 0.00000
train epoch 427 avg loss: 0.73547 (A-MSE: 0.63762) avg lploss: 0.00000
train epoch 428 avg loss: 0.78398 (A-MSE: 0.68996) avg lploss: 0.00000
train epoch 429 avg loss: 0.86592 (A-MSE: 0.75044) avg lploss: 0.00000
train epoch 430 avg loss: 0.72789 (A-MSE: 0.63737) avg lploss: 0.00000
==> val epoch 430 avg loss: 1.40840 (A-MSE: 1.23624) avg lploss: 0.00000
==> test epoch 430 avg loss: 1.55773 (A-MSE: 1.41680) avg lploss: 0.00000
*** Best Val Loss: 1.39519 	 Best Test Loss: 1.53795 	 Best epoch 425
EarlyStopping counter: 1 out of 50
train epoch 431 avg loss: 0.70887 (A-MSE: 0.61556) avg lploss: 0.00000
train epoch 432 avg loss: 0.75467 (A-MSE: 0.65793) avg lploss: 0.00000
train epoch 433 avg loss: 0.87458 (A-MSE: 0.77140) avg lploss: 0.00000
train epoch 434 avg loss: 0.85096 (A-MSE: 0.73764) avg lploss: 0.00000
train epoch 435 avg loss: 0.78529 (A-MSE: 0.68836) avg lploss: 0.00000
==> val epoch 435 avg loss: 1.55219 (A-MSE: 1.37089) avg lploss: 0.00000
==> test epoch 435 avg loss: 1.70046 (A-MSE: 1.55778) avg lploss: 0.00000
*** Best Val Loss: 1.39519 	 Best Test Loss: 1.53795 	 Best epoch 425
EarlyStopping counter: 2 out of 50
train epoch 436 avg loss: 0.79605 (A-MSE: 0.70523) avg lploss: 0.00000
train epoch 437 avg loss: 0.75724 (A-MSE: 0.65848) avg lploss: 0.00000
train epoch 438 avg loss: 0.71775 (A-MSE: 0.62552) avg lploss: 0.00000
train epoch 439 avg loss: 0.67035 (A-MSE: 0.58352) avg lploss: 0.00000
train epoch 440 avg loss: 0.68595 (A-MSE: 0.59756) avg lploss: 0.00000
==> val epoch 440 avg loss: 1.63124 (A-MSE: 1.44256) avg lploss: 0.00000
==> test epoch 440 avg loss: 1.79382 (A-MSE: 1.64814) avg lploss: 0.00000
*** Best Val Loss: 1.39519 	 Best Test Loss: 1.53795 	 Best epoch 425
EarlyStopping counter: 3 out of 50
train epoch 441 avg loss: 0.70561 (A-MSE: 0.61592) avg lploss: 0.00000
train epoch 442 avg loss: 0.67528 (A-MSE: 0.58707) avg lploss: 0.00000
train epoch 443 avg loss: 0.65891 (A-MSE: 0.57073) avg lploss: 0.00000
train epoch 444 avg loss: 0.72454 (A-MSE: 0.63207) avg lploss: 0.00000
train epoch 445 avg loss: 0.72435 (A-MSE: 0.63244) avg lploss: 0.00000
==> val epoch 445 avg loss: 1.57099 (A-MSE: 1.37258) avg lploss: 0.00000
==> test epoch 445 avg loss: 1.69151 (A-MSE: 1.53771) avg lploss: 0.00000
*** Best Val Loss: 1.39519 	 Best Test Loss: 1.53795 	 Best epoch 425
EarlyStopping counter: 4 out of 50
train epoch 446 avg loss: 0.75491 (A-MSE: 0.65542) avg lploss: 0.00000
train epoch 447 avg loss: 0.76659 (A-MSE: 0.66795) avg lploss: 0.00000
train epoch 448 avg loss: 0.67852 (A-MSE: 0.59125) avg lploss: 0.00000
train epoch 449 avg loss: 0.73202 (A-MSE: 0.63557) avg lploss: 0.00000
train epoch 450 avg loss: 0.75161 (A-MSE: 0.66278) avg lploss: 0.00000
==> val epoch 450 avg loss: 1.65308 (A-MSE: 1.43236) avg lploss: 0.00000
==> test epoch 450 avg loss: 1.77154 (A-MSE: 1.59653) avg lploss: 0.00000
*** Best Val Loss: 1.39519 	 Best Test Loss: 1.53795 	 Best epoch 425
EarlyStopping counter: 5 out of 50
train epoch 451 avg loss: 0.73174 (A-MSE: 0.63519) avg lploss: 0.00000
train epoch 452 avg loss: 0.69377 (A-MSE: 0.60602) avg lploss: 0.00000
train epoch 453 avg loss: 0.67504 (A-MSE: 0.58764) avg lploss: 0.00000
train epoch 454 avg loss: 0.70375 (A-MSE: 0.61847) avg lploss: 0.00000
train epoch 455 avg loss: 0.64303 (A-MSE: 0.56035) avg lploss: 0.00000
==> val epoch 455 avg loss: 1.38774 (A-MSE: 1.22517) avg lploss: 0.00000
==> test epoch 455 avg loss: 1.57461 (A-MSE: 1.45780) avg lploss: 0.00000
*** Best Val Loss: 1.38774 	 Best Test Loss: 1.57461 	 Best epoch 455
Validation loss decreased (1.395186 --> 1.387738).  Saving model ...
train epoch 456 avg loss: 0.66296 (A-MSE: 0.57581) avg lploss: 0.00000
train epoch 457 avg loss: 0.63519 (A-MSE: 0.55412) avg lploss: 0.00000
train epoch 458 avg loss: 0.59421 (A-MSE: 0.51440) avg lploss: 0.00000
train epoch 459 avg loss: 0.62837 (A-MSE: 0.55046) avg lploss: 0.00000
train epoch 460 avg loss: 0.67644 (A-MSE: 0.58706) avg lploss: 0.00000
==> val epoch 460 avg loss: 1.30625 (A-MSE: 1.15009) avg lploss: 0.00000
==> test epoch 460 avg loss: 1.37371 (A-MSE: 1.26370) avg lploss: 0.00000
*** Best Val Loss: 1.30625 	 Best Test Loss: 1.37371 	 Best epoch 460
Validation loss decreased (1.387738 --> 1.306254).  Saving model ...
train epoch 461 avg loss: 0.70662 (A-MSE: 0.61770) avg lploss: 0.00000
train epoch 462 avg loss: 0.72056 (A-MSE: 0.62491) avg lploss: 0.00000
train epoch 463 avg loss: 0.67544 (A-MSE: 0.59200) avg lploss: 0.00000
train epoch 464 avg loss: 0.67283 (A-MSE: 0.58786) avg lploss: 0.00000
train epoch 465 avg loss: 0.61263 (A-MSE: 0.53201) avg lploss: 0.00000
==> val epoch 465 avg loss: 1.33365 (A-MSE: 1.15012) avg lploss: 0.00000
==> test epoch 465 avg loss: 1.47174 (A-MSE: 1.31905) avg lploss: 0.00000
*** Best Val Loss: 1.30625 	 Best Test Loss: 1.37371 	 Best epoch 460
EarlyStopping counter: 1 out of 50
train epoch 466 avg loss: 0.65389 (A-MSE: 0.56877) avg lploss: 0.00000
train epoch 467 avg loss: 0.62118 (A-MSE: 0.54483) avg lploss: 0.00000
train epoch 468 avg loss: 0.66195 (A-MSE: 0.57698) avg lploss: 0.00000
train epoch 469 avg loss: 0.64345 (A-MSE: 0.55988) avg lploss: 0.00000
train epoch 470 avg loss: 0.63807 (A-MSE: 0.55905) avg lploss: 0.00000
==> val epoch 470 avg loss: 1.36530 (A-MSE: 1.20973) avg lploss: 0.00000
==> test epoch 470 avg loss: 1.45221 (A-MSE: 1.33452) avg lploss: 0.00000
*** Best Val Loss: 1.30625 	 Best Test Loss: 1.37371 	 Best epoch 460
EarlyStopping counter: 2 out of 50
train epoch 471 avg loss: 0.80778 (A-MSE: 0.70711) avg lploss: 0.00000
train epoch 472 avg loss: 0.72517 (A-MSE: 0.63321) avg lploss: 0.00000
train epoch 473 avg loss: 0.73554 (A-MSE: 0.63557) avg lploss: 0.00000
train epoch 474 avg loss: 0.76933 (A-MSE: 0.67107) avg lploss: 0.00000
train epoch 475 avg loss: 0.72486 (A-MSE: 0.63016) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.25520 (A-MSE: 1.07517) avg lploss: 0.00000
==> test epoch 475 avg loss: 1.35211 (A-MSE: 1.21126) avg lploss: 0.00000
*** Best Val Loss: 1.25520 	 Best Test Loss: 1.35211 	 Best epoch 475
Validation loss decreased (1.306254 --> 1.255198).  Saving model ...
train epoch 476 avg loss: 0.60994 (A-MSE: 0.53140) avg lploss: 0.00000
train epoch 477 avg loss: 0.58731 (A-MSE: 0.51246) avg lploss: 0.00000
train epoch 478 avg loss: 0.60248 (A-MSE: 0.52623) avg lploss: 0.00000
train epoch 479 avg loss: 0.59322 (A-MSE: 0.51808) avg lploss: 0.00000
train epoch 480 avg loss: 0.58026 (A-MSE: 0.50342) avg lploss: 0.00000
==> val epoch 480 avg loss: 1.36138 (A-MSE: 1.17735) avg lploss: 0.00000
==> test epoch 480 avg loss: 1.45154 (A-MSE: 1.30312) avg lploss: 0.00000
*** Best Val Loss: 1.25520 	 Best Test Loss: 1.35211 	 Best epoch 475
EarlyStopping counter: 1 out of 50
train epoch 481 avg loss: 0.57778 (A-MSE: 0.50359) avg lploss: 0.00000
train epoch 482 avg loss: 0.66853 (A-MSE: 0.58396) avg lploss: 0.00000
train epoch 483 avg loss: 0.66656 (A-MSE: 0.58174) avg lploss: 0.00000
train epoch 484 avg loss: 0.66538 (A-MSE: 0.58133) avg lploss: 0.00000
train epoch 485 avg loss: 0.61840 (A-MSE: 0.54278) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.52351 (A-MSE: 1.33145) avg lploss: 0.00000
==> test epoch 485 avg loss: 1.63019 (A-MSE: 1.47781) avg lploss: 0.00000
*** Best Val Loss: 1.25520 	 Best Test Loss: 1.35211 	 Best epoch 475
EarlyStopping counter: 2 out of 50
train epoch 486 avg loss: 0.64222 (A-MSE: 0.56146) avg lploss: 0.00000
train epoch 487 avg loss: 0.63786 (A-MSE: 0.56266) avg lploss: 0.00000
train epoch 488 avg loss: 0.60662 (A-MSE: 0.52768) avg lploss: 0.00000
train epoch 489 avg loss: 0.65737 (A-MSE: 0.57710) avg lploss: 0.00000
train epoch 490 avg loss: 0.64275 (A-MSE: 0.55966) avg lploss: 0.00000
==> val epoch 490 avg loss: 1.37169 (A-MSE: 1.20337) avg lploss: 0.00000
==> test epoch 490 avg loss: 1.44441 (A-MSE: 1.31826) avg lploss: 0.00000
*** Best Val Loss: 1.25520 	 Best Test Loss: 1.35211 	 Best epoch 475
EarlyStopping counter: 3 out of 50
train epoch 491 avg loss: 0.64603 (A-MSE: 0.57229) avg lploss: 0.00000
train epoch 492 avg loss: 0.65057 (A-MSE: 0.56076) avg lploss: 0.00000
train epoch 493 avg loss: 0.58077 (A-MSE: 0.50280) avg lploss: 0.00000
train epoch 494 avg loss: 0.58882 (A-MSE: 0.51109) avg lploss: 0.00000
train epoch 495 avg loss: 0.56423 (A-MSE: 0.49362) avg lploss: 0.00000
==> val epoch 495 avg loss: 1.18892 (A-MSE: 1.06235) avg lploss: 0.00000
==> test epoch 495 avg loss: 1.38995 (A-MSE: 1.28311) avg lploss: 0.00000
*** Best Val Loss: 1.18892 	 Best Test Loss: 1.38995 	 Best epoch 495
Validation loss decreased (1.255198 --> 1.188918).  Saving model ...
train epoch 496 avg loss: 0.56107 (A-MSE: 0.49001) avg lploss: 0.00000
train epoch 497 avg loss: 0.52676 (A-MSE: 0.45858) avg lploss: 0.00000
train epoch 498 avg loss: 0.57393 (A-MSE: 0.50043) avg lploss: 0.00000
train epoch 499 avg loss: 0.60554 (A-MSE: 0.52979) avg lploss: 0.00000
train epoch 500 avg loss: 0.68262 (A-MSE: 0.59869) avg lploss: 0.00000
==> val epoch 500 avg loss: 1.13331 (A-MSE: 1.01134) avg lploss: 0.00000
==> test epoch 500 avg loss: 1.31949 (A-MSE: 1.22099) avg lploss: 0.00000
*** Best Val Loss: 1.13331 	 Best Test Loss: 1.31949 	 Best epoch 500
Validation loss decreased (1.188918 --> 1.133307).  Saving model ...
train epoch 501 avg loss: 0.66726 (A-MSE: 0.58750) avg lploss: 0.00000
train epoch 502 avg loss: 0.62247 (A-MSE: 0.53783) avg lploss: 0.00000
train epoch 503 avg loss: 0.62422 (A-MSE: 0.54458) avg lploss: 0.00000
train epoch 504 avg loss: 0.63231 (A-MSE: 0.54805) avg lploss: 0.00000
train epoch 505 avg loss: 0.67455 (A-MSE: 0.58819) avg lploss: 0.00000
==> val epoch 505 avg loss: 1.10343 (A-MSE: 0.96706) avg lploss: 0.00000
==> test epoch 505 avg loss: 1.26433 (A-MSE: 1.14625) avg lploss: 0.00000
*** Best Val Loss: 1.10343 	 Best Test Loss: 1.26433 	 Best epoch 505
Validation loss decreased (1.133307 --> 1.103425).  Saving model ...
train epoch 506 avg loss: 0.73420 (A-MSE: 0.64452) avg lploss: 0.00000
train epoch 507 avg loss: 0.72418 (A-MSE: 0.63282) avg lploss: 0.00000
train epoch 508 avg loss: 0.64794 (A-MSE: 0.56667) avg lploss: 0.00000
train epoch 509 avg loss: 0.66064 (A-MSE: 0.57862) avg lploss: 0.00000
train epoch 510 avg loss: 0.60758 (A-MSE: 0.52516) avg lploss: 0.00000
==> val epoch 510 avg loss: 1.24671 (A-MSE: 1.10459) avg lploss: 0.00000
==> test epoch 510 avg loss: 1.35893 (A-MSE: 1.24019) avg lploss: 0.00000
*** Best Val Loss: 1.10343 	 Best Test Loss: 1.26433 	 Best epoch 505
EarlyStopping counter: 1 out of 50
train epoch 511 avg loss: 0.62992 (A-MSE: 0.55315) avg lploss: 0.00000
train epoch 512 avg loss: 0.64003 (A-MSE: 0.55688) avg lploss: 0.00000
train epoch 513 avg loss: 0.70541 (A-MSE: 0.61869) avg lploss: 0.00000
train epoch 514 avg loss: 0.67186 (A-MSE: 0.58733) avg lploss: 0.00000
train epoch 515 avg loss: 0.63261 (A-MSE: 0.54773) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.10432 (A-MSE: 0.96654) avg lploss: 0.00000
==> test epoch 515 avg loss: 1.22977 (A-MSE: 1.12192) avg lploss: 0.00000
*** Best Val Loss: 1.10343 	 Best Test Loss: 1.26433 	 Best epoch 505
EarlyStopping counter: 2 out of 50
train epoch 516 avg loss: 0.66827 (A-MSE: 0.58322) avg lploss: 0.00000
train epoch 517 avg loss: 0.65554 (A-MSE: 0.56968) avg lploss: 0.00000
train epoch 518 avg loss: 0.57274 (A-MSE: 0.50068) avg lploss: 0.00000
train epoch 519 avg loss: 0.57990 (A-MSE: 0.50540) avg lploss: 0.00000
train epoch 520 avg loss: 0.52709 (A-MSE: 0.45908) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.48417 (A-MSE: 1.29369) avg lploss: 0.00000
==> test epoch 520 avg loss: 1.54961 (A-MSE: 1.40070) avg lploss: 0.00000
*** Best Val Loss: 1.10343 	 Best Test Loss: 1.26433 	 Best epoch 505
EarlyStopping counter: 3 out of 50
train epoch 521 avg loss: 0.66324 (A-MSE: 0.58163) avg lploss: 0.00000
train epoch 522 avg loss: 0.65116 (A-MSE: 0.56667) avg lploss: 0.00000
train epoch 523 avg loss: 0.53303 (A-MSE: 0.46336) avg lploss: 0.00000
train epoch 524 avg loss: 0.54114 (A-MSE: 0.47325) avg lploss: 0.00000
train epoch 525 avg loss: 0.55321 (A-MSE: 0.48195) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.03817 (A-MSE: 0.92698) avg lploss: 0.00000
==> test epoch 525 avg loss: 1.17409 (A-MSE: 1.08075) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
Validation loss decreased (1.103425 --> 1.038173).  Saving model ...
train epoch 526 avg loss: 0.59536 (A-MSE: 0.52123) avg lploss: 0.00000
train epoch 527 avg loss: 0.58526 (A-MSE: 0.51250) avg lploss: 0.00000
train epoch 528 avg loss: 0.60783 (A-MSE: 0.53259) avg lploss: 0.00000
train epoch 529 avg loss: 0.55048 (A-MSE: 0.47652) avg lploss: 0.00000
train epoch 530 avg loss: 0.50491 (A-MSE: 0.43993) avg lploss: 0.00000
==> val epoch 530 avg loss: 1.14237 (A-MSE: 0.99439) avg lploss: 0.00000
==> test epoch 530 avg loss: 1.23819 (A-MSE: 1.11756) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
EarlyStopping counter: 1 out of 50
train epoch 531 avg loss: 0.51829 (A-MSE: 0.44968) avg lploss: 0.00000
train epoch 532 avg loss: 0.54161 (A-MSE: 0.47158) avg lploss: 0.00000
train epoch 533 avg loss: 0.57321 (A-MSE: 0.50379) avg lploss: 0.00000
train epoch 534 avg loss: 0.54584 (A-MSE: 0.47469) avg lploss: 0.00000
train epoch 535 avg loss: 0.51775 (A-MSE: 0.45119) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.15324 (A-MSE: 1.00698) avg lploss: 0.00000
==> test epoch 535 avg loss: 1.27379 (A-MSE: 1.15273) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
EarlyStopping counter: 2 out of 50
train epoch 536 avg loss: 0.50108 (A-MSE: 0.43596) avg lploss: 0.00000
train epoch 537 avg loss: 0.53069 (A-MSE: 0.46804) avg lploss: 0.00000
train epoch 538 avg loss: 0.57891 (A-MSE: 0.50582) avg lploss: 0.00000
train epoch 539 avg loss: 0.53485 (A-MSE: 0.46209) avg lploss: 0.00000
train epoch 540 avg loss: 0.65990 (A-MSE: 0.57917) avg lploss: 0.00000
==> val epoch 540 avg loss: 1.08832 (A-MSE: 0.96963) avg lploss: 0.00000
==> test epoch 540 avg loss: 1.29725 (A-MSE: 1.19723) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
EarlyStopping counter: 3 out of 50
train epoch 541 avg loss: 0.60812 (A-MSE: 0.52935) avg lploss: 0.00000
train epoch 542 avg loss: 0.59297 (A-MSE: 0.52638) avg lploss: 0.00000
train epoch 543 avg loss: 0.57495 (A-MSE: 0.49888) avg lploss: 0.00000
train epoch 544 avg loss: 0.51405 (A-MSE: 0.44899) avg lploss: 0.00000
train epoch 545 avg loss: 0.55558 (A-MSE: 0.48332) avg lploss: 0.00000
==> val epoch 545 avg loss: 1.12879 (A-MSE: 1.00308) avg lploss: 0.00000
==> test epoch 545 avg loss: 1.28655 (A-MSE: 1.18798) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
EarlyStopping counter: 4 out of 50
train epoch 546 avg loss: 0.56056 (A-MSE: 0.49188) avg lploss: 0.00000
train epoch 547 avg loss: 0.50538 (A-MSE: 0.44060) avg lploss: 0.00000
train epoch 548 avg loss: 0.50632 (A-MSE: 0.44214) avg lploss: 0.00000
train epoch 549 avg loss: 0.52411 (A-MSE: 0.46085) avg lploss: 0.00000
train epoch 550 avg loss: 0.57765 (A-MSE: 0.50474) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.11461 (A-MSE: 0.96343) avg lploss: 0.00000
==> test epoch 550 avg loss: 1.23278 (A-MSE: 1.10830) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
EarlyStopping counter: 5 out of 50
train epoch 551 avg loss: 0.53107 (A-MSE: 0.46462) avg lploss: 0.00000
train epoch 552 avg loss: 0.53181 (A-MSE: 0.46227) avg lploss: 0.00000
train epoch 553 avg loss: 0.46995 (A-MSE: 0.40925) avg lploss: 0.00000
train epoch 554 avg loss: 0.51703 (A-MSE: 0.44937) avg lploss: 0.00000
train epoch 555 avg loss: 0.50996 (A-MSE: 0.44818) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.14028 (A-MSE: 0.99190) avg lploss: 0.00000
==> test epoch 555 avg loss: 1.23668 (A-MSE: 1.12265) avg lploss: 0.00000
*** Best Val Loss: 1.03817 	 Best Test Loss: 1.17409 	 Best epoch 525
EarlyStopping counter: 6 out of 50
train epoch 556 avg loss: 0.46760 (A-MSE: 0.40829) avg lploss: 0.00000
train epoch 557 avg loss: 0.47452 (A-MSE: 0.41546) avg lploss: 0.00000
train epoch 558 avg loss: 0.67743 (A-MSE: 0.58835) avg lploss: 0.00000
train epoch 559 avg loss: 0.54017 (A-MSE: 0.47312) avg lploss: 0.00000
train epoch 560 avg loss: 0.53649 (A-MSE: 0.46860) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.01127 (A-MSE: 0.91223) avg lploss: 0.00000
==> test epoch 560 avg loss: 1.17422 (A-MSE: 1.09520) avg lploss: 0.00000
*** Best Val Loss: 1.01127 	 Best Test Loss: 1.17422 	 Best epoch 560
Validation loss decreased (1.038173 --> 1.011274).  Saving model ...
train epoch 561 avg loss: 0.51260 (A-MSE: 0.45273) avg lploss: 0.00000
train epoch 562 avg loss: 0.51241 (A-MSE: 0.44716) avg lploss: 0.00000
train epoch 563 avg loss: 0.54895 (A-MSE: 0.47847) avg lploss: 0.00000
train epoch 564 avg loss: 0.54463 (A-MSE: 0.47872) avg lploss: 0.00000
train epoch 565 avg loss: 0.53713 (A-MSE: 0.47103) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.13857 (A-MSE: 1.01862) avg lploss: 0.00000
==> test epoch 565 avg loss: 1.29319 (A-MSE: 1.18865) avg lploss: 0.00000
*** Best Val Loss: 1.01127 	 Best Test Loss: 1.17422 	 Best epoch 560
EarlyStopping counter: 1 out of 50
train epoch 566 avg loss: 0.56568 (A-MSE: 0.49323) avg lploss: 0.00000
train epoch 567 avg loss: 0.50115 (A-MSE: 0.43700) avg lploss: 0.00000
train epoch 568 avg loss: 0.48694 (A-MSE: 0.43232) avg lploss: 0.00000
train epoch 569 avg loss: 0.53220 (A-MSE: 0.46079) avg lploss: 0.00000
train epoch 570 avg loss: 0.61729 (A-MSE: 0.54440) avg lploss: 0.00000
==> val epoch 570 avg loss: 1.15795 (A-MSE: 1.03158) avg lploss: 0.00000
==> test epoch 570 avg loss: 1.28432 (A-MSE: 1.17861) avg lploss: 0.00000
*** Best Val Loss: 1.01127 	 Best Test Loss: 1.17422 	 Best epoch 560
EarlyStopping counter: 2 out of 50
train epoch 571 avg loss: 0.53225 (A-MSE: 0.46291) avg lploss: 0.00000
train epoch 572 avg loss: 0.57720 (A-MSE: 0.51073) avg lploss: 0.00000
train epoch 573 avg loss: 0.57167 (A-MSE: 0.49554) avg lploss: 0.00000
train epoch 574 avg loss: 0.55794 (A-MSE: 0.48787) avg lploss: 0.00000
train epoch 575 avg loss: 0.54737 (A-MSE: 0.47694) avg lploss: 0.00000
==> val epoch 575 avg loss: 1.19855 (A-MSE: 1.06388) avg lploss: 0.00000
==> test epoch 575 avg loss: 1.29906 (A-MSE: 1.19322) avg lploss: 0.00000
*** Best Val Loss: 1.01127 	 Best Test Loss: 1.17422 	 Best epoch 560
EarlyStopping counter: 3 out of 50
train epoch 576 avg loss: 0.46279 (A-MSE: 0.40338) avg lploss: 0.00000
train epoch 577 avg loss: 0.43086 (A-MSE: 0.37815) avg lploss: 0.00000
train epoch 578 avg loss: 0.43408 (A-MSE: 0.37896) avg lploss: 0.00000
train epoch 579 avg loss: 0.41083 (A-MSE: 0.35959) avg lploss: 0.00000
train epoch 580 avg loss: 0.48326 (A-MSE: 0.41963) avg lploss: 0.00000
==> val epoch 580 avg loss: 1.02328 (A-MSE: 0.91416) avg lploss: 0.00000
==> test epoch 580 avg loss: 1.14899 (A-MSE: 1.05497) avg lploss: 0.00000
*** Best Val Loss: 1.01127 	 Best Test Loss: 1.17422 	 Best epoch 560
EarlyStopping counter: 4 out of 50
train epoch 581 avg loss: 0.46923 (A-MSE: 0.41204) avg lploss: 0.00000
train epoch 582 avg loss: 0.51360 (A-MSE: 0.44713) avg lploss: 0.00000
train epoch 583 avg loss: 0.46775 (A-MSE: 0.40873) avg lploss: 0.00000
train epoch 584 avg loss: 0.41379 (A-MSE: 0.36250) avg lploss: 0.00000
train epoch 585 avg loss: 0.46866 (A-MSE: 0.41151) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.95238 (A-MSE: 0.84027) avg lploss: 0.00000
==> test epoch 585 avg loss: 1.03327 (A-MSE: 0.93991) avg lploss: 0.00000
*** Best Val Loss: 0.95238 	 Best Test Loss: 1.03327 	 Best epoch 585
Validation loss decreased (1.011274 --> 0.952381).  Saving model ...
train epoch 586 avg loss: 0.44889 (A-MSE: 0.38964) avg lploss: 0.00000
train epoch 587 avg loss: 0.42485 (A-MSE: 0.37371) avg lploss: 0.00000
train epoch 588 avg loss: 0.43046 (A-MSE: 0.37401) avg lploss: 0.00000
train epoch 589 avg loss: 0.42912 (A-MSE: 0.37771) avg lploss: 0.00000
train epoch 590 avg loss: 0.51052 (A-MSE: 0.44505) avg lploss: 0.00000
==> val epoch 590 avg loss: 1.23834 (A-MSE: 1.08597) avg lploss: 0.00000
==> test epoch 590 avg loss: 1.34943 (A-MSE: 1.22402) avg lploss: 0.00000
*** Best Val Loss: 0.95238 	 Best Test Loss: 1.03327 	 Best epoch 585
EarlyStopping counter: 1 out of 50
train epoch 591 avg loss: 0.52731 (A-MSE: 0.46213) avg lploss: 0.00000
train epoch 592 avg loss: 0.48017 (A-MSE: 0.42065) avg lploss: 0.00000
train epoch 593 avg loss: 0.44335 (A-MSE: 0.38912) avg lploss: 0.00000
train epoch 594 avg loss: 0.43553 (A-MSE: 0.38082) avg lploss: 0.00000
train epoch 595 avg loss: 0.45197 (A-MSE: 0.39315) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.90810 (A-MSE: 0.80999) avg lploss: 0.00000
==> test epoch 595 avg loss: 1.05127 (A-MSE: 0.96758) avg lploss: 0.00000
*** Best Val Loss: 0.90810 	 Best Test Loss: 1.05127 	 Best epoch 595
Validation loss decreased (0.952381 --> 0.908096).  Saving model ...
train epoch 596 avg loss: 0.41671 (A-MSE: 0.36649) avg lploss: 0.00000
train epoch 597 avg loss: 0.43536 (A-MSE: 0.38069) avg lploss: 0.00000
train epoch 598 avg loss: 0.42601 (A-MSE: 0.37360) avg lploss: 0.00000
train epoch 599 avg loss: 0.45025 (A-MSE: 0.39264) avg lploss: 0.00000
train epoch 600 avg loss: 0.41643 (A-MSE: 0.36544) avg lploss: 0.00000
==> val epoch 600 avg loss: 1.00538 (A-MSE: 0.89585) avg lploss: 0.00000
==> test epoch 600 avg loss: 1.10646 (A-MSE: 1.01902) avg lploss: 0.00000
*** Best Val Loss: 0.90810 	 Best Test Loss: 1.05127 	 Best epoch 595
EarlyStopping counter: 1 out of 50
train epoch 601 avg loss: 0.41353 (A-MSE: 0.35954) avg lploss: 0.00000
train epoch 602 avg loss: 0.38706 (A-MSE: 0.33711) avg lploss: 0.00000
train epoch 603 avg loss: 0.43615 (A-MSE: 0.38310) avg lploss: 0.00000
train epoch 604 avg loss: 0.43647 (A-MSE: 0.38348) avg lploss: 0.00000
train epoch 605 avg loss: 0.43470 (A-MSE: 0.38117) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.89216 (A-MSE: 0.80123) avg lploss: 0.00000
==> test epoch 605 avg loss: 1.05065 (A-MSE: 0.97059) avg lploss: 0.00000
*** Best Val Loss: 0.89216 	 Best Test Loss: 1.05065 	 Best epoch 605
Validation loss decreased (0.908096 --> 0.892164).  Saving model ...
train epoch 606 avg loss: 0.43668 (A-MSE: 0.38135) avg lploss: 0.00000
train epoch 607 avg loss: 0.46954 (A-MSE: 0.41117) avg lploss: 0.00000
train epoch 608 avg loss: 0.48890 (A-MSE: 0.42749) avg lploss: 0.00000
train epoch 609 avg loss: 0.54663 (A-MSE: 0.48108) avg lploss: 0.00000
train epoch 610 avg loss: 0.44449 (A-MSE: 0.38933) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.99938 (A-MSE: 0.87732) avg lploss: 0.00000
==> test epoch 610 avg loss: 1.10994 (A-MSE: 1.00319) avg lploss: 0.00000
*** Best Val Loss: 0.89216 	 Best Test Loss: 1.05065 	 Best epoch 605
EarlyStopping counter: 1 out of 50
train epoch 611 avg loss: 0.48286 (A-MSE: 0.42534) avg lploss: 0.00000
train epoch 612 avg loss: 0.44529 (A-MSE: 0.38585) avg lploss: 0.00000
train epoch 613 avg loss: 0.47341 (A-MSE: 0.41394) avg lploss: 0.00000
train epoch 614 avg loss: 0.47987 (A-MSE: 0.42278) avg lploss: 0.00000
train epoch 615 avg loss: 0.41801 (A-MSE: 0.36608) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.88809 (A-MSE: 0.79709) avg lploss: 0.00000
==> test epoch 615 avg loss: 1.03302 (A-MSE: 0.95108) avg lploss: 0.00000
*** Best Val Loss: 0.88809 	 Best Test Loss: 1.03302 	 Best epoch 615
Validation loss decreased (0.892164 --> 0.888094).  Saving model ...
train epoch 616 avg loss: 0.42644 (A-MSE: 0.37372) avg lploss: 0.00000
train epoch 617 avg loss: 0.51304 (A-MSE: 0.44803) avg lploss: 0.00000
train epoch 618 avg loss: 0.51797 (A-MSE: 0.45277) avg lploss: 0.00000
train epoch 619 avg loss: 0.43808 (A-MSE: 0.38538) avg lploss: 0.00000
train epoch 620 avg loss: 0.38317 (A-MSE: 0.33531) avg lploss: 0.00000
==> val epoch 620 avg loss: 1.01074 (A-MSE: 0.88580) avg lploss: 0.00000
==> test epoch 620 avg loss: 1.13014 (A-MSE: 1.02232) avg lploss: 0.00000
*** Best Val Loss: 0.88809 	 Best Test Loss: 1.03302 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.41857 (A-MSE: 0.36663) avg lploss: 0.00000
train epoch 622 avg loss: 0.40101 (A-MSE: 0.35166) avg lploss: 0.00000
train epoch 623 avg loss: 0.41681 (A-MSE: 0.36414) avg lploss: 0.00000
train epoch 624 avg loss: 0.38864 (A-MSE: 0.33989) avg lploss: 0.00000
train epoch 625 avg loss: 0.39849 (A-MSE: 0.34875) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.89943 (A-MSE: 0.80323) avg lploss: 0.00000
==> test epoch 625 avg loss: 1.01782 (A-MSE: 0.93372) avg lploss: 0.00000
*** Best Val Loss: 0.88809 	 Best Test Loss: 1.03302 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.42965 (A-MSE: 0.37468) avg lploss: 0.00000
train epoch 627 avg loss: 0.45559 (A-MSE: 0.40140) avg lploss: 0.00000
train epoch 628 avg loss: 0.48639 (A-MSE: 0.42237) avg lploss: 0.00000
train epoch 629 avg loss: 0.43870 (A-MSE: 0.38416) avg lploss: 0.00000
train epoch 630 avg loss: 0.37528 (A-MSE: 0.32822) avg lploss: 0.00000
==> val epoch 630 avg loss: 1.01257 (A-MSE: 0.90191) avg lploss: 0.00000
==> test epoch 630 avg loss: 1.07442 (A-MSE: 0.98361) avg lploss: 0.00000
*** Best Val Loss: 0.88809 	 Best Test Loss: 1.03302 	 Best epoch 615
EarlyStopping counter: 3 out of 50
train epoch 631 avg loss: 0.40579 (A-MSE: 0.35423) avg lploss: 0.00000
train epoch 632 avg loss: 0.59343 (A-MSE: 0.52309) avg lploss: 0.00000
train epoch 633 avg loss: 0.47062 (A-MSE: 0.41378) avg lploss: 0.00000
train epoch 634 avg loss: 0.41366 (A-MSE: 0.36196) avg lploss: 0.00000
train epoch 635 avg loss: 0.39159 (A-MSE: 0.34479) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.96225 (A-MSE: 0.85927) avg lploss: 0.00000
==> test epoch 635 avg loss: 1.06256 (A-MSE: 0.97780) avg lploss: 0.00000
*** Best Val Loss: 0.88809 	 Best Test Loss: 1.03302 	 Best epoch 615
EarlyStopping counter: 4 out of 50
train epoch 636 avg loss: 0.40571 (A-MSE: 0.35172) avg lploss: 0.00000
train epoch 637 avg loss: 0.41945 (A-MSE: 0.36926) avg lploss: 0.00000
train epoch 638 avg loss: 0.38663 (A-MSE: 0.33855) avg lploss: 0.00000
train epoch 639 avg loss: 0.41588 (A-MSE: 0.36773) avg lploss: 0.00000
train epoch 640 avg loss: 0.42608 (A-MSE: 0.37304) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.87025 (A-MSE: 0.76855) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.99507 (A-MSE: 0.91025) avg lploss: 0.00000
*** Best Val Loss: 0.87025 	 Best Test Loss: 0.99507 	 Best epoch 640
Validation loss decreased (0.888094 --> 0.870253).  Saving model ...
train epoch 641 avg loss: 0.35970 (A-MSE: 0.31329) avg lploss: 0.00000
train epoch 642 avg loss: 0.39469 (A-MSE: 0.34379) avg lploss: 0.00000
train epoch 643 avg loss: 0.36950 (A-MSE: 0.32659) avg lploss: 0.00000
train epoch 644 avg loss: 0.37640 (A-MSE: 0.32763) avg lploss: 0.00000
train epoch 645 avg loss: 0.40816 (A-MSE: 0.35903) avg lploss: 0.00000
==> val epoch 645 avg loss: 1.17183 (A-MSE: 1.03726) avg lploss: 0.00000
==> test epoch 645 avg loss: 1.25008 (A-MSE: 1.13966) avg lploss: 0.00000
*** Best Val Loss: 0.87025 	 Best Test Loss: 0.99507 	 Best epoch 640
EarlyStopping counter: 1 out of 50
train epoch 646 avg loss: 0.46537 (A-MSE: 0.40740) avg lploss: 0.00000
train epoch 647 avg loss: 0.41692 (A-MSE: 0.36574) avg lploss: 0.00000
train epoch 648 avg loss: 0.39863 (A-MSE: 0.34745) avg lploss: 0.00000
train epoch 649 avg loss: 0.38622 (A-MSE: 0.33737) avg lploss: 0.00000
train epoch 650 avg loss: 0.40573 (A-MSE: 0.35492) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.83547 (A-MSE: 0.75025) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.93999 (A-MSE: 0.86562) avg lploss: 0.00000
*** Best Val Loss: 0.83547 	 Best Test Loss: 0.93999 	 Best epoch 650
Validation loss decreased (0.870253 --> 0.835471).  Saving model ...
train epoch 651 avg loss: 0.40376 (A-MSE: 0.35405) avg lploss: 0.00000
train epoch 652 avg loss: 0.39307 (A-MSE: 0.34435) avg lploss: 0.00000
train epoch 653 avg loss: 0.43045 (A-MSE: 0.37919) avg lploss: 0.00000
train epoch 654 avg loss: 0.39182 (A-MSE: 0.34306) avg lploss: 0.00000
train epoch 655 avg loss: 0.40204 (A-MSE: 0.35434) avg lploss: 0.00000
==> val epoch 655 avg loss: 1.18114 (A-MSE: 1.04550) avg lploss: 0.00000
==> test epoch 655 avg loss: 1.18477 (A-MSE: 1.08333) avg lploss: 0.00000
*** Best Val Loss: 0.83547 	 Best Test Loss: 0.93999 	 Best epoch 650
EarlyStopping counter: 1 out of 50
train epoch 656 avg loss: 0.40560 (A-MSE: 0.35420) avg lploss: 0.00000
train epoch 657 avg loss: 0.37818 (A-MSE: 0.33236) avg lploss: 0.00000
train epoch 658 avg loss: 0.35604 (A-MSE: 0.31203) avg lploss: 0.00000
train epoch 659 avg loss: 0.36655 (A-MSE: 0.32226) avg lploss: 0.00000
train epoch 660 avg loss: 0.35784 (A-MSE: 0.31420) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.82661 (A-MSE: 0.75162) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.91400 (A-MSE: 0.85185) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
Validation loss decreased (0.835471 --> 0.826605).  Saving model ...
train epoch 661 avg loss: 0.39146 (A-MSE: 0.34280) avg lploss: 0.00000
train epoch 662 avg loss: 0.50293 (A-MSE: 0.44045) avg lploss: 0.00000
train epoch 663 avg loss: 0.64355 (A-MSE: 0.56404) avg lploss: 0.00000
train epoch 664 avg loss: 0.58212 (A-MSE: 0.51055) avg lploss: 0.00000
train epoch 665 avg loss: 0.48922 (A-MSE: 0.43387) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.97750 (A-MSE: 0.86515) avg lploss: 0.00000
==> test epoch 665 avg loss: 1.04089 (A-MSE: 0.94492) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
EarlyStopping counter: 1 out of 50
train epoch 666 avg loss: 0.40985 (A-MSE: 0.35889) avg lploss: 0.00000
train epoch 667 avg loss: 0.34807 (A-MSE: 0.30519) avg lploss: 0.00000
train epoch 668 avg loss: 0.34676 (A-MSE: 0.30280) avg lploss: 0.00000
train epoch 669 avg loss: 0.35670 (A-MSE: 0.31508) avg lploss: 0.00000
train epoch 670 avg loss: 0.39033 (A-MSE: 0.34096) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.87405 (A-MSE: 0.77184) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.93674 (A-MSE: 0.85001) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
EarlyStopping counter: 2 out of 50
train epoch 671 avg loss: 0.37375 (A-MSE: 0.32522) avg lploss: 0.00000
train epoch 672 avg loss: 0.37398 (A-MSE: 0.32944) avg lploss: 0.00000
train epoch 673 avg loss: 0.36420 (A-MSE: 0.31829) avg lploss: 0.00000
train epoch 674 avg loss: 0.32847 (A-MSE: 0.28457) avg lploss: 0.00000
train epoch 675 avg loss: 0.35904 (A-MSE: 0.31604) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.90154 (A-MSE: 0.79698) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.97666 (A-MSE: 0.89260) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
EarlyStopping counter: 3 out of 50
train epoch 676 avg loss: 0.34492 (A-MSE: 0.30245) avg lploss: 0.00000
train epoch 677 avg loss: 0.36765 (A-MSE: 0.32263) avg lploss: 0.00000
train epoch 678 avg loss: 0.44685 (A-MSE: 0.39370) avg lploss: 0.00000
train epoch 679 avg loss: 0.36522 (A-MSE: 0.32084) avg lploss: 0.00000
train epoch 680 avg loss: 0.38245 (A-MSE: 0.33435) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.85153 (A-MSE: 0.78133) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.93591 (A-MSE: 0.88339) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
EarlyStopping counter: 4 out of 50
train epoch 681 avg loss: 0.33532 (A-MSE: 0.29439) avg lploss: 0.00000
train epoch 682 avg loss: 0.36719 (A-MSE: 0.32224) avg lploss: 0.00000
train epoch 683 avg loss: 0.32062 (A-MSE: 0.27818) avg lploss: 0.00000
train epoch 684 avg loss: 0.32048 (A-MSE: 0.28176) avg lploss: 0.00000
train epoch 685 avg loss: 0.41491 (A-MSE: 0.36511) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.96181 (A-MSE: 0.83896) avg lploss: 0.00000
==> test epoch 685 avg loss: 1.01086 (A-MSE: 0.91461) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
EarlyStopping counter: 5 out of 50
train epoch 686 avg loss: 0.37684 (A-MSE: 0.32898) avg lploss: 0.00000
train epoch 687 avg loss: 0.31976 (A-MSE: 0.28073) avg lploss: 0.00000
train epoch 688 avg loss: 0.36056 (A-MSE: 0.31593) avg lploss: 0.00000
train epoch 689 avg loss: 0.37769 (A-MSE: 0.33022) avg lploss: 0.00000
train epoch 690 avg loss: 0.39080 (A-MSE: 0.34236) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.95222 (A-MSE: 0.85999) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.99714 (A-MSE: 0.93108) avg lploss: 0.00000
*** Best Val Loss: 0.82661 	 Best Test Loss: 0.91400 	 Best epoch 660
EarlyStopping counter: 6 out of 50
train epoch 691 avg loss: 0.37475 (A-MSE: 0.33096) avg lploss: 0.00000
train epoch 692 avg loss: 0.33966 (A-MSE: 0.29852) avg lploss: 0.00000
train epoch 693 avg loss: 0.36990 (A-MSE: 0.32326) avg lploss: 0.00000
train epoch 694 avg loss: 0.33239 (A-MSE: 0.29094) avg lploss: 0.00000
train epoch 695 avg loss: 0.32902 (A-MSE: 0.28598) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.79477 (A-MSE: 0.71558) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.86297 (A-MSE: 0.79699) avg lploss: 0.00000
*** Best Val Loss: 0.79477 	 Best Test Loss: 0.86297 	 Best epoch 695
Validation loss decreased (0.826605 --> 0.794775).  Saving model ...
train epoch 696 avg loss: 0.33716 (A-MSE: 0.29579) avg lploss: 0.00000
train epoch 697 avg loss: 0.34166 (A-MSE: 0.30085) avg lploss: 0.00000
train epoch 698 avg loss: 0.35226 (A-MSE: 0.30903) avg lploss: 0.00000
train epoch 699 avg loss: 0.40381 (A-MSE: 0.35563) avg lploss: 0.00000
train epoch 700 avg loss: 0.36045 (A-MSE: 0.31627) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.83113 (A-MSE: 0.75681) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.88508 (A-MSE: 0.82330) avg lploss: 0.00000
*** Best Val Loss: 0.79477 	 Best Test Loss: 0.86297 	 Best epoch 695
EarlyStopping counter: 1 out of 50
train epoch 701 avg loss: 0.32710 (A-MSE: 0.28694) avg lploss: 0.00000
train epoch 702 avg loss: 0.41688 (A-MSE: 0.36619) avg lploss: 0.00000
train epoch 703 avg loss: 0.44804 (A-MSE: 0.39009) avg lploss: 0.00000
train epoch 704 avg loss: 0.35437 (A-MSE: 0.31224) avg lploss: 0.00000
train epoch 705 avg loss: 0.36134 (A-MSE: 0.31430) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.86355 (A-MSE: 0.77553) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.91457 (A-MSE: 0.84166) avg lploss: 0.00000
*** Best Val Loss: 0.79477 	 Best Test Loss: 0.86297 	 Best epoch 695
EarlyStopping counter: 2 out of 50
train epoch 706 avg loss: 0.33457 (A-MSE: 0.29250) avg lploss: 0.00000
train epoch 707 avg loss: 0.32349 (A-MSE: 0.28600) avg lploss: 0.00000
train epoch 708 avg loss: 0.33332 (A-MSE: 0.29070) avg lploss: 0.00000
train epoch 709 avg loss: 0.38454 (A-MSE: 0.33731) avg lploss: 0.00000
train epoch 710 avg loss: 0.34357 (A-MSE: 0.30139) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.84347 (A-MSE: 0.76782) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.92326 (A-MSE: 0.86537) avg lploss: 0.00000
*** Best Val Loss: 0.79477 	 Best Test Loss: 0.86297 	 Best epoch 695
EarlyStopping counter: 3 out of 50
train epoch 711 avg loss: 0.33052 (A-MSE: 0.28948) avg lploss: 0.00000
train epoch 712 avg loss: 0.30256 (A-MSE: 0.26648) avg lploss: 0.00000
train epoch 713 avg loss: 0.30951 (A-MSE: 0.27081) avg lploss: 0.00000
train epoch 714 avg loss: 0.31211 (A-MSE: 0.27317) avg lploss: 0.00000
train epoch 715 avg loss: 0.36228 (A-MSE: 0.31783) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.73390 (A-MSE: 0.66430) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.83304 (A-MSE: 0.77193) avg lploss: 0.00000
*** Best Val Loss: 0.73390 	 Best Test Loss: 0.83304 	 Best epoch 715
Validation loss decreased (0.794775 --> 0.733903).  Saving model ...
train epoch 716 avg loss: 0.36843 (A-MSE: 0.32376) avg lploss: 0.00000
train epoch 717 avg loss: 0.40845 (A-MSE: 0.35736) avg lploss: 0.00000
train epoch 718 avg loss: 0.34742 (A-MSE: 0.30333) avg lploss: 0.00000
train epoch 719 avg loss: 0.29404 (A-MSE: 0.25776) avg lploss: 0.00000
train epoch 720 avg loss: 0.32463 (A-MSE: 0.28332) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.85349 (A-MSE: 0.77767) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.88198 (A-MSE: 0.81777) avg lploss: 0.00000
*** Best Val Loss: 0.73390 	 Best Test Loss: 0.83304 	 Best epoch 715
EarlyStopping counter: 1 out of 50
train epoch 721 avg loss: 0.38596 (A-MSE: 0.33805) avg lploss: 0.00000
train epoch 722 avg loss: 0.38898 (A-MSE: 0.34040) avg lploss: 0.00000
train epoch 723 avg loss: 0.34951 (A-MSE: 0.30616) avg lploss: 0.00000
train epoch 724 avg loss: 0.33063 (A-MSE: 0.28866) avg lploss: 0.00000
train epoch 725 avg loss: 0.32994 (A-MSE: 0.29068) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.80240 (A-MSE: 0.72217) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.87993 (A-MSE: 0.81705) avg lploss: 0.00000
*** Best Val Loss: 0.73390 	 Best Test Loss: 0.83304 	 Best epoch 715
EarlyStopping counter: 2 out of 50
train epoch 726 avg loss: 0.30109 (A-MSE: 0.26639) avg lploss: 0.00000
train epoch 727 avg loss: 0.35042 (A-MSE: 0.30850) avg lploss: 0.00000
train epoch 728 avg loss: 0.35353 (A-MSE: 0.30577) avg lploss: 0.00000
train epoch 729 avg loss: 0.30691 (A-MSE: 0.27070) avg lploss: 0.00000
train epoch 730 avg loss: 0.33541 (A-MSE: 0.29299) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.84443 (A-MSE: 0.76487) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.87621 (A-MSE: 0.80937) avg lploss: 0.00000
*** Best Val Loss: 0.73390 	 Best Test Loss: 0.83304 	 Best epoch 715
EarlyStopping counter: 3 out of 50
train epoch 731 avg loss: 0.32697 (A-MSE: 0.28737) avg lploss: 0.00000
train epoch 732 avg loss: 0.30318 (A-MSE: 0.26401) avg lploss: 0.00000
train epoch 733 avg loss: 0.32398 (A-MSE: 0.28471) avg lploss: 0.00000
train epoch 734 avg loss: 0.34328 (A-MSE: 0.30158) avg lploss: 0.00000
train epoch 735 avg loss: 0.31379 (A-MSE: 0.27437) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.69051 (A-MSE: 0.62110) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.77598 (A-MSE: 0.71141) avg lploss: 0.00000
*** Best Val Loss: 0.69051 	 Best Test Loss: 0.77598 	 Best epoch 735
Validation loss decreased (0.733903 --> 0.690513).  Saving model ...
train epoch 736 avg loss: 0.33048 (A-MSE: 0.28974) avg lploss: 0.00000
train epoch 737 avg loss: 0.35640 (A-MSE: 0.30856) avg lploss: 0.00000
train epoch 738 avg loss: 0.32770 (A-MSE: 0.28794) avg lploss: 0.00000
train epoch 739 avg loss: 0.34410 (A-MSE: 0.30102) avg lploss: 0.00000
train epoch 740 avg loss: 0.30774 (A-MSE: 0.26990) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.70652 (A-MSE: 0.63100) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.79095 (A-MSE: 0.72613) avg lploss: 0.00000
*** Best Val Loss: 0.69051 	 Best Test Loss: 0.77598 	 Best epoch 735
EarlyStopping counter: 1 out of 50
train epoch 741 avg loss: 0.28257 (A-MSE: 0.24781) avg lploss: 0.00000
train epoch 742 avg loss: 0.33005 (A-MSE: 0.28961) avg lploss: 0.00000
train epoch 743 avg loss: 0.32674 (A-MSE: 0.28575) avg lploss: 0.00000
train epoch 744 avg loss: 0.33041 (A-MSE: 0.29162) avg lploss: 0.00000
train epoch 745 avg loss: 0.33223 (A-MSE: 0.29053) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.84535 (A-MSE: 0.75484) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.89174 (A-MSE: 0.81037) avg lploss: 0.00000
*** Best Val Loss: 0.69051 	 Best Test Loss: 0.77598 	 Best epoch 735
EarlyStopping counter: 2 out of 50
train epoch 746 avg loss: 0.29272 (A-MSE: 0.25541) avg lploss: 0.00000
train epoch 747 avg loss: 0.29095 (A-MSE: 0.25438) avg lploss: 0.00000
train epoch 748 avg loss: 0.33738 (A-MSE: 0.29370) avg lploss: 0.00000
train epoch 749 avg loss: 0.36762 (A-MSE: 0.32023) avg lploss: 0.00000
train epoch 750 avg loss: 0.29795 (A-MSE: 0.25875) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.75002 (A-MSE: 0.67322) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.79962 (A-MSE: 0.73575) avg lploss: 0.00000
*** Best Val Loss: 0.69051 	 Best Test Loss: 0.77598 	 Best epoch 735
EarlyStopping counter: 3 out of 50
train epoch 751 avg loss: 0.25089 (A-MSE: 0.22061) avg lploss: 0.00000
train epoch 752 avg loss: 0.26658 (A-MSE: 0.23391) avg lploss: 0.00000
train epoch 753 avg loss: 0.29896 (A-MSE: 0.26375) avg lploss: 0.00000
train epoch 754 avg loss: 0.28439 (A-MSE: 0.25064) avg lploss: 0.00000
train epoch 755 avg loss: 0.33569 (A-MSE: 0.29261) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.80784 (A-MSE: 0.71845) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.79851 (A-MSE: 0.72988) avg lploss: 0.00000
*** Best Val Loss: 0.69051 	 Best Test Loss: 0.77598 	 Best epoch 735
EarlyStopping counter: 4 out of 50
train epoch 756 avg loss: 0.31644 (A-MSE: 0.27810) avg lploss: 0.00000
train epoch 757 avg loss: 0.28628 (A-MSE: 0.25073) avg lploss: 0.00000
train epoch 758 avg loss: 0.25558 (A-MSE: 0.22454) avg lploss: 0.00000
train epoch 759 avg loss: 0.29029 (A-MSE: 0.25313) avg lploss: 0.00000
train epoch 760 avg loss: 0.30103 (A-MSE: 0.26444) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.73609 (A-MSE: 0.65862) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.77343 (A-MSE: 0.71244) avg lploss: 0.00000
*** Best Val Loss: 0.69051 	 Best Test Loss: 0.77598 	 Best epoch 735
EarlyStopping counter: 5 out of 50
train epoch 761 avg loss: 0.26779 (A-MSE: 0.23330) avg lploss: 0.00000
train epoch 762 avg loss: 0.25845 (A-MSE: 0.22464) avg lploss: 0.00000
train epoch 763 avg loss: 0.27169 (A-MSE: 0.23914) avg lploss: 0.00000
train epoch 764 avg loss: 0.26615 (A-MSE: 0.23374) avg lploss: 0.00000
train epoch 765 avg loss: 0.28563 (A-MSE: 0.24997) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.68097 (A-MSE: 0.61511) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.72955 (A-MSE: 0.67353) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
Validation loss decreased (0.690513 --> 0.680972).  Saving model ...
train epoch 766 avg loss: 0.27216 (A-MSE: 0.23934) avg lploss: 0.00000
train epoch 767 avg loss: 0.27074 (A-MSE: 0.23667) avg lploss: 0.00000
train epoch 768 avg loss: 0.31005 (A-MSE: 0.27117) avg lploss: 0.00000
train epoch 769 avg loss: 0.32724 (A-MSE: 0.28523) avg lploss: 0.00000
train epoch 770 avg loss: 0.35120 (A-MSE: 0.30890) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.82421 (A-MSE: 0.74347) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.83428 (A-MSE: 0.76971) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 1 out of 50
train epoch 771 avg loss: 0.32732 (A-MSE: 0.28761) avg lploss: 0.00000
train epoch 772 avg loss: 0.29695 (A-MSE: 0.26008) avg lploss: 0.00000
train epoch 773 avg loss: 0.28933 (A-MSE: 0.25302) avg lploss: 0.00000
train epoch 774 avg loss: 0.30415 (A-MSE: 0.26610) avg lploss: 0.00000
train epoch 775 avg loss: 0.26058 (A-MSE: 0.22846) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.68524 (A-MSE: 0.61065) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.72457 (A-MSE: 0.66331) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 2 out of 50
train epoch 776 avg loss: 0.27112 (A-MSE: 0.23746) avg lploss: 0.00000
train epoch 777 avg loss: 0.26976 (A-MSE: 0.23780) avg lploss: 0.00000
train epoch 778 avg loss: 0.23767 (A-MSE: 0.20730) avg lploss: 0.00000
train epoch 779 avg loss: 0.25362 (A-MSE: 0.22265) avg lploss: 0.00000
train epoch 780 avg loss: 0.26705 (A-MSE: 0.23355) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.68868 (A-MSE: 0.62393) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.74225 (A-MSE: 0.68832) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 3 out of 50
train epoch 781 avg loss: 0.28242 (A-MSE: 0.24744) avg lploss: 0.00000
train epoch 782 avg loss: 0.25647 (A-MSE: 0.22489) avg lploss: 0.00000
train epoch 783 avg loss: 0.30326 (A-MSE: 0.26396) avg lploss: 0.00000
train epoch 784 avg loss: 0.29715 (A-MSE: 0.26031) avg lploss: 0.00000
train epoch 785 avg loss: 0.29455 (A-MSE: 0.25678) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.79250 (A-MSE: 0.72786) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.79440 (A-MSE: 0.74250) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 4 out of 50
train epoch 786 avg loss: 0.27512 (A-MSE: 0.24318) avg lploss: 0.00000
train epoch 787 avg loss: 0.28286 (A-MSE: 0.24682) avg lploss: 0.00000
train epoch 788 avg loss: 0.27449 (A-MSE: 0.23867) avg lploss: 0.00000
train epoch 789 avg loss: 0.29694 (A-MSE: 0.25783) avg lploss: 0.00000
train epoch 790 avg loss: 0.34754 (A-MSE: 0.30436) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.74204 (A-MSE: 0.66646) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.74486 (A-MSE: 0.68612) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 5 out of 50
train epoch 791 avg loss: 0.28095 (A-MSE: 0.24764) avg lploss: 0.00000
train epoch 792 avg loss: 0.27348 (A-MSE: 0.23987) avg lploss: 0.00000
train epoch 793 avg loss: 0.25989 (A-MSE: 0.22686) avg lploss: 0.00000
train epoch 794 avg loss: 0.27052 (A-MSE: 0.23875) avg lploss: 0.00000
train epoch 795 avg loss: 0.29408 (A-MSE: 0.25921) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.70437 (A-MSE: 0.64473) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.73771 (A-MSE: 0.68833) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 6 out of 50
train epoch 796 avg loss: 0.35618 (A-MSE: 0.31032) avg lploss: 0.00000
train epoch 797 avg loss: 0.34011 (A-MSE: 0.30030) avg lploss: 0.00000
train epoch 798 avg loss: 0.33147 (A-MSE: 0.29017) avg lploss: 0.00000
train epoch 799 avg loss: 0.31320 (A-MSE: 0.27609) avg lploss: 0.00000
train epoch 800 avg loss: 0.27216 (A-MSE: 0.23866) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.77508 (A-MSE: 0.68517) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.75785 (A-MSE: 0.68687) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 7 out of 50
train epoch 801 avg loss: 0.28685 (A-MSE: 0.24935) avg lploss: 0.00000
train epoch 802 avg loss: 0.26487 (A-MSE: 0.23056) avg lploss: 0.00000
train epoch 803 avg loss: 0.24816 (A-MSE: 0.21719) avg lploss: 0.00000
train epoch 804 avg loss: 0.26651 (A-MSE: 0.23332) avg lploss: 0.00000
train epoch 805 avg loss: 0.29242 (A-MSE: 0.25760) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.75603 (A-MSE: 0.68332) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.75551 (A-MSE: 0.69998) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 8 out of 50
train epoch 806 avg loss: 0.30817 (A-MSE: 0.27141) avg lploss: 0.00000
train epoch 807 avg loss: 0.27463 (A-MSE: 0.23952) avg lploss: 0.00000
train epoch 808 avg loss: 0.24353 (A-MSE: 0.21429) avg lploss: 0.00000
train epoch 809 avg loss: 0.26593 (A-MSE: 0.23360) avg lploss: 0.00000
train epoch 810 avg loss: 0.28764 (A-MSE: 0.25282) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.88467 (A-MSE: 0.78332) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.89732 (A-MSE: 0.81629) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 9 out of 50
train epoch 811 avg loss: 0.27070 (A-MSE: 0.23660) avg lploss: 0.00000
train epoch 812 avg loss: 0.28508 (A-MSE: 0.24936) avg lploss: 0.00000
train epoch 813 avg loss: 0.30474 (A-MSE: 0.26791) avg lploss: 0.00000
train epoch 814 avg loss: 0.31880 (A-MSE: 0.27874) avg lploss: 0.00000
train epoch 815 avg loss: 0.29038 (A-MSE: 0.25565) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.72267 (A-MSE: 0.64020) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.70848 (A-MSE: 0.64231) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 10 out of 50
train epoch 816 avg loss: 0.25296 (A-MSE: 0.21926) avg lploss: 0.00000
train epoch 817 avg loss: 0.22438 (A-MSE: 0.19764) avg lploss: 0.00000
train epoch 818 avg loss: 0.21443 (A-MSE: 0.18839) avg lploss: 0.00000
train epoch 819 avg loss: 0.24249 (A-MSE: 0.21125) avg lploss: 0.00000
train epoch 820 avg loss: 0.24356 (A-MSE: 0.21410) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.70150 (A-MSE: 0.63019) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.74946 (A-MSE: 0.68748) avg lploss: 0.00000
*** Best Val Loss: 0.68097 	 Best Test Loss: 0.72955 	 Best epoch 765
EarlyStopping counter: 11 out of 50
train epoch 821 avg loss: 0.25446 (A-MSE: 0.22219) avg lploss: 0.00000
train epoch 822 avg loss: 0.28387 (A-MSE: 0.24969) avg lploss: 0.00000
train epoch 823 avg loss: 0.28309 (A-MSE: 0.24697) avg lploss: 0.00000
train epoch 824 avg loss: 0.33606 (A-MSE: 0.29516) avg lploss: 0.00000
train epoch 825 avg loss: 0.30523 (A-MSE: 0.26642) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.64591 (A-MSE: 0.58015) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.71469 (A-MSE: 0.64903) avg lploss: 0.00000
*** Best Val Loss: 0.64591 	 Best Test Loss: 0.71469 	 Best epoch 825
Validation loss decreased (0.680972 --> 0.645912).  Saving model ...
train epoch 826 avg loss: 0.24089 (A-MSE: 0.21327) avg lploss: 0.00000
train epoch 827 avg loss: 0.25709 (A-MSE: 0.22356) avg lploss: 0.00000
train epoch 828 avg loss: 0.26748 (A-MSE: 0.23599) avg lploss: 0.00000
train epoch 829 avg loss: 0.27262 (A-MSE: 0.23636) avg lploss: 0.00000
train epoch 830 avg loss: 0.25532 (A-MSE: 0.22355) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.74728 (A-MSE: 0.66966) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.74566 (A-MSE: 0.67895) avg lploss: 0.00000
*** Best Val Loss: 0.64591 	 Best Test Loss: 0.71469 	 Best epoch 825
EarlyStopping counter: 1 out of 50
train epoch 831 avg loss: 0.23292 (A-MSE: 0.20642) avg lploss: 0.00000
train epoch 832 avg loss: 0.21613 (A-MSE: 0.18854) avg lploss: 0.00000
train epoch 833 avg loss: 0.26267 (A-MSE: 0.22873) avg lploss: 0.00000
train epoch 834 avg loss: 0.23891 (A-MSE: 0.21141) avg lploss: 0.00000
train epoch 835 avg loss: 0.24443 (A-MSE: 0.21297) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.61414 (A-MSE: 0.55344) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.64972 (A-MSE: 0.59384) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
Validation loss decreased (0.645912 --> 0.614142).  Saving model ...
train epoch 836 avg loss: 0.24626 (A-MSE: 0.21638) avg lploss: 0.00000
train epoch 837 avg loss: 0.21408 (A-MSE: 0.18708) avg lploss: 0.00000
train epoch 838 avg loss: 0.24610 (A-MSE: 0.21561) avg lploss: 0.00000
train epoch 839 avg loss: 0.34376 (A-MSE: 0.30136) avg lploss: 0.00000
train epoch 840 avg loss: 0.31782 (A-MSE: 0.28060) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.68497 (A-MSE: 0.61550) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.75308 (A-MSE: 0.68033) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 1 out of 50
train epoch 841 avg loss: 0.35947 (A-MSE: 0.31518) avg lploss: 0.00000
train epoch 842 avg loss: 0.33471 (A-MSE: 0.29655) avg lploss: 0.00000
train epoch 843 avg loss: 0.41001 (A-MSE: 0.35873) avg lploss: 0.00000
train epoch 844 avg loss: 0.31142 (A-MSE: 0.27098) avg lploss: 0.00000
train epoch 845 avg loss: 0.24657 (A-MSE: 0.21393) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.83725 (A-MSE: 0.75310) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.83210 (A-MSE: 0.76623) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 2 out of 50
train epoch 846 avg loss: 0.27469 (A-MSE: 0.24160) avg lploss: 0.00000
train epoch 847 avg loss: 0.29049 (A-MSE: 0.25421) avg lploss: 0.00000
train epoch 848 avg loss: 0.24985 (A-MSE: 0.21968) avg lploss: 0.00000
train epoch 849 avg loss: 0.22138 (A-MSE: 0.19456) avg lploss: 0.00000
train epoch 850 avg loss: 0.25338 (A-MSE: 0.21948) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.68623 (A-MSE: 0.60257) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.69744 (A-MSE: 0.63127) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 3 out of 50
train epoch 851 avg loss: 0.22470 (A-MSE: 0.19694) avg lploss: 0.00000
train epoch 852 avg loss: 0.22155 (A-MSE: 0.19341) avg lploss: 0.00000
train epoch 853 avg loss: 0.22792 (A-MSE: 0.19861) avg lploss: 0.00000
train epoch 854 avg loss: 0.21341 (A-MSE: 0.18831) avg lploss: 0.00000
train epoch 855 avg loss: 0.23252 (A-MSE: 0.20381) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.68754 (A-MSE: 0.61854) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.68703 (A-MSE: 0.62918) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 4 out of 50
train epoch 856 avg loss: 0.21317 (A-MSE: 0.18823) avg lploss: 0.00000
train epoch 857 avg loss: 0.22844 (A-MSE: 0.20081) avg lploss: 0.00000
train epoch 858 avg loss: 0.21652 (A-MSE: 0.19071) avg lploss: 0.00000
train epoch 859 avg loss: 0.27847 (A-MSE: 0.24319) avg lploss: 0.00000
train epoch 860 avg loss: 0.30089 (A-MSE: 0.26378) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.65770 (A-MSE: 0.58563) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.67587 (A-MSE: 0.61280) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 5 out of 50
train epoch 861 avg loss: 0.27341 (A-MSE: 0.23964) avg lploss: 0.00000
train epoch 862 avg loss: 0.24024 (A-MSE: 0.21222) avg lploss: 0.00000
train epoch 863 avg loss: 0.20961 (A-MSE: 0.18325) avg lploss: 0.00000
train epoch 864 avg loss: 0.24021 (A-MSE: 0.21224) avg lploss: 0.00000
train epoch 865 avg loss: 0.22884 (A-MSE: 0.20005) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.70013 (A-MSE: 0.62866) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.75178 (A-MSE: 0.69130) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 6 out of 50
train epoch 866 avg loss: 0.21301 (A-MSE: 0.18757) avg lploss: 0.00000
train epoch 867 avg loss: 0.19754 (A-MSE: 0.17291) avg lploss: 0.00000
train epoch 868 avg loss: 0.21115 (A-MSE: 0.18596) avg lploss: 0.00000
train epoch 869 avg loss: 0.28602 (A-MSE: 0.25015) avg lploss: 0.00000
train epoch 870 avg loss: 0.33902 (A-MSE: 0.29664) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.71332 (A-MSE: 0.65179) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.75474 (A-MSE: 0.69649) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 7 out of 50
train epoch 871 avg loss: 0.31675 (A-MSE: 0.27757) avg lploss: 0.00000
train epoch 872 avg loss: 0.28242 (A-MSE: 0.24764) avg lploss: 0.00000
train epoch 873 avg loss: 0.25369 (A-MSE: 0.22388) avg lploss: 0.00000
train epoch 874 avg loss: 0.22245 (A-MSE: 0.19357) avg lploss: 0.00000
train epoch 875 avg loss: 0.22283 (A-MSE: 0.19572) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.74490 (A-MSE: 0.66904) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.78700 (A-MSE: 0.71240) avg lploss: 0.00000
*** Best Val Loss: 0.61414 	 Best Test Loss: 0.64972 	 Best epoch 835
EarlyStopping counter: 8 out of 50
train epoch 876 avg loss: 0.31048 (A-MSE: 0.27182) avg lploss: 0.00000
train epoch 877 avg loss: 0.28117 (A-MSE: 0.24650) avg lploss: 0.00000
train epoch 878 avg loss: 0.23187 (A-MSE: 0.20257) avg lploss: 0.00000
train epoch 879 avg loss: 0.22619 (A-MSE: 0.19750) avg lploss: 0.00000
train epoch 880 avg loss: 0.22471 (A-MSE: 0.19609) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.60426 (A-MSE: 0.53907) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.65008 (A-MSE: 0.59332) avg lploss: 0.00000
*** Best Val Loss: 0.60426 	 Best Test Loss: 0.65008 	 Best epoch 880
Validation loss decreased (0.614142 --> 0.604256).  Saving model ...
train epoch 881 avg loss: 0.22050 (A-MSE: 0.19326) avg lploss: 0.00000
train epoch 882 avg loss: 0.26535 (A-MSE: 0.23079) avg lploss: 0.00000
train epoch 883 avg loss: 0.25400 (A-MSE: 0.22184) avg lploss: 0.00000
train epoch 884 avg loss: 0.22179 (A-MSE: 0.19491) avg lploss: 0.00000
train epoch 885 avg loss: 0.19610 (A-MSE: 0.17239) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.55642 (A-MSE: 0.50788) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.58884 (A-MSE: 0.54836) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
Validation loss decreased (0.604256 --> 0.556421).  Saving model ...
train epoch 886 avg loss: 0.20102 (A-MSE: 0.17541) avg lploss: 0.00000
train epoch 887 avg loss: 0.24434 (A-MSE: 0.21438) avg lploss: 0.00000
train epoch 888 avg loss: 0.23836 (A-MSE: 0.21151) avg lploss: 0.00000
train epoch 889 avg loss: 0.21055 (A-MSE: 0.18472) avg lploss: 0.00000
train epoch 890 avg loss: 0.20530 (A-MSE: 0.18094) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.63609 (A-MSE: 0.55343) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.64551 (A-MSE: 0.57810) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 1 out of 50
train epoch 891 avg loss: 0.23400 (A-MSE: 0.20477) avg lploss: 0.00000
train epoch 892 avg loss: 0.22570 (A-MSE: 0.19736) avg lploss: 0.00000
train epoch 893 avg loss: 0.22143 (A-MSE: 0.19380) avg lploss: 0.00000
train epoch 894 avg loss: 0.19908 (A-MSE: 0.17419) avg lploss: 0.00000
train epoch 895 avg loss: 0.23409 (A-MSE: 0.20525) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.60309 (A-MSE: 0.54348) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.60853 (A-MSE: 0.56332) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 2 out of 50
train epoch 896 avg loss: 0.23847 (A-MSE: 0.20897) avg lploss: 0.00000
train epoch 897 avg loss: 0.23820 (A-MSE: 0.20836) avg lploss: 0.00000
train epoch 898 avg loss: 0.18908 (A-MSE: 0.16511) avg lploss: 0.00000
train epoch 899 avg loss: 0.22076 (A-MSE: 0.19512) avg lploss: 0.00000
train epoch 900 avg loss: 0.22863 (A-MSE: 0.19942) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.58188 (A-MSE: 0.52725) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.59666 (A-MSE: 0.55165) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 3 out of 50
train epoch 901 avg loss: 0.20703 (A-MSE: 0.18033) avg lploss: 0.00000
train epoch 902 avg loss: 0.22698 (A-MSE: 0.19989) avg lploss: 0.00000
train epoch 903 avg loss: 0.19283 (A-MSE: 0.16815) avg lploss: 0.00000
train epoch 904 avg loss: 0.19567 (A-MSE: 0.17095) avg lploss: 0.00000
train epoch 905 avg loss: 0.21391 (A-MSE: 0.18650) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.68031 (A-MSE: 0.61209) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.68525 (A-MSE: 0.62159) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 4 out of 50
train epoch 906 avg loss: 0.26092 (A-MSE: 0.22622) avg lploss: 0.00000
train epoch 907 avg loss: 0.23837 (A-MSE: 0.20927) avg lploss: 0.00000
train epoch 908 avg loss: 0.19611 (A-MSE: 0.17042) avg lploss: 0.00000
train epoch 909 avg loss: 0.19372 (A-MSE: 0.16900) avg lploss: 0.00000
train epoch 910 avg loss: 0.17641 (A-MSE: 0.15516) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.56505 (A-MSE: 0.50748) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.57898 (A-MSE: 0.52968) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 5 out of 50
train epoch 911 avg loss: 0.20924 (A-MSE: 0.18328) avg lploss: 0.00000
train epoch 912 avg loss: 0.21508 (A-MSE: 0.18880) avg lploss: 0.00000
train epoch 913 avg loss: 0.19163 (A-MSE: 0.16901) avg lploss: 0.00000
train epoch 914 avg loss: 0.20450 (A-MSE: 0.18023) avg lploss: 0.00000
train epoch 915 avg loss: 0.22673 (A-MSE: 0.19855) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.61913 (A-MSE: 0.55784) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.63943 (A-MSE: 0.58890) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 6 out of 50
train epoch 916 avg loss: 0.21540 (A-MSE: 0.18818) avg lploss: 0.00000
train epoch 917 avg loss: 0.21195 (A-MSE: 0.18585) avg lploss: 0.00000
train epoch 918 avg loss: 0.21548 (A-MSE: 0.18926) avg lploss: 0.00000
train epoch 919 avg loss: 0.24506 (A-MSE: 0.21438) avg lploss: 0.00000
train epoch 920 avg loss: 0.22340 (A-MSE: 0.19523) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.71855 (A-MSE: 0.63376) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.71532 (A-MSE: 0.64390) avg lploss: 0.00000
*** Best Val Loss: 0.55642 	 Best Test Loss: 0.58884 	 Best epoch 885
EarlyStopping counter: 7 out of 50
train epoch 921 avg loss: 0.21769 (A-MSE: 0.18932) avg lploss: 0.00000
train epoch 922 avg loss: 0.21882 (A-MSE: 0.18960) avg lploss: 0.00000
train epoch 923 avg loss: 0.20731 (A-MSE: 0.18237) avg lploss: 0.00000
train epoch 924 avg loss: 0.19772 (A-MSE: 0.17200) avg lploss: 0.00000
train epoch 925 avg loss: 0.19922 (A-MSE: 0.17420) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.54687 (A-MSE: 0.47908) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.56323 (A-MSE: 0.50767) avg lploss: 0.00000
*** Best Val Loss: 0.54687 	 Best Test Loss: 0.56323 	 Best epoch 925
Validation loss decreased (0.556421 --> 0.546875).  Saving model ...
train epoch 926 avg loss: 0.18364 (A-MSE: 0.16198) avg lploss: 0.00000
train epoch 927 avg loss: 0.18310 (A-MSE: 0.16014) avg lploss: 0.00000
train epoch 928 avg loss: 0.20651 (A-MSE: 0.18068) avg lploss: 0.00000
train epoch 929 avg loss: 0.20748 (A-MSE: 0.18245) avg lploss: 0.00000
train epoch 930 avg loss: 0.20620 (A-MSE: 0.17930) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.71583 (A-MSE: 0.63008) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.71421 (A-MSE: 0.64566) avg lploss: 0.00000
*** Best Val Loss: 0.54687 	 Best Test Loss: 0.56323 	 Best epoch 925
EarlyStopping counter: 1 out of 50
train epoch 931 avg loss: 0.18647 (A-MSE: 0.16360) avg lploss: 0.00000
train epoch 932 avg loss: 0.18212 (A-MSE: 0.16108) avg lploss: 0.00000
train epoch 933 avg loss: 0.16920 (A-MSE: 0.14796) avg lploss: 0.00000
train epoch 934 avg loss: 0.18960 (A-MSE: 0.16527) avg lploss: 0.00000
train epoch 935 avg loss: 0.21041 (A-MSE: 0.18650) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.78921 (A-MSE: 0.70474) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.76610 (A-MSE: 0.69635) avg lploss: 0.00000
*** Best Val Loss: 0.54687 	 Best Test Loss: 0.56323 	 Best epoch 925
EarlyStopping counter: 2 out of 50
train epoch 936 avg loss: 0.22099 (A-MSE: 0.19362) avg lploss: 0.00000
train epoch 937 avg loss: 0.20683 (A-MSE: 0.18081) avg lploss: 0.00000
train epoch 938 avg loss: 0.20749 (A-MSE: 0.17969) avg lploss: 0.00000
train epoch 939 avg loss: 0.17531 (A-MSE: 0.15370) avg lploss: 0.00000
train epoch 940 avg loss: 0.18901 (A-MSE: 0.16662) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.53548 (A-MSE: 0.47580) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.56381 (A-MSE: 0.50925) avg lploss: 0.00000
*** Best Val Loss: 0.53548 	 Best Test Loss: 0.56381 	 Best epoch 940
Validation loss decreased (0.546875 --> 0.535480).  Saving model ...
train epoch 941 avg loss: 0.18652 (A-MSE: 0.16275) avg lploss: 0.00000
train epoch 942 avg loss: 0.19456 (A-MSE: 0.16899) avg lploss: 0.00000
train epoch 943 avg loss: 0.20027 (A-MSE: 0.17610) avg lploss: 0.00000
train epoch 944 avg loss: 0.19779 (A-MSE: 0.17467) avg lploss: 0.00000
train epoch 945 avg loss: 0.20116 (A-MSE: 0.17486) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.55659 (A-MSE: 0.50046) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.57775 (A-MSE: 0.52192) avg lploss: 0.00000
*** Best Val Loss: 0.53548 	 Best Test Loss: 0.56381 	 Best epoch 940
EarlyStopping counter: 1 out of 50
train epoch 946 avg loss: 0.17808 (A-MSE: 0.15602) avg lploss: 0.00000
train epoch 947 avg loss: 0.19028 (A-MSE: 0.16714) avg lploss: 0.00000
train epoch 948 avg loss: 0.20552 (A-MSE: 0.17969) avg lploss: 0.00000
train epoch 949 avg loss: 0.18464 (A-MSE: 0.16357) avg lploss: 0.00000
train epoch 950 avg loss: 0.20668 (A-MSE: 0.18204) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.64095 (A-MSE: 0.56600) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.64632 (A-MSE: 0.58566) avg lploss: 0.00000
*** Best Val Loss: 0.53548 	 Best Test Loss: 0.56381 	 Best epoch 940
EarlyStopping counter: 2 out of 50
train epoch 951 avg loss: 0.23179 (A-MSE: 0.20252) avg lploss: 0.00000
train epoch 952 avg loss: 0.19879 (A-MSE: 0.17427) avg lploss: 0.00000
train epoch 953 avg loss: 0.20025 (A-MSE: 0.17374) avg lploss: 0.00000
train epoch 954 avg loss: 0.19725 (A-MSE: 0.17305) avg lploss: 0.00000
train epoch 955 avg loss: 0.17170 (A-MSE: 0.15062) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.71529 (A-MSE: 0.62546) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.68066 (A-MSE: 0.60615) avg lploss: 0.00000
*** Best Val Loss: 0.53548 	 Best Test Loss: 0.56381 	 Best epoch 940
EarlyStopping counter: 3 out of 50
train epoch 956 avg loss: 0.21433 (A-MSE: 0.18713) avg lploss: 0.00000
train epoch 957 avg loss: 0.19496 (A-MSE: 0.17320) avg lploss: 0.00000
train epoch 958 avg loss: 0.20284 (A-MSE: 0.17849) avg lploss: 0.00000
train epoch 959 avg loss: 0.18418 (A-MSE: 0.16149) avg lploss: 0.00000
train epoch 960 avg loss: 0.15067 (A-MSE: 0.13200) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.50315 (A-MSE: 0.44887) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.51742 (A-MSE: 0.47061) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
Validation loss decreased (0.535480 --> 0.503149).  Saving model ...
train epoch 961 avg loss: 0.19220 (A-MSE: 0.16678) avg lploss: 0.00000
train epoch 962 avg loss: 0.17873 (A-MSE: 0.15594) avg lploss: 0.00000
train epoch 963 avg loss: 0.18373 (A-MSE: 0.15919) avg lploss: 0.00000
train epoch 964 avg loss: 0.16936 (A-MSE: 0.14861) avg lploss: 0.00000
train epoch 965 avg loss: 0.15106 (A-MSE: 0.13162) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.55192 (A-MSE: 0.49457) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.57719 (A-MSE: 0.52297) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 1 out of 50
train epoch 966 avg loss: 0.16836 (A-MSE: 0.14699) avg lploss: 0.00000
train epoch 967 avg loss: 0.16464 (A-MSE: 0.14352) avg lploss: 0.00000
train epoch 968 avg loss: 0.15324 (A-MSE: 0.13368) avg lploss: 0.00000
train epoch 969 avg loss: 0.18555 (A-MSE: 0.16127) avg lploss: 0.00000
train epoch 970 avg loss: 0.21544 (A-MSE: 0.18846) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.58677 (A-MSE: 0.51776) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.62077 (A-MSE: 0.55553) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 2 out of 50
train epoch 971 avg loss: 0.20196 (A-MSE: 0.17602) avg lploss: 0.00000
train epoch 972 avg loss: 0.17932 (A-MSE: 0.15644) avg lploss: 0.00000
train epoch 973 avg loss: 0.19298 (A-MSE: 0.16761) avg lploss: 0.00000
train epoch 974 avg loss: 0.22455 (A-MSE: 0.19689) avg lploss: 0.00000
train epoch 975 avg loss: 0.22001 (A-MSE: 0.19249) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.60671 (A-MSE: 0.54297) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.64218 (A-MSE: 0.58634) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 3 out of 50
train epoch 976 avg loss: 0.19651 (A-MSE: 0.17188) avg lploss: 0.00000
train epoch 977 avg loss: 0.21107 (A-MSE: 0.18523) avg lploss: 0.00000
train epoch 978 avg loss: 0.19205 (A-MSE: 0.16856) avg lploss: 0.00000
train epoch 979 avg loss: 0.18563 (A-MSE: 0.16132) avg lploss: 0.00000
train epoch 980 avg loss: 0.18570 (A-MSE: 0.16314) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.51785 (A-MSE: 0.46170) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.57806 (A-MSE: 0.51673) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 4 out of 50
train epoch 981 avg loss: 0.16859 (A-MSE: 0.14769) avg lploss: 0.00000
train epoch 982 avg loss: 0.16024 (A-MSE: 0.14046) avg lploss: 0.00000
train epoch 983 avg loss: 0.18418 (A-MSE: 0.16110) avg lploss: 0.00000
train epoch 984 avg loss: 0.17444 (A-MSE: 0.15259) avg lploss: 0.00000
train epoch 985 avg loss: 0.15288 (A-MSE: 0.13402) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.56418 (A-MSE: 0.50047) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.55073 (A-MSE: 0.50046) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 5 out of 50
train epoch 986 avg loss: 0.15741 (A-MSE: 0.13619) avg lploss: 0.00000
train epoch 987 avg loss: 0.21479 (A-MSE: 0.18787) avg lploss: 0.00000
train epoch 988 avg loss: 0.22190 (A-MSE: 0.19587) avg lploss: 0.00000
train epoch 989 avg loss: 0.21389 (A-MSE: 0.18523) avg lploss: 0.00000
train epoch 990 avg loss: 0.16849 (A-MSE: 0.14814) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.61337 (A-MSE: 0.54557) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.62098 (A-MSE: 0.56524) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 6 out of 50
train epoch 991 avg loss: 0.15939 (A-MSE: 0.13947) avg lploss: 0.00000
train epoch 992 avg loss: 0.21435 (A-MSE: 0.18860) avg lploss: 0.00000
train epoch 993 avg loss: 0.21069 (A-MSE: 0.18465) avg lploss: 0.00000
train epoch 994 avg loss: 0.17196 (A-MSE: 0.14922) avg lploss: 0.00000
train epoch 995 avg loss: 0.16463 (A-MSE: 0.14378) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.57665 (A-MSE: 0.52035) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.57377 (A-MSE: 0.52679) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 7 out of 50
train epoch 996 avg loss: 0.19884 (A-MSE: 0.17367) avg lploss: 0.00000
train epoch 997 avg loss: 0.19181 (A-MSE: 0.16696) avg lploss: 0.00000
train epoch 998 avg loss: 0.18892 (A-MSE: 0.16530) avg lploss: 0.00000
train epoch 999 avg loss: 0.16763 (A-MSE: 0.14572) avg lploss: 0.00000
train epoch 1000 avg loss: 0.16349 (A-MSE: 0.14212) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.52671 (A-MSE: 0.46577) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.54962 (A-MSE: 0.49539) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 8 out of 50
train epoch 1001 avg loss: 0.14941 (A-MSE: 0.13074) avg lploss: 0.00000
train epoch 1002 avg loss: 0.16896 (A-MSE: 0.14805) avg lploss: 0.00000
train epoch 1003 avg loss: 0.20620 (A-MSE: 0.18169) avg lploss: 0.00000
train epoch 1004 avg loss: 0.16450 (A-MSE: 0.14259) avg lploss: 0.00000
train epoch 1005 avg loss: 0.17655 (A-MSE: 0.15326) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.60249 (A-MSE: 0.53967) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.58764 (A-MSE: 0.53567) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 9 out of 50
train epoch 1006 avg loss: 0.16173 (A-MSE: 0.14119) avg lploss: 0.00000
train epoch 1007 avg loss: 0.15629 (A-MSE: 0.13753) avg lploss: 0.00000
train epoch 1008 avg loss: 0.14590 (A-MSE: 0.12669) avg lploss: 0.00000
train epoch 1009 avg loss: 0.16955 (A-MSE: 0.14857) avg lploss: 0.00000
train epoch 1010 avg loss: 0.15522 (A-MSE: 0.13514) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.61154 (A-MSE: 0.54140) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.60908 (A-MSE: 0.54746) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 10 out of 50
train epoch 1011 avg loss: 0.14980 (A-MSE: 0.13158) avg lploss: 0.00000
train epoch 1012 avg loss: 0.18111 (A-MSE: 0.15908) avg lploss: 0.00000
train epoch 1013 avg loss: 0.19138 (A-MSE: 0.16876) avg lploss: 0.00000
train epoch 1014 avg loss: 0.16542 (A-MSE: 0.14490) avg lploss: 0.00000
train epoch 1015 avg loss: 0.14588 (A-MSE: 0.12702) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.67715 (A-MSE: 0.61147) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.65338 (A-MSE: 0.59855) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 11 out of 50
train epoch 1016 avg loss: 0.16040 (A-MSE: 0.14139) avg lploss: 0.00000
train epoch 1017 avg loss: 0.16528 (A-MSE: 0.14314) avg lploss: 0.00000
train epoch 1018 avg loss: 0.14817 (A-MSE: 0.12921) avg lploss: 0.00000
train epoch 1019 avg loss: 0.15531 (A-MSE: 0.13693) avg lploss: 0.00000
train epoch 1020 avg loss: 0.16738 (A-MSE: 0.14772) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.60243 (A-MSE: 0.53226) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.61232 (A-MSE: 0.54931) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 12 out of 50
train epoch 1021 avg loss: 0.15545 (A-MSE: 0.13570) avg lploss: 0.00000
train epoch 1022 avg loss: 0.19330 (A-MSE: 0.16933) avg lploss: 0.00000
train epoch 1023 avg loss: 0.20069 (A-MSE: 0.17610) avg lploss: 0.00000
train epoch 1024 avg loss: 0.27260 (A-MSE: 0.23869) avg lploss: 0.00000
train epoch 1025 avg loss: 0.26941 (A-MSE: 0.23302) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.53591 (A-MSE: 0.48897) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.55974 (A-MSE: 0.51503) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 13 out of 50
train epoch 1026 avg loss: 0.19612 (A-MSE: 0.17087) avg lploss: 0.00000
train epoch 1027 avg loss: 0.18391 (A-MSE: 0.16116) avg lploss: 0.00000
train epoch 1028 avg loss: 0.17398 (A-MSE: 0.15177) avg lploss: 0.00000
train epoch 1029 avg loss: 0.18428 (A-MSE: 0.16291) avg lploss: 0.00000
train epoch 1030 avg loss: 0.17986 (A-MSE: 0.15678) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.52318 (A-MSE: 0.46179) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.56057 (A-MSE: 0.50477) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 14 out of 50
train epoch 1031 avg loss: 0.18648 (A-MSE: 0.16438) avg lploss: 0.00000
train epoch 1032 avg loss: 0.17415 (A-MSE: 0.15305) avg lploss: 0.00000
train epoch 1033 avg loss: 0.16628 (A-MSE: 0.14575) avg lploss: 0.00000
train epoch 1034 avg loss: 0.18034 (A-MSE: 0.15888) avg lploss: 0.00000
train epoch 1035 avg loss: 0.17781 (A-MSE: 0.15574) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.62029 (A-MSE: 0.54710) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.60330 (A-MSE: 0.54412) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 15 out of 50
train epoch 1036 avg loss: 0.16694 (A-MSE: 0.14544) avg lploss: 0.00000
train epoch 1037 avg loss: 0.19887 (A-MSE: 0.17656) avg lploss: 0.00000
train epoch 1038 avg loss: 0.17308 (A-MSE: 0.14995) avg lploss: 0.00000
train epoch 1039 avg loss: 0.17358 (A-MSE: 0.15179) avg lploss: 0.00000
train epoch 1040 avg loss: 0.16279 (A-MSE: 0.14193) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.54284 (A-MSE: 0.48166) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.54735 (A-MSE: 0.49294) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 16 out of 50
train epoch 1041 avg loss: 0.14468 (A-MSE: 0.12737) avg lploss: 0.00000
train epoch 1042 avg loss: 0.15617 (A-MSE: 0.13584) avg lploss: 0.00000
train epoch 1043 avg loss: 0.13983 (A-MSE: 0.12176) avg lploss: 0.00000
train epoch 1044 avg loss: 0.14569 (A-MSE: 0.12625) avg lploss: 0.00000
train epoch 1045 avg loss: 0.14814 (A-MSE: 0.12955) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.56137 (A-MSE: 0.49737) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.54017 (A-MSE: 0.48468) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 17 out of 50
train epoch 1046 avg loss: 0.14682 (A-MSE: 0.12773) avg lploss: 0.00000
train epoch 1047 avg loss: 0.13157 (A-MSE: 0.11571) avg lploss: 0.00000
train epoch 1048 avg loss: 0.15668 (A-MSE: 0.13807) avg lploss: 0.00000
train epoch 1049 avg loss: 0.18079 (A-MSE: 0.15551) avg lploss: 0.00000
train epoch 1050 avg loss: 0.18782 (A-MSE: 0.16439) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.55351 (A-MSE: 0.48773) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.57775 (A-MSE: 0.51027) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 18 out of 50
train epoch 1051 avg loss: 0.16688 (A-MSE: 0.14669) avg lploss: 0.00000
train epoch 1052 avg loss: 0.14708 (A-MSE: 0.12931) avg lploss: 0.00000
train epoch 1053 avg loss: 0.15304 (A-MSE: 0.13400) avg lploss: 0.00000
train epoch 1054 avg loss: 0.16661 (A-MSE: 0.14647) avg lploss: 0.00000
train epoch 1055 avg loss: 0.15188 (A-MSE: 0.13205) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.62398 (A-MSE: 0.55107) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.62324 (A-MSE: 0.56644) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 19 out of 50
train epoch 1056 avg loss: 0.15137 (A-MSE: 0.13269) avg lploss: 0.00000
train epoch 1057 avg loss: 0.14482 (A-MSE: 0.12787) avg lploss: 0.00000
train epoch 1058 avg loss: 0.14052 (A-MSE: 0.12318) avg lploss: 0.00000
train epoch 1059 avg loss: 0.16510 (A-MSE: 0.14457) avg lploss: 0.00000
train epoch 1060 avg loss: 0.20297 (A-MSE: 0.17745) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.52975 (A-MSE: 0.46647) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.50850 (A-MSE: 0.45576) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 20 out of 50
train epoch 1061 avg loss: 0.19433 (A-MSE: 0.16942) avg lploss: 0.00000
train epoch 1062 avg loss: 0.18359 (A-MSE: 0.16059) avg lploss: 0.00000
train epoch 1063 avg loss: 0.16244 (A-MSE: 0.14190) avg lploss: 0.00000
train epoch 1064 avg loss: 0.18607 (A-MSE: 0.16348) avg lploss: 0.00000
train epoch 1065 avg loss: 0.18024 (A-MSE: 0.15888) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.56094 (A-MSE: 0.49471) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.58974 (A-MSE: 0.52310) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 21 out of 50
train epoch 1066 avg loss: 0.19284 (A-MSE: 0.16904) avg lploss: 0.00000
train epoch 1067 avg loss: 0.20764 (A-MSE: 0.18262) avg lploss: 0.00000
train epoch 1068 avg loss: 0.17906 (A-MSE: 0.15851) avg lploss: 0.00000
train epoch 1069 avg loss: 0.16551 (A-MSE: 0.14467) avg lploss: 0.00000
train epoch 1070 avg loss: 0.16198 (A-MSE: 0.14264) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.50776 (A-MSE: 0.43900) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.49385 (A-MSE: 0.43972) avg lploss: 0.00000
*** Best Val Loss: 0.50315 	 Best Test Loss: 0.51742 	 Best epoch 960
EarlyStopping counter: 22 out of 50
train epoch 1071 avg loss: 0.13721 (A-MSE: 0.12000) avg lploss: 0.00000
train epoch 1072 avg loss: 0.14391 (A-MSE: 0.12616) avg lploss: 0.00000
train epoch 1073 avg loss: 0.14958 (A-MSE: 0.13113) avg lploss: 0.00000
train epoch 1074 avg loss: 0.14971 (A-MSE: 0.13229) avg lploss: 0.00000
train epoch 1075 avg loss: 0.14055 (A-MSE: 0.12168) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.44564 (A-MSE: 0.39854) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.46819 (A-MSE: 0.42111) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
Validation loss decreased (0.503149 --> 0.445643).  Saving model ...
train epoch 1076 avg loss: 0.19281 (A-MSE: 0.16990) avg lploss: 0.00000
train epoch 1077 avg loss: 0.17641 (A-MSE: 0.15485) avg lploss: 0.00000
train epoch 1078 avg loss: 0.18322 (A-MSE: 0.15879) avg lploss: 0.00000
train epoch 1079 avg loss: 0.17760 (A-MSE: 0.15660) avg lploss: 0.00000
train epoch 1080 avg loss: 0.15461 (A-MSE: 0.13544) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.58288 (A-MSE: 0.51545) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.61278 (A-MSE: 0.54522) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 1 out of 50
train epoch 1081 avg loss: 0.16801 (A-MSE: 0.14512) avg lploss: 0.00000
train epoch 1082 avg loss: 0.13361 (A-MSE: 0.11633) avg lploss: 0.00000
train epoch 1083 avg loss: 0.13862 (A-MSE: 0.12067) avg lploss: 0.00000
train epoch 1084 avg loss: 0.13147 (A-MSE: 0.11492) avg lploss: 0.00000
train epoch 1085 avg loss: 0.13186 (A-MSE: 0.11586) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.54512 (A-MSE: 0.48062) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.53746 (A-MSE: 0.48585) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 2 out of 50
train epoch 1086 avg loss: 0.12766 (A-MSE: 0.11220) avg lploss: 0.00000
train epoch 1087 avg loss: 0.12882 (A-MSE: 0.11322) avg lploss: 0.00000
train epoch 1088 avg loss: 0.15138 (A-MSE: 0.13336) avg lploss: 0.00000
train epoch 1089 avg loss: 0.16239 (A-MSE: 0.14118) avg lploss: 0.00000
train epoch 1090 avg loss: 0.13925 (A-MSE: 0.12268) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.57679 (A-MSE: 0.49877) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.55079 (A-MSE: 0.48747) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 3 out of 50
train epoch 1091 avg loss: 0.13879 (A-MSE: 0.12249) avg lploss: 0.00000
train epoch 1092 avg loss: 0.14020 (A-MSE: 0.12376) avg lploss: 0.00000
train epoch 1093 avg loss: 0.12369 (A-MSE: 0.10879) avg lploss: 0.00000
train epoch 1094 avg loss: 0.13714 (A-MSE: 0.11926) avg lploss: 0.00000
train epoch 1095 avg loss: 0.15576 (A-MSE: 0.13623) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.54586 (A-MSE: 0.47491) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.54245 (A-MSE: 0.48081) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 4 out of 50
train epoch 1096 avg loss: 0.16913 (A-MSE: 0.14745) avg lploss: 0.00000
train epoch 1097 avg loss: 0.18613 (A-MSE: 0.16353) avg lploss: 0.00000
train epoch 1098 avg loss: 0.16416 (A-MSE: 0.14391) avg lploss: 0.00000
train epoch 1099 avg loss: 0.19778 (A-MSE: 0.17243) avg lploss: 0.00000
train epoch 1100 avg loss: 0.19240 (A-MSE: 0.16968) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.48874 (A-MSE: 0.42389) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.49541 (A-MSE: 0.43760) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 5 out of 50
train epoch 1101 avg loss: 0.15753 (A-MSE: 0.13753) avg lploss: 0.00000
train epoch 1102 avg loss: 0.14235 (A-MSE: 0.12423) avg lploss: 0.00000
train epoch 1103 avg loss: 0.13227 (A-MSE: 0.11621) avg lploss: 0.00000
train epoch 1104 avg loss: 0.16020 (A-MSE: 0.14049) avg lploss: 0.00000
train epoch 1105 avg loss: 0.18446 (A-MSE: 0.16121) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.58275 (A-MSE: 0.49941) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.56558 (A-MSE: 0.49596) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 6 out of 50
train epoch 1106 avg loss: 0.18257 (A-MSE: 0.15742) avg lploss: 0.00000
train epoch 1107 avg loss: 0.16296 (A-MSE: 0.14348) avg lploss: 0.00000
train epoch 1108 avg loss: 0.14323 (A-MSE: 0.12537) avg lploss: 0.00000
train epoch 1109 avg loss: 0.12789 (A-MSE: 0.11268) avg lploss: 0.00000
train epoch 1110 avg loss: 0.13259 (A-MSE: 0.11649) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.51184 (A-MSE: 0.44830) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.50786 (A-MSE: 0.45242) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 7 out of 50
train epoch 1111 avg loss: 0.15245 (A-MSE: 0.13440) avg lploss: 0.00000
train epoch 1112 avg loss: 0.15104 (A-MSE: 0.13388) avg lploss: 0.00000
train epoch 1113 avg loss: 0.14989 (A-MSE: 0.13236) avg lploss: 0.00000
train epoch 1114 avg loss: 0.14717 (A-MSE: 0.12860) avg lploss: 0.00000
train epoch 1115 avg loss: 0.15316 (A-MSE: 0.13461) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.52660 (A-MSE: 0.46924) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.52922 (A-MSE: 0.47564) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 8 out of 50
train epoch 1116 avg loss: 0.13799 (A-MSE: 0.12069) avg lploss: 0.00000
train epoch 1117 avg loss: 0.12497 (A-MSE: 0.10961) avg lploss: 0.00000
train epoch 1118 avg loss: 0.13839 (A-MSE: 0.11962) avg lploss: 0.00000
train epoch 1119 avg loss: 0.13682 (A-MSE: 0.12021) avg lploss: 0.00000
train epoch 1120 avg loss: 0.11995 (A-MSE: 0.10451) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.48643 (A-MSE: 0.42663) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.46210 (A-MSE: 0.41483) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 9 out of 50
train epoch 1121 avg loss: 0.12341 (A-MSE: 0.10786) avg lploss: 0.00000
train epoch 1122 avg loss: 0.12289 (A-MSE: 0.10729) avg lploss: 0.00000
train epoch 1123 avg loss: 0.16199 (A-MSE: 0.14182) avg lploss: 0.00000
train epoch 1124 avg loss: 0.15266 (A-MSE: 0.13403) avg lploss: 0.00000
train epoch 1125 avg loss: 0.14604 (A-MSE: 0.12723) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.59077 (A-MSE: 0.51786) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.55144 (A-MSE: 0.49003) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 10 out of 50
train epoch 1126 avg loss: 0.13975 (A-MSE: 0.12185) avg lploss: 0.00000
train epoch 1127 avg loss: 0.13559 (A-MSE: 0.11879) avg lploss: 0.00000
train epoch 1128 avg loss: 0.14423 (A-MSE: 0.12517) avg lploss: 0.00000
train epoch 1129 avg loss: 0.17173 (A-MSE: 0.15149) avg lploss: 0.00000
train epoch 1130 avg loss: 0.17452 (A-MSE: 0.15368) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.58208 (A-MSE: 0.51627) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.57941 (A-MSE: 0.52133) avg lploss: 0.00000
*** Best Val Loss: 0.44564 	 Best Test Loss: 0.46819 	 Best epoch 1075
EarlyStopping counter: 11 out of 50
train epoch 1131 avg loss: 0.17220 (A-MSE: 0.15157) avg lploss: 0.00000
train epoch 1132 avg loss: 0.15361 (A-MSE: 0.13576) avg lploss: 0.00000
train epoch 1133 avg loss: 0.14604 (A-MSE: 0.12841) avg lploss: 0.00000
train epoch 1134 avg loss: 0.12823 (A-MSE: 0.11208) avg lploss: 0.00000
train epoch 1135 avg loss: 0.12384 (A-MSE: 0.10804) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.43899 (A-MSE: 0.38915) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.45454 (A-MSE: 0.40675) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
Validation loss decreased (0.445643 --> 0.438995).  Saving model ...
train epoch 1136 avg loss: 0.12104 (A-MSE: 0.10603) avg lploss: 0.00000
train epoch 1137 avg loss: 0.15248 (A-MSE: 0.13229) avg lploss: 0.00000
train epoch 1138 avg loss: 0.12711 (A-MSE: 0.11044) avg lploss: 0.00000
train epoch 1139 avg loss: 0.13289 (A-MSE: 0.11613) avg lploss: 0.00000
train epoch 1140 avg loss: 0.13014 (A-MSE: 0.11490) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.52876 (A-MSE: 0.45651) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.55027 (A-MSE: 0.48471) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 1 out of 50
train epoch 1141 avg loss: 0.15288 (A-MSE: 0.13420) avg lploss: 0.00000
train epoch 1142 avg loss: 0.15293 (A-MSE: 0.13475) avg lploss: 0.00000
train epoch 1143 avg loss: 0.12774 (A-MSE: 0.11210) avg lploss: 0.00000
train epoch 1144 avg loss: 0.12821 (A-MSE: 0.11270) avg lploss: 0.00000
train epoch 1145 avg loss: 0.13847 (A-MSE: 0.12101) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.51361 (A-MSE: 0.44920) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.52240 (A-MSE: 0.46236) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 2 out of 50
train epoch 1146 avg loss: 0.12596 (A-MSE: 0.11162) avg lploss: 0.00000
train epoch 1147 avg loss: 0.15256 (A-MSE: 0.13351) avg lploss: 0.00000
train epoch 1148 avg loss: 0.13434 (A-MSE: 0.11925) avg lploss: 0.00000
train epoch 1149 avg loss: 0.11845 (A-MSE: 0.10352) avg lploss: 0.00000
train epoch 1150 avg loss: 0.11524 (A-MSE: 0.10047) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.48050 (A-MSE: 0.42242) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.47252 (A-MSE: 0.42021) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 3 out of 50
train epoch 1151 avg loss: 0.10795 (A-MSE: 0.09480) avg lploss: 0.00000
train epoch 1152 avg loss: 0.10682 (A-MSE: 0.09300) avg lploss: 0.00000
train epoch 1153 avg loss: 0.11855 (A-MSE: 0.10365) avg lploss: 0.00000
train epoch 1154 avg loss: 0.12122 (A-MSE: 0.10742) avg lploss: 0.00000
train epoch 1155 avg loss: 0.13583 (A-MSE: 0.11913) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.51847 (A-MSE: 0.45141) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.56072 (A-MSE: 0.49136) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 4 out of 50
train epoch 1156 avg loss: 0.14691 (A-MSE: 0.12836) avg lploss: 0.00000
train epoch 1157 avg loss: 0.13482 (A-MSE: 0.11738) avg lploss: 0.00000
train epoch 1158 avg loss: 0.13573 (A-MSE: 0.11901) avg lploss: 0.00000
train epoch 1159 avg loss: 0.13699 (A-MSE: 0.11933) avg lploss: 0.00000
train epoch 1160 avg loss: 0.14042 (A-MSE: 0.12190) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.44491 (A-MSE: 0.39761) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.46681 (A-MSE: 0.41905) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 5 out of 50
train epoch 1161 avg loss: 0.12829 (A-MSE: 0.11304) avg lploss: 0.00000
train epoch 1162 avg loss: 0.13529 (A-MSE: 0.11931) avg lploss: 0.00000
train epoch 1163 avg loss: 0.14691 (A-MSE: 0.13014) avg lploss: 0.00000
train epoch 1164 avg loss: 0.15561 (A-MSE: 0.13623) avg lploss: 0.00000
train epoch 1165 avg loss: 0.13027 (A-MSE: 0.11379) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.50042 (A-MSE: 0.42645) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.51109 (A-MSE: 0.44449) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 6 out of 50
train epoch 1166 avg loss: 0.14054 (A-MSE: 0.12322) avg lploss: 0.00000
train epoch 1167 avg loss: 0.16723 (A-MSE: 0.14632) avg lploss: 0.00000
train epoch 1168 avg loss: 0.16057 (A-MSE: 0.14225) avg lploss: 0.00000
train epoch 1169 avg loss: 0.15645 (A-MSE: 0.13707) avg lploss: 0.00000
train epoch 1170 avg loss: 0.13606 (A-MSE: 0.11760) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.48336 (A-MSE: 0.42520) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.49329 (A-MSE: 0.44262) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 7 out of 50
train epoch 1171 avg loss: 0.11464 (A-MSE: 0.10053) avg lploss: 0.00000
train epoch 1172 avg loss: 0.11860 (A-MSE: 0.10511) avg lploss: 0.00000
train epoch 1173 avg loss: 0.14890 (A-MSE: 0.13006) avg lploss: 0.00000
train epoch 1174 avg loss: 0.14405 (A-MSE: 0.12726) avg lploss: 0.00000
train epoch 1175 avg loss: 0.11174 (A-MSE: 0.09877) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.50935 (A-MSE: 0.43896) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.50443 (A-MSE: 0.43967) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 8 out of 50
train epoch 1176 avg loss: 0.11008 (A-MSE: 0.09651) avg lploss: 0.00000
train epoch 1177 avg loss: 0.11258 (A-MSE: 0.09891) avg lploss: 0.00000
train epoch 1178 avg loss: 0.11502 (A-MSE: 0.10166) avg lploss: 0.00000
train epoch 1179 avg loss: 0.10686 (A-MSE: 0.09423) avg lploss: 0.00000
train epoch 1180 avg loss: 0.12132 (A-MSE: 0.10621) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.47230 (A-MSE: 0.41319) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.49252 (A-MSE: 0.44231) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 9 out of 50
train epoch 1181 avg loss: 0.10622 (A-MSE: 0.09277) avg lploss: 0.00000
train epoch 1182 avg loss: 0.11798 (A-MSE: 0.10244) avg lploss: 0.00000
train epoch 1183 avg loss: 0.11653 (A-MSE: 0.10234) avg lploss: 0.00000
train epoch 1184 avg loss: 0.12053 (A-MSE: 0.10582) avg lploss: 0.00000
train epoch 1185 avg loss: 0.12292 (A-MSE: 0.10725) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.51099 (A-MSE: 0.45429) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.52599 (A-MSE: 0.47105) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 10 out of 50
train epoch 1186 avg loss: 0.13933 (A-MSE: 0.12311) avg lploss: 0.00000
train epoch 1187 avg loss: 0.11559 (A-MSE: 0.10147) avg lploss: 0.00000
train epoch 1188 avg loss: 0.12342 (A-MSE: 0.10839) avg lploss: 0.00000
train epoch 1189 avg loss: 0.12588 (A-MSE: 0.11154) avg lploss: 0.00000
train epoch 1190 avg loss: 0.12342 (A-MSE: 0.10802) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.53054 (A-MSE: 0.46897) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.54299 (A-MSE: 0.48983) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 11 out of 50
train epoch 1191 avg loss: 0.12719 (A-MSE: 0.11193) avg lploss: 0.00000
train epoch 1192 avg loss: 0.12472 (A-MSE: 0.10926) avg lploss: 0.00000
train epoch 1193 avg loss: 0.12742 (A-MSE: 0.11161) avg lploss: 0.00000
train epoch 1194 avg loss: 0.12376 (A-MSE: 0.10824) avg lploss: 0.00000
train epoch 1195 avg loss: 0.12836 (A-MSE: 0.11257) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.61681 (A-MSE: 0.53290) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.57365 (A-MSE: 0.50780) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 12 out of 50
train epoch 1196 avg loss: 0.13164 (A-MSE: 0.11559) avg lploss: 0.00000
train epoch 1197 avg loss: 0.12567 (A-MSE: 0.11072) avg lploss: 0.00000
train epoch 1198 avg loss: 0.10135 (A-MSE: 0.08895) avg lploss: 0.00000
train epoch 1199 avg loss: 0.12826 (A-MSE: 0.11141) avg lploss: 0.00000
train epoch 1200 avg loss: 0.14352 (A-MSE: 0.12478) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.49484 (A-MSE: 0.42362) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.50750 (A-MSE: 0.44346) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 13 out of 50
train epoch 1201 avg loss: 0.12778 (A-MSE: 0.11314) avg lploss: 0.00000
train epoch 1202 avg loss: 0.12180 (A-MSE: 0.10714) avg lploss: 0.00000
train epoch 1203 avg loss: 0.11464 (A-MSE: 0.09995) avg lploss: 0.00000
train epoch 1204 avg loss: 0.10975 (A-MSE: 0.09610) avg lploss: 0.00000
train epoch 1205 avg loss: 0.12035 (A-MSE: 0.10521) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.45080 (A-MSE: 0.40286) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.46516 (A-MSE: 0.41842) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 14 out of 50
train epoch 1206 avg loss: 0.12355 (A-MSE: 0.10823) avg lploss: 0.00000
train epoch 1207 avg loss: 0.12156 (A-MSE: 0.10724) avg lploss: 0.00000
train epoch 1208 avg loss: 0.11993 (A-MSE: 0.10567) avg lploss: 0.00000
train epoch 1209 avg loss: 0.11310 (A-MSE: 0.09888) avg lploss: 0.00000
train epoch 1210 avg loss: 0.12875 (A-MSE: 0.11313) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.46608 (A-MSE: 0.41552) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.48723 (A-MSE: 0.43803) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 15 out of 50
train epoch 1211 avg loss: 0.12604 (A-MSE: 0.10985) avg lploss: 0.00000
train epoch 1212 avg loss: 0.13159 (A-MSE: 0.11476) avg lploss: 0.00000
train epoch 1213 avg loss: 0.10589 (A-MSE: 0.09301) avg lploss: 0.00000
train epoch 1214 avg loss: 0.10160 (A-MSE: 0.08878) avg lploss: 0.00000
train epoch 1215 avg loss: 0.12976 (A-MSE: 0.11318) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.57369 (A-MSE: 0.50752) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.55040 (A-MSE: 0.49746) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 16 out of 50
train epoch 1216 avg loss: 0.13231 (A-MSE: 0.11538) avg lploss: 0.00000
train epoch 1217 avg loss: 0.10584 (A-MSE: 0.09288) avg lploss: 0.00000
train epoch 1218 avg loss: 0.10344 (A-MSE: 0.09039) avg lploss: 0.00000
train epoch 1219 avg loss: 0.09571 (A-MSE: 0.08407) avg lploss: 0.00000
train epoch 1220 avg loss: 0.12763 (A-MSE: 0.11149) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.55793 (A-MSE: 0.47880) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.53316 (A-MSE: 0.46653) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 17 out of 50
train epoch 1221 avg loss: 0.11582 (A-MSE: 0.10212) avg lploss: 0.00000
train epoch 1222 avg loss: 0.10660 (A-MSE: 0.09459) avg lploss: 0.00000
train epoch 1223 avg loss: 0.11877 (A-MSE: 0.10513) avg lploss: 0.00000
train epoch 1224 avg loss: 0.11688 (A-MSE: 0.10341) avg lploss: 0.00000
train epoch 1225 avg loss: 0.11367 (A-MSE: 0.09993) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.49474 (A-MSE: 0.43693) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.49595 (A-MSE: 0.44307) avg lploss: 0.00000
*** Best Val Loss: 0.43899 	 Best Test Loss: 0.45454 	 Best epoch 1135
EarlyStopping counter: 18 out of 50
train epoch 1226 avg loss: 0.10579 (A-MSE: 0.09292) avg lploss: 0.00000
train epoch 1227 avg loss: 0.11620 (A-MSE: 0.10170) avg lploss: 0.00000
train epoch 1228 avg loss: 0.15210 (A-MSE: 0.13415) avg lploss: 0.00000
train epoch 1229 avg loss: 0.17419 (A-MSE: 0.15212) avg lploss: 0.00000
train epoch 1230 avg loss: 0.16767 (A-MSE: 0.14688) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.43107 (A-MSE: 0.38736) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.48383 (A-MSE: 0.42819) avg lploss: 0.00000
*** Best Val Loss: 0.43107 	 Best Test Loss: 0.48383 	 Best epoch 1230
Validation loss decreased (0.438995 --> 0.431065).  Saving model ...
train epoch 1231 avg loss: 0.13503 (A-MSE: 0.11692) avg lploss: 0.00000
train epoch 1232 avg loss: 0.12658 (A-MSE: 0.11096) avg lploss: 0.00000
train epoch 1233 avg loss: 0.12690 (A-MSE: 0.11211) avg lploss: 0.00000
train epoch 1234 avg loss: 0.11298 (A-MSE: 0.09887) avg lploss: 0.00000
train epoch 1235 avg loss: 0.10465 (A-MSE: 0.09198) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.45309 (A-MSE: 0.39599) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.48349 (A-MSE: 0.42797) avg lploss: 0.00000
*** Best Val Loss: 0.43107 	 Best Test Loss: 0.48383 	 Best epoch 1230
EarlyStopping counter: 1 out of 50
train epoch 1236 avg loss: 0.13249 (A-MSE: 0.11777) avg lploss: 0.00000
train epoch 1237 avg loss: 0.13261 (A-MSE: 0.11588) avg lploss: 0.00000
train epoch 1238 avg loss: 0.13341 (A-MSE: 0.11623) avg lploss: 0.00000
train epoch 1239 avg loss: 0.14327 (A-MSE: 0.12505) avg lploss: 0.00000
train epoch 1240 avg loss: 0.11982 (A-MSE: 0.10542) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.45110 (A-MSE: 0.39854) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.47619 (A-MSE: 0.41762) avg lploss: 0.00000
*** Best Val Loss: 0.43107 	 Best Test Loss: 0.48383 	 Best epoch 1230
EarlyStopping counter: 2 out of 50
train epoch 1241 avg loss: 0.11757 (A-MSE: 0.10252) avg lploss: 0.00000
train epoch 1242 avg loss: 0.10970 (A-MSE: 0.09670) avg lploss: 0.00000
train epoch 1243 avg loss: 0.10834 (A-MSE: 0.09578) avg lploss: 0.00000
train epoch 1244 avg loss: 0.09968 (A-MSE: 0.08710) avg lploss: 0.00000
train epoch 1245 avg loss: 0.08938 (A-MSE: 0.07864) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.47407 (A-MSE: 0.41999) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.46169 (A-MSE: 0.41169) avg lploss: 0.00000
*** Best Val Loss: 0.43107 	 Best Test Loss: 0.48383 	 Best epoch 1230
EarlyStopping counter: 3 out of 50
train epoch 1246 avg loss: 0.09765 (A-MSE: 0.08615) avg lploss: 0.00000
train epoch 1247 avg loss: 0.10135 (A-MSE: 0.08861) avg lploss: 0.00000
train epoch 1248 avg loss: 0.09120 (A-MSE: 0.07966) avg lploss: 0.00000
train epoch 1249 avg loss: 0.08715 (A-MSE: 0.07632) avg lploss: 0.00000
train epoch 1250 avg loss: 0.09133 (A-MSE: 0.08039) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.54001 (A-MSE: 0.47263) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.50891 (A-MSE: 0.45517) avg lploss: 0.00000
*** Best Val Loss: 0.43107 	 Best Test Loss: 0.48383 	 Best epoch 1230
EarlyStopping counter: 4 out of 50
train epoch 1251 avg loss: 0.09516 (A-MSE: 0.08364) avg lploss: 0.00000
train epoch 1252 avg loss: 0.09664 (A-MSE: 0.08559) avg lploss: 0.00000
train epoch 1253 avg loss: 0.11466 (A-MSE: 0.09993) avg lploss: 0.00000
train epoch 1254 avg loss: 0.11448 (A-MSE: 0.10109) avg lploss: 0.00000
train epoch 1255 avg loss: 0.11838 (A-MSE: 0.10507) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.42843 (A-MSE: 0.37506) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.44241 (A-MSE: 0.39014) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
Validation loss decreased (0.431065 --> 0.428431).  Saving model ...
train epoch 1256 avg loss: 0.10614 (A-MSE: 0.09437) avg lploss: 0.00000
train epoch 1257 avg loss: 0.13613 (A-MSE: 0.11945) avg lploss: 0.00000
train epoch 1258 avg loss: 0.15486 (A-MSE: 0.13414) avg lploss: 0.00000
train epoch 1259 avg loss: 0.11909 (A-MSE: 0.10497) avg lploss: 0.00000
train epoch 1260 avg loss: 0.10516 (A-MSE: 0.09277) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.44610 (A-MSE: 0.38685) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.43842 (A-MSE: 0.38713) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 1 out of 50
train epoch 1261 avg loss: 0.11575 (A-MSE: 0.10053) avg lploss: 0.00000
train epoch 1262 avg loss: 0.12946 (A-MSE: 0.11483) avg lploss: 0.00000
train epoch 1263 avg loss: 0.11185 (A-MSE: 0.09845) avg lploss: 0.00000
train epoch 1264 avg loss: 0.10776 (A-MSE: 0.09516) avg lploss: 0.00000
train epoch 1265 avg loss: 0.11224 (A-MSE: 0.09862) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.45639 (A-MSE: 0.39696) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.44725 (A-MSE: 0.39605) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 2 out of 50
train epoch 1266 avg loss: 0.10637 (A-MSE: 0.09273) avg lploss: 0.00000
train epoch 1267 avg loss: 0.11688 (A-MSE: 0.10290) avg lploss: 0.00000
train epoch 1268 avg loss: 0.10938 (A-MSE: 0.09633) avg lploss: 0.00000
train epoch 1269 avg loss: 0.11044 (A-MSE: 0.09635) avg lploss: 0.00000
train epoch 1270 avg loss: 0.11507 (A-MSE: 0.10177) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.49470 (A-MSE: 0.44156) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.45294 (A-MSE: 0.40556) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 3 out of 50
train epoch 1271 avg loss: 0.10784 (A-MSE: 0.09565) avg lploss: 0.00000
train epoch 1272 avg loss: 0.13208 (A-MSE: 0.11630) avg lploss: 0.00000
train epoch 1273 avg loss: 0.13255 (A-MSE: 0.11362) avg lploss: 0.00000
train epoch 1274 avg loss: 0.16494 (A-MSE: 0.14672) avg lploss: 0.00000
train epoch 1275 avg loss: 0.17678 (A-MSE: 0.15447) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.57409 (A-MSE: 0.50504) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.61766 (A-MSE: 0.55587) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 4 out of 50
train epoch 1276 avg loss: 0.19143 (A-MSE: 0.16606) avg lploss: 0.00000
train epoch 1277 avg loss: 0.14008 (A-MSE: 0.12406) avg lploss: 0.00000
train epoch 1278 avg loss: 0.10336 (A-MSE: 0.09132) avg lploss: 0.00000
train epoch 1279 avg loss: 0.09991 (A-MSE: 0.08810) avg lploss: 0.00000
train epoch 1280 avg loss: 0.12793 (A-MSE: 0.11178) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.50237 (A-MSE: 0.43590) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.48086 (A-MSE: 0.42156) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 5 out of 50
train epoch 1281 avg loss: 0.11499 (A-MSE: 0.10009) avg lploss: 0.00000
train epoch 1282 avg loss: 0.10933 (A-MSE: 0.09551) avg lploss: 0.00000
train epoch 1283 avg loss: 0.10819 (A-MSE: 0.09606) avg lploss: 0.00000
train epoch 1284 avg loss: 0.11137 (A-MSE: 0.09784) avg lploss: 0.00000
train epoch 1285 avg loss: 0.11478 (A-MSE: 0.10106) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.48857 (A-MSE: 0.43481) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.45999 (A-MSE: 0.40858) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 6 out of 50
train epoch 1286 avg loss: 0.11849 (A-MSE: 0.10509) avg lploss: 0.00000
train epoch 1287 avg loss: 0.12106 (A-MSE: 0.10692) avg lploss: 0.00000
train epoch 1288 avg loss: 0.12423 (A-MSE: 0.10891) avg lploss: 0.00000
train epoch 1289 avg loss: 0.14355 (A-MSE: 0.12630) avg lploss: 0.00000
train epoch 1290 avg loss: 0.13364 (A-MSE: 0.11856) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.43290 (A-MSE: 0.38211) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.46278 (A-MSE: 0.41432) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 7 out of 50
train epoch 1291 avg loss: 0.11149 (A-MSE: 0.09620) avg lploss: 0.00000
train epoch 1292 avg loss: 0.10223 (A-MSE: 0.08910) avg lploss: 0.00000
train epoch 1293 avg loss: 0.10440 (A-MSE: 0.09139) avg lploss: 0.00000
train epoch 1294 avg loss: 0.09835 (A-MSE: 0.08698) avg lploss: 0.00000
train epoch 1295 avg loss: 0.09863 (A-MSE: 0.08688) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.45889 (A-MSE: 0.39863) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.49109 (A-MSE: 0.43683) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 8 out of 50
train epoch 1296 avg loss: 0.09784 (A-MSE: 0.08596) avg lploss: 0.00000
train epoch 1297 avg loss: 0.09891 (A-MSE: 0.08681) avg lploss: 0.00000
train epoch 1298 avg loss: 0.10837 (A-MSE: 0.09664) avg lploss: 0.00000
train epoch 1299 avg loss: 0.10335 (A-MSE: 0.09033) avg lploss: 0.00000
train epoch 1300 avg loss: 0.09587 (A-MSE: 0.08406) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.46421 (A-MSE: 0.40880) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.47684 (A-MSE: 0.42575) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 9 out of 50
train epoch 1301 avg loss: 0.08739 (A-MSE: 0.07693) avg lploss: 0.00000
train epoch 1302 avg loss: 0.09242 (A-MSE: 0.08134) avg lploss: 0.00000
train epoch 1303 avg loss: 0.10656 (A-MSE: 0.09390) avg lploss: 0.00000
train epoch 1304 avg loss: 0.11166 (A-MSE: 0.09796) avg lploss: 0.00000
train epoch 1305 avg loss: 0.11298 (A-MSE: 0.09977) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.46769 (A-MSE: 0.41339) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.45730 (A-MSE: 0.41049) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 10 out of 50
train epoch 1306 avg loss: 0.08689 (A-MSE: 0.07665) avg lploss: 0.00000
train epoch 1307 avg loss: 0.10170 (A-MSE: 0.09064) avg lploss: 0.00000
train epoch 1308 avg loss: 0.10746 (A-MSE: 0.09504) avg lploss: 0.00000
train epoch 1309 avg loss: 0.13512 (A-MSE: 0.11721) avg lploss: 0.00000
train epoch 1310 avg loss: 0.13723 (A-MSE: 0.12092) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.55630 (A-MSE: 0.49469) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.54114 (A-MSE: 0.48976) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 11 out of 50
train epoch 1311 avg loss: 0.12397 (A-MSE: 0.10906) avg lploss: 0.00000
train epoch 1312 avg loss: 0.11018 (A-MSE: 0.09705) avg lploss: 0.00000
train epoch 1313 avg loss: 0.09698 (A-MSE: 0.08449) avg lploss: 0.00000
train epoch 1314 avg loss: 0.08445 (A-MSE: 0.07433) avg lploss: 0.00000
train epoch 1315 avg loss: 0.10540 (A-MSE: 0.09084) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.51251 (A-MSE: 0.43958) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.51210 (A-MSE: 0.44386) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 12 out of 50
train epoch 1316 avg loss: 0.12037 (A-MSE: 0.10755) avg lploss: 0.00000
train epoch 1317 avg loss: 0.12804 (A-MSE: 0.11295) avg lploss: 0.00000
train epoch 1318 avg loss: 0.11589 (A-MSE: 0.10136) avg lploss: 0.00000
train epoch 1319 avg loss: 0.09874 (A-MSE: 0.08594) avg lploss: 0.00000
train epoch 1320 avg loss: 0.10619 (A-MSE: 0.09447) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.53043 (A-MSE: 0.45843) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.53279 (A-MSE: 0.46917) avg lploss: 0.00000
*** Best Val Loss: 0.42843 	 Best Test Loss: 0.44241 	 Best epoch 1255
EarlyStopping counter: 13 out of 50
train epoch 1321 avg loss: 0.10818 (A-MSE: 0.09516) avg lploss: 0.00000
train epoch 1322 avg loss: 0.09311 (A-MSE: 0.08153) avg lploss: 0.00000
train epoch 1323 avg loss: 0.09793 (A-MSE: 0.08564) avg lploss: 0.00000
train epoch 1324 avg loss: 0.09318 (A-MSE: 0.08099) avg lploss: 0.00000
train epoch 1325 avg loss: 0.08314 (A-MSE: 0.07290) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.41340 (A-MSE: 0.36129) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.42479 (A-MSE: 0.37677) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
Validation loss decreased (0.428431 --> 0.413401).  Saving model ...
train epoch 1326 avg loss: 0.08523 (A-MSE: 0.07570) avg lploss: 0.00000
train epoch 1327 avg loss: 0.07856 (A-MSE: 0.06868) avg lploss: 0.00000
train epoch 1328 avg loss: 0.09001 (A-MSE: 0.07844) avg lploss: 0.00000
train epoch 1329 avg loss: 0.11654 (A-MSE: 0.10198) avg lploss: 0.00000
train epoch 1330 avg loss: 0.11348 (A-MSE: 0.10073) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.42822 (A-MSE: 0.37278) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.43765 (A-MSE: 0.38718) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
EarlyStopping counter: 1 out of 50
train epoch 1331 avg loss: 0.13500 (A-MSE: 0.12058) avg lploss: 0.00000
train epoch 1332 avg loss: 0.12741 (A-MSE: 0.11242) avg lploss: 0.00000
train epoch 1333 avg loss: 0.10746 (A-MSE: 0.09354) avg lploss: 0.00000
train epoch 1334 avg loss: 0.09543 (A-MSE: 0.08327) avg lploss: 0.00000
train epoch 1335 avg loss: 0.13049 (A-MSE: 0.11456) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.48741 (A-MSE: 0.42730) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.50372 (A-MSE: 0.44821) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
EarlyStopping counter: 2 out of 50
train epoch 1336 avg loss: 0.12276 (A-MSE: 0.10727) avg lploss: 0.00000
train epoch 1337 avg loss: 0.09695 (A-MSE: 0.08480) avg lploss: 0.00000
train epoch 1338 avg loss: 0.09195 (A-MSE: 0.08047) avg lploss: 0.00000
train epoch 1339 avg loss: 0.09091 (A-MSE: 0.08012) avg lploss: 0.00000
train epoch 1340 avg loss: 0.08246 (A-MSE: 0.07249) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.46227 (A-MSE: 0.40396) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.44225 (A-MSE: 0.39311) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
EarlyStopping counter: 3 out of 50
train epoch 1341 avg loss: 0.09386 (A-MSE: 0.08237) avg lploss: 0.00000
train epoch 1342 avg loss: 0.08278 (A-MSE: 0.07172) avg lploss: 0.00000
train epoch 1343 avg loss: 0.07125 (A-MSE: 0.06264) avg lploss: 0.00000
train epoch 1344 avg loss: 0.08531 (A-MSE: 0.07452) avg lploss: 0.00000
train epoch 1345 avg loss: 0.09291 (A-MSE: 0.08230) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.44077 (A-MSE: 0.39047) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.44379 (A-MSE: 0.39744) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
EarlyStopping counter: 4 out of 50
train epoch 1346 avg loss: 0.08487 (A-MSE: 0.07528) avg lploss: 0.00000
train epoch 1347 avg loss: 0.08079 (A-MSE: 0.07005) avg lploss: 0.00000
train epoch 1348 avg loss: 0.07534 (A-MSE: 0.06558) avg lploss: 0.00000
train epoch 1349 avg loss: 0.08140 (A-MSE: 0.07233) avg lploss: 0.00000
train epoch 1350 avg loss: 0.07391 (A-MSE: 0.06542) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.46741 (A-MSE: 0.40385) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.46069 (A-MSE: 0.40654) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
EarlyStopping counter: 5 out of 50
train epoch 1351 avg loss: 0.10029 (A-MSE: 0.08829) avg lploss: 0.00000
train epoch 1352 avg loss: 0.09304 (A-MSE: 0.08234) avg lploss: 0.00000
train epoch 1353 avg loss: 0.09772 (A-MSE: 0.08641) avg lploss: 0.00000
train epoch 1354 avg loss: 0.09639 (A-MSE: 0.08510) avg lploss: 0.00000
train epoch 1355 avg loss: 0.09787 (A-MSE: 0.08594) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.43443 (A-MSE: 0.38077) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.43481 (A-MSE: 0.38495) avg lploss: 0.00000
*** Best Val Loss: 0.41340 	 Best Test Loss: 0.42479 	 Best epoch 1325
EarlyStopping counter: 6 out of 50
train epoch 1356 avg loss: 0.10445 (A-MSE: 0.09111) avg lploss: 0.00000
train epoch 1357 avg loss: 0.10575 (A-MSE: 0.09323) avg lploss: 0.00000
train epoch 1358 avg loss: 0.10043 (A-MSE: 0.08887) avg lploss: 0.00000
train epoch 1359 avg loss: 0.09610 (A-MSE: 0.08485) avg lploss: 0.00000
train epoch 1360 avg loss: 0.08580 (A-MSE: 0.07523) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.39359 (A-MSE: 0.34991) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.39097 (A-MSE: 0.34848) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
Validation loss decreased (0.413401 --> 0.393591).  Saving model ...
train epoch 1361 avg loss: 0.07979 (A-MSE: 0.06998) avg lploss: 0.00000
train epoch 1362 avg loss: 0.08422 (A-MSE: 0.07492) avg lploss: 0.00000
train epoch 1363 avg loss: 0.08520 (A-MSE: 0.07495) avg lploss: 0.00000
train epoch 1364 avg loss: 0.07922 (A-MSE: 0.06945) avg lploss: 0.00000
train epoch 1365 avg loss: 0.08287 (A-MSE: 0.07303) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.50770 (A-MSE: 0.45002) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.49493 (A-MSE: 0.44635) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 1 out of 50
train epoch 1366 avg loss: 0.09148 (A-MSE: 0.08152) avg lploss: 0.00000
train epoch 1367 avg loss: 0.09612 (A-MSE: 0.08407) avg lploss: 0.00000
train epoch 1368 avg loss: 0.11291 (A-MSE: 0.09954) avg lploss: 0.00000
train epoch 1369 avg loss: 0.11570 (A-MSE: 0.10007) avg lploss: 0.00000
train epoch 1370 avg loss: 0.11114 (A-MSE: 0.09764) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.58869 (A-MSE: 0.51090) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.52110 (A-MSE: 0.46235) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 2 out of 50
train epoch 1371 avg loss: 0.09062 (A-MSE: 0.07922) avg lploss: 0.00000
train epoch 1372 avg loss: 0.07760 (A-MSE: 0.06835) avg lploss: 0.00000
train epoch 1373 avg loss: 0.07435 (A-MSE: 0.06515) avg lploss: 0.00000
train epoch 1374 avg loss: 0.08050 (A-MSE: 0.07022) avg lploss: 0.00000
train epoch 1375 avg loss: 0.09781 (A-MSE: 0.08734) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.53852 (A-MSE: 0.46113) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.52424 (A-MSE: 0.45848) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 3 out of 50
train epoch 1376 avg loss: 0.11284 (A-MSE: 0.09877) avg lploss: 0.00000
train epoch 1377 avg loss: 0.09967 (A-MSE: 0.08750) avg lploss: 0.00000
train epoch 1378 avg loss: 0.09418 (A-MSE: 0.08284) avg lploss: 0.00000
train epoch 1379 avg loss: 0.08153 (A-MSE: 0.07176) avg lploss: 0.00000
train epoch 1380 avg loss: 0.08863 (A-MSE: 0.07740) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.42685 (A-MSE: 0.37735) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.43902 (A-MSE: 0.39200) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 4 out of 50
train epoch 1381 avg loss: 0.07763 (A-MSE: 0.06815) avg lploss: 0.00000
train epoch 1382 avg loss: 0.08166 (A-MSE: 0.07141) avg lploss: 0.00000
train epoch 1383 avg loss: 0.08776 (A-MSE: 0.07739) avg lploss: 0.00000
train epoch 1384 avg loss: 0.09373 (A-MSE: 0.08310) avg lploss: 0.00000
train epoch 1385 avg loss: 0.10147 (A-MSE: 0.08951) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.46741 (A-MSE: 0.40913) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.43045 (A-MSE: 0.38311) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 5 out of 50
train epoch 1386 avg loss: 0.08629 (A-MSE: 0.07540) avg lploss: 0.00000
train epoch 1387 avg loss: 0.09882 (A-MSE: 0.08634) avg lploss: 0.00000
train epoch 1388 avg loss: 0.09431 (A-MSE: 0.08282) avg lploss: 0.00000
train epoch 1389 avg loss: 0.09990 (A-MSE: 0.08893) avg lploss: 0.00000
train epoch 1390 avg loss: 0.08265 (A-MSE: 0.07241) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.47323 (A-MSE: 0.41293) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.43782 (A-MSE: 0.38707) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 6 out of 50
train epoch 1391 avg loss: 0.08685 (A-MSE: 0.07602) avg lploss: 0.00000
train epoch 1392 avg loss: 0.07762 (A-MSE: 0.06862) avg lploss: 0.00000
train epoch 1393 avg loss: 0.07031 (A-MSE: 0.06168) avg lploss: 0.00000
train epoch 1394 avg loss: 0.06983 (A-MSE: 0.06142) avg lploss: 0.00000
train epoch 1395 avg loss: 0.08567 (A-MSE: 0.07487) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.47789 (A-MSE: 0.41309) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.47622 (A-MSE: 0.41549) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 7 out of 50
train epoch 1396 avg loss: 0.07651 (A-MSE: 0.06725) avg lploss: 0.00000
train epoch 1397 avg loss: 0.09572 (A-MSE: 0.08447) avg lploss: 0.00000
train epoch 1398 avg loss: 0.07935 (A-MSE: 0.06999) avg lploss: 0.00000
train epoch 1399 avg loss: 0.14944 (A-MSE: 0.13294) avg lploss: 0.00000
train epoch 1400 avg loss: 0.15836 (A-MSE: 0.14041) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.45883 (A-MSE: 0.40930) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.52178 (A-MSE: 0.46864) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 8 out of 50
train epoch 1401 avg loss: 0.13326 (A-MSE: 0.11668) avg lploss: 0.00000
train epoch 1402 avg loss: 0.09457 (A-MSE: 0.08272) avg lploss: 0.00000
train epoch 1403 avg loss: 0.08391 (A-MSE: 0.07402) avg lploss: 0.00000
train epoch 1404 avg loss: 0.08889 (A-MSE: 0.07827) avg lploss: 0.00000
train epoch 1405 avg loss: 0.09253 (A-MSE: 0.08185) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.47133 (A-MSE: 0.40802) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.46810 (A-MSE: 0.41429) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 9 out of 50
train epoch 1406 avg loss: 0.09142 (A-MSE: 0.08057) avg lploss: 0.00000
train epoch 1407 avg loss: 0.08635 (A-MSE: 0.07559) avg lploss: 0.00000
train epoch 1408 avg loss: 0.08307 (A-MSE: 0.07268) avg lploss: 0.00000
train epoch 1409 avg loss: 0.08428 (A-MSE: 0.07431) avg lploss: 0.00000
train epoch 1410 avg loss: 0.10166 (A-MSE: 0.08917) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.47594 (A-MSE: 0.41528) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.47172 (A-MSE: 0.41632) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 10 out of 50
train epoch 1411 avg loss: 0.11396 (A-MSE: 0.09796) avg lploss: 0.00000
train epoch 1412 avg loss: 0.14777 (A-MSE: 0.13039) avg lploss: 0.00000
train epoch 1413 avg loss: 0.11194 (A-MSE: 0.09902) avg lploss: 0.00000
train epoch 1414 avg loss: 0.10126 (A-MSE: 0.08959) avg lploss: 0.00000
train epoch 1415 avg loss: 0.12627 (A-MSE: 0.11199) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.46057 (A-MSE: 0.40036) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.44011 (A-MSE: 0.38742) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 11 out of 50
train epoch 1416 avg loss: 0.13342 (A-MSE: 0.11628) avg lploss: 0.00000
train epoch 1417 avg loss: 0.10134 (A-MSE: 0.08867) avg lploss: 0.00000
train epoch 1418 avg loss: 0.07902 (A-MSE: 0.06905) avg lploss: 0.00000
train epoch 1419 avg loss: 0.08891 (A-MSE: 0.07722) avg lploss: 0.00000
train epoch 1420 avg loss: 0.08199 (A-MSE: 0.07201) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.41765 (A-MSE: 0.36367) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.43208 (A-MSE: 0.38192) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 12 out of 50
train epoch 1421 avg loss: 0.08062 (A-MSE: 0.07106) avg lploss: 0.00000
train epoch 1422 avg loss: 0.08598 (A-MSE: 0.07509) avg lploss: 0.00000
train epoch 1423 avg loss: 0.07555 (A-MSE: 0.06573) avg lploss: 0.00000
train epoch 1424 avg loss: 0.06821 (A-MSE: 0.05981) avg lploss: 0.00000
train epoch 1425 avg loss: 0.07434 (A-MSE: 0.06502) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.44309 (A-MSE: 0.39414) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.41263 (A-MSE: 0.37424) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 13 out of 50
train epoch 1426 avg loss: 0.08544 (A-MSE: 0.07583) avg lploss: 0.00000
train epoch 1427 avg loss: 0.08818 (A-MSE: 0.07801) avg lploss: 0.00000
train epoch 1428 avg loss: 0.08367 (A-MSE: 0.07424) avg lploss: 0.00000
train epoch 1429 avg loss: 0.07596 (A-MSE: 0.06649) avg lploss: 0.00000
train epoch 1430 avg loss: 0.07061 (A-MSE: 0.06232) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.46135 (A-MSE: 0.40130) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.44407 (A-MSE: 0.39370) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 14 out of 50
train epoch 1431 avg loss: 0.08282 (A-MSE: 0.07319) avg lploss: 0.00000
train epoch 1432 avg loss: 0.09098 (A-MSE: 0.08060) avg lploss: 0.00000
train epoch 1433 avg loss: 0.08194 (A-MSE: 0.07149) avg lploss: 0.00000
train epoch 1434 avg loss: 0.08872 (A-MSE: 0.07858) avg lploss: 0.00000
train epoch 1435 avg loss: 0.10670 (A-MSE: 0.09415) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.39906 (A-MSE: 0.35553) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.41286 (A-MSE: 0.37012) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 15 out of 50
train epoch 1436 avg loss: 0.09706 (A-MSE: 0.08532) avg lploss: 0.00000
train epoch 1437 avg loss: 0.08086 (A-MSE: 0.07041) avg lploss: 0.00000
train epoch 1438 avg loss: 0.08424 (A-MSE: 0.07448) avg lploss: 0.00000
train epoch 1439 avg loss: 0.07756 (A-MSE: 0.06805) avg lploss: 0.00000
train epoch 1440 avg loss: 0.07675 (A-MSE: 0.06721) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.49788 (A-MSE: 0.43842) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.46660 (A-MSE: 0.41576) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 16 out of 50
train epoch 1441 avg loss: 0.08848 (A-MSE: 0.07750) avg lploss: 0.00000
train epoch 1442 avg loss: 0.10849 (A-MSE: 0.09504) avg lploss: 0.00000
train epoch 1443 avg loss: 0.09166 (A-MSE: 0.08106) avg lploss: 0.00000
train epoch 1444 avg loss: 0.08634 (A-MSE: 0.07596) avg lploss: 0.00000
train epoch 1445 avg loss: 0.09279 (A-MSE: 0.08067) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.44700 (A-MSE: 0.39556) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.42635 (A-MSE: 0.38495) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 17 out of 50
train epoch 1446 avg loss: 0.08490 (A-MSE: 0.07558) avg lploss: 0.00000
train epoch 1447 avg loss: 0.09908 (A-MSE: 0.08684) avg lploss: 0.00000
train epoch 1448 avg loss: 0.10918 (A-MSE: 0.09532) avg lploss: 0.00000
train epoch 1449 avg loss: 0.10691 (A-MSE: 0.09560) avg lploss: 0.00000
train epoch 1450 avg loss: 0.09400 (A-MSE: 0.08279) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.44633 (A-MSE: 0.39609) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.43253 (A-MSE: 0.38732) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 18 out of 50
train epoch 1451 avg loss: 0.08718 (A-MSE: 0.07628) avg lploss: 0.00000
train epoch 1452 avg loss: 0.07745 (A-MSE: 0.06820) avg lploss: 0.00000
train epoch 1453 avg loss: 0.07621 (A-MSE: 0.06661) avg lploss: 0.00000
train epoch 1454 avg loss: 0.07901 (A-MSE: 0.06978) avg lploss: 0.00000
train epoch 1455 avg loss: 0.08781 (A-MSE: 0.07771) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.52587 (A-MSE: 0.45401) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.45687 (A-MSE: 0.40155) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 19 out of 50
train epoch 1456 avg loss: 0.09350 (A-MSE: 0.08175) avg lploss: 0.00000
train epoch 1457 avg loss: 0.09397 (A-MSE: 0.08227) avg lploss: 0.00000
train epoch 1458 avg loss: 0.09196 (A-MSE: 0.08073) avg lploss: 0.00000
train epoch 1459 avg loss: 0.08224 (A-MSE: 0.07169) avg lploss: 0.00000
train epoch 1460 avg loss: 0.06953 (A-MSE: 0.06112) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.39952 (A-MSE: 0.35079) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.42964 (A-MSE: 0.37667) avg lploss: 0.00000
*** Best Val Loss: 0.39359 	 Best Test Loss: 0.39097 	 Best epoch 1360
EarlyStopping counter: 20 out of 50
train epoch 1461 avg loss: 0.08982 (A-MSE: 0.07863) avg lploss: 0.00000
train epoch 1462 avg loss: 0.10211 (A-MSE: 0.09042) avg lploss: 0.00000
train epoch 1463 avg loss: 0.07946 (A-MSE: 0.06981) avg lploss: 0.00000
train epoch 1464 avg loss: 0.07841 (A-MSE: 0.06869) avg lploss: 0.00000
train epoch 1465 avg loss: 0.06927 (A-MSE: 0.06053) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.35851 (A-MSE: 0.31528) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.37184 (A-MSE: 0.32878) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
Validation loss decreased (0.393591 --> 0.358513).  Saving model ...
train epoch 1466 avg loss: 0.06705 (A-MSE: 0.05868) avg lploss: 0.00000
train epoch 1467 avg loss: 0.06919 (A-MSE: 0.06048) avg lploss: 0.00000
train epoch 1468 avg loss: 0.07431 (A-MSE: 0.06542) avg lploss: 0.00000
train epoch 1469 avg loss: 0.07548 (A-MSE: 0.06720) avg lploss: 0.00000
train epoch 1470 avg loss: 0.07535 (A-MSE: 0.06644) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.48327 (A-MSE: 0.42770) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.44848 (A-MSE: 0.39973) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 1 out of 50
train epoch 1471 avg loss: 0.07932 (A-MSE: 0.06964) avg lploss: 0.00000
train epoch 1472 avg loss: 0.07383 (A-MSE: 0.06519) avg lploss: 0.00000
train epoch 1473 avg loss: 0.07937 (A-MSE: 0.06977) avg lploss: 0.00000
train epoch 1474 avg loss: 0.08902 (A-MSE: 0.07844) avg lploss: 0.00000
train epoch 1475 avg loss: 0.09057 (A-MSE: 0.07994) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.47875 (A-MSE: 0.41598) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.48503 (A-MSE: 0.42967) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 2 out of 50
train epoch 1476 avg loss: 0.08538 (A-MSE: 0.07525) avg lploss: 0.00000
train epoch 1477 avg loss: 0.08605 (A-MSE: 0.07584) avg lploss: 0.00000
train epoch 1478 avg loss: 0.10185 (A-MSE: 0.09051) avg lploss: 0.00000
train epoch 1479 avg loss: 0.11463 (A-MSE: 0.10104) avg lploss: 0.00000
train epoch 1480 avg loss: 0.10611 (A-MSE: 0.09407) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.51192 (A-MSE: 0.44708) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.46496 (A-MSE: 0.41153) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 3 out of 50
train epoch 1481 avg loss: 0.10132 (A-MSE: 0.08860) avg lploss: 0.00000
train epoch 1482 avg loss: 0.11136 (A-MSE: 0.09827) avg lploss: 0.00000
train epoch 1483 avg loss: 0.10964 (A-MSE: 0.09664) avg lploss: 0.00000
train epoch 1484 avg loss: 0.09534 (A-MSE: 0.08336) avg lploss: 0.00000
train epoch 1485 avg loss: 0.09075 (A-MSE: 0.07967) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.41294 (A-MSE: 0.36226) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.40689 (A-MSE: 0.35936) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 4 out of 50
train epoch 1486 avg loss: 0.09659 (A-MSE: 0.08558) avg lploss: 0.00000
train epoch 1487 avg loss: 0.08031 (A-MSE: 0.07027) avg lploss: 0.00000
train epoch 1488 avg loss: 0.06638 (A-MSE: 0.05809) avg lploss: 0.00000
train epoch 1489 avg loss: 0.06634 (A-MSE: 0.05790) avg lploss: 0.00000
train epoch 1490 avg loss: 0.07083 (A-MSE: 0.06183) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.46821 (A-MSE: 0.41272) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.43674 (A-MSE: 0.39163) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 5 out of 50
train epoch 1491 avg loss: 0.06451 (A-MSE: 0.05646) avg lploss: 0.00000
train epoch 1492 avg loss: 0.06644 (A-MSE: 0.05843) avg lploss: 0.00000
train epoch 1493 avg loss: 0.07643 (A-MSE: 0.06765) avg lploss: 0.00000
train epoch 1494 avg loss: 0.08197 (A-MSE: 0.07199) avg lploss: 0.00000
train epoch 1495 avg loss: 0.07081 (A-MSE: 0.06234) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.37769 (A-MSE: 0.33206) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.40608 (A-MSE: 0.36178) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 6 out of 50
train epoch 1496 avg loss: 0.10295 (A-MSE: 0.09041) avg lploss: 0.00000
train epoch 1497 avg loss: 0.07590 (A-MSE: 0.06628) avg lploss: 0.00000
train epoch 1498 avg loss: 0.07051 (A-MSE: 0.06250) avg lploss: 0.00000
train epoch 1499 avg loss: 0.06954 (A-MSE: 0.06108) avg lploss: 0.00000
train epoch 1500 avg loss: 0.07556 (A-MSE: 0.06704) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.49086 (A-MSE: 0.43605) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.48100 (A-MSE: 0.43186) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 7 out of 50
train epoch 1501 avg loss: 0.08170 (A-MSE: 0.07222) avg lploss: 0.00000
train epoch 1502 avg loss: 0.07813 (A-MSE: 0.06912) avg lploss: 0.00000
train epoch 1503 avg loss: 0.06768 (A-MSE: 0.05958) avg lploss: 0.00000
train epoch 1504 avg loss: 0.06997 (A-MSE: 0.06180) avg lploss: 0.00000
train epoch 1505 avg loss: 0.06952 (A-MSE: 0.06133) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.43665 (A-MSE: 0.38521) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.42085 (A-MSE: 0.37699) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 8 out of 50
train epoch 1506 avg loss: 0.06078 (A-MSE: 0.05339) avg lploss: 0.00000
train epoch 1507 avg loss: 0.06473 (A-MSE: 0.05685) avg lploss: 0.00000
train epoch 1508 avg loss: 0.06317 (A-MSE: 0.05554) avg lploss: 0.00000
train epoch 1509 avg loss: 0.07119 (A-MSE: 0.06354) avg lploss: 0.00000
train epoch 1510 avg loss: 0.08849 (A-MSE: 0.07838) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.39053 (A-MSE: 0.34461) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.41651 (A-MSE: 0.37322) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 9 out of 50
train epoch 1511 avg loss: 0.09143 (A-MSE: 0.08071) avg lploss: 0.00000
train epoch 1512 avg loss: 0.08644 (A-MSE: 0.07596) avg lploss: 0.00000
train epoch 1513 avg loss: 0.06785 (A-MSE: 0.06017) avg lploss: 0.00000
train epoch 1514 avg loss: 0.07942 (A-MSE: 0.06949) avg lploss: 0.00000
train epoch 1515 avg loss: 0.07883 (A-MSE: 0.06965) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.45682 (A-MSE: 0.40106) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.41419 (A-MSE: 0.36918) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 10 out of 50
train epoch 1516 avg loss: 0.07071 (A-MSE: 0.06235) avg lploss: 0.00000
train epoch 1517 avg loss: 0.06443 (A-MSE: 0.05641) avg lploss: 0.00000
train epoch 1518 avg loss: 0.06024 (A-MSE: 0.05336) avg lploss: 0.00000
train epoch 1519 avg loss: 0.06159 (A-MSE: 0.05433) avg lploss: 0.00000
train epoch 1520 avg loss: 0.05940 (A-MSE: 0.05259) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.39197 (A-MSE: 0.34662) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.37658 (A-MSE: 0.33724) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 11 out of 50
train epoch 1521 avg loss: 0.05984 (A-MSE: 0.05296) avg lploss: 0.00000
train epoch 1522 avg loss: 0.06552 (A-MSE: 0.05761) avg lploss: 0.00000
train epoch 1523 avg loss: 0.08536 (A-MSE: 0.07489) avg lploss: 0.00000
train epoch 1524 avg loss: 0.08264 (A-MSE: 0.07179) avg lploss: 0.00000
train epoch 1525 avg loss: 0.08959 (A-MSE: 0.07876) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.42744 (A-MSE: 0.37391) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.40946 (A-MSE: 0.36029) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 12 out of 50
train epoch 1526 avg loss: 0.07272 (A-MSE: 0.06407) avg lploss: 0.00000
train epoch 1527 avg loss: 0.08539 (A-MSE: 0.07482) avg lploss: 0.00000
train epoch 1528 avg loss: 0.07771 (A-MSE: 0.06911) avg lploss: 0.00000
train epoch 1529 avg loss: 0.08235 (A-MSE: 0.07241) avg lploss: 0.00000
train epoch 1530 avg loss: 0.08323 (A-MSE: 0.07326) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.44759 (A-MSE: 0.39243) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.42753 (A-MSE: 0.37785) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 13 out of 50
train epoch 1531 avg loss: 0.08190 (A-MSE: 0.07207) avg lploss: 0.00000
train epoch 1532 avg loss: 0.07260 (A-MSE: 0.06393) avg lploss: 0.00000
train epoch 1533 avg loss: 0.07838 (A-MSE: 0.06877) avg lploss: 0.00000
train epoch 1534 avg loss: 0.07301 (A-MSE: 0.06377) avg lploss: 0.00000
train epoch 1535 avg loss: 0.08316 (A-MSE: 0.07312) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.44232 (A-MSE: 0.38728) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.44930 (A-MSE: 0.39825) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 14 out of 50
train epoch 1536 avg loss: 0.10316 (A-MSE: 0.09025) avg lploss: 0.00000
train epoch 1537 avg loss: 0.09762 (A-MSE: 0.08673) avg lploss: 0.00000
train epoch 1538 avg loss: 0.09575 (A-MSE: 0.08474) avg lploss: 0.00000
train epoch 1539 avg loss: 0.08982 (A-MSE: 0.07925) avg lploss: 0.00000
train epoch 1540 avg loss: 0.07746 (A-MSE: 0.06775) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.42849 (A-MSE: 0.37526) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.42616 (A-MSE: 0.37917) avg lploss: 0.00000
*** Best Val Loss: 0.35851 	 Best Test Loss: 0.37184 	 Best epoch 1465
EarlyStopping counter: 15 out of 50
train epoch 1541 avg loss: 0.06573 (A-MSE: 0.05801) avg lploss: 0.00000
train epoch 1542 avg loss: 0.07177 (A-MSE: 0.06287) avg lploss: 0.00000
train epoch 1543 avg loss: 0.07485 (A-MSE: 0.06522) avg lploss: 0.00000
train epoch 1544 avg loss: 0.06651 (A-MSE: 0.05879) avg lploss: 0.00000
train epoch 1545 avg loss: 0.06563 (A-MSE: 0.05785) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.35119 (A-MSE: 0.30862) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.35252 (A-MSE: 0.31690) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
Validation loss decreased (0.358513 --> 0.351189).  Saving model ...
train epoch 1546 avg loss: 0.06643 (A-MSE: 0.05846) avg lploss: 0.00000
train epoch 1547 avg loss: 0.05900 (A-MSE: 0.05192) avg lploss: 0.00000
train epoch 1548 avg loss: 0.05230 (A-MSE: 0.04572) avg lploss: 0.00000
train epoch 1549 avg loss: 0.06127 (A-MSE: 0.05400) avg lploss: 0.00000
train epoch 1550 avg loss: 0.07994 (A-MSE: 0.06991) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.42792 (A-MSE: 0.37768) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.44897 (A-MSE: 0.40057) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 1 out of 50
train epoch 1551 avg loss: 0.08129 (A-MSE: 0.07159) avg lploss: 0.00000
train epoch 1552 avg loss: 0.06158 (A-MSE: 0.05460) avg lploss: 0.00000
train epoch 1553 avg loss: 0.06898 (A-MSE: 0.06042) avg lploss: 0.00000
train epoch 1554 avg loss: 0.08760 (A-MSE: 0.07688) avg lploss: 0.00000
train epoch 1555 avg loss: 0.09342 (A-MSE: 0.08214) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.43251 (A-MSE: 0.38359) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.43209 (A-MSE: 0.38849) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 2 out of 50
train epoch 1556 avg loss: 0.07413 (A-MSE: 0.06527) avg lploss: 0.00000
train epoch 1557 avg loss: 0.06403 (A-MSE: 0.05694) avg lploss: 0.00000
train epoch 1558 avg loss: 0.06497 (A-MSE: 0.05756) avg lploss: 0.00000
train epoch 1559 avg loss: 0.06590 (A-MSE: 0.05861) avg lploss: 0.00000
train epoch 1560 avg loss: 0.05554 (A-MSE: 0.04914) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.42234 (A-MSE: 0.36822) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.41906 (A-MSE: 0.37521) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 3 out of 50
train epoch 1561 avg loss: 0.05883 (A-MSE: 0.05172) avg lploss: 0.00000
train epoch 1562 avg loss: 0.05644 (A-MSE: 0.04901) avg lploss: 0.00000
train epoch 1563 avg loss: 0.06556 (A-MSE: 0.05750) avg lploss: 0.00000
train epoch 1564 avg loss: 0.06907 (A-MSE: 0.06106) avg lploss: 0.00000
train epoch 1565 avg loss: 0.08587 (A-MSE: 0.07532) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.39945 (A-MSE: 0.35711) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.40381 (A-MSE: 0.36513) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 4 out of 50
train epoch 1566 avg loss: 0.06819 (A-MSE: 0.06075) avg lploss: 0.00000
train epoch 1567 avg loss: 0.05494 (A-MSE: 0.04814) avg lploss: 0.00000
train epoch 1568 avg loss: 0.06227 (A-MSE: 0.05524) avg lploss: 0.00000
train epoch 1569 avg loss: 0.06457 (A-MSE: 0.05716) avg lploss: 0.00000
train epoch 1570 avg loss: 0.06208 (A-MSE: 0.05438) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.38447 (A-MSE: 0.33691) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.39079 (A-MSE: 0.34799) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 5 out of 50
train epoch 1571 avg loss: 0.07271 (A-MSE: 0.06360) avg lploss: 0.00000
train epoch 1572 avg loss: 0.05966 (A-MSE: 0.05217) avg lploss: 0.00000
train epoch 1573 avg loss: 0.06000 (A-MSE: 0.05257) avg lploss: 0.00000
train epoch 1574 avg loss: 0.07096 (A-MSE: 0.06280) avg lploss: 0.00000
train epoch 1575 avg loss: 0.07899 (A-MSE: 0.07026) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.40407 (A-MSE: 0.34973) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.41240 (A-MSE: 0.36498) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 6 out of 50
train epoch 1576 avg loss: 0.07205 (A-MSE: 0.06459) avg lploss: 0.00000
train epoch 1577 avg loss: 0.06456 (A-MSE: 0.05640) avg lploss: 0.00000
train epoch 1578 avg loss: 0.06224 (A-MSE: 0.05461) avg lploss: 0.00000
train epoch 1579 avg loss: 0.06210 (A-MSE: 0.05426) avg lploss: 0.00000
train epoch 1580 avg loss: 0.07024 (A-MSE: 0.06119) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.41789 (A-MSE: 0.36190) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.38841 (A-MSE: 0.34340) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 7 out of 50
train epoch 1581 avg loss: 0.05365 (A-MSE: 0.04760) avg lploss: 0.00000
train epoch 1582 avg loss: 0.06389 (A-MSE: 0.05621) avg lploss: 0.00000
train epoch 1583 avg loss: 0.05750 (A-MSE: 0.05096) avg lploss: 0.00000
train epoch 1584 avg loss: 0.06358 (A-MSE: 0.05645) avg lploss: 0.00000
train epoch 1585 avg loss: 0.08548 (A-MSE: 0.07585) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.39622 (A-MSE: 0.34733) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.41123 (A-MSE: 0.36889) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 8 out of 50
train epoch 1586 avg loss: 0.12843 (A-MSE: 0.11452) avg lploss: 0.00000
train epoch 1587 avg loss: 0.12922 (A-MSE: 0.11372) avg lploss: 0.00000
train epoch 1588 avg loss: 0.15330 (A-MSE: 0.13391) avg lploss: 0.00000
train epoch 1589 avg loss: 0.13159 (A-MSE: 0.11610) avg lploss: 0.00000
train epoch 1590 avg loss: 0.10862 (A-MSE: 0.09568) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.40216 (A-MSE: 0.35361) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.37808 (A-MSE: 0.33413) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 9 out of 50
train epoch 1591 avg loss: 0.08891 (A-MSE: 0.07742) avg lploss: 0.00000
train epoch 1592 avg loss: 0.08035 (A-MSE: 0.07125) avg lploss: 0.00000
train epoch 1593 avg loss: 0.06457 (A-MSE: 0.05656) avg lploss: 0.00000
train epoch 1594 avg loss: 0.05950 (A-MSE: 0.05201) avg lploss: 0.00000
train epoch 1595 avg loss: 0.05246 (A-MSE: 0.04626) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.42217 (A-MSE: 0.37171) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.39604 (A-MSE: 0.35339) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 10 out of 50
train epoch 1596 avg loss: 0.05512 (A-MSE: 0.04818) avg lploss: 0.00000
train epoch 1597 avg loss: 0.05695 (A-MSE: 0.05005) avg lploss: 0.00000
train epoch 1598 avg loss: 0.05482 (A-MSE: 0.04864) avg lploss: 0.00000
train epoch 1599 avg loss: 0.06158 (A-MSE: 0.05446) avg lploss: 0.00000
train epoch 1600 avg loss: 0.06535 (A-MSE: 0.05732) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.41013 (A-MSE: 0.35310) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.43029 (A-MSE: 0.37716) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 11 out of 50
train epoch 1601 avg loss: 0.05471 (A-MSE: 0.04814) avg lploss: 0.00000
train epoch 1602 avg loss: 0.05315 (A-MSE: 0.04683) avg lploss: 0.00000
train epoch 1603 avg loss: 0.05463 (A-MSE: 0.04817) avg lploss: 0.00000
train epoch 1604 avg loss: 0.05182 (A-MSE: 0.04512) avg lploss: 0.00000
train epoch 1605 avg loss: 0.05335 (A-MSE: 0.04726) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.38017 (A-MSE: 0.33631) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.38246 (A-MSE: 0.34197) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 12 out of 50
train epoch 1606 avg loss: 0.05129 (A-MSE: 0.04487) avg lploss: 0.00000
train epoch 1607 avg loss: 0.05955 (A-MSE: 0.05172) avg lploss: 0.00000
train epoch 1608 avg loss: 0.05395 (A-MSE: 0.04707) avg lploss: 0.00000
train epoch 1609 avg loss: 0.06267 (A-MSE: 0.05457) avg lploss: 0.00000
train epoch 1610 avg loss: 0.06796 (A-MSE: 0.05994) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.41630 (A-MSE: 0.36564) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.40656 (A-MSE: 0.36183) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 13 out of 50
train epoch 1611 avg loss: 0.06138 (A-MSE: 0.05399) avg lploss: 0.00000
train epoch 1612 avg loss: 0.05106 (A-MSE: 0.04466) avg lploss: 0.00000
train epoch 1613 avg loss: 0.04994 (A-MSE: 0.04449) avg lploss: 0.00000
train epoch 1614 avg loss: 0.06256 (A-MSE: 0.05447) avg lploss: 0.00000
train epoch 1615 avg loss: 0.05833 (A-MSE: 0.05244) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.40296 (A-MSE: 0.35722) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.39289 (A-MSE: 0.35103) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 14 out of 50
train epoch 1616 avg loss: 0.05532 (A-MSE: 0.04839) avg lploss: 0.00000
train epoch 1617 avg loss: 0.05420 (A-MSE: 0.04791) avg lploss: 0.00000
train epoch 1618 avg loss: 0.07450 (A-MSE: 0.06514) avg lploss: 0.00000
train epoch 1619 avg loss: 0.07155 (A-MSE: 0.06296) avg lploss: 0.00000
train epoch 1620 avg loss: 0.08305 (A-MSE: 0.07274) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.44730 (A-MSE: 0.38311) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.46166 (A-MSE: 0.40426) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 15 out of 50
train epoch 1621 avg loss: 0.06608 (A-MSE: 0.05821) avg lploss: 0.00000
train epoch 1622 avg loss: 0.05718 (A-MSE: 0.05021) avg lploss: 0.00000
train epoch 1623 avg loss: 0.07354 (A-MSE: 0.06480) avg lploss: 0.00000
train epoch 1624 avg loss: 0.09210 (A-MSE: 0.08169) avg lploss: 0.00000
train epoch 1625 avg loss: 0.09499 (A-MSE: 0.08325) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.42209 (A-MSE: 0.36913) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.41951 (A-MSE: 0.37408) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 16 out of 50
train epoch 1626 avg loss: 0.07962 (A-MSE: 0.07002) avg lploss: 0.00000
train epoch 1627 avg loss: 0.07876 (A-MSE: 0.06894) avg lploss: 0.00000
train epoch 1628 avg loss: 0.07147 (A-MSE: 0.06386) avg lploss: 0.00000
train epoch 1629 avg loss: 0.05681 (A-MSE: 0.04959) avg lploss: 0.00000
train epoch 1630 avg loss: 0.04954 (A-MSE: 0.04345) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.42789 (A-MSE: 0.38000) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.39958 (A-MSE: 0.36079) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 17 out of 50
train epoch 1631 avg loss: 0.05573 (A-MSE: 0.04817) avg lploss: 0.00000
train epoch 1632 avg loss: 0.06392 (A-MSE: 0.05612) avg lploss: 0.00000
train epoch 1633 avg loss: 0.06359 (A-MSE: 0.05602) avg lploss: 0.00000
train epoch 1634 avg loss: 0.06606 (A-MSE: 0.05754) avg lploss: 0.00000
train epoch 1635 avg loss: 0.06087 (A-MSE: 0.05373) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.49622 (A-MSE: 0.43538) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.43518 (A-MSE: 0.38873) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 18 out of 50
train epoch 1636 avg loss: 0.05778 (A-MSE: 0.05077) avg lploss: 0.00000
train epoch 1637 avg loss: 0.06049 (A-MSE: 0.05283) avg lploss: 0.00000
train epoch 1638 avg loss: 0.05463 (A-MSE: 0.04826) avg lploss: 0.00000
train epoch 1639 avg loss: 0.05025 (A-MSE: 0.04411) avg lploss: 0.00000
train epoch 1640 avg loss: 0.05421 (A-MSE: 0.04733) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.43031 (A-MSE: 0.37983) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.42083 (A-MSE: 0.37568) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 19 out of 50
train epoch 1641 avg loss: 0.06805 (A-MSE: 0.05934) avg lploss: 0.00000
train epoch 1642 avg loss: 0.06838 (A-MSE: 0.06039) avg lploss: 0.00000
train epoch 1643 avg loss: 0.06566 (A-MSE: 0.05762) avg lploss: 0.00000
train epoch 1644 avg loss: 0.06903 (A-MSE: 0.06108) avg lploss: 0.00000
train epoch 1645 avg loss: 0.06615 (A-MSE: 0.05776) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.45008 (A-MSE: 0.39225) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.44501 (A-MSE: 0.39334) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 20 out of 50
train epoch 1646 avg loss: 0.08755 (A-MSE: 0.07659) avg lploss: 0.00000
train epoch 1647 avg loss: 0.08737 (A-MSE: 0.07720) avg lploss: 0.00000
train epoch 1648 avg loss: 0.07360 (A-MSE: 0.06485) avg lploss: 0.00000
train epoch 1649 avg loss: 0.06931 (A-MSE: 0.06125) avg lploss: 0.00000
train epoch 1650 avg loss: 0.06167 (A-MSE: 0.05448) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.42028 (A-MSE: 0.37405) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.40236 (A-MSE: 0.35921) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 21 out of 50
train epoch 1651 avg loss: 0.05640 (A-MSE: 0.04946) avg lploss: 0.00000
train epoch 1652 avg loss: 0.05743 (A-MSE: 0.04992) avg lploss: 0.00000
train epoch 1653 avg loss: 0.05342 (A-MSE: 0.04709) avg lploss: 0.00000
train epoch 1654 avg loss: 0.05582 (A-MSE: 0.04888) avg lploss: 0.00000
train epoch 1655 avg loss: 0.04951 (A-MSE: 0.04308) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.43342 (A-MSE: 0.37714) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.43164 (A-MSE: 0.38129) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 22 out of 50
train epoch 1656 avg loss: 0.05031 (A-MSE: 0.04422) avg lploss: 0.00000
train epoch 1657 avg loss: 0.04309 (A-MSE: 0.03823) avg lploss: 0.00000
train epoch 1658 avg loss: 0.05282 (A-MSE: 0.04677) avg lploss: 0.00000
train epoch 1659 avg loss: 0.05653 (A-MSE: 0.04890) avg lploss: 0.00000
train epoch 1660 avg loss: 0.06783 (A-MSE: 0.05939) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.44649 (A-MSE: 0.39220) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.44561 (A-MSE: 0.40219) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 23 out of 50
train epoch 1661 avg loss: 0.05616 (A-MSE: 0.04936) avg lploss: 0.00000
train epoch 1662 avg loss: 0.07402 (A-MSE: 0.06486) avg lploss: 0.00000
train epoch 1663 avg loss: 0.06943 (A-MSE: 0.06113) avg lploss: 0.00000
train epoch 1664 avg loss: 0.07674 (A-MSE: 0.06776) avg lploss: 0.00000
train epoch 1665 avg loss: 0.05908 (A-MSE: 0.05200) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.35699 (A-MSE: 0.31396) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.37384 (A-MSE: 0.33051) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 24 out of 50
train epoch 1666 avg loss: 0.07113 (A-MSE: 0.06263) avg lploss: 0.00000
train epoch 1667 avg loss: 0.06720 (A-MSE: 0.05979) avg lploss: 0.00000
train epoch 1668 avg loss: 0.06578 (A-MSE: 0.05755) avg lploss: 0.00000
train epoch 1669 avg loss: 0.05686 (A-MSE: 0.04969) avg lploss: 0.00000
train epoch 1670 avg loss: 0.05637 (A-MSE: 0.04961) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.39639 (A-MSE: 0.34253) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.40377 (A-MSE: 0.36038) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 25 out of 50
train epoch 1671 avg loss: 0.06045 (A-MSE: 0.05340) avg lploss: 0.00000
train epoch 1672 avg loss: 0.05947 (A-MSE: 0.05192) avg lploss: 0.00000
train epoch 1673 avg loss: 0.07337 (A-MSE: 0.06431) avg lploss: 0.00000
train epoch 1674 avg loss: 0.06863 (A-MSE: 0.06091) avg lploss: 0.00000
train epoch 1675 avg loss: 0.05928 (A-MSE: 0.05249) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.39053 (A-MSE: 0.34767) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.37681 (A-MSE: 0.33781) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 26 out of 50
train epoch 1676 avg loss: 0.05698 (A-MSE: 0.05047) avg lploss: 0.00000
train epoch 1677 avg loss: 0.05097 (A-MSE: 0.04498) avg lploss: 0.00000
train epoch 1678 avg loss: 0.04944 (A-MSE: 0.04333) avg lploss: 0.00000
train epoch 1679 avg loss: 0.06669 (A-MSE: 0.05849) avg lploss: 0.00000
train epoch 1680 avg loss: 0.07038 (A-MSE: 0.06216) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.41470 (A-MSE: 0.36994) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.42887 (A-MSE: 0.38957) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 27 out of 50
train epoch 1681 avg loss: 0.05880 (A-MSE: 0.05123) avg lploss: 0.00000
train epoch 1682 avg loss: 0.05960 (A-MSE: 0.05291) avg lploss: 0.00000
train epoch 1683 avg loss: 0.06066 (A-MSE: 0.05272) avg lploss: 0.00000
train epoch 1684 avg loss: 0.06262 (A-MSE: 0.05534) avg lploss: 0.00000
train epoch 1685 avg loss: 0.06309 (A-MSE: 0.05519) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.46600 (A-MSE: 0.41159) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.44650 (A-MSE: 0.40359) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 28 out of 50
train epoch 1686 avg loss: 0.06993 (A-MSE: 0.06130) avg lploss: 0.00000
train epoch 1687 avg loss: 0.05878 (A-MSE: 0.05238) avg lploss: 0.00000
train epoch 1688 avg loss: 0.07151 (A-MSE: 0.06277) avg lploss: 0.00000
train epoch 1689 avg loss: 0.07292 (A-MSE: 0.06383) avg lploss: 0.00000
train epoch 1690 avg loss: 0.06257 (A-MSE: 0.05464) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.41863 (A-MSE: 0.37160) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.42492 (A-MSE: 0.38725) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 29 out of 50
train epoch 1691 avg loss: 0.05574 (A-MSE: 0.04901) avg lploss: 0.00000
train epoch 1692 avg loss: 0.06198 (A-MSE: 0.05448) avg lploss: 0.00000
train epoch 1693 avg loss: 0.07792 (A-MSE: 0.06858) avg lploss: 0.00000
train epoch 1694 avg loss: 0.07411 (A-MSE: 0.06582) avg lploss: 0.00000
train epoch 1695 avg loss: 0.07282 (A-MSE: 0.06467) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.38892 (A-MSE: 0.33850) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.42769 (A-MSE: 0.37618) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 30 out of 50
train epoch 1696 avg loss: 0.06742 (A-MSE: 0.05899) avg lploss: 0.00000
train epoch 1697 avg loss: 0.05959 (A-MSE: 0.05268) avg lploss: 0.00000
train epoch 1698 avg loss: 0.05187 (A-MSE: 0.04585) avg lploss: 0.00000
train epoch 1699 avg loss: 0.05509 (A-MSE: 0.04813) avg lploss: 0.00000
train epoch 1700 avg loss: 0.05240 (A-MSE: 0.04629) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.39891 (A-MSE: 0.35146) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.39566 (A-MSE: 0.35053) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 31 out of 50
train epoch 1701 avg loss: 0.05283 (A-MSE: 0.04579) avg lploss: 0.00000
train epoch 1702 avg loss: 0.06390 (A-MSE: 0.05722) avg lploss: 0.00000
train epoch 1703 avg loss: 0.05842 (A-MSE: 0.05156) avg lploss: 0.00000
train epoch 1704 avg loss: 0.05487 (A-MSE: 0.04781) avg lploss: 0.00000
train epoch 1705 avg loss: 0.05841 (A-MSE: 0.05109) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.41745 (A-MSE: 0.36793) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.42033 (A-MSE: 0.37763) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 32 out of 50
train epoch 1706 avg loss: 0.05756 (A-MSE: 0.05035) avg lploss: 0.00000
train epoch 1707 avg loss: 0.05042 (A-MSE: 0.04470) avg lploss: 0.00000
train epoch 1708 avg loss: 0.05525 (A-MSE: 0.04860) avg lploss: 0.00000
train epoch 1709 avg loss: 0.04831 (A-MSE: 0.04264) avg lploss: 0.00000
train epoch 1710 avg loss: 0.05354 (A-MSE: 0.04721) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.42354 (A-MSE: 0.36779) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.40151 (A-MSE: 0.35770) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 33 out of 50
train epoch 1711 avg loss: 0.04591 (A-MSE: 0.04022) avg lploss: 0.00000
train epoch 1712 avg loss: 0.04778 (A-MSE: 0.04182) avg lploss: 0.00000
train epoch 1713 avg loss: 0.04767 (A-MSE: 0.04194) avg lploss: 0.00000
train epoch 1714 avg loss: 0.05511 (A-MSE: 0.04834) avg lploss: 0.00000
train epoch 1715 avg loss: 0.07283 (A-MSE: 0.06446) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.40661 (A-MSE: 0.35996) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.40176 (A-MSE: 0.36341) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 34 out of 50
train epoch 1716 avg loss: 0.07343 (A-MSE: 0.06518) avg lploss: 0.00000
train epoch 1717 avg loss: 0.06064 (A-MSE: 0.05291) avg lploss: 0.00000
train epoch 1718 avg loss: 0.05213 (A-MSE: 0.04586) avg lploss: 0.00000
train epoch 1719 avg loss: 0.05094 (A-MSE: 0.04561) avg lploss: 0.00000
train epoch 1720 avg loss: 0.04298 (A-MSE: 0.03753) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.44513 (A-MSE: 0.38793) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.41861 (A-MSE: 0.37435) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 35 out of 50
train epoch 1721 avg loss: 0.04814 (A-MSE: 0.04198) avg lploss: 0.00000
train epoch 1722 avg loss: 0.05133 (A-MSE: 0.04526) avg lploss: 0.00000
train epoch 1723 avg loss: 0.05390 (A-MSE: 0.04704) avg lploss: 0.00000
train epoch 1724 avg loss: 0.06821 (A-MSE: 0.06048) avg lploss: 0.00000
train epoch 1725 avg loss: 0.05977 (A-MSE: 0.05325) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.41313 (A-MSE: 0.36126) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.41732 (A-MSE: 0.36877) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 36 out of 50
train epoch 1726 avg loss: 0.07469 (A-MSE: 0.06469) avg lploss: 0.00000
train epoch 1727 avg loss: 0.07364 (A-MSE: 0.06639) avg lploss: 0.00000
train epoch 1728 avg loss: 0.05970 (A-MSE: 0.05224) avg lploss: 0.00000
train epoch 1729 avg loss: 0.07374 (A-MSE: 0.06463) avg lploss: 0.00000
train epoch 1730 avg loss: 0.06019 (A-MSE: 0.05255) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.41815 (A-MSE: 0.36352) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.41401 (A-MSE: 0.36688) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 37 out of 50
train epoch 1731 avg loss: 0.05231 (A-MSE: 0.04578) avg lploss: 0.00000
train epoch 1732 avg loss: 0.04909 (A-MSE: 0.04288) avg lploss: 0.00000
train epoch 1733 avg loss: 0.04565 (A-MSE: 0.03982) avg lploss: 0.00000
train epoch 1734 avg loss: 0.04599 (A-MSE: 0.04012) avg lploss: 0.00000
train epoch 1735 avg loss: 0.06094 (A-MSE: 0.05384) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.45310 (A-MSE: 0.40019) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.45375 (A-MSE: 0.40689) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 38 out of 50
train epoch 1736 avg loss: 0.06562 (A-MSE: 0.05790) avg lploss: 0.00000
train epoch 1737 avg loss: 0.07506 (A-MSE: 0.06619) avg lploss: 0.00000
train epoch 1738 avg loss: 0.07404 (A-MSE: 0.06594) avg lploss: 0.00000
train epoch 1739 avg loss: 0.07355 (A-MSE: 0.06501) avg lploss: 0.00000
train epoch 1740 avg loss: 0.06045 (A-MSE: 0.05286) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.37466 (A-MSE: 0.32594) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.35163 (A-MSE: 0.31327) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 39 out of 50
train epoch 1741 avg loss: 0.05233 (A-MSE: 0.04603) avg lploss: 0.00000
train epoch 1742 avg loss: 0.04545 (A-MSE: 0.03951) avg lploss: 0.00000
train epoch 1743 avg loss: 0.04262 (A-MSE: 0.03693) avg lploss: 0.00000
train epoch 1744 avg loss: 0.04230 (A-MSE: 0.03705) avg lploss: 0.00000
train epoch 1745 avg loss: 0.04536 (A-MSE: 0.03974) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.37459 (A-MSE: 0.33001) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.39411 (A-MSE: 0.35239) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 40 out of 50
train epoch 1746 avg loss: 0.05051 (A-MSE: 0.04381) avg lploss: 0.00000
train epoch 1747 avg loss: 0.06199 (A-MSE: 0.05436) avg lploss: 0.00000
train epoch 1748 avg loss: 0.06100 (A-MSE: 0.05413) avg lploss: 0.00000
train epoch 1749 avg loss: 0.06754 (A-MSE: 0.05964) avg lploss: 0.00000
train epoch 1750 avg loss: 0.06272 (A-MSE: 0.05475) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.42447 (A-MSE: 0.37507) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.41616 (A-MSE: 0.37478) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 41 out of 50
train epoch 1751 avg loss: 0.06315 (A-MSE: 0.05497) avg lploss: 0.00000
train epoch 1752 avg loss: 0.06325 (A-MSE: 0.05541) avg lploss: 0.00000
train epoch 1753 avg loss: 0.05809 (A-MSE: 0.05103) avg lploss: 0.00000
train epoch 1754 avg loss: 0.04809 (A-MSE: 0.04230) avg lploss: 0.00000
train epoch 1755 avg loss: 0.05309 (A-MSE: 0.04627) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.38012 (A-MSE: 0.33535) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.37792 (A-MSE: 0.34090) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 42 out of 50
train epoch 1756 avg loss: 0.05269 (A-MSE: 0.04641) avg lploss: 0.00000
train epoch 1757 avg loss: 0.05673 (A-MSE: 0.04997) avg lploss: 0.00000
train epoch 1758 avg loss: 0.04743 (A-MSE: 0.04172) avg lploss: 0.00000
train epoch 1759 avg loss: 0.04477 (A-MSE: 0.03942) avg lploss: 0.00000
train epoch 1760 avg loss: 0.04811 (A-MSE: 0.04223) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.44407 (A-MSE: 0.39098) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.40016 (A-MSE: 0.36173) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 43 out of 50
train epoch 1761 avg loss: 0.06892 (A-MSE: 0.06115) avg lploss: 0.00000
train epoch 1762 avg loss: 0.07672 (A-MSE: 0.06825) avg lploss: 0.00000
train epoch 1763 avg loss: 0.06614 (A-MSE: 0.05888) avg lploss: 0.00000
train epoch 1764 avg loss: 0.05186 (A-MSE: 0.04578) avg lploss: 0.00000
train epoch 1765 avg loss: 0.04470 (A-MSE: 0.03928) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.41543 (A-MSE: 0.35922) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.39434 (A-MSE: 0.35247) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 44 out of 50
train epoch 1766 avg loss: 0.04854 (A-MSE: 0.04245) avg lploss: 0.00000
train epoch 1767 avg loss: 0.04917 (A-MSE: 0.04318) avg lploss: 0.00000
train epoch 1768 avg loss: 0.04914 (A-MSE: 0.04337) avg lploss: 0.00000
train epoch 1769 avg loss: 0.04579 (A-MSE: 0.03985) avg lploss: 0.00000
train epoch 1770 avg loss: 0.04289 (A-MSE: 0.03737) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.39296 (A-MSE: 0.34612) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.37726 (A-MSE: 0.33917) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 45 out of 50
train epoch 1771 avg loss: 0.03531 (A-MSE: 0.03082) avg lploss: 0.00000
train epoch 1772 avg loss: 0.04614 (A-MSE: 0.04058) avg lploss: 0.00000
train epoch 1773 avg loss: 0.04244 (A-MSE: 0.03726) avg lploss: 0.00000
train epoch 1774 avg loss: 0.04123 (A-MSE: 0.03631) avg lploss: 0.00000
train epoch 1775 avg loss: 0.03951 (A-MSE: 0.03489) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.41672 (A-MSE: 0.36492) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.38746 (A-MSE: 0.34897) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 46 out of 50
train epoch 1776 avg loss: 0.04383 (A-MSE: 0.03868) avg lploss: 0.00000
train epoch 1777 avg loss: 0.04913 (A-MSE: 0.04320) avg lploss: 0.00000
train epoch 1778 avg loss: 0.04045 (A-MSE: 0.03546) avg lploss: 0.00000
train epoch 1779 avg loss: 0.04719 (A-MSE: 0.04153) avg lploss: 0.00000
train epoch 1780 avg loss: 0.05881 (A-MSE: 0.05197) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.43065 (A-MSE: 0.37110) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.42725 (A-MSE: 0.38092) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 47 out of 50
train epoch 1781 avg loss: 0.06083 (A-MSE: 0.05380) avg lploss: 0.00000
train epoch 1782 avg loss: 0.09838 (A-MSE: 0.08647) avg lploss: 0.00000
train epoch 1783 avg loss: 0.09757 (A-MSE: 0.08631) avg lploss: 0.00000
train epoch 1784 avg loss: 0.07961 (A-MSE: 0.07009) avg lploss: 0.00000
train epoch 1785 avg loss: 0.06054 (A-MSE: 0.05266) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.38485 (A-MSE: 0.33832) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.38565 (A-MSE: 0.34875) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 48 out of 50
train epoch 1786 avg loss: 0.04701 (A-MSE: 0.04121) avg lploss: 0.00000
train epoch 1787 avg loss: 0.04262 (A-MSE: 0.03751) avg lploss: 0.00000
train epoch 1788 avg loss: 0.03994 (A-MSE: 0.03492) avg lploss: 0.00000
train epoch 1789 avg loss: 0.04990 (A-MSE: 0.04406) avg lploss: 0.00000
train epoch 1790 avg loss: 0.05367 (A-MSE: 0.04717) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.39533 (A-MSE: 0.34817) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.39803 (A-MSE: 0.36238) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 49 out of 50
train epoch 1791 avg loss: 0.07460 (A-MSE: 0.06527) avg lploss: 0.00000
train epoch 1792 avg loss: 0.07109 (A-MSE: 0.06249) avg lploss: 0.00000
train epoch 1793 avg loss: 0.06151 (A-MSE: 0.05458) avg lploss: 0.00000
train epoch 1794 avg loss: 0.05649 (A-MSE: 0.05064) avg lploss: 0.00000
train epoch 1795 avg loss: 0.06387 (A-MSE: 0.05648) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.37288 (A-MSE: 0.32581) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.36820 (A-MSE: 0.33008) avg lploss: 0.00000
*** Best Val Loss: 0.35119 	 Best Test Loss: 0.35252 	 Best epoch 1545
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.065626
best_lp = 0.000000
best_val = 0.351189
best_test = 0.352519
best_epoch = 1545
best_train = 0.065626, best_lp = 0.000000, best_val = 0.351189, best_test = 0.352519, best_epoch = 1545
Training completed for seed 5 with num_modes=1
