Date              = Sat Dec  6 08:06:21 CET 2025
Hostname          = mel2071
Array Task ID     = 0
Running config: configs/mocap_run_seed1.json
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_seed1.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_seed1', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/mocap', pooling_layer=3, seed=1, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/mocap/mocap_run_seed1/saved_model.pth
train epoch 0 avg loss: 627.72743 (A-MSE: 610.91730) avg lploss: 0.00000
==> val epoch 0 avg loss: 96.01215 (A-MSE: 84.69168) avg lploss: 0.00000
==> test epoch 0 avg loss: 91.44628 (A-MSE: 80.67589) avg lploss: 0.00000
*** Best Val Loss: 96.01215 	 Best Test Loss: 91.44628 	 Best epoch 0
Validation loss decreased (inf --> 96.012153).  Saving model ...
train epoch 1 avg loss: 90.95380 (A-MSE: 80.17951) avg lploss: 0.00000
train epoch 2 avg loss: 79.92945 (A-MSE: 70.45785) avg lploss: 0.00000
train epoch 3 avg loss: 56.89903 (A-MSE: 50.13829) avg lploss: 0.00000
train epoch 4 avg loss: 38.90182 (A-MSE: 34.20187) avg lploss: 0.00000
train epoch 5 avg loss: 26.00071 (A-MSE: 22.77095) avg lploss: 0.00000
==> val epoch 5 avg loss: 21.94329 (A-MSE: 19.10222) avg lploss: 0.00000
==> test epoch 5 avg loss: 20.68797 (A-MSE: 18.04796) avg lploss: 0.00000
*** Best Val Loss: 21.94329 	 Best Test Loss: 20.68797 	 Best epoch 5
Validation loss decreased (96.012153 --> 21.943292).  Saving model ...
train epoch 6 avg loss: 20.13970 (A-MSE: 17.77876) avg lploss: 0.00000
train epoch 7 avg loss: 17.42043 (A-MSE: 15.40846) avg lploss: 0.00000
train epoch 8 avg loss: 15.64568 (A-MSE: 13.99769) avg lploss: 0.00000
train epoch 9 avg loss: 13.68603 (A-MSE: 12.13547) avg lploss: 0.00000
train epoch 10 avg loss: 12.42107 (A-MSE: 11.12143) avg lploss: 0.00000
==> val epoch 10 avg loss: 11.65319 (A-MSE: 10.62491) avg lploss: 0.00000
==> test epoch 10 avg loss: 10.98260 (A-MSE: 10.00407) avg lploss: 0.00000
*** Best Val Loss: 11.65319 	 Best Test Loss: 10.98260 	 Best epoch 10
Validation loss decreased (21.943292 --> 11.653193).  Saving model ...
train epoch 11 avg loss: 12.54017 (A-MSE: 11.22564) avg lploss: 0.00000
train epoch 12 avg loss: 11.56090 (A-MSE: 10.33268) avg lploss: 0.00000
train epoch 13 avg loss: 10.55128 (A-MSE: 9.42620) avg lploss: 0.00000
train epoch 14 avg loss: 8.97773 (A-MSE: 8.00755) avg lploss: 0.00000
train epoch 15 avg loss: 8.71809 (A-MSE: 7.78127) avg lploss: 0.00000
==> val epoch 15 avg loss: 8.18101 (A-MSE: 7.30453) avg lploss: 0.00000
==> test epoch 15 avg loss: 7.88315 (A-MSE: 7.04374) avg lploss: 0.00000
*** Best Val Loss: 8.18101 	 Best Test Loss: 7.88315 	 Best epoch 15
Validation loss decreased (11.653193 --> 8.181008).  Saving model ...
train epoch 16 avg loss: 8.18323 (A-MSE: 7.36480) avg lploss: 0.00000
train epoch 17 avg loss: 7.75597 (A-MSE: 6.94408) avg lploss: 0.00000
train epoch 18 avg loss: 7.53044 (A-MSE: 6.73680) avg lploss: 0.00000
train epoch 19 avg loss: 6.83075 (A-MSE: 6.11800) avg lploss: 0.00000
train epoch 20 avg loss: 6.51699 (A-MSE: 5.87989) avg lploss: 0.00000
==> val epoch 20 avg loss: 6.80949 (A-MSE: 5.96732) avg lploss: 0.00000
==> test epoch 20 avg loss: 6.76617 (A-MSE: 5.94738) avg lploss: 0.00000
*** Best Val Loss: 6.80949 	 Best Test Loss: 6.76617 	 Best epoch 20
Validation loss decreased (8.181008 --> 6.809491).  Saving model ...
train epoch 21 avg loss: 6.61988 (A-MSE: 5.92644) avg lploss: 0.00000
train epoch 22 avg loss: 6.24203 (A-MSE: 5.60437) avg lploss: 0.00000
train epoch 23 avg loss: 6.31357 (A-MSE: 5.67135) avg lploss: 0.00000
train epoch 24 avg loss: 7.09584 (A-MSE: 6.37352) avg lploss: 0.00000
train epoch 25 avg loss: 5.72375 (A-MSE: 5.10158) avg lploss: 0.00000
==> val epoch 25 avg loss: 5.34682 (A-MSE: 4.81283) avg lploss: 0.00000
==> test epoch 25 avg loss: 5.42085 (A-MSE: 4.88576) avg lploss: 0.00000
*** Best Val Loss: 5.34682 	 Best Test Loss: 5.42085 	 Best epoch 25
Validation loss decreased (6.809491 --> 5.346824).  Saving model ...
train epoch 26 avg loss: 5.53428 (A-MSE: 4.95609) avg lploss: 0.00000
train epoch 27 avg loss: 5.62986 (A-MSE: 5.07271) avg lploss: 0.00000
train epoch 28 avg loss: 5.47136 (A-MSE: 4.92007) avg lploss: 0.00000
train epoch 29 avg loss: 5.20359 (A-MSE: 4.68720) avg lploss: 0.00000
train epoch 30 avg loss: 5.09731 (A-MSE: 4.55828) avg lploss: 0.00000
==> val epoch 30 avg loss: 5.05191 (A-MSE: 4.74504) avg lploss: 0.00000
==> test epoch 30 avg loss: 5.18699 (A-MSE: 4.86402) avg lploss: 0.00000
*** Best Val Loss: 5.05191 	 Best Test Loss: 5.18699 	 Best epoch 30
Validation loss decreased (5.346824 --> 5.051907).  Saving model ...
train epoch 31 avg loss: 5.09335 (A-MSE: 4.57704) avg lploss: 0.00000
train epoch 32 avg loss: 4.60781 (A-MSE: 4.12631) avg lploss: 0.00000
train epoch 33 avg loss: 4.47467 (A-MSE: 4.01443) avg lploss: 0.00000
train epoch 34 avg loss: 4.39439 (A-MSE: 3.94745) avg lploss: 0.00000
train epoch 35 avg loss: 5.05199 (A-MSE: 4.55264) avg lploss: 0.00000
==> val epoch 35 avg loss: 4.65499 (A-MSE: 4.24380) avg lploss: 0.00000
==> test epoch 35 avg loss: 4.71468 (A-MSE: 4.29161) avg lploss: 0.00000
*** Best Val Loss: 4.65499 	 Best Test Loss: 4.71468 	 Best epoch 35
Validation loss decreased (5.051907 --> 4.654993).  Saving model ...
train epoch 36 avg loss: 4.51528 (A-MSE: 4.06191) avg lploss: 0.00000
train epoch 37 avg loss: 4.41304 (A-MSE: 3.97251) avg lploss: 0.00000
train epoch 38 avg loss: 4.28004 (A-MSE: 3.87695) avg lploss: 0.00000
train epoch 39 avg loss: 4.16479 (A-MSE: 3.72300) avg lploss: 0.00000
train epoch 40 avg loss: 4.19199 (A-MSE: 3.77217) avg lploss: 0.00000
==> val epoch 40 avg loss: 5.31334 (A-MSE: 4.87199) avg lploss: 0.00000
==> test epoch 40 avg loss: 5.22837 (A-MSE: 4.78900) avg lploss: 0.00000
*** Best Val Loss: 4.65499 	 Best Test Loss: 4.71468 	 Best epoch 35
EarlyStopping counter: 1 out of 50
train epoch 41 avg loss: 4.15851 (A-MSE: 3.74146) avg lploss: 0.00000
train epoch 42 avg loss: 4.02042 (A-MSE: 3.61541) avg lploss: 0.00000
train epoch 43 avg loss: 3.78167 (A-MSE: 3.43100) avg lploss: 0.00000
train epoch 44 avg loss: 3.57319 (A-MSE: 3.23593) avg lploss: 0.00000
train epoch 45 avg loss: 3.66122 (A-MSE: 3.29718) avg lploss: 0.00000
==> val epoch 45 avg loss: 3.81479 (A-MSE: 3.50957) avg lploss: 0.00000
==> test epoch 45 avg loss: 4.00032 (A-MSE: 3.68193) avg lploss: 0.00000
*** Best Val Loss: 3.81479 	 Best Test Loss: 4.00032 	 Best epoch 45
Validation loss decreased (4.654993 --> 3.814786).  Saving model ...
train epoch 46 avg loss: 3.73640 (A-MSE: 3.36161) avg lploss: 0.00000
train epoch 47 avg loss: 4.02963 (A-MSE: 3.63091) avg lploss: 0.00000
train epoch 48 avg loss: 3.61753 (A-MSE: 3.27159) avg lploss: 0.00000
train epoch 49 avg loss: 3.22145 (A-MSE: 2.91224) avg lploss: 0.00000
train epoch 50 avg loss: 3.26032 (A-MSE: 2.93805) avg lploss: 0.00000
==> val epoch 50 avg loss: 3.55779 (A-MSE: 3.22086) avg lploss: 0.00000
==> test epoch 50 avg loss: 3.65764 (A-MSE: 3.31406) avg lploss: 0.00000
*** Best Val Loss: 3.55779 	 Best Test Loss: 3.65764 	 Best epoch 50
Validation loss decreased (3.814786 --> 3.557794).  Saving model ...
train epoch 51 avg loss: 3.59061 (A-MSE: 3.23497) avg lploss: 0.00000
train epoch 52 avg loss: 3.38830 (A-MSE: 3.06523) avg lploss: 0.00000
train epoch 53 avg loss: 3.51610 (A-MSE: 3.17511) avg lploss: 0.00000
train epoch 54 avg loss: 3.29300 (A-MSE: 2.97512) avg lploss: 0.00000
train epoch 55 avg loss: 3.07571 (A-MSE: 2.77660) avg lploss: 0.00000
==> val epoch 55 avg loss: 3.28877 (A-MSE: 3.02988) avg lploss: 0.00000
==> test epoch 55 avg loss: 3.47360 (A-MSE: 3.19051) avg lploss: 0.00000
*** Best Val Loss: 3.28877 	 Best Test Loss: 3.47360 	 Best epoch 55
Validation loss decreased (3.557794 --> 3.288775).  Saving model ...
train epoch 56 avg loss: 3.09609 (A-MSE: 2.80240) avg lploss: 0.00000
train epoch 57 avg loss: 3.05887 (A-MSE: 2.76308) avg lploss: 0.00000
train epoch 58 avg loss: 2.70585 (A-MSE: 2.44803) avg lploss: 0.00000
train epoch 59 avg loss: 2.80313 (A-MSE: 2.53024) avg lploss: 0.00000
train epoch 60 avg loss: 2.73645 (A-MSE: 2.48151) avg lploss: 0.00000
==> val epoch 60 avg loss: 3.47979 (A-MSE: 3.24103) avg lploss: 0.00000
==> test epoch 60 avg loss: 3.63486 (A-MSE: 3.37021) avg lploss: 0.00000
*** Best Val Loss: 3.28877 	 Best Test Loss: 3.47360 	 Best epoch 55
EarlyStopping counter: 1 out of 50
train epoch 61 avg loss: 2.63715 (A-MSE: 2.38639) avg lploss: 0.00000
train epoch 62 avg loss: 2.73832 (A-MSE: 2.47199) avg lploss: 0.00000
train epoch 63 avg loss: 2.94340 (A-MSE: 2.66375) avg lploss: 0.00000
train epoch 64 avg loss: 2.64147 (A-MSE: 2.38767) avg lploss: 0.00000
train epoch 65 avg loss: 2.70030 (A-MSE: 2.43648) avg lploss: 0.00000
==> val epoch 65 avg loss: 3.63035 (A-MSE: 3.37375) avg lploss: 0.00000
==> test epoch 65 avg loss: 3.72922 (A-MSE: 3.45736) avg lploss: 0.00000
*** Best Val Loss: 3.28877 	 Best Test Loss: 3.47360 	 Best epoch 55
EarlyStopping counter: 2 out of 50
train epoch 66 avg loss: 3.06921 (A-MSE: 2.79377) avg lploss: 0.00000
train epoch 67 avg loss: 2.79031 (A-MSE: 2.52929) avg lploss: 0.00000
train epoch 68 avg loss: 2.79458 (A-MSE: 2.51259) avg lploss: 0.00000
train epoch 69 avg loss: 2.65642 (A-MSE: 2.40198) avg lploss: 0.00000
train epoch 70 avg loss: 2.36387 (A-MSE: 2.13312) avg lploss: 0.00000
==> val epoch 70 avg loss: 2.73619 (A-MSE: 2.50944) avg lploss: 0.00000
==> test epoch 70 avg loss: 2.89342 (A-MSE: 2.64592) avg lploss: 0.00000
*** Best Val Loss: 2.73619 	 Best Test Loss: 2.89342 	 Best epoch 70
Validation loss decreased (3.288775 --> 2.736190).  Saving model ...
train epoch 71 avg loss: 2.38029 (A-MSE: 2.15428) avg lploss: 0.00000
train epoch 72 avg loss: 2.47872 (A-MSE: 2.22743) avg lploss: 0.00000
train epoch 73 avg loss: 2.39872 (A-MSE: 2.17522) avg lploss: 0.00000
train epoch 74 avg loss: 2.30136 (A-MSE: 2.07197) avg lploss: 0.00000
train epoch 75 avg loss: 2.23600 (A-MSE: 2.01023) avg lploss: 0.00000
==> val epoch 75 avg loss: 2.63149 (A-MSE: 2.42744) avg lploss: 0.00000
==> test epoch 75 avg loss: 2.68924 (A-MSE: 2.49301) avg lploss: 0.00000
*** Best Val Loss: 2.63149 	 Best Test Loss: 2.68924 	 Best epoch 75
Validation loss decreased (2.736190 --> 2.631486).  Saving model ...
train epoch 76 avg loss: 2.00106 (A-MSE: 1.80258) avg lploss: 0.00000
train epoch 77 avg loss: 2.10482 (A-MSE: 1.88752) avg lploss: 0.00000
train epoch 78 avg loss: 2.02557 (A-MSE: 1.82481) avg lploss: 0.00000
train epoch 79 avg loss: 2.13009 (A-MSE: 1.90966) avg lploss: 0.00000
train epoch 80 avg loss: 2.34044 (A-MSE: 2.11562) avg lploss: 0.00000
==> val epoch 80 avg loss: 2.73227 (A-MSE: 2.50175) avg lploss: 0.00000
==> test epoch 80 avg loss: 2.75978 (A-MSE: 2.54604) avg lploss: 0.00000
*** Best Val Loss: 2.63149 	 Best Test Loss: 2.68924 	 Best epoch 75
EarlyStopping counter: 1 out of 50
train epoch 81 avg loss: 2.00779 (A-MSE: 1.80260) avg lploss: 0.00000
train epoch 82 avg loss: 1.90386 (A-MSE: 1.69176) avg lploss: 0.00000
train epoch 83 avg loss: 1.98278 (A-MSE: 1.77727) avg lploss: 0.00000
train epoch 84 avg loss: 1.83295 (A-MSE: 1.63478) avg lploss: 0.00000
train epoch 85 avg loss: 1.73014 (A-MSE: 1.54037) avg lploss: 0.00000
==> val epoch 85 avg loss: 2.28729 (A-MSE: 2.04918) avg lploss: 0.00000
==> test epoch 85 avg loss: 2.33956 (A-MSE: 2.11275) avg lploss: 0.00000
*** Best Val Loss: 2.28729 	 Best Test Loss: 2.33956 	 Best epoch 85
Validation loss decreased (2.631486 --> 2.287290).  Saving model ...
train epoch 86 avg loss: 1.74651 (A-MSE: 1.55841) avg lploss: 0.00000
train epoch 87 avg loss: 1.71276 (A-MSE: 1.53036) avg lploss: 0.00000
train epoch 88 avg loss: 1.64243 (A-MSE: 1.45518) avg lploss: 0.00000
train epoch 89 avg loss: 1.60583 (A-MSE: 1.43222) avg lploss: 0.00000
train epoch 90 avg loss: 1.51789 (A-MSE: 1.35286) avg lploss: 0.00000
==> val epoch 90 avg loss: 1.68156 (A-MSE: 1.52205) avg lploss: 0.00000
==> test epoch 90 avg loss: 1.88771 (A-MSE: 1.72594) avg lploss: 0.00000
*** Best Val Loss: 1.68156 	 Best Test Loss: 1.88771 	 Best epoch 90
Validation loss decreased (2.287290 --> 1.681555).  Saving model ...
train epoch 91 avg loss: 1.42786 (A-MSE: 1.26405) avg lploss: 0.00000
train epoch 92 avg loss: 1.56718 (A-MSE: 1.39748) avg lploss: 0.00000
train epoch 93 avg loss: 1.67254 (A-MSE: 1.49503) avg lploss: 0.00000
train epoch 94 avg loss: 1.49198 (A-MSE: 1.32482) avg lploss: 0.00000
train epoch 95 avg loss: 1.67393 (A-MSE: 1.49606) avg lploss: 0.00000
==> val epoch 95 avg loss: 1.68163 (A-MSE: 1.49740) avg lploss: 0.00000
==> test epoch 95 avg loss: 1.76623 (A-MSE: 1.58649) avg lploss: 0.00000
*** Best Val Loss: 1.68156 	 Best Test Loss: 1.88771 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 1.41082 (A-MSE: 1.25559) avg lploss: 0.00000
train epoch 97 avg loss: 1.35284 (A-MSE: 1.20002) avg lploss: 0.00000
train epoch 98 avg loss: 1.38820 (A-MSE: 1.23140) avg lploss: 0.00000
train epoch 99 avg loss: 1.37976 (A-MSE: 1.22624) avg lploss: 0.00000
train epoch 100 avg loss: 1.39043 (A-MSE: 1.23739) avg lploss: 0.00000
==> val epoch 100 avg loss: 1.72378 (A-MSE: 1.53551) avg lploss: 0.00000
==> test epoch 100 avg loss: 1.83876 (A-MSE: 1.65166) avg lploss: 0.00000
*** Best Val Loss: 1.68156 	 Best Test Loss: 1.88771 	 Best epoch 90
EarlyStopping counter: 2 out of 50
train epoch 101 avg loss: 1.30403 (A-MSE: 1.15733) avg lploss: 0.00000
train epoch 102 avg loss: 1.38539 (A-MSE: 1.23250) avg lploss: 0.00000
train epoch 103 avg loss: 1.31018 (A-MSE: 1.16667) avg lploss: 0.00000
train epoch 104 avg loss: 1.45955 (A-MSE: 1.30496) avg lploss: 0.00000
train epoch 105 avg loss: 1.32318 (A-MSE: 1.17661) avg lploss: 0.00000
==> val epoch 105 avg loss: 1.59894 (A-MSE: 1.44166) avg lploss: 0.00000
==> test epoch 105 avg loss: 1.73864 (A-MSE: 1.58077) avg lploss: 0.00000
*** Best Val Loss: 1.59894 	 Best Test Loss: 1.73864 	 Best epoch 105
Validation loss decreased (1.681555 --> 1.598943).  Saving model ...
train epoch 106 avg loss: 1.33582 (A-MSE: 1.18892) avg lploss: 0.00000
train epoch 107 avg loss: 1.34681 (A-MSE: 1.20054) avg lploss: 0.00000
train epoch 108 avg loss: 1.35456 (A-MSE: 1.19645) avg lploss: 0.00000
train epoch 109 avg loss: 1.34324 (A-MSE: 1.19836) avg lploss: 0.00000
train epoch 110 avg loss: 1.29783 (A-MSE: 1.14809) avg lploss: 0.00000
==> val epoch 110 avg loss: 1.93653 (A-MSE: 1.75567) avg lploss: 0.00000
==> test epoch 110 avg loss: 2.03403 (A-MSE: 1.85723) avg lploss: 0.00000
*** Best Val Loss: 1.59894 	 Best Test Loss: 1.73864 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 1.23491 (A-MSE: 1.09229) avg lploss: 0.00000
train epoch 112 avg loss: 1.09210 (A-MSE: 0.96698) avg lploss: 0.00000
train epoch 113 avg loss: 1.18292 (A-MSE: 1.05616) avg lploss: 0.00000
train epoch 114 avg loss: 1.33514 (A-MSE: 1.19150) avg lploss: 0.00000
train epoch 115 avg loss: 1.18953 (A-MSE: 1.05526) avg lploss: 0.00000
==> val epoch 115 avg loss: 1.39356 (A-MSE: 1.24985) avg lploss: 0.00000
==> test epoch 115 avg loss: 1.51607 (A-MSE: 1.37511) avg lploss: 0.00000
*** Best Val Loss: 1.39356 	 Best Test Loss: 1.51607 	 Best epoch 115
Validation loss decreased (1.598943 --> 1.393559).  Saving model ...
train epoch 116 avg loss: 1.07910 (A-MSE: 0.95927) avg lploss: 0.00000
train epoch 117 avg loss: 1.27020 (A-MSE: 1.12831) avg lploss: 0.00000
train epoch 118 avg loss: 1.23727 (A-MSE: 1.10474) avg lploss: 0.00000
train epoch 119 avg loss: 1.19759 (A-MSE: 1.06703) avg lploss: 0.00000
train epoch 120 avg loss: 1.17214 (A-MSE: 1.04280) avg lploss: 0.00000
==> val epoch 120 avg loss: 1.62753 (A-MSE: 1.45230) avg lploss: 0.00000
==> test epoch 120 avg loss: 1.68851 (A-MSE: 1.51653) avg lploss: 0.00000
*** Best Val Loss: 1.39356 	 Best Test Loss: 1.51607 	 Best epoch 115
EarlyStopping counter: 1 out of 50
train epoch 121 avg loss: 1.11555 (A-MSE: 0.99040) avg lploss: 0.00000
train epoch 122 avg loss: 1.05308 (A-MSE: 0.93275) avg lploss: 0.00000
train epoch 123 avg loss: 1.09483 (A-MSE: 0.97562) avg lploss: 0.00000
train epoch 124 avg loss: 1.10429 (A-MSE: 0.98652) avg lploss: 0.00000
train epoch 125 avg loss: 1.05402 (A-MSE: 0.94005) avg lploss: 0.00000
==> val epoch 125 avg loss: 1.31296 (A-MSE: 1.18324) avg lploss: 0.00000
==> test epoch 125 avg loss: 1.50353 (A-MSE: 1.36861) avg lploss: 0.00000
*** Best Val Loss: 1.31296 	 Best Test Loss: 1.50353 	 Best epoch 125
Validation loss decreased (1.393559 --> 1.312964).  Saving model ...
train epoch 126 avg loss: 1.10257 (A-MSE: 0.98429) avg lploss: 0.00000
train epoch 127 avg loss: 0.96062 (A-MSE: 0.85815) avg lploss: 0.00000
train epoch 128 avg loss: 1.14418 (A-MSE: 1.02465) avg lploss: 0.00000
train epoch 129 avg loss: 1.19638 (A-MSE: 1.07301) avg lploss: 0.00000
train epoch 130 avg loss: 0.97897 (A-MSE: 0.86923) avg lploss: 0.00000
==> val epoch 130 avg loss: 1.33381 (A-MSE: 1.19900) avg lploss: 0.00000
==> test epoch 130 avg loss: 1.43551 (A-MSE: 1.30487) avg lploss: 0.00000
*** Best Val Loss: 1.31296 	 Best Test Loss: 1.50353 	 Best epoch 125
EarlyStopping counter: 1 out of 50
train epoch 131 avg loss: 1.15551 (A-MSE: 1.03031) avg lploss: 0.00000
train epoch 132 avg loss: 1.02975 (A-MSE: 0.91598) avg lploss: 0.00000
train epoch 133 avg loss: 1.03081 (A-MSE: 0.92046) avg lploss: 0.00000
train epoch 134 avg loss: 0.93904 (A-MSE: 0.83261) avg lploss: 0.00000
train epoch 135 avg loss: 0.97903 (A-MSE: 0.86929) avg lploss: 0.00000
==> val epoch 135 avg loss: 1.26660 (A-MSE: 1.13635) avg lploss: 0.00000
==> test epoch 135 avg loss: 1.33172 (A-MSE: 1.20812) avg lploss: 0.00000
*** Best Val Loss: 1.26660 	 Best Test Loss: 1.33172 	 Best epoch 135
Validation loss decreased (1.312964 --> 1.266604).  Saving model ...
train epoch 136 avg loss: 0.92143 (A-MSE: 0.82181) avg lploss: 0.00000
train epoch 137 avg loss: 0.98662 (A-MSE: 0.87502) avg lploss: 0.00000
train epoch 138 avg loss: 0.93931 (A-MSE: 0.83588) avg lploss: 0.00000
train epoch 139 avg loss: 0.96526 (A-MSE: 0.85518) avg lploss: 0.00000
train epoch 140 avg loss: 0.97797 (A-MSE: 0.86766) avg lploss: 0.00000
==> val epoch 140 avg loss: 1.21929 (A-MSE: 1.09734) avg lploss: 0.00000
==> test epoch 140 avg loss: 1.35251 (A-MSE: 1.22845) avg lploss: 0.00000
*** Best Val Loss: 1.21929 	 Best Test Loss: 1.35251 	 Best epoch 140
Validation loss decreased (1.266604 --> 1.219294).  Saving model ...
train epoch 141 avg loss: 0.99420 (A-MSE: 0.88679) avg lploss: 0.00000
train epoch 142 avg loss: 0.96966 (A-MSE: 0.86806) avg lploss: 0.00000
train epoch 143 avg loss: 0.98121 (A-MSE: 0.87622) avg lploss: 0.00000
train epoch 144 avg loss: 0.94649 (A-MSE: 0.84624) avg lploss: 0.00000
train epoch 145 avg loss: 0.89510 (A-MSE: 0.79721) avg lploss: 0.00000
==> val epoch 145 avg loss: 1.25740 (A-MSE: 1.13052) avg lploss: 0.00000
==> test epoch 145 avg loss: 1.35621 (A-MSE: 1.22977) avg lploss: 0.00000
*** Best Val Loss: 1.21929 	 Best Test Loss: 1.35251 	 Best epoch 140
EarlyStopping counter: 1 out of 50
train epoch 146 avg loss: 0.99896 (A-MSE: 0.89750) avg lploss: 0.00000
train epoch 147 avg loss: 1.00341 (A-MSE: 0.89622) avg lploss: 0.00000
train epoch 148 avg loss: 0.92694 (A-MSE: 0.82782) avg lploss: 0.00000
train epoch 149 avg loss: 0.92683 (A-MSE: 0.82790) avg lploss: 0.00000
train epoch 150 avg loss: 0.92735 (A-MSE: 0.83116) avg lploss: 0.00000
==> val epoch 150 avg loss: 1.13717 (A-MSE: 1.02139) avg lploss: 0.00000
==> test epoch 150 avg loss: 1.21232 (A-MSE: 1.10661) avg lploss: 0.00000
*** Best Val Loss: 1.13717 	 Best Test Loss: 1.21232 	 Best epoch 150
Validation loss decreased (1.219294 --> 1.137168).  Saving model ...
train epoch 151 avg loss: 1.02761 (A-MSE: 0.92482) avg lploss: 0.00000
train epoch 152 avg loss: 1.09735 (A-MSE: 0.98728) avg lploss: 0.00000
train epoch 153 avg loss: 1.19941 (A-MSE: 1.08144) avg lploss: 0.00000
train epoch 154 avg loss: 1.12468 (A-MSE: 1.01146) avg lploss: 0.00000
train epoch 155 avg loss: 0.98319 (A-MSE: 0.88353) avg lploss: 0.00000
==> val epoch 155 avg loss: 1.07191 (A-MSE: 0.95823) avg lploss: 0.00000
==> test epoch 155 avg loss: 1.19250 (A-MSE: 1.07938) avg lploss: 0.00000
*** Best Val Loss: 1.07191 	 Best Test Loss: 1.19250 	 Best epoch 155
Validation loss decreased (1.137168 --> 1.071910).  Saving model ...
train epoch 156 avg loss: 0.94055 (A-MSE: 0.83966) avg lploss: 0.00000
train epoch 157 avg loss: 0.89869 (A-MSE: 0.80184) avg lploss: 0.00000
train epoch 158 avg loss: 0.82847 (A-MSE: 0.74272) avg lploss: 0.00000
train epoch 159 avg loss: 0.85061 (A-MSE: 0.76007) avg lploss: 0.00000
train epoch 160 avg loss: 0.81786 (A-MSE: 0.73007) avg lploss: 0.00000
==> val epoch 160 avg loss: 1.00694 (A-MSE: 0.91006) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.11904 (A-MSE: 1.02721) avg lploss: 0.00000
*** Best Val Loss: 1.00694 	 Best Test Loss: 1.11904 	 Best epoch 160
Validation loss decreased (1.071910 --> 1.006945).  Saving model ...
train epoch 161 avg loss: 0.80318 (A-MSE: 0.72181) avg lploss: 0.00000
train epoch 162 avg loss: 0.84195 (A-MSE: 0.75659) avg lploss: 0.00000
train epoch 163 avg loss: 0.78620 (A-MSE: 0.70547) avg lploss: 0.00000
train epoch 164 avg loss: 0.75518 (A-MSE: 0.67619) avg lploss: 0.00000
train epoch 165 avg loss: 0.79903 (A-MSE: 0.71645) avg lploss: 0.00000
==> val epoch 165 avg loss: 1.41843 (A-MSE: 1.25710) avg lploss: 0.00000
==> test epoch 165 avg loss: 1.53152 (A-MSE: 1.37366) avg lploss: 0.00000
*** Best Val Loss: 1.00694 	 Best Test Loss: 1.11904 	 Best epoch 160
EarlyStopping counter: 1 out of 50
train epoch 166 avg loss: 0.89190 (A-MSE: 0.79842) avg lploss: 0.00000
train epoch 167 avg loss: 1.02858 (A-MSE: 0.92803) avg lploss: 0.00000
train epoch 168 avg loss: 0.93005 (A-MSE: 0.83172) avg lploss: 0.00000
train epoch 169 avg loss: 0.81753 (A-MSE: 0.73475) avg lploss: 0.00000
train epoch 170 avg loss: 0.79720 (A-MSE: 0.71514) avg lploss: 0.00000
==> val epoch 170 avg loss: 1.19748 (A-MSE: 1.08750) avg lploss: 0.00000
==> test epoch 170 avg loss: 1.23400 (A-MSE: 1.13373) avg lploss: 0.00000
*** Best Val Loss: 1.00694 	 Best Test Loss: 1.11904 	 Best epoch 160
EarlyStopping counter: 2 out of 50
train epoch 171 avg loss: 0.84578 (A-MSE: 0.76355) avg lploss: 0.00000
train epoch 172 avg loss: 0.83472 (A-MSE: 0.75273) avg lploss: 0.00000
train epoch 173 avg loss: 0.74516 (A-MSE: 0.66265) avg lploss: 0.00000
train epoch 174 avg loss: 0.71757 (A-MSE: 0.64666) avg lploss: 0.00000
train epoch 175 avg loss: 0.85019 (A-MSE: 0.76453) avg lploss: 0.00000
==> val epoch 175 avg loss: 1.11235 (A-MSE: 0.99325) avg lploss: 0.00000
==> test epoch 175 avg loss: 1.21506 (A-MSE: 1.10047) avg lploss: 0.00000
*** Best Val Loss: 1.00694 	 Best Test Loss: 1.11904 	 Best epoch 160
EarlyStopping counter: 3 out of 50
train epoch 176 avg loss: 0.77176 (A-MSE: 0.69110) avg lploss: 0.00000
train epoch 177 avg loss: 0.82063 (A-MSE: 0.73845) avg lploss: 0.00000
train epoch 178 avg loss: 0.76972 (A-MSE: 0.69214) avg lploss: 0.00000
train epoch 179 avg loss: 0.85574 (A-MSE: 0.76492) avg lploss: 0.00000
train epoch 180 avg loss: 0.80111 (A-MSE: 0.71967) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.97579 (A-MSE: 0.86743) avg lploss: 0.00000
==> test epoch 180 avg loss: 1.09956 (A-MSE: 0.98811) avg lploss: 0.00000
*** Best Val Loss: 0.97579 	 Best Test Loss: 1.09956 	 Best epoch 180
Validation loss decreased (1.006945 --> 0.975793).  Saving model ...
train epoch 181 avg loss: 0.72360 (A-MSE: 0.65027) avg lploss: 0.00000
train epoch 182 avg loss: 0.78415 (A-MSE: 0.70583) avg lploss: 0.00000
train epoch 183 avg loss: 0.80431 (A-MSE: 0.72248) avg lploss: 0.00000
train epoch 184 avg loss: 0.75023 (A-MSE: 0.67453) avg lploss: 0.00000
train epoch 185 avg loss: 0.73460 (A-MSE: 0.65925) avg lploss: 0.00000
==> val epoch 185 avg loss: 1.15839 (A-MSE: 1.02855) avg lploss: 0.00000
==> test epoch 185 avg loss: 1.16250 (A-MSE: 1.05115) avg lploss: 0.00000
*** Best Val Loss: 0.97579 	 Best Test Loss: 1.09956 	 Best epoch 180
EarlyStopping counter: 1 out of 50
train epoch 186 avg loss: 0.81492 (A-MSE: 0.73425) avg lploss: 0.00000
train epoch 187 avg loss: 0.74609 (A-MSE: 0.67010) avg lploss: 0.00000
train epoch 188 avg loss: 0.68697 (A-MSE: 0.61529) avg lploss: 0.00000
train epoch 189 avg loss: 0.75289 (A-MSE: 0.67975) avg lploss: 0.00000
train epoch 190 avg loss: 0.72139 (A-MSE: 0.64716) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.95063 (A-MSE: 0.85176) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.98811 (A-MSE: 0.89845) avg lploss: 0.00000
*** Best Val Loss: 0.95063 	 Best Test Loss: 0.98811 	 Best epoch 190
Validation loss decreased (0.975793 --> 0.950629).  Saving model ...
train epoch 191 avg loss: 0.76479 (A-MSE: 0.68820) avg lploss: 0.00000
train epoch 192 avg loss: 0.75024 (A-MSE: 0.67373) avg lploss: 0.00000
train epoch 193 avg loss: 0.71504 (A-MSE: 0.64174) avg lploss: 0.00000
train epoch 194 avg loss: 0.79887 (A-MSE: 0.71914) avg lploss: 0.00000
train epoch 195 avg loss: 0.72988 (A-MSE: 0.65881) avg lploss: 0.00000
==> val epoch 195 avg loss: 1.25669 (A-MSE: 1.14485) avg lploss: 0.00000
==> test epoch 195 avg loss: 1.32308 (A-MSE: 1.21718) avg lploss: 0.00000
*** Best Val Loss: 0.95063 	 Best Test Loss: 0.98811 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 0.77712 (A-MSE: 0.70671) avg lploss: 0.00000
train epoch 197 avg loss: 0.80805 (A-MSE: 0.72927) avg lploss: 0.00000
train epoch 198 avg loss: 0.66933 (A-MSE: 0.60352) avg lploss: 0.00000
train epoch 199 avg loss: 0.72731 (A-MSE: 0.65492) avg lploss: 0.00000
train epoch 200 avg loss: 0.75844 (A-MSE: 0.68348) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.98318 (A-MSE: 0.87906) avg lploss: 0.00000
==> test epoch 200 avg loss: 1.05349 (A-MSE: 0.95518) avg lploss: 0.00000
*** Best Val Loss: 0.95063 	 Best Test Loss: 0.98811 	 Best epoch 190
EarlyStopping counter: 2 out of 50
train epoch 201 avg loss: 0.69241 (A-MSE: 0.62352) avg lploss: 0.00000
train epoch 202 avg loss: 0.68146 (A-MSE: 0.61348) avg lploss: 0.00000
train epoch 203 avg loss: 0.70468 (A-MSE: 0.63545) avg lploss: 0.00000
train epoch 204 avg loss: 0.70768 (A-MSE: 0.63602) avg lploss: 0.00000
train epoch 205 avg loss: 0.66519 (A-MSE: 0.59376) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.85811 (A-MSE: 0.77166) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.99387 (A-MSE: 0.90656) avg lploss: 0.00000
*** Best Val Loss: 0.85811 	 Best Test Loss: 0.99387 	 Best epoch 205
Validation loss decreased (0.950629 --> 0.858108).  Saving model ...
train epoch 206 avg loss: 0.69951 (A-MSE: 0.63324) avg lploss: 0.00000
train epoch 207 avg loss: 0.63197 (A-MSE: 0.56554) avg lploss: 0.00000
train epoch 208 avg loss: 0.61189 (A-MSE: 0.55012) avg lploss: 0.00000
train epoch 209 avg loss: 0.65350 (A-MSE: 0.58607) avg lploss: 0.00000
train epoch 210 avg loss: 0.76389 (A-MSE: 0.68400) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.88521 (A-MSE: 0.79152) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.95385 (A-MSE: 0.86353) avg lploss: 0.00000
*** Best Val Loss: 0.85811 	 Best Test Loss: 0.99387 	 Best epoch 205
EarlyStopping counter: 1 out of 50
train epoch 211 avg loss: 0.65878 (A-MSE: 0.59130) avg lploss: 0.00000
train epoch 212 avg loss: 0.70735 (A-MSE: 0.64195) avg lploss: 0.00000
train epoch 213 avg loss: 0.66156 (A-MSE: 0.59246) avg lploss: 0.00000
train epoch 214 avg loss: 0.63250 (A-MSE: 0.56830) avg lploss: 0.00000
train epoch 215 avg loss: 0.64388 (A-MSE: 0.57911) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.87565 (A-MSE: 0.77871) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.93141 (A-MSE: 0.84191) avg lploss: 0.00000
*** Best Val Loss: 0.85811 	 Best Test Loss: 0.99387 	 Best epoch 205
EarlyStopping counter: 2 out of 50
train epoch 216 avg loss: 0.74649 (A-MSE: 0.66855) avg lploss: 0.00000
train epoch 217 avg loss: 0.79253 (A-MSE: 0.71213) avg lploss: 0.00000
train epoch 218 avg loss: 0.67587 (A-MSE: 0.60803) avg lploss: 0.00000
train epoch 219 avg loss: 0.61966 (A-MSE: 0.55614) avg lploss: 0.00000
train epoch 220 avg loss: 0.68759 (A-MSE: 0.61989) avg lploss: 0.00000
==> val epoch 220 avg loss: 1.02271 (A-MSE: 0.95181) avg lploss: 0.00000
==> test epoch 220 avg loss: 1.16406 (A-MSE: 1.09447) avg lploss: 0.00000
*** Best Val Loss: 0.85811 	 Best Test Loss: 0.99387 	 Best epoch 205
EarlyStopping counter: 3 out of 50
train epoch 221 avg loss: 0.74083 (A-MSE: 0.66754) avg lploss: 0.00000
train epoch 222 avg loss: 0.66976 (A-MSE: 0.60406) avg lploss: 0.00000
train epoch 223 avg loss: 0.64682 (A-MSE: 0.58408) avg lploss: 0.00000
train epoch 224 avg loss: 0.62905 (A-MSE: 0.56167) avg lploss: 0.00000
train epoch 225 avg loss: 0.65208 (A-MSE: 0.58895) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.85324 (A-MSE: 0.77914) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.97618 (A-MSE: 0.89831) avg lploss: 0.00000
*** Best Val Loss: 0.85324 	 Best Test Loss: 0.97618 	 Best epoch 225
Validation loss decreased (0.858108 --> 0.853243).  Saving model ...
train epoch 226 avg loss: 0.68966 (A-MSE: 0.62460) avg lploss: 0.00000
train epoch 227 avg loss: 0.64574 (A-MSE: 0.57890) avg lploss: 0.00000
train epoch 228 avg loss: 0.60526 (A-MSE: 0.54598) avg lploss: 0.00000
train epoch 229 avg loss: 0.73138 (A-MSE: 0.65734) avg lploss: 0.00000
train epoch 230 avg loss: 0.64595 (A-MSE: 0.57963) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.88966 (A-MSE: 0.80488) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.94459 (A-MSE: 0.85813) avg lploss: 0.00000
*** Best Val Loss: 0.85324 	 Best Test Loss: 0.97618 	 Best epoch 225
EarlyStopping counter: 1 out of 50
train epoch 231 avg loss: 0.61208 (A-MSE: 0.55095) avg lploss: 0.00000
train epoch 232 avg loss: 0.60066 (A-MSE: 0.53960) avg lploss: 0.00000
train epoch 233 avg loss: 0.65614 (A-MSE: 0.59347) avg lploss: 0.00000
train epoch 234 avg loss: 0.66140 (A-MSE: 0.59391) avg lploss: 0.00000
train epoch 235 avg loss: 0.62119 (A-MSE: 0.55739) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.81260 (A-MSE: 0.71423) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.84922 (A-MSE: 0.75652) avg lploss: 0.00000
*** Best Val Loss: 0.81260 	 Best Test Loss: 0.84922 	 Best epoch 235
Validation loss decreased (0.853243 --> 0.812598).  Saving model ...
train epoch 236 avg loss: 0.58000 (A-MSE: 0.52144) avg lploss: 0.00000
train epoch 237 avg loss: 0.58911 (A-MSE: 0.53053) avg lploss: 0.00000
train epoch 238 avg loss: 0.69245 (A-MSE: 0.62144) avg lploss: 0.00000
train epoch 239 avg loss: 0.60138 (A-MSE: 0.54156) avg lploss: 0.00000
train epoch 240 avg loss: 0.59915 (A-MSE: 0.53901) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.92196 (A-MSE: 0.81772) avg lploss: 0.00000
==> test epoch 240 avg loss: 1.03833 (A-MSE: 0.93623) avg lploss: 0.00000
*** Best Val Loss: 0.81260 	 Best Test Loss: 0.84922 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.63923 (A-MSE: 0.57281) avg lploss: 0.00000
train epoch 242 avg loss: 0.55630 (A-MSE: 0.50234) avg lploss: 0.00000
train epoch 243 avg loss: 0.55106 (A-MSE: 0.49427) avg lploss: 0.00000
train epoch 244 avg loss: 0.54629 (A-MSE: 0.49142) avg lploss: 0.00000
train epoch 245 avg loss: 0.56060 (A-MSE: 0.50383) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.92253 (A-MSE: 0.81851) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.96284 (A-MSE: 0.86404) avg lploss: 0.00000
*** Best Val Loss: 0.81260 	 Best Test Loss: 0.84922 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.59033 (A-MSE: 0.52856) avg lploss: 0.00000
train epoch 247 avg loss: 0.63961 (A-MSE: 0.58063) avg lploss: 0.00000
train epoch 248 avg loss: 0.58379 (A-MSE: 0.52649) avg lploss: 0.00000
train epoch 249 avg loss: 0.56326 (A-MSE: 0.50597) avg lploss: 0.00000
train epoch 250 avg loss: 0.54609 (A-MSE: 0.49035) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.79868 (A-MSE: 0.69896) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.83499 (A-MSE: 0.74513) avg lploss: 0.00000
*** Best Val Loss: 0.79868 	 Best Test Loss: 0.83499 	 Best epoch 250
Validation loss decreased (0.812598 --> 0.798684).  Saving model ...
train epoch 251 avg loss: 0.54256 (A-MSE: 0.48851) avg lploss: 0.00000
train epoch 252 avg loss: 0.58603 (A-MSE: 0.53096) avg lploss: 0.00000
train epoch 253 avg loss: 0.56783 (A-MSE: 0.50987) avg lploss: 0.00000
train epoch 254 avg loss: 0.53088 (A-MSE: 0.47761) avg lploss: 0.00000
train epoch 255 avg loss: 0.53049 (A-MSE: 0.47727) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.70344 (A-MSE: 0.63100) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.79702 (A-MSE: 0.72824) avg lploss: 0.00000
*** Best Val Loss: 0.70344 	 Best Test Loss: 0.79702 	 Best epoch 255
Validation loss decreased (0.798684 --> 0.703442).  Saving model ...
train epoch 256 avg loss: 0.54914 (A-MSE: 0.49406) avg lploss: 0.00000
train epoch 257 avg loss: 0.47976 (A-MSE: 0.42985) avg lploss: 0.00000
train epoch 258 avg loss: 0.48985 (A-MSE: 0.43935) avg lploss: 0.00000
train epoch 259 avg loss: 0.51751 (A-MSE: 0.46609) avg lploss: 0.00000
train epoch 260 avg loss: 0.56595 (A-MSE: 0.51019) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.82656 (A-MSE: 0.71525) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.86697 (A-MSE: 0.75452) avg lploss: 0.00000
*** Best Val Loss: 0.70344 	 Best Test Loss: 0.79702 	 Best epoch 255
EarlyStopping counter: 1 out of 50
train epoch 261 avg loss: 0.55901 (A-MSE: 0.50775) avg lploss: 0.00000
train epoch 262 avg loss: 0.55649 (A-MSE: 0.50032) avg lploss: 0.00000
train epoch 263 avg loss: 0.58388 (A-MSE: 0.52241) avg lploss: 0.00000
train epoch 264 avg loss: 0.56080 (A-MSE: 0.50633) avg lploss: 0.00000
train epoch 265 avg loss: 0.58196 (A-MSE: 0.52422) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.86482 (A-MSE: 0.77285) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.89849 (A-MSE: 0.80654) avg lploss: 0.00000
*** Best Val Loss: 0.70344 	 Best Test Loss: 0.79702 	 Best epoch 255
EarlyStopping counter: 2 out of 50
train epoch 266 avg loss: 0.54428 (A-MSE: 0.49067) avg lploss: 0.00000
train epoch 267 avg loss: 0.59997 (A-MSE: 0.54407) avg lploss: 0.00000
train epoch 268 avg loss: 0.61766 (A-MSE: 0.55656) avg lploss: 0.00000
train epoch 269 avg loss: 0.56663 (A-MSE: 0.51258) avg lploss: 0.00000
train epoch 270 avg loss: 0.57705 (A-MSE: 0.52006) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.71491 (A-MSE: 0.63681) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.80472 (A-MSE: 0.72844) avg lploss: 0.00000
*** Best Val Loss: 0.70344 	 Best Test Loss: 0.79702 	 Best epoch 255
EarlyStopping counter: 3 out of 50
train epoch 271 avg loss: 0.52066 (A-MSE: 0.47036) avg lploss: 0.00000
train epoch 272 avg loss: 0.46149 (A-MSE: 0.41641) avg lploss: 0.00000
train epoch 273 avg loss: 0.55589 (A-MSE: 0.50179) avg lploss: 0.00000
train epoch 274 avg loss: 0.52062 (A-MSE: 0.47230) avg lploss: 0.00000
train epoch 275 avg loss: 0.53673 (A-MSE: 0.48285) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.79754 (A-MSE: 0.69530) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.88658 (A-MSE: 0.78334) avg lploss: 0.00000
*** Best Val Loss: 0.70344 	 Best Test Loss: 0.79702 	 Best epoch 255
EarlyStopping counter: 4 out of 50
train epoch 276 avg loss: 0.65362 (A-MSE: 0.59058) avg lploss: 0.00000
train epoch 277 avg loss: 0.61990 (A-MSE: 0.56024) avg lploss: 0.00000
train epoch 278 avg loss: 0.49898 (A-MSE: 0.45036) avg lploss: 0.00000
train epoch 279 avg loss: 0.48794 (A-MSE: 0.43879) avg lploss: 0.00000
train epoch 280 avg loss: 0.48381 (A-MSE: 0.43633) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.66766 (A-MSE: 0.59189) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.77282 (A-MSE: 0.68949) avg lploss: 0.00000
*** Best Val Loss: 0.66766 	 Best Test Loss: 0.77282 	 Best epoch 280
Validation loss decreased (0.703442 --> 0.667662).  Saving model ...
train epoch 281 avg loss: 0.44628 (A-MSE: 0.40329) avg lploss: 0.00000
train epoch 282 avg loss: 0.55926 (A-MSE: 0.50441) avg lploss: 0.00000
train epoch 283 avg loss: 0.63000 (A-MSE: 0.56737) avg lploss: 0.00000
train epoch 284 avg loss: 0.52269 (A-MSE: 0.47136) avg lploss: 0.00000
train epoch 285 avg loss: 0.51874 (A-MSE: 0.46253) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.67657 (A-MSE: 0.59027) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.76055 (A-MSE: 0.66484) avg lploss: 0.00000
*** Best Val Loss: 0.66766 	 Best Test Loss: 0.77282 	 Best epoch 280
EarlyStopping counter: 1 out of 50
train epoch 286 avg loss: 0.49227 (A-MSE: 0.44277) avg lploss: 0.00000
train epoch 287 avg loss: 0.49558 (A-MSE: 0.44828) avg lploss: 0.00000
train epoch 288 avg loss: 0.52397 (A-MSE: 0.47299) avg lploss: 0.00000
train epoch 289 avg loss: 0.51560 (A-MSE: 0.46784) avg lploss: 0.00000
train epoch 290 avg loss: 0.54708 (A-MSE: 0.49012) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.83240 (A-MSE: 0.73569) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.85403 (A-MSE: 0.76106) avg lploss: 0.00000
*** Best Val Loss: 0.66766 	 Best Test Loss: 0.77282 	 Best epoch 280
EarlyStopping counter: 2 out of 50
train epoch 291 avg loss: 0.50654 (A-MSE: 0.45506) avg lploss: 0.00000
train epoch 292 avg loss: 0.47345 (A-MSE: 0.42724) avg lploss: 0.00000
train epoch 293 avg loss: 0.43268 (A-MSE: 0.38992) avg lploss: 0.00000
train epoch 294 avg loss: 0.50597 (A-MSE: 0.45351) avg lploss: 0.00000
train epoch 295 avg loss: 0.52124 (A-MSE: 0.47435) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.77385 (A-MSE: 0.68962) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.85056 (A-MSE: 0.76009) avg lploss: 0.00000
*** Best Val Loss: 0.66766 	 Best Test Loss: 0.77282 	 Best epoch 280
EarlyStopping counter: 3 out of 50
train epoch 296 avg loss: 0.46102 (A-MSE: 0.41399) avg lploss: 0.00000
train epoch 297 avg loss: 0.48922 (A-MSE: 0.44166) avg lploss: 0.00000
train epoch 298 avg loss: 0.43668 (A-MSE: 0.39580) avg lploss: 0.00000
train epoch 299 avg loss: 0.48785 (A-MSE: 0.44157) avg lploss: 0.00000
train epoch 300 avg loss: 0.42060 (A-MSE: 0.38128) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.58799 (A-MSE: 0.52361) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.67864 (A-MSE: 0.60269) avg lploss: 0.00000
*** Best Val Loss: 0.58799 	 Best Test Loss: 0.67864 	 Best epoch 300
Validation loss decreased (0.667662 --> 0.587988).  Saving model ...
train epoch 301 avg loss: 0.43704 (A-MSE: 0.39154) avg lploss: 0.00000
train epoch 302 avg loss: 0.52463 (A-MSE: 0.47443) avg lploss: 0.00000
train epoch 303 avg loss: 0.46938 (A-MSE: 0.42244) avg lploss: 0.00000
train epoch 304 avg loss: 0.43701 (A-MSE: 0.39402) avg lploss: 0.00000
train epoch 305 avg loss: 0.42693 (A-MSE: 0.38479) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.74091 (A-MSE: 0.64813) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.81678 (A-MSE: 0.71350) avg lploss: 0.00000
*** Best Val Loss: 0.58799 	 Best Test Loss: 0.67864 	 Best epoch 300
EarlyStopping counter: 1 out of 50
train epoch 306 avg loss: 0.44208 (A-MSE: 0.39965) avg lploss: 0.00000
train epoch 307 avg loss: 0.49678 (A-MSE: 0.44743) avg lploss: 0.00000
train epoch 308 avg loss: 0.48402 (A-MSE: 0.43476) avg lploss: 0.00000
train epoch 309 avg loss: 0.42662 (A-MSE: 0.38669) avg lploss: 0.00000
train epoch 310 avg loss: 0.45514 (A-MSE: 0.41070) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.70323 (A-MSE: 0.62718) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.81596 (A-MSE: 0.72889) avg lploss: 0.00000
*** Best Val Loss: 0.58799 	 Best Test Loss: 0.67864 	 Best epoch 300
EarlyStopping counter: 2 out of 50
train epoch 311 avg loss: 0.40900 (A-MSE: 0.36883) avg lploss: 0.00000
train epoch 312 avg loss: 0.38426 (A-MSE: 0.34828) avg lploss: 0.00000
train epoch 313 avg loss: 0.38684 (A-MSE: 0.34832) avg lploss: 0.00000
train epoch 314 avg loss: 0.42812 (A-MSE: 0.38660) avg lploss: 0.00000
train epoch 315 avg loss: 0.43563 (A-MSE: 0.39421) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.62482 (A-MSE: 0.55492) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.66489 (A-MSE: 0.59339) avg lploss: 0.00000
*** Best Val Loss: 0.58799 	 Best Test Loss: 0.67864 	 Best epoch 300
EarlyStopping counter: 3 out of 50
train epoch 316 avg loss: 0.39491 (A-MSE: 0.35891) avg lploss: 0.00000
train epoch 317 avg loss: 0.42045 (A-MSE: 0.38005) avg lploss: 0.00000
train epoch 318 avg loss: 0.41296 (A-MSE: 0.37362) avg lploss: 0.00000
train epoch 319 avg loss: 0.40405 (A-MSE: 0.36509) avg lploss: 0.00000
train epoch 320 avg loss: 0.44425 (A-MSE: 0.40249) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.58585 (A-MSE: 0.52366) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.70255 (A-MSE: 0.63031) avg lploss: 0.00000
*** Best Val Loss: 0.58585 	 Best Test Loss: 0.70255 	 Best epoch 320
Validation loss decreased (0.587988 --> 0.585848).  Saving model ...
train epoch 321 avg loss: 0.42156 (A-MSE: 0.37933) avg lploss: 0.00000
train epoch 322 avg loss: 0.43910 (A-MSE: 0.39493) avg lploss: 0.00000
train epoch 323 avg loss: 0.42582 (A-MSE: 0.38614) avg lploss: 0.00000
train epoch 324 avg loss: 0.41418 (A-MSE: 0.37264) avg lploss: 0.00000
train epoch 325 avg loss: 0.43193 (A-MSE: 0.38744) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.54490 (A-MSE: 0.48822) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.63125 (A-MSE: 0.57117) avg lploss: 0.00000
*** Best Val Loss: 0.54490 	 Best Test Loss: 0.63125 	 Best epoch 325
Validation loss decreased (0.585848 --> 0.544904).  Saving model ...
train epoch 326 avg loss: 0.35588 (A-MSE: 0.32236) avg lploss: 0.00000
train epoch 327 avg loss: 0.38775 (A-MSE: 0.35144) avg lploss: 0.00000
train epoch 328 avg loss: 0.41571 (A-MSE: 0.37408) avg lploss: 0.00000
train epoch 329 avg loss: 0.38318 (A-MSE: 0.34503) avg lploss: 0.00000
train epoch 330 avg loss: 0.38217 (A-MSE: 0.34407) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.55064 (A-MSE: 0.49175) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.64748 (A-MSE: 0.57787) avg lploss: 0.00000
*** Best Val Loss: 0.54490 	 Best Test Loss: 0.63125 	 Best epoch 325
EarlyStopping counter: 1 out of 50
train epoch 331 avg loss: 0.34731 (A-MSE: 0.31365) avg lploss: 0.00000
train epoch 332 avg loss: 0.35766 (A-MSE: 0.32285) avg lploss: 0.00000
train epoch 333 avg loss: 0.40525 (A-MSE: 0.36433) avg lploss: 0.00000
train epoch 334 avg loss: 0.37109 (A-MSE: 0.33665) avg lploss: 0.00000
train epoch 335 avg loss: 0.37830 (A-MSE: 0.33972) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.55005 (A-MSE: 0.48710) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.63879 (A-MSE: 0.56561) avg lploss: 0.00000
*** Best Val Loss: 0.54490 	 Best Test Loss: 0.63125 	 Best epoch 325
EarlyStopping counter: 2 out of 50
train epoch 336 avg loss: 0.38042 (A-MSE: 0.34525) avg lploss: 0.00000
train epoch 337 avg loss: 0.38160 (A-MSE: 0.34635) avg lploss: 0.00000
train epoch 338 avg loss: 0.38009 (A-MSE: 0.34405) avg lploss: 0.00000
train epoch 339 avg loss: 0.40198 (A-MSE: 0.36415) avg lploss: 0.00000
train epoch 340 avg loss: 0.38583 (A-MSE: 0.34761) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.79994 (A-MSE: 0.71344) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.90262 (A-MSE: 0.80693) avg lploss: 0.00000
*** Best Val Loss: 0.54490 	 Best Test Loss: 0.63125 	 Best epoch 325
EarlyStopping counter: 3 out of 50
train epoch 341 avg loss: 0.43016 (A-MSE: 0.39252) avg lploss: 0.00000
train epoch 342 avg loss: 0.35886 (A-MSE: 0.32342) avg lploss: 0.00000
train epoch 343 avg loss: 0.36839 (A-MSE: 0.33317) avg lploss: 0.00000
train epoch 344 avg loss: 0.37405 (A-MSE: 0.33742) avg lploss: 0.00000
train epoch 345 avg loss: 0.35249 (A-MSE: 0.31821) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.62992 (A-MSE: 0.54955) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.69938 (A-MSE: 0.61674) avg lploss: 0.00000
*** Best Val Loss: 0.54490 	 Best Test Loss: 0.63125 	 Best epoch 325
EarlyStopping counter: 4 out of 50
train epoch 346 avg loss: 0.32866 (A-MSE: 0.29635) avg lploss: 0.00000
train epoch 347 avg loss: 0.32493 (A-MSE: 0.29091) avg lploss: 0.00000
train epoch 348 avg loss: 0.36280 (A-MSE: 0.32702) avg lploss: 0.00000
train epoch 349 avg loss: 0.33463 (A-MSE: 0.30155) avg lploss: 0.00000
train epoch 350 avg loss: 0.37077 (A-MSE: 0.33370) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.52165 (A-MSE: 0.46303) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.60108 (A-MSE: 0.53647) avg lploss: 0.00000
*** Best Val Loss: 0.52165 	 Best Test Loss: 0.60108 	 Best epoch 350
Validation loss decreased (0.544904 --> 0.521650).  Saving model ...
train epoch 351 avg loss: 0.35047 (A-MSE: 0.31609) avg lploss: 0.00000
train epoch 352 avg loss: 0.37118 (A-MSE: 0.33433) avg lploss: 0.00000
train epoch 353 avg loss: 0.35626 (A-MSE: 0.32127) avg lploss: 0.00000
train epoch 354 avg loss: 0.37869 (A-MSE: 0.34301) avg lploss: 0.00000
train epoch 355 avg loss: 0.35983 (A-MSE: 0.32492) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.57793 (A-MSE: 0.51994) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.64564 (A-MSE: 0.58317) avg lploss: 0.00000
*** Best Val Loss: 0.52165 	 Best Test Loss: 0.60108 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.35546 (A-MSE: 0.32216) avg lploss: 0.00000
train epoch 357 avg loss: 0.37762 (A-MSE: 0.34049) avg lploss: 0.00000
train epoch 358 avg loss: 0.34879 (A-MSE: 0.31319) avg lploss: 0.00000
train epoch 359 avg loss: 0.36713 (A-MSE: 0.32915) avg lploss: 0.00000
train epoch 360 avg loss: 0.35866 (A-MSE: 0.32005) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.65745 (A-MSE: 0.57114) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.69922 (A-MSE: 0.61065) avg lploss: 0.00000
*** Best Val Loss: 0.52165 	 Best Test Loss: 0.60108 	 Best epoch 350
EarlyStopping counter: 2 out of 50
train epoch 361 avg loss: 0.35708 (A-MSE: 0.32469) avg lploss: 0.00000
train epoch 362 avg loss: 0.37682 (A-MSE: 0.34194) avg lploss: 0.00000
train epoch 363 avg loss: 0.36290 (A-MSE: 0.32679) avg lploss: 0.00000
train epoch 364 avg loss: 0.41801 (A-MSE: 0.37683) avg lploss: 0.00000
train epoch 365 avg loss: 0.40655 (A-MSE: 0.36379) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.61735 (A-MSE: 0.53893) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.65220 (A-MSE: 0.57476) avg lploss: 0.00000
*** Best Val Loss: 0.52165 	 Best Test Loss: 0.60108 	 Best epoch 350
EarlyStopping counter: 3 out of 50
train epoch 366 avg loss: 0.40573 (A-MSE: 0.36279) avg lploss: 0.00000
train epoch 367 avg loss: 0.34632 (A-MSE: 0.31118) avg lploss: 0.00000
train epoch 368 avg loss: 0.35646 (A-MSE: 0.32464) avg lploss: 0.00000
train epoch 369 avg loss: 0.36410 (A-MSE: 0.32723) avg lploss: 0.00000
train epoch 370 avg loss: 0.35014 (A-MSE: 0.31552) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.55560 (A-MSE: 0.48697) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.61905 (A-MSE: 0.54531) avg lploss: 0.00000
*** Best Val Loss: 0.52165 	 Best Test Loss: 0.60108 	 Best epoch 350
EarlyStopping counter: 4 out of 50
train epoch 371 avg loss: 0.34684 (A-MSE: 0.31345) avg lploss: 0.00000
train epoch 372 avg loss: 0.37585 (A-MSE: 0.33741) avg lploss: 0.00000
train epoch 373 avg loss: 0.37589 (A-MSE: 0.33750) avg lploss: 0.00000
train epoch 374 avg loss: 0.33766 (A-MSE: 0.30294) avg lploss: 0.00000
train epoch 375 avg loss: 0.32371 (A-MSE: 0.29048) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.63136 (A-MSE: 0.56736) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.71261 (A-MSE: 0.63921) avg lploss: 0.00000
*** Best Val Loss: 0.52165 	 Best Test Loss: 0.60108 	 Best epoch 350
EarlyStopping counter: 5 out of 50
train epoch 376 avg loss: 0.35771 (A-MSE: 0.32428) avg lploss: 0.00000
train epoch 377 avg loss: 0.35830 (A-MSE: 0.32624) avg lploss: 0.00000
train epoch 378 avg loss: 0.40876 (A-MSE: 0.36999) avg lploss: 0.00000
train epoch 379 avg loss: 0.40580 (A-MSE: 0.36843) avg lploss: 0.00000
train epoch 380 avg loss: 0.39883 (A-MSE: 0.35663) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.49384 (A-MSE: 0.43884) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.56929 (A-MSE: 0.51058) avg lploss: 0.00000
*** Best Val Loss: 0.49384 	 Best Test Loss: 0.56929 	 Best epoch 380
Validation loss decreased (0.521650 --> 0.493841).  Saving model ...
train epoch 381 avg loss: 0.32203 (A-MSE: 0.29142) avg lploss: 0.00000
train epoch 382 avg loss: 0.32850 (A-MSE: 0.29540) avg lploss: 0.00000
train epoch 383 avg loss: 0.36145 (A-MSE: 0.32657) avg lploss: 0.00000
train epoch 384 avg loss: 0.33424 (A-MSE: 0.29972) avg lploss: 0.00000
train epoch 385 avg loss: 0.35191 (A-MSE: 0.31574) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.53152 (A-MSE: 0.47940) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.64949 (A-MSE: 0.59106) avg lploss: 0.00000
*** Best Val Loss: 0.49384 	 Best Test Loss: 0.56929 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.38386 (A-MSE: 0.34423) avg lploss: 0.00000
train epoch 387 avg loss: 0.43823 (A-MSE: 0.39286) avg lploss: 0.00000
train epoch 388 avg loss: 0.41687 (A-MSE: 0.37618) avg lploss: 0.00000
train epoch 389 avg loss: 0.38968 (A-MSE: 0.34786) avg lploss: 0.00000
train epoch 390 avg loss: 0.34675 (A-MSE: 0.31159) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.48791 (A-MSE: 0.42792) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.57611 (A-MSE: 0.51006) avg lploss: 0.00000
*** Best Val Loss: 0.48791 	 Best Test Loss: 0.57611 	 Best epoch 390
Validation loss decreased (0.493841 --> 0.487905).  Saving model ...
train epoch 391 avg loss: 0.31563 (A-MSE: 0.28591) avg lploss: 0.00000
train epoch 392 avg loss: 0.28197 (A-MSE: 0.25363) avg lploss: 0.00000
train epoch 393 avg loss: 0.30447 (A-MSE: 0.27569) avg lploss: 0.00000
train epoch 394 avg loss: 0.28612 (A-MSE: 0.25618) avg lploss: 0.00000
train epoch 395 avg loss: 0.28730 (A-MSE: 0.25843) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.47342 (A-MSE: 0.41981) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.56750 (A-MSE: 0.50380) avg lploss: 0.00000
*** Best Val Loss: 0.47342 	 Best Test Loss: 0.56750 	 Best epoch 395
Validation loss decreased (0.487905 --> 0.473417).  Saving model ...
train epoch 396 avg loss: 0.31687 (A-MSE: 0.28436) avg lploss: 0.00000
train epoch 397 avg loss: 0.31485 (A-MSE: 0.28339) avg lploss: 0.00000
train epoch 398 avg loss: 0.37264 (A-MSE: 0.33514) avg lploss: 0.00000
train epoch 399 avg loss: 0.35771 (A-MSE: 0.32036) avg lploss: 0.00000
train epoch 400 avg loss: 0.31052 (A-MSE: 0.27870) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.43085 (A-MSE: 0.38414) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.50804 (A-MSE: 0.45620) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
Validation loss decreased (0.473417 --> 0.430848).  Saving model ...
train epoch 401 avg loss: 0.33583 (A-MSE: 0.30190) avg lploss: 0.00000
train epoch 402 avg loss: 0.34497 (A-MSE: 0.31075) avg lploss: 0.00000
train epoch 403 avg loss: 0.35916 (A-MSE: 0.32205) avg lploss: 0.00000
train epoch 404 avg loss: 0.29837 (A-MSE: 0.26868) avg lploss: 0.00000
train epoch 405 avg loss: 0.40421 (A-MSE: 0.35953) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.66125 (A-MSE: 0.57989) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.76167 (A-MSE: 0.67101) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 1 out of 50
train epoch 406 avg loss: 0.36962 (A-MSE: 0.33363) avg lploss: 0.00000
train epoch 407 avg loss: 0.31911 (A-MSE: 0.28681) avg lploss: 0.00000
train epoch 408 avg loss: 0.30556 (A-MSE: 0.27513) avg lploss: 0.00000
train epoch 409 avg loss: 0.29358 (A-MSE: 0.26399) avg lploss: 0.00000
train epoch 410 avg loss: 0.27766 (A-MSE: 0.25026) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.51568 (A-MSE: 0.45421) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.58181 (A-MSE: 0.51288) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 2 out of 50
train epoch 411 avg loss: 0.27057 (A-MSE: 0.24394) avg lploss: 0.00000
train epoch 412 avg loss: 0.34666 (A-MSE: 0.31531) avg lploss: 0.00000
train epoch 413 avg loss: 0.31725 (A-MSE: 0.28599) avg lploss: 0.00000
train epoch 414 avg loss: 0.35210 (A-MSE: 0.31628) avg lploss: 0.00000
train epoch 415 avg loss: 0.29166 (A-MSE: 0.26219) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.45715 (A-MSE: 0.40605) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.55254 (A-MSE: 0.48988) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 3 out of 50
train epoch 416 avg loss: 0.27617 (A-MSE: 0.24705) avg lploss: 0.00000
train epoch 417 avg loss: 0.28579 (A-MSE: 0.25481) avg lploss: 0.00000
train epoch 418 avg loss: 0.28390 (A-MSE: 0.25467) avg lploss: 0.00000
train epoch 419 avg loss: 0.34030 (A-MSE: 0.30747) avg lploss: 0.00000
train epoch 420 avg loss: 0.35125 (A-MSE: 0.31634) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.48685 (A-MSE: 0.43024) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.54254 (A-MSE: 0.48314) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 4 out of 50
train epoch 421 avg loss: 0.33375 (A-MSE: 0.29894) avg lploss: 0.00000
train epoch 422 avg loss: 0.37126 (A-MSE: 0.33527) avg lploss: 0.00000
train epoch 423 avg loss: 0.34620 (A-MSE: 0.31253) avg lploss: 0.00000
train epoch 424 avg loss: 0.32997 (A-MSE: 0.29643) avg lploss: 0.00000
train epoch 425 avg loss: 0.34781 (A-MSE: 0.31568) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.69845 (A-MSE: 0.61875) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.74152 (A-MSE: 0.65700) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 5 out of 50
train epoch 426 avg loss: 0.32091 (A-MSE: 0.28992) avg lploss: 0.00000
train epoch 427 avg loss: 0.30975 (A-MSE: 0.27830) avg lploss: 0.00000
train epoch 428 avg loss: 0.30120 (A-MSE: 0.27189) avg lploss: 0.00000
train epoch 429 avg loss: 0.29297 (A-MSE: 0.26271) avg lploss: 0.00000
train epoch 430 avg loss: 0.30803 (A-MSE: 0.27587) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.67977 (A-MSE: 0.60023) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.74618 (A-MSE: 0.65301) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 6 out of 50
train epoch 431 avg loss: 0.33942 (A-MSE: 0.30473) avg lploss: 0.00000
train epoch 432 avg loss: 0.28262 (A-MSE: 0.25380) avg lploss: 0.00000
train epoch 433 avg loss: 0.25774 (A-MSE: 0.23197) avg lploss: 0.00000
train epoch 434 avg loss: 0.26853 (A-MSE: 0.24231) avg lploss: 0.00000
train epoch 435 avg loss: 0.26440 (A-MSE: 0.23749) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.52409 (A-MSE: 0.45788) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.58922 (A-MSE: 0.51427) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 7 out of 50
train epoch 436 avg loss: 0.27992 (A-MSE: 0.25134) avg lploss: 0.00000
train epoch 437 avg loss: 0.26779 (A-MSE: 0.24066) avg lploss: 0.00000
train epoch 438 avg loss: 0.27955 (A-MSE: 0.25237) avg lploss: 0.00000
train epoch 439 avg loss: 0.28064 (A-MSE: 0.25102) avg lploss: 0.00000
train epoch 440 avg loss: 0.27771 (A-MSE: 0.24775) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.50682 (A-MSE: 0.45320) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.60730 (A-MSE: 0.54051) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 8 out of 50
train epoch 441 avg loss: 0.28097 (A-MSE: 0.25412) avg lploss: 0.00000
train epoch 442 avg loss: 0.26935 (A-MSE: 0.24157) avg lploss: 0.00000
train epoch 443 avg loss: 0.27482 (A-MSE: 0.24580) avg lploss: 0.00000
train epoch 444 avg loss: 0.30273 (A-MSE: 0.27485) avg lploss: 0.00000
train epoch 445 avg loss: 0.30348 (A-MSE: 0.27426) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.48929 (A-MSE: 0.43961) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.56649 (A-MSE: 0.50618) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 9 out of 50
train epoch 446 avg loss: 0.27298 (A-MSE: 0.24411) avg lploss: 0.00000
train epoch 447 avg loss: 0.29033 (A-MSE: 0.25903) avg lploss: 0.00000
train epoch 448 avg loss: 0.30775 (A-MSE: 0.27470) avg lploss: 0.00000
train epoch 449 avg loss: 0.30837 (A-MSE: 0.27792) avg lploss: 0.00000
train epoch 450 avg loss: 0.28390 (A-MSE: 0.25581) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.47640 (A-MSE: 0.41847) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.57664 (A-MSE: 0.50396) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 10 out of 50
train epoch 451 avg loss: 0.30404 (A-MSE: 0.27184) avg lploss: 0.00000
train epoch 452 avg loss: 0.27510 (A-MSE: 0.24831) avg lploss: 0.00000
train epoch 453 avg loss: 0.27788 (A-MSE: 0.24957) avg lploss: 0.00000
train epoch 454 avg loss: 0.25330 (A-MSE: 0.22624) avg lploss: 0.00000
train epoch 455 avg loss: 0.28920 (A-MSE: 0.26126) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.47835 (A-MSE: 0.41915) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.56206 (A-MSE: 0.49707) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 11 out of 50
train epoch 456 avg loss: 0.26661 (A-MSE: 0.24080) avg lploss: 0.00000
train epoch 457 avg loss: 0.31757 (A-MSE: 0.28714) avg lploss: 0.00000
train epoch 458 avg loss: 0.26833 (A-MSE: 0.24134) avg lploss: 0.00000
train epoch 459 avg loss: 0.28390 (A-MSE: 0.25719) avg lploss: 0.00000
train epoch 460 avg loss: 0.28832 (A-MSE: 0.25930) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.46232 (A-MSE: 0.40580) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.55165 (A-MSE: 0.48628) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 12 out of 50
train epoch 461 avg loss: 0.25897 (A-MSE: 0.23468) avg lploss: 0.00000
train epoch 462 avg loss: 0.26729 (A-MSE: 0.23911) avg lploss: 0.00000
train epoch 463 avg loss: 0.24803 (A-MSE: 0.22249) avg lploss: 0.00000
train epoch 464 avg loss: 0.26075 (A-MSE: 0.23536) avg lploss: 0.00000
train epoch 465 avg loss: 0.26132 (A-MSE: 0.23316) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.59116 (A-MSE: 0.51563) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.62917 (A-MSE: 0.55040) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 13 out of 50
train epoch 466 avg loss: 0.27298 (A-MSE: 0.24492) avg lploss: 0.00000
train epoch 467 avg loss: 0.31326 (A-MSE: 0.28230) avg lploss: 0.00000
train epoch 468 avg loss: 0.30242 (A-MSE: 0.27343) avg lploss: 0.00000
train epoch 469 avg loss: 0.25265 (A-MSE: 0.22678) avg lploss: 0.00000
train epoch 470 avg loss: 0.23355 (A-MSE: 0.20933) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.45352 (A-MSE: 0.40063) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.54974 (A-MSE: 0.48432) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 14 out of 50
train epoch 471 avg loss: 0.26200 (A-MSE: 0.23485) avg lploss: 0.00000
train epoch 472 avg loss: 0.31238 (A-MSE: 0.28050) avg lploss: 0.00000
train epoch 473 avg loss: 0.29955 (A-MSE: 0.26944) avg lploss: 0.00000
train epoch 474 avg loss: 0.33745 (A-MSE: 0.30214) avg lploss: 0.00000
train epoch 475 avg loss: 0.29830 (A-MSE: 0.26912) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.54965 (A-MSE: 0.49057) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.64431 (A-MSE: 0.57553) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 15 out of 50
train epoch 476 avg loss: 0.32151 (A-MSE: 0.28924) avg lploss: 0.00000
train epoch 477 avg loss: 0.27171 (A-MSE: 0.24306) avg lploss: 0.00000
train epoch 478 avg loss: 0.26950 (A-MSE: 0.24461) avg lploss: 0.00000
train epoch 479 avg loss: 0.25918 (A-MSE: 0.23210) avg lploss: 0.00000
train epoch 480 avg loss: 0.26171 (A-MSE: 0.23575) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.51067 (A-MSE: 0.45482) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.56875 (A-MSE: 0.50513) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 16 out of 50
train epoch 481 avg loss: 0.24584 (A-MSE: 0.22060) avg lploss: 0.00000
train epoch 482 avg loss: 0.22312 (A-MSE: 0.20091) avg lploss: 0.00000
train epoch 483 avg loss: 0.24330 (A-MSE: 0.21825) avg lploss: 0.00000
train epoch 484 avg loss: 0.21455 (A-MSE: 0.19385) avg lploss: 0.00000
train epoch 485 avg loss: 0.21747 (A-MSE: 0.19411) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.57559 (A-MSE: 0.52144) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.64034 (A-MSE: 0.57831) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 17 out of 50
train epoch 486 avg loss: 0.29310 (A-MSE: 0.26509) avg lploss: 0.00000
train epoch 487 avg loss: 0.32413 (A-MSE: 0.29151) avg lploss: 0.00000
train epoch 488 avg loss: 0.30316 (A-MSE: 0.27133) avg lploss: 0.00000
train epoch 489 avg loss: 0.30561 (A-MSE: 0.27524) avg lploss: 0.00000
train epoch 490 avg loss: 0.35053 (A-MSE: 0.31769) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.46610 (A-MSE: 0.42122) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.55099 (A-MSE: 0.48960) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 18 out of 50
train epoch 491 avg loss: 0.30291 (A-MSE: 0.27177) avg lploss: 0.00000
train epoch 492 avg loss: 0.31928 (A-MSE: 0.28717) avg lploss: 0.00000
train epoch 493 avg loss: 0.29080 (A-MSE: 0.26122) avg lploss: 0.00000
train epoch 494 avg loss: 0.24834 (A-MSE: 0.22276) avg lploss: 0.00000
train epoch 495 avg loss: 0.26102 (A-MSE: 0.23575) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.53981 (A-MSE: 0.48301) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.62658 (A-MSE: 0.55938) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 19 out of 50
train epoch 496 avg loss: 0.25238 (A-MSE: 0.22627) avg lploss: 0.00000
train epoch 497 avg loss: 0.31306 (A-MSE: 0.27988) avg lploss: 0.00000
train epoch 498 avg loss: 0.24907 (A-MSE: 0.22443) avg lploss: 0.00000
train epoch 499 avg loss: 0.24048 (A-MSE: 0.21658) avg lploss: 0.00000
train epoch 500 avg loss: 0.23737 (A-MSE: 0.21397) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.49197 (A-MSE: 0.43271) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.51865 (A-MSE: 0.45887) avg lploss: 0.00000
*** Best Val Loss: 0.43085 	 Best Test Loss: 0.50804 	 Best epoch 400
EarlyStopping counter: 20 out of 50
train epoch 501 avg loss: 0.28160 (A-MSE: 0.25056) avg lploss: 0.00000
train epoch 502 avg loss: 0.23127 (A-MSE: 0.20810) avg lploss: 0.00000
train epoch 503 avg loss: 0.22752 (A-MSE: 0.20523) avg lploss: 0.00000
train epoch 504 avg loss: 0.24729 (A-MSE: 0.22230) avg lploss: 0.00000
train epoch 505 avg loss: 0.25197 (A-MSE: 0.22460) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.39447 (A-MSE: 0.35143) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.48092 (A-MSE: 0.42783) avg lploss: 0.00000
*** Best Val Loss: 0.39447 	 Best Test Loss: 0.48092 	 Best epoch 505
Validation loss decreased (0.430848 --> 0.394471).  Saving model ...
train epoch 506 avg loss: 0.23067 (A-MSE: 0.20769) avg lploss: 0.00000
train epoch 507 avg loss: 0.22844 (A-MSE: 0.20454) avg lploss: 0.00000
train epoch 508 avg loss: 0.20978 (A-MSE: 0.18855) avg lploss: 0.00000
train epoch 509 avg loss: 0.24014 (A-MSE: 0.21549) avg lploss: 0.00000
train epoch 510 avg loss: 0.22923 (A-MSE: 0.20587) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.36316 (A-MSE: 0.32648) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.46334 (A-MSE: 0.41091) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
Validation loss decreased (0.394471 --> 0.363160).  Saving model ...
train epoch 511 avg loss: 0.24427 (A-MSE: 0.21842) avg lploss: 0.00000
train epoch 512 avg loss: 0.23515 (A-MSE: 0.21373) avg lploss: 0.00000
train epoch 513 avg loss: 0.23914 (A-MSE: 0.21315) avg lploss: 0.00000
train epoch 514 avg loss: 0.24539 (A-MSE: 0.21976) avg lploss: 0.00000
train epoch 515 avg loss: 0.21249 (A-MSE: 0.19182) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.43469 (A-MSE: 0.38936) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.50622 (A-MSE: 0.45049) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 1 out of 50
train epoch 516 avg loss: 0.22112 (A-MSE: 0.19971) avg lploss: 0.00000
train epoch 517 avg loss: 0.22353 (A-MSE: 0.19917) avg lploss: 0.00000
train epoch 518 avg loss: 0.23296 (A-MSE: 0.20996) avg lploss: 0.00000
train epoch 519 avg loss: 0.24140 (A-MSE: 0.21593) avg lploss: 0.00000
train epoch 520 avg loss: 0.23334 (A-MSE: 0.21085) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.50492 (A-MSE: 0.45483) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.58579 (A-MSE: 0.52743) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 2 out of 50
train epoch 521 avg loss: 0.23421 (A-MSE: 0.21228) avg lploss: 0.00000
train epoch 522 avg loss: 0.24317 (A-MSE: 0.21637) avg lploss: 0.00000
train epoch 523 avg loss: 0.24944 (A-MSE: 0.22733) avg lploss: 0.00000
train epoch 524 avg loss: 0.22919 (A-MSE: 0.20495) avg lploss: 0.00000
train epoch 525 avg loss: 0.26531 (A-MSE: 0.23767) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.52767 (A-MSE: 0.47361) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.62175 (A-MSE: 0.55639) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 3 out of 50
train epoch 526 avg loss: 0.29885 (A-MSE: 0.27193) avg lploss: 0.00000
train epoch 527 avg loss: 0.27725 (A-MSE: 0.24964) avg lploss: 0.00000
train epoch 528 avg loss: 0.22857 (A-MSE: 0.20369) avg lploss: 0.00000
train epoch 529 avg loss: 0.27171 (A-MSE: 0.24543) avg lploss: 0.00000
train epoch 530 avg loss: 0.24545 (A-MSE: 0.22296) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.49518 (A-MSE: 0.44352) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.59426 (A-MSE: 0.53981) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 4 out of 50
train epoch 531 avg loss: 0.23954 (A-MSE: 0.21410) avg lploss: 0.00000
train epoch 532 avg loss: 0.20689 (A-MSE: 0.18436) avg lploss: 0.00000
train epoch 533 avg loss: 0.24467 (A-MSE: 0.21762) avg lploss: 0.00000
train epoch 534 avg loss: 0.25234 (A-MSE: 0.22650) avg lploss: 0.00000
train epoch 535 avg loss: 0.25607 (A-MSE: 0.22937) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.51248 (A-MSE: 0.45220) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.60410 (A-MSE: 0.53455) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 5 out of 50
train epoch 536 avg loss: 0.26070 (A-MSE: 0.23480) avg lploss: 0.00000
train epoch 537 avg loss: 0.23542 (A-MSE: 0.21018) avg lploss: 0.00000
train epoch 538 avg loss: 0.22232 (A-MSE: 0.20011) avg lploss: 0.00000
train epoch 539 avg loss: 0.21592 (A-MSE: 0.19435) avg lploss: 0.00000
train epoch 540 avg loss: 0.20704 (A-MSE: 0.18445) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.40365 (A-MSE: 0.36385) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.52737 (A-MSE: 0.47086) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 6 out of 50
train epoch 541 avg loss: 0.21642 (A-MSE: 0.19507) avg lploss: 0.00000
train epoch 542 avg loss: 0.23865 (A-MSE: 0.21377) avg lploss: 0.00000
train epoch 543 avg loss: 0.24305 (A-MSE: 0.21637) avg lploss: 0.00000
train epoch 544 avg loss: 0.22574 (A-MSE: 0.20207) avg lploss: 0.00000
train epoch 545 avg loss: 0.19334 (A-MSE: 0.17452) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.38597 (A-MSE: 0.34585) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.44774 (A-MSE: 0.39993) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 7 out of 50
train epoch 546 avg loss: 0.18886 (A-MSE: 0.16978) avg lploss: 0.00000
train epoch 547 avg loss: 0.25493 (A-MSE: 0.23151) avg lploss: 0.00000
train epoch 548 avg loss: 0.23375 (A-MSE: 0.20893) avg lploss: 0.00000
train epoch 549 avg loss: 0.19545 (A-MSE: 0.17470) avg lploss: 0.00000
train epoch 550 avg loss: 0.18921 (A-MSE: 0.16975) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.53279 (A-MSE: 0.47948) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.58071 (A-MSE: 0.52121) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 8 out of 50
train epoch 551 avg loss: 0.22212 (A-MSE: 0.19885) avg lploss: 0.00000
train epoch 552 avg loss: 0.23696 (A-MSE: 0.21364) avg lploss: 0.00000
train epoch 553 avg loss: 0.21580 (A-MSE: 0.19461) avg lploss: 0.00000
train epoch 554 avg loss: 0.21403 (A-MSE: 0.19128) avg lploss: 0.00000
train epoch 555 avg loss: 0.18721 (A-MSE: 0.16785) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.38546 (A-MSE: 0.33998) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.48782 (A-MSE: 0.43288) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 9 out of 50
train epoch 556 avg loss: 0.19886 (A-MSE: 0.17894) avg lploss: 0.00000
train epoch 557 avg loss: 0.22390 (A-MSE: 0.20083) avg lploss: 0.00000
train epoch 558 avg loss: 0.19967 (A-MSE: 0.17879) avg lploss: 0.00000
train epoch 559 avg loss: 0.21324 (A-MSE: 0.19062) avg lploss: 0.00000
train epoch 560 avg loss: 0.19107 (A-MSE: 0.17177) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.36793 (A-MSE: 0.33451) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.46051 (A-MSE: 0.41536) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 10 out of 50
train epoch 561 avg loss: 0.19524 (A-MSE: 0.17568) avg lploss: 0.00000
train epoch 562 avg loss: 0.20851 (A-MSE: 0.18626) avg lploss: 0.00000
train epoch 563 avg loss: 0.18999 (A-MSE: 0.17114) avg lploss: 0.00000
train epoch 564 avg loss: 0.24207 (A-MSE: 0.21721) avg lploss: 0.00000
train epoch 565 avg loss: 0.22652 (A-MSE: 0.20345) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.59740 (A-MSE: 0.52906) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.64197 (A-MSE: 0.56874) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 11 out of 50
train epoch 566 avg loss: 0.21393 (A-MSE: 0.19360) avg lploss: 0.00000
train epoch 567 avg loss: 0.23305 (A-MSE: 0.20661) avg lploss: 0.00000
train epoch 568 avg loss: 0.20964 (A-MSE: 0.18750) avg lploss: 0.00000
train epoch 569 avg loss: 0.20165 (A-MSE: 0.18092) avg lploss: 0.00000
train epoch 570 avg loss: 0.20473 (A-MSE: 0.18269) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.43541 (A-MSE: 0.38678) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.52536 (A-MSE: 0.46751) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 12 out of 50
train epoch 571 avg loss: 0.20829 (A-MSE: 0.18569) avg lploss: 0.00000
train epoch 572 avg loss: 0.20673 (A-MSE: 0.18676) avg lploss: 0.00000
train epoch 573 avg loss: 0.24491 (A-MSE: 0.21919) avg lploss: 0.00000
train epoch 574 avg loss: 0.23271 (A-MSE: 0.21079) avg lploss: 0.00000
train epoch 575 avg loss: 0.21370 (A-MSE: 0.19107) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.41409 (A-MSE: 0.36812) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.48336 (A-MSE: 0.42979) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 13 out of 50
train epoch 576 avg loss: 0.20367 (A-MSE: 0.18247) avg lploss: 0.00000
train epoch 577 avg loss: 0.18351 (A-MSE: 0.16696) avg lploss: 0.00000
train epoch 578 avg loss: 0.18888 (A-MSE: 0.16929) avg lploss: 0.00000
train epoch 579 avg loss: 0.22872 (A-MSE: 0.20356) avg lploss: 0.00000
train epoch 580 avg loss: 0.26004 (A-MSE: 0.23267) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.42922 (A-MSE: 0.37798) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.51895 (A-MSE: 0.46210) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 14 out of 50
train epoch 581 avg loss: 0.24573 (A-MSE: 0.22075) avg lploss: 0.00000
train epoch 582 avg loss: 0.22627 (A-MSE: 0.20341) avg lploss: 0.00000
train epoch 583 avg loss: 0.24553 (A-MSE: 0.21950) avg lploss: 0.00000
train epoch 584 avg loss: 0.28956 (A-MSE: 0.25871) avg lploss: 0.00000
train epoch 585 avg loss: 0.26756 (A-MSE: 0.23971) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.57245 (A-MSE: 0.52427) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.62265 (A-MSE: 0.56568) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 15 out of 50
train epoch 586 avg loss: 0.26410 (A-MSE: 0.23804) avg lploss: 0.00000
train epoch 587 avg loss: 0.23201 (A-MSE: 0.20863) avg lploss: 0.00000
train epoch 588 avg loss: 0.23019 (A-MSE: 0.20776) avg lploss: 0.00000
train epoch 589 avg loss: 0.20954 (A-MSE: 0.18783) avg lploss: 0.00000
train epoch 590 avg loss: 0.20497 (A-MSE: 0.18309) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.40594 (A-MSE: 0.36092) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.49643 (A-MSE: 0.44087) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 16 out of 50
train epoch 591 avg loss: 0.21090 (A-MSE: 0.18895) avg lploss: 0.00000
train epoch 592 avg loss: 0.21500 (A-MSE: 0.19251) avg lploss: 0.00000
train epoch 593 avg loss: 0.20364 (A-MSE: 0.18124) avg lploss: 0.00000
train epoch 594 avg loss: 0.24297 (A-MSE: 0.21805) avg lploss: 0.00000
train epoch 595 avg loss: 0.19764 (A-MSE: 0.17812) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.44949 (A-MSE: 0.40254) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.52981 (A-MSE: 0.46950) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 17 out of 50
train epoch 596 avg loss: 0.17652 (A-MSE: 0.15774) avg lploss: 0.00000
train epoch 597 avg loss: 0.17033 (A-MSE: 0.15233) avg lploss: 0.00000
train epoch 598 avg loss: 0.19612 (A-MSE: 0.17536) avg lploss: 0.00000
train epoch 599 avg loss: 0.18220 (A-MSE: 0.16414) avg lploss: 0.00000
train epoch 600 avg loss: 0.17154 (A-MSE: 0.15461) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.44116 (A-MSE: 0.39017) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.49431 (A-MSE: 0.43530) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 18 out of 50
train epoch 601 avg loss: 0.17532 (A-MSE: 0.15763) avg lploss: 0.00000
train epoch 602 avg loss: 0.17720 (A-MSE: 0.15874) avg lploss: 0.00000
train epoch 603 avg loss: 0.17049 (A-MSE: 0.15363) avg lploss: 0.00000
train epoch 604 avg loss: 0.19832 (A-MSE: 0.17731) avg lploss: 0.00000
train epoch 605 avg loss: 0.18434 (A-MSE: 0.16451) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.47996 (A-MSE: 0.43332) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.57317 (A-MSE: 0.51442) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 19 out of 50
train epoch 606 avg loss: 0.21505 (A-MSE: 0.19327) avg lploss: 0.00000
train epoch 607 avg loss: 0.18236 (A-MSE: 0.16310) avg lploss: 0.00000
train epoch 608 avg loss: 0.15465 (A-MSE: 0.14006) avg lploss: 0.00000
train epoch 609 avg loss: 0.19107 (A-MSE: 0.17171) avg lploss: 0.00000
train epoch 610 avg loss: 0.19701 (A-MSE: 0.17793) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.42690 (A-MSE: 0.38889) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.51265 (A-MSE: 0.46074) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 20 out of 50
train epoch 611 avg loss: 0.17921 (A-MSE: 0.16201) avg lploss: 0.00000
train epoch 612 avg loss: 0.17736 (A-MSE: 0.15902) avg lploss: 0.00000
train epoch 613 avg loss: 0.18047 (A-MSE: 0.16081) avg lploss: 0.00000
train epoch 614 avg loss: 0.16752 (A-MSE: 0.15063) avg lploss: 0.00000
train epoch 615 avg loss: 0.17236 (A-MSE: 0.15481) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.37558 (A-MSE: 0.33414) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.47168 (A-MSE: 0.41827) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 21 out of 50
train epoch 616 avg loss: 0.22512 (A-MSE: 0.20245) avg lploss: 0.00000
train epoch 617 avg loss: 0.22221 (A-MSE: 0.20193) avg lploss: 0.00000
train epoch 618 avg loss: 0.21597 (A-MSE: 0.19288) avg lploss: 0.00000
train epoch 619 avg loss: 0.18824 (A-MSE: 0.16859) avg lploss: 0.00000
train epoch 620 avg loss: 0.16242 (A-MSE: 0.14674) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.44682 (A-MSE: 0.40140) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.52679 (A-MSE: 0.47085) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 22 out of 50
train epoch 621 avg loss: 0.15439 (A-MSE: 0.13938) avg lploss: 0.00000
train epoch 622 avg loss: 0.18867 (A-MSE: 0.16918) avg lploss: 0.00000
train epoch 623 avg loss: 0.19366 (A-MSE: 0.17395) avg lploss: 0.00000
train epoch 624 avg loss: 0.17967 (A-MSE: 0.16019) avg lploss: 0.00000
train epoch 625 avg loss: 0.15542 (A-MSE: 0.13945) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.44752 (A-MSE: 0.39946) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.50747 (A-MSE: 0.44771) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 23 out of 50
train epoch 626 avg loss: 0.16087 (A-MSE: 0.14407) avg lploss: 0.00000
train epoch 627 avg loss: 0.16569 (A-MSE: 0.14851) avg lploss: 0.00000
train epoch 628 avg loss: 0.22110 (A-MSE: 0.19433) avg lploss: 0.00000
train epoch 629 avg loss: 0.23892 (A-MSE: 0.21433) avg lploss: 0.00000
train epoch 630 avg loss: 0.21586 (A-MSE: 0.19254) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.39981 (A-MSE: 0.35918) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.46725 (A-MSE: 0.41536) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 24 out of 50
train epoch 631 avg loss: 0.18006 (A-MSE: 0.16013) avg lploss: 0.00000
train epoch 632 avg loss: 0.23650 (A-MSE: 0.21191) avg lploss: 0.00000
train epoch 633 avg loss: 0.24336 (A-MSE: 0.21905) avg lploss: 0.00000
train epoch 634 avg loss: 0.21289 (A-MSE: 0.19057) avg lploss: 0.00000
train epoch 635 avg loss: 0.19519 (A-MSE: 0.17541) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.44428 (A-MSE: 0.38963) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.51210 (A-MSE: 0.44750) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 25 out of 50
train epoch 636 avg loss: 0.18323 (A-MSE: 0.16290) avg lploss: 0.00000
train epoch 637 avg loss: 0.19431 (A-MSE: 0.17450) avg lploss: 0.00000
train epoch 638 avg loss: 0.16557 (A-MSE: 0.14874) avg lploss: 0.00000
train epoch 639 avg loss: 0.20569 (A-MSE: 0.18565) avg lploss: 0.00000
train epoch 640 avg loss: 0.19152 (A-MSE: 0.17210) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.36436 (A-MSE: 0.32809) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.44750 (A-MSE: 0.39678) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 26 out of 50
train epoch 641 avg loss: 0.16637 (A-MSE: 0.15058) avg lploss: 0.00000
train epoch 642 avg loss: 0.20454 (A-MSE: 0.18294) avg lploss: 0.00000
train epoch 643 avg loss: 0.21160 (A-MSE: 0.18970) avg lploss: 0.00000
train epoch 644 avg loss: 0.21403 (A-MSE: 0.19012) avg lploss: 0.00000
train epoch 645 avg loss: 0.22153 (A-MSE: 0.20012) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.46810 (A-MSE: 0.41089) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.52135 (A-MSE: 0.45803) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 27 out of 50
train epoch 646 avg loss: 0.21833 (A-MSE: 0.19746) avg lploss: 0.00000
train epoch 647 avg loss: 0.18873 (A-MSE: 0.16891) avg lploss: 0.00000
train epoch 648 avg loss: 0.19103 (A-MSE: 0.17124) avg lploss: 0.00000
train epoch 649 avg loss: 0.15431 (A-MSE: 0.13804) avg lploss: 0.00000
train epoch 650 avg loss: 0.15508 (A-MSE: 0.13779) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.38542 (A-MSE: 0.34185) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.45881 (A-MSE: 0.40843) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 28 out of 50
train epoch 651 avg loss: 0.15583 (A-MSE: 0.13945) avg lploss: 0.00000
train epoch 652 avg loss: 0.15561 (A-MSE: 0.13856) avg lploss: 0.00000
train epoch 653 avg loss: 0.16246 (A-MSE: 0.14626) avg lploss: 0.00000
train epoch 654 avg loss: 0.14711 (A-MSE: 0.13201) avg lploss: 0.00000
train epoch 655 avg loss: 0.15326 (A-MSE: 0.13808) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.40839 (A-MSE: 0.35959) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.47055 (A-MSE: 0.41648) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 29 out of 50
train epoch 656 avg loss: 0.17851 (A-MSE: 0.15813) avg lploss: 0.00000
train epoch 657 avg loss: 0.18793 (A-MSE: 0.17141) avg lploss: 0.00000
train epoch 658 avg loss: 0.19906 (A-MSE: 0.17880) avg lploss: 0.00000
train epoch 659 avg loss: 0.16944 (A-MSE: 0.15146) avg lploss: 0.00000
train epoch 660 avg loss: 0.18151 (A-MSE: 0.16178) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.44849 (A-MSE: 0.39487) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.51120 (A-MSE: 0.45146) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 30 out of 50
train epoch 661 avg loss: 0.14823 (A-MSE: 0.13275) avg lploss: 0.00000
train epoch 662 avg loss: 0.14799 (A-MSE: 0.13352) avg lploss: 0.00000
train epoch 663 avg loss: 0.14583 (A-MSE: 0.13011) avg lploss: 0.00000
train epoch 664 avg loss: 0.14110 (A-MSE: 0.12706) avg lploss: 0.00000
train epoch 665 avg loss: 0.20075 (A-MSE: 0.18024) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.51705 (A-MSE: 0.44481) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.55343 (A-MSE: 0.48464) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 31 out of 50
train epoch 666 avg loss: 0.20810 (A-MSE: 0.18776) avg lploss: 0.00000
train epoch 667 avg loss: 0.15707 (A-MSE: 0.14144) avg lploss: 0.00000
train epoch 668 avg loss: 0.15367 (A-MSE: 0.13756) avg lploss: 0.00000
train epoch 669 avg loss: 0.16074 (A-MSE: 0.14562) avg lploss: 0.00000
train epoch 670 avg loss: 0.16134 (A-MSE: 0.14604) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.39224 (A-MSE: 0.34987) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.48961 (A-MSE: 0.43409) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 32 out of 50
train epoch 671 avg loss: 0.17501 (A-MSE: 0.15810) avg lploss: 0.00000
train epoch 672 avg loss: 0.14469 (A-MSE: 0.12889) avg lploss: 0.00000
train epoch 673 avg loss: 0.14914 (A-MSE: 0.13490) avg lploss: 0.00000
train epoch 674 avg loss: 0.14209 (A-MSE: 0.12720) avg lploss: 0.00000
train epoch 675 avg loss: 0.14422 (A-MSE: 0.12861) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.37231 (A-MSE: 0.33153) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.47053 (A-MSE: 0.41429) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 33 out of 50
train epoch 676 avg loss: 0.15633 (A-MSE: 0.14035) avg lploss: 0.00000
train epoch 677 avg loss: 0.15518 (A-MSE: 0.13825) avg lploss: 0.00000
train epoch 678 avg loss: 0.17055 (A-MSE: 0.15293) avg lploss: 0.00000
train epoch 679 avg loss: 0.19786 (A-MSE: 0.17759) avg lploss: 0.00000
train epoch 680 avg loss: 0.15990 (A-MSE: 0.14378) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.39260 (A-MSE: 0.34367) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.46065 (A-MSE: 0.40616) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 34 out of 50
train epoch 681 avg loss: 0.13445 (A-MSE: 0.12137) avg lploss: 0.00000
train epoch 682 avg loss: 0.14698 (A-MSE: 0.13236) avg lploss: 0.00000
train epoch 683 avg loss: 0.15526 (A-MSE: 0.13833) avg lploss: 0.00000
train epoch 684 avg loss: 0.14800 (A-MSE: 0.13279) avg lploss: 0.00000
train epoch 685 avg loss: 0.16423 (A-MSE: 0.14838) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.46175 (A-MSE: 0.41134) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.54604 (A-MSE: 0.48335) avg lploss: 0.00000
*** Best Val Loss: 0.36316 	 Best Test Loss: 0.46334 	 Best epoch 510
EarlyStopping counter: 35 out of 50
train epoch 686 avg loss: 0.15463 (A-MSE: 0.13777) avg lploss: 0.00000
train epoch 687 avg loss: 0.13333 (A-MSE: 0.12083) avg lploss: 0.00000
train epoch 688 avg loss: 0.15093 (A-MSE: 0.13538) avg lploss: 0.00000
train epoch 689 avg loss: 0.15926 (A-MSE: 0.14256) avg lploss: 0.00000
train epoch 690 avg loss: 0.17503 (A-MSE: 0.15692) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.36102 (A-MSE: 0.31818) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.44289 (A-MSE: 0.39104) avg lploss: 0.00000
*** Best Val Loss: 0.36102 	 Best Test Loss: 0.44289 	 Best epoch 690
Validation loss decreased (0.363160 --> 0.361024).  Saving model ...
train epoch 691 avg loss: 0.16431 (A-MSE: 0.14886) avg lploss: 0.00000
train epoch 692 avg loss: 0.18698 (A-MSE: 0.16800) avg lploss: 0.00000
train epoch 693 avg loss: 0.18554 (A-MSE: 0.16566) avg lploss: 0.00000
train epoch 694 avg loss: 0.21036 (A-MSE: 0.18712) avg lploss: 0.00000
train epoch 695 avg loss: 0.22128 (A-MSE: 0.19868) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.52683 (A-MSE: 0.46224) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.53844 (A-MSE: 0.47574) avg lploss: 0.00000
*** Best Val Loss: 0.36102 	 Best Test Loss: 0.44289 	 Best epoch 690
EarlyStopping counter: 1 out of 50
train epoch 696 avg loss: 0.22614 (A-MSE: 0.20250) avg lploss: 0.00000
train epoch 697 avg loss: 0.18878 (A-MSE: 0.16974) avg lploss: 0.00000
train epoch 698 avg loss: 0.16348 (A-MSE: 0.14658) avg lploss: 0.00000
train epoch 699 avg loss: 0.16567 (A-MSE: 0.14931) avg lploss: 0.00000
train epoch 700 avg loss: 0.15736 (A-MSE: 0.13999) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.42110 (A-MSE: 0.37850) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.48352 (A-MSE: 0.43430) avg lploss: 0.00000
*** Best Val Loss: 0.36102 	 Best Test Loss: 0.44289 	 Best epoch 690
EarlyStopping counter: 2 out of 50
train epoch 701 avg loss: 0.13529 (A-MSE: 0.12109) avg lploss: 0.00000
train epoch 702 avg loss: 0.15808 (A-MSE: 0.14255) avg lploss: 0.00000
train epoch 703 avg loss: 0.13603 (A-MSE: 0.12200) avg lploss: 0.00000
train epoch 704 avg loss: 0.12471 (A-MSE: 0.11140) avg lploss: 0.00000
train epoch 705 avg loss: 0.13390 (A-MSE: 0.12130) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.36606 (A-MSE: 0.32832) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.44780 (A-MSE: 0.39663) avg lploss: 0.00000
*** Best Val Loss: 0.36102 	 Best Test Loss: 0.44289 	 Best epoch 690
EarlyStopping counter: 3 out of 50
train epoch 706 avg loss: 0.14939 (A-MSE: 0.13379) avg lploss: 0.00000
train epoch 707 avg loss: 0.18613 (A-MSE: 0.16670) avg lploss: 0.00000
train epoch 708 avg loss: 0.18016 (A-MSE: 0.16120) avg lploss: 0.00000
train epoch 709 avg loss: 0.14570 (A-MSE: 0.13128) avg lploss: 0.00000
train epoch 710 avg loss: 0.15609 (A-MSE: 0.14004) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.47031 (A-MSE: 0.41111) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.55108 (A-MSE: 0.48749) avg lploss: 0.00000
*** Best Val Loss: 0.36102 	 Best Test Loss: 0.44289 	 Best epoch 690
EarlyStopping counter: 4 out of 50
train epoch 711 avg loss: 0.21740 (A-MSE: 0.19549) avg lploss: 0.00000
train epoch 712 avg loss: 0.22229 (A-MSE: 0.19946) avg lploss: 0.00000
train epoch 713 avg loss: 0.19648 (A-MSE: 0.17373) avg lploss: 0.00000
train epoch 714 avg loss: 0.17537 (A-MSE: 0.15675) avg lploss: 0.00000
train epoch 715 avg loss: 0.15417 (A-MSE: 0.13812) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.37825 (A-MSE: 0.34008) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.46441 (A-MSE: 0.41564) avg lploss: 0.00000
*** Best Val Loss: 0.36102 	 Best Test Loss: 0.44289 	 Best epoch 690
EarlyStopping counter: 5 out of 50
train epoch 716 avg loss: 0.15810 (A-MSE: 0.14179) avg lploss: 0.00000
train epoch 717 avg loss: 0.16263 (A-MSE: 0.14495) avg lploss: 0.00000
train epoch 718 avg loss: 0.14023 (A-MSE: 0.12502) avg lploss: 0.00000
train epoch 719 avg loss: 0.14978 (A-MSE: 0.13480) avg lploss: 0.00000
train epoch 720 avg loss: 0.14338 (A-MSE: 0.12836) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.32737 (A-MSE: 0.29435) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.40752 (A-MSE: 0.36507) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
Validation loss decreased (0.361024 --> 0.327371).  Saving model ...
train epoch 721 avg loss: 0.14805 (A-MSE: 0.13232) avg lploss: 0.00000
train epoch 722 avg loss: 0.14055 (A-MSE: 0.12685) avg lploss: 0.00000
train epoch 723 avg loss: 0.12315 (A-MSE: 0.11091) avg lploss: 0.00000
train epoch 724 avg loss: 0.13277 (A-MSE: 0.11770) avg lploss: 0.00000
train epoch 725 avg loss: 0.14863 (A-MSE: 0.13246) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.37082 (A-MSE: 0.33282) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.45550 (A-MSE: 0.40533) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 1 out of 50
train epoch 726 avg loss: 0.16330 (A-MSE: 0.14596) avg lploss: 0.00000
train epoch 727 avg loss: 0.13391 (A-MSE: 0.11957) avg lploss: 0.00000
train epoch 728 avg loss: 0.12204 (A-MSE: 0.11062) avg lploss: 0.00000
train epoch 729 avg loss: 0.14050 (A-MSE: 0.12512) avg lploss: 0.00000
train epoch 730 avg loss: 0.12117 (A-MSE: 0.10866) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.39296 (A-MSE: 0.35348) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.47540 (A-MSE: 0.42637) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 2 out of 50
train epoch 731 avg loss: 0.12058 (A-MSE: 0.10875) avg lploss: 0.00000
train epoch 732 avg loss: 0.12641 (A-MSE: 0.11277) avg lploss: 0.00000
train epoch 733 avg loss: 0.15178 (A-MSE: 0.13537) avg lploss: 0.00000
train epoch 734 avg loss: 0.16625 (A-MSE: 0.14966) avg lploss: 0.00000
train epoch 735 avg loss: 0.16528 (A-MSE: 0.14736) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.46125 (A-MSE: 0.40826) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.47087 (A-MSE: 0.41504) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 3 out of 50
train epoch 736 avg loss: 0.17545 (A-MSE: 0.15842) avg lploss: 0.00000
train epoch 737 avg loss: 0.17017 (A-MSE: 0.15294) avg lploss: 0.00000
train epoch 738 avg loss: 0.19181 (A-MSE: 0.17449) avg lploss: 0.00000
train epoch 739 avg loss: 0.15738 (A-MSE: 0.14093) avg lploss: 0.00000
train epoch 740 avg loss: 0.13917 (A-MSE: 0.12468) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.41655 (A-MSE: 0.37849) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.45092 (A-MSE: 0.40574) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 4 out of 50
train epoch 741 avg loss: 0.15474 (A-MSE: 0.13913) avg lploss: 0.00000
train epoch 742 avg loss: 0.13663 (A-MSE: 0.12244) avg lploss: 0.00000
train epoch 743 avg loss: 0.14166 (A-MSE: 0.12679) avg lploss: 0.00000
train epoch 744 avg loss: 0.14970 (A-MSE: 0.13386) avg lploss: 0.00000
train epoch 745 avg loss: 0.14434 (A-MSE: 0.12923) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.39312 (A-MSE: 0.34743) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.45481 (A-MSE: 0.40029) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 5 out of 50
train epoch 746 avg loss: 0.14218 (A-MSE: 0.12742) avg lploss: 0.00000
train epoch 747 avg loss: 0.15126 (A-MSE: 0.13593) avg lploss: 0.00000
train epoch 748 avg loss: 0.13549 (A-MSE: 0.12234) avg lploss: 0.00000
train epoch 749 avg loss: 0.13390 (A-MSE: 0.12075) avg lploss: 0.00000
train epoch 750 avg loss: 0.12575 (A-MSE: 0.11313) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.33376 (A-MSE: 0.29613) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.40590 (A-MSE: 0.35943) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 6 out of 50
train epoch 751 avg loss: 0.13659 (A-MSE: 0.12278) avg lploss: 0.00000
train epoch 752 avg loss: 0.14532 (A-MSE: 0.12997) avg lploss: 0.00000
train epoch 753 avg loss: 0.15636 (A-MSE: 0.13949) avg lploss: 0.00000
train epoch 754 avg loss: 0.15388 (A-MSE: 0.13713) avg lploss: 0.00000
train epoch 755 avg loss: 0.12893 (A-MSE: 0.11504) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.46049 (A-MSE: 0.41212) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.52134 (A-MSE: 0.46208) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 7 out of 50
train epoch 756 avg loss: 0.13130 (A-MSE: 0.11695) avg lploss: 0.00000
train epoch 757 avg loss: 0.13575 (A-MSE: 0.12036) avg lploss: 0.00000
train epoch 758 avg loss: 0.17715 (A-MSE: 0.15890) avg lploss: 0.00000
train epoch 759 avg loss: 0.16051 (A-MSE: 0.14477) avg lploss: 0.00000
train epoch 760 avg loss: 0.16514 (A-MSE: 0.14716) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.37616 (A-MSE: 0.33352) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.47282 (A-MSE: 0.41726) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 8 out of 50
train epoch 761 avg loss: 0.16240 (A-MSE: 0.14651) avg lploss: 0.00000
train epoch 762 avg loss: 0.14609 (A-MSE: 0.13023) avg lploss: 0.00000
train epoch 763 avg loss: 0.16187 (A-MSE: 0.14297) avg lploss: 0.00000
train epoch 764 avg loss: 0.15306 (A-MSE: 0.13806) avg lploss: 0.00000
train epoch 765 avg loss: 0.14397 (A-MSE: 0.12826) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.38121 (A-MSE: 0.33659) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.45396 (A-MSE: 0.39819) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 9 out of 50
train epoch 766 avg loss: 0.14458 (A-MSE: 0.12992) avg lploss: 0.00000
train epoch 767 avg loss: 0.16950 (A-MSE: 0.15331) avg lploss: 0.00000
train epoch 768 avg loss: 0.14767 (A-MSE: 0.13064) avg lploss: 0.00000
train epoch 769 avg loss: 0.12272 (A-MSE: 0.11058) avg lploss: 0.00000
train epoch 770 avg loss: 0.12329 (A-MSE: 0.11107) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.38111 (A-MSE: 0.33669) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.42824 (A-MSE: 0.37929) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 10 out of 50
train epoch 771 avg loss: 0.12212 (A-MSE: 0.10944) avg lploss: 0.00000
train epoch 772 avg loss: 0.11512 (A-MSE: 0.10299) avg lploss: 0.00000
train epoch 773 avg loss: 0.12226 (A-MSE: 0.10924) avg lploss: 0.00000
train epoch 774 avg loss: 0.11671 (A-MSE: 0.10511) avg lploss: 0.00000
train epoch 775 avg loss: 0.11673 (A-MSE: 0.10421) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.37790 (A-MSE: 0.33597) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.45017 (A-MSE: 0.39900) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 11 out of 50
train epoch 776 avg loss: 0.11955 (A-MSE: 0.10725) avg lploss: 0.00000
train epoch 777 avg loss: 0.13840 (A-MSE: 0.12510) avg lploss: 0.00000
train epoch 778 avg loss: 0.12910 (A-MSE: 0.11549) avg lploss: 0.00000
train epoch 779 avg loss: 0.12383 (A-MSE: 0.11181) avg lploss: 0.00000
train epoch 780 avg loss: 0.12639 (A-MSE: 0.11318) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.35421 (A-MSE: 0.31628) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.42377 (A-MSE: 0.37331) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 12 out of 50
train epoch 781 avg loss: 0.13991 (A-MSE: 0.12600) avg lploss: 0.00000
train epoch 782 avg loss: 0.12935 (A-MSE: 0.11518) avg lploss: 0.00000
train epoch 783 avg loss: 0.13083 (A-MSE: 0.11779) avg lploss: 0.00000
train epoch 784 avg loss: 0.12730 (A-MSE: 0.11368) avg lploss: 0.00000
train epoch 785 avg loss: 0.13402 (A-MSE: 0.12004) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.34675 (A-MSE: 0.30790) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.42330 (A-MSE: 0.37544) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 13 out of 50
train epoch 786 avg loss: 0.12933 (A-MSE: 0.11597) avg lploss: 0.00000
train epoch 787 avg loss: 0.14253 (A-MSE: 0.12742) avg lploss: 0.00000
train epoch 788 avg loss: 0.12959 (A-MSE: 0.11614) avg lploss: 0.00000
train epoch 789 avg loss: 0.13335 (A-MSE: 0.11954) avg lploss: 0.00000
train epoch 790 avg loss: 0.15984 (A-MSE: 0.14472) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.42812 (A-MSE: 0.37275) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.48515 (A-MSE: 0.42458) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 14 out of 50
train epoch 791 avg loss: 0.14910 (A-MSE: 0.13205) avg lploss: 0.00000
train epoch 792 avg loss: 0.14120 (A-MSE: 0.12616) avg lploss: 0.00000
train epoch 793 avg loss: 0.12476 (A-MSE: 0.11211) avg lploss: 0.00000
train epoch 794 avg loss: 0.12098 (A-MSE: 0.10918) avg lploss: 0.00000
train epoch 795 avg loss: 0.12131 (A-MSE: 0.10933) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.35121 (A-MSE: 0.31362) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.41265 (A-MSE: 0.36643) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 15 out of 50
train epoch 796 avg loss: 0.11953 (A-MSE: 0.10682) avg lploss: 0.00000
train epoch 797 avg loss: 0.13618 (A-MSE: 0.12255) avg lploss: 0.00000
train epoch 798 avg loss: 0.13381 (A-MSE: 0.12048) avg lploss: 0.00000
train epoch 799 avg loss: 0.12130 (A-MSE: 0.10807) avg lploss: 0.00000
train epoch 800 avg loss: 0.12687 (A-MSE: 0.11354) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.36851 (A-MSE: 0.32412) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.41548 (A-MSE: 0.36503) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 16 out of 50
train epoch 801 avg loss: 0.13535 (A-MSE: 0.12102) avg lploss: 0.00000
train epoch 802 avg loss: 0.18689 (A-MSE: 0.16703) avg lploss: 0.00000
train epoch 803 avg loss: 0.17945 (A-MSE: 0.16093) avg lploss: 0.00000
train epoch 804 avg loss: 0.17818 (A-MSE: 0.15866) avg lploss: 0.00000
train epoch 805 avg loss: 0.14853 (A-MSE: 0.13287) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.36905 (A-MSE: 0.33005) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.44442 (A-MSE: 0.39193) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 17 out of 50
train epoch 806 avg loss: 0.15393 (A-MSE: 0.13888) avg lploss: 0.00000
train epoch 807 avg loss: 0.16322 (A-MSE: 0.14453) avg lploss: 0.00000
train epoch 808 avg loss: 0.16089 (A-MSE: 0.14395) avg lploss: 0.00000
train epoch 809 avg loss: 0.12449 (A-MSE: 0.11163) avg lploss: 0.00000
train epoch 810 avg loss: 0.11787 (A-MSE: 0.10510) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.41146 (A-MSE: 0.36224) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.43369 (A-MSE: 0.38329) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 18 out of 50
train epoch 811 avg loss: 0.12796 (A-MSE: 0.11468) avg lploss: 0.00000
train epoch 812 avg loss: 0.12050 (A-MSE: 0.10738) avg lploss: 0.00000
train epoch 813 avg loss: 0.12966 (A-MSE: 0.11675) avg lploss: 0.00000
train epoch 814 avg loss: 0.14742 (A-MSE: 0.13066) avg lploss: 0.00000
train epoch 815 avg loss: 0.13422 (A-MSE: 0.12077) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.42458 (A-MSE: 0.37689) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.47411 (A-MSE: 0.41915) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 19 out of 50
train epoch 816 avg loss: 0.12419 (A-MSE: 0.11091) avg lploss: 0.00000
train epoch 817 avg loss: 0.13627 (A-MSE: 0.12167) avg lploss: 0.00000
train epoch 818 avg loss: 0.11248 (A-MSE: 0.10192) avg lploss: 0.00000
train epoch 819 avg loss: 0.14477 (A-MSE: 0.12991) avg lploss: 0.00000
train epoch 820 avg loss: 0.11724 (A-MSE: 0.10466) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.35514 (A-MSE: 0.31407) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.42722 (A-MSE: 0.37711) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 20 out of 50
train epoch 821 avg loss: 0.13034 (A-MSE: 0.11789) avg lploss: 0.00000
train epoch 822 avg loss: 0.13358 (A-MSE: 0.11794) avg lploss: 0.00000
train epoch 823 avg loss: 0.11132 (A-MSE: 0.10004) avg lploss: 0.00000
train epoch 824 avg loss: 0.13733 (A-MSE: 0.12287) avg lploss: 0.00000
train epoch 825 avg loss: 0.12049 (A-MSE: 0.10862) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.35915 (A-MSE: 0.32077) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.42143 (A-MSE: 0.37308) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 21 out of 50
train epoch 826 avg loss: 0.11920 (A-MSE: 0.10618) avg lploss: 0.00000
train epoch 827 avg loss: 0.12766 (A-MSE: 0.11428) avg lploss: 0.00000
train epoch 828 avg loss: 0.11302 (A-MSE: 0.10066) avg lploss: 0.00000
train epoch 829 avg loss: 0.12230 (A-MSE: 0.10940) avg lploss: 0.00000
train epoch 830 avg loss: 0.11492 (A-MSE: 0.10283) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.35465 (A-MSE: 0.30908) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.39199 (A-MSE: 0.34327) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 22 out of 50
train epoch 831 avg loss: 0.12567 (A-MSE: 0.11347) avg lploss: 0.00000
train epoch 832 avg loss: 0.14402 (A-MSE: 0.12849) avg lploss: 0.00000
train epoch 833 avg loss: 0.12895 (A-MSE: 0.11483) avg lploss: 0.00000
train epoch 834 avg loss: 0.11593 (A-MSE: 0.10389) avg lploss: 0.00000
train epoch 835 avg loss: 0.11719 (A-MSE: 0.10466) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.33583 (A-MSE: 0.29892) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.41845 (A-MSE: 0.37382) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 23 out of 50
train epoch 836 avg loss: 0.12835 (A-MSE: 0.11512) avg lploss: 0.00000
train epoch 837 avg loss: 0.16414 (A-MSE: 0.14633) avg lploss: 0.00000
train epoch 838 avg loss: 0.13145 (A-MSE: 0.11722) avg lploss: 0.00000
train epoch 839 avg loss: 0.11885 (A-MSE: 0.10758) avg lploss: 0.00000
train epoch 840 avg loss: 0.13000 (A-MSE: 0.11709) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.43887 (A-MSE: 0.38616) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.45353 (A-MSE: 0.40115) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 24 out of 50
train epoch 841 avg loss: 0.16953 (A-MSE: 0.15252) avg lploss: 0.00000
train epoch 842 avg loss: 0.16085 (A-MSE: 0.14457) avg lploss: 0.00000
train epoch 843 avg loss: 0.13967 (A-MSE: 0.12489) avg lploss: 0.00000
train epoch 844 avg loss: 0.13313 (A-MSE: 0.11952) avg lploss: 0.00000
train epoch 845 avg loss: 0.11193 (A-MSE: 0.09968) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.38572 (A-MSE: 0.33644) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.43878 (A-MSE: 0.38231) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 25 out of 50
train epoch 846 avg loss: 0.11114 (A-MSE: 0.09921) avg lploss: 0.00000
train epoch 847 avg loss: 0.12151 (A-MSE: 0.11074) avg lploss: 0.00000
train epoch 848 avg loss: 0.12573 (A-MSE: 0.11171) avg lploss: 0.00000
train epoch 849 avg loss: 0.14057 (A-MSE: 0.12580) avg lploss: 0.00000
train epoch 850 avg loss: 0.11906 (A-MSE: 0.10582) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.33268 (A-MSE: 0.29689) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.38710 (A-MSE: 0.34377) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 26 out of 50
train epoch 851 avg loss: 0.10552 (A-MSE: 0.09447) avg lploss: 0.00000
train epoch 852 avg loss: 0.11180 (A-MSE: 0.09961) avg lploss: 0.00000
train epoch 853 avg loss: 0.12618 (A-MSE: 0.11152) avg lploss: 0.00000
train epoch 854 avg loss: 0.12198 (A-MSE: 0.11059) avg lploss: 0.00000
train epoch 855 avg loss: 0.11592 (A-MSE: 0.10391) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.35714 (A-MSE: 0.31461) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.40856 (A-MSE: 0.36101) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 27 out of 50
train epoch 856 avg loss: 0.13095 (A-MSE: 0.11769) avg lploss: 0.00000
train epoch 857 avg loss: 0.12472 (A-MSE: 0.11249) avg lploss: 0.00000
train epoch 858 avg loss: 0.12555 (A-MSE: 0.11254) avg lploss: 0.00000
train epoch 859 avg loss: 0.11581 (A-MSE: 0.10480) avg lploss: 0.00000
train epoch 860 avg loss: 0.11695 (A-MSE: 0.10508) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.38407 (A-MSE: 0.33925) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.44797 (A-MSE: 0.39685) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 28 out of 50
train epoch 861 avg loss: 0.11332 (A-MSE: 0.10089) avg lploss: 0.00000
train epoch 862 avg loss: 0.13734 (A-MSE: 0.12438) avg lploss: 0.00000
train epoch 863 avg loss: 0.18376 (A-MSE: 0.16536) avg lploss: 0.00000
train epoch 864 avg loss: 0.20577 (A-MSE: 0.18336) avg lploss: 0.00000
train epoch 865 avg loss: 0.15348 (A-MSE: 0.13720) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.42313 (A-MSE: 0.37457) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.48347 (A-MSE: 0.43061) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 29 out of 50
train epoch 866 avg loss: 0.12818 (A-MSE: 0.11447) avg lploss: 0.00000
train epoch 867 avg loss: 0.12542 (A-MSE: 0.11067) avg lploss: 0.00000
train epoch 868 avg loss: 0.12245 (A-MSE: 0.10999) avg lploss: 0.00000
train epoch 869 avg loss: 0.11505 (A-MSE: 0.10213) avg lploss: 0.00000
train epoch 870 avg loss: 0.12785 (A-MSE: 0.11356) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.37743 (A-MSE: 0.33145) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.44992 (A-MSE: 0.39796) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 30 out of 50
train epoch 871 avg loss: 0.12155 (A-MSE: 0.11055) avg lploss: 0.00000
train epoch 872 avg loss: 0.10664 (A-MSE: 0.09662) avg lploss: 0.00000
train epoch 873 avg loss: 0.11131 (A-MSE: 0.09934) avg lploss: 0.00000
train epoch 874 avg loss: 0.14347 (A-MSE: 0.12722) avg lploss: 0.00000
train epoch 875 avg loss: 0.15041 (A-MSE: 0.13540) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.39571 (A-MSE: 0.34870) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.47579 (A-MSE: 0.42226) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 31 out of 50
train epoch 876 avg loss: 0.12166 (A-MSE: 0.10824) avg lploss: 0.00000
train epoch 877 avg loss: 0.11968 (A-MSE: 0.10695) avg lploss: 0.00000
train epoch 878 avg loss: 0.11923 (A-MSE: 0.10648) avg lploss: 0.00000
train epoch 879 avg loss: 0.12342 (A-MSE: 0.10882) avg lploss: 0.00000
train epoch 880 avg loss: 0.12373 (A-MSE: 0.11026) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.38988 (A-MSE: 0.33851) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.44018 (A-MSE: 0.38261) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 32 out of 50
train epoch 881 avg loss: 0.13660 (A-MSE: 0.12196) avg lploss: 0.00000
train epoch 882 avg loss: 0.10496 (A-MSE: 0.09420) avg lploss: 0.00000
train epoch 883 avg loss: 0.09799 (A-MSE: 0.08852) avg lploss: 0.00000
train epoch 884 avg loss: 0.10739 (A-MSE: 0.09685) avg lploss: 0.00000
train epoch 885 avg loss: 0.10375 (A-MSE: 0.09340) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.36983 (A-MSE: 0.32519) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.40396 (A-MSE: 0.35661) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 33 out of 50
train epoch 886 avg loss: 0.09763 (A-MSE: 0.08763) avg lploss: 0.00000
train epoch 887 avg loss: 0.09854 (A-MSE: 0.08955) avg lploss: 0.00000
train epoch 888 avg loss: 0.11227 (A-MSE: 0.10026) avg lploss: 0.00000
train epoch 889 avg loss: 0.11976 (A-MSE: 0.10671) avg lploss: 0.00000
train epoch 890 avg loss: 0.12046 (A-MSE: 0.10798) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.40028 (A-MSE: 0.35102) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.44432 (A-MSE: 0.39054) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 34 out of 50
train epoch 891 avg loss: 0.12750 (A-MSE: 0.11485) avg lploss: 0.00000
train epoch 892 avg loss: 0.11385 (A-MSE: 0.10221) avg lploss: 0.00000
train epoch 893 avg loss: 0.09278 (A-MSE: 0.08335) avg lploss: 0.00000
train epoch 894 avg loss: 0.11630 (A-MSE: 0.10480) avg lploss: 0.00000
train epoch 895 avg loss: 0.11956 (A-MSE: 0.10701) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.35699 (A-MSE: 0.31640) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.38685 (A-MSE: 0.34362) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 35 out of 50
train epoch 896 avg loss: 0.10237 (A-MSE: 0.09211) avg lploss: 0.00000
train epoch 897 avg loss: 0.09937 (A-MSE: 0.08900) avg lploss: 0.00000
train epoch 898 avg loss: 0.10674 (A-MSE: 0.09536) avg lploss: 0.00000
train epoch 899 avg loss: 0.10814 (A-MSE: 0.09784) avg lploss: 0.00000
train epoch 900 avg loss: 0.10985 (A-MSE: 0.09760) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.34721 (A-MSE: 0.30433) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.40940 (A-MSE: 0.36369) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 36 out of 50
train epoch 901 avg loss: 0.13033 (A-MSE: 0.11655) avg lploss: 0.00000
train epoch 902 avg loss: 0.11941 (A-MSE: 0.10807) avg lploss: 0.00000
train epoch 903 avg loss: 0.11094 (A-MSE: 0.10011) avg lploss: 0.00000
train epoch 904 avg loss: 0.10766 (A-MSE: 0.09518) avg lploss: 0.00000
train epoch 905 avg loss: 0.14669 (A-MSE: 0.13092) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.45271 (A-MSE: 0.40204) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.49016 (A-MSE: 0.43633) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 37 out of 50
train epoch 906 avg loss: 0.13158 (A-MSE: 0.11879) avg lploss: 0.00000
train epoch 907 avg loss: 0.11585 (A-MSE: 0.10518) avg lploss: 0.00000
train epoch 908 avg loss: 0.11239 (A-MSE: 0.10119) avg lploss: 0.00000
train epoch 909 avg loss: 0.11707 (A-MSE: 0.10463) avg lploss: 0.00000
train epoch 910 avg loss: 0.18874 (A-MSE: 0.17096) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.38943 (A-MSE: 0.34525) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.42164 (A-MSE: 0.37483) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 38 out of 50
train epoch 911 avg loss: 0.12845 (A-MSE: 0.11575) avg lploss: 0.00000
train epoch 912 avg loss: 0.11149 (A-MSE: 0.09911) avg lploss: 0.00000
train epoch 913 avg loss: 0.10643 (A-MSE: 0.09515) avg lploss: 0.00000
train epoch 914 avg loss: 0.09787 (A-MSE: 0.08861) avg lploss: 0.00000
train epoch 915 avg loss: 0.11204 (A-MSE: 0.09994) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.43627 (A-MSE: 0.38742) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.48932 (A-MSE: 0.43874) avg lploss: 0.00000
*** Best Val Loss: 0.32737 	 Best Test Loss: 0.40752 	 Best epoch 720
EarlyStopping counter: 39 out of 50
train epoch 916 avg loss: 0.11524 (A-MSE: 0.10481) avg lploss: 0.00000
train epoch 917 avg loss: 0.11941 (A-MSE: 0.10652) avg lploss: 0.00000
train epoch 918 avg loss: 0.09832 (A-MSE: 0.08904) avg lploss: 0.00000
train epoch 919 avg loss: 0.09256 (A-MSE: 0.08219) avg lploss: 0.00000
train epoch 920 avg loss: 0.11353 (A-MSE: 0.10151) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.29433 (A-MSE: 0.25869) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.37953 (A-MSE: 0.33545) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
Validation loss decreased (0.327371 --> 0.294328).  Saving model ...
train epoch 921 avg loss: 0.10085 (A-MSE: 0.08991) avg lploss: 0.00000
train epoch 922 avg loss: 0.10001 (A-MSE: 0.08891) avg lploss: 0.00000
train epoch 923 avg loss: 0.10747 (A-MSE: 0.09664) avg lploss: 0.00000
train epoch 924 avg loss: 0.09951 (A-MSE: 0.08876) avg lploss: 0.00000
train epoch 925 avg loss: 0.09270 (A-MSE: 0.08351) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.44147 (A-MSE: 0.38280) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.46385 (A-MSE: 0.40684) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 1 out of 50
train epoch 926 avg loss: 0.11322 (A-MSE: 0.10085) avg lploss: 0.00000
train epoch 927 avg loss: 0.10298 (A-MSE: 0.09242) avg lploss: 0.00000
train epoch 928 avg loss: 0.10352 (A-MSE: 0.09284) avg lploss: 0.00000
train epoch 929 avg loss: 0.10373 (A-MSE: 0.09280) avg lploss: 0.00000
train epoch 930 avg loss: 0.09138 (A-MSE: 0.08192) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.33347 (A-MSE: 0.28885) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.38498 (A-MSE: 0.33905) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 2 out of 50
train epoch 931 avg loss: 0.09488 (A-MSE: 0.08446) avg lploss: 0.00000
train epoch 932 avg loss: 0.09647 (A-MSE: 0.08625) avg lploss: 0.00000
train epoch 933 avg loss: 0.10243 (A-MSE: 0.09244) avg lploss: 0.00000
train epoch 934 avg loss: 0.11710 (A-MSE: 0.10530) avg lploss: 0.00000
train epoch 935 avg loss: 0.18420 (A-MSE: 0.16351) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.41340 (A-MSE: 0.36522) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.45743 (A-MSE: 0.40488) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 3 out of 50
train epoch 936 avg loss: 0.17981 (A-MSE: 0.16092) avg lploss: 0.00000
train epoch 937 avg loss: 0.17909 (A-MSE: 0.15708) avg lploss: 0.00000
train epoch 938 avg loss: 0.15334 (A-MSE: 0.13641) avg lploss: 0.00000
train epoch 939 avg loss: 0.13131 (A-MSE: 0.11691) avg lploss: 0.00000
train epoch 940 avg loss: 0.12625 (A-MSE: 0.11337) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.36413 (A-MSE: 0.31800) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.44603 (A-MSE: 0.39295) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 4 out of 50
train epoch 941 avg loss: 0.12308 (A-MSE: 0.10978) avg lploss: 0.00000
train epoch 942 avg loss: 0.13526 (A-MSE: 0.12103) avg lploss: 0.00000
train epoch 943 avg loss: 0.13475 (A-MSE: 0.12156) avg lploss: 0.00000
train epoch 944 avg loss: 0.10840 (A-MSE: 0.09638) avg lploss: 0.00000
train epoch 945 avg loss: 0.09999 (A-MSE: 0.08902) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.36269 (A-MSE: 0.31800) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.41024 (A-MSE: 0.36271) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 5 out of 50
train epoch 946 avg loss: 0.09265 (A-MSE: 0.08325) avg lploss: 0.00000
train epoch 947 avg loss: 0.09269 (A-MSE: 0.08299) avg lploss: 0.00000
train epoch 948 avg loss: 0.08709 (A-MSE: 0.07796) avg lploss: 0.00000
train epoch 949 avg loss: 0.09349 (A-MSE: 0.08289) avg lploss: 0.00000
train epoch 950 avg loss: 0.11299 (A-MSE: 0.10225) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.39398 (A-MSE: 0.34444) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.42079 (A-MSE: 0.36869) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 6 out of 50
train epoch 951 avg loss: 0.11078 (A-MSE: 0.09806) avg lploss: 0.00000
train epoch 952 avg loss: 0.11317 (A-MSE: 0.10180) avg lploss: 0.00000
train epoch 953 avg loss: 0.09875 (A-MSE: 0.08842) avg lploss: 0.00000
train epoch 954 avg loss: 0.09237 (A-MSE: 0.08277) avg lploss: 0.00000
train epoch 955 avg loss: 0.09606 (A-MSE: 0.08640) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.35071 (A-MSE: 0.31088) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.40996 (A-MSE: 0.36512) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 7 out of 50
train epoch 956 avg loss: 0.09057 (A-MSE: 0.08211) avg lploss: 0.00000
train epoch 957 avg loss: 0.10201 (A-MSE: 0.09110) avg lploss: 0.00000
train epoch 958 avg loss: 0.10724 (A-MSE: 0.09573) avg lploss: 0.00000
train epoch 959 avg loss: 0.10410 (A-MSE: 0.09298) avg lploss: 0.00000
train epoch 960 avg loss: 0.08664 (A-MSE: 0.07775) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.32943 (A-MSE: 0.28861) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.37534 (A-MSE: 0.33210) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 8 out of 50
train epoch 961 avg loss: 0.09050 (A-MSE: 0.08092) avg lploss: 0.00000
train epoch 962 avg loss: 0.10215 (A-MSE: 0.09172) avg lploss: 0.00000
train epoch 963 avg loss: 0.10747 (A-MSE: 0.09679) avg lploss: 0.00000
train epoch 964 avg loss: 0.09967 (A-MSE: 0.08854) avg lploss: 0.00000
train epoch 965 avg loss: 0.09069 (A-MSE: 0.08136) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.35715 (A-MSE: 0.31803) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.44567 (A-MSE: 0.39864) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 9 out of 50
train epoch 966 avg loss: 0.10345 (A-MSE: 0.09270) avg lploss: 0.00000
train epoch 967 avg loss: 0.09721 (A-MSE: 0.08799) avg lploss: 0.00000
train epoch 968 avg loss: 0.09225 (A-MSE: 0.08389) avg lploss: 0.00000
train epoch 969 avg loss: 0.10410 (A-MSE: 0.09330) avg lploss: 0.00000
train epoch 970 avg loss: 0.10088 (A-MSE: 0.09065) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.36494 (A-MSE: 0.32504) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.42298 (A-MSE: 0.37850) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 10 out of 50
train epoch 971 avg loss: 0.11002 (A-MSE: 0.09883) avg lploss: 0.00000
train epoch 972 avg loss: 0.12392 (A-MSE: 0.11002) avg lploss: 0.00000
train epoch 973 avg loss: 0.10807 (A-MSE: 0.09725) avg lploss: 0.00000
train epoch 974 avg loss: 0.08717 (A-MSE: 0.07800) avg lploss: 0.00000
train epoch 975 avg loss: 0.08872 (A-MSE: 0.07881) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.36621 (A-MSE: 0.31678) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.42077 (A-MSE: 0.37031) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 11 out of 50
train epoch 976 avg loss: 0.11215 (A-MSE: 0.10033) avg lploss: 0.00000
train epoch 977 avg loss: 0.11417 (A-MSE: 0.10133) avg lploss: 0.00000
train epoch 978 avg loss: 0.10925 (A-MSE: 0.09866) avg lploss: 0.00000
train epoch 979 avg loss: 0.11319 (A-MSE: 0.10071) avg lploss: 0.00000
train epoch 980 avg loss: 0.10413 (A-MSE: 0.09298) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.39460 (A-MSE: 0.35212) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.44827 (A-MSE: 0.40062) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 12 out of 50
train epoch 981 avg loss: 0.09240 (A-MSE: 0.08303) avg lploss: 0.00000
train epoch 982 avg loss: 0.08986 (A-MSE: 0.08096) avg lploss: 0.00000
train epoch 983 avg loss: 0.12235 (A-MSE: 0.10890) avg lploss: 0.00000
train epoch 984 avg loss: 0.12959 (A-MSE: 0.11615) avg lploss: 0.00000
train epoch 985 avg loss: 0.12569 (A-MSE: 0.11388) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.46290 (A-MSE: 0.40875) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.48083 (A-MSE: 0.42556) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 13 out of 50
train epoch 986 avg loss: 0.14935 (A-MSE: 0.13447) avg lploss: 0.00000
train epoch 987 avg loss: 0.13053 (A-MSE: 0.11664) avg lploss: 0.00000
train epoch 988 avg loss: 0.10601 (A-MSE: 0.09529) avg lploss: 0.00000
train epoch 989 avg loss: 0.08285 (A-MSE: 0.07441) avg lploss: 0.00000
train epoch 990 avg loss: 0.09321 (A-MSE: 0.08294) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.34550 (A-MSE: 0.30561) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.40072 (A-MSE: 0.35822) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 14 out of 50
train epoch 991 avg loss: 0.09211 (A-MSE: 0.08268) avg lploss: 0.00000
train epoch 992 avg loss: 0.08237 (A-MSE: 0.07375) avg lploss: 0.00000
train epoch 993 avg loss: 0.08002 (A-MSE: 0.07124) avg lploss: 0.00000
train epoch 994 avg loss: 0.07540 (A-MSE: 0.06830) avg lploss: 0.00000
train epoch 995 avg loss: 0.09276 (A-MSE: 0.08369) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.33141 (A-MSE: 0.29697) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.40902 (A-MSE: 0.36743) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 15 out of 50
train epoch 996 avg loss: 0.09600 (A-MSE: 0.08514) avg lploss: 0.00000
train epoch 997 avg loss: 0.09870 (A-MSE: 0.08871) avg lploss: 0.00000
train epoch 998 avg loss: 0.11666 (A-MSE: 0.10396) avg lploss: 0.00000
train epoch 999 avg loss: 0.10271 (A-MSE: 0.09193) avg lploss: 0.00000
train epoch 1000 avg loss: 0.09949 (A-MSE: 0.08803) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.39822 (A-MSE: 0.34893) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.43841 (A-MSE: 0.38679) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 16 out of 50
train epoch 1001 avg loss: 0.10157 (A-MSE: 0.09079) avg lploss: 0.00000
train epoch 1002 avg loss: 0.10202 (A-MSE: 0.09167) avg lploss: 0.00000
train epoch 1003 avg loss: 0.10669 (A-MSE: 0.09570) avg lploss: 0.00000
train epoch 1004 avg loss: 0.08589 (A-MSE: 0.07735) avg lploss: 0.00000
train epoch 1005 avg loss: 0.08502 (A-MSE: 0.07702) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.34473 (A-MSE: 0.30499) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.37970 (A-MSE: 0.33698) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 17 out of 50
train epoch 1006 avg loss: 0.08454 (A-MSE: 0.07517) avg lploss: 0.00000
train epoch 1007 avg loss: 0.09259 (A-MSE: 0.08229) avg lploss: 0.00000
train epoch 1008 avg loss: 0.09713 (A-MSE: 0.08723) avg lploss: 0.00000
train epoch 1009 avg loss: 0.09811 (A-MSE: 0.08754) avg lploss: 0.00000
train epoch 1010 avg loss: 0.09380 (A-MSE: 0.08433) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.33103 (A-MSE: 0.29233) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.37719 (A-MSE: 0.33481) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 18 out of 50
train epoch 1011 avg loss: 0.08161 (A-MSE: 0.07431) avg lploss: 0.00000
train epoch 1012 avg loss: 0.08358 (A-MSE: 0.07526) avg lploss: 0.00000
train epoch 1013 avg loss: 0.08827 (A-MSE: 0.07918) avg lploss: 0.00000
train epoch 1014 avg loss: 0.11579 (A-MSE: 0.10444) avg lploss: 0.00000
train epoch 1015 avg loss: 0.11988 (A-MSE: 0.10723) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.36823 (A-MSE: 0.32616) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.41704 (A-MSE: 0.36830) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 19 out of 50
train epoch 1016 avg loss: 0.12067 (A-MSE: 0.10640) avg lploss: 0.00000
train epoch 1017 avg loss: 0.12488 (A-MSE: 0.11139) avg lploss: 0.00000
train epoch 1018 avg loss: 0.09827 (A-MSE: 0.08844) avg lploss: 0.00000
train epoch 1019 avg loss: 0.07798 (A-MSE: 0.06953) avg lploss: 0.00000
train epoch 1020 avg loss: 0.08453 (A-MSE: 0.07646) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.36936 (A-MSE: 0.32962) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.41095 (A-MSE: 0.36792) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 20 out of 50
train epoch 1021 avg loss: 0.09930 (A-MSE: 0.08909) avg lploss: 0.00000
train epoch 1022 avg loss: 0.09626 (A-MSE: 0.08649) avg lploss: 0.00000
train epoch 1023 avg loss: 0.08309 (A-MSE: 0.07423) avg lploss: 0.00000
train epoch 1024 avg loss: 0.10154 (A-MSE: 0.09143) avg lploss: 0.00000
train epoch 1025 avg loss: 0.10939 (A-MSE: 0.09853) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.37837 (A-MSE: 0.33111) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.41438 (A-MSE: 0.36590) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 21 out of 50
train epoch 1026 avg loss: 0.10442 (A-MSE: 0.09370) avg lploss: 0.00000
train epoch 1027 avg loss: 0.10146 (A-MSE: 0.09060) avg lploss: 0.00000
train epoch 1028 avg loss: 0.09794 (A-MSE: 0.08828) avg lploss: 0.00000
train epoch 1029 avg loss: 0.09121 (A-MSE: 0.08168) avg lploss: 0.00000
train epoch 1030 avg loss: 0.09622 (A-MSE: 0.08715) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.38012 (A-MSE: 0.33588) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.42487 (A-MSE: 0.37737) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 22 out of 50
train epoch 1031 avg loss: 0.08896 (A-MSE: 0.07937) avg lploss: 0.00000
train epoch 1032 avg loss: 0.08784 (A-MSE: 0.07837) avg lploss: 0.00000
train epoch 1033 avg loss: 0.07949 (A-MSE: 0.07158) avg lploss: 0.00000
train epoch 1034 avg loss: 0.07544 (A-MSE: 0.06764) avg lploss: 0.00000
train epoch 1035 avg loss: 0.07420 (A-MSE: 0.06661) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.33898 (A-MSE: 0.29620) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.39508 (A-MSE: 0.34692) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 23 out of 50
train epoch 1036 avg loss: 0.08077 (A-MSE: 0.07229) avg lploss: 0.00000
train epoch 1037 avg loss: 0.07916 (A-MSE: 0.07054) avg lploss: 0.00000
train epoch 1038 avg loss: 0.07798 (A-MSE: 0.06987) avg lploss: 0.00000
train epoch 1039 avg loss: 0.08270 (A-MSE: 0.07370) avg lploss: 0.00000
train epoch 1040 avg loss: 0.08049 (A-MSE: 0.07259) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.34718 (A-MSE: 0.30814) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.36601 (A-MSE: 0.32426) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 24 out of 50
train epoch 1041 avg loss: 0.09204 (A-MSE: 0.08202) avg lploss: 0.00000
train epoch 1042 avg loss: 0.08600 (A-MSE: 0.07780) avg lploss: 0.00000
train epoch 1043 avg loss: 0.10024 (A-MSE: 0.08949) avg lploss: 0.00000
train epoch 1044 avg loss: 0.09200 (A-MSE: 0.08334) avg lploss: 0.00000
train epoch 1045 avg loss: 0.08704 (A-MSE: 0.07849) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.37379 (A-MSE: 0.32787) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.41311 (A-MSE: 0.36675) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 25 out of 50
train epoch 1046 avg loss: 0.07738 (A-MSE: 0.06921) avg lploss: 0.00000
train epoch 1047 avg loss: 0.08340 (A-MSE: 0.07432) avg lploss: 0.00000
train epoch 1048 avg loss: 0.10840 (A-MSE: 0.09711) avg lploss: 0.00000
train epoch 1049 avg loss: 0.09932 (A-MSE: 0.08903) avg lploss: 0.00000
train epoch 1050 avg loss: 0.09437 (A-MSE: 0.08399) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.35471 (A-MSE: 0.31777) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.42535 (A-MSE: 0.37663) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 26 out of 50
train epoch 1051 avg loss: 0.09669 (A-MSE: 0.08596) avg lploss: 0.00000
train epoch 1052 avg loss: 0.10464 (A-MSE: 0.09362) avg lploss: 0.00000
train epoch 1053 avg loss: 0.09793 (A-MSE: 0.08824) avg lploss: 0.00000
train epoch 1054 avg loss: 0.08811 (A-MSE: 0.07959) avg lploss: 0.00000
train epoch 1055 avg loss: 0.08977 (A-MSE: 0.08003) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.37452 (A-MSE: 0.33085) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.41018 (A-MSE: 0.36729) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 27 out of 50
train epoch 1056 avg loss: 0.08248 (A-MSE: 0.07373) avg lploss: 0.00000
train epoch 1057 avg loss: 0.07643 (A-MSE: 0.06913) avg lploss: 0.00000
train epoch 1058 avg loss: 0.07037 (A-MSE: 0.06259) avg lploss: 0.00000
train epoch 1059 avg loss: 0.06972 (A-MSE: 0.06273) avg lploss: 0.00000
train epoch 1060 avg loss: 0.08235 (A-MSE: 0.07331) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.32960 (A-MSE: 0.29286) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.36533 (A-MSE: 0.32457) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 28 out of 50
train epoch 1061 avg loss: 0.08755 (A-MSE: 0.07827) avg lploss: 0.00000
train epoch 1062 avg loss: 0.09538 (A-MSE: 0.08602) avg lploss: 0.00000
train epoch 1063 avg loss: 0.08850 (A-MSE: 0.07949) avg lploss: 0.00000
train epoch 1064 avg loss: 0.10139 (A-MSE: 0.09145) avg lploss: 0.00000
train epoch 1065 avg loss: 0.09844 (A-MSE: 0.08710) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.33744 (A-MSE: 0.30061) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.40469 (A-MSE: 0.36100) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 29 out of 50
train epoch 1066 avg loss: 0.08289 (A-MSE: 0.07454) avg lploss: 0.00000
train epoch 1067 avg loss: 0.08628 (A-MSE: 0.07788) avg lploss: 0.00000
train epoch 1068 avg loss: 0.09586 (A-MSE: 0.08649) avg lploss: 0.00000
train epoch 1069 avg loss: 0.08272 (A-MSE: 0.07401) avg lploss: 0.00000
train epoch 1070 avg loss: 0.07394 (A-MSE: 0.06635) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.33684 (A-MSE: 0.30051) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.39773 (A-MSE: 0.35535) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 30 out of 50
train epoch 1071 avg loss: 0.07194 (A-MSE: 0.06420) avg lploss: 0.00000
train epoch 1072 avg loss: 0.06745 (A-MSE: 0.06094) avg lploss: 0.00000
train epoch 1073 avg loss: 0.06615 (A-MSE: 0.05915) avg lploss: 0.00000
train epoch 1074 avg loss: 0.06190 (A-MSE: 0.05567) avg lploss: 0.00000
train epoch 1075 avg loss: 0.06670 (A-MSE: 0.05962) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.34580 (A-MSE: 0.30154) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.39225 (A-MSE: 0.34577) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 31 out of 50
train epoch 1076 avg loss: 0.06775 (A-MSE: 0.06053) avg lploss: 0.00000
train epoch 1077 avg loss: 0.07262 (A-MSE: 0.06535) avg lploss: 0.00000
train epoch 1078 avg loss: 0.08787 (A-MSE: 0.07916) avg lploss: 0.00000
train epoch 1079 avg loss: 0.10838 (A-MSE: 0.09708) avg lploss: 0.00000
train epoch 1080 avg loss: 0.10231 (A-MSE: 0.09228) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.40269 (A-MSE: 0.34840) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.43690 (A-MSE: 0.38316) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 32 out of 50
train epoch 1081 avg loss: 0.09103 (A-MSE: 0.08100) avg lploss: 0.00000
train epoch 1082 avg loss: 0.07114 (A-MSE: 0.06455) avg lploss: 0.00000
train epoch 1083 avg loss: 0.06450 (A-MSE: 0.05790) avg lploss: 0.00000
train epoch 1084 avg loss: 0.06528 (A-MSE: 0.05823) avg lploss: 0.00000
train epoch 1085 avg loss: 0.06824 (A-MSE: 0.06081) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.34446 (A-MSE: 0.30128) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.39457 (A-MSE: 0.34830) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 33 out of 50
train epoch 1086 avg loss: 0.07043 (A-MSE: 0.06268) avg lploss: 0.00000
train epoch 1087 avg loss: 0.06308 (A-MSE: 0.05651) avg lploss: 0.00000
train epoch 1088 avg loss: 0.06343 (A-MSE: 0.05631) avg lploss: 0.00000
train epoch 1089 avg loss: 0.06818 (A-MSE: 0.06130) avg lploss: 0.00000
train epoch 1090 avg loss: 0.06973 (A-MSE: 0.06273) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.34882 (A-MSE: 0.30609) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.41145 (A-MSE: 0.36425) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 34 out of 50
train epoch 1091 avg loss: 0.07710 (A-MSE: 0.06920) avg lploss: 0.00000
train epoch 1092 avg loss: 0.09419 (A-MSE: 0.08404) avg lploss: 0.00000
train epoch 1093 avg loss: 0.10488 (A-MSE: 0.09431) avg lploss: 0.00000
train epoch 1094 avg loss: 0.12186 (A-MSE: 0.10879) avg lploss: 0.00000
train epoch 1095 avg loss: 0.13233 (A-MSE: 0.11711) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.35215 (A-MSE: 0.31117) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.41301 (A-MSE: 0.37026) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 35 out of 50
train epoch 1096 avg loss: 0.12091 (A-MSE: 0.10774) avg lploss: 0.00000
train epoch 1097 avg loss: 0.10851 (A-MSE: 0.09642) avg lploss: 0.00000
train epoch 1098 avg loss: 0.11174 (A-MSE: 0.09987) avg lploss: 0.00000
train epoch 1099 avg loss: 0.12533 (A-MSE: 0.11122) avg lploss: 0.00000
train epoch 1100 avg loss: 0.10401 (A-MSE: 0.09344) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.39196 (A-MSE: 0.34339) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.43017 (A-MSE: 0.38092) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 36 out of 50
train epoch 1101 avg loss: 0.11240 (A-MSE: 0.09952) avg lploss: 0.00000
train epoch 1102 avg loss: 0.10826 (A-MSE: 0.09616) avg lploss: 0.00000
train epoch 1103 avg loss: 0.11506 (A-MSE: 0.10399) avg lploss: 0.00000
train epoch 1104 avg loss: 0.11305 (A-MSE: 0.10068) avg lploss: 0.00000
train epoch 1105 avg loss: 0.09493 (A-MSE: 0.08506) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.35993 (A-MSE: 0.31720) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.43561 (A-MSE: 0.38194) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 37 out of 50
train epoch 1106 avg loss: 0.10538 (A-MSE: 0.09437) avg lploss: 0.00000
train epoch 1107 avg loss: 0.11661 (A-MSE: 0.10480) avg lploss: 0.00000
train epoch 1108 avg loss: 0.11526 (A-MSE: 0.10392) avg lploss: 0.00000
train epoch 1109 avg loss: 0.08523 (A-MSE: 0.07599) avg lploss: 0.00000
train epoch 1110 avg loss: 0.06723 (A-MSE: 0.06037) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.35706 (A-MSE: 0.31251) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.40533 (A-MSE: 0.35949) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 38 out of 50
train epoch 1111 avg loss: 0.06476 (A-MSE: 0.05785) avg lploss: 0.00000
train epoch 1112 avg loss: 0.06743 (A-MSE: 0.06060) avg lploss: 0.00000
train epoch 1113 avg loss: 0.08107 (A-MSE: 0.07246) avg lploss: 0.00000
train epoch 1114 avg loss: 0.07812 (A-MSE: 0.06961) avg lploss: 0.00000
train epoch 1115 avg loss: 0.06421 (A-MSE: 0.05790) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.33405 (A-MSE: 0.29485) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.37468 (A-MSE: 0.33386) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 39 out of 50
train epoch 1116 avg loss: 0.06367 (A-MSE: 0.05717) avg lploss: 0.00000
train epoch 1117 avg loss: 0.07306 (A-MSE: 0.06462) avg lploss: 0.00000
train epoch 1118 avg loss: 0.07361 (A-MSE: 0.06600) avg lploss: 0.00000
train epoch 1119 avg loss: 0.07548 (A-MSE: 0.06744) avg lploss: 0.00000
train epoch 1120 avg loss: 0.07494 (A-MSE: 0.06757) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.36581 (A-MSE: 0.31798) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.38466 (A-MSE: 0.33910) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 40 out of 50
train epoch 1121 avg loss: 0.09764 (A-MSE: 0.08771) avg lploss: 0.00000
train epoch 1122 avg loss: 0.09750 (A-MSE: 0.08719) avg lploss: 0.00000
train epoch 1123 avg loss: 0.07666 (A-MSE: 0.06831) avg lploss: 0.00000
train epoch 1124 avg loss: 0.07213 (A-MSE: 0.06451) avg lploss: 0.00000
train epoch 1125 avg loss: 0.08620 (A-MSE: 0.07799) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.35980 (A-MSE: 0.32021) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.40263 (A-MSE: 0.35953) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 41 out of 50
train epoch 1126 avg loss: 0.07269 (A-MSE: 0.06564) avg lploss: 0.00000
train epoch 1127 avg loss: 0.07607 (A-MSE: 0.06840) avg lploss: 0.00000
train epoch 1128 avg loss: 0.07052 (A-MSE: 0.06393) avg lploss: 0.00000
train epoch 1129 avg loss: 0.08915 (A-MSE: 0.07900) avg lploss: 0.00000
train epoch 1130 avg loss: 0.09220 (A-MSE: 0.08235) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.35237 (A-MSE: 0.30883) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.40942 (A-MSE: 0.36199) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 42 out of 50
train epoch 1131 avg loss: 0.09163 (A-MSE: 0.08267) avg lploss: 0.00000
train epoch 1132 avg loss: 0.09990 (A-MSE: 0.08908) avg lploss: 0.00000
train epoch 1133 avg loss: 0.10816 (A-MSE: 0.09679) avg lploss: 0.00000
train epoch 1134 avg loss: 0.11069 (A-MSE: 0.09904) avg lploss: 0.00000
train epoch 1135 avg loss: 0.09992 (A-MSE: 0.08901) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.33759 (A-MSE: 0.29792) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.39627 (A-MSE: 0.35450) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 43 out of 50
train epoch 1136 avg loss: 0.09557 (A-MSE: 0.08547) avg lploss: 0.00000
train epoch 1137 avg loss: 0.09714 (A-MSE: 0.08645) avg lploss: 0.00000
train epoch 1138 avg loss: 0.07900 (A-MSE: 0.07012) avg lploss: 0.00000
train epoch 1139 avg loss: 0.06173 (A-MSE: 0.05548) avg lploss: 0.00000
train epoch 1140 avg loss: 0.06933 (A-MSE: 0.06227) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.32797 (A-MSE: 0.28676) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.34806 (A-MSE: 0.30774) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 44 out of 50
train epoch 1141 avg loss: 0.06385 (A-MSE: 0.05690) avg lploss: 0.00000
train epoch 1142 avg loss: 0.06295 (A-MSE: 0.05654) avg lploss: 0.00000
train epoch 1143 avg loss: 0.05813 (A-MSE: 0.05204) avg lploss: 0.00000
train epoch 1144 avg loss: 0.07125 (A-MSE: 0.06412) avg lploss: 0.00000
train epoch 1145 avg loss: 0.07805 (A-MSE: 0.07007) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.38455 (A-MSE: 0.33372) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.44100 (A-MSE: 0.38706) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 45 out of 50
train epoch 1146 avg loss: 0.08438 (A-MSE: 0.07579) avg lploss: 0.00000
train epoch 1147 avg loss: 0.07315 (A-MSE: 0.06521) avg lploss: 0.00000
train epoch 1148 avg loss: 0.06460 (A-MSE: 0.05816) avg lploss: 0.00000
train epoch 1149 avg loss: 0.07851 (A-MSE: 0.07067) avg lploss: 0.00000
train epoch 1150 avg loss: 0.09724 (A-MSE: 0.08744) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.31886 (A-MSE: 0.28571) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.37983 (A-MSE: 0.33766) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 46 out of 50
train epoch 1151 avg loss: 0.09809 (A-MSE: 0.08756) avg lploss: 0.00000
train epoch 1152 avg loss: 0.07890 (A-MSE: 0.07080) avg lploss: 0.00000
train epoch 1153 avg loss: 0.07143 (A-MSE: 0.06428) avg lploss: 0.00000
train epoch 1154 avg loss: 0.06373 (A-MSE: 0.05653) avg lploss: 0.00000
train epoch 1155 avg loss: 0.06792 (A-MSE: 0.06131) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.36222 (A-MSE: 0.31687) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.39938 (A-MSE: 0.35388) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 47 out of 50
train epoch 1156 avg loss: 0.05789 (A-MSE: 0.05163) avg lploss: 0.00000
train epoch 1157 avg loss: 0.05746 (A-MSE: 0.05140) avg lploss: 0.00000
train epoch 1158 avg loss: 0.05986 (A-MSE: 0.05345) avg lploss: 0.00000
train epoch 1159 avg loss: 0.07278 (A-MSE: 0.06513) avg lploss: 0.00000
train epoch 1160 avg loss: 0.06436 (A-MSE: 0.05744) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.37193 (A-MSE: 0.32584) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.40302 (A-MSE: 0.35772) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 48 out of 50
train epoch 1161 avg loss: 0.06783 (A-MSE: 0.06055) avg lploss: 0.00000
train epoch 1162 avg loss: 0.06820 (A-MSE: 0.06146) avg lploss: 0.00000
train epoch 1163 avg loss: 0.06501 (A-MSE: 0.05794) avg lploss: 0.00000
train epoch 1164 avg loss: 0.06104 (A-MSE: 0.05485) avg lploss: 0.00000
train epoch 1165 avg loss: 0.07209 (A-MSE: 0.06435) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.36233 (A-MSE: 0.32397) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.41096 (A-MSE: 0.36789) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 49 out of 50
train epoch 1166 avg loss: 0.07814 (A-MSE: 0.06998) avg lploss: 0.00000
train epoch 1167 avg loss: 0.08111 (A-MSE: 0.07213) avg lploss: 0.00000
train epoch 1168 avg loss: 0.11669 (A-MSE: 0.10591) avg lploss: 0.00000
train epoch 1169 avg loss: 0.09579 (A-MSE: 0.08563) avg lploss: 0.00000
train epoch 1170 avg loss: 0.07936 (A-MSE: 0.07118) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.36320 (A-MSE: 0.32135) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.41721 (A-MSE: 0.37044) avg lploss: 0.00000
*** Best Val Loss: 0.29433 	 Best Test Loss: 0.37953 	 Best epoch 920
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.113534
best_lp = 0.000000
best_val = 0.294328
best_test = 0.379529
best_epoch = 920
best_train = 0.113534, best_lp = 0.000000, best_val = 0.294328, best_test = 0.379529, best_epoch = 920
Job completed at Sat Dec  6 08:18:12 CET 2025
