Date              = Mon Dec  8 23:11:23 CET 2025
Hostname          = mel2152
Array Task ID     = 3
Running config: configs/mocap_run_seed4.json
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_seed4.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_seed4', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_seed4/saved_model.pth
train epoch 0 avg loss: 214921.98033 (A-MSE: 196500.12199) avg lploss: 0.00000
==> val epoch 0 avg loss: 88.93692 (A-MSE: 78.28191) avg lploss: 0.00000
==> test epoch 0 avg loss: 84.73434 (A-MSE: 74.58917) avg lploss: 0.00000
*** Best Val Loss: 88.93692 	 Best Test Loss: 84.73434 	 Best epoch 0
Validation loss decreased (inf --> 88.936919).  Saving model ...
train epoch 1 avg loss: 85.81445 (A-MSE: 75.59195) avg lploss: 0.00000
train epoch 2 avg loss: 83.80721 (A-MSE: 73.82332) avg lploss: 0.00000
train epoch 3 avg loss: 80.25897 (A-MSE: 70.75857) avg lploss: 0.00000
train epoch 4 avg loss: 69.65211 (A-MSE: 61.04770) avg lploss: 0.00000
train epoch 5 avg loss: 51.34645 (A-MSE: 44.73093) avg lploss: 0.00000
==> val epoch 5 avg loss: 43.39359 (A-MSE: 37.82661) avg lploss: 0.00000
==> test epoch 5 avg loss: 40.88573 (A-MSE: 35.66209) avg lploss: 0.00000
*** Best Val Loss: 43.39359 	 Best Test Loss: 40.88573 	 Best epoch 5
Validation loss decreased (88.936919 --> 43.393585).  Saving model ...
train epoch 6 avg loss: 39.82729 (A-MSE: 34.53207) avg lploss: 0.00000
train epoch 7 avg loss: 33.89068 (A-MSE: 29.37389) avg lploss: 0.00000
train epoch 8 avg loss: 29.89696 (A-MSE: 25.85224) avg lploss: 0.00000
train epoch 9 avg loss: 27.34670 (A-MSE: 23.67585) avg lploss: 0.00000
train epoch 10 avg loss: 25.77961 (A-MSE: 22.39036) avg lploss: 0.00000
==> val epoch 10 avg loss: 25.30057 (A-MSE: 21.72405) avg lploss: 0.00000
==> test epoch 10 avg loss: 23.89239 (A-MSE: 20.45679) avg lploss: 0.00000
*** Best Val Loss: 25.30057 	 Best Test Loss: 23.89239 	 Best epoch 10
Validation loss decreased (43.393585 --> 25.300568).  Saving model ...
train epoch 11 avg loss: 24.38128 (A-MSE: 21.04752) avg lploss: 0.00000
train epoch 12 avg loss: 23.49021 (A-MSE: 20.36003) avg lploss: 0.00000
train epoch 13 avg loss: 22.35706 (A-MSE: 19.36706) avg lploss: 0.00000
train epoch 14 avg loss: 20.93318 (A-MSE: 18.14080) avg lploss: 0.00000
train epoch 15 avg loss: 20.28454 (A-MSE: 17.58570) avg lploss: 0.00000
==> val epoch 15 avg loss: 19.36270 (A-MSE: 16.60362) avg lploss: 0.00000
==> test epoch 15 avg loss: 18.37687 (A-MSE: 15.68853) avg lploss: 0.00000
*** Best Val Loss: 19.36270 	 Best Test Loss: 18.37687 	 Best epoch 15
Validation loss decreased (25.300568 --> 19.362698).  Saving model ...
train epoch 16 avg loss: 20.00729 (A-MSE: 17.37723) avg lploss: 0.00000
train epoch 17 avg loss: 19.55095 (A-MSE: 16.98998) avg lploss: 0.00000
train epoch 18 avg loss: 18.81596 (A-MSE: 16.33755) avg lploss: 0.00000
train epoch 19 avg loss: 17.79582 (A-MSE: 15.47046) avg lploss: 0.00000
train epoch 20 avg loss: 17.53839 (A-MSE: 15.27279) avg lploss: 0.00000
==> val epoch 20 avg loss: 18.58386 (A-MSE: 16.23957) avg lploss: 0.00000
==> test epoch 20 avg loss: 17.27878 (A-MSE: 14.98534) avg lploss: 0.00000
*** Best Val Loss: 18.58386 	 Best Test Loss: 17.27878 	 Best epoch 20
Validation loss decreased (19.362698 --> 18.583855).  Saving model ...
train epoch 21 avg loss: 17.15516 (A-MSE: 14.92706) avg lploss: 0.00000
train epoch 22 avg loss: 16.93602 (A-MSE: 14.76013) avg lploss: 0.00000
train epoch 23 avg loss: 16.30592 (A-MSE: 14.21904) avg lploss: 0.00000
train epoch 24 avg loss: 16.40464 (A-MSE: 14.30807) avg lploss: 0.00000
train epoch 25 avg loss: 16.22988 (A-MSE: 14.16068) avg lploss: 0.00000
==> val epoch 25 avg loss: 15.95500 (A-MSE: 13.76497) avg lploss: 0.00000
==> test epoch 25 avg loss: 15.11783 (A-MSE: 12.96558) avg lploss: 0.00000
*** Best Val Loss: 15.95500 	 Best Test Loss: 15.11783 	 Best epoch 25
Validation loss decreased (18.583855 --> 15.955003).  Saving model ...
train epoch 26 avg loss: 15.67394 (A-MSE: 13.69148) avg lploss: 0.00000
train epoch 27 avg loss: 15.28649 (A-MSE: 13.34858) avg lploss: 0.00000
train epoch 28 avg loss: 14.94641 (A-MSE: 13.06265) avg lploss: 0.00000
train epoch 29 avg loss: 14.94620 (A-MSE: 13.07027) avg lploss: 0.00000
train epoch 30 avg loss: 14.78848 (A-MSE: 12.92081) avg lploss: 0.00000
==> val epoch 30 avg loss: 14.74695 (A-MSE: 12.65478) avg lploss: 0.00000
==> test epoch 30 avg loss: 14.27223 (A-MSE: 12.22708) avg lploss: 0.00000
*** Best Val Loss: 14.74695 	 Best Test Loss: 14.27223 	 Best epoch 30
Validation loss decreased (15.955003 --> 14.746946).  Saving model ...
train epoch 31 avg loss: 14.29199 (A-MSE: 12.47830) avg lploss: 0.00000
train epoch 32 avg loss: 13.89146 (A-MSE: 12.12065) avg lploss: 0.00000
train epoch 33 avg loss: 13.83269 (A-MSE: 12.08754) avg lploss: 0.00000
train epoch 34 avg loss: 13.50533 (A-MSE: 11.77839) avg lploss: 0.00000
train epoch 35 avg loss: 13.13165 (A-MSE: 11.46591) avg lploss: 0.00000
==> val epoch 35 avg loss: 13.12679 (A-MSE: 11.34730) avg lploss: 0.00000
==> test epoch 35 avg loss: 12.80194 (A-MSE: 11.06371) avg lploss: 0.00000
*** Best Val Loss: 13.12679 	 Best Test Loss: 12.80194 	 Best epoch 35
Validation loss decreased (14.746946 --> 13.126791).  Saving model ...
train epoch 36 avg loss: 12.26231 (A-MSE: 10.68653) avg lploss: 0.00000
train epoch 37 avg loss: 12.24385 (A-MSE: 10.68796) avg lploss: 0.00000
train epoch 38 avg loss: 11.99478 (A-MSE: 10.45874) avg lploss: 0.00000
train epoch 39 avg loss: 12.64996 (A-MSE: 11.07012) avg lploss: 0.00000
train epoch 40 avg loss: 12.23779 (A-MSE: 10.72131) avg lploss: 0.00000
==> val epoch 40 avg loss: 11.95601 (A-MSE: 10.32378) avg lploss: 0.00000
==> test epoch 40 avg loss: 11.66143 (A-MSE: 10.05761) avg lploss: 0.00000
*** Best Val Loss: 11.95601 	 Best Test Loss: 11.66143 	 Best epoch 40
Validation loss decreased (13.126791 --> 11.956010).  Saving model ...
train epoch 41 avg loss: 11.36860 (A-MSE: 9.87678) avg lploss: 0.00000
train epoch 42 avg loss: 10.97813 (A-MSE: 9.61690) avg lploss: 0.00000
train epoch 43 avg loss: 10.79363 (A-MSE: 9.43043) avg lploss: 0.00000
train epoch 44 avg loss: 10.57122 (A-MSE: 9.20851) avg lploss: 0.00000
train epoch 45 avg loss: 10.39776 (A-MSE: 9.07886) avg lploss: 0.00000
==> val epoch 45 avg loss: 10.12464 (A-MSE: 8.76492) avg lploss: 0.00000
==> test epoch 45 avg loss: 9.96676 (A-MSE: 8.61999) avg lploss: 0.00000
*** Best Val Loss: 10.12464 	 Best Test Loss: 9.96676 	 Best epoch 45
Validation loss decreased (11.956010 --> 10.124640).  Saving model ...
train epoch 46 avg loss: 9.69833 (A-MSE: 8.45171) avg lploss: 0.00000
train epoch 47 avg loss: 10.19928 (A-MSE: 8.89826) avg lploss: 0.00000
train epoch 48 avg loss: 9.36168 (A-MSE: 8.16536) avg lploss: 0.00000
train epoch 49 avg loss: 8.81739 (A-MSE: 7.69076) avg lploss: 0.00000
train epoch 50 avg loss: 8.70545 (A-MSE: 7.55603) avg lploss: 0.00000
==> val epoch 50 avg loss: 8.48983 (A-MSE: 7.48664) avg lploss: 0.00000
==> test epoch 50 avg loss: 8.44841 (A-MSE: 7.42851) avg lploss: 0.00000
*** Best Val Loss: 8.48983 	 Best Test Loss: 8.44841 	 Best epoch 50
Validation loss decreased (10.124640 --> 8.489826).  Saving model ...
train epoch 51 avg loss: 8.25653 (A-MSE: 7.21400) avg lploss: 0.00000
train epoch 52 avg loss: 8.34188 (A-MSE: 7.26311) avg lploss: 0.00000
train epoch 53 avg loss: 8.45580 (A-MSE: 7.37094) avg lploss: 0.00000
train epoch 54 avg loss: 8.31882 (A-MSE: 7.26688) avg lploss: 0.00000
train epoch 55 avg loss: 8.05059 (A-MSE: 6.98969) avg lploss: 0.00000
==> val epoch 55 avg loss: 8.59870 (A-MSE: 7.62610) avg lploss: 0.00000
==> test epoch 55 avg loss: 8.31552 (A-MSE: 7.33605) avg lploss: 0.00000
*** Best Val Loss: 8.48983 	 Best Test Loss: 8.44841 	 Best epoch 50
EarlyStopping counter: 1 out of 50
train epoch 56 avg loss: 7.62032 (A-MSE: 6.66371) avg lploss: 0.00000
train epoch 57 avg loss: 7.73781 (A-MSE: 6.72993) avg lploss: 0.00000
train epoch 58 avg loss: 7.45548 (A-MSE: 6.53366) avg lploss: 0.00000
train epoch 59 avg loss: 7.32827 (A-MSE: 6.37276) avg lploss: 0.00000
train epoch 60 avg loss: 7.15805 (A-MSE: 6.25400) avg lploss: 0.00000
==> val epoch 60 avg loss: 8.30011 (A-MSE: 7.16783) avg lploss: 0.00000
==> test epoch 60 avg loss: 8.23081 (A-MSE: 7.10876) avg lploss: 0.00000
*** Best Val Loss: 8.30011 	 Best Test Loss: 8.23081 	 Best epoch 60
Validation loss decreased (8.489826 --> 8.300107).  Saving model ...
train epoch 61 avg loss: 7.22588 (A-MSE: 6.30381) avg lploss: 0.00000
train epoch 62 avg loss: 6.96889 (A-MSE: 6.09768) avg lploss: 0.00000
train epoch 63 avg loss: 7.69884 (A-MSE: 6.73315) avg lploss: 0.00000
train epoch 64 avg loss: 6.97632 (A-MSE: 6.07855) avg lploss: 0.00000
train epoch 65 avg loss: 6.74311 (A-MSE: 5.89930) avg lploss: 0.00000
==> val epoch 65 avg loss: 7.58357 (A-MSE: 6.81577) avg lploss: 0.00000
==> test epoch 65 avg loss: 7.32693 (A-MSE: 6.56127) avg lploss: 0.00000
*** Best Val Loss: 7.58357 	 Best Test Loss: 7.32693 	 Best epoch 65
Validation loss decreased (8.300107 --> 7.583565).  Saving model ...
train epoch 66 avg loss: 7.03057 (A-MSE: 6.15254) avg lploss: 0.00000
train epoch 67 avg loss: 6.77659 (A-MSE: 5.91343) avg lploss: 0.00000
train epoch 68 avg loss: 6.50071 (A-MSE: 5.68943) avg lploss: 0.00000
train epoch 69 avg loss: 6.85092 (A-MSE: 6.02602) avg lploss: 0.00000
train epoch 70 avg loss: 6.83554 (A-MSE: 5.98123) avg lploss: 0.00000
==> val epoch 70 avg loss: 7.39787 (A-MSE: 6.42479) avg lploss: 0.00000
==> test epoch 70 avg loss: 7.44133 (A-MSE: 6.45659) avg lploss: 0.00000
*** Best Val Loss: 7.39787 	 Best Test Loss: 7.44133 	 Best epoch 70
Validation loss decreased (7.583565 --> 7.397869).  Saving model ...
train epoch 71 avg loss: 6.49002 (A-MSE: 5.68866) avg lploss: 0.00000
train epoch 72 avg loss: 6.57959 (A-MSE: 5.73946) avg lploss: 0.00000
train epoch 73 avg loss: 6.59132 (A-MSE: 5.78797) avg lploss: 0.00000
train epoch 74 avg loss: 6.65783 (A-MSE: 5.84653) avg lploss: 0.00000
train epoch 75 avg loss: 6.49158 (A-MSE: 5.70670) avg lploss: 0.00000
==> val epoch 75 avg loss: 8.59606 (A-MSE: 7.49495) avg lploss: 0.00000
==> test epoch 75 avg loss: 8.49721 (A-MSE: 7.42476) avg lploss: 0.00000
*** Best Val Loss: 7.39787 	 Best Test Loss: 7.44133 	 Best epoch 70
EarlyStopping counter: 1 out of 50
train epoch 76 avg loss: 7.06160 (A-MSE: 6.19511) avg lploss: 0.00000
train epoch 77 avg loss: 6.18540 (A-MSE: 5.42040) avg lploss: 0.00000
train epoch 78 avg loss: 6.35804 (A-MSE: 5.57619) avg lploss: 0.00000
train epoch 79 avg loss: 6.06223 (A-MSE: 5.32927) avg lploss: 0.00000
train epoch 80 avg loss: 6.10486 (A-MSE: 5.34963) avg lploss: 0.00000
==> val epoch 80 avg loss: 7.20298 (A-MSE: 6.42761) avg lploss: 0.00000
==> test epoch 80 avg loss: 7.18948 (A-MSE: 6.41879) avg lploss: 0.00000
*** Best Val Loss: 7.20298 	 Best Test Loss: 7.18948 	 Best epoch 80
Validation loss decreased (7.397869 --> 7.202982).  Saving model ...
train epoch 81 avg loss: 6.00795 (A-MSE: 5.29206) avg lploss: 0.00000
train epoch 82 avg loss: 6.17252 (A-MSE: 5.43268) avg lploss: 0.00000
train epoch 83 avg loss: 6.33133 (A-MSE: 5.56023) avg lploss: 0.00000
train epoch 84 avg loss: 6.55674 (A-MSE: 5.78888) avg lploss: 0.00000
train epoch 85 avg loss: 6.22224 (A-MSE: 5.45870) avg lploss: 0.00000
==> val epoch 85 avg loss: 6.78011 (A-MSE: 5.93893) avg lploss: 0.00000
==> test epoch 85 avg loss: 6.53730 (A-MSE: 5.72387) avg lploss: 0.00000
*** Best Val Loss: 6.78011 	 Best Test Loss: 6.53730 	 Best epoch 85
Validation loss decreased (7.202982 --> 6.780113).  Saving model ...
train epoch 86 avg loss: 5.92376 (A-MSE: 5.21773) avg lploss: 0.00000
train epoch 87 avg loss: 5.78440 (A-MSE: 5.08377) avg lploss: 0.00000
train epoch 88 avg loss: 5.81391 (A-MSE: 5.11919) avg lploss: 0.00000
train epoch 89 avg loss: 6.00028 (A-MSE: 5.30548) avg lploss: 0.00000
train epoch 90 avg loss: 5.70607 (A-MSE: 5.00661) avg lploss: 0.00000
==> val epoch 90 avg loss: 6.31938 (A-MSE: 5.48735) avg lploss: 0.00000
==> test epoch 90 avg loss: 6.23879 (A-MSE: 5.44208) avg lploss: 0.00000
*** Best Val Loss: 6.31938 	 Best Test Loss: 6.23879 	 Best epoch 90
Validation loss decreased (6.780113 --> 6.319382).  Saving model ...
train epoch 91 avg loss: 5.64208 (A-MSE: 4.98277) avg lploss: 0.00000
train epoch 92 avg loss: 5.62700 (A-MSE: 4.96126) avg lploss: 0.00000
train epoch 93 avg loss: 5.53197 (A-MSE: 4.87881) avg lploss: 0.00000
train epoch 94 avg loss: 5.44469 (A-MSE: 4.77924) avg lploss: 0.00000
train epoch 95 avg loss: 5.35790 (A-MSE: 4.72188) avg lploss: 0.00000
==> val epoch 95 avg loss: 6.45075 (A-MSE: 5.73811) avg lploss: 0.00000
==> test epoch 95 avg loss: 6.33425 (A-MSE: 5.64321) avg lploss: 0.00000
*** Best Val Loss: 6.31938 	 Best Test Loss: 6.23879 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 5.33128 (A-MSE: 4.71605) avg lploss: 0.00000
train epoch 97 avg loss: 5.22923 (A-MSE: 4.61197) avg lploss: 0.00000
train epoch 98 avg loss: 5.21203 (A-MSE: 4.60465) avg lploss: 0.00000
train epoch 99 avg loss: 5.31340 (A-MSE: 4.67980) avg lploss: 0.00000
train epoch 100 avg loss: 5.49458 (A-MSE: 4.88291) avg lploss: 0.00000
==> val epoch 100 avg loss: 6.97767 (A-MSE: 6.03937) avg lploss: 0.00000
==> test epoch 100 avg loss: 6.78020 (A-MSE: 5.90326) avg lploss: 0.00000
*** Best Val Loss: 6.31938 	 Best Test Loss: 6.23879 	 Best epoch 90
EarlyStopping counter: 2 out of 50
train epoch 101 avg loss: 5.63050 (A-MSE: 4.96565) avg lploss: 0.00000
train epoch 102 avg loss: 5.36389 (A-MSE: 4.75233) avg lploss: 0.00000
train epoch 103 avg loss: 5.06169 (A-MSE: 4.46921) avg lploss: 0.00000
train epoch 104 avg loss: 4.96182 (A-MSE: 4.38957) avg lploss: 0.00000
train epoch 105 avg loss: 4.99719 (A-MSE: 4.41940) avg lploss: 0.00000
==> val epoch 105 avg loss: 6.46866 (A-MSE: 5.80214) avg lploss: 0.00000
==> test epoch 105 avg loss: 6.57015 (A-MSE: 5.93429) avg lploss: 0.00000
*** Best Val Loss: 6.31938 	 Best Test Loss: 6.23879 	 Best epoch 90
EarlyStopping counter: 3 out of 50
train epoch 106 avg loss: 4.77453 (A-MSE: 4.22336) avg lploss: 0.00000
train epoch 107 avg loss: 4.80857 (A-MSE: 4.24298) avg lploss: 0.00000
train epoch 108 avg loss: 4.75053 (A-MSE: 4.22429) avg lploss: 0.00000
train epoch 109 avg loss: 4.70704 (A-MSE: 4.17363) avg lploss: 0.00000
train epoch 110 avg loss: 4.82145 (A-MSE: 4.30475) avg lploss: 0.00000
==> val epoch 110 avg loss: 5.65482 (A-MSE: 5.06575) avg lploss: 0.00000
==> test epoch 110 avg loss: 5.58863 (A-MSE: 5.05083) avg lploss: 0.00000
*** Best Val Loss: 5.65482 	 Best Test Loss: 5.58863 	 Best epoch 110
Validation loss decreased (6.319382 --> 5.654816).  Saving model ...
train epoch 111 avg loss: 4.74675 (A-MSE: 4.20464) avg lploss: 0.00000
train epoch 112 avg loss: 4.76477 (A-MSE: 4.22903) avg lploss: 0.00000
train epoch 113 avg loss: 5.06147 (A-MSE: 4.49301) avg lploss: 0.00000
train epoch 114 avg loss: 4.81976 (A-MSE: 4.28157) avg lploss: 0.00000
train epoch 115 avg loss: 4.62840 (A-MSE: 4.09528) avg lploss: 0.00000
==> val epoch 115 avg loss: 5.91076 (A-MSE: 5.25803) avg lploss: 0.00000
==> test epoch 115 avg loss: 6.06833 (A-MSE: 5.47075) avg lploss: 0.00000
*** Best Val Loss: 5.65482 	 Best Test Loss: 5.58863 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 4.91361 (A-MSE: 4.36850) avg lploss: 0.00000
train epoch 117 avg loss: 4.53586 (A-MSE: 4.03331) avg lploss: 0.00000
train epoch 118 avg loss: 4.50125 (A-MSE: 4.01275) avg lploss: 0.00000
train epoch 119 avg loss: 4.90964 (A-MSE: 4.37925) avg lploss: 0.00000
train epoch 120 avg loss: 4.59023 (A-MSE: 4.09144) avg lploss: 0.00000
==> val epoch 120 avg loss: 5.07652 (A-MSE: 4.49996) avg lploss: 0.00000
==> test epoch 120 avg loss: 5.06824 (A-MSE: 4.55637) avg lploss: 0.00000
*** Best Val Loss: 5.07652 	 Best Test Loss: 5.06824 	 Best epoch 120
Validation loss decreased (5.654816 --> 5.076519).  Saving model ...
train epoch 121 avg loss: 4.34341 (A-MSE: 3.85846) avg lploss: 0.00000
train epoch 122 avg loss: 4.25792 (A-MSE: 3.79151) avg lploss: 0.00000
train epoch 123 avg loss: 4.13666 (A-MSE: 3.69182) avg lploss: 0.00000
train epoch 124 avg loss: 4.04283 (A-MSE: 3.60679) avg lploss: 0.00000
train epoch 125 avg loss: 4.02692 (A-MSE: 3.59642) avg lploss: 0.00000
==> val epoch 125 avg loss: 4.82322 (A-MSE: 4.31721) avg lploss: 0.00000
==> test epoch 125 avg loss: 4.78583 (A-MSE: 4.33208) avg lploss: 0.00000
*** Best Val Loss: 4.82322 	 Best Test Loss: 4.78583 	 Best epoch 125
Validation loss decreased (5.076519 --> 4.823223).  Saving model ...
train epoch 126 avg loss: 4.26532 (A-MSE: 3.80550) avg lploss: 0.00000
train epoch 127 avg loss: 4.16323 (A-MSE: 3.71802) avg lploss: 0.00000
train epoch 128 avg loss: 3.97954 (A-MSE: 3.54250) avg lploss: 0.00000
train epoch 129 avg loss: 3.91619 (A-MSE: 3.48933) avg lploss: 0.00000
train epoch 130 avg loss: 3.78971 (A-MSE: 3.39686) avg lploss: 0.00000
==> val epoch 130 avg loss: 4.79000 (A-MSE: 4.27359) avg lploss: 0.00000
==> test epoch 130 avg loss: 4.89014 (A-MSE: 4.43220) avg lploss: 0.00000
*** Best Val Loss: 4.79000 	 Best Test Loss: 4.89014 	 Best epoch 130
Validation loss decreased (4.823223 --> 4.789999).  Saving model ...
train epoch 131 avg loss: 4.11703 (A-MSE: 3.69272) avg lploss: 0.00000
train epoch 132 avg loss: 4.26616 (A-MSE: 3.78943) avg lploss: 0.00000
train epoch 133 avg loss: 4.00299 (A-MSE: 3.58244) avg lploss: 0.00000
train epoch 134 avg loss: 3.70615 (A-MSE: 3.31415) avg lploss: 0.00000
train epoch 135 avg loss: 3.79547 (A-MSE: 3.39473) avg lploss: 0.00000
==> val epoch 135 avg loss: 4.61435 (A-MSE: 4.18326) avg lploss: 0.00000
==> test epoch 135 avg loss: 4.61192 (A-MSE: 4.25397) avg lploss: 0.00000
*** Best Val Loss: 4.61435 	 Best Test Loss: 4.61192 	 Best epoch 135
Validation loss decreased (4.789999 --> 4.614349).  Saving model ...
train epoch 136 avg loss: 3.67780 (A-MSE: 3.28392) avg lploss: 0.00000
train epoch 137 avg loss: 3.55816 (A-MSE: 3.18177) avg lploss: 0.00000
train epoch 138 avg loss: 3.63460 (A-MSE: 3.23923) avg lploss: 0.00000
train epoch 139 avg loss: 3.70217 (A-MSE: 3.32822) avg lploss: 0.00000
train epoch 140 avg loss: 4.02818 (A-MSE: 3.61597) avg lploss: 0.00000
==> val epoch 140 avg loss: 4.56099 (A-MSE: 4.09941) avg lploss: 0.00000
==> test epoch 140 avg loss: 4.63074 (A-MSE: 4.21798) avg lploss: 0.00000
*** Best Val Loss: 4.56099 	 Best Test Loss: 4.63074 	 Best epoch 140
Validation loss decreased (4.614349 --> 4.560992).  Saving model ...
train epoch 141 avg loss: 4.03931 (A-MSE: 3.61037) avg lploss: 0.00000
train epoch 142 avg loss: 3.72700 (A-MSE: 3.34558) avg lploss: 0.00000
train epoch 143 avg loss: 3.48157 (A-MSE: 3.11542) avg lploss: 0.00000
train epoch 144 avg loss: 3.49163 (A-MSE: 3.12945) avg lploss: 0.00000
train epoch 145 avg loss: 3.54822 (A-MSE: 3.17285) avg lploss: 0.00000
==> val epoch 145 avg loss: 4.44084 (A-MSE: 4.05370) avg lploss: 0.00000
==> test epoch 145 avg loss: 4.70111 (A-MSE: 4.35113) avg lploss: 0.00000
*** Best Val Loss: 4.44084 	 Best Test Loss: 4.70111 	 Best epoch 145
Validation loss decreased (4.560992 --> 4.440843).  Saving model ...
train epoch 146 avg loss: 3.33855 (A-MSE: 3.00223) avg lploss: 0.00000
train epoch 147 avg loss: 3.51324 (A-MSE: 3.15203) avg lploss: 0.00000
train epoch 148 avg loss: 3.62834 (A-MSE: 3.24135) avg lploss: 0.00000
train epoch 149 avg loss: 3.88217 (A-MSE: 3.48589) avg lploss: 0.00000
train epoch 150 avg loss: 3.53356 (A-MSE: 3.16323) avg lploss: 0.00000
==> val epoch 150 avg loss: 4.30641 (A-MSE: 3.88037) avg lploss: 0.00000
==> test epoch 150 avg loss: 4.55673 (A-MSE: 4.17198) avg lploss: 0.00000
*** Best Val Loss: 4.30641 	 Best Test Loss: 4.55673 	 Best epoch 150
Validation loss decreased (4.440843 --> 4.306415).  Saving model ...
train epoch 151 avg loss: 3.25007 (A-MSE: 2.91216) avg lploss: 0.00000
train epoch 152 avg loss: 3.25637 (A-MSE: 2.91802) avg lploss: 0.00000
train epoch 153 avg loss: 3.44019 (A-MSE: 3.08574) avg lploss: 0.00000
train epoch 154 avg loss: 3.84239 (A-MSE: 3.43847) avg lploss: 0.00000
train epoch 155 avg loss: 3.40874 (A-MSE: 3.04840) avg lploss: 0.00000
==> val epoch 155 avg loss: 4.42482 (A-MSE: 3.94542) avg lploss: 0.00000
==> test epoch 155 avg loss: 4.59152 (A-MSE: 4.15781) avg lploss: 0.00000
*** Best Val Loss: 4.30641 	 Best Test Loss: 4.55673 	 Best epoch 150
EarlyStopping counter: 1 out of 50
train epoch 156 avg loss: 3.11424 (A-MSE: 2.78875) avg lploss: 0.00000
train epoch 157 avg loss: 3.26417 (A-MSE: 2.92433) avg lploss: 0.00000
train epoch 158 avg loss: 3.24617 (A-MSE: 2.91394) avg lploss: 0.00000
train epoch 159 avg loss: 3.65442 (A-MSE: 3.26819) avg lploss: 0.00000
train epoch 160 avg loss: 3.13247 (A-MSE: 2.80602) avg lploss: 0.00000
==> val epoch 160 avg loss: 4.20554 (A-MSE: 3.74110) avg lploss: 0.00000
==> test epoch 160 avg loss: 4.29477 (A-MSE: 3.86119) avg lploss: 0.00000
*** Best Val Loss: 4.20554 	 Best Test Loss: 4.29477 	 Best epoch 160
Validation loss decreased (4.306415 --> 4.205541).  Saving model ...
train epoch 161 avg loss: 3.30713 (A-MSE: 2.95499) avg lploss: 0.00000
train epoch 162 avg loss: 3.25811 (A-MSE: 2.92322) avg lploss: 0.00000
train epoch 163 avg loss: 3.03177 (A-MSE: 2.71504) avg lploss: 0.00000
train epoch 164 avg loss: 3.29799 (A-MSE: 2.95614) avg lploss: 0.00000
train epoch 165 avg loss: 3.05858 (A-MSE: 2.74630) avg lploss: 0.00000
==> val epoch 165 avg loss: 4.01820 (A-MSE: 3.60876) avg lploss: 0.00000
==> test epoch 165 avg loss: 4.10710 (A-MSE: 3.72840) avg lploss: 0.00000
*** Best Val Loss: 4.01820 	 Best Test Loss: 4.10710 	 Best epoch 165
Validation loss decreased (4.205541 --> 4.018202).  Saving model ...
train epoch 166 avg loss: 3.01691 (A-MSE: 2.70189) avg lploss: 0.00000
train epoch 167 avg loss: 3.11948 (A-MSE: 2.79263) avg lploss: 0.00000
train epoch 168 avg loss: 2.95914 (A-MSE: 2.65399) avg lploss: 0.00000
train epoch 169 avg loss: 2.91369 (A-MSE: 2.61215) avg lploss: 0.00000
train epoch 170 avg loss: 3.02625 (A-MSE: 2.70809) avg lploss: 0.00000
==> val epoch 170 avg loss: 4.03519 (A-MSE: 3.58481) avg lploss: 0.00000
==> test epoch 170 avg loss: 4.25083 (A-MSE: 3.81131) avg lploss: 0.00000
*** Best Val Loss: 4.01820 	 Best Test Loss: 4.10710 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 2.77731 (A-MSE: 2.48735) avg lploss: 0.00000
train epoch 172 avg loss: 2.86439 (A-MSE: 2.56388) avg lploss: 0.00000
train epoch 173 avg loss: 2.91305 (A-MSE: 2.60962) avg lploss: 0.00000
train epoch 174 avg loss: 2.76138 (A-MSE: 2.47695) avg lploss: 0.00000
train epoch 175 avg loss: 2.86136 (A-MSE: 2.56345) avg lploss: 0.00000
==> val epoch 175 avg loss: 4.17831 (A-MSE: 3.70825) avg lploss: 0.00000
==> test epoch 175 avg loss: 4.45497 (A-MSE: 3.98736) avg lploss: 0.00000
*** Best Val Loss: 4.01820 	 Best Test Loss: 4.10710 	 Best epoch 165
EarlyStopping counter: 2 out of 50
train epoch 176 avg loss: 3.23563 (A-MSE: 2.90470) avg lploss: 0.00000
train epoch 177 avg loss: 2.80860 (A-MSE: 2.50163) avg lploss: 0.00000
train epoch 178 avg loss: 3.05680 (A-MSE: 2.74005) avg lploss: 0.00000
train epoch 179 avg loss: 3.18675 (A-MSE: 2.85420) avg lploss: 0.00000
train epoch 180 avg loss: 3.58278 (A-MSE: 3.21227) avg lploss: 0.00000
==> val epoch 180 avg loss: 4.68753 (A-MSE: 4.16532) avg lploss: 0.00000
==> test epoch 180 avg loss: 4.80487 (A-MSE: 4.32228) avg lploss: 0.00000
*** Best Val Loss: 4.01820 	 Best Test Loss: 4.10710 	 Best epoch 165
EarlyStopping counter: 3 out of 50
train epoch 181 avg loss: 3.20121 (A-MSE: 2.86890) avg lploss: 0.00000
train epoch 182 avg loss: 2.93176 (A-MSE: 2.62703) avg lploss: 0.00000
train epoch 183 avg loss: 2.59327 (A-MSE: 2.32663) avg lploss: 0.00000
train epoch 184 avg loss: 2.86202 (A-MSE: 2.56102) avg lploss: 0.00000
train epoch 185 avg loss: 2.77119 (A-MSE: 2.48631) avg lploss: 0.00000
==> val epoch 185 avg loss: 4.06976 (A-MSE: 3.61647) avg lploss: 0.00000
==> test epoch 185 avg loss: 4.26809 (A-MSE: 3.82547) avg lploss: 0.00000
*** Best Val Loss: 4.01820 	 Best Test Loss: 4.10710 	 Best epoch 165
EarlyStopping counter: 4 out of 50
train epoch 186 avg loss: 2.59374 (A-MSE: 2.32431) avg lploss: 0.00000
train epoch 187 avg loss: 2.81773 (A-MSE: 2.52215) avg lploss: 0.00000
train epoch 188 avg loss: 3.26548 (A-MSE: 2.92104) avg lploss: 0.00000
train epoch 189 avg loss: 2.89795 (A-MSE: 2.59546) avg lploss: 0.00000
train epoch 190 avg loss: 2.78996 (A-MSE: 2.50250) avg lploss: 0.00000
==> val epoch 190 avg loss: 3.48381 (A-MSE: 3.13231) avg lploss: 0.00000
==> test epoch 190 avg loss: 3.60878 (A-MSE: 3.27409) avg lploss: 0.00000
*** Best Val Loss: 3.48381 	 Best Test Loss: 3.60878 	 Best epoch 190
Validation loss decreased (4.018202 --> 3.483814).  Saving model ...
train epoch 191 avg loss: 2.69932 (A-MSE: 2.41365) avg lploss: 0.00000
train epoch 192 avg loss: 2.72318 (A-MSE: 2.45559) avg lploss: 0.00000
train epoch 193 avg loss: 2.56027 (A-MSE: 2.28904) avg lploss: 0.00000
train epoch 194 avg loss: 2.55041 (A-MSE: 2.28637) avg lploss: 0.00000
train epoch 195 avg loss: 2.84245 (A-MSE: 2.55491) avg lploss: 0.00000
==> val epoch 195 avg loss: 3.94143 (A-MSE: 3.49004) avg lploss: 0.00000
==> test epoch 195 avg loss: 4.01198 (A-MSE: 3.58078) avg lploss: 0.00000
*** Best Val Loss: 3.48381 	 Best Test Loss: 3.60878 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 2.53575 (A-MSE: 2.26176) avg lploss: 0.00000
train epoch 197 avg loss: 2.60714 (A-MSE: 2.33266) avg lploss: 0.00000
train epoch 198 avg loss: 2.50886 (A-MSE: 2.23615) avg lploss: 0.00000
train epoch 199 avg loss: 2.58064 (A-MSE: 2.30601) avg lploss: 0.00000
train epoch 200 avg loss: 2.55568 (A-MSE: 2.29042) avg lploss: 0.00000
==> val epoch 200 avg loss: 3.38123 (A-MSE: 2.98192) avg lploss: 0.00000
==> test epoch 200 avg loss: 3.41037 (A-MSE: 3.03842) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
Validation loss decreased (3.483814 --> 3.381233).  Saving model ...
train epoch 201 avg loss: 2.33550 (A-MSE: 2.09285) avg lploss: 0.00000
train epoch 202 avg loss: 2.32417 (A-MSE: 2.07910) avg lploss: 0.00000
train epoch 203 avg loss: 2.61221 (A-MSE: 2.33491) avg lploss: 0.00000
train epoch 204 avg loss: 2.63198 (A-MSE: 2.36258) avg lploss: 0.00000
train epoch 205 avg loss: 2.60155 (A-MSE: 2.32408) avg lploss: 0.00000
==> val epoch 205 avg loss: 3.68115 (A-MSE: 3.31844) avg lploss: 0.00000
==> test epoch 205 avg loss: 3.81252 (A-MSE: 3.45181) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 2.43992 (A-MSE: 2.18151) avg lploss: 0.00000
train epoch 207 avg loss: 2.49087 (A-MSE: 2.22655) avg lploss: 0.00000
train epoch 208 avg loss: 2.53797 (A-MSE: 2.26998) avg lploss: 0.00000
train epoch 209 avg loss: 2.58654 (A-MSE: 2.31329) avg lploss: 0.00000
train epoch 210 avg loss: 2.44352 (A-MSE: 2.18884) avg lploss: 0.00000
==> val epoch 210 avg loss: 3.76311 (A-MSE: 3.36634) avg lploss: 0.00000
==> test epoch 210 avg loss: 3.82911 (A-MSE: 3.45732) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
EarlyStopping counter: 2 out of 50
train epoch 211 avg loss: 2.39483 (A-MSE: 2.13680) avg lploss: 0.00000
train epoch 212 avg loss: 2.42937 (A-MSE: 2.17928) avg lploss: 0.00000
train epoch 213 avg loss: 2.32957 (A-MSE: 2.09208) avg lploss: 0.00000
train epoch 214 avg loss: 2.36610 (A-MSE: 2.11612) avg lploss: 0.00000
train epoch 215 avg loss: 2.26701 (A-MSE: 2.02093) avg lploss: 0.00000
==> val epoch 215 avg loss: 3.58078 (A-MSE: 3.19349) avg lploss: 0.00000
==> test epoch 215 avg loss: 3.66894 (A-MSE: 3.28876) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
EarlyStopping counter: 3 out of 50
train epoch 216 avg loss: 2.54261 (A-MSE: 2.28256) avg lploss: 0.00000
train epoch 217 avg loss: 2.49305 (A-MSE: 2.23276) avg lploss: 0.00000
train epoch 218 avg loss: 2.41865 (A-MSE: 2.16799) avg lploss: 0.00000
train epoch 219 avg loss: 2.33254 (A-MSE: 2.07931) avg lploss: 0.00000
train epoch 220 avg loss: 2.25607 (A-MSE: 2.01341) avg lploss: 0.00000
==> val epoch 220 avg loss: 3.91380 (A-MSE: 3.45109) avg lploss: 0.00000
==> test epoch 220 avg loss: 4.19854 (A-MSE: 3.73835) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
EarlyStopping counter: 4 out of 50
train epoch 221 avg loss: 2.52152 (A-MSE: 2.25477) avg lploss: 0.00000
train epoch 222 avg loss: 2.73367 (A-MSE: 2.44565) avg lploss: 0.00000
train epoch 223 avg loss: 2.27179 (A-MSE: 2.02800) avg lploss: 0.00000
train epoch 224 avg loss: 2.28294 (A-MSE: 2.04118) avg lploss: 0.00000
train epoch 225 avg loss: 2.37617 (A-MSE: 2.13041) avg lploss: 0.00000
==> val epoch 225 avg loss: 3.52396 (A-MSE: 3.11112) avg lploss: 0.00000
==> test epoch 225 avg loss: 3.65610 (A-MSE: 3.24551) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
EarlyStopping counter: 5 out of 50
train epoch 226 avg loss: 2.41446 (A-MSE: 2.16285) avg lploss: 0.00000
train epoch 227 avg loss: 2.42954 (A-MSE: 2.17562) avg lploss: 0.00000
train epoch 228 avg loss: 2.26147 (A-MSE: 2.02215) avg lploss: 0.00000
train epoch 229 avg loss: 2.11511 (A-MSE: 1.88949) avg lploss: 0.00000
train epoch 230 avg loss: 2.00985 (A-MSE: 1.79631) avg lploss: 0.00000
==> val epoch 230 avg loss: 4.13916 (A-MSE: 3.69845) avg lploss: 0.00000
==> test epoch 230 avg loss: 4.41975 (A-MSE: 3.97193) avg lploss: 0.00000
*** Best Val Loss: 3.38123 	 Best Test Loss: 3.41037 	 Best epoch 200
EarlyStopping counter: 6 out of 50
train epoch 231 avg loss: 2.29869 (A-MSE: 2.04786) avg lploss: 0.00000
train epoch 232 avg loss: 2.35915 (A-MSE: 2.11507) avg lploss: 0.00000
train epoch 233 avg loss: 2.27667 (A-MSE: 2.03134) avg lploss: 0.00000
train epoch 234 avg loss: 2.15530 (A-MSE: 1.92578) avg lploss: 0.00000
train epoch 235 avg loss: 2.09425 (A-MSE: 1.87263) avg lploss: 0.00000
==> val epoch 235 avg loss: 2.97031 (A-MSE: 2.64355) avg lploss: 0.00000
==> test epoch 235 avg loss: 3.15004 (A-MSE: 2.82889) avg lploss: 0.00000
*** Best Val Loss: 2.97031 	 Best Test Loss: 3.15004 	 Best epoch 235
Validation loss decreased (3.381233 --> 2.970313).  Saving model ...
train epoch 236 avg loss: 2.00957 (A-MSE: 1.79183) avg lploss: 0.00000
train epoch 237 avg loss: 2.25998 (A-MSE: 2.01979) avg lploss: 0.00000
train epoch 238 avg loss: 2.56590 (A-MSE: 2.29154) avg lploss: 0.00000
train epoch 239 avg loss: 2.08254 (A-MSE: 1.85673) avg lploss: 0.00000
train epoch 240 avg loss: 2.11822 (A-MSE: 1.88913) avg lploss: 0.00000
==> val epoch 240 avg loss: 3.43681 (A-MSE: 3.08036) avg lploss: 0.00000
==> test epoch 240 avg loss: 3.54322 (A-MSE: 3.19939) avg lploss: 0.00000
*** Best Val Loss: 2.97031 	 Best Test Loss: 3.15004 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 2.22358 (A-MSE: 1.99399) avg lploss: 0.00000
train epoch 242 avg loss: 2.04511 (A-MSE: 1.82314) avg lploss: 0.00000
train epoch 243 avg loss: 2.02942 (A-MSE: 1.81050) avg lploss: 0.00000
train epoch 244 avg loss: 2.17639 (A-MSE: 1.93502) avg lploss: 0.00000
train epoch 245 avg loss: 2.50801 (A-MSE: 2.25251) avg lploss: 0.00000
==> val epoch 245 avg loss: 3.27494 (A-MSE: 2.92654) avg lploss: 0.00000
==> test epoch 245 avg loss: 3.54781 (A-MSE: 3.19457) avg lploss: 0.00000
*** Best Val Loss: 2.97031 	 Best Test Loss: 3.15004 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 2.09678 (A-MSE: 1.86576) avg lploss: 0.00000
train epoch 247 avg loss: 2.21852 (A-MSE: 1.98355) avg lploss: 0.00000
train epoch 248 avg loss: 2.13441 (A-MSE: 1.90910) avg lploss: 0.00000
train epoch 249 avg loss: 2.22987 (A-MSE: 1.99210) avg lploss: 0.00000
train epoch 250 avg loss: 2.14734 (A-MSE: 1.91269) avg lploss: 0.00000
==> val epoch 250 avg loss: 3.07427 (A-MSE: 2.74130) avg lploss: 0.00000
==> test epoch 250 avg loss: 3.28189 (A-MSE: 2.94085) avg lploss: 0.00000
*** Best Val Loss: 2.97031 	 Best Test Loss: 3.15004 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 1.89163 (A-MSE: 1.68885) avg lploss: 0.00000
train epoch 252 avg loss: 2.09178 (A-MSE: 1.86671) avg lploss: 0.00000
train epoch 253 avg loss: 2.05859 (A-MSE: 1.83873) avg lploss: 0.00000
train epoch 254 avg loss: 2.02661 (A-MSE: 1.80797) avg lploss: 0.00000
train epoch 255 avg loss: 2.11471 (A-MSE: 1.88935) avg lploss: 0.00000
==> val epoch 255 avg loss: 2.93264 (A-MSE: 2.60585) avg lploss: 0.00000
==> test epoch 255 avg loss: 3.04093 (A-MSE: 2.72305) avg lploss: 0.00000
*** Best Val Loss: 2.93264 	 Best Test Loss: 3.04093 	 Best epoch 255
Validation loss decreased (2.970313 --> 2.932640).  Saving model ...
train epoch 256 avg loss: 2.30626 (A-MSE: 2.05529) avg lploss: 0.00000
train epoch 257 avg loss: 2.15647 (A-MSE: 1.91940) avg lploss: 0.00000
train epoch 258 avg loss: 1.89890 (A-MSE: 1.69334) avg lploss: 0.00000
train epoch 259 avg loss: 2.00574 (A-MSE: 1.79081) avg lploss: 0.00000
train epoch 260 avg loss: 1.95801 (A-MSE: 1.75005) avg lploss: 0.00000
==> val epoch 260 avg loss: 3.03247 (A-MSE: 2.69317) avg lploss: 0.00000
==> test epoch 260 avg loss: 3.24488 (A-MSE: 2.89431) avg lploss: 0.00000
*** Best Val Loss: 2.93264 	 Best Test Loss: 3.04093 	 Best epoch 255
EarlyStopping counter: 1 out of 50
train epoch 261 avg loss: 2.02547 (A-MSE: 1.80708) avg lploss: 0.00000
train epoch 262 avg loss: 1.97890 (A-MSE: 1.76772) avg lploss: 0.00000
train epoch 263 avg loss: 1.85975 (A-MSE: 1.65697) avg lploss: 0.00000
train epoch 264 avg loss: 1.85517 (A-MSE: 1.65473) avg lploss: 0.00000
train epoch 265 avg loss: 1.86007 (A-MSE: 1.65676) avg lploss: 0.00000
==> val epoch 265 avg loss: 2.97404 (A-MSE: 2.65312) avg lploss: 0.00000
==> test epoch 265 avg loss: 3.14432 (A-MSE: 2.82213) avg lploss: 0.00000
*** Best Val Loss: 2.93264 	 Best Test Loss: 3.04093 	 Best epoch 255
EarlyStopping counter: 2 out of 50
train epoch 266 avg loss: 1.91547 (A-MSE: 1.70719) avg lploss: 0.00000
train epoch 267 avg loss: 1.95654 (A-MSE: 1.75235) avg lploss: 0.00000
train epoch 268 avg loss: 1.77774 (A-MSE: 1.58683) avg lploss: 0.00000
train epoch 269 avg loss: 1.80005 (A-MSE: 1.61297) avg lploss: 0.00000
train epoch 270 avg loss: 1.87287 (A-MSE: 1.66679) avg lploss: 0.00000
==> val epoch 270 avg loss: 3.00728 (A-MSE: 2.67762) avg lploss: 0.00000
==> test epoch 270 avg loss: 3.27752 (A-MSE: 2.95113) avg lploss: 0.00000
*** Best Val Loss: 2.93264 	 Best Test Loss: 3.04093 	 Best epoch 255
EarlyStopping counter: 3 out of 50
train epoch 271 avg loss: 1.85188 (A-MSE: 1.65040) avg lploss: 0.00000
train epoch 272 avg loss: 1.79441 (A-MSE: 1.60417) avg lploss: 0.00000
train epoch 273 avg loss: 1.92309 (A-MSE: 1.71389) avg lploss: 0.00000
train epoch 274 avg loss: 1.90138 (A-MSE: 1.68967) avg lploss: 0.00000
train epoch 275 avg loss: 1.85763 (A-MSE: 1.66156) avg lploss: 0.00000
==> val epoch 275 avg loss: 2.78188 (A-MSE: 2.45938) avg lploss: 0.00000
==> test epoch 275 avg loss: 3.02782 (A-MSE: 2.69528) avg lploss: 0.00000
*** Best Val Loss: 2.78188 	 Best Test Loss: 3.02782 	 Best epoch 275
Validation loss decreased (2.932640 --> 2.781880).  Saving model ...
train epoch 276 avg loss: 1.79519 (A-MSE: 1.59877) avg lploss: 0.00000
train epoch 277 avg loss: 1.89721 (A-MSE: 1.69167) avg lploss: 0.00000
train epoch 278 avg loss: 1.87960 (A-MSE: 1.67490) avg lploss: 0.00000
train epoch 279 avg loss: 2.10373 (A-MSE: 1.87713) avg lploss: 0.00000
train epoch 280 avg loss: 2.22809 (A-MSE: 1.99444) avg lploss: 0.00000
==> val epoch 280 avg loss: 2.79673 (A-MSE: 2.49353) avg lploss: 0.00000
==> test epoch 280 avg loss: 2.98362 (A-MSE: 2.67682) avg lploss: 0.00000
*** Best Val Loss: 2.78188 	 Best Test Loss: 3.02782 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 1.99524 (A-MSE: 1.77920) avg lploss: 0.00000
train epoch 282 avg loss: 1.96468 (A-MSE: 1.76011) avg lploss: 0.00000
train epoch 283 avg loss: 1.70455 (A-MSE: 1.52041) avg lploss: 0.00000
train epoch 284 avg loss: 1.90203 (A-MSE: 1.69765) avg lploss: 0.00000
train epoch 285 avg loss: 1.86263 (A-MSE: 1.66009) avg lploss: 0.00000
==> val epoch 285 avg loss: 3.18308 (A-MSE: 2.85713) avg lploss: 0.00000
==> test epoch 285 avg loss: 3.38489 (A-MSE: 3.05864) avg lploss: 0.00000
*** Best Val Loss: 2.78188 	 Best Test Loss: 3.02782 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 1.92489 (A-MSE: 1.71735) avg lploss: 0.00000
train epoch 287 avg loss: 1.80767 (A-MSE: 1.61246) avg lploss: 0.00000
train epoch 288 avg loss: 1.76338 (A-MSE: 1.57706) avg lploss: 0.00000
train epoch 289 avg loss: 1.70684 (A-MSE: 1.52031) avg lploss: 0.00000
train epoch 290 avg loss: 1.64942 (A-MSE: 1.47427) avg lploss: 0.00000
==> val epoch 290 avg loss: 2.64525 (A-MSE: 2.34511) avg lploss: 0.00000
==> test epoch 290 avg loss: 2.76449 (A-MSE: 2.47012) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
Validation loss decreased (2.781880 --> 2.645249).  Saving model ...
train epoch 291 avg loss: 2.17976 (A-MSE: 1.95148) avg lploss: 0.00000
train epoch 292 avg loss: 1.91488 (A-MSE: 1.71060) avg lploss: 0.00000
train epoch 293 avg loss: 1.81024 (A-MSE: 1.61142) avg lploss: 0.00000
train epoch 294 avg loss: 1.83908 (A-MSE: 1.64353) avg lploss: 0.00000
train epoch 295 avg loss: 1.84346 (A-MSE: 1.64583) avg lploss: 0.00000
==> val epoch 295 avg loss: 3.05225 (A-MSE: 2.70300) avg lploss: 0.00000
==> test epoch 295 avg loss: 3.22483 (A-MSE: 2.87409) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 1.90062 (A-MSE: 1.69379) avg lploss: 0.00000
train epoch 297 avg loss: 1.76476 (A-MSE: 1.57404) avg lploss: 0.00000
train epoch 298 avg loss: 1.87012 (A-MSE: 1.66921) avg lploss: 0.00000
train epoch 299 avg loss: 1.65852 (A-MSE: 1.48413) avg lploss: 0.00000
train epoch 300 avg loss: 1.72848 (A-MSE: 1.53886) avg lploss: 0.00000
==> val epoch 300 avg loss: 2.71045 (A-MSE: 2.41335) avg lploss: 0.00000
==> test epoch 300 avg loss: 2.90285 (A-MSE: 2.60712) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 1.72050 (A-MSE: 1.54198) avg lploss: 0.00000
train epoch 302 avg loss: 1.80724 (A-MSE: 1.61036) avg lploss: 0.00000
train epoch 303 avg loss: 1.73360 (A-MSE: 1.54333) avg lploss: 0.00000
train epoch 304 avg loss: 1.64760 (A-MSE: 1.47049) avg lploss: 0.00000
train epoch 305 avg loss: 1.68661 (A-MSE: 1.49640) avg lploss: 0.00000
==> val epoch 305 avg loss: 2.83104 (A-MSE: 2.51589) avg lploss: 0.00000
==> test epoch 305 avg loss: 3.12678 (A-MSE: 2.79655) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 3 out of 50
train epoch 306 avg loss: 1.65469 (A-MSE: 1.47433) avg lploss: 0.00000
train epoch 307 avg loss: 1.79645 (A-MSE: 1.60237) avg lploss: 0.00000
train epoch 308 avg loss: 1.82143 (A-MSE: 1.62892) avg lploss: 0.00000
train epoch 309 avg loss: 1.60444 (A-MSE: 1.42922) avg lploss: 0.00000
train epoch 310 avg loss: 1.64335 (A-MSE: 1.46515) avg lploss: 0.00000
==> val epoch 310 avg loss: 3.05559 (A-MSE: 2.73360) avg lploss: 0.00000
==> test epoch 310 avg loss: 3.32409 (A-MSE: 2.99309) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 4 out of 50
train epoch 311 avg loss: 1.67185 (A-MSE: 1.49681) avg lploss: 0.00000
train epoch 312 avg loss: 1.64845 (A-MSE: 1.47015) avg lploss: 0.00000
train epoch 313 avg loss: 1.58921 (A-MSE: 1.42410) avg lploss: 0.00000
train epoch 314 avg loss: 1.59089 (A-MSE: 1.41812) avg lploss: 0.00000
train epoch 315 avg loss: 1.75299 (A-MSE: 1.56334) avg lploss: 0.00000
==> val epoch 315 avg loss: 2.99031 (A-MSE: 2.69045) avg lploss: 0.00000
==> test epoch 315 avg loss: 3.36477 (A-MSE: 3.04899) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 5 out of 50
train epoch 316 avg loss: 1.75105 (A-MSE: 1.56986) avg lploss: 0.00000
train epoch 317 avg loss: 1.68970 (A-MSE: 1.50507) avg lploss: 0.00000
train epoch 318 avg loss: 1.83473 (A-MSE: 1.64433) avg lploss: 0.00000
train epoch 319 avg loss: 1.75662 (A-MSE: 1.57408) avg lploss: 0.00000
train epoch 320 avg loss: 2.21392 (A-MSE: 1.98388) avg lploss: 0.00000
==> val epoch 320 avg loss: 3.90217 (A-MSE: 3.45317) avg lploss: 0.00000
==> test epoch 320 avg loss: 3.92290 (A-MSE: 3.50449) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 6 out of 50
train epoch 321 avg loss: 2.33911 (A-MSE: 2.08053) avg lploss: 0.00000
train epoch 322 avg loss: 1.93127 (A-MSE: 1.71872) avg lploss: 0.00000
train epoch 323 avg loss: 1.52178 (A-MSE: 1.35737) avg lploss: 0.00000
train epoch 324 avg loss: 1.62410 (A-MSE: 1.45563) avg lploss: 0.00000
train epoch 325 avg loss: 1.79293 (A-MSE: 1.59623) avg lploss: 0.00000
==> val epoch 325 avg loss: 2.74876 (A-MSE: 2.48380) avg lploss: 0.00000
==> test epoch 325 avg loss: 3.06586 (A-MSE: 2.79950) avg lploss: 0.00000
*** Best Val Loss: 2.64525 	 Best Test Loss: 2.76449 	 Best epoch 290
EarlyStopping counter: 7 out of 50
train epoch 326 avg loss: 1.59940 (A-MSE: 1.42738) avg lploss: 0.00000
train epoch 327 avg loss: 1.51873 (A-MSE: 1.35422) avg lploss: 0.00000
train epoch 328 avg loss: 1.46261 (A-MSE: 1.30518) avg lploss: 0.00000
train epoch 329 avg loss: 1.49387 (A-MSE: 1.32890) avg lploss: 0.00000
train epoch 330 avg loss: 1.59857 (A-MSE: 1.42751) avg lploss: 0.00000
==> val epoch 330 avg loss: 2.30166 (A-MSE: 2.06155) avg lploss: 0.00000
==> test epoch 330 avg loss: 2.59397 (A-MSE: 2.33961) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
Validation loss decreased (2.645249 --> 2.301656).  Saving model ...
train epoch 331 avg loss: 1.62129 (A-MSE: 1.44389) avg lploss: 0.00000
train epoch 332 avg loss: 1.57977 (A-MSE: 1.41135) avg lploss: 0.00000
train epoch 333 avg loss: 1.56667 (A-MSE: 1.39296) avg lploss: 0.00000
train epoch 334 avg loss: 1.55049 (A-MSE: 1.38228) avg lploss: 0.00000
train epoch 335 avg loss: 1.70455 (A-MSE: 1.51919) avg lploss: 0.00000
==> val epoch 335 avg loss: 3.11613 (A-MSE: 2.81013) avg lploss: 0.00000
==> test epoch 335 avg loss: 3.43193 (A-MSE: 3.11205) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 1 out of 50
train epoch 336 avg loss: 1.66962 (A-MSE: 1.48876) avg lploss: 0.00000
train epoch 337 avg loss: 1.71366 (A-MSE: 1.53107) avg lploss: 0.00000
train epoch 338 avg loss: 1.55253 (A-MSE: 1.38451) avg lploss: 0.00000
train epoch 339 avg loss: 1.51444 (A-MSE: 1.35093) avg lploss: 0.00000
train epoch 340 avg loss: 1.48262 (A-MSE: 1.32512) avg lploss: 0.00000
==> val epoch 340 avg loss: 2.54779 (A-MSE: 2.27992) avg lploss: 0.00000
==> test epoch 340 avg loss: 2.92209 (A-MSE: 2.63435) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 2 out of 50
train epoch 341 avg loss: 1.71380 (A-MSE: 1.52951) avg lploss: 0.00000
train epoch 342 avg loss: 1.58204 (A-MSE: 1.41254) avg lploss: 0.00000
train epoch 343 avg loss: 1.44056 (A-MSE: 1.28241) avg lploss: 0.00000
train epoch 344 avg loss: 1.37350 (A-MSE: 1.22614) avg lploss: 0.00000
train epoch 345 avg loss: 1.34752 (A-MSE: 1.19945) avg lploss: 0.00000
==> val epoch 345 avg loss: 2.37728 (A-MSE: 2.13165) avg lploss: 0.00000
==> test epoch 345 avg loss: 2.59510 (A-MSE: 2.34223) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 3 out of 50
train epoch 346 avg loss: 1.41797 (A-MSE: 1.27172) avg lploss: 0.00000
train epoch 347 avg loss: 1.48353 (A-MSE: 1.32044) avg lploss: 0.00000
train epoch 348 avg loss: 1.53645 (A-MSE: 1.36844) avg lploss: 0.00000
train epoch 349 avg loss: 1.67149 (A-MSE: 1.49742) avg lploss: 0.00000
train epoch 350 avg loss: 1.51710 (A-MSE: 1.34909) avg lploss: 0.00000
==> val epoch 350 avg loss: 3.00509 (A-MSE: 2.68611) avg lploss: 0.00000
==> test epoch 350 avg loss: 3.30557 (A-MSE: 2.97523) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 4 out of 50
train epoch 351 avg loss: 1.60982 (A-MSE: 1.43966) avg lploss: 0.00000
train epoch 352 avg loss: 1.65192 (A-MSE: 1.47855) avg lploss: 0.00000
train epoch 353 avg loss: 1.55518 (A-MSE: 1.38805) avg lploss: 0.00000
train epoch 354 avg loss: 1.52136 (A-MSE: 1.35667) avg lploss: 0.00000
train epoch 355 avg loss: 1.52047 (A-MSE: 1.35513) avg lploss: 0.00000
==> val epoch 355 avg loss: 3.03911 (A-MSE: 2.71588) avg lploss: 0.00000
==> test epoch 355 avg loss: 3.24131 (A-MSE: 2.92024) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 5 out of 50
train epoch 356 avg loss: 1.50755 (A-MSE: 1.34771) avg lploss: 0.00000
train epoch 357 avg loss: 1.36171 (A-MSE: 1.20887) avg lploss: 0.00000
train epoch 358 avg loss: 1.33084 (A-MSE: 1.18386) avg lploss: 0.00000
train epoch 359 avg loss: 1.40424 (A-MSE: 1.25330) avg lploss: 0.00000
train epoch 360 avg loss: 1.41671 (A-MSE: 1.25772) avg lploss: 0.00000
==> val epoch 360 avg loss: 2.49164 (A-MSE: 2.23662) avg lploss: 0.00000
==> test epoch 360 avg loss: 2.86540 (A-MSE: 2.58414) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 6 out of 50
train epoch 361 avg loss: 1.44680 (A-MSE: 1.28908) avg lploss: 0.00000
train epoch 362 avg loss: 1.47689 (A-MSE: 1.31646) avg lploss: 0.00000
train epoch 363 avg loss: 1.28366 (A-MSE: 1.14532) avg lploss: 0.00000
train epoch 364 avg loss: 1.30836 (A-MSE: 1.16697) avg lploss: 0.00000
train epoch 365 avg loss: 1.51953 (A-MSE: 1.35864) avg lploss: 0.00000
==> val epoch 365 avg loss: 2.86107 (A-MSE: 2.54553) avg lploss: 0.00000
==> test epoch 365 avg loss: 3.11822 (A-MSE: 2.79183) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 7 out of 50
train epoch 366 avg loss: 1.56481 (A-MSE: 1.39136) avg lploss: 0.00000
train epoch 367 avg loss: 1.50735 (A-MSE: 1.33892) avg lploss: 0.00000
train epoch 368 avg loss: 1.45478 (A-MSE: 1.29843) avg lploss: 0.00000
train epoch 369 avg loss: 1.42550 (A-MSE: 1.27158) avg lploss: 0.00000
train epoch 370 avg loss: 1.38360 (A-MSE: 1.23269) avg lploss: 0.00000
==> val epoch 370 avg loss: 2.30730 (A-MSE: 2.06407) avg lploss: 0.00000
==> test epoch 370 avg loss: 2.61908 (A-MSE: 2.35554) avg lploss: 0.00000
*** Best Val Loss: 2.30166 	 Best Test Loss: 2.59397 	 Best epoch 330
EarlyStopping counter: 8 out of 50
train epoch 371 avg loss: 1.38987 (A-MSE: 1.24260) avg lploss: 0.00000
train epoch 372 avg loss: 1.34343 (A-MSE: 1.19933) avg lploss: 0.00000
train epoch 373 avg loss: 1.31046 (A-MSE: 1.16706) avg lploss: 0.00000
train epoch 374 avg loss: 1.35532 (A-MSE: 1.20860) avg lploss: 0.00000
train epoch 375 avg loss: 1.40057 (A-MSE: 1.24467) avg lploss: 0.00000
==> val epoch 375 avg loss: 2.28096 (A-MSE: 2.02310) avg lploss: 0.00000
==> test epoch 375 avg loss: 2.53473 (A-MSE: 2.26472) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
Validation loss decreased (2.301656 --> 2.280960).  Saving model ...
train epoch 376 avg loss: 1.39227 (A-MSE: 1.24390) avg lploss: 0.00000
train epoch 377 avg loss: 1.50069 (A-MSE: 1.33400) avg lploss: 0.00000
train epoch 378 avg loss: 1.42740 (A-MSE: 1.27787) avg lploss: 0.00000
train epoch 379 avg loss: 1.33974 (A-MSE: 1.19602) avg lploss: 0.00000
train epoch 380 avg loss: 1.32090 (A-MSE: 1.17918) avg lploss: 0.00000
==> val epoch 380 avg loss: 2.30302 (A-MSE: 2.06092) avg lploss: 0.00000
==> test epoch 380 avg loss: 2.48597 (A-MSE: 2.24571) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 1 out of 50
train epoch 381 avg loss: 1.25624 (A-MSE: 1.12046) avg lploss: 0.00000
train epoch 382 avg loss: 1.23988 (A-MSE: 1.10340) avg lploss: 0.00000
train epoch 383 avg loss: 1.26742 (A-MSE: 1.12877) avg lploss: 0.00000
train epoch 384 avg loss: 1.25093 (A-MSE: 1.11282) avg lploss: 0.00000
train epoch 385 avg loss: 1.23560 (A-MSE: 1.09720) avg lploss: 0.00000
==> val epoch 385 avg loss: 2.99486 (A-MSE: 2.68024) avg lploss: 0.00000
==> test epoch 385 avg loss: 3.22565 (A-MSE: 2.90405) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 2 out of 50
train epoch 386 avg loss: 1.30216 (A-MSE: 1.16161) avg lploss: 0.00000
train epoch 387 avg loss: 1.58956 (A-MSE: 1.42044) avg lploss: 0.00000
train epoch 388 avg loss: 1.63223 (A-MSE: 1.45226) avg lploss: 0.00000
train epoch 389 avg loss: 1.35970 (A-MSE: 1.20749) avg lploss: 0.00000
train epoch 390 avg loss: 1.66606 (A-MSE: 1.47876) avg lploss: 0.00000
==> val epoch 390 avg loss: 2.57454 (A-MSE: 2.28258) avg lploss: 0.00000
==> test epoch 390 avg loss: 2.81526 (A-MSE: 2.50861) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 3 out of 50
train epoch 391 avg loss: 1.41725 (A-MSE: 1.27296) avg lploss: 0.00000
train epoch 392 avg loss: 1.43192 (A-MSE: 1.26993) avg lploss: 0.00000
train epoch 393 avg loss: 1.38488 (A-MSE: 1.23787) avg lploss: 0.00000
train epoch 394 avg loss: 1.27158 (A-MSE: 1.13393) avg lploss: 0.00000
train epoch 395 avg loss: 1.25735 (A-MSE: 1.11821) avg lploss: 0.00000
==> val epoch 395 avg loss: 2.32540 (A-MSE: 2.08178) avg lploss: 0.00000
==> test epoch 395 avg loss: 2.62524 (A-MSE: 2.36988) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 4 out of 50
train epoch 396 avg loss: 1.34506 (A-MSE: 1.20575) avg lploss: 0.00000
train epoch 397 avg loss: 1.30367 (A-MSE: 1.16355) avg lploss: 0.00000
train epoch 398 avg loss: 1.33273 (A-MSE: 1.18593) avg lploss: 0.00000
train epoch 399 avg loss: 1.22645 (A-MSE: 1.09231) avg lploss: 0.00000
train epoch 400 avg loss: 1.21527 (A-MSE: 1.08004) avg lploss: 0.00000
==> val epoch 400 avg loss: 2.52364 (A-MSE: 2.27351) avg lploss: 0.00000
==> test epoch 400 avg loss: 2.74936 (A-MSE: 2.48922) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 5 out of 50
train epoch 401 avg loss: 1.24015 (A-MSE: 1.10180) avg lploss: 0.00000
train epoch 402 avg loss: 1.22577 (A-MSE: 1.09109) avg lploss: 0.00000
train epoch 403 avg loss: 1.27221 (A-MSE: 1.13735) avg lploss: 0.00000
train epoch 404 avg loss: 1.26964 (A-MSE: 1.13115) avg lploss: 0.00000
train epoch 405 avg loss: 1.27878 (A-MSE: 1.13475) avg lploss: 0.00000
==> val epoch 405 avg loss: 2.41069 (A-MSE: 2.16003) avg lploss: 0.00000
==> test epoch 405 avg loss: 2.67037 (A-MSE: 2.40344) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 6 out of 50
train epoch 406 avg loss: 1.24128 (A-MSE: 1.10956) avg lploss: 0.00000
train epoch 407 avg loss: 1.33098 (A-MSE: 1.18855) avg lploss: 0.00000
train epoch 408 avg loss: 1.22286 (A-MSE: 1.08321) avg lploss: 0.00000
train epoch 409 avg loss: 1.18202 (A-MSE: 1.05280) avg lploss: 0.00000
train epoch 410 avg loss: 1.18030 (A-MSE: 1.05229) avg lploss: 0.00000
==> val epoch 410 avg loss: 2.29640 (A-MSE: 2.04675) avg lploss: 0.00000
==> test epoch 410 avg loss: 2.59336 (A-MSE: 2.32568) avg lploss: 0.00000
*** Best Val Loss: 2.28096 	 Best Test Loss: 2.53473 	 Best epoch 375
EarlyStopping counter: 7 out of 50
train epoch 411 avg loss: 1.22046 (A-MSE: 1.08951) avg lploss: 0.00000
train epoch 412 avg loss: 1.18497 (A-MSE: 1.05175) avg lploss: 0.00000
train epoch 413 avg loss: 1.25067 (A-MSE: 1.11603) avg lploss: 0.00000
train epoch 414 avg loss: 1.39184 (A-MSE: 1.24863) avg lploss: 0.00000
train epoch 415 avg loss: 1.42483 (A-MSE: 1.27060) avg lploss: 0.00000
==> val epoch 415 avg loss: 2.10672 (A-MSE: 1.89528) avg lploss: 0.00000
==> test epoch 415 avg loss: 2.44960 (A-MSE: 2.21879) avg lploss: 0.00000
*** Best Val Loss: 2.10672 	 Best Test Loss: 2.44960 	 Best epoch 415
Validation loss decreased (2.280960 --> 2.106723).  Saving model ...
train epoch 416 avg loss: 1.41439 (A-MSE: 1.25777) avg lploss: 0.00000
train epoch 417 avg loss: 1.31849 (A-MSE: 1.17780) avg lploss: 0.00000
train epoch 418 avg loss: 1.22963 (A-MSE: 1.08773) avg lploss: 0.00000
train epoch 419 avg loss: 1.33558 (A-MSE: 1.18596) avg lploss: 0.00000
train epoch 420 avg loss: 1.26889 (A-MSE: 1.13195) avg lploss: 0.00000
==> val epoch 420 avg loss: 3.07809 (A-MSE: 2.75102) avg lploss: 0.00000
==> test epoch 420 avg loss: 3.18661 (A-MSE: 2.86377) avg lploss: 0.00000
*** Best Val Loss: 2.10672 	 Best Test Loss: 2.44960 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 1.42403 (A-MSE: 1.26769) avg lploss: 0.00000
train epoch 422 avg loss: 1.47282 (A-MSE: 1.31679) avg lploss: 0.00000
train epoch 423 avg loss: 1.27445 (A-MSE: 1.13706) avg lploss: 0.00000
train epoch 424 avg loss: 1.30127 (A-MSE: 1.15343) avg lploss: 0.00000
train epoch 425 avg loss: 1.11855 (A-MSE: 0.99929) avg lploss: 0.00000
==> val epoch 425 avg loss: 2.22013 (A-MSE: 1.98004) avg lploss: 0.00000
==> test epoch 425 avg loss: 2.47938 (A-MSE: 2.22640) avg lploss: 0.00000
*** Best Val Loss: 2.10672 	 Best Test Loss: 2.44960 	 Best epoch 415
EarlyStopping counter: 2 out of 50
train epoch 426 avg loss: 1.19768 (A-MSE: 1.06438) avg lploss: 0.00000
train epoch 427 avg loss: 1.24683 (A-MSE: 1.10775) avg lploss: 0.00000
train epoch 428 avg loss: 1.19443 (A-MSE: 1.06295) avg lploss: 0.00000
train epoch 429 avg loss: 1.19325 (A-MSE: 1.06393) avg lploss: 0.00000
train epoch 430 avg loss: 1.29341 (A-MSE: 1.14835) avg lploss: 0.00000
==> val epoch 430 avg loss: 2.24488 (A-MSE: 2.01892) avg lploss: 0.00000
==> test epoch 430 avg loss: 2.44884 (A-MSE: 2.22039) avg lploss: 0.00000
*** Best Val Loss: 2.10672 	 Best Test Loss: 2.44960 	 Best epoch 415
EarlyStopping counter: 3 out of 50
train epoch 431 avg loss: 1.34236 (A-MSE: 1.19536) avg lploss: 0.00000
train epoch 432 avg loss: 1.31955 (A-MSE: 1.16879) avg lploss: 0.00000
train epoch 433 avg loss: 1.21292 (A-MSE: 1.08237) avg lploss: 0.00000
train epoch 434 avg loss: 1.25558 (A-MSE: 1.11576) avg lploss: 0.00000
train epoch 435 avg loss: 1.24212 (A-MSE: 1.10805) avg lploss: 0.00000
==> val epoch 435 avg loss: 2.06918 (A-MSE: 1.84163) avg lploss: 0.00000
==> test epoch 435 avg loss: 2.26977 (A-MSE: 2.03884) avg lploss: 0.00000
*** Best Val Loss: 2.06918 	 Best Test Loss: 2.26977 	 Best epoch 435
Validation loss decreased (2.106723 --> 2.069184).  Saving model ...
train epoch 436 avg loss: 1.06018 (A-MSE: 0.93908) avg lploss: 0.00000
train epoch 437 avg loss: 1.04846 (A-MSE: 0.93059) avg lploss: 0.00000
train epoch 438 avg loss: 1.14015 (A-MSE: 1.01178) avg lploss: 0.00000
train epoch 439 avg loss: 1.31427 (A-MSE: 1.17307) avg lploss: 0.00000
train epoch 440 avg loss: 1.19946 (A-MSE: 1.06942) avg lploss: 0.00000
==> val epoch 440 avg loss: 2.19907 (A-MSE: 1.96326) avg lploss: 0.00000
==> test epoch 440 avg loss: 2.35381 (A-MSE: 2.11020) avg lploss: 0.00000
*** Best Val Loss: 2.06918 	 Best Test Loss: 2.26977 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 1.07001 (A-MSE: 0.94759) avg lploss: 0.00000
train epoch 442 avg loss: 1.10178 (A-MSE: 0.98237) avg lploss: 0.00000
train epoch 443 avg loss: 1.11194 (A-MSE: 0.99058) avg lploss: 0.00000
train epoch 444 avg loss: 1.15546 (A-MSE: 1.02545) avg lploss: 0.00000
train epoch 445 avg loss: 1.10026 (A-MSE: 0.97844) avg lploss: 0.00000
==> val epoch 445 avg loss: 2.27344 (A-MSE: 2.01834) avg lploss: 0.00000
==> test epoch 445 avg loss: 2.42441 (A-MSE: 2.17335) avg lploss: 0.00000
*** Best Val Loss: 2.06918 	 Best Test Loss: 2.26977 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 1.10545 (A-MSE: 0.98781) avg lploss: 0.00000
train epoch 447 avg loss: 1.01383 (A-MSE: 0.90094) avg lploss: 0.00000
train epoch 448 avg loss: 1.01018 (A-MSE: 0.89420) avg lploss: 0.00000
train epoch 449 avg loss: 1.08139 (A-MSE: 0.96187) avg lploss: 0.00000
train epoch 450 avg loss: 1.17327 (A-MSE: 1.04028) avg lploss: 0.00000
==> val epoch 450 avg loss: 2.12922 (A-MSE: 1.89562) avg lploss: 0.00000
==> test epoch 450 avg loss: 2.32409 (A-MSE: 2.08875) avg lploss: 0.00000
*** Best Val Loss: 2.06918 	 Best Test Loss: 2.26977 	 Best epoch 435
EarlyStopping counter: 3 out of 50
train epoch 451 avg loss: 1.33900 (A-MSE: 1.19597) avg lploss: 0.00000
train epoch 452 avg loss: 1.44108 (A-MSE: 1.28375) avg lploss: 0.00000
train epoch 453 avg loss: 1.18060 (A-MSE: 1.05059) avg lploss: 0.00000
train epoch 454 avg loss: 1.13087 (A-MSE: 1.00423) avg lploss: 0.00000
train epoch 455 avg loss: 1.14869 (A-MSE: 1.02484) avg lploss: 0.00000
==> val epoch 455 avg loss: 2.63204 (A-MSE: 2.35792) avg lploss: 0.00000
==> test epoch 455 avg loss: 2.63876 (A-MSE: 2.38335) avg lploss: 0.00000
*** Best Val Loss: 2.06918 	 Best Test Loss: 2.26977 	 Best epoch 435
EarlyStopping counter: 4 out of 50
train epoch 456 avg loss: 1.37358 (A-MSE: 1.22141) avg lploss: 0.00000
train epoch 457 avg loss: 1.25419 (A-MSE: 1.11504) avg lploss: 0.00000
train epoch 458 avg loss: 1.18000 (A-MSE: 1.05296) avg lploss: 0.00000
train epoch 459 avg loss: 1.08745 (A-MSE: 0.97175) avg lploss: 0.00000
train epoch 460 avg loss: 1.35524 (A-MSE: 1.20851) avg lploss: 0.00000
==> val epoch 460 avg loss: 2.47513 (A-MSE: 2.20636) avg lploss: 0.00000
==> test epoch 460 avg loss: 2.66541 (A-MSE: 2.38984) avg lploss: 0.00000
*** Best Val Loss: 2.06918 	 Best Test Loss: 2.26977 	 Best epoch 435
EarlyStopping counter: 5 out of 50
train epoch 461 avg loss: 1.23707 (A-MSE: 1.10223) avg lploss: 0.00000
train epoch 462 avg loss: 1.17093 (A-MSE: 1.04748) avg lploss: 0.00000
train epoch 463 avg loss: 1.07179 (A-MSE: 0.95354) avg lploss: 0.00000
train epoch 464 avg loss: 1.08259 (A-MSE: 0.95958) avg lploss: 0.00000
train epoch 465 avg loss: 1.00937 (A-MSE: 0.89572) avg lploss: 0.00000
==> val epoch 465 avg loss: 1.99951 (A-MSE: 1.78399) avg lploss: 0.00000
==> test epoch 465 avg loss: 2.26547 (A-MSE: 2.03692) avg lploss: 0.00000
*** Best Val Loss: 1.99951 	 Best Test Loss: 2.26547 	 Best epoch 465
Validation loss decreased (2.069184 --> 1.999511).  Saving model ...
train epoch 466 avg loss: 0.97388 (A-MSE: 0.86484) avg lploss: 0.00000
train epoch 467 avg loss: 1.03193 (A-MSE: 0.91680) avg lploss: 0.00000
train epoch 468 avg loss: 1.12245 (A-MSE: 0.99553) avg lploss: 0.00000
train epoch 469 avg loss: 1.09813 (A-MSE: 0.97917) avg lploss: 0.00000
train epoch 470 avg loss: 1.15078 (A-MSE: 1.02454) avg lploss: 0.00000
==> val epoch 470 avg loss: 2.52989 (A-MSE: 2.24849) avg lploss: 0.00000
==> test epoch 470 avg loss: 2.76223 (A-MSE: 2.47758) avg lploss: 0.00000
*** Best Val Loss: 1.99951 	 Best Test Loss: 2.26547 	 Best epoch 465
EarlyStopping counter: 1 out of 50
train epoch 471 avg loss: 1.14587 (A-MSE: 1.01662) avg lploss: 0.00000
train epoch 472 avg loss: 1.13573 (A-MSE: 1.01101) avg lploss: 0.00000
train epoch 473 avg loss: 0.99441 (A-MSE: 0.88443) avg lploss: 0.00000
train epoch 474 avg loss: 1.05655 (A-MSE: 0.93935) avg lploss: 0.00000
train epoch 475 avg loss: 1.06326 (A-MSE: 0.94500) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.87753 (A-MSE: 1.67055) avg lploss: 0.00000
==> test epoch 475 avg loss: 2.16882 (A-MSE: 1.94873) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
Validation loss decreased (1.999511 --> 1.877527).  Saving model ...
train epoch 476 avg loss: 1.03391 (A-MSE: 0.92464) avg lploss: 0.00000
train epoch 477 avg loss: 1.12242 (A-MSE: 0.99285) avg lploss: 0.00000
train epoch 478 avg loss: 1.03645 (A-MSE: 0.92338) avg lploss: 0.00000
train epoch 479 avg loss: 1.11296 (A-MSE: 0.99182) avg lploss: 0.00000
train epoch 480 avg loss: 1.08678 (A-MSE: 0.96051) avg lploss: 0.00000
==> val epoch 480 avg loss: 2.28436 (A-MSE: 2.05650) avg lploss: 0.00000
==> test epoch 480 avg loss: 2.44608 (A-MSE: 2.21592) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 1 out of 50
train epoch 481 avg loss: 1.04432 (A-MSE: 0.93050) avg lploss: 0.00000
train epoch 482 avg loss: 1.03539 (A-MSE: 0.91665) avg lploss: 0.00000
train epoch 483 avg loss: 1.09851 (A-MSE: 0.97805) avg lploss: 0.00000
train epoch 484 avg loss: 1.07062 (A-MSE: 0.95169) avg lploss: 0.00000
train epoch 485 avg loss: 1.15066 (A-MSE: 1.02568) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.97384 (A-MSE: 1.74789) avg lploss: 0.00000
==> test epoch 485 avg loss: 2.17746 (A-MSE: 1.94575) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 2 out of 50
train epoch 486 avg loss: 1.02949 (A-MSE: 0.91641) avg lploss: 0.00000
train epoch 487 avg loss: 1.01740 (A-MSE: 0.90668) avg lploss: 0.00000
train epoch 488 avg loss: 0.93896 (A-MSE: 0.83273) avg lploss: 0.00000
train epoch 489 avg loss: 0.97946 (A-MSE: 0.87055) avg lploss: 0.00000
train epoch 490 avg loss: 1.08511 (A-MSE: 0.96393) avg lploss: 0.00000
==> val epoch 490 avg loss: 2.03497 (A-MSE: 1.82554) avg lploss: 0.00000
==> test epoch 490 avg loss: 2.21993 (A-MSE: 2.00075) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 3 out of 50
train epoch 491 avg loss: 1.00492 (A-MSE: 0.89465) avg lploss: 0.00000
train epoch 492 avg loss: 0.95844 (A-MSE: 0.84873) avg lploss: 0.00000
train epoch 493 avg loss: 0.99172 (A-MSE: 0.88286) avg lploss: 0.00000
train epoch 494 avg loss: 1.05127 (A-MSE: 0.93824) avg lploss: 0.00000
train epoch 495 avg loss: 1.10588 (A-MSE: 0.98740) avg lploss: 0.00000
==> val epoch 495 avg loss: 2.26824 (A-MSE: 2.02300) avg lploss: 0.00000
==> test epoch 495 avg loss: 2.58775 (A-MSE: 2.33220) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 4 out of 50
train epoch 496 avg loss: 1.12659 (A-MSE: 0.99822) avg lploss: 0.00000
train epoch 497 avg loss: 0.94557 (A-MSE: 0.84259) avg lploss: 0.00000
train epoch 498 avg loss: 0.99336 (A-MSE: 0.88307) avg lploss: 0.00000
train epoch 499 avg loss: 1.15916 (A-MSE: 1.02751) avg lploss: 0.00000
train epoch 500 avg loss: 1.02822 (A-MSE: 0.91619) avg lploss: 0.00000
==> val epoch 500 avg loss: 2.23719 (A-MSE: 1.98382) avg lploss: 0.00000
==> test epoch 500 avg loss: 2.45765 (A-MSE: 2.20378) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 5 out of 50
train epoch 501 avg loss: 0.99276 (A-MSE: 0.88421) avg lploss: 0.00000
train epoch 502 avg loss: 0.98853 (A-MSE: 0.87782) avg lploss: 0.00000
train epoch 503 avg loss: 0.95224 (A-MSE: 0.84631) avg lploss: 0.00000
train epoch 504 avg loss: 1.01541 (A-MSE: 0.90320) avg lploss: 0.00000
train epoch 505 avg loss: 1.03512 (A-MSE: 0.92379) avg lploss: 0.00000
==> val epoch 505 avg loss: 1.90625 (A-MSE: 1.69975) avg lploss: 0.00000
==> test epoch 505 avg loss: 2.24139 (A-MSE: 2.01652) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 6 out of 50
train epoch 506 avg loss: 0.94521 (A-MSE: 0.83825) avg lploss: 0.00000
train epoch 507 avg loss: 0.93341 (A-MSE: 0.82963) avg lploss: 0.00000
train epoch 508 avg loss: 0.96594 (A-MSE: 0.85704) avg lploss: 0.00000
train epoch 509 avg loss: 0.95428 (A-MSE: 0.84347) avg lploss: 0.00000
train epoch 510 avg loss: 0.93647 (A-MSE: 0.83604) avg lploss: 0.00000
==> val epoch 510 avg loss: 2.20514 (A-MSE: 1.97072) avg lploss: 0.00000
==> test epoch 510 avg loss: 2.35329 (A-MSE: 2.11637) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 7 out of 50
train epoch 511 avg loss: 0.97758 (A-MSE: 0.87186) avg lploss: 0.00000
train epoch 512 avg loss: 0.94044 (A-MSE: 0.83989) avg lploss: 0.00000
train epoch 513 avg loss: 1.01890 (A-MSE: 0.90655) avg lploss: 0.00000
train epoch 514 avg loss: 0.90618 (A-MSE: 0.80365) avg lploss: 0.00000
train epoch 515 avg loss: 0.81826 (A-MSE: 0.72661) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.89977 (A-MSE: 1.68313) avg lploss: 0.00000
==> test epoch 515 avg loss: 2.07123 (A-MSE: 1.85535) avg lploss: 0.00000
*** Best Val Loss: 1.87753 	 Best Test Loss: 2.16882 	 Best epoch 475
EarlyStopping counter: 8 out of 50
train epoch 516 avg loss: 0.85627 (A-MSE: 0.76155) avg lploss: 0.00000
train epoch 517 avg loss: 0.91363 (A-MSE: 0.81138) avg lploss: 0.00000
train epoch 518 avg loss: 0.92703 (A-MSE: 0.82695) avg lploss: 0.00000
train epoch 519 avg loss: 1.01927 (A-MSE: 0.90655) avg lploss: 0.00000
train epoch 520 avg loss: 1.00536 (A-MSE: 0.89635) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.81060 (A-MSE: 1.61593) avg lploss: 0.00000
==> test epoch 520 avg loss: 2.04039 (A-MSE: 1.83998) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
Validation loss decreased (1.877527 --> 1.810597).  Saving model ...
train epoch 521 avg loss: 0.93789 (A-MSE: 0.83642) avg lploss: 0.00000
train epoch 522 avg loss: 0.94514 (A-MSE: 0.83777) avg lploss: 0.00000
train epoch 523 avg loss: 0.97126 (A-MSE: 0.86097) avg lploss: 0.00000
train epoch 524 avg loss: 0.91159 (A-MSE: 0.81134) avg lploss: 0.00000
train epoch 525 avg loss: 1.06343 (A-MSE: 0.95414) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.81071 (A-MSE: 1.61431) avg lploss: 0.00000
==> test epoch 525 avg loss: 2.15331 (A-MSE: 1.94697) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 1 out of 50
train epoch 526 avg loss: 1.05414 (A-MSE: 0.94457) avg lploss: 0.00000
train epoch 527 avg loss: 0.95947 (A-MSE: 0.85469) avg lploss: 0.00000
train epoch 528 avg loss: 0.99824 (A-MSE: 0.88650) avg lploss: 0.00000
train epoch 529 avg loss: 1.02930 (A-MSE: 0.91787) avg lploss: 0.00000
train epoch 530 avg loss: 0.94602 (A-MSE: 0.84058) avg lploss: 0.00000
==> val epoch 530 avg loss: 2.12954 (A-MSE: 1.90960) avg lploss: 0.00000
==> test epoch 530 avg loss: 2.29271 (A-MSE: 2.06266) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 2 out of 50
train epoch 531 avg loss: 0.98287 (A-MSE: 0.88483) avg lploss: 0.00000
train epoch 532 avg loss: 0.93217 (A-MSE: 0.82941) avg lploss: 0.00000
train epoch 533 avg loss: 0.96178 (A-MSE: 0.85406) avg lploss: 0.00000
train epoch 534 avg loss: 0.95606 (A-MSE: 0.85059) avg lploss: 0.00000
train epoch 535 avg loss: 0.89514 (A-MSE: 0.80302) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.84120 (A-MSE: 1.62851) avg lploss: 0.00000
==> test epoch 535 avg loss: 2.00355 (A-MSE: 1.79147) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 3 out of 50
train epoch 536 avg loss: 0.83872 (A-MSE: 0.74318) avg lploss: 0.00000
train epoch 537 avg loss: 0.91088 (A-MSE: 0.80956) avg lploss: 0.00000
train epoch 538 avg loss: 0.88385 (A-MSE: 0.78583) avg lploss: 0.00000
train epoch 539 avg loss: 0.83992 (A-MSE: 0.74831) avg lploss: 0.00000
train epoch 540 avg loss: 0.86317 (A-MSE: 0.76485) avg lploss: 0.00000
==> val epoch 540 avg loss: 1.99320 (A-MSE: 1.76273) avg lploss: 0.00000
==> test epoch 540 avg loss: 2.15122 (A-MSE: 1.92558) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 4 out of 50
train epoch 541 avg loss: 0.87424 (A-MSE: 0.77452) avg lploss: 0.00000
train epoch 542 avg loss: 0.84542 (A-MSE: 0.74954) avg lploss: 0.00000
train epoch 543 avg loss: 0.96386 (A-MSE: 0.85751) avg lploss: 0.00000
train epoch 544 avg loss: 1.03530 (A-MSE: 0.93048) avg lploss: 0.00000
train epoch 545 avg loss: 1.10579 (A-MSE: 0.97930) avg lploss: 0.00000
==> val epoch 545 avg loss: 2.19386 (A-MSE: 1.99038) avg lploss: 0.00000
==> test epoch 545 avg loss: 2.40024 (A-MSE: 2.17581) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 5 out of 50
train epoch 546 avg loss: 1.04010 (A-MSE: 0.93055) avg lploss: 0.00000
train epoch 547 avg loss: 0.95038 (A-MSE: 0.84662) avg lploss: 0.00000
train epoch 548 avg loss: 0.82463 (A-MSE: 0.73254) avg lploss: 0.00000
train epoch 549 avg loss: 0.81418 (A-MSE: 0.72129) avg lploss: 0.00000
train epoch 550 avg loss: 0.80211 (A-MSE: 0.71303) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.88227 (A-MSE: 1.67087) avg lploss: 0.00000
==> test epoch 550 avg loss: 2.13950 (A-MSE: 1.91162) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 6 out of 50
train epoch 551 avg loss: 1.00129 (A-MSE: 0.89073) avg lploss: 0.00000
train epoch 552 avg loss: 1.04751 (A-MSE: 0.93586) avg lploss: 0.00000
train epoch 553 avg loss: 0.97910 (A-MSE: 0.86786) avg lploss: 0.00000
train epoch 554 avg loss: 0.86649 (A-MSE: 0.77012) avg lploss: 0.00000
train epoch 555 avg loss: 0.89945 (A-MSE: 0.79705) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.98270 (A-MSE: 1.76430) avg lploss: 0.00000
==> test epoch 555 avg loss: 2.14480 (A-MSE: 1.92407) avg lploss: 0.00000
*** Best Val Loss: 1.81060 	 Best Test Loss: 2.04039 	 Best epoch 520
EarlyStopping counter: 7 out of 50
train epoch 556 avg loss: 0.93098 (A-MSE: 0.83080) avg lploss: 0.00000
train epoch 557 avg loss: 0.95303 (A-MSE: 0.84350) avg lploss: 0.00000
train epoch 558 avg loss: 0.88761 (A-MSE: 0.78567) avg lploss: 0.00000
train epoch 559 avg loss: 0.86429 (A-MSE: 0.77395) avg lploss: 0.00000
train epoch 560 avg loss: 0.90118 (A-MSE: 0.80248) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.79285 (A-MSE: 1.59898) avg lploss: 0.00000
==> test epoch 560 avg loss: 2.10418 (A-MSE: 1.89011) avg lploss: 0.00000
*** Best Val Loss: 1.79285 	 Best Test Loss: 2.10418 	 Best epoch 560
Validation loss decreased (1.810597 --> 1.792852).  Saving model ...
train epoch 561 avg loss: 0.82981 (A-MSE: 0.73496) avg lploss: 0.00000
train epoch 562 avg loss: 0.83341 (A-MSE: 0.74064) avg lploss: 0.00000
train epoch 563 avg loss: 0.82537 (A-MSE: 0.73097) avg lploss: 0.00000
train epoch 564 avg loss: 0.81717 (A-MSE: 0.72305) avg lploss: 0.00000
train epoch 565 avg loss: 0.82024 (A-MSE: 0.72669) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.69840 (A-MSE: 1.52503) avg lploss: 0.00000
==> test epoch 565 avg loss: 1.89562 (A-MSE: 1.71078) avg lploss: 0.00000
*** Best Val Loss: 1.69840 	 Best Test Loss: 1.89562 	 Best epoch 565
Validation loss decreased (1.792852 --> 1.698403).  Saving model ...
train epoch 566 avg loss: 0.82540 (A-MSE: 0.73606) avg lploss: 0.00000
train epoch 567 avg loss: 0.92985 (A-MSE: 0.82325) avg lploss: 0.00000
train epoch 568 avg loss: 0.88777 (A-MSE: 0.78842) avg lploss: 0.00000
train epoch 569 avg loss: 0.82912 (A-MSE: 0.73611) avg lploss: 0.00000
train epoch 570 avg loss: 0.82747 (A-MSE: 0.73505) avg lploss: 0.00000
==> val epoch 570 avg loss: 1.66496 (A-MSE: 1.49234) avg lploss: 0.00000
==> test epoch 570 avg loss: 1.95395 (A-MSE: 1.77869) avg lploss: 0.00000
*** Best Val Loss: 1.66496 	 Best Test Loss: 1.95395 	 Best epoch 570
Validation loss decreased (1.698403 --> 1.664957).  Saving model ...
train epoch 571 avg loss: 0.92496 (A-MSE: 0.82995) avg lploss: 0.00000
train epoch 572 avg loss: 0.87104 (A-MSE: 0.77306) avg lploss: 0.00000
train epoch 573 avg loss: 0.81197 (A-MSE: 0.71845) avg lploss: 0.00000
train epoch 574 avg loss: 0.79696 (A-MSE: 0.70835) avg lploss: 0.00000
train epoch 575 avg loss: 0.76515 (A-MSE: 0.68063) avg lploss: 0.00000
==> val epoch 575 avg loss: 1.72868 (A-MSE: 1.53166) avg lploss: 0.00000
==> test epoch 575 avg loss: 1.93183 (A-MSE: 1.73228) avg lploss: 0.00000
*** Best Val Loss: 1.66496 	 Best Test Loss: 1.95395 	 Best epoch 570
EarlyStopping counter: 1 out of 50
train epoch 576 avg loss: 0.78890 (A-MSE: 0.70242) avg lploss: 0.00000
train epoch 577 avg loss: 0.82270 (A-MSE: 0.73255) avg lploss: 0.00000
train epoch 578 avg loss: 0.77948 (A-MSE: 0.69369) avg lploss: 0.00000
train epoch 579 avg loss: 0.86783 (A-MSE: 0.76980) avg lploss: 0.00000
train epoch 580 avg loss: 0.83159 (A-MSE: 0.73822) avg lploss: 0.00000
==> val epoch 580 avg loss: 1.84063 (A-MSE: 1.63266) avg lploss: 0.00000
==> test epoch 580 avg loss: 2.08836 (A-MSE: 1.87114) avg lploss: 0.00000
*** Best Val Loss: 1.66496 	 Best Test Loss: 1.95395 	 Best epoch 570
EarlyStopping counter: 2 out of 50
train epoch 581 avg loss: 0.78507 (A-MSE: 0.69466) avg lploss: 0.00000
train epoch 582 avg loss: 0.80298 (A-MSE: 0.71331) avg lploss: 0.00000
train epoch 583 avg loss: 0.80784 (A-MSE: 0.71788) avg lploss: 0.00000
train epoch 584 avg loss: 0.93113 (A-MSE: 0.83802) avg lploss: 0.00000
train epoch 585 avg loss: 0.89147 (A-MSE: 0.79073) avg lploss: 0.00000
==> val epoch 585 avg loss: 2.10770 (A-MSE: 1.89447) avg lploss: 0.00000
==> test epoch 585 avg loss: 2.18869 (A-MSE: 1.96973) avg lploss: 0.00000
*** Best Val Loss: 1.66496 	 Best Test Loss: 1.95395 	 Best epoch 570
EarlyStopping counter: 3 out of 50
train epoch 586 avg loss: 0.82299 (A-MSE: 0.73044) avg lploss: 0.00000
train epoch 587 avg loss: 0.86752 (A-MSE: 0.77069) avg lploss: 0.00000
train epoch 588 avg loss: 0.89732 (A-MSE: 0.79451) avg lploss: 0.00000
train epoch 589 avg loss: 0.81692 (A-MSE: 0.72324) avg lploss: 0.00000
train epoch 590 avg loss: 0.89574 (A-MSE: 0.79902) avg lploss: 0.00000
==> val epoch 590 avg loss: 1.92565 (A-MSE: 1.70216) avg lploss: 0.00000
==> test epoch 590 avg loss: 2.23586 (A-MSE: 1.99387) avg lploss: 0.00000
*** Best Val Loss: 1.66496 	 Best Test Loss: 1.95395 	 Best epoch 570
EarlyStopping counter: 4 out of 50
train epoch 591 avg loss: 0.78060 (A-MSE: 0.68732) avg lploss: 0.00000
train epoch 592 avg loss: 0.78591 (A-MSE: 0.69726) avg lploss: 0.00000
train epoch 593 avg loss: 0.73515 (A-MSE: 0.65396) avg lploss: 0.00000
train epoch 594 avg loss: 0.82654 (A-MSE: 0.73190) avg lploss: 0.00000
train epoch 595 avg loss: 0.86339 (A-MSE: 0.76885) avg lploss: 0.00000
==> val epoch 595 avg loss: 1.77949 (A-MSE: 1.58611) avg lploss: 0.00000
==> test epoch 595 avg loss: 2.09540 (A-MSE: 1.88045) avg lploss: 0.00000
*** Best Val Loss: 1.66496 	 Best Test Loss: 1.95395 	 Best epoch 570
EarlyStopping counter: 5 out of 50
train epoch 596 avg loss: 0.83576 (A-MSE: 0.74519) avg lploss: 0.00000
train epoch 597 avg loss: 0.84111 (A-MSE: 0.74706) avg lploss: 0.00000
train epoch 598 avg loss: 0.84865 (A-MSE: 0.75609) avg lploss: 0.00000
train epoch 599 avg loss: 0.85602 (A-MSE: 0.75877) avg lploss: 0.00000
train epoch 600 avg loss: 0.80223 (A-MSE: 0.71163) avg lploss: 0.00000
==> val epoch 600 avg loss: 1.66315 (A-MSE: 1.47223) avg lploss: 0.00000
==> test epoch 600 avg loss: 1.89405 (A-MSE: 1.69828) avg lploss: 0.00000
*** Best Val Loss: 1.66315 	 Best Test Loss: 1.89405 	 Best epoch 600
Validation loss decreased (1.664957 --> 1.663154).  Saving model ...
train epoch 601 avg loss: 0.73934 (A-MSE: 0.65963) avg lploss: 0.00000
train epoch 602 avg loss: 0.70311 (A-MSE: 0.62353) avg lploss: 0.00000
train epoch 603 avg loss: 0.74863 (A-MSE: 0.66225) avg lploss: 0.00000
train epoch 604 avg loss: 0.76603 (A-MSE: 0.67943) avg lploss: 0.00000
train epoch 605 avg loss: 0.81250 (A-MSE: 0.72356) avg lploss: 0.00000
==> val epoch 605 avg loss: 1.63828 (A-MSE: 1.46385) avg lploss: 0.00000
==> test epoch 605 avg loss: 1.80713 (A-MSE: 1.62456) avg lploss: 0.00000
*** Best Val Loss: 1.63828 	 Best Test Loss: 1.80713 	 Best epoch 605
Validation loss decreased (1.663154 --> 1.638281).  Saving model ...
train epoch 606 avg loss: 0.75546 (A-MSE: 0.66769) avg lploss: 0.00000
train epoch 607 avg loss: 0.76852 (A-MSE: 0.68374) avg lploss: 0.00000
train epoch 608 avg loss: 0.76355 (A-MSE: 0.67631) avg lploss: 0.00000
train epoch 609 avg loss: 0.83950 (A-MSE: 0.74688) avg lploss: 0.00000
train epoch 610 avg loss: 0.74694 (A-MSE: 0.66458) avg lploss: 0.00000
==> val epoch 610 avg loss: 1.72136 (A-MSE: 1.52544) avg lploss: 0.00000
==> test epoch 610 avg loss: 1.95009 (A-MSE: 1.74884) avg lploss: 0.00000
*** Best Val Loss: 1.63828 	 Best Test Loss: 1.80713 	 Best epoch 605
EarlyStopping counter: 1 out of 50
train epoch 611 avg loss: 0.75815 (A-MSE: 0.67479) avg lploss: 0.00000
train epoch 612 avg loss: 0.80296 (A-MSE: 0.71106) avg lploss: 0.00000
train epoch 613 avg loss: 0.85020 (A-MSE: 0.75389) avg lploss: 0.00000
train epoch 614 avg loss: 0.86654 (A-MSE: 0.76868) avg lploss: 0.00000
train epoch 615 avg loss: 0.78839 (A-MSE: 0.70253) avg lploss: 0.00000
==> val epoch 615 avg loss: 1.56151 (A-MSE: 1.38516) avg lploss: 0.00000
==> test epoch 615 avg loss: 1.69204 (A-MSE: 1.51719) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
Validation loss decreased (1.638281 --> 1.561506).  Saving model ...
train epoch 616 avg loss: 0.77240 (A-MSE: 0.68723) avg lploss: 0.00000
train epoch 617 avg loss: 0.74324 (A-MSE: 0.65955) avg lploss: 0.00000
train epoch 618 avg loss: 0.75344 (A-MSE: 0.66503) avg lploss: 0.00000
train epoch 619 avg loss: 0.81377 (A-MSE: 0.72484) avg lploss: 0.00000
train epoch 620 avg loss: 0.79667 (A-MSE: 0.70743) avg lploss: 0.00000
==> val epoch 620 avg loss: 1.64501 (A-MSE: 1.45892) avg lploss: 0.00000
==> test epoch 620 avg loss: 1.98227 (A-MSE: 1.78318) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.73514 (A-MSE: 0.65390) avg lploss: 0.00000
train epoch 622 avg loss: 0.75661 (A-MSE: 0.66726) avg lploss: 0.00000
train epoch 623 avg loss: 0.69086 (A-MSE: 0.61188) avg lploss: 0.00000
train epoch 624 avg loss: 0.76893 (A-MSE: 0.68570) avg lploss: 0.00000
train epoch 625 avg loss: 0.74239 (A-MSE: 0.65815) avg lploss: 0.00000
==> val epoch 625 avg loss: 1.70389 (A-MSE: 1.51745) avg lploss: 0.00000
==> test epoch 625 avg loss: 1.82888 (A-MSE: 1.64366) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.77680 (A-MSE: 0.68776) avg lploss: 0.00000
train epoch 627 avg loss: 0.71777 (A-MSE: 0.64118) avg lploss: 0.00000
train epoch 628 avg loss: 0.76550 (A-MSE: 0.67773) avg lploss: 0.00000
train epoch 629 avg loss: 0.82575 (A-MSE: 0.73645) avg lploss: 0.00000
train epoch 630 avg loss: 0.87058 (A-MSE: 0.77028) avg lploss: 0.00000
==> val epoch 630 avg loss: 2.10867 (A-MSE: 1.87624) avg lploss: 0.00000
==> test epoch 630 avg loss: 2.44910 (A-MSE: 2.18468) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 3 out of 50
train epoch 631 avg loss: 0.88458 (A-MSE: 0.78044) avg lploss: 0.00000
train epoch 632 avg loss: 0.83402 (A-MSE: 0.74394) avg lploss: 0.00000
train epoch 633 avg loss: 0.70787 (A-MSE: 0.62744) avg lploss: 0.00000
train epoch 634 avg loss: 0.70140 (A-MSE: 0.62453) avg lploss: 0.00000
train epoch 635 avg loss: 0.65594 (A-MSE: 0.57981) avg lploss: 0.00000
==> val epoch 635 avg loss: 1.79012 (A-MSE: 1.59216) avg lploss: 0.00000
==> test epoch 635 avg loss: 1.87157 (A-MSE: 1.67527) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 4 out of 50
train epoch 636 avg loss: 0.69660 (A-MSE: 0.61610) avg lploss: 0.00000
train epoch 637 avg loss: 0.69218 (A-MSE: 0.61580) avg lploss: 0.00000
train epoch 638 avg loss: 0.75667 (A-MSE: 0.66929) avg lploss: 0.00000
train epoch 639 avg loss: 0.74485 (A-MSE: 0.66200) avg lploss: 0.00000
train epoch 640 avg loss: 0.71711 (A-MSE: 0.63615) avg lploss: 0.00000
==> val epoch 640 avg loss: 1.60887 (A-MSE: 1.42802) avg lploss: 0.00000
==> test epoch 640 avg loss: 1.74351 (A-MSE: 1.56608) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 5 out of 50
train epoch 641 avg loss: 0.75965 (A-MSE: 0.67683) avg lploss: 0.00000
train epoch 642 avg loss: 0.78419 (A-MSE: 0.70041) avg lploss: 0.00000
train epoch 643 avg loss: 0.70347 (A-MSE: 0.62096) avg lploss: 0.00000
train epoch 644 avg loss: 0.78269 (A-MSE: 0.69423) avg lploss: 0.00000
train epoch 645 avg loss: 0.79293 (A-MSE: 0.70122) avg lploss: 0.00000
==> val epoch 645 avg loss: 1.66904 (A-MSE: 1.48101) avg lploss: 0.00000
==> test epoch 645 avg loss: 1.74964 (A-MSE: 1.56186) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 6 out of 50
train epoch 646 avg loss: 0.65859 (A-MSE: 0.58426) avg lploss: 0.00000
train epoch 647 avg loss: 0.68363 (A-MSE: 0.60956) avg lploss: 0.00000
train epoch 648 avg loss: 0.71260 (A-MSE: 0.63074) avg lploss: 0.00000
train epoch 649 avg loss: 0.66332 (A-MSE: 0.58824) avg lploss: 0.00000
train epoch 650 avg loss: 0.71163 (A-MSE: 0.63168) avg lploss: 0.00000
==> val epoch 650 avg loss: 1.65096 (A-MSE: 1.47743) avg lploss: 0.00000
==> test epoch 650 avg loss: 1.85401 (A-MSE: 1.67532) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 7 out of 50
train epoch 651 avg loss: 0.77087 (A-MSE: 0.68896) avg lploss: 0.00000
train epoch 652 avg loss: 0.74717 (A-MSE: 0.66024) avg lploss: 0.00000
train epoch 653 avg loss: 0.71517 (A-MSE: 0.63567) avg lploss: 0.00000
train epoch 654 avg loss: 0.81164 (A-MSE: 0.71983) avg lploss: 0.00000
train epoch 655 avg loss: 0.74704 (A-MSE: 0.66447) avg lploss: 0.00000
==> val epoch 655 avg loss: 1.82663 (A-MSE: 1.61885) avg lploss: 0.00000
==> test epoch 655 avg loss: 1.98036 (A-MSE: 1.76390) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 8 out of 50
train epoch 656 avg loss: 0.71915 (A-MSE: 0.63628) avg lploss: 0.00000
train epoch 657 avg loss: 0.66592 (A-MSE: 0.58901) avg lploss: 0.00000
train epoch 658 avg loss: 0.62091 (A-MSE: 0.54869) avg lploss: 0.00000
train epoch 659 avg loss: 0.69396 (A-MSE: 0.61515) avg lploss: 0.00000
train epoch 660 avg loss: 0.67585 (A-MSE: 0.59814) avg lploss: 0.00000
==> val epoch 660 avg loss: 1.86388 (A-MSE: 1.65830) avg lploss: 0.00000
==> test epoch 660 avg loss: 1.87873 (A-MSE: 1.67880) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 9 out of 50
train epoch 661 avg loss: 0.65152 (A-MSE: 0.57796) avg lploss: 0.00000
train epoch 662 avg loss: 0.69894 (A-MSE: 0.61885) avg lploss: 0.00000
train epoch 663 avg loss: 0.69106 (A-MSE: 0.61150) avg lploss: 0.00000
train epoch 664 avg loss: 0.65444 (A-MSE: 0.58156) avg lploss: 0.00000
train epoch 665 avg loss: 0.64093 (A-MSE: 0.56850) avg lploss: 0.00000
==> val epoch 665 avg loss: 1.59457 (A-MSE: 1.41114) avg lploss: 0.00000
==> test epoch 665 avg loss: 1.79129 (A-MSE: 1.59607) avg lploss: 0.00000
*** Best Val Loss: 1.56151 	 Best Test Loss: 1.69204 	 Best epoch 615
EarlyStopping counter: 10 out of 50
train epoch 666 avg loss: 0.67502 (A-MSE: 0.59707) avg lploss: 0.00000
train epoch 667 avg loss: 0.68219 (A-MSE: 0.60386) avg lploss: 0.00000
train epoch 668 avg loss: 0.69653 (A-MSE: 0.61911) avg lploss: 0.00000
train epoch 669 avg loss: 0.77943 (A-MSE: 0.69307) avg lploss: 0.00000
train epoch 670 avg loss: 0.73055 (A-MSE: 0.65099) avg lploss: 0.00000
==> val epoch 670 avg loss: 1.55342 (A-MSE: 1.36892) avg lploss: 0.00000
==> test epoch 670 avg loss: 1.84505 (A-MSE: 1.64702) avg lploss: 0.00000
*** Best Val Loss: 1.55342 	 Best Test Loss: 1.84505 	 Best epoch 670
Validation loss decreased (1.561506 --> 1.553420).  Saving model ...
train epoch 671 avg loss: 0.77266 (A-MSE: 0.69009) avg lploss: 0.00000
train epoch 672 avg loss: 0.76439 (A-MSE: 0.67798) avg lploss: 0.00000
train epoch 673 avg loss: 0.78653 (A-MSE: 0.69524) avg lploss: 0.00000
train epoch 674 avg loss: 0.72731 (A-MSE: 0.64725) avg lploss: 0.00000
train epoch 675 avg loss: 0.74056 (A-MSE: 0.65504) avg lploss: 0.00000
==> val epoch 675 avg loss: 1.53205 (A-MSE: 1.35806) avg lploss: 0.00000
==> test epoch 675 avg loss: 1.83424 (A-MSE: 1.65496) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
Validation loss decreased (1.553420 --> 1.532050).  Saving model ...
train epoch 676 avg loss: 0.68429 (A-MSE: 0.60597) avg lploss: 0.00000
train epoch 677 avg loss: 0.67817 (A-MSE: 0.60137) avg lploss: 0.00000
train epoch 678 avg loss: 0.67490 (A-MSE: 0.59634) avg lploss: 0.00000
train epoch 679 avg loss: 0.75356 (A-MSE: 0.66693) avg lploss: 0.00000
train epoch 680 avg loss: 0.82739 (A-MSE: 0.73462) avg lploss: 0.00000
==> val epoch 680 avg loss: 1.62164 (A-MSE: 1.44563) avg lploss: 0.00000
==> test epoch 680 avg loss: 1.77209 (A-MSE: 1.58729) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 1 out of 50
train epoch 681 avg loss: 0.69278 (A-MSE: 0.61276) avg lploss: 0.00000
train epoch 682 avg loss: 0.76101 (A-MSE: 0.67480) avg lploss: 0.00000
train epoch 683 avg loss: 0.68914 (A-MSE: 0.61302) avg lploss: 0.00000
train epoch 684 avg loss: 0.70850 (A-MSE: 0.62766) avg lploss: 0.00000
train epoch 685 avg loss: 0.69255 (A-MSE: 0.61144) avg lploss: 0.00000
==> val epoch 685 avg loss: 1.77110 (A-MSE: 1.56308) avg lploss: 0.00000
==> test epoch 685 avg loss: 1.86713 (A-MSE: 1.67412) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 2 out of 50
train epoch 686 avg loss: 0.74560 (A-MSE: 0.66115) avg lploss: 0.00000
train epoch 687 avg loss: 0.72110 (A-MSE: 0.63768) avg lploss: 0.00000
train epoch 688 avg loss: 0.65501 (A-MSE: 0.58150) avg lploss: 0.00000
train epoch 689 avg loss: 0.64022 (A-MSE: 0.56619) avg lploss: 0.00000
train epoch 690 avg loss: 0.62778 (A-MSE: 0.55499) avg lploss: 0.00000
==> val epoch 690 avg loss: 1.65490 (A-MSE: 1.47568) avg lploss: 0.00000
==> test epoch 690 avg loss: 1.67810 (A-MSE: 1.49739) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 3 out of 50
train epoch 691 avg loss: 0.64636 (A-MSE: 0.57085) avg lploss: 0.00000
train epoch 692 avg loss: 0.67212 (A-MSE: 0.59310) avg lploss: 0.00000
train epoch 693 avg loss: 0.73996 (A-MSE: 0.65703) avg lploss: 0.00000
train epoch 694 avg loss: 0.70164 (A-MSE: 0.62409) avg lploss: 0.00000
train epoch 695 avg loss: 0.69333 (A-MSE: 0.61815) avg lploss: 0.00000
==> val epoch 695 avg loss: 1.71999 (A-MSE: 1.53471) avg lploss: 0.00000
==> test epoch 695 avg loss: 1.91075 (A-MSE: 1.71637) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 4 out of 50
train epoch 696 avg loss: 0.69388 (A-MSE: 0.61516) avg lploss: 0.00000
train epoch 697 avg loss: 0.64117 (A-MSE: 0.56790) avg lploss: 0.00000
train epoch 698 avg loss: 0.70618 (A-MSE: 0.62256) avg lploss: 0.00000
train epoch 699 avg loss: 0.71841 (A-MSE: 0.64146) avg lploss: 0.00000
train epoch 700 avg loss: 0.65861 (A-MSE: 0.58517) avg lploss: 0.00000
==> val epoch 700 avg loss: 1.56490 (A-MSE: 1.39403) avg lploss: 0.00000
==> test epoch 700 avg loss: 1.66627 (A-MSE: 1.48442) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 5 out of 50
train epoch 701 avg loss: 0.71964 (A-MSE: 0.63769) avg lploss: 0.00000
train epoch 702 avg loss: 0.70457 (A-MSE: 0.62770) avg lploss: 0.00000
train epoch 703 avg loss: 0.61792 (A-MSE: 0.54606) avg lploss: 0.00000
train epoch 704 avg loss: 0.65734 (A-MSE: 0.58263) avg lploss: 0.00000
train epoch 705 avg loss: 0.66804 (A-MSE: 0.59103) avg lploss: 0.00000
==> val epoch 705 avg loss: 1.63204 (A-MSE: 1.44636) avg lploss: 0.00000
==> test epoch 705 avg loss: 1.70115 (A-MSE: 1.51738) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 6 out of 50
train epoch 706 avg loss: 0.61854 (A-MSE: 0.55060) avg lploss: 0.00000
train epoch 707 avg loss: 0.61258 (A-MSE: 0.54100) avg lploss: 0.00000
train epoch 708 avg loss: 0.61872 (A-MSE: 0.55096) avg lploss: 0.00000
train epoch 709 avg loss: 0.64740 (A-MSE: 0.57308) avg lploss: 0.00000
train epoch 710 avg loss: 0.64611 (A-MSE: 0.57199) avg lploss: 0.00000
==> val epoch 710 avg loss: 1.75723 (A-MSE: 1.56934) avg lploss: 0.00000
==> test epoch 710 avg loss: 1.98787 (A-MSE: 1.76919) avg lploss: 0.00000
*** Best Val Loss: 1.53205 	 Best Test Loss: 1.83424 	 Best epoch 675
EarlyStopping counter: 7 out of 50
train epoch 711 avg loss: 0.63100 (A-MSE: 0.56019) avg lploss: 0.00000
train epoch 712 avg loss: 0.63984 (A-MSE: 0.56898) avg lploss: 0.00000
train epoch 713 avg loss: 0.64510 (A-MSE: 0.56846) avg lploss: 0.00000
train epoch 714 avg loss: 0.60477 (A-MSE: 0.53482) avg lploss: 0.00000
train epoch 715 avg loss: 0.63196 (A-MSE: 0.56151) avg lploss: 0.00000
==> val epoch 715 avg loss: 1.46285 (A-MSE: 1.29027) avg lploss: 0.00000
==> test epoch 715 avg loss: 1.57264 (A-MSE: 1.40002) avg lploss: 0.00000
*** Best Val Loss: 1.46285 	 Best Test Loss: 1.57264 	 Best epoch 715
Validation loss decreased (1.532050 --> 1.462851).  Saving model ...
train epoch 716 avg loss: 0.58383 (A-MSE: 0.51672) avg lploss: 0.00000
train epoch 717 avg loss: 0.65749 (A-MSE: 0.58396) avg lploss: 0.00000
train epoch 718 avg loss: 0.62400 (A-MSE: 0.55237) avg lploss: 0.00000
train epoch 719 avg loss: 0.66497 (A-MSE: 0.59113) avg lploss: 0.00000
train epoch 720 avg loss: 0.62135 (A-MSE: 0.54756) avg lploss: 0.00000
==> val epoch 720 avg loss: 1.60694 (A-MSE: 1.41422) avg lploss: 0.00000
==> test epoch 720 avg loss: 1.80343 (A-MSE: 1.61071) avg lploss: 0.00000
*** Best Val Loss: 1.46285 	 Best Test Loss: 1.57264 	 Best epoch 715
EarlyStopping counter: 1 out of 50
train epoch 721 avg loss: 0.62936 (A-MSE: 0.55936) avg lploss: 0.00000
train epoch 722 avg loss: 0.66610 (A-MSE: 0.59541) avg lploss: 0.00000
train epoch 723 avg loss: 0.63909 (A-MSE: 0.56704) avg lploss: 0.00000
train epoch 724 avg loss: 0.65691 (A-MSE: 0.58053) avg lploss: 0.00000
train epoch 725 avg loss: 0.60572 (A-MSE: 0.53611) avg lploss: 0.00000
==> val epoch 725 avg loss: 1.51325 (A-MSE: 1.33559) avg lploss: 0.00000
==> test epoch 725 avg loss: 1.64838 (A-MSE: 1.46527) avg lploss: 0.00000
*** Best Val Loss: 1.46285 	 Best Test Loss: 1.57264 	 Best epoch 715
EarlyStopping counter: 2 out of 50
train epoch 726 avg loss: 0.57078 (A-MSE: 0.50448) avg lploss: 0.00000
train epoch 727 avg loss: 0.65393 (A-MSE: 0.58002) avg lploss: 0.00000
train epoch 728 avg loss: 0.63261 (A-MSE: 0.55643) avg lploss: 0.00000
train epoch 729 avg loss: 0.59934 (A-MSE: 0.53217) avg lploss: 0.00000
train epoch 730 avg loss: 0.60903 (A-MSE: 0.53960) avg lploss: 0.00000
==> val epoch 730 avg loss: 1.67423 (A-MSE: 1.46578) avg lploss: 0.00000
==> test epoch 730 avg loss: 1.93758 (A-MSE: 1.71218) avg lploss: 0.00000
*** Best Val Loss: 1.46285 	 Best Test Loss: 1.57264 	 Best epoch 715
EarlyStopping counter: 3 out of 50
train epoch 731 avg loss: 0.59406 (A-MSE: 0.52916) avg lploss: 0.00000
train epoch 732 avg loss: 0.65141 (A-MSE: 0.57944) avg lploss: 0.00000
train epoch 733 avg loss: 0.66945 (A-MSE: 0.59117) avg lploss: 0.00000
train epoch 734 avg loss: 0.66301 (A-MSE: 0.58925) avg lploss: 0.00000
train epoch 735 avg loss: 0.59439 (A-MSE: 0.52555) avg lploss: 0.00000
==> val epoch 735 avg loss: 1.43045 (A-MSE: 1.27333) avg lploss: 0.00000
==> test epoch 735 avg loss: 1.57773 (A-MSE: 1.40779) avg lploss: 0.00000
*** Best Val Loss: 1.43045 	 Best Test Loss: 1.57773 	 Best epoch 735
Validation loss decreased (1.462851 --> 1.430455).  Saving model ...
train epoch 736 avg loss: 0.59801 (A-MSE: 0.53369) avg lploss: 0.00000
train epoch 737 avg loss: 0.63194 (A-MSE: 0.55943) avg lploss: 0.00000
train epoch 738 avg loss: 0.63349 (A-MSE: 0.55849) avg lploss: 0.00000
train epoch 739 avg loss: 0.56088 (A-MSE: 0.49715) avg lploss: 0.00000
train epoch 740 avg loss: 0.55440 (A-MSE: 0.49077) avg lploss: 0.00000
==> val epoch 740 avg loss: 1.57641 (A-MSE: 1.39715) avg lploss: 0.00000
==> test epoch 740 avg loss: 1.64901 (A-MSE: 1.47303) avg lploss: 0.00000
*** Best Val Loss: 1.43045 	 Best Test Loss: 1.57773 	 Best epoch 735
EarlyStopping counter: 1 out of 50
train epoch 741 avg loss: 0.56333 (A-MSE: 0.49616) avg lploss: 0.00000
train epoch 742 avg loss: 0.59069 (A-MSE: 0.52192) avg lploss: 0.00000
train epoch 743 avg loss: 0.57507 (A-MSE: 0.50740) avg lploss: 0.00000
train epoch 744 avg loss: 0.70548 (A-MSE: 0.62578) avg lploss: 0.00000
train epoch 745 avg loss: 0.64090 (A-MSE: 0.57077) avg lploss: 0.00000
==> val epoch 745 avg loss: 1.57544 (A-MSE: 1.40012) avg lploss: 0.00000
==> test epoch 745 avg loss: 1.71595 (A-MSE: 1.52114) avg lploss: 0.00000
*** Best Val Loss: 1.43045 	 Best Test Loss: 1.57773 	 Best epoch 735
EarlyStopping counter: 2 out of 50
train epoch 746 avg loss: 0.57016 (A-MSE: 0.50446) avg lploss: 0.00000
train epoch 747 avg loss: 0.56899 (A-MSE: 0.50409) avg lploss: 0.00000
train epoch 748 avg loss: 0.56347 (A-MSE: 0.49877) avg lploss: 0.00000
train epoch 749 avg loss: 0.61820 (A-MSE: 0.54619) avg lploss: 0.00000
train epoch 750 avg loss: 0.57888 (A-MSE: 0.51134) avg lploss: 0.00000
==> val epoch 750 avg loss: 1.54990 (A-MSE: 1.37820) avg lploss: 0.00000
==> test epoch 750 avg loss: 1.71212 (A-MSE: 1.52123) avg lploss: 0.00000
*** Best Val Loss: 1.43045 	 Best Test Loss: 1.57773 	 Best epoch 735
EarlyStopping counter: 3 out of 50
train epoch 751 avg loss: 0.55845 (A-MSE: 0.49326) avg lploss: 0.00000
train epoch 752 avg loss: 0.53598 (A-MSE: 0.47160) avg lploss: 0.00000
train epoch 753 avg loss: 0.56698 (A-MSE: 0.50104) avg lploss: 0.00000
train epoch 754 avg loss: 0.59934 (A-MSE: 0.52940) avg lploss: 0.00000
train epoch 755 avg loss: 0.60792 (A-MSE: 0.54094) avg lploss: 0.00000
==> val epoch 755 avg loss: 1.42625 (A-MSE: 1.26377) avg lploss: 0.00000
==> test epoch 755 avg loss: 1.61974 (A-MSE: 1.43386) avg lploss: 0.00000
*** Best Val Loss: 1.42625 	 Best Test Loss: 1.61974 	 Best epoch 755
Validation loss decreased (1.430455 --> 1.426248).  Saving model ...
train epoch 756 avg loss: 0.61457 (A-MSE: 0.54598) avg lploss: 0.00000
train epoch 757 avg loss: 0.59099 (A-MSE: 0.52241) avg lploss: 0.00000
train epoch 758 avg loss: 0.52554 (A-MSE: 0.46479) avg lploss: 0.00000
train epoch 759 avg loss: 0.53514 (A-MSE: 0.46896) avg lploss: 0.00000
train epoch 760 avg loss: 0.56690 (A-MSE: 0.50201) avg lploss: 0.00000
==> val epoch 760 avg loss: 1.45982 (A-MSE: 1.28196) avg lploss: 0.00000
==> test epoch 760 avg loss: 1.60948 (A-MSE: 1.44371) avg lploss: 0.00000
*** Best Val Loss: 1.42625 	 Best Test Loss: 1.61974 	 Best epoch 755
EarlyStopping counter: 1 out of 50
train epoch 761 avg loss: 0.62127 (A-MSE: 0.54834) avg lploss: 0.00000
train epoch 762 avg loss: 0.54184 (A-MSE: 0.47394) avg lploss: 0.00000
train epoch 763 avg loss: 0.62915 (A-MSE: 0.56056) avg lploss: 0.00000
train epoch 764 avg loss: 0.63609 (A-MSE: 0.56404) avg lploss: 0.00000
train epoch 765 avg loss: 0.62223 (A-MSE: 0.54820) avg lploss: 0.00000
==> val epoch 765 avg loss: 1.53521 (A-MSE: 1.34732) avg lploss: 0.00000
==> test epoch 765 avg loss: 1.68419 (A-MSE: 1.49018) avg lploss: 0.00000
*** Best Val Loss: 1.42625 	 Best Test Loss: 1.61974 	 Best epoch 755
EarlyStopping counter: 2 out of 50
train epoch 766 avg loss: 0.59377 (A-MSE: 0.52265) avg lploss: 0.00000
train epoch 767 avg loss: 0.55922 (A-MSE: 0.49306) avg lploss: 0.00000
train epoch 768 avg loss: 0.52258 (A-MSE: 0.46325) avg lploss: 0.00000
train epoch 769 avg loss: 0.55291 (A-MSE: 0.48808) avg lploss: 0.00000
train epoch 770 avg loss: 0.53590 (A-MSE: 0.47224) avg lploss: 0.00000
==> val epoch 770 avg loss: 1.49330 (A-MSE: 1.30779) avg lploss: 0.00000
==> test epoch 770 avg loss: 1.62632 (A-MSE: 1.43367) avg lploss: 0.00000
*** Best Val Loss: 1.42625 	 Best Test Loss: 1.61974 	 Best epoch 755
EarlyStopping counter: 3 out of 50
train epoch 771 avg loss: 0.55428 (A-MSE: 0.49117) avg lploss: 0.00000
train epoch 772 avg loss: 0.58528 (A-MSE: 0.51658) avg lploss: 0.00000
train epoch 773 avg loss: 0.59001 (A-MSE: 0.51891) avg lploss: 0.00000
train epoch 774 avg loss: 0.58218 (A-MSE: 0.51227) avg lploss: 0.00000
train epoch 775 avg loss: 0.59892 (A-MSE: 0.52798) avg lploss: 0.00000
==> val epoch 775 avg loss: 1.57140 (A-MSE: 1.41082) avg lploss: 0.00000
==> test epoch 775 avg loss: 1.75262 (A-MSE: 1.56722) avg lploss: 0.00000
*** Best Val Loss: 1.42625 	 Best Test Loss: 1.61974 	 Best epoch 755
EarlyStopping counter: 4 out of 50
train epoch 776 avg loss: 0.52969 (A-MSE: 0.46793) avg lploss: 0.00000
train epoch 777 avg loss: 0.52385 (A-MSE: 0.46080) avg lploss: 0.00000
train epoch 778 avg loss: 0.61452 (A-MSE: 0.54504) avg lploss: 0.00000
train epoch 779 avg loss: 0.61505 (A-MSE: 0.54296) avg lploss: 0.00000
train epoch 780 avg loss: 0.58682 (A-MSE: 0.52007) avg lploss: 0.00000
==> val epoch 780 avg loss: 1.95876 (A-MSE: 1.71211) avg lploss: 0.00000
==> test epoch 780 avg loss: 2.06692 (A-MSE: 1.81982) avg lploss: 0.00000
*** Best Val Loss: 1.42625 	 Best Test Loss: 1.61974 	 Best epoch 755
EarlyStopping counter: 5 out of 50
train epoch 781 avg loss: 0.64203 (A-MSE: 0.57050) avg lploss: 0.00000
train epoch 782 avg loss: 0.63115 (A-MSE: 0.55900) avg lploss: 0.00000
train epoch 783 avg loss: 0.53201 (A-MSE: 0.47006) avg lploss: 0.00000
train epoch 784 avg loss: 0.53283 (A-MSE: 0.46801) avg lploss: 0.00000
train epoch 785 avg loss: 0.60929 (A-MSE: 0.54105) avg lploss: 0.00000
==> val epoch 785 avg loss: 1.41905 (A-MSE: 1.23444) avg lploss: 0.00000
==> test epoch 785 avg loss: 1.58582 (A-MSE: 1.39634) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
Validation loss decreased (1.426248 --> 1.419052).  Saving model ...
train epoch 786 avg loss: 0.56801 (A-MSE: 0.49890) avg lploss: 0.00000
train epoch 787 avg loss: 0.57564 (A-MSE: 0.50929) avg lploss: 0.00000
train epoch 788 avg loss: 0.55541 (A-MSE: 0.48985) avg lploss: 0.00000
train epoch 789 avg loss: 0.56783 (A-MSE: 0.49921) avg lploss: 0.00000
train epoch 790 avg loss: 0.81747 (A-MSE: 0.70580) avg lploss: 0.00000
==> val epoch 790 avg loss: 3.13182 (A-MSE: 2.73953) avg lploss: 0.00000
==> test epoch 790 avg loss: 3.35126 (A-MSE: 2.95170) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 1 out of 50
train epoch 791 avg loss: 1.55078 (A-MSE: 1.37593) avg lploss: 0.00000
train epoch 792 avg loss: 0.81528 (A-MSE: 0.71937) avg lploss: 0.00000
train epoch 793 avg loss: 0.62681 (A-MSE: 0.54689) avg lploss: 0.00000
train epoch 794 avg loss: 0.60476 (A-MSE: 0.53704) avg lploss: 0.00000
train epoch 795 avg loss: 0.55137 (A-MSE: 0.48562) avg lploss: 0.00000
==> val epoch 795 avg loss: 1.60188 (A-MSE: 1.42011) avg lploss: 0.00000
==> test epoch 795 avg loss: 1.79972 (A-MSE: 1.59589) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 2 out of 50
train epoch 796 avg loss: 0.56002 (A-MSE: 0.49225) avg lploss: 0.00000
train epoch 797 avg loss: 0.54779 (A-MSE: 0.48472) avg lploss: 0.00000
train epoch 798 avg loss: 0.52287 (A-MSE: 0.46128) avg lploss: 0.00000
train epoch 799 avg loss: 0.54622 (A-MSE: 0.48012) avg lploss: 0.00000
train epoch 800 avg loss: 0.51159 (A-MSE: 0.44975) avg lploss: 0.00000
==> val epoch 800 avg loss: 1.58016 (A-MSE: 1.39910) avg lploss: 0.00000
==> test epoch 800 avg loss: 1.67933 (A-MSE: 1.48248) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 3 out of 50
train epoch 801 avg loss: 0.49959 (A-MSE: 0.44128) avg lploss: 0.00000
train epoch 802 avg loss: 0.47076 (A-MSE: 0.41360) avg lploss: 0.00000
train epoch 803 avg loss: 0.49027 (A-MSE: 0.43448) avg lploss: 0.00000
train epoch 804 avg loss: 0.50173 (A-MSE: 0.44223) avg lploss: 0.00000
train epoch 805 avg loss: 0.49508 (A-MSE: 0.43487) avg lploss: 0.00000
==> val epoch 805 avg loss: 1.57895 (A-MSE: 1.39856) avg lploss: 0.00000
==> test epoch 805 avg loss: 1.66954 (A-MSE: 1.47675) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 4 out of 50
train epoch 806 avg loss: 0.52792 (A-MSE: 0.46930) avg lploss: 0.00000
train epoch 807 avg loss: 0.50626 (A-MSE: 0.44416) avg lploss: 0.00000
train epoch 808 avg loss: 0.48874 (A-MSE: 0.42923) avg lploss: 0.00000
train epoch 809 avg loss: 0.48338 (A-MSE: 0.42638) avg lploss: 0.00000
train epoch 810 avg loss: 0.48331 (A-MSE: 0.42466) avg lploss: 0.00000
==> val epoch 810 avg loss: 1.52470 (A-MSE: 1.34480) avg lploss: 0.00000
==> test epoch 810 avg loss: 1.73484 (A-MSE: 1.53376) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 5 out of 50
train epoch 811 avg loss: 0.51421 (A-MSE: 0.45581) avg lploss: 0.00000
train epoch 812 avg loss: 0.49837 (A-MSE: 0.43870) avg lploss: 0.00000
train epoch 813 avg loss: 0.52843 (A-MSE: 0.46712) avg lploss: 0.00000
train epoch 814 avg loss: 0.53255 (A-MSE: 0.47182) avg lploss: 0.00000
train epoch 815 avg loss: 0.50439 (A-MSE: 0.44725) avg lploss: 0.00000
==> val epoch 815 avg loss: 1.73999 (A-MSE: 1.52047) avg lploss: 0.00000
==> test epoch 815 avg loss: 2.04754 (A-MSE: 1.78534) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 6 out of 50
train epoch 816 avg loss: 0.49700 (A-MSE: 0.43707) avg lploss: 0.00000
train epoch 817 avg loss: 0.49254 (A-MSE: 0.42954) avg lploss: 0.00000
train epoch 818 avg loss: 0.50438 (A-MSE: 0.44339) avg lploss: 0.00000
train epoch 819 avg loss: 0.51697 (A-MSE: 0.45212) avg lploss: 0.00000
train epoch 820 avg loss: 0.49452 (A-MSE: 0.43716) avg lploss: 0.00000
==> val epoch 820 avg loss: 1.43951 (A-MSE: 1.25941) avg lploss: 0.00000
==> test epoch 820 avg loss: 1.52097 (A-MSE: 1.34310) avg lploss: 0.00000
*** Best Val Loss: 1.41905 	 Best Test Loss: 1.58582 	 Best epoch 785
EarlyStopping counter: 7 out of 50
train epoch 821 avg loss: 0.51572 (A-MSE: 0.45538) avg lploss: 0.00000
train epoch 822 avg loss: 0.53259 (A-MSE: 0.47269) avg lploss: 0.00000
train epoch 823 avg loss: 0.54453 (A-MSE: 0.47909) avg lploss: 0.00000
train epoch 824 avg loss: 0.48849 (A-MSE: 0.43286) avg lploss: 0.00000
train epoch 825 avg loss: 0.44071 (A-MSE: 0.38510) avg lploss: 0.00000
==> val epoch 825 avg loss: 1.35422 (A-MSE: 1.18231) avg lploss: 0.00000
==> test epoch 825 avg loss: 1.54459 (A-MSE: 1.35349) avg lploss: 0.00000
*** Best Val Loss: 1.35422 	 Best Test Loss: 1.54459 	 Best epoch 825
Validation loss decreased (1.419052 --> 1.354216).  Saving model ...
train epoch 826 avg loss: 0.46722 (A-MSE: 0.40936) avg lploss: 0.00000
train epoch 827 avg loss: 0.51262 (A-MSE: 0.45110) avg lploss: 0.00000
train epoch 828 avg loss: 0.51501 (A-MSE: 0.45665) avg lploss: 0.00000
train epoch 829 avg loss: 0.47765 (A-MSE: 0.42352) avg lploss: 0.00000
train epoch 830 avg loss: 0.48223 (A-MSE: 0.42218) avg lploss: 0.00000
==> val epoch 830 avg loss: 1.37875 (A-MSE: 1.21078) avg lploss: 0.00000
==> test epoch 830 avg loss: 1.56140 (A-MSE: 1.36050) avg lploss: 0.00000
*** Best Val Loss: 1.35422 	 Best Test Loss: 1.54459 	 Best epoch 825
EarlyStopping counter: 1 out of 50
train epoch 831 avg loss: 0.54933 (A-MSE: 0.48412) avg lploss: 0.00000
train epoch 832 avg loss: 0.57209 (A-MSE: 0.50476) avg lploss: 0.00000
train epoch 833 avg loss: 0.54812 (A-MSE: 0.48433) avg lploss: 0.00000
train epoch 834 avg loss: 0.52577 (A-MSE: 0.46124) avg lploss: 0.00000
train epoch 835 avg loss: 0.49342 (A-MSE: 0.43461) avg lploss: 0.00000
==> val epoch 835 avg loss: 1.42121 (A-MSE: 1.25662) avg lploss: 0.00000
==> test epoch 835 avg loss: 1.55862 (A-MSE: 1.37831) avg lploss: 0.00000
*** Best Val Loss: 1.35422 	 Best Test Loss: 1.54459 	 Best epoch 825
EarlyStopping counter: 2 out of 50
train epoch 836 avg loss: 0.54518 (A-MSE: 0.48433) avg lploss: 0.00000
train epoch 837 avg loss: 0.62857 (A-MSE: 0.55681) avg lploss: 0.00000
train epoch 838 avg loss: 0.54236 (A-MSE: 0.47992) avg lploss: 0.00000
train epoch 839 avg loss: 0.52384 (A-MSE: 0.46007) avg lploss: 0.00000
train epoch 840 avg loss: 0.51022 (A-MSE: 0.44865) avg lploss: 0.00000
==> val epoch 840 avg loss: 1.37658 (A-MSE: 1.21124) avg lploss: 0.00000
==> test epoch 840 avg loss: 1.47670 (A-MSE: 1.30612) avg lploss: 0.00000
*** Best Val Loss: 1.35422 	 Best Test Loss: 1.54459 	 Best epoch 825
EarlyStopping counter: 3 out of 50
train epoch 841 avg loss: 0.53761 (A-MSE: 0.47705) avg lploss: 0.00000
train epoch 842 avg loss: 0.52367 (A-MSE: 0.46245) avg lploss: 0.00000
train epoch 843 avg loss: 0.43754 (A-MSE: 0.38357) avg lploss: 0.00000
train epoch 844 avg loss: 0.44281 (A-MSE: 0.38824) avg lploss: 0.00000
train epoch 845 avg loss: 0.47978 (A-MSE: 0.42328) avg lploss: 0.00000
==> val epoch 845 avg loss: 1.35034 (A-MSE: 1.19609) avg lploss: 0.00000
==> test epoch 845 avg loss: 1.54595 (A-MSE: 1.35870) avg lploss: 0.00000
*** Best Val Loss: 1.35034 	 Best Test Loss: 1.54595 	 Best epoch 845
Validation loss decreased (1.354216 --> 1.350344).  Saving model ...
train epoch 846 avg loss: 0.47819 (A-MSE: 0.42317) avg lploss: 0.00000
train epoch 847 avg loss: 0.44314 (A-MSE: 0.39124) avg lploss: 0.00000
train epoch 848 avg loss: 0.48442 (A-MSE: 0.42861) avg lploss: 0.00000
train epoch 849 avg loss: 0.53241 (A-MSE: 0.46834) avg lploss: 0.00000
train epoch 850 avg loss: 0.50493 (A-MSE: 0.44488) avg lploss: 0.00000
==> val epoch 850 avg loss: 1.23828 (A-MSE: 1.09666) avg lploss: 0.00000
==> test epoch 850 avg loss: 1.43226 (A-MSE: 1.26503) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
Validation loss decreased (1.350344 --> 1.238283).  Saving model ...
train epoch 851 avg loss: 0.47334 (A-MSE: 0.41748) avg lploss: 0.00000
train epoch 852 avg loss: 0.45391 (A-MSE: 0.40258) avg lploss: 0.00000
train epoch 853 avg loss: 0.45463 (A-MSE: 0.40211) avg lploss: 0.00000
train epoch 854 avg loss: 0.46703 (A-MSE: 0.41071) avg lploss: 0.00000
train epoch 855 avg loss: 0.55332 (A-MSE: 0.48504) avg lploss: 0.00000
==> val epoch 855 avg loss: 1.46046 (A-MSE: 1.28995) avg lploss: 0.00000
==> test epoch 855 avg loss: 1.59280 (A-MSE: 1.41413) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 1 out of 50
train epoch 856 avg loss: 0.54827 (A-MSE: 0.48584) avg lploss: 0.00000
train epoch 857 avg loss: 0.48137 (A-MSE: 0.42305) avg lploss: 0.00000
train epoch 858 avg loss: 0.45453 (A-MSE: 0.39723) avg lploss: 0.00000
train epoch 859 avg loss: 0.48693 (A-MSE: 0.42826) avg lploss: 0.00000
train epoch 860 avg loss: 0.49806 (A-MSE: 0.44404) avg lploss: 0.00000
==> val epoch 860 avg loss: 1.31466 (A-MSE: 1.15627) avg lploss: 0.00000
==> test epoch 860 avg loss: 1.47465 (A-MSE: 1.29260) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 2 out of 50
train epoch 861 avg loss: 0.46583 (A-MSE: 0.40790) avg lploss: 0.00000
train epoch 862 avg loss: 0.43898 (A-MSE: 0.38648) avg lploss: 0.00000
train epoch 863 avg loss: 0.41813 (A-MSE: 0.36907) avg lploss: 0.00000
train epoch 864 avg loss: 0.48516 (A-MSE: 0.42887) avg lploss: 0.00000
train epoch 865 avg loss: 0.47386 (A-MSE: 0.41869) avg lploss: 0.00000
==> val epoch 865 avg loss: 1.32546 (A-MSE: 1.16179) avg lploss: 0.00000
==> test epoch 865 avg loss: 1.57643 (A-MSE: 1.39044) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 3 out of 50
train epoch 866 avg loss: 0.41534 (A-MSE: 0.36746) avg lploss: 0.00000
train epoch 867 avg loss: 0.43240 (A-MSE: 0.38110) avg lploss: 0.00000
train epoch 868 avg loss: 0.43887 (A-MSE: 0.38768) avg lploss: 0.00000
train epoch 869 avg loss: 0.46171 (A-MSE: 0.40974) avg lploss: 0.00000
train epoch 870 avg loss: 0.45481 (A-MSE: 0.40162) avg lploss: 0.00000
==> val epoch 870 avg loss: 1.28423 (A-MSE: 1.13168) avg lploss: 0.00000
==> test epoch 870 avg loss: 1.41460 (A-MSE: 1.24948) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 4 out of 50
train epoch 871 avg loss: 0.44922 (A-MSE: 0.39468) avg lploss: 0.00000
train epoch 872 avg loss: 0.47520 (A-MSE: 0.41946) avg lploss: 0.00000
train epoch 873 avg loss: 0.49901 (A-MSE: 0.44362) avg lploss: 0.00000
train epoch 874 avg loss: 0.46295 (A-MSE: 0.40608) avg lploss: 0.00000
train epoch 875 avg loss: 0.48663 (A-MSE: 0.42941) avg lploss: 0.00000
==> val epoch 875 avg loss: 1.25384 (A-MSE: 1.11436) avg lploss: 0.00000
==> test epoch 875 avg loss: 1.39996 (A-MSE: 1.25635) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 5 out of 50
train epoch 876 avg loss: 0.51166 (A-MSE: 0.45428) avg lploss: 0.00000
train epoch 877 avg loss: 0.63335 (A-MSE: 0.55902) avg lploss: 0.00000
train epoch 878 avg loss: 0.52180 (A-MSE: 0.46031) avg lploss: 0.00000
train epoch 879 avg loss: 0.41511 (A-MSE: 0.36744) avg lploss: 0.00000
train epoch 880 avg loss: 0.39880 (A-MSE: 0.35014) avg lploss: 0.00000
==> val epoch 880 avg loss: 1.29066 (A-MSE: 1.15060) avg lploss: 0.00000
==> test epoch 880 avg loss: 1.50131 (A-MSE: 1.33201) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 6 out of 50
train epoch 881 avg loss: 0.42457 (A-MSE: 0.37720) avg lploss: 0.00000
train epoch 882 avg loss: 0.42184 (A-MSE: 0.37067) avg lploss: 0.00000
train epoch 883 avg loss: 0.40161 (A-MSE: 0.35331) avg lploss: 0.00000
train epoch 884 avg loss: 0.43921 (A-MSE: 0.39177) avg lploss: 0.00000
train epoch 885 avg loss: 0.41626 (A-MSE: 0.36815) avg lploss: 0.00000
==> val epoch 885 avg loss: 1.48822 (A-MSE: 1.31258) avg lploss: 0.00000
==> test epoch 885 avg loss: 1.70662 (A-MSE: 1.49799) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 7 out of 50
train epoch 886 avg loss: 0.44198 (A-MSE: 0.39062) avg lploss: 0.00000
train epoch 887 avg loss: 0.46578 (A-MSE: 0.41278) avg lploss: 0.00000
train epoch 888 avg loss: 0.44464 (A-MSE: 0.39082) avg lploss: 0.00000
train epoch 889 avg loss: 0.45706 (A-MSE: 0.40141) avg lploss: 0.00000
train epoch 890 avg loss: 0.45963 (A-MSE: 0.40550) avg lploss: 0.00000
==> val epoch 890 avg loss: 1.35971 (A-MSE: 1.18928) avg lploss: 0.00000
==> test epoch 890 avg loss: 1.52394 (A-MSE: 1.33696) avg lploss: 0.00000
*** Best Val Loss: 1.23828 	 Best Test Loss: 1.43226 	 Best epoch 850
EarlyStopping counter: 8 out of 50
train epoch 891 avg loss: 0.44268 (A-MSE: 0.39094) avg lploss: 0.00000
train epoch 892 avg loss: 0.43815 (A-MSE: 0.38807) avg lploss: 0.00000
train epoch 893 avg loss: 0.47604 (A-MSE: 0.41993) avg lploss: 0.00000
train epoch 894 avg loss: 0.45377 (A-MSE: 0.40159) avg lploss: 0.00000
train epoch 895 avg loss: 0.39703 (A-MSE: 0.34948) avg lploss: 0.00000
==> val epoch 895 avg loss: 1.12326 (A-MSE: 1.00889) avg lploss: 0.00000
==> test epoch 895 avg loss: 1.27703 (A-MSE: 1.13907) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
Validation loss decreased (1.238283 --> 1.123259).  Saving model ...
train epoch 896 avg loss: 0.38405 (A-MSE: 0.33936) avg lploss: 0.00000
train epoch 897 avg loss: 0.41749 (A-MSE: 0.36787) avg lploss: 0.00000
train epoch 898 avg loss: 0.43188 (A-MSE: 0.38446) avg lploss: 0.00000
train epoch 899 avg loss: 0.39381 (A-MSE: 0.34756) avg lploss: 0.00000
train epoch 900 avg loss: 0.42303 (A-MSE: 0.37619) avg lploss: 0.00000
==> val epoch 900 avg loss: 1.47615 (A-MSE: 1.30051) avg lploss: 0.00000
==> test epoch 900 avg loss: 1.56920 (A-MSE: 1.38842) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 1 out of 50
train epoch 901 avg loss: 0.43871 (A-MSE: 0.38779) avg lploss: 0.00000
train epoch 902 avg loss: 0.40193 (A-MSE: 0.35570) avg lploss: 0.00000
train epoch 903 avg loss: 0.39648 (A-MSE: 0.35030) avg lploss: 0.00000
train epoch 904 avg loss: 0.39902 (A-MSE: 0.35066) avg lploss: 0.00000
train epoch 905 avg loss: 0.46191 (A-MSE: 0.41032) avg lploss: 0.00000
==> val epoch 905 avg loss: 1.50130 (A-MSE: 1.34583) avg lploss: 0.00000
==> test epoch 905 avg loss: 1.59436 (A-MSE: 1.43231) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 2 out of 50
train epoch 906 avg loss: 0.49753 (A-MSE: 0.43557) avg lploss: 0.00000
train epoch 907 avg loss: 0.46540 (A-MSE: 0.41164) avg lploss: 0.00000
train epoch 908 avg loss: 0.37781 (A-MSE: 0.33497) avg lploss: 0.00000
train epoch 909 avg loss: 0.36047 (A-MSE: 0.31926) avg lploss: 0.00000
train epoch 910 avg loss: 0.38693 (A-MSE: 0.34179) avg lploss: 0.00000
==> val epoch 910 avg loss: 1.21942 (A-MSE: 1.07723) avg lploss: 0.00000
==> test epoch 910 avg loss: 1.37313 (A-MSE: 1.20525) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 3 out of 50
train epoch 911 avg loss: 0.41625 (A-MSE: 0.36711) avg lploss: 0.00000
train epoch 912 avg loss: 0.42518 (A-MSE: 0.37862) avg lploss: 0.00000
train epoch 913 avg loss: 0.49965 (A-MSE: 0.44251) avg lploss: 0.00000
train epoch 914 avg loss: 0.54339 (A-MSE: 0.48642) avg lploss: 0.00000
train epoch 915 avg loss: 0.47404 (A-MSE: 0.41800) avg lploss: 0.00000
==> val epoch 915 avg loss: 1.28151 (A-MSE: 1.12625) avg lploss: 0.00000
==> test epoch 915 avg loss: 1.50144 (A-MSE: 1.32556) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 4 out of 50
train epoch 916 avg loss: 0.43149 (A-MSE: 0.38170) avg lploss: 0.00000
train epoch 917 avg loss: 0.45010 (A-MSE: 0.39779) avg lploss: 0.00000
train epoch 918 avg loss: 0.39526 (A-MSE: 0.35101) avg lploss: 0.00000
train epoch 919 avg loss: 0.38124 (A-MSE: 0.33592) avg lploss: 0.00000
train epoch 920 avg loss: 0.38504 (A-MSE: 0.33943) avg lploss: 0.00000
==> val epoch 920 avg loss: 1.15600 (A-MSE: 1.02346) avg lploss: 0.00000
==> test epoch 920 avg loss: 1.27890 (A-MSE: 1.13279) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 5 out of 50
train epoch 921 avg loss: 0.40089 (A-MSE: 0.35455) avg lploss: 0.00000
train epoch 922 avg loss: 0.40277 (A-MSE: 0.35703) avg lploss: 0.00000
train epoch 923 avg loss: 0.39350 (A-MSE: 0.34688) avg lploss: 0.00000
train epoch 924 avg loss: 0.37800 (A-MSE: 0.33440) avg lploss: 0.00000
train epoch 925 avg loss: 0.40092 (A-MSE: 0.35323) avg lploss: 0.00000
==> val epoch 925 avg loss: 1.43071 (A-MSE: 1.26695) avg lploss: 0.00000
==> test epoch 925 avg loss: 1.56507 (A-MSE: 1.38586) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 6 out of 50
train epoch 926 avg loss: 0.39528 (A-MSE: 0.35053) avg lploss: 0.00000
train epoch 927 avg loss: 0.41889 (A-MSE: 0.37195) avg lploss: 0.00000
train epoch 928 avg loss: 0.38127 (A-MSE: 0.33483) avg lploss: 0.00000
train epoch 929 avg loss: 0.36716 (A-MSE: 0.32367) avg lploss: 0.00000
train epoch 930 avg loss: 0.38212 (A-MSE: 0.33663) avg lploss: 0.00000
==> val epoch 930 avg loss: 1.32356 (A-MSE: 1.16715) avg lploss: 0.00000
==> test epoch 930 avg loss: 1.46709 (A-MSE: 1.28262) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 7 out of 50
train epoch 931 avg loss: 0.41233 (A-MSE: 0.36315) avg lploss: 0.00000
train epoch 932 avg loss: 0.40574 (A-MSE: 0.35805) avg lploss: 0.00000
train epoch 933 avg loss: 0.40648 (A-MSE: 0.36214) avg lploss: 0.00000
train epoch 934 avg loss: 0.41631 (A-MSE: 0.36729) avg lploss: 0.00000
train epoch 935 avg loss: 0.40313 (A-MSE: 0.35432) avg lploss: 0.00000
==> val epoch 935 avg loss: 1.14894 (A-MSE: 1.02614) avg lploss: 0.00000
==> test epoch 935 avg loss: 1.33815 (A-MSE: 1.18499) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 8 out of 50
train epoch 936 avg loss: 0.40501 (A-MSE: 0.35638) avg lploss: 0.00000
train epoch 937 avg loss: 0.44350 (A-MSE: 0.39517) avg lploss: 0.00000
train epoch 938 avg loss: 0.43161 (A-MSE: 0.37909) avg lploss: 0.00000
train epoch 939 avg loss: 0.42351 (A-MSE: 0.37581) avg lploss: 0.00000
train epoch 940 avg loss: 0.45560 (A-MSE: 0.40331) avg lploss: 0.00000
==> val epoch 940 avg loss: 1.14815 (A-MSE: 1.02001) avg lploss: 0.00000
==> test epoch 940 avg loss: 1.33354 (A-MSE: 1.18050) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 9 out of 50
train epoch 941 avg loss: 0.41366 (A-MSE: 0.36650) avg lploss: 0.00000
train epoch 942 avg loss: 0.42431 (A-MSE: 0.37610) avg lploss: 0.00000
train epoch 943 avg loss: 0.44819 (A-MSE: 0.39820) avg lploss: 0.00000
train epoch 944 avg loss: 0.45957 (A-MSE: 0.40566) avg lploss: 0.00000
train epoch 945 avg loss: 0.41804 (A-MSE: 0.37076) avg lploss: 0.00000
==> val epoch 945 avg loss: 1.29752 (A-MSE: 1.14789) avg lploss: 0.00000
==> test epoch 945 avg loss: 1.53653 (A-MSE: 1.35305) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 10 out of 50
train epoch 946 avg loss: 0.40352 (A-MSE: 0.35802) avg lploss: 0.00000
train epoch 947 avg loss: 0.38623 (A-MSE: 0.33852) avg lploss: 0.00000
train epoch 948 avg loss: 0.37848 (A-MSE: 0.33500) avg lploss: 0.00000
train epoch 949 avg loss: 0.36190 (A-MSE: 0.31825) avg lploss: 0.00000
train epoch 950 avg loss: 0.36113 (A-MSE: 0.31674) avg lploss: 0.00000
==> val epoch 950 avg loss: 1.16385 (A-MSE: 1.03095) avg lploss: 0.00000
==> test epoch 950 avg loss: 1.38882 (A-MSE: 1.21787) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 11 out of 50
train epoch 951 avg loss: 0.36197 (A-MSE: 0.32143) avg lploss: 0.00000
train epoch 952 avg loss: 0.40775 (A-MSE: 0.35673) avg lploss: 0.00000
train epoch 953 avg loss: 0.46497 (A-MSE: 0.41329) avg lploss: 0.00000
train epoch 954 avg loss: 0.39715 (A-MSE: 0.35138) avg lploss: 0.00000
train epoch 955 avg loss: 0.41001 (A-MSE: 0.35885) avg lploss: 0.00000
==> val epoch 955 avg loss: 1.28816 (A-MSE: 1.14799) avg lploss: 0.00000
==> test epoch 955 avg loss: 1.50877 (A-MSE: 1.32175) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 12 out of 50
train epoch 956 avg loss: 0.42068 (A-MSE: 0.36957) avg lploss: 0.00000
train epoch 957 avg loss: 0.42336 (A-MSE: 0.37478) avg lploss: 0.00000
train epoch 958 avg loss: 0.38496 (A-MSE: 0.34109) avg lploss: 0.00000
train epoch 959 avg loss: 0.35881 (A-MSE: 0.31227) avg lploss: 0.00000
train epoch 960 avg loss: 0.36834 (A-MSE: 0.32274) avg lploss: 0.00000
==> val epoch 960 avg loss: 1.15810 (A-MSE: 1.03402) avg lploss: 0.00000
==> test epoch 960 avg loss: 1.33570 (A-MSE: 1.18849) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 13 out of 50
train epoch 961 avg loss: 0.33328 (A-MSE: 0.29319) avg lploss: 0.00000
train epoch 962 avg loss: 0.34024 (A-MSE: 0.29857) avg lploss: 0.00000
train epoch 963 avg loss: 0.35283 (A-MSE: 0.31115) avg lploss: 0.00000
train epoch 964 avg loss: 0.36064 (A-MSE: 0.31786) avg lploss: 0.00000
train epoch 965 avg loss: 0.33850 (A-MSE: 0.29923) avg lploss: 0.00000
==> val epoch 965 avg loss: 1.15992 (A-MSE: 1.03096) avg lploss: 0.00000
==> test epoch 965 avg loss: 1.33115 (A-MSE: 1.17807) avg lploss: 0.00000
*** Best Val Loss: 1.12326 	 Best Test Loss: 1.27703 	 Best epoch 895
EarlyStopping counter: 14 out of 50
train epoch 966 avg loss: 0.37422 (A-MSE: 0.33358) avg lploss: 0.00000
train epoch 967 avg loss: 0.40565 (A-MSE: 0.35905) avg lploss: 0.00000
train epoch 968 avg loss: 0.36070 (A-MSE: 0.31838) avg lploss: 0.00000
train epoch 969 avg loss: 0.34661 (A-MSE: 0.30768) avg lploss: 0.00000
train epoch 970 avg loss: 0.33907 (A-MSE: 0.29908) avg lploss: 0.00000
==> val epoch 970 avg loss: 1.09497 (A-MSE: 0.98468) avg lploss: 0.00000
==> test epoch 970 avg loss: 1.22878 (A-MSE: 1.09108) avg lploss: 0.00000
*** Best Val Loss: 1.09497 	 Best Test Loss: 1.22878 	 Best epoch 970
Validation loss decreased (1.123259 --> 1.094967).  Saving model ...
train epoch 971 avg loss: 0.34010 (A-MSE: 0.29860) avg lploss: 0.00000
train epoch 972 avg loss: 0.40318 (A-MSE: 0.35334) avg lploss: 0.00000
train epoch 973 avg loss: 0.42684 (A-MSE: 0.37746) avg lploss: 0.00000
train epoch 974 avg loss: 0.34663 (A-MSE: 0.30596) avg lploss: 0.00000
train epoch 975 avg loss: 0.36304 (A-MSE: 0.32131) avg lploss: 0.00000
==> val epoch 975 avg loss: 1.25404 (A-MSE: 1.11416) avg lploss: 0.00000
==> test epoch 975 avg loss: 1.34939 (A-MSE: 1.19991) avg lploss: 0.00000
*** Best Val Loss: 1.09497 	 Best Test Loss: 1.22878 	 Best epoch 970
EarlyStopping counter: 1 out of 50
train epoch 976 avg loss: 0.37581 (A-MSE: 0.33333) avg lploss: 0.00000
train epoch 977 avg loss: 0.39570 (A-MSE: 0.34983) avg lploss: 0.00000
train epoch 978 avg loss: 0.38093 (A-MSE: 0.33789) avg lploss: 0.00000
train epoch 979 avg loss: 0.45270 (A-MSE: 0.39881) avg lploss: 0.00000
train epoch 980 avg loss: 0.41180 (A-MSE: 0.36103) avg lploss: 0.00000
==> val epoch 980 avg loss: 1.17646 (A-MSE: 1.04468) avg lploss: 0.00000
==> test epoch 980 avg loss: 1.42870 (A-MSE: 1.25994) avg lploss: 0.00000
*** Best Val Loss: 1.09497 	 Best Test Loss: 1.22878 	 Best epoch 970
EarlyStopping counter: 2 out of 50
train epoch 981 avg loss: 0.38795 (A-MSE: 0.34266) avg lploss: 0.00000
train epoch 982 avg loss: 0.37612 (A-MSE: 0.33014) avg lploss: 0.00000
train epoch 983 avg loss: 0.36137 (A-MSE: 0.31764) avg lploss: 0.00000
train epoch 984 avg loss: 0.34545 (A-MSE: 0.30573) avg lploss: 0.00000
train epoch 985 avg loss: 0.36261 (A-MSE: 0.32168) avg lploss: 0.00000
==> val epoch 985 avg loss: 1.33701 (A-MSE: 1.16246) avg lploss: 0.00000
==> test epoch 985 avg loss: 1.45811 (A-MSE: 1.27849) avg lploss: 0.00000
*** Best Val Loss: 1.09497 	 Best Test Loss: 1.22878 	 Best epoch 970
EarlyStopping counter: 3 out of 50
train epoch 986 avg loss: 0.37681 (A-MSE: 0.33008) avg lploss: 0.00000
train epoch 987 avg loss: 0.45215 (A-MSE: 0.40292) avg lploss: 0.00000
train epoch 988 avg loss: 0.44967 (A-MSE: 0.39931) avg lploss: 0.00000
train epoch 989 avg loss: 0.38751 (A-MSE: 0.34360) avg lploss: 0.00000
train epoch 990 avg loss: 0.37624 (A-MSE: 0.33111) avg lploss: 0.00000
==> val epoch 990 avg loss: 1.08435 (A-MSE: 0.97231) avg lploss: 0.00000
==> test epoch 990 avg loss: 1.15437 (A-MSE: 1.04470) avg lploss: 0.00000
*** Best Val Loss: 1.08435 	 Best Test Loss: 1.15437 	 Best epoch 990
Validation loss decreased (1.094967 --> 1.084355).  Saving model ...
train epoch 991 avg loss: 0.35390 (A-MSE: 0.31118) avg lploss: 0.00000
train epoch 992 avg loss: 0.36478 (A-MSE: 0.32074) avg lploss: 0.00000
train epoch 993 avg loss: 0.39983 (A-MSE: 0.35342) avg lploss: 0.00000
train epoch 994 avg loss: 0.37560 (A-MSE: 0.32728) avg lploss: 0.00000
train epoch 995 avg loss: 0.33634 (A-MSE: 0.29513) avg lploss: 0.00000
==> val epoch 995 avg loss: 1.14054 (A-MSE: 1.03232) avg lploss: 0.00000
==> test epoch 995 avg loss: 1.30535 (A-MSE: 1.16856) avg lploss: 0.00000
*** Best Val Loss: 1.08435 	 Best Test Loss: 1.15437 	 Best epoch 990
EarlyStopping counter: 1 out of 50
train epoch 996 avg loss: 0.33330 (A-MSE: 0.29566) avg lploss: 0.00000
train epoch 997 avg loss: 0.31149 (A-MSE: 0.27298) avg lploss: 0.00000
train epoch 998 avg loss: 0.33312 (A-MSE: 0.29219) avg lploss: 0.00000
train epoch 999 avg loss: 0.34288 (A-MSE: 0.30121) avg lploss: 0.00000
train epoch 1000 avg loss: 0.41447 (A-MSE: 0.36714) avg lploss: 0.00000
==> val epoch 1000 avg loss: 1.12487 (A-MSE: 1.00528) avg lploss: 0.00000
==> test epoch 1000 avg loss: 1.34281 (A-MSE: 1.19828) avg lploss: 0.00000
*** Best Val Loss: 1.08435 	 Best Test Loss: 1.15437 	 Best epoch 990
EarlyStopping counter: 2 out of 50
train epoch 1001 avg loss: 0.43266 (A-MSE: 0.37936) avg lploss: 0.00000
train epoch 1002 avg loss: 0.35432 (A-MSE: 0.31299) avg lploss: 0.00000
train epoch 1003 avg loss: 0.35650 (A-MSE: 0.31443) avg lploss: 0.00000
train epoch 1004 avg loss: 0.32436 (A-MSE: 0.28414) avg lploss: 0.00000
train epoch 1005 avg loss: 0.30493 (A-MSE: 0.26853) avg lploss: 0.00000
==> val epoch 1005 avg loss: 1.00802 (A-MSE: 0.90852) avg lploss: 0.00000
==> test epoch 1005 avg loss: 1.10209 (A-MSE: 0.98921) avg lploss: 0.00000
*** Best Val Loss: 1.00802 	 Best Test Loss: 1.10209 	 Best epoch 1005
Validation loss decreased (1.084355 --> 1.008022).  Saving model ...
train epoch 1006 avg loss: 0.35858 (A-MSE: 0.31779) avg lploss: 0.00000
train epoch 1007 avg loss: 0.32969 (A-MSE: 0.29149) avg lploss: 0.00000
train epoch 1008 avg loss: 0.36660 (A-MSE: 0.32271) avg lploss: 0.00000
train epoch 1009 avg loss: 0.35425 (A-MSE: 0.31233) avg lploss: 0.00000
train epoch 1010 avg loss: 0.40313 (A-MSE: 0.35734) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.98473 (A-MSE: 0.88675) avg lploss: 0.00000
==> test epoch 1010 avg loss: 1.10157 (A-MSE: 1.00018) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
Validation loss decreased (1.008022 --> 0.984726).  Saving model ...
train epoch 1011 avg loss: 0.33637 (A-MSE: 0.29823) avg lploss: 0.00000
train epoch 1012 avg loss: 0.30979 (A-MSE: 0.27447) avg lploss: 0.00000
train epoch 1013 avg loss: 0.31301 (A-MSE: 0.27592) avg lploss: 0.00000
train epoch 1014 avg loss: 0.33422 (A-MSE: 0.29572) avg lploss: 0.00000
train epoch 1015 avg loss: 0.32056 (A-MSE: 0.28272) avg lploss: 0.00000
==> val epoch 1015 avg loss: 1.07633 (A-MSE: 0.96598) avg lploss: 0.00000
==> test epoch 1015 avg loss: 1.25564 (A-MSE: 1.11330) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 1 out of 50
train epoch 1016 avg loss: 0.32310 (A-MSE: 0.28365) avg lploss: 0.00000
train epoch 1017 avg loss: 0.30084 (A-MSE: 0.26530) avg lploss: 0.00000
train epoch 1018 avg loss: 0.30768 (A-MSE: 0.27039) avg lploss: 0.00000
train epoch 1019 avg loss: 0.32498 (A-MSE: 0.28597) avg lploss: 0.00000
train epoch 1020 avg loss: 0.34755 (A-MSE: 0.30600) avg lploss: 0.00000
==> val epoch 1020 avg loss: 1.06216 (A-MSE: 0.95372) avg lploss: 0.00000
==> test epoch 1020 avg loss: 1.27984 (A-MSE: 1.14290) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 2 out of 50
train epoch 1021 avg loss: 0.33652 (A-MSE: 0.29800) avg lploss: 0.00000
train epoch 1022 avg loss: 0.33062 (A-MSE: 0.29168) avg lploss: 0.00000
train epoch 1023 avg loss: 0.31356 (A-MSE: 0.27675) avg lploss: 0.00000
train epoch 1024 avg loss: 0.33671 (A-MSE: 0.29558) avg lploss: 0.00000
train epoch 1025 avg loss: 0.31648 (A-MSE: 0.27977) avg lploss: 0.00000
==> val epoch 1025 avg loss: 1.00403 (A-MSE: 0.89830) avg lploss: 0.00000
==> test epoch 1025 avg loss: 1.20312 (A-MSE: 1.08262) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 3 out of 50
train epoch 1026 avg loss: 0.31209 (A-MSE: 0.27279) avg lploss: 0.00000
train epoch 1027 avg loss: 0.35874 (A-MSE: 0.31606) avg lploss: 0.00000
train epoch 1028 avg loss: 0.32112 (A-MSE: 0.28141) avg lploss: 0.00000
train epoch 1029 avg loss: 0.30898 (A-MSE: 0.27267) avg lploss: 0.00000
train epoch 1030 avg loss: 0.28878 (A-MSE: 0.25413) avg lploss: 0.00000
==> val epoch 1030 avg loss: 1.01794 (A-MSE: 0.91118) avg lploss: 0.00000
==> test epoch 1030 avg loss: 1.14082 (A-MSE: 1.02613) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 4 out of 50
train epoch 1031 avg loss: 0.30304 (A-MSE: 0.26677) avg lploss: 0.00000
train epoch 1032 avg loss: 0.34902 (A-MSE: 0.30724) avg lploss: 0.00000
train epoch 1033 avg loss: 0.37867 (A-MSE: 0.33121) avg lploss: 0.00000
train epoch 1034 avg loss: 0.40611 (A-MSE: 0.35650) avg lploss: 0.00000
train epoch 1035 avg loss: 0.36509 (A-MSE: 0.32120) avg lploss: 0.00000
==> val epoch 1035 avg loss: 1.08770 (A-MSE: 0.99053) avg lploss: 0.00000
==> test epoch 1035 avg loss: 1.20179 (A-MSE: 1.09279) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 5 out of 50
train epoch 1036 avg loss: 0.34190 (A-MSE: 0.30167) avg lploss: 0.00000
train epoch 1037 avg loss: 0.35787 (A-MSE: 0.31539) avg lploss: 0.00000
train epoch 1038 avg loss: 0.33893 (A-MSE: 0.30072) avg lploss: 0.00000
train epoch 1039 avg loss: 0.33229 (A-MSE: 0.29209) avg lploss: 0.00000
train epoch 1040 avg loss: 0.29308 (A-MSE: 0.25787) avg lploss: 0.00000
==> val epoch 1040 avg loss: 1.08658 (A-MSE: 0.98996) avg lploss: 0.00000
==> test epoch 1040 avg loss: 1.22942 (A-MSE: 1.11588) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 6 out of 50
train epoch 1041 avg loss: 0.30611 (A-MSE: 0.26863) avg lploss: 0.00000
train epoch 1042 avg loss: 0.36651 (A-MSE: 0.32180) avg lploss: 0.00000
train epoch 1043 avg loss: 0.32217 (A-MSE: 0.28597) avg lploss: 0.00000
train epoch 1044 avg loss: 0.34164 (A-MSE: 0.30207) avg lploss: 0.00000
train epoch 1045 avg loss: 0.34464 (A-MSE: 0.30443) avg lploss: 0.00000
==> val epoch 1045 avg loss: 1.15427 (A-MSE: 1.02879) avg lploss: 0.00000
==> test epoch 1045 avg loss: 1.29519 (A-MSE: 1.15688) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 7 out of 50
train epoch 1046 avg loss: 0.32950 (A-MSE: 0.29188) avg lploss: 0.00000
train epoch 1047 avg loss: 0.31568 (A-MSE: 0.27470) avg lploss: 0.00000
train epoch 1048 avg loss: 0.32487 (A-MSE: 0.28715) avg lploss: 0.00000
train epoch 1049 avg loss: 0.31634 (A-MSE: 0.27894) avg lploss: 0.00000
train epoch 1050 avg loss: 0.33378 (A-MSE: 0.29333) avg lploss: 0.00000
==> val epoch 1050 avg loss: 1.32344 (A-MSE: 1.16567) avg lploss: 0.00000
==> test epoch 1050 avg loss: 1.39693 (A-MSE: 1.23100) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 8 out of 50
train epoch 1051 avg loss: 0.34623 (A-MSE: 0.30425) avg lploss: 0.00000
train epoch 1052 avg loss: 0.29686 (A-MSE: 0.26051) avg lploss: 0.00000
train epoch 1053 avg loss: 0.26754 (A-MSE: 0.23526) avg lploss: 0.00000
train epoch 1054 avg loss: 0.30673 (A-MSE: 0.26855) avg lploss: 0.00000
train epoch 1055 avg loss: 0.32112 (A-MSE: 0.28166) avg lploss: 0.00000
==> val epoch 1055 avg loss: 1.20281 (A-MSE: 1.07802) avg lploss: 0.00000
==> test epoch 1055 avg loss: 1.30832 (A-MSE: 1.16646) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 9 out of 50
train epoch 1056 avg loss: 0.32221 (A-MSE: 0.28529) avg lploss: 0.00000
train epoch 1057 avg loss: 0.28856 (A-MSE: 0.25422) avg lploss: 0.00000
train epoch 1058 avg loss: 0.32552 (A-MSE: 0.28838) avg lploss: 0.00000
train epoch 1059 avg loss: 0.32934 (A-MSE: 0.29090) avg lploss: 0.00000
train epoch 1060 avg loss: 0.31709 (A-MSE: 0.27927) avg lploss: 0.00000
==> val epoch 1060 avg loss: 1.00597 (A-MSE: 0.90655) avg lploss: 0.00000
==> test epoch 1060 avg loss: 1.15434 (A-MSE: 1.03334) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 10 out of 50
train epoch 1061 avg loss: 0.32711 (A-MSE: 0.28813) avg lploss: 0.00000
train epoch 1062 avg loss: 0.32069 (A-MSE: 0.28117) avg lploss: 0.00000
train epoch 1063 avg loss: 0.32319 (A-MSE: 0.28752) avg lploss: 0.00000
train epoch 1064 avg loss: 0.30847 (A-MSE: 0.27163) avg lploss: 0.00000
train epoch 1065 avg loss: 0.34457 (A-MSE: 0.30458) avg lploss: 0.00000
==> val epoch 1065 avg loss: 1.00370 (A-MSE: 0.90724) avg lploss: 0.00000
==> test epoch 1065 avg loss: 1.08800 (A-MSE: 0.98882) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 11 out of 50
train epoch 1066 avg loss: 0.51493 (A-MSE: 0.44735) avg lploss: 0.00000
train epoch 1067 avg loss: 0.51891 (A-MSE: 0.45959) avg lploss: 0.00000
train epoch 1068 avg loss: 0.38904 (A-MSE: 0.34286) avg lploss: 0.00000
train epoch 1069 avg loss: 0.33180 (A-MSE: 0.29064) avg lploss: 0.00000
train epoch 1070 avg loss: 0.30394 (A-MSE: 0.26779) avg lploss: 0.00000
==> val epoch 1070 avg loss: 1.02312 (A-MSE: 0.91831) avg lploss: 0.00000
==> test epoch 1070 avg loss: 1.17642 (A-MSE: 1.04960) avg lploss: 0.00000
*** Best Val Loss: 0.98473 	 Best Test Loss: 1.10157 	 Best epoch 1010
EarlyStopping counter: 12 out of 50
train epoch 1071 avg loss: 0.34224 (A-MSE: 0.30309) avg lploss: 0.00000
train epoch 1072 avg loss: 0.31323 (A-MSE: 0.27479) avg lploss: 0.00000
train epoch 1073 avg loss: 0.26622 (A-MSE: 0.23444) avg lploss: 0.00000
train epoch 1074 avg loss: 0.27095 (A-MSE: 0.23899) avg lploss: 0.00000
train epoch 1075 avg loss: 0.26919 (A-MSE: 0.23683) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.92096 (A-MSE: 0.82853) avg lploss: 0.00000
==> test epoch 1075 avg loss: 1.10236 (A-MSE: 0.98967) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
Validation loss decreased (0.984726 --> 0.920963).  Saving model ...
train epoch 1076 avg loss: 0.26133 (A-MSE: 0.23046) avg lploss: 0.00000
train epoch 1077 avg loss: 0.27077 (A-MSE: 0.23844) avg lploss: 0.00000
train epoch 1078 avg loss: 0.30238 (A-MSE: 0.26591) avg lploss: 0.00000
train epoch 1079 avg loss: 0.29393 (A-MSE: 0.25927) avg lploss: 0.00000
train epoch 1080 avg loss: 0.27572 (A-MSE: 0.24411) avg lploss: 0.00000
==> val epoch 1080 avg loss: 1.09139 (A-MSE: 0.97594) avg lploss: 0.00000
==> test epoch 1080 avg loss: 1.28471 (A-MSE: 1.14275) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 1 out of 50
train epoch 1081 avg loss: 0.30241 (A-MSE: 0.26782) avg lploss: 0.00000
train epoch 1082 avg loss: 0.34136 (A-MSE: 0.29871) avg lploss: 0.00000
train epoch 1083 avg loss: 0.32539 (A-MSE: 0.28588) avg lploss: 0.00000
train epoch 1084 avg loss: 0.29576 (A-MSE: 0.26079) avg lploss: 0.00000
train epoch 1085 avg loss: 0.30630 (A-MSE: 0.26870) avg lploss: 0.00000
==> val epoch 1085 avg loss: 1.06591 (A-MSE: 0.95905) avg lploss: 0.00000
==> test epoch 1085 avg loss: 1.20287 (A-MSE: 1.07933) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 2 out of 50
train epoch 1086 avg loss: 0.28730 (A-MSE: 0.25436) avg lploss: 0.00000
train epoch 1087 avg loss: 0.25309 (A-MSE: 0.22357) avg lploss: 0.00000
train epoch 1088 avg loss: 0.25378 (A-MSE: 0.22474) avg lploss: 0.00000
train epoch 1089 avg loss: 0.24284 (A-MSE: 0.21446) avg lploss: 0.00000
train epoch 1090 avg loss: 0.24344 (A-MSE: 0.21368) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.98159 (A-MSE: 0.87045) avg lploss: 0.00000
==> test epoch 1090 avg loss: 1.11731 (A-MSE: 0.98124) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 3 out of 50
train epoch 1091 avg loss: 0.24697 (A-MSE: 0.21872) avg lploss: 0.00000
train epoch 1092 avg loss: 0.28362 (A-MSE: 0.25105) avg lploss: 0.00000
train epoch 1093 avg loss: 0.28251 (A-MSE: 0.24888) avg lploss: 0.00000
train epoch 1094 avg loss: 0.29757 (A-MSE: 0.26125) avg lploss: 0.00000
train epoch 1095 avg loss: 0.30735 (A-MSE: 0.27406) avg lploss: 0.00000
==> val epoch 1095 avg loss: 1.04157 (A-MSE: 0.93888) avg lploss: 0.00000
==> test epoch 1095 avg loss: 1.15810 (A-MSE: 1.04040) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 4 out of 50
train epoch 1096 avg loss: 0.30425 (A-MSE: 0.26559) avg lploss: 0.00000
train epoch 1097 avg loss: 0.37285 (A-MSE: 0.32937) avg lploss: 0.00000
train epoch 1098 avg loss: 0.35191 (A-MSE: 0.30700) avg lploss: 0.00000
train epoch 1099 avg loss: 0.29799 (A-MSE: 0.26437) avg lploss: 0.00000
train epoch 1100 avg loss: 0.29668 (A-MSE: 0.26206) avg lploss: 0.00000
==> val epoch 1100 avg loss: 1.03900 (A-MSE: 0.92971) avg lploss: 0.00000
==> test epoch 1100 avg loss: 1.27145 (A-MSE: 1.13243) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 5 out of 50
train epoch 1101 avg loss: 0.31566 (A-MSE: 0.27759) avg lploss: 0.00000
train epoch 1102 avg loss: 0.31747 (A-MSE: 0.28175) avg lploss: 0.00000
train epoch 1103 avg loss: 0.34554 (A-MSE: 0.30550) avg lploss: 0.00000
train epoch 1104 avg loss: 0.30405 (A-MSE: 0.26716) avg lploss: 0.00000
train epoch 1105 avg loss: 0.30785 (A-MSE: 0.27076) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.99780 (A-MSE: 0.89730) avg lploss: 0.00000
==> test epoch 1105 avg loss: 1.21662 (A-MSE: 1.07719) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 6 out of 50
train epoch 1106 avg loss: 0.32471 (A-MSE: 0.28495) avg lploss: 0.00000
train epoch 1107 avg loss: 0.27997 (A-MSE: 0.24707) avg lploss: 0.00000
train epoch 1108 avg loss: 0.26441 (A-MSE: 0.23327) avg lploss: 0.00000
train epoch 1109 avg loss: 0.26182 (A-MSE: 0.22972) avg lploss: 0.00000
train epoch 1110 avg loss: 0.26806 (A-MSE: 0.23654) avg lploss: 0.00000
==> val epoch 1110 avg loss: 1.04698 (A-MSE: 0.95001) avg lploss: 0.00000
==> test epoch 1110 avg loss: 1.21062 (A-MSE: 1.08955) avg lploss: 0.00000
*** Best Val Loss: 0.92096 	 Best Test Loss: 1.10236 	 Best epoch 1075
EarlyStopping counter: 7 out of 50
train epoch 1111 avg loss: 0.28943 (A-MSE: 0.25345) avg lploss: 0.00000
train epoch 1112 avg loss: 0.28891 (A-MSE: 0.25493) avg lploss: 0.00000
train epoch 1113 avg loss: 0.27938 (A-MSE: 0.24521) avg lploss: 0.00000
train epoch 1114 avg loss: 0.28012 (A-MSE: 0.24697) avg lploss: 0.00000
train epoch 1115 avg loss: 0.25284 (A-MSE: 0.22468) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.86355 (A-MSE: 0.77617) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.99292 (A-MSE: 0.89077) avg lploss: 0.00000
*** Best Val Loss: 0.86355 	 Best Test Loss: 0.99292 	 Best epoch 1115
Validation loss decreased (0.920963 --> 0.863550).  Saving model ...
train epoch 1116 avg loss: 0.25193 (A-MSE: 0.22247) avg lploss: 0.00000
train epoch 1117 avg loss: 0.27599 (A-MSE: 0.24270) avg lploss: 0.00000
train epoch 1118 avg loss: 0.30038 (A-MSE: 0.26520) avg lploss: 0.00000
train epoch 1119 avg loss: 0.26673 (A-MSE: 0.23499) avg lploss: 0.00000
train epoch 1120 avg loss: 0.30837 (A-MSE: 0.27359) avg lploss: 0.00000
==> val epoch 1120 avg loss: 1.00963 (A-MSE: 0.89907) avg lploss: 0.00000
==> test epoch 1120 avg loss: 1.15525 (A-MSE: 1.02525) avg lploss: 0.00000
*** Best Val Loss: 0.86355 	 Best Test Loss: 0.99292 	 Best epoch 1115
EarlyStopping counter: 1 out of 50
train epoch 1121 avg loss: 0.26181 (A-MSE: 0.22995) avg lploss: 0.00000
train epoch 1122 avg loss: 0.27881 (A-MSE: 0.24467) avg lploss: 0.00000
train epoch 1123 avg loss: 0.27888 (A-MSE: 0.24763) avg lploss: 0.00000
train epoch 1124 avg loss: 0.29287 (A-MSE: 0.25795) avg lploss: 0.00000
train epoch 1125 avg loss: 0.33368 (A-MSE: 0.29585) avg lploss: 0.00000
==> val epoch 1125 avg loss: 1.16867 (A-MSE: 1.04038) avg lploss: 0.00000
==> test epoch 1125 avg loss: 1.30411 (A-MSE: 1.16805) avg lploss: 0.00000
*** Best Val Loss: 0.86355 	 Best Test Loss: 0.99292 	 Best epoch 1115
EarlyStopping counter: 2 out of 50
train epoch 1126 avg loss: 0.29935 (A-MSE: 0.26496) avg lploss: 0.00000
train epoch 1127 avg loss: 0.28485 (A-MSE: 0.25195) avg lploss: 0.00000
train epoch 1128 avg loss: 0.31679 (A-MSE: 0.27897) avg lploss: 0.00000
train epoch 1129 avg loss: 0.54170 (A-MSE: 0.46711) avg lploss: 0.00000
train epoch 1130 avg loss: 0.54024 (A-MSE: 0.47005) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.95744 (A-MSE: 0.85575) avg lploss: 0.00000
==> test epoch 1130 avg loss: 1.04084 (A-MSE: 0.94087) avg lploss: 0.00000
*** Best Val Loss: 0.86355 	 Best Test Loss: 0.99292 	 Best epoch 1115
EarlyStopping counter: 3 out of 50
train epoch 1131 avg loss: 0.34999 (A-MSE: 0.31096) avg lploss: 0.00000
train epoch 1132 avg loss: 0.29965 (A-MSE: 0.26357) avg lploss: 0.00000
train epoch 1133 avg loss: 0.25074 (A-MSE: 0.22128) avg lploss: 0.00000
train epoch 1134 avg loss: 0.26009 (A-MSE: 0.22788) avg lploss: 0.00000
train epoch 1135 avg loss: 0.26209 (A-MSE: 0.23305) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.98577 (A-MSE: 0.88022) avg lploss: 0.00000
==> test epoch 1135 avg loss: 1.11485 (A-MSE: 0.99807) avg lploss: 0.00000
*** Best Val Loss: 0.86355 	 Best Test Loss: 0.99292 	 Best epoch 1115
EarlyStopping counter: 4 out of 50
train epoch 1136 avg loss: 0.25452 (A-MSE: 0.22527) avg lploss: 0.00000
train epoch 1137 avg loss: 0.24642 (A-MSE: 0.21757) avg lploss: 0.00000
train epoch 1138 avg loss: 0.24641 (A-MSE: 0.21489) avg lploss: 0.00000
train epoch 1139 avg loss: 0.26647 (A-MSE: 0.23680) avg lploss: 0.00000
train epoch 1140 avg loss: 0.26910 (A-MSE: 0.23764) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.86580 (A-MSE: 0.77444) avg lploss: 0.00000
==> test epoch 1140 avg loss: 1.06712 (A-MSE: 0.94298) avg lploss: 0.00000
*** Best Val Loss: 0.86355 	 Best Test Loss: 0.99292 	 Best epoch 1115
EarlyStopping counter: 5 out of 50
train epoch 1141 avg loss: 0.26803 (A-MSE: 0.23666) avg lploss: 0.00000
train epoch 1142 avg loss: 0.28077 (A-MSE: 0.24776) avg lploss: 0.00000
train epoch 1143 avg loss: 0.27065 (A-MSE: 0.23955) avg lploss: 0.00000
train epoch 1144 avg loss: 0.24539 (A-MSE: 0.21699) avg lploss: 0.00000
train epoch 1145 avg loss: 0.24252 (A-MSE: 0.21282) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.85007 (A-MSE: 0.76664) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.95807 (A-MSE: 0.85636) avg lploss: 0.00000
*** Best Val Loss: 0.85007 	 Best Test Loss: 0.95807 	 Best epoch 1145
Validation loss decreased (0.863550 --> 0.850069).  Saving model ...
train epoch 1146 avg loss: 0.23322 (A-MSE: 0.20434) avg lploss: 0.00000
train epoch 1147 avg loss: 0.27305 (A-MSE: 0.24031) avg lploss: 0.00000
train epoch 1148 avg loss: 0.29662 (A-MSE: 0.26099) avg lploss: 0.00000
train epoch 1149 avg loss: 0.23915 (A-MSE: 0.21203) avg lploss: 0.00000
train epoch 1150 avg loss: 0.21712 (A-MSE: 0.19155) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.86708 (A-MSE: 0.78020) avg lploss: 0.00000
==> test epoch 1150 avg loss: 1.02720 (A-MSE: 0.91709) avg lploss: 0.00000
*** Best Val Loss: 0.85007 	 Best Test Loss: 0.95807 	 Best epoch 1145
EarlyStopping counter: 1 out of 50
train epoch 1151 avg loss: 0.22933 (A-MSE: 0.20087) avg lploss: 0.00000
train epoch 1152 avg loss: 0.24974 (A-MSE: 0.21975) avg lploss: 0.00000
train epoch 1153 avg loss: 0.24252 (A-MSE: 0.21452) avg lploss: 0.00000
train epoch 1154 avg loss: 0.25570 (A-MSE: 0.22298) avg lploss: 0.00000
train epoch 1155 avg loss: 0.25264 (A-MSE: 0.22350) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.92380 (A-MSE: 0.82518) avg lploss: 0.00000
==> test epoch 1155 avg loss: 1.02205 (A-MSE: 0.91929) avg lploss: 0.00000
*** Best Val Loss: 0.85007 	 Best Test Loss: 0.95807 	 Best epoch 1145
EarlyStopping counter: 2 out of 50
train epoch 1156 avg loss: 0.29804 (A-MSE: 0.26270) avg lploss: 0.00000
train epoch 1157 avg loss: 0.29625 (A-MSE: 0.26260) avg lploss: 0.00000
train epoch 1158 avg loss: 0.28527 (A-MSE: 0.25287) avg lploss: 0.00000
train epoch 1159 avg loss: 0.26937 (A-MSE: 0.23584) avg lploss: 0.00000
train epoch 1160 avg loss: 0.23110 (A-MSE: 0.20378) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.82659 (A-MSE: 0.73597) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.93205 (A-MSE: 0.82985) avg lploss: 0.00000
*** Best Val Loss: 0.82659 	 Best Test Loss: 0.93205 	 Best epoch 1160
Validation loss decreased (0.850069 --> 0.826593).  Saving model ...
train epoch 1161 avg loss: 0.22710 (A-MSE: 0.19969) avg lploss: 0.00000
train epoch 1162 avg loss: 0.25451 (A-MSE: 0.22478) avg lploss: 0.00000
train epoch 1163 avg loss: 0.29651 (A-MSE: 0.26133) avg lploss: 0.00000
train epoch 1164 avg loss: 0.27287 (A-MSE: 0.24042) avg lploss: 0.00000
train epoch 1165 avg loss: 0.23569 (A-MSE: 0.20635) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.89684 (A-MSE: 0.79930) avg lploss: 0.00000
==> test epoch 1165 avg loss: 1.06079 (A-MSE: 0.93814) avg lploss: 0.00000
*** Best Val Loss: 0.82659 	 Best Test Loss: 0.93205 	 Best epoch 1160
EarlyStopping counter: 1 out of 50
train epoch 1166 avg loss: 0.22817 (A-MSE: 0.20254) avg lploss: 0.00000
train epoch 1167 avg loss: 0.25384 (A-MSE: 0.22415) avg lploss: 0.00000
train epoch 1168 avg loss: 0.23362 (A-MSE: 0.20551) avg lploss: 0.00000
train epoch 1169 avg loss: 0.23592 (A-MSE: 0.20870) avg lploss: 0.00000
train epoch 1170 avg loss: 0.24021 (A-MSE: 0.21095) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.97479 (A-MSE: 0.86482) avg lploss: 0.00000
==> test epoch 1170 avg loss: 1.12055 (A-MSE: 0.98741) avg lploss: 0.00000
*** Best Val Loss: 0.82659 	 Best Test Loss: 0.93205 	 Best epoch 1160
EarlyStopping counter: 2 out of 50
train epoch 1171 avg loss: 0.25223 (A-MSE: 0.22302) avg lploss: 0.00000
train epoch 1172 avg loss: 0.24682 (A-MSE: 0.21895) avg lploss: 0.00000
train epoch 1173 avg loss: 0.22825 (A-MSE: 0.20361) avg lploss: 0.00000
train epoch 1174 avg loss: 0.23772 (A-MSE: 0.21033) avg lploss: 0.00000
train epoch 1175 avg loss: 0.25085 (A-MSE: 0.22198) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.93502 (A-MSE: 0.83649) avg lploss: 0.00000
==> test epoch 1175 avg loss: 1.01572 (A-MSE: 0.91257) avg lploss: 0.00000
*** Best Val Loss: 0.82659 	 Best Test Loss: 0.93205 	 Best epoch 1160
EarlyStopping counter: 3 out of 50
train epoch 1176 avg loss: 0.29346 (A-MSE: 0.25648) avg lploss: 0.00000
train epoch 1177 avg loss: 0.25466 (A-MSE: 0.22352) avg lploss: 0.00000
train epoch 1178 avg loss: 0.28586 (A-MSE: 0.25114) avg lploss: 0.00000
train epoch 1179 avg loss: 0.23373 (A-MSE: 0.20543) avg lploss: 0.00000
train epoch 1180 avg loss: 0.22043 (A-MSE: 0.19352) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.78510 (A-MSE: 0.70641) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.95410 (A-MSE: 0.85194) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
Validation loss decreased (0.826593 --> 0.785105).  Saving model ...
train epoch 1181 avg loss: 0.26663 (A-MSE: 0.23545) avg lploss: 0.00000
train epoch 1182 avg loss: 0.25122 (A-MSE: 0.21971) avg lploss: 0.00000
train epoch 1183 avg loss: 0.23413 (A-MSE: 0.20648) avg lploss: 0.00000
train epoch 1184 avg loss: 0.23459 (A-MSE: 0.20803) avg lploss: 0.00000
train epoch 1185 avg loss: 0.23120 (A-MSE: 0.20479) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.98477 (A-MSE: 0.86844) avg lploss: 0.00000
==> test epoch 1185 avg loss: 1.18423 (A-MSE: 1.03619) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 1 out of 50
train epoch 1186 avg loss: 0.27804 (A-MSE: 0.24638) avg lploss: 0.00000
train epoch 1187 avg loss: 0.26744 (A-MSE: 0.23354) avg lploss: 0.00000
train epoch 1188 avg loss: 0.24182 (A-MSE: 0.21336) avg lploss: 0.00000
train epoch 1189 avg loss: 0.26888 (A-MSE: 0.23549) avg lploss: 0.00000
train epoch 1190 avg loss: 0.25408 (A-MSE: 0.22394) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.79359 (A-MSE: 0.70867) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.98139 (A-MSE: 0.86875) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 2 out of 50
train epoch 1191 avg loss: 0.32175 (A-MSE: 0.28279) avg lploss: 0.00000
train epoch 1192 avg loss: 0.27963 (A-MSE: 0.24650) avg lploss: 0.00000
train epoch 1193 avg loss: 0.23152 (A-MSE: 0.20518) avg lploss: 0.00000
train epoch 1194 avg loss: 0.27118 (A-MSE: 0.23802) avg lploss: 0.00000
train epoch 1195 avg loss: 0.24990 (A-MSE: 0.21899) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.83479 (A-MSE: 0.73989) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.99702 (A-MSE: 0.87952) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 3 out of 50
train epoch 1196 avg loss: 0.23642 (A-MSE: 0.20979) avg lploss: 0.00000
train epoch 1197 avg loss: 0.23769 (A-MSE: 0.21072) avg lploss: 0.00000
train epoch 1198 avg loss: 0.26002 (A-MSE: 0.22921) avg lploss: 0.00000
train epoch 1199 avg loss: 0.27504 (A-MSE: 0.24373) avg lploss: 0.00000
train epoch 1200 avg loss: 0.27790 (A-MSE: 0.24461) avg lploss: 0.00000
==> val epoch 1200 avg loss: 1.01065 (A-MSE: 0.88863) avg lploss: 0.00000
==> test epoch 1200 avg loss: 1.12180 (A-MSE: 0.99189) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 4 out of 50
train epoch 1201 avg loss: 0.26255 (A-MSE: 0.23104) avg lploss: 0.00000
train epoch 1202 avg loss: 0.25659 (A-MSE: 0.22714) avg lploss: 0.00000
train epoch 1203 avg loss: 0.25174 (A-MSE: 0.22136) avg lploss: 0.00000
train epoch 1204 avg loss: 0.23950 (A-MSE: 0.21281) avg lploss: 0.00000
train epoch 1205 avg loss: 0.23628 (A-MSE: 0.20732) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.81530 (A-MSE: 0.73526) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.91547 (A-MSE: 0.82805) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 5 out of 50
train epoch 1206 avg loss: 0.22417 (A-MSE: 0.19933) avg lploss: 0.00000
train epoch 1207 avg loss: 0.23550 (A-MSE: 0.20611) avg lploss: 0.00000
train epoch 1208 avg loss: 0.28033 (A-MSE: 0.24683) avg lploss: 0.00000
train epoch 1209 avg loss: 0.24357 (A-MSE: 0.21441) avg lploss: 0.00000
train epoch 1210 avg loss: 0.24800 (A-MSE: 0.22163) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.94494 (A-MSE: 0.83838) avg lploss: 0.00000
==> test epoch 1210 avg loss: 1.10676 (A-MSE: 0.97602) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 6 out of 50
train epoch 1211 avg loss: 0.22698 (A-MSE: 0.20041) avg lploss: 0.00000
train epoch 1212 avg loss: 0.24319 (A-MSE: 0.21387) avg lploss: 0.00000
train epoch 1213 avg loss: 0.24694 (A-MSE: 0.22028) avg lploss: 0.00000
train epoch 1214 avg loss: 0.23664 (A-MSE: 0.20874) avg lploss: 0.00000
train epoch 1215 avg loss: 0.23245 (A-MSE: 0.20562) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.99031 (A-MSE: 0.86652) avg lploss: 0.00000
==> test epoch 1215 avg loss: 1.14426 (A-MSE: 1.00573) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 7 out of 50
train epoch 1216 avg loss: 0.25420 (A-MSE: 0.22346) avg lploss: 0.00000
train epoch 1217 avg loss: 0.25330 (A-MSE: 0.22176) avg lploss: 0.00000
train epoch 1218 avg loss: 0.23520 (A-MSE: 0.20712) avg lploss: 0.00000
train epoch 1219 avg loss: 0.22772 (A-MSE: 0.20026) avg lploss: 0.00000
train epoch 1220 avg loss: 0.23001 (A-MSE: 0.20157) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.98250 (A-MSE: 0.86988) avg lploss: 0.00000
==> test epoch 1220 avg loss: 1.09379 (A-MSE: 0.96497) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 8 out of 50
train epoch 1221 avg loss: 0.24518 (A-MSE: 0.21629) avg lploss: 0.00000
train epoch 1222 avg loss: 0.24403 (A-MSE: 0.21647) avg lploss: 0.00000
train epoch 1223 avg loss: 0.24531 (A-MSE: 0.21779) avg lploss: 0.00000
train epoch 1224 avg loss: 0.23425 (A-MSE: 0.20575) avg lploss: 0.00000
train epoch 1225 avg loss: 0.20702 (A-MSE: 0.18273) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.89442 (A-MSE: 0.79580) avg lploss: 0.00000
==> test epoch 1225 avg loss: 1.05289 (A-MSE: 0.92979) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 9 out of 50
train epoch 1226 avg loss: 0.19790 (A-MSE: 0.17460) avg lploss: 0.00000
train epoch 1227 avg loss: 0.19701 (A-MSE: 0.17354) avg lploss: 0.00000
train epoch 1228 avg loss: 0.24566 (A-MSE: 0.21510) avg lploss: 0.00000
train epoch 1229 avg loss: 0.22362 (A-MSE: 0.19877) avg lploss: 0.00000
train epoch 1230 avg loss: 0.23304 (A-MSE: 0.20671) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.80752 (A-MSE: 0.72004) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.94776 (A-MSE: 0.84668) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 10 out of 50
train epoch 1231 avg loss: 0.20347 (A-MSE: 0.17925) avg lploss: 0.00000
train epoch 1232 avg loss: 0.19532 (A-MSE: 0.17330) avg lploss: 0.00000
train epoch 1233 avg loss: 0.18457 (A-MSE: 0.16315) avg lploss: 0.00000
train epoch 1234 avg loss: 0.22656 (A-MSE: 0.20247) avg lploss: 0.00000
train epoch 1235 avg loss: 0.24120 (A-MSE: 0.21158) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.98620 (A-MSE: 0.87089) avg lploss: 0.00000
==> test epoch 1235 avg loss: 1.05389 (A-MSE: 0.93403) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 11 out of 50
train epoch 1236 avg loss: 0.31164 (A-MSE: 0.27316) avg lploss: 0.00000
train epoch 1237 avg loss: 0.31248 (A-MSE: 0.27824) avg lploss: 0.00000
train epoch 1238 avg loss: 0.29998 (A-MSE: 0.26394) avg lploss: 0.00000
train epoch 1239 avg loss: 0.23378 (A-MSE: 0.20747) avg lploss: 0.00000
train epoch 1240 avg loss: 0.23897 (A-MSE: 0.21309) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.81188 (A-MSE: 0.72379) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.96353 (A-MSE: 0.85793) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 12 out of 50
train epoch 1241 avg loss: 0.22791 (A-MSE: 0.20183) avg lploss: 0.00000
train epoch 1242 avg loss: 0.21031 (A-MSE: 0.18648) avg lploss: 0.00000
train epoch 1243 avg loss: 0.24526 (A-MSE: 0.21666) avg lploss: 0.00000
train epoch 1244 avg loss: 0.24446 (A-MSE: 0.21721) avg lploss: 0.00000
train epoch 1245 avg loss: 0.20840 (A-MSE: 0.18383) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.81128 (A-MSE: 0.71816) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.94701 (A-MSE: 0.83227) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 13 out of 50
train epoch 1246 avg loss: 0.19197 (A-MSE: 0.16970) avg lploss: 0.00000
train epoch 1247 avg loss: 0.22007 (A-MSE: 0.19423) avg lploss: 0.00000
train epoch 1248 avg loss: 0.21753 (A-MSE: 0.19232) avg lploss: 0.00000
train epoch 1249 avg loss: 0.19887 (A-MSE: 0.17694) avg lploss: 0.00000
train epoch 1250 avg loss: 0.20069 (A-MSE: 0.17938) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.85577 (A-MSE: 0.75216) avg lploss: 0.00000
==> test epoch 1250 avg loss: 1.01859 (A-MSE: 0.88593) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 14 out of 50
train epoch 1251 avg loss: 0.19900 (A-MSE: 0.17560) avg lploss: 0.00000
train epoch 1252 avg loss: 0.20834 (A-MSE: 0.18326) avg lploss: 0.00000
train epoch 1253 avg loss: 0.23589 (A-MSE: 0.20882) avg lploss: 0.00000
train epoch 1254 avg loss: 0.23044 (A-MSE: 0.20497) avg lploss: 0.00000
train epoch 1255 avg loss: 0.22174 (A-MSE: 0.19792) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.96881 (A-MSE: 0.85048) avg lploss: 0.00000
==> test epoch 1255 avg loss: 1.18904 (A-MSE: 1.03265) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 15 out of 50
train epoch 1256 avg loss: 0.23578 (A-MSE: 0.20781) avg lploss: 0.00000
train epoch 1257 avg loss: 0.24641 (A-MSE: 0.21745) avg lploss: 0.00000
train epoch 1258 avg loss: 0.25924 (A-MSE: 0.22788) avg lploss: 0.00000
train epoch 1259 avg loss: 0.23251 (A-MSE: 0.20483) avg lploss: 0.00000
train epoch 1260 avg loss: 0.24170 (A-MSE: 0.21251) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.82336 (A-MSE: 0.72984) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.96799 (A-MSE: 0.85832) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 16 out of 50
train epoch 1261 avg loss: 0.23010 (A-MSE: 0.20415) avg lploss: 0.00000
train epoch 1262 avg loss: 0.24794 (A-MSE: 0.22038) avg lploss: 0.00000
train epoch 1263 avg loss: 0.23810 (A-MSE: 0.21023) avg lploss: 0.00000
train epoch 1264 avg loss: 0.21494 (A-MSE: 0.19101) avg lploss: 0.00000
train epoch 1265 avg loss: 0.20645 (A-MSE: 0.18219) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.80299 (A-MSE: 0.71549) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.93199 (A-MSE: 0.82505) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 17 out of 50
train epoch 1266 avg loss: 0.20999 (A-MSE: 0.18566) avg lploss: 0.00000
train epoch 1267 avg loss: 0.21667 (A-MSE: 0.19296) avg lploss: 0.00000
train epoch 1268 avg loss: 0.25078 (A-MSE: 0.22169) avg lploss: 0.00000
train epoch 1269 avg loss: 0.25145 (A-MSE: 0.22267) avg lploss: 0.00000
train epoch 1270 avg loss: 0.24285 (A-MSE: 0.21521) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.88433 (A-MSE: 0.78871) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.97035 (A-MSE: 0.86784) avg lploss: 0.00000
*** Best Val Loss: 0.78510 	 Best Test Loss: 0.95410 	 Best epoch 1180
EarlyStopping counter: 18 out of 50
train epoch 1271 avg loss: 0.23518 (A-MSE: 0.20732) avg lploss: 0.00000
train epoch 1272 avg loss: 0.22267 (A-MSE: 0.19580) avg lploss: 0.00000
train epoch 1273 avg loss: 0.18810 (A-MSE: 0.16685) avg lploss: 0.00000
train epoch 1274 avg loss: 0.21387 (A-MSE: 0.18919) avg lploss: 0.00000
train epoch 1275 avg loss: 0.19017 (A-MSE: 0.16750) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.74427 (A-MSE: 0.66653) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.90885 (A-MSE: 0.80745) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
Validation loss decreased (0.785105 --> 0.744273).  Saving model ...
train epoch 1276 avg loss: 0.18611 (A-MSE: 0.16707) avg lploss: 0.00000
train epoch 1277 avg loss: 0.22599 (A-MSE: 0.19953) avg lploss: 0.00000
train epoch 1278 avg loss: 0.19455 (A-MSE: 0.17213) avg lploss: 0.00000
train epoch 1279 avg loss: 0.19936 (A-MSE: 0.17728) avg lploss: 0.00000
train epoch 1280 avg loss: 0.21182 (A-MSE: 0.18707) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.85395 (A-MSE: 0.75519) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.99035 (A-MSE: 0.87231) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 1 out of 50
train epoch 1281 avg loss: 0.20024 (A-MSE: 0.17636) avg lploss: 0.00000
train epoch 1282 avg loss: 0.25068 (A-MSE: 0.22147) avg lploss: 0.00000
train epoch 1283 avg loss: 0.25995 (A-MSE: 0.22989) avg lploss: 0.00000
train epoch 1284 avg loss: 0.20516 (A-MSE: 0.18195) avg lploss: 0.00000
train epoch 1285 avg loss: 0.18903 (A-MSE: 0.16799) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.93948 (A-MSE: 0.83686) avg lploss: 0.00000
==> test epoch 1285 avg loss: 1.03515 (A-MSE: 0.92541) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 2 out of 50
train epoch 1286 avg loss: 0.20320 (A-MSE: 0.18009) avg lploss: 0.00000
train epoch 1287 avg loss: 0.19737 (A-MSE: 0.17540) avg lploss: 0.00000
train epoch 1288 avg loss: 0.20110 (A-MSE: 0.17649) avg lploss: 0.00000
train epoch 1289 avg loss: 0.18385 (A-MSE: 0.16406) avg lploss: 0.00000
train epoch 1290 avg loss: 0.21305 (A-MSE: 0.18916) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.84784 (A-MSE: 0.76244) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.95911 (A-MSE: 0.85642) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 3 out of 50
train epoch 1291 avg loss: 0.22868 (A-MSE: 0.20297) avg lploss: 0.00000
train epoch 1292 avg loss: 0.23794 (A-MSE: 0.21010) avg lploss: 0.00000
train epoch 1293 avg loss: 0.25181 (A-MSE: 0.22279) avg lploss: 0.00000
train epoch 1294 avg loss: 0.24430 (A-MSE: 0.21625) avg lploss: 0.00000
train epoch 1295 avg loss: 0.22009 (A-MSE: 0.19371) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.86833 (A-MSE: 0.76529) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.95065 (A-MSE: 0.84056) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 4 out of 50
train epoch 1296 avg loss: 0.17938 (A-MSE: 0.15838) avg lploss: 0.00000
train epoch 1297 avg loss: 0.18358 (A-MSE: 0.16226) avg lploss: 0.00000
train epoch 1298 avg loss: 0.20194 (A-MSE: 0.17810) avg lploss: 0.00000
train epoch 1299 avg loss: 0.18601 (A-MSE: 0.16422) avg lploss: 0.00000
train epoch 1300 avg loss: 0.21614 (A-MSE: 0.19116) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.81067 (A-MSE: 0.70853) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.95176 (A-MSE: 0.82804) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 5 out of 50
train epoch 1301 avg loss: 0.23132 (A-MSE: 0.20349) avg lploss: 0.00000
train epoch 1302 avg loss: 0.25102 (A-MSE: 0.22366) avg lploss: 0.00000
train epoch 1303 avg loss: 0.22296 (A-MSE: 0.19698) avg lploss: 0.00000
train epoch 1304 avg loss: 0.22658 (A-MSE: 0.20236) avg lploss: 0.00000
train epoch 1305 avg loss: 0.20672 (A-MSE: 0.18423) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.88872 (A-MSE: 0.78552) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.98936 (A-MSE: 0.87444) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 6 out of 50
train epoch 1306 avg loss: 0.22532 (A-MSE: 0.20067) avg lploss: 0.00000
train epoch 1307 avg loss: 0.20996 (A-MSE: 0.18641) avg lploss: 0.00000
train epoch 1308 avg loss: 0.19801 (A-MSE: 0.17661) avg lploss: 0.00000
train epoch 1309 avg loss: 0.19410 (A-MSE: 0.17153) avg lploss: 0.00000
train epoch 1310 avg loss: 0.20861 (A-MSE: 0.18499) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.84469 (A-MSE: 0.74380) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.93515 (A-MSE: 0.82107) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 7 out of 50
train epoch 1311 avg loss: 0.18378 (A-MSE: 0.16237) avg lploss: 0.00000
train epoch 1312 avg loss: 0.23260 (A-MSE: 0.20623) avg lploss: 0.00000
train epoch 1313 avg loss: 0.25513 (A-MSE: 0.22538) avg lploss: 0.00000
train epoch 1314 avg loss: 0.27836 (A-MSE: 0.24687) avg lploss: 0.00000
train epoch 1315 avg loss: 0.24214 (A-MSE: 0.21514) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.80247 (A-MSE: 0.72130) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.93081 (A-MSE: 0.82776) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 8 out of 50
train epoch 1316 avg loss: 0.32518 (A-MSE: 0.29072) avg lploss: 0.00000
train epoch 1317 avg loss: 0.33422 (A-MSE: 0.29395) avg lploss: 0.00000
train epoch 1318 avg loss: 0.23047 (A-MSE: 0.20322) avg lploss: 0.00000
train epoch 1319 avg loss: 0.18090 (A-MSE: 0.15975) avg lploss: 0.00000
train epoch 1320 avg loss: 0.16847 (A-MSE: 0.14956) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.76001 (A-MSE: 0.66945) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.85103 (A-MSE: 0.75778) avg lploss: 0.00000
*** Best Val Loss: 0.74427 	 Best Test Loss: 0.90885 	 Best epoch 1275
EarlyStopping counter: 9 out of 50
train epoch 1321 avg loss: 0.21946 (A-MSE: 0.19348) avg lploss: 0.00000
train epoch 1322 avg loss: 0.22097 (A-MSE: 0.19495) avg lploss: 0.00000
train epoch 1323 avg loss: 0.20927 (A-MSE: 0.18572) avg lploss: 0.00000
train epoch 1324 avg loss: 0.20087 (A-MSE: 0.17802) avg lploss: 0.00000
train epoch 1325 avg loss: 0.17554 (A-MSE: 0.15683) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.70452 (A-MSE: 0.61919) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.82421 (A-MSE: 0.72703) avg lploss: 0.00000
*** Best Val Loss: 0.70452 	 Best Test Loss: 0.82421 	 Best epoch 1325
Validation loss decreased (0.744273 --> 0.704521).  Saving model ...
train epoch 1326 avg loss: 0.16840 (A-MSE: 0.14918) avg lploss: 0.00000
train epoch 1327 avg loss: 0.18379 (A-MSE: 0.16164) avg lploss: 0.00000
train epoch 1328 avg loss: 0.19286 (A-MSE: 0.17030) avg lploss: 0.00000
train epoch 1329 avg loss: 0.22827 (A-MSE: 0.20196) avg lploss: 0.00000
train epoch 1330 avg loss: 0.25649 (A-MSE: 0.22547) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.78733 (A-MSE: 0.69425) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.85680 (A-MSE: 0.75689) avg lploss: 0.00000
*** Best Val Loss: 0.70452 	 Best Test Loss: 0.82421 	 Best epoch 1325
EarlyStopping counter: 1 out of 50
train epoch 1331 avg loss: 0.18945 (A-MSE: 0.16859) avg lploss: 0.00000
train epoch 1332 avg loss: 0.19735 (A-MSE: 0.17515) avg lploss: 0.00000
train epoch 1333 avg loss: 0.19686 (A-MSE: 0.17512) avg lploss: 0.00000
train epoch 1334 avg loss: 0.18534 (A-MSE: 0.16341) avg lploss: 0.00000
train epoch 1335 avg loss: 0.18354 (A-MSE: 0.16409) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.72699 (A-MSE: 0.63743) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.83562 (A-MSE: 0.73121) avg lploss: 0.00000
*** Best Val Loss: 0.70452 	 Best Test Loss: 0.82421 	 Best epoch 1325
EarlyStopping counter: 2 out of 50
train epoch 1336 avg loss: 0.16708 (A-MSE: 0.14876) avg lploss: 0.00000
train epoch 1337 avg loss: 0.18472 (A-MSE: 0.16498) avg lploss: 0.00000
train epoch 1338 avg loss: 0.18914 (A-MSE: 0.16704) avg lploss: 0.00000
train epoch 1339 avg loss: 0.17785 (A-MSE: 0.15766) avg lploss: 0.00000
train epoch 1340 avg loss: 0.19059 (A-MSE: 0.16953) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.77208 (A-MSE: 0.67662) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.91339 (A-MSE: 0.79740) avg lploss: 0.00000
*** Best Val Loss: 0.70452 	 Best Test Loss: 0.82421 	 Best epoch 1325
EarlyStopping counter: 3 out of 50
train epoch 1341 avg loss: 0.19891 (A-MSE: 0.17652) avg lploss: 0.00000
train epoch 1342 avg loss: 0.19547 (A-MSE: 0.17389) avg lploss: 0.00000
train epoch 1343 avg loss: 0.19695 (A-MSE: 0.17389) avg lploss: 0.00000
train epoch 1344 avg loss: 0.20277 (A-MSE: 0.18102) avg lploss: 0.00000
train epoch 1345 avg loss: 0.21738 (A-MSE: 0.19063) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.80427 (A-MSE: 0.71728) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.96573 (A-MSE: 0.85205) avg lploss: 0.00000
*** Best Val Loss: 0.70452 	 Best Test Loss: 0.82421 	 Best epoch 1325
EarlyStopping counter: 4 out of 50
train epoch 1346 avg loss: 0.18551 (A-MSE: 0.16436) avg lploss: 0.00000
train epoch 1347 avg loss: 0.17786 (A-MSE: 0.15761) avg lploss: 0.00000
train epoch 1348 avg loss: 0.16109 (A-MSE: 0.14384) avg lploss: 0.00000
train epoch 1349 avg loss: 0.18715 (A-MSE: 0.16571) avg lploss: 0.00000
train epoch 1350 avg loss: 0.24198 (A-MSE: 0.21459) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.77787 (A-MSE: 0.69217) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.85323 (A-MSE: 0.75936) avg lploss: 0.00000
*** Best Val Loss: 0.70452 	 Best Test Loss: 0.82421 	 Best epoch 1325
EarlyStopping counter: 5 out of 50
train epoch 1351 avg loss: 0.18387 (A-MSE: 0.16451) avg lploss: 0.00000
train epoch 1352 avg loss: 0.18623 (A-MSE: 0.16582) avg lploss: 0.00000
train epoch 1353 avg loss: 0.18431 (A-MSE: 0.16327) avg lploss: 0.00000
train epoch 1354 avg loss: 0.17206 (A-MSE: 0.15223) avg lploss: 0.00000
train epoch 1355 avg loss: 0.16753 (A-MSE: 0.14880) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.65123 (A-MSE: 0.58036) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.78429 (A-MSE: 0.69440) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
Validation loss decreased (0.704521 --> 0.651235).  Saving model ...
train epoch 1356 avg loss: 0.16393 (A-MSE: 0.14545) avg lploss: 0.00000
train epoch 1357 avg loss: 0.18653 (A-MSE: 0.16495) avg lploss: 0.00000
train epoch 1358 avg loss: 0.21550 (A-MSE: 0.18999) avg lploss: 0.00000
train epoch 1359 avg loss: 0.20537 (A-MSE: 0.18222) avg lploss: 0.00000
train epoch 1360 avg loss: 0.18851 (A-MSE: 0.16693) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.70713 (A-MSE: 0.62519) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.82835 (A-MSE: 0.72636) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 1 out of 50
train epoch 1361 avg loss: 0.16355 (A-MSE: 0.14633) avg lploss: 0.00000
train epoch 1362 avg loss: 0.17377 (A-MSE: 0.15440) avg lploss: 0.00000
train epoch 1363 avg loss: 0.18742 (A-MSE: 0.16655) avg lploss: 0.00000
train epoch 1364 avg loss: 0.17883 (A-MSE: 0.15985) avg lploss: 0.00000
train epoch 1365 avg loss: 0.19356 (A-MSE: 0.17170) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.80529 (A-MSE: 0.71387) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.92420 (A-MSE: 0.81537) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 2 out of 50
train epoch 1366 avg loss: 0.22285 (A-MSE: 0.19654) avg lploss: 0.00000
train epoch 1367 avg loss: 0.22209 (A-MSE: 0.19671) avg lploss: 0.00000
train epoch 1368 avg loss: 0.23039 (A-MSE: 0.20330) avg lploss: 0.00000
train epoch 1369 avg loss: 0.24492 (A-MSE: 0.21607) avg lploss: 0.00000
train epoch 1370 avg loss: 0.21165 (A-MSE: 0.18781) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.79303 (A-MSE: 0.69133) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.89729 (A-MSE: 0.78726) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 3 out of 50
train epoch 1371 avg loss: 0.25148 (A-MSE: 0.22298) avg lploss: 0.00000
train epoch 1372 avg loss: 0.22386 (A-MSE: 0.19975) avg lploss: 0.00000
train epoch 1373 avg loss: 0.20449 (A-MSE: 0.18263) avg lploss: 0.00000
train epoch 1374 avg loss: 0.19069 (A-MSE: 0.16980) avg lploss: 0.00000
train epoch 1375 avg loss: 0.16331 (A-MSE: 0.14597) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.80178 (A-MSE: 0.69904) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.95182 (A-MSE: 0.82934) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 4 out of 50
train epoch 1376 avg loss: 0.16829 (A-MSE: 0.14914) avg lploss: 0.00000
train epoch 1377 avg loss: 0.17090 (A-MSE: 0.15270) avg lploss: 0.00000
train epoch 1378 avg loss: 0.16106 (A-MSE: 0.14134) avg lploss: 0.00000
train epoch 1379 avg loss: 0.14778 (A-MSE: 0.13202) avg lploss: 0.00000
train epoch 1380 avg loss: 0.15943 (A-MSE: 0.14179) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.70129 (A-MSE: 0.61862) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.82107 (A-MSE: 0.72145) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 5 out of 50
train epoch 1381 avg loss: 0.17233 (A-MSE: 0.15258) avg lploss: 0.00000
train epoch 1382 avg loss: 0.15302 (A-MSE: 0.13579) avg lploss: 0.00000
train epoch 1383 avg loss: 0.21334 (A-MSE: 0.18830) avg lploss: 0.00000
train epoch 1384 avg loss: 0.22425 (A-MSE: 0.19874) avg lploss: 0.00000
train epoch 1385 avg loss: 0.20190 (A-MSE: 0.17872) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.80509 (A-MSE: 0.70107) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.90331 (A-MSE: 0.79002) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 6 out of 50
train epoch 1386 avg loss: 0.18216 (A-MSE: 0.16339) avg lploss: 0.00000
train epoch 1387 avg loss: 0.18737 (A-MSE: 0.16528) avg lploss: 0.00000
train epoch 1388 avg loss: 0.22837 (A-MSE: 0.20276) avg lploss: 0.00000
train epoch 1389 avg loss: 0.20708 (A-MSE: 0.18501) avg lploss: 0.00000
train epoch 1390 avg loss: 0.21372 (A-MSE: 0.18871) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.85677 (A-MSE: 0.76136) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.97336 (A-MSE: 0.86213) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 7 out of 50
train epoch 1391 avg loss: 0.17337 (A-MSE: 0.15402) avg lploss: 0.00000
train epoch 1392 avg loss: 0.17538 (A-MSE: 0.15547) avg lploss: 0.00000
train epoch 1393 avg loss: 0.20860 (A-MSE: 0.18197) avg lploss: 0.00000
train epoch 1394 avg loss: 0.19533 (A-MSE: 0.17455) avg lploss: 0.00000
train epoch 1395 avg loss: 0.20828 (A-MSE: 0.18354) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.78553 (A-MSE: 0.69392) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.86315 (A-MSE: 0.76190) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 8 out of 50
train epoch 1396 avg loss: 0.17746 (A-MSE: 0.15842) avg lploss: 0.00000
train epoch 1397 avg loss: 0.17529 (A-MSE: 0.15650) avg lploss: 0.00000
train epoch 1398 avg loss: 0.14581 (A-MSE: 0.13047) avg lploss: 0.00000
train epoch 1399 avg loss: 0.15527 (A-MSE: 0.13768) avg lploss: 0.00000
train epoch 1400 avg loss: 0.17498 (A-MSE: 0.15625) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.77570 (A-MSE: 0.68634) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.90692 (A-MSE: 0.79852) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 9 out of 50
train epoch 1401 avg loss: 0.15985 (A-MSE: 0.14210) avg lploss: 0.00000
train epoch 1402 avg loss: 0.16162 (A-MSE: 0.14325) avg lploss: 0.00000
train epoch 1403 avg loss: 0.14565 (A-MSE: 0.12995) avg lploss: 0.00000
train epoch 1404 avg loss: 0.15236 (A-MSE: 0.13582) avg lploss: 0.00000
train epoch 1405 avg loss: 0.14817 (A-MSE: 0.13061) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.80169 (A-MSE: 0.70802) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.88650 (A-MSE: 0.78328) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 10 out of 50
train epoch 1406 avg loss: 0.14920 (A-MSE: 0.13269) avg lploss: 0.00000
train epoch 1407 avg loss: 0.13631 (A-MSE: 0.12203) avg lploss: 0.00000
train epoch 1408 avg loss: 0.13915 (A-MSE: 0.12472) avg lploss: 0.00000
train epoch 1409 avg loss: 0.15190 (A-MSE: 0.13608) avg lploss: 0.00000
train epoch 1410 avg loss: 0.15784 (A-MSE: 0.13994) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.69808 (A-MSE: 0.62107) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.81344 (A-MSE: 0.71779) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 11 out of 50
train epoch 1411 avg loss: 0.16449 (A-MSE: 0.14599) avg lploss: 0.00000
train epoch 1412 avg loss: 0.15338 (A-MSE: 0.13769) avg lploss: 0.00000
train epoch 1413 avg loss: 0.16233 (A-MSE: 0.14537) avg lploss: 0.00000
train epoch 1414 avg loss: 0.16797 (A-MSE: 0.14827) avg lploss: 0.00000
train epoch 1415 avg loss: 0.16956 (A-MSE: 0.15096) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.78487 (A-MSE: 0.68259) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.92194 (A-MSE: 0.79936) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 12 out of 50
train epoch 1416 avg loss: 0.16054 (A-MSE: 0.14184) avg lploss: 0.00000
train epoch 1417 avg loss: 0.20601 (A-MSE: 0.18321) avg lploss: 0.00000
train epoch 1418 avg loss: 0.22893 (A-MSE: 0.20284) avg lploss: 0.00000
train epoch 1419 avg loss: 0.22948 (A-MSE: 0.20218) avg lploss: 0.00000
train epoch 1420 avg loss: 0.18749 (A-MSE: 0.16487) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.72322 (A-MSE: 0.62916) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.80415 (A-MSE: 0.70548) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 13 out of 50
train epoch 1421 avg loss: 0.16739 (A-MSE: 0.14946) avg lploss: 0.00000
train epoch 1422 avg loss: 0.18160 (A-MSE: 0.16062) avg lploss: 0.00000
train epoch 1423 avg loss: 0.19101 (A-MSE: 0.16921) avg lploss: 0.00000
train epoch 1424 avg loss: 0.19467 (A-MSE: 0.17395) avg lploss: 0.00000
train epoch 1425 avg loss: 0.16907 (A-MSE: 0.15106) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.72483 (A-MSE: 0.63570) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.86890 (A-MSE: 0.75732) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 14 out of 50
train epoch 1426 avg loss: 0.14813 (A-MSE: 0.13304) avg lploss: 0.00000
train epoch 1427 avg loss: 0.15317 (A-MSE: 0.13608) avg lploss: 0.00000
train epoch 1428 avg loss: 0.16262 (A-MSE: 0.14502) avg lploss: 0.00000
train epoch 1429 avg loss: 0.18786 (A-MSE: 0.16600) avg lploss: 0.00000
train epoch 1430 avg loss: 0.20685 (A-MSE: 0.18158) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.67774 (A-MSE: 0.59448) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.77788 (A-MSE: 0.68482) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 15 out of 50
train epoch 1431 avg loss: 0.16900 (A-MSE: 0.14919) avg lploss: 0.00000
train epoch 1432 avg loss: 0.15697 (A-MSE: 0.13846) avg lploss: 0.00000
train epoch 1433 avg loss: 0.17669 (A-MSE: 0.15646) avg lploss: 0.00000
train epoch 1434 avg loss: 0.17570 (A-MSE: 0.15705) avg lploss: 0.00000
train epoch 1435 avg loss: 0.16298 (A-MSE: 0.14576) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.71975 (A-MSE: 0.63710) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.79716 (A-MSE: 0.70297) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 16 out of 50
train epoch 1436 avg loss: 0.15318 (A-MSE: 0.13506) avg lploss: 0.00000
train epoch 1437 avg loss: 0.18896 (A-MSE: 0.16669) avg lploss: 0.00000
train epoch 1438 avg loss: 27.89188 (A-MSE: 24.46261) avg lploss: 0.00000
train epoch 1439 avg loss: 10.97926 (A-MSE: 9.37967) avg lploss: 0.00000
train epoch 1440 avg loss: 4.99143 (A-MSE: 4.24861) avg lploss: 0.00000
==> val epoch 1440 avg loss: 4.24706 (A-MSE: 3.64083) avg lploss: 0.00000
==> test epoch 1440 avg loss: 4.44991 (A-MSE: 3.81009) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 17 out of 50
train epoch 1441 avg loss: 3.29453 (A-MSE: 2.80641) avg lploss: 0.00000
train epoch 1442 avg loss: 2.59626 (A-MSE: 2.22091) avg lploss: 0.00000
train epoch 1443 avg loss: 2.20437 (A-MSE: 1.88690) avg lploss: 0.00000
train epoch 1444 avg loss: 1.81362 (A-MSE: 1.54017) avg lploss: 0.00000
train epoch 1445 avg loss: 1.66284 (A-MSE: 1.42083) avg lploss: 0.00000
==> val epoch 1445 avg loss: 2.00348 (A-MSE: 1.62527) avg lploss: 0.00000
==> test epoch 1445 avg loss: 2.19232 (A-MSE: 1.81069) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 18 out of 50
train epoch 1446 avg loss: 1.52520 (A-MSE: 1.30109) avg lploss: 0.00000
train epoch 1447 avg loss: 1.49083 (A-MSE: 1.27484) avg lploss: 0.00000
train epoch 1448 avg loss: 1.38487 (A-MSE: 1.18745) avg lploss: 0.00000
train epoch 1449 avg loss: 1.28315 (A-MSE: 1.12444) avg lploss: 0.00000
train epoch 1450 avg loss: 1.17528 (A-MSE: 1.01346) avg lploss: 0.00000
==> val epoch 1450 avg loss: 1.38245 (A-MSE: 1.17954) avg lploss: 0.00000
==> test epoch 1450 avg loss: 1.45064 (A-MSE: 1.25896) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 19 out of 50
train epoch 1451 avg loss: 1.15286 (A-MSE: 1.00261) avg lploss: 0.00000
train epoch 1452 avg loss: 1.07010 (A-MSE: 0.92397) avg lploss: 0.00000
train epoch 1453 avg loss: 1.04457 (A-MSE: 0.90293) avg lploss: 0.00000
train epoch 1454 avg loss: 0.97438 (A-MSE: 0.85711) avg lploss: 0.00000
train epoch 1455 avg loss: 0.95986 (A-MSE: 0.84225) avg lploss: 0.00000
==> val epoch 1455 avg loss: 1.30324 (A-MSE: 1.06301) avg lploss: 0.00000
==> test epoch 1455 avg loss: 1.44910 (A-MSE: 1.21274) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 20 out of 50
train epoch 1456 avg loss: 0.91933 (A-MSE: 0.79283) avg lploss: 0.00000
train epoch 1457 avg loss: 0.89589 (A-MSE: 0.78746) avg lploss: 0.00000
train epoch 1458 avg loss: 0.95971 (A-MSE: 0.83722) avg lploss: 0.00000
train epoch 1459 avg loss: 0.96258 (A-MSE: 0.84931) avg lploss: 0.00000
train epoch 1460 avg loss: 0.90921 (A-MSE: 0.79916) avg lploss: 0.00000
==> val epoch 1460 avg loss: 1.16619 (A-MSE: 1.03413) avg lploss: 0.00000
==> test epoch 1460 avg loss: 1.28946 (A-MSE: 1.16934) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 21 out of 50
train epoch 1461 avg loss: 0.85776 (A-MSE: 0.75286) avg lploss: 0.00000
train epoch 1462 avg loss: 0.78586 (A-MSE: 0.68338) avg lploss: 0.00000
train epoch 1463 avg loss: 0.74604 (A-MSE: 0.65373) avg lploss: 0.00000
train epoch 1464 avg loss: 0.75768 (A-MSE: 0.66056) avg lploss: 0.00000
train epoch 1465 avg loss: 0.72047 (A-MSE: 0.63051) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.97441 (A-MSE: 0.86419) avg lploss: 0.00000
==> test epoch 1465 avg loss: 1.05494 (A-MSE: 0.95471) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 22 out of 50
train epoch 1466 avg loss: 0.67488 (A-MSE: 0.59582) avg lploss: 0.00000
train epoch 1467 avg loss: 0.70811 (A-MSE: 0.62449) avg lploss: 0.00000
train epoch 1468 avg loss: 0.65853 (A-MSE: 0.57584) avg lploss: 0.00000
train epoch 1469 avg loss: 0.63398 (A-MSE: 0.56054) avg lploss: 0.00000
train epoch 1470 avg loss: 0.63482 (A-MSE: 0.55687) avg lploss: 0.00000
==> val epoch 1470 avg loss: 1.04499 (A-MSE: 0.89061) avg lploss: 0.00000
==> test epoch 1470 avg loss: 1.09074 (A-MSE: 0.96206) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 23 out of 50
train epoch 1471 avg loss: 0.67751 (A-MSE: 0.59834) avg lploss: 0.00000
train epoch 1472 avg loss: 0.64616 (A-MSE: 0.56686) avg lploss: 0.00000
train epoch 1473 avg loss: 0.62680 (A-MSE: 0.55293) avg lploss: 0.00000
train epoch 1474 avg loss: 0.63315 (A-MSE: 0.55897) avg lploss: 0.00000
train epoch 1475 avg loss: 0.60660 (A-MSE: 0.53122) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.85727 (A-MSE: 0.74507) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.92029 (A-MSE: 0.82421) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 24 out of 50
train epoch 1476 avg loss: 0.55067 (A-MSE: 0.48709) avg lploss: 0.00000
train epoch 1477 avg loss: 0.55377 (A-MSE: 0.48693) avg lploss: 0.00000
train epoch 1478 avg loss: 0.53524 (A-MSE: 0.47188) avg lploss: 0.00000
train epoch 1479 avg loss: 0.51294 (A-MSE: 0.45238) avg lploss: 0.00000
train epoch 1480 avg loss: 0.50308 (A-MSE: 0.44229) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.79942 (A-MSE: 0.69691) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.83600 (A-MSE: 0.75741) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 25 out of 50
train epoch 1481 avg loss: 0.54821 (A-MSE: 0.48308) avg lploss: 0.00000
train epoch 1482 avg loss: 0.57384 (A-MSE: 0.50364) avg lploss: 0.00000
train epoch 1483 avg loss: 0.53317 (A-MSE: 0.47094) avg lploss: 0.00000
train epoch 1484 avg loss: 0.56795 (A-MSE: 0.50176) avg lploss: 0.00000
train epoch 1485 avg loss: 0.54115 (A-MSE: 0.47835) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.85452 (A-MSE: 0.72228) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.87601 (A-MSE: 0.77277) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 26 out of 50
train epoch 1486 avg loss: 0.48318 (A-MSE: 0.42717) avg lploss: 0.00000
train epoch 1487 avg loss: 0.46248 (A-MSE: 0.41054) avg lploss: 0.00000
train epoch 1488 avg loss: 0.43690 (A-MSE: 0.38863) avg lploss: 0.00000
train epoch 1489 avg loss: 0.45055 (A-MSE: 0.39919) avg lploss: 0.00000
train epoch 1490 avg loss: 0.43544 (A-MSE: 0.38449) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.65710 (A-MSE: 0.56909) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.72007 (A-MSE: 0.64171) avg lploss: 0.00000
*** Best Val Loss: 0.65123 	 Best Test Loss: 0.78429 	 Best epoch 1355
EarlyStopping counter: 27 out of 50
train epoch 1491 avg loss: 0.44348 (A-MSE: 0.39247) avg lploss: 0.00000
train epoch 1492 avg loss: 0.44171 (A-MSE: 0.39298) avg lploss: 0.00000
train epoch 1493 avg loss: 0.42214 (A-MSE: 0.37326) avg lploss: 0.00000
train epoch 1494 avg loss: 0.40473 (A-MSE: 0.36059) avg lploss: 0.00000
train epoch 1495 avg loss: 0.42184 (A-MSE: 0.37391) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.60728 (A-MSE: 0.51772) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.60599 (A-MSE: 0.54260) avg lploss: 0.00000
*** Best Val Loss: 0.60728 	 Best Test Loss: 0.60599 	 Best epoch 1495
Validation loss decreased (0.651235 --> 0.607282).  Saving model ...
train epoch 1496 avg loss: 0.37969 (A-MSE: 0.33511) avg lploss: 0.00000
train epoch 1497 avg loss: 0.40041 (A-MSE: 0.35302) avg lploss: 0.00000
train epoch 1498 avg loss: 0.40174 (A-MSE: 0.35523) avg lploss: 0.00000
train epoch 1499 avg loss: 0.41855 (A-MSE: 0.37106) avg lploss: 0.00000
train epoch 1500 avg loss: 0.40869 (A-MSE: 0.36217) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.61055 (A-MSE: 0.52804) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.63552 (A-MSE: 0.57098) avg lploss: 0.00000
*** Best Val Loss: 0.60728 	 Best Test Loss: 0.60599 	 Best epoch 1495
EarlyStopping counter: 1 out of 50
train epoch 1501 avg loss: 0.41889 (A-MSE: 0.37418) avg lploss: 0.00000
train epoch 1502 avg loss: 0.36362 (A-MSE: 0.32013) avg lploss: 0.00000
train epoch 1503 avg loss: 0.37747 (A-MSE: 0.33377) avg lploss: 0.00000
train epoch 1504 avg loss: 0.36419 (A-MSE: 0.32219) avg lploss: 0.00000
train epoch 1505 avg loss: 0.36960 (A-MSE: 0.32744) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.61894 (A-MSE: 0.52914) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.63620 (A-MSE: 0.57033) avg lploss: 0.00000
*** Best Val Loss: 0.60728 	 Best Test Loss: 0.60599 	 Best epoch 1495
EarlyStopping counter: 2 out of 50
train epoch 1506 avg loss: 0.34668 (A-MSE: 0.30814) avg lploss: 0.00000
train epoch 1507 avg loss: 0.35576 (A-MSE: 0.31244) avg lploss: 0.00000
train epoch 1508 avg loss: 0.34826 (A-MSE: 0.31038) avg lploss: 0.00000
train epoch 1509 avg loss: 0.38917 (A-MSE: 0.34472) avg lploss: 0.00000
train epoch 1510 avg loss: 0.34898 (A-MSE: 0.30919) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.53658 (A-MSE: 0.46266) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.58667 (A-MSE: 0.52387) avg lploss: 0.00000
*** Best Val Loss: 0.53658 	 Best Test Loss: 0.58667 	 Best epoch 1510
Validation loss decreased (0.607282 --> 0.536579).  Saving model ...
train epoch 1511 avg loss: 0.33932 (A-MSE: 0.30025) avg lploss: 0.00000
train epoch 1512 avg loss: 0.38631 (A-MSE: 0.34109) avg lploss: 0.00000
train epoch 1513 avg loss: 0.42149 (A-MSE: 0.37408) avg lploss: 0.00000
train epoch 1514 avg loss: 0.36658 (A-MSE: 0.32554) avg lploss: 0.00000
train epoch 1515 avg loss: 0.34629 (A-MSE: 0.30717) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.55217 (A-MSE: 0.47279) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.56027 (A-MSE: 0.50064) avg lploss: 0.00000
*** Best Val Loss: 0.53658 	 Best Test Loss: 0.58667 	 Best epoch 1510
EarlyStopping counter: 1 out of 50
train epoch 1516 avg loss: 0.33890 (A-MSE: 0.29899) avg lploss: 0.00000
train epoch 1517 avg loss: 0.34442 (A-MSE: 0.30647) avg lploss: 0.00000
train epoch 1518 avg loss: 0.33817 (A-MSE: 0.30031) avg lploss: 0.00000
train epoch 1519 avg loss: 0.34012 (A-MSE: 0.30088) avg lploss: 0.00000
train epoch 1520 avg loss: 0.30608 (A-MSE: 0.27210) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.52462 (A-MSE: 0.45004) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.52320 (A-MSE: 0.47135) avg lploss: 0.00000
*** Best Val Loss: 0.52462 	 Best Test Loss: 0.52320 	 Best epoch 1520
Validation loss decreased (0.536579 --> 0.524620).  Saving model ...
train epoch 1521 avg loss: 0.30811 (A-MSE: 0.27174) avg lploss: 0.00000
train epoch 1522 avg loss: 0.30362 (A-MSE: 0.27099) avg lploss: 0.00000
train epoch 1523 avg loss: 0.29627 (A-MSE: 0.26212) avg lploss: 0.00000
train epoch 1524 avg loss: 0.32034 (A-MSE: 0.28279) avg lploss: 0.00000
train epoch 1525 avg loss: 0.31651 (A-MSE: 0.28287) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.51413 (A-MSE: 0.43752) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.52126 (A-MSE: 0.46385) avg lploss: 0.00000
*** Best Val Loss: 0.51413 	 Best Test Loss: 0.52126 	 Best epoch 1525
Validation loss decreased (0.524620 --> 0.514133).  Saving model ...
train epoch 1526 avg loss: 0.33128 (A-MSE: 0.29231) avg lploss: 0.00000
train epoch 1527 avg loss: 0.32955 (A-MSE: 0.29168) avg lploss: 0.00000
train epoch 1528 avg loss: 0.30690 (A-MSE: 0.27269) avg lploss: 0.00000
train epoch 1529 avg loss: 0.31502 (A-MSE: 0.28184) avg lploss: 0.00000
train epoch 1530 avg loss: 0.33894 (A-MSE: 0.29996) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.57661 (A-MSE: 0.48824) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.55330 (A-MSE: 0.49153) avg lploss: 0.00000
*** Best Val Loss: 0.51413 	 Best Test Loss: 0.52126 	 Best epoch 1525
EarlyStopping counter: 1 out of 50
train epoch 1531 avg loss: 0.30003 (A-MSE: 0.26574) avg lploss: 0.00000
train epoch 1532 avg loss: 0.30211 (A-MSE: 0.26769) avg lploss: 0.00000
train epoch 1533 avg loss: 0.30206 (A-MSE: 0.26744) avg lploss: 0.00000
train epoch 1534 avg loss: 0.29175 (A-MSE: 0.25886) avg lploss: 0.00000
train epoch 1535 avg loss: 0.29840 (A-MSE: 0.26524) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.64145 (A-MSE: 0.55558) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.58778 (A-MSE: 0.53223) avg lploss: 0.00000
*** Best Val Loss: 0.51413 	 Best Test Loss: 0.52126 	 Best epoch 1525
EarlyStopping counter: 2 out of 50
train epoch 1536 avg loss: 0.30629 (A-MSE: 0.27163) avg lploss: 0.00000
train epoch 1537 avg loss: 0.32056 (A-MSE: 0.28336) avg lploss: 0.00000
train epoch 1538 avg loss: 0.32838 (A-MSE: 0.29270) avg lploss: 0.00000
train epoch 1539 avg loss: 0.29395 (A-MSE: 0.26004) avg lploss: 0.00000
train epoch 1540 avg loss: 0.29257 (A-MSE: 0.25859) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.56080 (A-MSE: 0.48027) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.54714 (A-MSE: 0.49152) avg lploss: 0.00000
*** Best Val Loss: 0.51413 	 Best Test Loss: 0.52126 	 Best epoch 1525
EarlyStopping counter: 3 out of 50
train epoch 1541 avg loss: 0.31105 (A-MSE: 0.27776) avg lploss: 0.00000
train epoch 1542 avg loss: 0.30544 (A-MSE: 0.26893) avg lploss: 0.00000
train epoch 1543 avg loss: 0.27870 (A-MSE: 0.24690) avg lploss: 0.00000
train epoch 1544 avg loss: 0.28718 (A-MSE: 0.25422) avg lploss: 0.00000
train epoch 1545 avg loss: 0.26375 (A-MSE: 0.23230) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.45366 (A-MSE: 0.39272) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.47332 (A-MSE: 0.42922) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
Validation loss decreased (0.514133 --> 0.453658).  Saving model ...
train epoch 1546 avg loss: 0.25263 (A-MSE: 0.22391) avg lploss: 0.00000
train epoch 1547 avg loss: 0.28863 (A-MSE: 0.25619) avg lploss: 0.00000
train epoch 1548 avg loss: 0.25286 (A-MSE: 0.22474) avg lploss: 0.00000
train epoch 1549 avg loss: 0.26445 (A-MSE: 0.23435) avg lploss: 0.00000
train epoch 1550 avg loss: 0.27529 (A-MSE: 0.24255) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.50254 (A-MSE: 0.42456) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.49738 (A-MSE: 0.44277) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
EarlyStopping counter: 1 out of 50
train epoch 1551 avg loss: 0.27293 (A-MSE: 0.24147) avg lploss: 0.00000
train epoch 1552 avg loss: 0.26399 (A-MSE: 0.23348) avg lploss: 0.00000
train epoch 1553 avg loss: 0.25816 (A-MSE: 0.22941) avg lploss: 0.00000
train epoch 1554 avg loss: 0.28870 (A-MSE: 0.25564) avg lploss: 0.00000
train epoch 1555 avg loss: 0.30012 (A-MSE: 0.26823) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.55368 (A-MSE: 0.46966) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.54785 (A-MSE: 0.48062) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
EarlyStopping counter: 2 out of 50
train epoch 1556 avg loss: 0.30389 (A-MSE: 0.26637) avg lploss: 0.00000
train epoch 1557 avg loss: 0.26327 (A-MSE: 0.23346) avg lploss: 0.00000
train epoch 1558 avg loss: 0.25852 (A-MSE: 0.22894) avg lploss: 0.00000
train epoch 1559 avg loss: 0.26169 (A-MSE: 0.22840) avg lploss: 0.00000
train epoch 1560 avg loss: 0.25965 (A-MSE: 0.23085) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.46504 (A-MSE: 0.39375) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.45359 (A-MSE: 0.39832) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
EarlyStopping counter: 3 out of 50
train epoch 1561 avg loss: 0.27488 (A-MSE: 0.24306) avg lploss: 0.00000
train epoch 1562 avg loss: 0.24009 (A-MSE: 0.21180) avg lploss: 0.00000
train epoch 1563 avg loss: 0.23431 (A-MSE: 0.20602) avg lploss: 0.00000
train epoch 1564 avg loss: 0.24748 (A-MSE: 0.21971) avg lploss: 0.00000
train epoch 1565 avg loss: 0.26026 (A-MSE: 0.22883) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.55006 (A-MSE: 0.45662) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.51065 (A-MSE: 0.44605) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
EarlyStopping counter: 4 out of 50
train epoch 1566 avg loss: 0.25034 (A-MSE: 0.22035) avg lploss: 0.00000
train epoch 1567 avg loss: 0.23288 (A-MSE: 0.20567) avg lploss: 0.00000
train epoch 1568 avg loss: 0.25836 (A-MSE: 0.22968) avg lploss: 0.00000
train epoch 1569 avg loss: 0.24955 (A-MSE: 0.22098) avg lploss: 0.00000
train epoch 1570 avg loss: 0.28807 (A-MSE: 0.25680) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.69889 (A-MSE: 0.59693) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.63001 (A-MSE: 0.55952) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
EarlyStopping counter: 5 out of 50
train epoch 1571 avg loss: 0.29166 (A-MSE: 0.26083) avg lploss: 0.00000
train epoch 1572 avg loss: 0.28363 (A-MSE: 0.25170) avg lploss: 0.00000
train epoch 1573 avg loss: 0.25194 (A-MSE: 0.22170) avg lploss: 0.00000
train epoch 1574 avg loss: 0.23123 (A-MSE: 0.20541) avg lploss: 0.00000
train epoch 1575 avg loss: 0.23897 (A-MSE: 0.21052) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.49650 (A-MSE: 0.43882) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.53318 (A-MSE: 0.48064) avg lploss: 0.00000
*** Best Val Loss: 0.45366 	 Best Test Loss: 0.47332 	 Best epoch 1545
EarlyStopping counter: 6 out of 50
train epoch 1576 avg loss: 0.26488 (A-MSE: 0.23593) avg lploss: 0.00000
train epoch 1577 avg loss: 0.22484 (A-MSE: 0.19875) avg lploss: 0.00000
train epoch 1578 avg loss: 0.23183 (A-MSE: 0.20526) avg lploss: 0.00000
train epoch 1579 avg loss: 0.22898 (A-MSE: 0.20338) avg lploss: 0.00000
train epoch 1580 avg loss: 0.21947 (A-MSE: 0.19400) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.38781 (A-MSE: 0.33069) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.40932 (A-MSE: 0.36252) avg lploss: 0.00000
*** Best Val Loss: 0.38781 	 Best Test Loss: 0.40932 	 Best epoch 1580
Validation loss decreased (0.453658 --> 0.387813).  Saving model ...
train epoch 1581 avg loss: 0.21655 (A-MSE: 0.19089) avg lploss: 0.00000
train epoch 1582 avg loss: 0.23363 (A-MSE: 0.20474) avg lploss: 0.00000
train epoch 1583 avg loss: 0.24810 (A-MSE: 0.22021) avg lploss: 0.00000
train epoch 1584 avg loss: 0.26950 (A-MSE: 0.24000) avg lploss: 0.00000
train epoch 1585 avg loss: 0.23271 (A-MSE: 0.20734) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.43747 (A-MSE: 0.37390) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.46512 (A-MSE: 0.40813) avg lploss: 0.00000
*** Best Val Loss: 0.38781 	 Best Test Loss: 0.40932 	 Best epoch 1580
EarlyStopping counter: 1 out of 50
train epoch 1586 avg loss: 0.21407 (A-MSE: 0.18754) avg lploss: 0.00000
train epoch 1587 avg loss: 0.21225 (A-MSE: 0.18620) avg lploss: 0.00000
train epoch 1588 avg loss: 0.21295 (A-MSE: 0.18763) avg lploss: 0.00000
train epoch 1589 avg loss: 0.20375 (A-MSE: 0.17985) avg lploss: 0.00000
train epoch 1590 avg loss: 0.22972 (A-MSE: 0.20234) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.47680 (A-MSE: 0.40592) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.44772 (A-MSE: 0.40001) avg lploss: 0.00000
*** Best Val Loss: 0.38781 	 Best Test Loss: 0.40932 	 Best epoch 1580
EarlyStopping counter: 2 out of 50
train epoch 1591 avg loss: 0.26214 (A-MSE: 0.23202) avg lploss: 0.00000
train epoch 1592 avg loss: 0.23947 (A-MSE: 0.21207) avg lploss: 0.00000
train epoch 1593 avg loss: 0.21728 (A-MSE: 0.19312) avg lploss: 0.00000
train epoch 1594 avg loss: 0.21858 (A-MSE: 0.19319) avg lploss: 0.00000
train epoch 1595 avg loss: 0.20657 (A-MSE: 0.18354) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.46305 (A-MSE: 0.39476) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.45028 (A-MSE: 0.39977) avg lploss: 0.00000
*** Best Val Loss: 0.38781 	 Best Test Loss: 0.40932 	 Best epoch 1580
EarlyStopping counter: 3 out of 50
train epoch 1596 avg loss: 0.19415 (A-MSE: 0.17078) avg lploss: 0.00000
train epoch 1597 avg loss: 0.20377 (A-MSE: 0.17927) avg lploss: 0.00000
train epoch 1598 avg loss: 0.21517 (A-MSE: 0.19065) avg lploss: 0.00000
train epoch 1599 avg loss: 0.21064 (A-MSE: 0.18535) avg lploss: 0.00000
train epoch 1600 avg loss: 0.25379 (A-MSE: 0.22451) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.41658 (A-MSE: 0.36190) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.44019 (A-MSE: 0.39420) avg lploss: 0.00000
*** Best Val Loss: 0.38781 	 Best Test Loss: 0.40932 	 Best epoch 1580
EarlyStopping counter: 4 out of 50
train epoch 1601 avg loss: 0.24063 (A-MSE: 0.21104) avg lploss: 0.00000
train epoch 1602 avg loss: 0.19415 (A-MSE: 0.17102) avg lploss: 0.00000
train epoch 1603 avg loss: 0.19909 (A-MSE: 0.17547) avg lploss: 0.00000
train epoch 1604 avg loss: 0.19335 (A-MSE: 0.17039) avg lploss: 0.00000
train epoch 1605 avg loss: 0.18799 (A-MSE: 0.16507) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.46131 (A-MSE: 0.39413) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.42464 (A-MSE: 0.37690) avg lploss: 0.00000
*** Best Val Loss: 0.38781 	 Best Test Loss: 0.40932 	 Best epoch 1580
EarlyStopping counter: 5 out of 50
train epoch 1606 avg loss: 0.19527 (A-MSE: 0.17263) avg lploss: 0.00000
train epoch 1607 avg loss: 0.21118 (A-MSE: 0.18826) avg lploss: 0.00000
train epoch 1608 avg loss: 0.22137 (A-MSE: 0.19751) avg lploss: 0.00000
train epoch 1609 avg loss: 0.22696 (A-MSE: 0.20177) avg lploss: 0.00000
train epoch 1610 avg loss: 0.21923 (A-MSE: 0.19137) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.38430 (A-MSE: 0.33207) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.42434 (A-MSE: 0.38119) avg lploss: 0.00000
*** Best Val Loss: 0.38430 	 Best Test Loss: 0.42434 	 Best epoch 1610
Validation loss decreased (0.387813 --> 0.384299).  Saving model ...
train epoch 1611 avg loss: 0.21900 (A-MSE: 0.19424) avg lploss: 0.00000
train epoch 1612 avg loss: 0.21860 (A-MSE: 0.19438) avg lploss: 0.00000
train epoch 1613 avg loss: 0.23841 (A-MSE: 0.21052) avg lploss: 0.00000
train epoch 1614 avg loss: 0.20003 (A-MSE: 0.17783) avg lploss: 0.00000
train epoch 1615 avg loss: 0.24600 (A-MSE: 0.21804) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.39312 (A-MSE: 0.33555) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.40943 (A-MSE: 0.36143) avg lploss: 0.00000
*** Best Val Loss: 0.38430 	 Best Test Loss: 0.42434 	 Best epoch 1610
EarlyStopping counter: 1 out of 50
train epoch 1616 avg loss: 0.21985 (A-MSE: 0.19482) avg lploss: 0.00000
train epoch 1617 avg loss: 0.24095 (A-MSE: 0.21314) avg lploss: 0.00000
train epoch 1618 avg loss: 0.20319 (A-MSE: 0.18021) avg lploss: 0.00000
train epoch 1619 avg loss: 0.18029 (A-MSE: 0.16007) avg lploss: 0.00000
train epoch 1620 avg loss: 0.18954 (A-MSE: 0.16701) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.43834 (A-MSE: 0.37146) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.41118 (A-MSE: 0.36483) avg lploss: 0.00000
*** Best Val Loss: 0.38430 	 Best Test Loss: 0.42434 	 Best epoch 1610
EarlyStopping counter: 2 out of 50
train epoch 1621 avg loss: 0.23114 (A-MSE: 0.20368) avg lploss: 0.00000
train epoch 1622 avg loss: 0.24429 (A-MSE: 0.21614) avg lploss: 0.00000
train epoch 1623 avg loss: 0.20999 (A-MSE: 0.18591) avg lploss: 0.00000
train epoch 1624 avg loss: 0.19634 (A-MSE: 0.17399) avg lploss: 0.00000
train epoch 1625 avg loss: 0.20390 (A-MSE: 0.18034) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.38626 (A-MSE: 0.32798) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.40789 (A-MSE: 0.35952) avg lploss: 0.00000
*** Best Val Loss: 0.38430 	 Best Test Loss: 0.42434 	 Best epoch 1610
EarlyStopping counter: 3 out of 50
train epoch 1626 avg loss: 0.21400 (A-MSE: 0.18867) avg lploss: 0.00000
train epoch 1627 avg loss: 0.20080 (A-MSE: 0.17811) avg lploss: 0.00000
train epoch 1628 avg loss: 0.19349 (A-MSE: 0.17164) avg lploss: 0.00000
train epoch 1629 avg loss: 0.20599 (A-MSE: 0.18160) avg lploss: 0.00000
train epoch 1630 avg loss: 0.19650 (A-MSE: 0.17305) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.42462 (A-MSE: 0.35750) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.41365 (A-MSE: 0.36217) avg lploss: 0.00000
*** Best Val Loss: 0.38430 	 Best Test Loss: 0.42434 	 Best epoch 1610
EarlyStopping counter: 4 out of 50
train epoch 1631 avg loss: 0.18720 (A-MSE: 0.16616) avg lploss: 0.00000
train epoch 1632 avg loss: 0.20498 (A-MSE: 0.17974) avg lploss: 0.00000
train epoch 1633 avg loss: 0.19268 (A-MSE: 0.17124) avg lploss: 0.00000
train epoch 1634 avg loss: 0.18797 (A-MSE: 0.16585) avg lploss: 0.00000
train epoch 1635 avg loss: 0.20411 (A-MSE: 0.18110) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.41526 (A-MSE: 0.34967) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.41086 (A-MSE: 0.36049) avg lploss: 0.00000
*** Best Val Loss: 0.38430 	 Best Test Loss: 0.42434 	 Best epoch 1610
EarlyStopping counter: 5 out of 50
train epoch 1636 avg loss: 0.19462 (A-MSE: 0.17279) avg lploss: 0.00000
train epoch 1637 avg loss: 0.19668 (A-MSE: 0.17375) avg lploss: 0.00000
train epoch 1638 avg loss: 0.18893 (A-MSE: 0.16740) avg lploss: 0.00000
train epoch 1639 avg loss: 0.17844 (A-MSE: 0.15784) avg lploss: 0.00000
train epoch 1640 avg loss: 0.18555 (A-MSE: 0.16518) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.37963 (A-MSE: 0.32643) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.39094 (A-MSE: 0.34470) avg lploss: 0.00000
*** Best Val Loss: 0.37963 	 Best Test Loss: 0.39094 	 Best epoch 1640
Validation loss decreased (0.384299 --> 0.379629).  Saving model ...
train epoch 1641 avg loss: 0.18973 (A-MSE: 0.16768) avg lploss: 0.00000
train epoch 1642 avg loss: 0.17959 (A-MSE: 0.16024) avg lploss: 0.00000
train epoch 1643 avg loss: 0.23172 (A-MSE: 0.20558) avg lploss: 0.00000
train epoch 1644 avg loss: 0.21207 (A-MSE: 0.18832) avg lploss: 0.00000
train epoch 1645 avg loss: 0.19268 (A-MSE: 0.17036) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.37235 (A-MSE: 0.31673) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.38632 (A-MSE: 0.34306) avg lploss: 0.00000
*** Best Val Loss: 0.37235 	 Best Test Loss: 0.38632 	 Best epoch 1645
Validation loss decreased (0.379629 --> 0.372346).  Saving model ...
train epoch 1646 avg loss: 0.17456 (A-MSE: 0.15390) avg lploss: 0.00000
train epoch 1647 avg loss: 0.22359 (A-MSE: 0.19810) avg lploss: 0.00000
train epoch 1648 avg loss: 0.22808 (A-MSE: 0.20429) avg lploss: 0.00000
train epoch 1649 avg loss: 0.19958 (A-MSE: 0.17897) avg lploss: 0.00000
train epoch 1650 avg loss: 0.19030 (A-MSE: 0.16786) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.38621 (A-MSE: 0.33238) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.41599 (A-MSE: 0.36907) avg lploss: 0.00000
*** Best Val Loss: 0.37235 	 Best Test Loss: 0.38632 	 Best epoch 1645
EarlyStopping counter: 1 out of 50
train epoch 1651 avg loss: 0.20488 (A-MSE: 0.18224) avg lploss: 0.00000
train epoch 1652 avg loss: 0.19736 (A-MSE: 0.17374) avg lploss: 0.00000
train epoch 1653 avg loss: 0.24113 (A-MSE: 0.21378) avg lploss: 0.00000
train epoch 1654 avg loss: 0.20286 (A-MSE: 0.17965) avg lploss: 0.00000
train epoch 1655 avg loss: 0.16849 (A-MSE: 0.14964) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.36091 (A-MSE: 0.30788) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.38333 (A-MSE: 0.33998) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
Validation loss decreased (0.372346 --> 0.360907).  Saving model ...
train epoch 1656 avg loss: 0.17130 (A-MSE: 0.15192) avg lploss: 0.00000
train epoch 1657 avg loss: 0.17785 (A-MSE: 0.15869) avg lploss: 0.00000
train epoch 1658 avg loss: 0.17221 (A-MSE: 0.15251) avg lploss: 0.00000
train epoch 1659 avg loss: 0.22917 (A-MSE: 0.20639) avg lploss: 0.00000
train epoch 1660 avg loss: 0.20660 (A-MSE: 0.18303) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.40924 (A-MSE: 0.34839) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.41329 (A-MSE: 0.36680) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 1 out of 50
train epoch 1661 avg loss: 0.17918 (A-MSE: 0.15817) avg lploss: 0.00000
train epoch 1662 avg loss: 0.18325 (A-MSE: 0.16383) avg lploss: 0.00000
train epoch 1663 avg loss: 0.16926 (A-MSE: 0.15027) avg lploss: 0.00000
train epoch 1664 avg loss: 0.19438 (A-MSE: 0.17293) avg lploss: 0.00000
train epoch 1665 avg loss: 0.18179 (A-MSE: 0.15982) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.42434 (A-MSE: 0.35861) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.41278 (A-MSE: 0.36728) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 2 out of 50
train epoch 1666 avg loss: 0.16524 (A-MSE: 0.14686) avg lploss: 0.00000
train epoch 1667 avg loss: 0.20076 (A-MSE: 0.17901) avg lploss: 0.00000
train epoch 1668 avg loss: 0.21910 (A-MSE: 0.19373) avg lploss: 0.00000
train epoch 1669 avg loss: 0.18587 (A-MSE: 0.16621) avg lploss: 0.00000
train epoch 1670 avg loss: 0.16915 (A-MSE: 0.14980) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.40168 (A-MSE: 0.34888) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.39974 (A-MSE: 0.35426) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 3 out of 50
train epoch 1671 avg loss: 0.20626 (A-MSE: 0.18261) avg lploss: 0.00000
train epoch 1672 avg loss: 0.21507 (A-MSE: 0.19158) avg lploss: 0.00000
train epoch 1673 avg loss: 0.20368 (A-MSE: 0.18174) avg lploss: 0.00000
train epoch 1674 avg loss: 0.16507 (A-MSE: 0.14587) avg lploss: 0.00000
train epoch 1675 avg loss: 0.16913 (A-MSE: 0.15062) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.40005 (A-MSE: 0.34262) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.42801 (A-MSE: 0.37649) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 4 out of 50
train epoch 1676 avg loss: 0.18193 (A-MSE: 0.16106) avg lploss: 0.00000
train epoch 1677 avg loss: 0.20788 (A-MSE: 0.18519) avg lploss: 0.00000
train epoch 1678 avg loss: 0.17719 (A-MSE: 0.15592) avg lploss: 0.00000
train epoch 1679 avg loss: 0.16929 (A-MSE: 0.15050) avg lploss: 0.00000
train epoch 1680 avg loss: 0.14992 (A-MSE: 0.13254) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.36429 (A-MSE: 0.31314) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.36919 (A-MSE: 0.32810) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 5 out of 50
train epoch 1681 avg loss: 0.15680 (A-MSE: 0.13944) avg lploss: 0.00000
train epoch 1682 avg loss: 0.17002 (A-MSE: 0.15091) avg lploss: 0.00000
train epoch 1683 avg loss: 0.16598 (A-MSE: 0.14883) avg lploss: 0.00000
train epoch 1684 avg loss: 0.16875 (A-MSE: 0.15107) avg lploss: 0.00000
train epoch 1685 avg loss: 0.16772 (A-MSE: 0.15127) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.38238 (A-MSE: 0.32794) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.40164 (A-MSE: 0.36038) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 6 out of 50
train epoch 1686 avg loss: 0.16956 (A-MSE: 0.15219) avg lploss: 0.00000
train epoch 1687 avg loss: 0.17278 (A-MSE: 0.15269) avg lploss: 0.00000
train epoch 1688 avg loss: 0.17855 (A-MSE: 0.15937) avg lploss: 0.00000
train epoch 1689 avg loss: 0.17646 (A-MSE: 0.15671) avg lploss: 0.00000
train epoch 1690 avg loss: 0.16121 (A-MSE: 0.14319) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.43116 (A-MSE: 0.37368) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.43281 (A-MSE: 0.38682) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 7 out of 50
train epoch 1691 avg loss: 0.18918 (A-MSE: 0.16773) avg lploss: 0.00000
train epoch 1692 avg loss: 0.17728 (A-MSE: 0.15747) avg lploss: 0.00000
train epoch 1693 avg loss: 0.17651 (A-MSE: 0.15896) avg lploss: 0.00000
train epoch 1694 avg loss: 0.17548 (A-MSE: 0.15725) avg lploss: 0.00000
train epoch 1695 avg loss: 0.15538 (A-MSE: 0.13706) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.38824 (A-MSE: 0.33028) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.39377 (A-MSE: 0.34755) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 8 out of 50
train epoch 1696 avg loss: 0.19361 (A-MSE: 0.17177) avg lploss: 0.00000
train epoch 1697 avg loss: 0.20117 (A-MSE: 0.17859) avg lploss: 0.00000
train epoch 1698 avg loss: 0.22379 (A-MSE: 0.19646) avg lploss: 0.00000
train epoch 1699 avg loss: 0.17149 (A-MSE: 0.15163) avg lploss: 0.00000
train epoch 1700 avg loss: 0.17152 (A-MSE: 0.15298) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.42122 (A-MSE: 0.36267) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.42976 (A-MSE: 0.37672) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 9 out of 50
train epoch 1701 avg loss: 0.18631 (A-MSE: 0.16652) avg lploss: 0.00000
train epoch 1702 avg loss: 0.15446 (A-MSE: 0.13795) avg lploss: 0.00000
train epoch 1703 avg loss: 0.16727 (A-MSE: 0.14797) avg lploss: 0.00000
train epoch 1704 avg loss: 0.19270 (A-MSE: 0.17089) avg lploss: 0.00000
train epoch 1705 avg loss: 0.17023 (A-MSE: 0.15328) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.45388 (A-MSE: 0.38903) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.42883 (A-MSE: 0.37745) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 10 out of 50
train epoch 1706 avg loss: 0.15097 (A-MSE: 0.13475) avg lploss: 0.00000
train epoch 1707 avg loss: 0.16129 (A-MSE: 0.14533) avg lploss: 0.00000
train epoch 1708 avg loss: 0.17198 (A-MSE: 0.15199) avg lploss: 0.00000
train epoch 1709 avg loss: 0.16507 (A-MSE: 0.14724) avg lploss: 0.00000
train epoch 1710 avg loss: 0.17068 (A-MSE: 0.15202) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.52886 (A-MSE: 0.45696) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.52433 (A-MSE: 0.46353) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 11 out of 50
train epoch 1711 avg loss: 0.17283 (A-MSE: 0.15230) avg lploss: 0.00000
train epoch 1712 avg loss: 0.15663 (A-MSE: 0.13974) avg lploss: 0.00000
train epoch 1713 avg loss: 0.19297 (A-MSE: 0.17168) avg lploss: 0.00000
train epoch 1714 avg loss: 0.15534 (A-MSE: 0.13984) avg lploss: 0.00000
train epoch 1715 avg loss: 0.17980 (A-MSE: 0.16063) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.36221 (A-MSE: 0.31034) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.38292 (A-MSE: 0.33649) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 12 out of 50
train epoch 1716 avg loss: 0.14723 (A-MSE: 0.13191) avg lploss: 0.00000
train epoch 1717 avg loss: 0.15651 (A-MSE: 0.13924) avg lploss: 0.00000
train epoch 1718 avg loss: 0.17061 (A-MSE: 0.15269) avg lploss: 0.00000
train epoch 1719 avg loss: 0.16505 (A-MSE: 0.14734) avg lploss: 0.00000
train epoch 1720 avg loss: 0.17531 (A-MSE: 0.15700) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.39776 (A-MSE: 0.34478) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.41506 (A-MSE: 0.36604) avg lploss: 0.00000
*** Best Val Loss: 0.36091 	 Best Test Loss: 0.38333 	 Best epoch 1655
EarlyStopping counter: 13 out of 50
train epoch 1721 avg loss: 0.16138 (A-MSE: 0.14300) avg lploss: 0.00000
train epoch 1722 avg loss: 0.14226 (A-MSE: 0.12742) avg lploss: 0.00000
train epoch 1723 avg loss: 0.12624 (A-MSE: 0.11259) avg lploss: 0.00000
train epoch 1724 avg loss: 0.15296 (A-MSE: 0.13644) avg lploss: 0.00000
train epoch 1725 avg loss: 0.16312 (A-MSE: 0.14644) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.35541 (A-MSE: 0.30489) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.36401 (A-MSE: 0.32102) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
Validation loss decreased (0.360907 --> 0.355408).  Saving model ...
train epoch 1726 avg loss: 0.15481 (A-MSE: 0.13754) avg lploss: 0.00000
train epoch 1727 avg loss: 0.16732 (A-MSE: 0.14851) avg lploss: 0.00000
train epoch 1728 avg loss: 0.16808 (A-MSE: 0.15129) avg lploss: 0.00000
train epoch 1729 avg loss: 0.17443 (A-MSE: 0.15563) avg lploss: 0.00000
train epoch 1730 avg loss: 0.16353 (A-MSE: 0.14814) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.36598 (A-MSE: 0.31332) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.40035 (A-MSE: 0.35316) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 1 out of 50
train epoch 1731 avg loss: 0.20242 (A-MSE: 0.18093) avg lploss: 0.00000
train epoch 1732 avg loss: 0.18723 (A-MSE: 0.16737) avg lploss: 0.00000
train epoch 1733 avg loss: 0.16758 (A-MSE: 0.14963) avg lploss: 0.00000
train epoch 1734 avg loss: 0.15321 (A-MSE: 0.13764) avg lploss: 0.00000
train epoch 1735 avg loss: 0.15158 (A-MSE: 0.13599) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.38212 (A-MSE: 0.32985) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.37282 (A-MSE: 0.32821) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 2 out of 50
train epoch 1736 avg loss: 0.18778 (A-MSE: 0.16611) avg lploss: 0.00000
train epoch 1737 avg loss: 0.19568 (A-MSE: 0.17517) avg lploss: 0.00000
train epoch 1738 avg loss: 0.18328 (A-MSE: 0.16393) avg lploss: 0.00000
train epoch 1739 avg loss: 0.15940 (A-MSE: 0.14364) avg lploss: 0.00000
train epoch 1740 avg loss: 0.13386 (A-MSE: 0.12036) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.36632 (A-MSE: 0.31318) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.37226 (A-MSE: 0.32912) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 3 out of 50
train epoch 1741 avg loss: 0.13948 (A-MSE: 0.12360) avg lploss: 0.00000
train epoch 1742 avg loss: 0.15392 (A-MSE: 0.13794) avg lploss: 0.00000
train epoch 1743 avg loss: 0.14376 (A-MSE: 0.13099) avg lploss: 0.00000
train epoch 1744 avg loss: 0.15060 (A-MSE: 0.13317) avg lploss: 0.00000
train epoch 1745 avg loss: 0.16521 (A-MSE: 0.14688) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.43256 (A-MSE: 0.37291) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.45772 (A-MSE: 0.40299) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 4 out of 50
train epoch 1746 avg loss: 0.15322 (A-MSE: 0.13795) avg lploss: 0.00000
train epoch 1747 avg loss: 0.13636 (A-MSE: 0.12157) avg lploss: 0.00000
train epoch 1748 avg loss: 0.13554 (A-MSE: 0.12064) avg lploss: 0.00000
train epoch 1749 avg loss: 0.14517 (A-MSE: 0.12873) avg lploss: 0.00000
train epoch 1750 avg loss: 0.14124 (A-MSE: 0.12607) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.38933 (A-MSE: 0.33370) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.38725 (A-MSE: 0.34216) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 5 out of 50
train epoch 1751 avg loss: 0.14470 (A-MSE: 0.12991) avg lploss: 0.00000
train epoch 1752 avg loss: 0.14055 (A-MSE: 0.12614) avg lploss: 0.00000
train epoch 1753 avg loss: 0.15255 (A-MSE: 0.13684) avg lploss: 0.00000
train epoch 1754 avg loss: 0.15201 (A-MSE: 0.13578) avg lploss: 0.00000
train epoch 1755 avg loss: 0.13934 (A-MSE: 0.12452) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.36852 (A-MSE: 0.31859) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.38631 (A-MSE: 0.34135) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 6 out of 50
train epoch 1756 avg loss: 0.13934 (A-MSE: 0.12398) avg lploss: 0.00000
train epoch 1757 avg loss: 0.13448 (A-MSE: 0.12075) avg lploss: 0.00000
train epoch 1758 avg loss: 0.13662 (A-MSE: 0.12243) avg lploss: 0.00000
train epoch 1759 avg loss: 0.13760 (A-MSE: 0.12188) avg lploss: 0.00000
train epoch 1760 avg loss: 0.13812 (A-MSE: 0.12408) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.36679 (A-MSE: 0.31442) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.38952 (A-MSE: 0.34479) avg lploss: 0.00000
*** Best Val Loss: 0.35541 	 Best Test Loss: 0.36401 	 Best epoch 1725
EarlyStopping counter: 7 out of 50
train epoch 1761 avg loss: 0.12861 (A-MSE: 0.11439) avg lploss: 0.00000
train epoch 1762 avg loss: 0.15188 (A-MSE: 0.13428) avg lploss: 0.00000
train epoch 1763 avg loss: 0.14840 (A-MSE: 0.13324) avg lploss: 0.00000
train epoch 1764 avg loss: 0.15329 (A-MSE: 0.13772) avg lploss: 0.00000
train epoch 1765 avg loss: 0.13537 (A-MSE: 0.12107) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.34975 (A-MSE: 0.30069) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.34450 (A-MSE: 0.30367) avg lploss: 0.00000
*** Best Val Loss: 0.34975 	 Best Test Loss: 0.34450 	 Best epoch 1765
Validation loss decreased (0.355408 --> 0.349751).  Saving model ...
train epoch 1766 avg loss: 0.14881 (A-MSE: 0.13359) avg lploss: 0.00000
train epoch 1767 avg loss: 0.15140 (A-MSE: 0.13456) avg lploss: 0.00000
train epoch 1768 avg loss: 0.13066 (A-MSE: 0.11714) avg lploss: 0.00000
train epoch 1769 avg loss: 0.13501 (A-MSE: 0.12082) avg lploss: 0.00000
train epoch 1770 avg loss: 0.13177 (A-MSE: 0.11845) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.35317 (A-MSE: 0.30550) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.37348 (A-MSE: 0.33120) avg lploss: 0.00000
*** Best Val Loss: 0.34975 	 Best Test Loss: 0.34450 	 Best epoch 1765
EarlyStopping counter: 1 out of 50
train epoch 1771 avg loss: 0.13676 (A-MSE: 0.12122) avg lploss: 0.00000
train epoch 1772 avg loss: 0.15830 (A-MSE: 0.14245) avg lploss: 0.00000
train epoch 1773 avg loss: 0.14444 (A-MSE: 0.12915) avg lploss: 0.00000
train epoch 1774 avg loss: 0.13853 (A-MSE: 0.12406) avg lploss: 0.00000
train epoch 1775 avg loss: 0.13640 (A-MSE: 0.12068) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.36082 (A-MSE: 0.31288) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.38362 (A-MSE: 0.33924) avg lploss: 0.00000
*** Best Val Loss: 0.34975 	 Best Test Loss: 0.34450 	 Best epoch 1765
EarlyStopping counter: 2 out of 50
train epoch 1776 avg loss: 0.14529 (A-MSE: 0.13037) avg lploss: 0.00000
train epoch 1777 avg loss: 0.13779 (A-MSE: 0.12315) avg lploss: 0.00000
train epoch 1778 avg loss: 0.12221 (A-MSE: 0.11032) avg lploss: 0.00000
train epoch 1779 avg loss: 0.11547 (A-MSE: 0.10341) avg lploss: 0.00000
train epoch 1780 avg loss: 0.11404 (A-MSE: 0.10220) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.33468 (A-MSE: 0.29150) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.37259 (A-MSE: 0.33005) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
Validation loss decreased (0.349751 --> 0.334678).  Saving model ...
train epoch 1781 avg loss: 0.11779 (A-MSE: 0.10613) avg lploss: 0.00000
train epoch 1782 avg loss: 0.13142 (A-MSE: 0.11866) avg lploss: 0.00000
train epoch 1783 avg loss: 0.13720 (A-MSE: 0.12302) avg lploss: 0.00000
train epoch 1784 avg loss: 0.14526 (A-MSE: 0.12931) avg lploss: 0.00000
train epoch 1785 avg loss: 0.14952 (A-MSE: 0.13335) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.36225 (A-MSE: 0.31232) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.35319 (A-MSE: 0.31119) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 1 out of 50
train epoch 1786 avg loss: 0.12716 (A-MSE: 0.11428) avg lploss: 0.00000
train epoch 1787 avg loss: 0.12823 (A-MSE: 0.11445) avg lploss: 0.00000
train epoch 1788 avg loss: 0.12790 (A-MSE: 0.11439) avg lploss: 0.00000
train epoch 1789 avg loss: 0.12380 (A-MSE: 0.11242) avg lploss: 0.00000
train epoch 1790 avg loss: 0.11948 (A-MSE: 0.10764) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.35189 (A-MSE: 0.30329) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.36404 (A-MSE: 0.32089) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 2 out of 50
train epoch 1791 avg loss: 0.12878 (A-MSE: 0.11556) avg lploss: 0.00000
train epoch 1792 avg loss: 0.14243 (A-MSE: 0.12794) avg lploss: 0.00000
train epoch 1793 avg loss: 0.14767 (A-MSE: 0.13165) avg lploss: 0.00000
train epoch 1794 avg loss: 0.13938 (A-MSE: 0.12613) avg lploss: 0.00000
train epoch 1795 avg loss: 0.13731 (A-MSE: 0.12232) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.35729 (A-MSE: 0.31218) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.36353 (A-MSE: 0.32341) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 3 out of 50
train epoch 1796 avg loss: 0.12683 (A-MSE: 0.11332) avg lploss: 0.00000
train epoch 1797 avg loss: 0.14145 (A-MSE: 0.12705) avg lploss: 0.00000
train epoch 1798 avg loss: 0.15157 (A-MSE: 0.13536) avg lploss: 0.00000
train epoch 1799 avg loss: 0.16083 (A-MSE: 0.14475) avg lploss: 0.00000
train epoch 1800 avg loss: 0.13583 (A-MSE: 0.12233) avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.37761 (A-MSE: 0.32138) avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.36806 (A-MSE: 0.32199) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 4 out of 50
train epoch 1801 avg loss: 0.12873 (A-MSE: 0.11542) avg lploss: 0.00000
train epoch 1802 avg loss: 0.13516 (A-MSE: 0.12136) avg lploss: 0.00000
train epoch 1803 avg loss: 0.13166 (A-MSE: 0.11823) avg lploss: 0.00000
train epoch 1804 avg loss: 0.11934 (A-MSE: 0.10723) avg lploss: 0.00000
train epoch 1805 avg loss: 0.11778 (A-MSE: 0.10468) avg lploss: 0.00000
==> val epoch 1805 avg loss: 0.38389 (A-MSE: 0.32575) avg lploss: 0.00000
==> test epoch 1805 avg loss: 0.36583 (A-MSE: 0.32095) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 5 out of 50
train epoch 1806 avg loss: 0.12296 (A-MSE: 0.11048) avg lploss: 0.00000
train epoch 1807 avg loss: 0.13886 (A-MSE: 0.12422) avg lploss: 0.00000
train epoch 1808 avg loss: 0.14740 (A-MSE: 0.13109) avg lploss: 0.00000
train epoch 1809 avg loss: 0.13633 (A-MSE: 0.12147) avg lploss: 0.00000
train epoch 1810 avg loss: 0.12864 (A-MSE: 0.11466) avg lploss: 0.00000
==> val epoch 1810 avg loss: 0.37137 (A-MSE: 0.31860) avg lploss: 0.00000
==> test epoch 1810 avg loss: 0.39599 (A-MSE: 0.34898) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 6 out of 50
train epoch 1811 avg loss: 0.15631 (A-MSE: 0.14034) avg lploss: 0.00000
train epoch 1812 avg loss: 0.14892 (A-MSE: 0.13350) avg lploss: 0.00000
train epoch 1813 avg loss: 0.13628 (A-MSE: 0.12110) avg lploss: 0.00000
train epoch 1814 avg loss: 0.12395 (A-MSE: 0.11060) avg lploss: 0.00000
train epoch 1815 avg loss: 0.15398 (A-MSE: 0.13886) avg lploss: 0.00000
==> val epoch 1815 avg loss: 0.39865 (A-MSE: 0.33877) avg lploss: 0.00000
==> test epoch 1815 avg loss: 0.37917 (A-MSE: 0.33202) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 7 out of 50
train epoch 1816 avg loss: 0.12610 (A-MSE: 0.11322) avg lploss: 0.00000
train epoch 1817 avg loss: 0.12144 (A-MSE: 0.10864) avg lploss: 0.00000
train epoch 1818 avg loss: 0.11911 (A-MSE: 0.10585) avg lploss: 0.00000
train epoch 1819 avg loss: 0.12906 (A-MSE: 0.11494) avg lploss: 0.00000
train epoch 1820 avg loss: 0.12870 (A-MSE: 0.11564) avg lploss: 0.00000
==> val epoch 1820 avg loss: 0.37742 (A-MSE: 0.33279) avg lploss: 0.00000
==> test epoch 1820 avg loss: 0.38862 (A-MSE: 0.34881) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 8 out of 50
train epoch 1821 avg loss: 0.12159 (A-MSE: 0.10826) avg lploss: 0.00000
train epoch 1822 avg loss: 0.13267 (A-MSE: 0.11890) avg lploss: 0.00000
train epoch 1823 avg loss: 0.13954 (A-MSE: 0.12357) avg lploss: 0.00000
train epoch 1824 avg loss: 0.11071 (A-MSE: 0.09952) avg lploss: 0.00000
train epoch 1825 avg loss: 0.11481 (A-MSE: 0.10340) avg lploss: 0.00000
==> val epoch 1825 avg loss: 0.40321 (A-MSE: 0.34642) avg lploss: 0.00000
==> test epoch 1825 avg loss: 0.39871 (A-MSE: 0.35000) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 9 out of 50
train epoch 1826 avg loss: 0.11245 (A-MSE: 0.10038) avg lploss: 0.00000
train epoch 1827 avg loss: 0.14716 (A-MSE: 0.13081) avg lploss: 0.00000
train epoch 1828 avg loss: 0.15837 (A-MSE: 0.14285) avg lploss: 0.00000
train epoch 1829 avg loss: 0.15950 (A-MSE: 0.14269) avg lploss: 0.00000
train epoch 1830 avg loss: 0.15084 (A-MSE: 0.13543) avg lploss: 0.00000
==> val epoch 1830 avg loss: 0.34372 (A-MSE: 0.31078) avg lploss: 0.00000
==> test epoch 1830 avg loss: 0.36627 (A-MSE: 0.33211) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 10 out of 50
train epoch 1831 avg loss: 0.13930 (A-MSE: 0.12453) avg lploss: 0.00000
train epoch 1832 avg loss: 0.14436 (A-MSE: 0.12970) avg lploss: 0.00000
train epoch 1833 avg loss: 0.13426 (A-MSE: 0.11926) avg lploss: 0.00000
train epoch 1834 avg loss: 0.12276 (A-MSE: 0.11048) avg lploss: 0.00000
train epoch 1835 avg loss: 0.13157 (A-MSE: 0.11737) avg lploss: 0.00000
==> val epoch 1835 avg loss: 0.33699 (A-MSE: 0.29564) avg lploss: 0.00000
==> test epoch 1835 avg loss: 0.36394 (A-MSE: 0.32753) avg lploss: 0.00000
*** Best Val Loss: 0.33468 	 Best Test Loss: 0.37259 	 Best epoch 1780
EarlyStopping counter: 11 out of 50
train epoch 1836 avg loss: 0.11909 (A-MSE: 0.10749) avg lploss: 0.00000
train epoch 1837 avg loss: 0.10360 (A-MSE: 0.09326) avg lploss: 0.00000
train epoch 1838 avg loss: 0.10596 (A-MSE: 0.09555) avg lploss: 0.00000
train epoch 1839 avg loss: 0.12050 (A-MSE: 0.10759) avg lploss: 0.00000
train epoch 1840 avg loss: 0.12869 (A-MSE: 0.11598) avg lploss: 0.00000
==> val epoch 1840 avg loss: 0.31758 (A-MSE: 0.27861) avg lploss: 0.00000
==> test epoch 1840 avg loss: 0.36511 (A-MSE: 0.32440) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
Validation loss decreased (0.334678 --> 0.317578).  Saving model ...
train epoch 1841 avg loss: 0.12416 (A-MSE: 0.11189) avg lploss: 0.00000
train epoch 1842 avg loss: 0.12094 (A-MSE: 0.10812) avg lploss: 0.00000
train epoch 1843 avg loss: 0.10453 (A-MSE: 0.09421) avg lploss: 0.00000
train epoch 1844 avg loss: 0.10642 (A-MSE: 0.09554) avg lploss: 0.00000
train epoch 1845 avg loss: 0.11360 (A-MSE: 0.10172) avg lploss: 0.00000
==> val epoch 1845 avg loss: 0.37913 (A-MSE: 0.33284) avg lploss: 0.00000
==> test epoch 1845 avg loss: 0.38012 (A-MSE: 0.34051) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 1 out of 50
train epoch 1846 avg loss: 0.12216 (A-MSE: 0.10924) avg lploss: 0.00000
train epoch 1847 avg loss: 0.10044 (A-MSE: 0.09083) avg lploss: 0.00000
train epoch 1848 avg loss: 0.11077 (A-MSE: 0.09889) avg lploss: 0.00000
train epoch 1849 avg loss: 0.10689 (A-MSE: 0.09601) avg lploss: 0.00000
train epoch 1850 avg loss: 0.11744 (A-MSE: 0.10538) avg lploss: 0.00000
==> val epoch 1850 avg loss: 0.32711 (A-MSE: 0.28509) avg lploss: 0.00000
==> test epoch 1850 avg loss: 0.35377 (A-MSE: 0.31950) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 2 out of 50
train epoch 1851 avg loss: 0.10769 (A-MSE: 0.09652) avg lploss: 0.00000
train epoch 1852 avg loss: 0.12392 (A-MSE: 0.11157) avg lploss: 0.00000
train epoch 1853 avg loss: 0.12933 (A-MSE: 0.11536) avg lploss: 0.00000
train epoch 1854 avg loss: 0.11448 (A-MSE: 0.10218) avg lploss: 0.00000
train epoch 1855 avg loss: 0.10433 (A-MSE: 0.09458) avg lploss: 0.00000
==> val epoch 1855 avg loss: 0.34160 (A-MSE: 0.29665) avg lploss: 0.00000
==> test epoch 1855 avg loss: 0.35512 (A-MSE: 0.31340) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 3 out of 50
train epoch 1856 avg loss: 0.10570 (A-MSE: 0.09442) avg lploss: 0.00000
train epoch 1857 avg loss: 0.11670 (A-MSE: 0.10489) avg lploss: 0.00000
train epoch 1858 avg loss: 0.12543 (A-MSE: 0.11280) avg lploss: 0.00000
train epoch 1859 avg loss: 0.11590 (A-MSE: 0.10367) avg lploss: 0.00000
train epoch 1860 avg loss: 0.11454 (A-MSE: 0.10289) avg lploss: 0.00000
==> val epoch 1860 avg loss: 0.37931 (A-MSE: 0.33594) avg lploss: 0.00000
==> test epoch 1860 avg loss: 0.39888 (A-MSE: 0.36102) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 4 out of 50
train epoch 1861 avg loss: 0.13699 (A-MSE: 0.12233) avg lploss: 0.00000
train epoch 1862 avg loss: 0.11262 (A-MSE: 0.10086) avg lploss: 0.00000
train epoch 1863 avg loss: 0.13348 (A-MSE: 0.11966) avg lploss: 0.00000
train epoch 1864 avg loss: 0.13258 (A-MSE: 0.11848) avg lploss: 0.00000
train epoch 1865 avg loss: 0.10977 (A-MSE: 0.09900) avg lploss: 0.00000
==> val epoch 1865 avg loss: 0.36679 (A-MSE: 0.31751) avg lploss: 0.00000
==> test epoch 1865 avg loss: 0.36797 (A-MSE: 0.32691) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 5 out of 50
train epoch 1866 avg loss: 0.11501 (A-MSE: 0.10301) avg lploss: 0.00000
train epoch 1867 avg loss: 0.10964 (A-MSE: 0.09755) avg lploss: 0.00000
train epoch 1868 avg loss: 0.10566 (A-MSE: 0.09368) avg lploss: 0.00000
train epoch 1869 avg loss: 0.09445 (A-MSE: 0.08506) avg lploss: 0.00000
train epoch 1870 avg loss: 0.09957 (A-MSE: 0.08911) avg lploss: 0.00000
==> val epoch 1870 avg loss: 0.34813 (A-MSE: 0.30155) avg lploss: 0.00000
==> test epoch 1870 avg loss: 0.36613 (A-MSE: 0.32402) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 6 out of 50
train epoch 1871 avg loss: 0.10503 (A-MSE: 0.09315) avg lploss: 0.00000
train epoch 1872 avg loss: 0.09892 (A-MSE: 0.08850) avg lploss: 0.00000
train epoch 1873 avg loss: 0.10148 (A-MSE: 0.09141) avg lploss: 0.00000
train epoch 1874 avg loss: 0.12037 (A-MSE: 0.10844) avg lploss: 0.00000
train epoch 1875 avg loss: 0.13869 (A-MSE: 0.12493) avg lploss: 0.00000
==> val epoch 1875 avg loss: 0.33301 (A-MSE: 0.28646) avg lploss: 0.00000
==> test epoch 1875 avg loss: 0.34699 (A-MSE: 0.30554) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 7 out of 50
train epoch 1876 avg loss: 0.12630 (A-MSE: 0.11267) avg lploss: 0.00000
train epoch 1877 avg loss: 0.10086 (A-MSE: 0.09049) avg lploss: 0.00000
train epoch 1878 avg loss: 0.10539 (A-MSE: 0.09329) avg lploss: 0.00000
train epoch 1879 avg loss: 0.09706 (A-MSE: 0.08673) avg lploss: 0.00000
train epoch 1880 avg loss: 0.09562 (A-MSE: 0.08534) avg lploss: 0.00000
==> val epoch 1880 avg loss: 0.39178 (A-MSE: 0.33205) avg lploss: 0.00000
==> test epoch 1880 avg loss: 0.37756 (A-MSE: 0.33059) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 8 out of 50
train epoch 1881 avg loss: 0.12788 (A-MSE: 0.11514) avg lploss: 0.00000
train epoch 1882 avg loss: 0.11042 (A-MSE: 0.09893) avg lploss: 0.00000
train epoch 1883 avg loss: 0.10377 (A-MSE: 0.09297) avg lploss: 0.00000
train epoch 1884 avg loss: 0.10336 (A-MSE: 0.09191) avg lploss: 0.00000
train epoch 1885 avg loss: 0.11268 (A-MSE: 0.10050) avg lploss: 0.00000
==> val epoch 1885 avg loss: 0.34288 (A-MSE: 0.29319) avg lploss: 0.00000
==> test epoch 1885 avg loss: 0.33852 (A-MSE: 0.30057) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 9 out of 50
train epoch 1886 avg loss: 0.10721 (A-MSE: 0.09575) avg lploss: 0.00000
train epoch 1887 avg loss: 0.12747 (A-MSE: 0.11344) avg lploss: 0.00000
train epoch 1888 avg loss: 0.09457 (A-MSE: 0.08468) avg lploss: 0.00000
train epoch 1889 avg loss: 0.11530 (A-MSE: 0.10327) avg lploss: 0.00000
train epoch 1890 avg loss: 0.13193 (A-MSE: 0.11786) avg lploss: 0.00000
==> val epoch 1890 avg loss: 0.38922 (A-MSE: 0.33899) avg lploss: 0.00000
==> test epoch 1890 avg loss: 0.41452 (A-MSE: 0.37129) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 10 out of 50
train epoch 1891 avg loss: 0.14273 (A-MSE: 0.12771) avg lploss: 0.00000
train epoch 1892 avg loss: 0.13925 (A-MSE: 0.12405) avg lploss: 0.00000
train epoch 1893 avg loss: 0.11408 (A-MSE: 0.10169) avg lploss: 0.00000
train epoch 1894 avg loss: 0.10616 (A-MSE: 0.09459) avg lploss: 0.00000
train epoch 1895 avg loss: 0.10970 (A-MSE: 0.09841) avg lploss: 0.00000
==> val epoch 1895 avg loss: 0.34218 (A-MSE: 0.29622) avg lploss: 0.00000
==> test epoch 1895 avg loss: 0.34678 (A-MSE: 0.31008) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 11 out of 50
train epoch 1896 avg loss: 0.10720 (A-MSE: 0.09506) avg lploss: 0.00000
train epoch 1897 avg loss: 0.11744 (A-MSE: 0.10548) avg lploss: 0.00000
train epoch 1898 avg loss: 0.12061 (A-MSE: 0.10764) avg lploss: 0.00000
train epoch 1899 avg loss: 0.11443 (A-MSE: 0.10190) avg lploss: 0.00000
train epoch 1900 avg loss: 0.12629 (A-MSE: 0.11326) avg lploss: 0.00000
==> val epoch 1900 avg loss: 0.34212 (A-MSE: 0.29712) avg lploss: 0.00000
==> test epoch 1900 avg loss: 0.35063 (A-MSE: 0.31277) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 12 out of 50
train epoch 1901 avg loss: 0.11150 (A-MSE: 0.10015) avg lploss: 0.00000
train epoch 1902 avg loss: 0.12745 (A-MSE: 0.11486) avg lploss: 0.00000
train epoch 1903 avg loss: 0.12311 (A-MSE: 0.10922) avg lploss: 0.00000
train epoch 1904 avg loss: 0.09548 (A-MSE: 0.08606) avg lploss: 0.00000
train epoch 1905 avg loss: 0.10069 (A-MSE: 0.09146) avg lploss: 0.00000
==> val epoch 1905 avg loss: 0.39123 (A-MSE: 0.33615) avg lploss: 0.00000
==> test epoch 1905 avg loss: 0.38747 (A-MSE: 0.34427) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 13 out of 50
train epoch 1906 avg loss: 0.10383 (A-MSE: 0.09247) avg lploss: 0.00000
train epoch 1907 avg loss: 0.12601 (A-MSE: 0.11211) avg lploss: 0.00000
train epoch 1908 avg loss: 0.10773 (A-MSE: 0.09561) avg lploss: 0.00000
train epoch 1909 avg loss: 0.09474 (A-MSE: 0.08571) avg lploss: 0.00000
train epoch 1910 avg loss: 0.09087 (A-MSE: 0.08082) avg lploss: 0.00000
==> val epoch 1910 avg loss: 0.32151 (A-MSE: 0.28246) avg lploss: 0.00000
==> test epoch 1910 avg loss: 0.34249 (A-MSE: 0.30715) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 14 out of 50
train epoch 1911 avg loss: 0.11466 (A-MSE: 0.10317) avg lploss: 0.00000
train epoch 1912 avg loss: 0.11269 (A-MSE: 0.10087) avg lploss: 0.00000
train epoch 1913 avg loss: 0.10043 (A-MSE: 0.08943) avg lploss: 0.00000
train epoch 1914 avg loss: 0.10069 (A-MSE: 0.09062) avg lploss: 0.00000
train epoch 1915 avg loss: 0.11289 (A-MSE: 0.10172) avg lploss: 0.00000
==> val epoch 1915 avg loss: 0.36131 (A-MSE: 0.31549) avg lploss: 0.00000
==> test epoch 1915 avg loss: 0.39749 (A-MSE: 0.35670) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 15 out of 50
train epoch 1916 avg loss: 0.11907 (A-MSE: 0.10619) avg lploss: 0.00000
train epoch 1917 avg loss: 0.10148 (A-MSE: 0.09147) avg lploss: 0.00000
train epoch 1918 avg loss: 0.10042 (A-MSE: 0.08937) avg lploss: 0.00000
train epoch 1919 avg loss: 0.09696 (A-MSE: 0.08729) avg lploss: 0.00000
train epoch 1920 avg loss: 0.08826 (A-MSE: 0.07919) avg lploss: 0.00000
==> val epoch 1920 avg loss: 0.34381 (A-MSE: 0.29356) avg lploss: 0.00000
==> test epoch 1920 avg loss: 0.33659 (A-MSE: 0.29725) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 16 out of 50
train epoch 1921 avg loss: 0.09496 (A-MSE: 0.08424) avg lploss: 0.00000
train epoch 1922 avg loss: 0.10599 (A-MSE: 0.09413) avg lploss: 0.00000
train epoch 1923 avg loss: 0.13432 (A-MSE: 0.12200) avg lploss: 0.00000
train epoch 1924 avg loss: 0.14628 (A-MSE: 0.13142) avg lploss: 0.00000
train epoch 1925 avg loss: 0.13126 (A-MSE: 0.11749) avg lploss: 0.00000
==> val epoch 1925 avg loss: 0.35478 (A-MSE: 0.30601) avg lploss: 0.00000
==> test epoch 1925 avg loss: 0.39357 (A-MSE: 0.35049) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 17 out of 50
train epoch 1926 avg loss: 0.11660 (A-MSE: 0.10453) avg lploss: 0.00000
train epoch 1927 avg loss: 0.11730 (A-MSE: 0.10470) avg lploss: 0.00000
train epoch 1928 avg loss: 0.10166 (A-MSE: 0.09114) avg lploss: 0.00000
train epoch 1929 avg loss: 0.11138 (A-MSE: 0.09852) avg lploss: 0.00000
train epoch 1930 avg loss: 0.11959 (A-MSE: 0.10707) avg lploss: 0.00000
==> val epoch 1930 avg loss: 0.33443 (A-MSE: 0.29067) avg lploss: 0.00000
==> test epoch 1930 avg loss: 0.36198 (A-MSE: 0.32224) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 18 out of 50
train epoch 1931 avg loss: 0.10545 (A-MSE: 0.09371) avg lploss: 0.00000
train epoch 1932 avg loss: 0.09446 (A-MSE: 0.08436) avg lploss: 0.00000
train epoch 1933 avg loss: 0.08503 (A-MSE: 0.07639) avg lploss: 0.00000
train epoch 1934 avg loss: 0.11469 (A-MSE: 0.10225) avg lploss: 0.00000
train epoch 1935 avg loss: 0.11100 (A-MSE: 0.10020) avg lploss: 0.00000
==> val epoch 1935 avg loss: 0.38212 (A-MSE: 0.32379) avg lploss: 0.00000
==> test epoch 1935 avg loss: 0.37339 (A-MSE: 0.32917) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 19 out of 50
train epoch 1936 avg loss: 0.10487 (A-MSE: 0.09469) avg lploss: 0.00000
train epoch 1937 avg loss: 0.12089 (A-MSE: 0.10840) avg lploss: 0.00000
train epoch 1938 avg loss: 0.10312 (A-MSE: 0.09176) avg lploss: 0.00000
train epoch 1939 avg loss: 0.09475 (A-MSE: 0.08428) avg lploss: 0.00000
train epoch 1940 avg loss: 0.09082 (A-MSE: 0.08238) avg lploss: 0.00000
==> val epoch 1940 avg loss: 0.32762 (A-MSE: 0.28483) avg lploss: 0.00000
==> test epoch 1940 avg loss: 0.34879 (A-MSE: 0.31353) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 20 out of 50
train epoch 1941 avg loss: 0.09993 (A-MSE: 0.08922) avg lploss: 0.00000
train epoch 1942 avg loss: 0.11379 (A-MSE: 0.10247) avg lploss: 0.00000
train epoch 1943 avg loss: 0.10123 (A-MSE: 0.09073) avg lploss: 0.00000
train epoch 1944 avg loss: 0.11304 (A-MSE: 0.10099) avg lploss: 0.00000
train epoch 1945 avg loss: 0.10695 (A-MSE: 0.09517) avg lploss: 0.00000
==> val epoch 1945 avg loss: 0.37737 (A-MSE: 0.32780) avg lploss: 0.00000
==> test epoch 1945 avg loss: 0.37852 (A-MSE: 0.33637) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 21 out of 50
train epoch 1946 avg loss: 0.12511 (A-MSE: 0.11279) avg lploss: 0.00000
train epoch 1947 avg loss: 0.11515 (A-MSE: 0.10319) avg lploss: 0.00000
train epoch 1948 avg loss: 0.11740 (A-MSE: 0.10444) avg lploss: 0.00000
train epoch 1949 avg loss: 0.09837 (A-MSE: 0.08758) avg lploss: 0.00000
train epoch 1950 avg loss: 0.09559 (A-MSE: 0.08575) avg lploss: 0.00000
==> val epoch 1950 avg loss: 0.37462 (A-MSE: 0.32370) avg lploss: 0.00000
==> test epoch 1950 avg loss: 0.36610 (A-MSE: 0.32424) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 22 out of 50
train epoch 1951 avg loss: 0.10497 (A-MSE: 0.09461) avg lploss: 0.00000
train epoch 1952 avg loss: 0.09688 (A-MSE: 0.08747) avg lploss: 0.00000
train epoch 1953 avg loss: 0.10125 (A-MSE: 0.08962) avg lploss: 0.00000
train epoch 1954 avg loss: 0.08608 (A-MSE: 0.07645) avg lploss: 0.00000
train epoch 1955 avg loss: 0.08593 (A-MSE: 0.07653) avg lploss: 0.00000
==> val epoch 1955 avg loss: 0.32344 (A-MSE: 0.27872) avg lploss: 0.00000
==> test epoch 1955 avg loss: 0.34251 (A-MSE: 0.30366) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 23 out of 50
train epoch 1956 avg loss: 0.09016 (A-MSE: 0.08061) avg lploss: 0.00000
train epoch 1957 avg loss: 0.09033 (A-MSE: 0.08145) avg lploss: 0.00000
train epoch 1958 avg loss: 0.08424 (A-MSE: 0.07527) avg lploss: 0.00000
train epoch 1959 avg loss: 0.08571 (A-MSE: 0.07662) avg lploss: 0.00000
train epoch 1960 avg loss: 0.09680 (A-MSE: 0.08678) avg lploss: 0.00000
==> val epoch 1960 avg loss: 0.35324 (A-MSE: 0.30584) avg lploss: 0.00000
==> test epoch 1960 avg loss: 0.36395 (A-MSE: 0.32363) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 24 out of 50
train epoch 1961 avg loss: 0.10229 (A-MSE: 0.09066) avg lploss: 0.00000
train epoch 1962 avg loss: 0.10688 (A-MSE: 0.09569) avg lploss: 0.00000
train epoch 1963 avg loss: 0.09316 (A-MSE: 0.08182) avg lploss: 0.00000
train epoch 1964 avg loss: 0.10224 (A-MSE: 0.09171) avg lploss: 0.00000
train epoch 1965 avg loss: 0.09535 (A-MSE: 0.08566) avg lploss: 0.00000
==> val epoch 1965 avg loss: 0.35926 (A-MSE: 0.31015) avg lploss: 0.00000
==> test epoch 1965 avg loss: 0.35146 (A-MSE: 0.31010) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 25 out of 50
train epoch 1966 avg loss: 0.09462 (A-MSE: 0.08532) avg lploss: 0.00000
train epoch 1967 avg loss: 0.10321 (A-MSE: 0.09172) avg lploss: 0.00000
train epoch 1968 avg loss: 0.10254 (A-MSE: 0.09030) avg lploss: 0.00000
train epoch 1969 avg loss: 0.10620 (A-MSE: 0.09557) avg lploss: 0.00000
train epoch 1970 avg loss: 0.09288 (A-MSE: 0.08348) avg lploss: 0.00000
==> val epoch 1970 avg loss: 0.34842 (A-MSE: 0.29902) avg lploss: 0.00000
==> test epoch 1970 avg loss: 0.33784 (A-MSE: 0.29731) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 26 out of 50
train epoch 1971 avg loss: 0.09528 (A-MSE: 0.08399) avg lploss: 0.00000
train epoch 1972 avg loss: 0.08962 (A-MSE: 0.07979) avg lploss: 0.00000
train epoch 1973 avg loss: 0.09113 (A-MSE: 0.08183) avg lploss: 0.00000
train epoch 1974 avg loss: 0.08297 (A-MSE: 0.07384) avg lploss: 0.00000
train epoch 1975 avg loss: 0.09155 (A-MSE: 0.08175) avg lploss: 0.00000
==> val epoch 1975 avg loss: 0.32278 (A-MSE: 0.27869) avg lploss: 0.00000
==> test epoch 1975 avg loss: 0.34068 (A-MSE: 0.30184) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 27 out of 50
train epoch 1976 avg loss: 0.11174 (A-MSE: 0.09991) avg lploss: 0.00000
train epoch 1977 avg loss: 0.11451 (A-MSE: 0.10346) avg lploss: 0.00000
train epoch 1978 avg loss: 0.09881 (A-MSE: 0.08749) avg lploss: 0.00000
train epoch 1979 avg loss: 0.08562 (A-MSE: 0.07697) avg lploss: 0.00000
train epoch 1980 avg loss: 0.09232 (A-MSE: 0.08243) avg lploss: 0.00000
==> val epoch 1980 avg loss: 0.33892 (A-MSE: 0.29039) avg lploss: 0.00000
==> test epoch 1980 avg loss: 0.35695 (A-MSE: 0.31528) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 28 out of 50
train epoch 1981 avg loss: 0.09501 (A-MSE: 0.08449) avg lploss: 0.00000
train epoch 1982 avg loss: 0.09012 (A-MSE: 0.08016) avg lploss: 0.00000
train epoch 1983 avg loss: 0.08985 (A-MSE: 0.07991) avg lploss: 0.00000
train epoch 1984 avg loss: 0.10361 (A-MSE: 0.09430) avg lploss: 0.00000
train epoch 1985 avg loss: 0.10108 (A-MSE: 0.09035) avg lploss: 0.00000
==> val epoch 1985 avg loss: 0.32898 (A-MSE: 0.28450) avg lploss: 0.00000
==> test epoch 1985 avg loss: 0.35330 (A-MSE: 0.31266) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 29 out of 50
train epoch 1986 avg loss: 0.10906 (A-MSE: 0.09831) avg lploss: 0.00000
train epoch 1987 avg loss: 0.10887 (A-MSE: 0.09710) avg lploss: 0.00000
train epoch 1988 avg loss: 0.09273 (A-MSE: 0.08413) avg lploss: 0.00000
train epoch 1989 avg loss: 0.09375 (A-MSE: 0.08381) avg lploss: 0.00000
train epoch 1990 avg loss: 0.09603 (A-MSE: 0.08537) avg lploss: 0.00000
==> val epoch 1990 avg loss: 0.37187 (A-MSE: 0.31733) avg lploss: 0.00000
==> test epoch 1990 avg loss: 0.37984 (A-MSE: 0.33194) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 30 out of 50
train epoch 1991 avg loss: 0.10671 (A-MSE: 0.09533) avg lploss: 0.00000
train epoch 1992 avg loss: 0.12465 (A-MSE: 0.11146) avg lploss: 0.00000
train epoch 1993 avg loss: 0.11729 (A-MSE: 0.10385) avg lploss: 0.00000
train epoch 1994 avg loss: 0.11092 (A-MSE: 0.09939) avg lploss: 0.00000
train epoch 1995 avg loss: 0.14991 (A-MSE: 0.13474) avg lploss: 0.00000
==> val epoch 1995 avg loss: 0.38333 (A-MSE: 0.33088) avg lploss: 0.00000
==> test epoch 1995 avg loss: 0.38864 (A-MSE: 0.33959) avg lploss: 0.00000
*** Best Val Loss: 0.31758 	 Best Test Loss: 0.36511 	 Best epoch 1840
EarlyStopping counter: 31 out of 50
train epoch 1996 avg loss: 0.13717 (A-MSE: 0.12115) avg lploss: 0.00000
train epoch 1997 avg loss: 0.11204 (A-MSE: 0.10013) avg lploss: 0.00000
train epoch 1998 avg loss: 0.09742 (A-MSE: 0.08719) avg lploss: 0.00000
train epoch 1999 avg loss: 0.08874 (A-MSE: 0.07891) avg lploss: 0.00000
best_train_f_mse = 0.128691
best_lp = 0.000000
best_val_f_mse = 0.317578
best_test_f_mse = 0.365115
best_test_a_mse = 0.324399
best_epoch = 1840
best_train_f_mse = 0.128691, best_lp = 0.000000, best_val_f_mse = 0.317578, best_test_f_mse = 0.365115, best_test_a_mse = 0.324399, best_epoch = 1840
Job completed at Mon Dec  8 23:31:43 CET 2025
