Date              = Sat Dec  6 08:06:21 CET 2025
Hostname          = mel2073
Array Task ID     = 3
Running config: configs/mocap_run_seed4.json
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_seed4.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_seed4', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/mocap', pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/mocap/mocap_run_seed4/saved_model.pth
train epoch 0 avg loss: 214921.73033 (A-MSE: 196499.23136) avg lploss: 0.00000
==> val epoch 0 avg loss: 88.93691 (A-MSE: 78.28191) avg lploss: 0.00000
==> test epoch 0 avg loss: 84.73434 (A-MSE: 74.58916) avg lploss: 0.00000
*** Best Val Loss: 88.93691 	 Best Test Loss: 84.73434 	 Best epoch 0
Validation loss decreased (inf --> 88.936915).  Saving model ...
train epoch 1 avg loss: 85.81445 (A-MSE: 75.59194) avg lploss: 0.00000
train epoch 2 avg loss: 83.80720 (A-MSE: 73.82331) avg lploss: 0.00000
train epoch 3 avg loss: 80.25892 (A-MSE: 70.75853) avg lploss: 0.00000
train epoch 4 avg loss: 69.65205 (A-MSE: 61.04767) avg lploss: 0.00000
train epoch 5 avg loss: 51.34647 (A-MSE: 44.73096) avg lploss: 0.00000
==> val epoch 5 avg loss: 43.39248 (A-MSE: 37.82558) avg lploss: 0.00000
==> test epoch 5 avg loss: 40.88469 (A-MSE: 35.66112) avg lploss: 0.00000
*** Best Val Loss: 43.39248 	 Best Test Loss: 40.88469 	 Best epoch 5
Validation loss decreased (88.936915 --> 43.392483).  Saving model ...
train epoch 6 avg loss: 39.82707 (A-MSE: 34.53192) avg lploss: 0.00000
train epoch 7 avg loss: 33.89080 (A-MSE: 29.37401) avg lploss: 0.00000
train epoch 8 avg loss: 29.89706 (A-MSE: 25.85233) avg lploss: 0.00000
train epoch 9 avg loss: 27.34625 (A-MSE: 23.67548) avg lploss: 0.00000
train epoch 10 avg loss: 25.77982 (A-MSE: 22.39054) avg lploss: 0.00000
==> val epoch 10 avg loss: 25.29900 (A-MSE: 21.72222) avg lploss: 0.00000
==> test epoch 10 avg loss: 23.89116 (A-MSE: 20.45530) avg lploss: 0.00000
*** Best Val Loss: 25.29900 	 Best Test Loss: 23.89116 	 Best epoch 10
Validation loss decreased (43.392483 --> 25.299000).  Saving model ...
train epoch 11 avg loss: 24.38088 (A-MSE: 21.04721) avg lploss: 0.00000
train epoch 12 avg loss: 23.49019 (A-MSE: 20.36008) avg lploss: 0.00000
train epoch 13 avg loss: 22.35739 (A-MSE: 19.36728) avg lploss: 0.00000
train epoch 14 avg loss: 20.93203 (A-MSE: 18.13986) avg lploss: 0.00000
train epoch 15 avg loss: 20.28638 (A-MSE: 17.58730) avg lploss: 0.00000
==> val epoch 15 avg loss: 19.37159 (A-MSE: 16.61129) avg lploss: 0.00000
==> test epoch 15 avg loss: 18.38905 (A-MSE: 15.69943) avg lploss: 0.00000
*** Best Val Loss: 19.37159 	 Best Test Loss: 18.38905 	 Best epoch 15
Validation loss decreased (25.299000 --> 19.371593).  Saving model ...
train epoch 16 avg loss: 20.00656 (A-MSE: 17.37647) avg lploss: 0.00000
train epoch 17 avg loss: 19.54546 (A-MSE: 16.98507) avg lploss: 0.00000
train epoch 18 avg loss: 18.81391 (A-MSE: 16.33597) avg lploss: 0.00000
train epoch 19 avg loss: 17.79513 (A-MSE: 15.46980) avg lploss: 0.00000
train epoch 20 avg loss: 17.53697 (A-MSE: 15.27169) avg lploss: 0.00000
==> val epoch 20 avg loss: 18.58240 (A-MSE: 16.23839) avg lploss: 0.00000
==> test epoch 20 avg loss: 17.27518 (A-MSE: 14.98221) avg lploss: 0.00000
*** Best Val Loss: 18.58240 	 Best Test Loss: 17.27518 	 Best epoch 20
Validation loss decreased (19.371593 --> 18.582395).  Saving model ...
train epoch 21 avg loss: 17.15327 (A-MSE: 14.92539) avg lploss: 0.00000
train epoch 22 avg loss: 16.92429 (A-MSE: 14.74949) avg lploss: 0.00000
train epoch 23 avg loss: 16.30225 (A-MSE: 14.21631) avg lploss: 0.00000
train epoch 24 avg loss: 16.39285 (A-MSE: 14.29803) avg lploss: 0.00000
train epoch 25 avg loss: 16.23127 (A-MSE: 14.16172) avg lploss: 0.00000
==> val epoch 25 avg loss: 15.94790 (A-MSE: 13.75400) avg lploss: 0.00000
==> test epoch 25 avg loss: 15.12717 (A-MSE: 12.97076) avg lploss: 0.00000
*** Best Val Loss: 15.94790 	 Best Test Loss: 15.12717 	 Best epoch 25
Validation loss decreased (18.582395 --> 15.947896).  Saving model ...
train epoch 26 avg loss: 15.67477 (A-MSE: 13.69259) avg lploss: 0.00000
train epoch 27 avg loss: 15.29974 (A-MSE: 13.36090) avg lploss: 0.00000
train epoch 28 avg loss: 14.93795 (A-MSE: 13.05448) avg lploss: 0.00000
train epoch 29 avg loss: 14.98280 (A-MSE: 13.10579) avg lploss: 0.00000
train epoch 30 avg loss: 14.81458 (A-MSE: 12.94185) avg lploss: 0.00000
==> val epoch 30 avg loss: 14.66573 (A-MSE: 12.57716) avg lploss: 0.00000
==> test epoch 30 avg loss: 14.15993 (A-MSE: 12.11869) avg lploss: 0.00000
*** Best Val Loss: 14.66573 	 Best Test Loss: 14.15993 	 Best epoch 30
Validation loss decreased (15.947896 --> 14.665735).  Saving model ...
train epoch 31 avg loss: 14.27902 (A-MSE: 12.46424) avg lploss: 0.00000
train epoch 32 avg loss: 13.84778 (A-MSE: 12.08358) avg lploss: 0.00000
train epoch 33 avg loss: 13.81723 (A-MSE: 12.07523) avg lploss: 0.00000
train epoch 34 avg loss: 13.51124 (A-MSE: 11.78352) avg lploss: 0.00000
train epoch 35 avg loss: 13.15828 (A-MSE: 11.49080) avg lploss: 0.00000
==> val epoch 35 avg loss: 13.11987 (A-MSE: 11.34059) avg lploss: 0.00000
==> test epoch 35 avg loss: 12.79583 (A-MSE: 11.05880) avg lploss: 0.00000
*** Best Val Loss: 13.11987 	 Best Test Loss: 12.79583 	 Best epoch 35
Validation loss decreased (14.665735 --> 13.119872).  Saving model ...
train epoch 36 avg loss: 12.27458 (A-MSE: 10.69716) avg lploss: 0.00000
train epoch 37 avg loss: 12.25197 (A-MSE: 10.69412) avg lploss: 0.00000
train epoch 38 avg loss: 12.00559 (A-MSE: 10.46870) avg lploss: 0.00000
train epoch 39 avg loss: 12.63060 (A-MSE: 11.05121) avg lploss: 0.00000
train epoch 40 avg loss: 12.25275 (A-MSE: 10.73507) avg lploss: 0.00000
==> val epoch 40 avg loss: 11.93174 (A-MSE: 10.30460) avg lploss: 0.00000
==> test epoch 40 avg loss: 11.62590 (A-MSE: 10.02649) avg lploss: 0.00000
*** Best Val Loss: 11.93174 	 Best Test Loss: 11.62590 	 Best epoch 40
Validation loss decreased (13.119872 --> 11.931736).  Saving model ...
train epoch 41 avg loss: 11.39194 (A-MSE: 9.89794) avg lploss: 0.00000
train epoch 42 avg loss: 10.97737 (A-MSE: 9.61705) avg lploss: 0.00000
train epoch 43 avg loss: 10.79844 (A-MSE: 9.43289) avg lploss: 0.00000
train epoch 44 avg loss: 10.54777 (A-MSE: 9.18839) avg lploss: 0.00000
train epoch 45 avg loss: 10.35205 (A-MSE: 9.03805) avg lploss: 0.00000
==> val epoch 45 avg loss: 10.15181 (A-MSE: 8.80858) avg lploss: 0.00000
==> test epoch 45 avg loss: 10.00781 (A-MSE: 8.67627) avg lploss: 0.00000
*** Best Val Loss: 10.15181 	 Best Test Loss: 10.00781 	 Best epoch 45
Validation loss decreased (11.931736 --> 10.151814).  Saving model ...
train epoch 46 avg loss: 9.66255 (A-MSE: 8.42023) avg lploss: 0.00000
train epoch 47 avg loss: 10.14699 (A-MSE: 8.85261) avg lploss: 0.00000
train epoch 48 avg loss: 9.53118 (A-MSE: 8.31922) avg lploss: 0.00000
train epoch 49 avg loss: 8.73259 (A-MSE: 7.61146) avg lploss: 0.00000
train epoch 50 avg loss: 8.94220 (A-MSE: 7.77402) avg lploss: 0.00000
==> val epoch 50 avg loss: 8.98978 (A-MSE: 7.95358) avg lploss: 0.00000
==> test epoch 50 avg loss: 9.08785 (A-MSE: 8.03442) avg lploss: 0.00000
*** Best Val Loss: 8.98978 	 Best Test Loss: 9.08785 	 Best epoch 50
Validation loss decreased (10.151814 --> 8.989782).  Saving model ...
train epoch 51 avg loss: 8.35344 (A-MSE: 7.29655) avg lploss: 0.00000
train epoch 52 avg loss: 8.26839 (A-MSE: 7.19013) avg lploss: 0.00000
train epoch 53 avg loss: 8.42434 (A-MSE: 7.34787) avg lploss: 0.00000
train epoch 54 avg loss: 8.30077 (A-MSE: 7.24803) avg lploss: 0.00000
train epoch 55 avg loss: 8.07491 (A-MSE: 7.00916) avg lploss: 0.00000
==> val epoch 55 avg loss: 8.59992 (A-MSE: 7.62855) avg lploss: 0.00000
==> test epoch 55 avg loss: 8.36023 (A-MSE: 7.38117) avg lploss: 0.00000
*** Best Val Loss: 8.59992 	 Best Test Loss: 8.36023 	 Best epoch 55
Validation loss decreased (8.989782 --> 8.599917).  Saving model ...
train epoch 56 avg loss: 7.61160 (A-MSE: 6.66069) avg lploss: 0.00000
train epoch 57 avg loss: 7.64706 (A-MSE: 6.64165) avg lploss: 0.00000
train epoch 58 avg loss: 7.38666 (A-MSE: 6.47505) avg lploss: 0.00000
train epoch 59 avg loss: 7.39847 (A-MSE: 6.44059) avg lploss: 0.00000
train epoch 60 avg loss: 7.19139 (A-MSE: 6.27965) avg lploss: 0.00000
==> val epoch 60 avg loss: 8.29910 (A-MSE: 7.18365) avg lploss: 0.00000
==> test epoch 60 avg loss: 8.23308 (A-MSE: 7.12764) avg lploss: 0.00000
*** Best Val Loss: 8.29910 	 Best Test Loss: 8.23308 	 Best epoch 60
Validation loss decreased (8.599917 --> 8.299099).  Saving model ...
train epoch 61 avg loss: 7.20020 (A-MSE: 6.28034) avg lploss: 0.00000
train epoch 62 avg loss: 6.96137 (A-MSE: 6.09148) avg lploss: 0.00000
train epoch 63 avg loss: 7.77847 (A-MSE: 6.80573) avg lploss: 0.00000
train epoch 64 avg loss: 7.01188 (A-MSE: 6.10734) avg lploss: 0.00000
train epoch 65 avg loss: 6.78555 (A-MSE: 5.93719) avg lploss: 0.00000
==> val epoch 65 avg loss: 7.61241 (A-MSE: 6.84629) avg lploss: 0.00000
==> test epoch 65 avg loss: 7.34358 (A-MSE: 6.58018) avg lploss: 0.00000
*** Best Val Loss: 7.61241 	 Best Test Loss: 7.34358 	 Best epoch 65
Validation loss decreased (8.299099 --> 7.612413).  Saving model ...
train epoch 66 avg loss: 7.02757 (A-MSE: 6.15260) avg lploss: 0.00000
train epoch 67 avg loss: 6.76629 (A-MSE: 5.90417) avg lploss: 0.00000
train epoch 68 avg loss: 6.49087 (A-MSE: 5.68091) avg lploss: 0.00000
train epoch 69 avg loss: 6.84126 (A-MSE: 6.01745) avg lploss: 0.00000
train epoch 70 avg loss: 6.83010 (A-MSE: 5.97456) avg lploss: 0.00000
==> val epoch 70 avg loss: 7.36498 (A-MSE: 6.38308) avg lploss: 0.00000
==> test epoch 70 avg loss: 7.39011 (A-MSE: 6.40052) avg lploss: 0.00000
*** Best Val Loss: 7.36498 	 Best Test Loss: 7.39011 	 Best epoch 70
Validation loss decreased (7.612413 --> 7.364983).  Saving model ...
train epoch 71 avg loss: 6.48952 (A-MSE: 5.68904) avg lploss: 0.00000
train epoch 72 avg loss: 6.57481 (A-MSE: 5.73620) avg lploss: 0.00000
train epoch 73 avg loss: 6.59792 (A-MSE: 5.79378) avg lploss: 0.00000
train epoch 74 avg loss: 6.68400 (A-MSE: 5.87024) avg lploss: 0.00000
train epoch 75 avg loss: 6.54790 (A-MSE: 5.75895) avg lploss: 0.00000
==> val epoch 75 avg loss: 8.88220 (A-MSE: 7.74754) avg lploss: 0.00000
==> test epoch 75 avg loss: 8.77801 (A-MSE: 7.67382) avg lploss: 0.00000
*** Best Val Loss: 7.36498 	 Best Test Loss: 7.39011 	 Best epoch 70
EarlyStopping counter: 1 out of 50
train epoch 76 avg loss: 7.07985 (A-MSE: 6.20629) avg lploss: 0.00000
train epoch 77 avg loss: 6.18152 (A-MSE: 5.41884) avg lploss: 0.00000
train epoch 78 avg loss: 6.38499 (A-MSE: 5.60017) avg lploss: 0.00000
train epoch 79 avg loss: 6.08836 (A-MSE: 5.35142) avg lploss: 0.00000
train epoch 80 avg loss: 6.11269 (A-MSE: 5.35679) avg lploss: 0.00000
==> val epoch 80 avg loss: 7.24937 (A-MSE: 6.48404) avg lploss: 0.00000
==> test epoch 80 avg loss: 7.25835 (A-MSE: 6.49922) avg lploss: 0.00000
*** Best Val Loss: 7.24937 	 Best Test Loss: 7.25835 	 Best epoch 80
Validation loss decreased (7.364983 --> 7.249370).  Saving model ...
train epoch 81 avg loss: 5.96213 (A-MSE: 5.25420) avg lploss: 0.00000
train epoch 82 avg loss: 6.21506 (A-MSE: 5.47188) avg lploss: 0.00000
train epoch 83 avg loss: 6.34199 (A-MSE: 5.57011) avg lploss: 0.00000
train epoch 84 avg loss: 6.44669 (A-MSE: 5.69165) avg lploss: 0.00000
train epoch 85 avg loss: 6.06538 (A-MSE: 5.31765) avg lploss: 0.00000
==> val epoch 85 avg loss: 6.62338 (A-MSE: 5.80480) avg lploss: 0.00000
==> test epoch 85 avg loss: 6.41678 (A-MSE: 5.62715) avg lploss: 0.00000
*** Best Val Loss: 6.62338 	 Best Test Loss: 6.41678 	 Best epoch 85
Validation loss decreased (7.249370 --> 6.623377).  Saving model ...
train epoch 86 avg loss: 5.82798 (A-MSE: 5.13409) avg lploss: 0.00000
train epoch 87 avg loss: 5.76014 (A-MSE: 5.06116) avg lploss: 0.00000
train epoch 88 avg loss: 5.75277 (A-MSE: 5.06888) avg lploss: 0.00000
train epoch 89 avg loss: 6.05124 (A-MSE: 5.35297) avg lploss: 0.00000
train epoch 90 avg loss: 5.74323 (A-MSE: 5.04126) avg lploss: 0.00000
==> val epoch 90 avg loss: 6.35272 (A-MSE: 5.52924) avg lploss: 0.00000
==> test epoch 90 avg loss: 6.26899 (A-MSE: 5.48257) avg lploss: 0.00000
*** Best Val Loss: 6.35272 	 Best Test Loss: 6.26899 	 Best epoch 90
Validation loss decreased (6.623377 --> 6.352717).  Saving model ...
train epoch 91 avg loss: 5.65240 (A-MSE: 4.99513) avg lploss: 0.00000
train epoch 92 avg loss: 5.65776 (A-MSE: 4.98758) avg lploss: 0.00000
train epoch 93 avg loss: 5.55752 (A-MSE: 4.90448) avg lploss: 0.00000
train epoch 94 avg loss: 5.44295 (A-MSE: 4.77840) avg lploss: 0.00000
train epoch 95 avg loss: 5.37302 (A-MSE: 4.73637) avg lploss: 0.00000
==> val epoch 95 avg loss: 6.43810 (A-MSE: 5.72635) avg lploss: 0.00000
==> test epoch 95 avg loss: 6.31264 (A-MSE: 5.62662) avg lploss: 0.00000
*** Best Val Loss: 6.35272 	 Best Test Loss: 6.26899 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 5.34871 (A-MSE: 4.73255) avg lploss: 0.00000
train epoch 97 avg loss: 5.24480 (A-MSE: 4.62838) avg lploss: 0.00000
train epoch 98 avg loss: 5.22644 (A-MSE: 4.61901) avg lploss: 0.00000
train epoch 99 avg loss: 5.27931 (A-MSE: 4.64992) avg lploss: 0.00000
train epoch 100 avg loss: 5.49367 (A-MSE: 4.88301) avg lploss: 0.00000
==> val epoch 100 avg loss: 7.03653 (A-MSE: 6.09209) avg lploss: 0.00000
==> test epoch 100 avg loss: 6.82465 (A-MSE: 5.94503) avg lploss: 0.00000
*** Best Val Loss: 6.35272 	 Best Test Loss: 6.26899 	 Best epoch 90
EarlyStopping counter: 2 out of 50
train epoch 101 avg loss: 5.64672 (A-MSE: 4.98087) avg lploss: 0.00000
train epoch 102 avg loss: 5.34506 (A-MSE: 4.73568) avg lploss: 0.00000
train epoch 103 avg loss: 5.04596 (A-MSE: 4.45694) avg lploss: 0.00000
train epoch 104 avg loss: 4.96493 (A-MSE: 4.39445) avg lploss: 0.00000
train epoch 105 avg loss: 5.01157 (A-MSE: 4.43316) avg lploss: 0.00000
==> val epoch 105 avg loss: 6.53290 (A-MSE: 5.86132) avg lploss: 0.00000
==> test epoch 105 avg loss: 6.64726 (A-MSE: 6.00636) avg lploss: 0.00000
*** Best Val Loss: 6.35272 	 Best Test Loss: 6.26899 	 Best epoch 90
EarlyStopping counter: 3 out of 50
train epoch 106 avg loss: 4.77691 (A-MSE: 4.22641) avg lploss: 0.00000
train epoch 107 avg loss: 4.82748 (A-MSE: 4.26076) avg lploss: 0.00000
train epoch 108 avg loss: 4.77154 (A-MSE: 4.24424) avg lploss: 0.00000
train epoch 109 avg loss: 4.71141 (A-MSE: 4.17779) avg lploss: 0.00000
train epoch 110 avg loss: 4.81246 (A-MSE: 4.29734) avg lploss: 0.00000
==> val epoch 110 avg loss: 5.67733 (A-MSE: 5.07808) avg lploss: 0.00000
==> test epoch 110 avg loss: 5.59413 (A-MSE: 5.04825) avg lploss: 0.00000
*** Best Val Loss: 5.67733 	 Best Test Loss: 5.59413 	 Best epoch 110
Validation loss decreased (6.352717 --> 5.677333).  Saving model ...
train epoch 111 avg loss: 4.74298 (A-MSE: 4.20201) avg lploss: 0.00000
train epoch 112 avg loss: 4.77129 (A-MSE: 4.23595) avg lploss: 0.00000
train epoch 113 avg loss: 5.07157 (A-MSE: 4.50176) avg lploss: 0.00000
train epoch 114 avg loss: 4.84424 (A-MSE: 4.30346) avg lploss: 0.00000
train epoch 115 avg loss: 4.64272 (A-MSE: 4.10985) avg lploss: 0.00000
==> val epoch 115 avg loss: 5.96922 (A-MSE: 5.31122) avg lploss: 0.00000
==> test epoch 115 avg loss: 6.13241 (A-MSE: 5.53019) avg lploss: 0.00000
*** Best Val Loss: 5.67733 	 Best Test Loss: 5.59413 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 4.91283 (A-MSE: 4.36714) avg lploss: 0.00000
train epoch 117 avg loss: 4.53190 (A-MSE: 4.03105) avg lploss: 0.00000
train epoch 118 avg loss: 4.51330 (A-MSE: 4.02342) avg lploss: 0.00000
train epoch 119 avg loss: 4.93667 (A-MSE: 4.40452) avg lploss: 0.00000
train epoch 120 avg loss: 4.59067 (A-MSE: 4.09225) avg lploss: 0.00000
==> val epoch 120 avg loss: 5.13508 (A-MSE: 4.54711) avg lploss: 0.00000
==> test epoch 120 avg loss: 5.12393 (A-MSE: 4.59976) avg lploss: 0.00000
*** Best Val Loss: 5.13508 	 Best Test Loss: 5.12393 	 Best epoch 120
Validation loss decreased (5.677333 --> 5.135080).  Saving model ...
train epoch 121 avg loss: 4.35225 (A-MSE: 3.86647) avg lploss: 0.00000
train epoch 122 avg loss: 4.23628 (A-MSE: 3.77308) avg lploss: 0.00000
train epoch 123 avg loss: 4.13153 (A-MSE: 3.68813) avg lploss: 0.00000
train epoch 124 avg loss: 4.05625 (A-MSE: 3.62045) avg lploss: 0.00000
train epoch 125 avg loss: 4.04980 (A-MSE: 3.61800) avg lploss: 0.00000
==> val epoch 125 avg loss: 4.83311 (A-MSE: 4.32477) avg lploss: 0.00000
==> test epoch 125 avg loss: 4.78921 (A-MSE: 4.33428) avg lploss: 0.00000
*** Best Val Loss: 4.83311 	 Best Test Loss: 4.78921 	 Best epoch 125
Validation loss decreased (5.135080 --> 4.833107).  Saving model ...
train epoch 126 avg loss: 4.26672 (A-MSE: 3.80678) avg lploss: 0.00000
train epoch 127 avg loss: 4.17996 (A-MSE: 3.73190) avg lploss: 0.00000
train epoch 128 avg loss: 4.00146 (A-MSE: 3.56242) avg lploss: 0.00000
train epoch 129 avg loss: 3.93394 (A-MSE: 3.50481) avg lploss: 0.00000
train epoch 130 avg loss: 3.79356 (A-MSE: 3.40097) avg lploss: 0.00000
==> val epoch 130 avg loss: 4.79347 (A-MSE: 4.27367) avg lploss: 0.00000
==> test epoch 130 avg loss: 4.89739 (A-MSE: 4.43572) avg lploss: 0.00000
*** Best Val Loss: 4.79347 	 Best Test Loss: 4.89739 	 Best epoch 130
Validation loss decreased (4.833107 --> 4.793473).  Saving model ...
train epoch 131 avg loss: 4.14567 (A-MSE: 3.71706) avg lploss: 0.00000
train epoch 132 avg loss: 4.29949 (A-MSE: 3.82122) avg lploss: 0.00000
train epoch 133 avg loss: 4.02749 (A-MSE: 3.60492) avg lploss: 0.00000
train epoch 134 avg loss: 3.71665 (A-MSE: 3.32300) avg lploss: 0.00000
train epoch 135 avg loss: 3.79165 (A-MSE: 3.39177) avg lploss: 0.00000
==> val epoch 135 avg loss: 4.66259 (A-MSE: 4.22134) avg lploss: 0.00000
==> test epoch 135 avg loss: 4.64956 (A-MSE: 4.28136) avg lploss: 0.00000
*** Best Val Loss: 4.66259 	 Best Test Loss: 4.64956 	 Best epoch 135
Validation loss decreased (4.793473 --> 4.662593).  Saving model ...
train epoch 136 avg loss: 3.69060 (A-MSE: 3.29497) avg lploss: 0.00000
train epoch 137 avg loss: 3.55719 (A-MSE: 3.18082) avg lploss: 0.00000
train epoch 138 avg loss: 3.62849 (A-MSE: 3.23331) avg lploss: 0.00000
train epoch 139 avg loss: 3.69226 (A-MSE: 3.31963) avg lploss: 0.00000
train epoch 140 avg loss: 3.99750 (A-MSE: 3.58626) avg lploss: 0.00000
==> val epoch 140 avg loss: 4.53780 (A-MSE: 4.06698) avg lploss: 0.00000
==> test epoch 140 avg loss: 4.61608 (A-MSE: 4.19089) avg lploss: 0.00000
*** Best Val Loss: 4.53780 	 Best Test Loss: 4.61608 	 Best epoch 140
Validation loss decreased (4.662593 --> 4.537797).  Saving model ...
train epoch 141 avg loss: 4.07775 (A-MSE: 3.64507) avg lploss: 0.00000
train epoch 142 avg loss: 3.73104 (A-MSE: 3.34662) avg lploss: 0.00000
train epoch 143 avg loss: 3.48262 (A-MSE: 3.11617) avg lploss: 0.00000
train epoch 144 avg loss: 3.51570 (A-MSE: 3.15028) avg lploss: 0.00000
train epoch 145 avg loss: 3.54479 (A-MSE: 3.16830) avg lploss: 0.00000
==> val epoch 145 avg loss: 4.47229 (A-MSE: 4.07837) avg lploss: 0.00000
==> test epoch 145 avg loss: 4.73114 (A-MSE: 4.37415) avg lploss: 0.00000
*** Best Val Loss: 4.47229 	 Best Test Loss: 4.73114 	 Best epoch 145
Validation loss decreased (4.537797 --> 4.472290).  Saving model ...
train epoch 146 avg loss: 3.34878 (A-MSE: 3.01033) avg lploss: 0.00000
train epoch 147 avg loss: 3.50951 (A-MSE: 3.14865) avg lploss: 0.00000
train epoch 148 avg loss: 3.64879 (A-MSE: 3.26002) avg lploss: 0.00000
train epoch 149 avg loss: 3.86776 (A-MSE: 3.47300) avg lploss: 0.00000
train epoch 150 avg loss: 3.52178 (A-MSE: 3.15288) avg lploss: 0.00000
==> val epoch 150 avg loss: 4.31429 (A-MSE: 3.88909) avg lploss: 0.00000
==> test epoch 150 avg loss: 4.57027 (A-MSE: 4.18466) avg lploss: 0.00000
*** Best Val Loss: 4.31429 	 Best Test Loss: 4.57027 	 Best epoch 150
Validation loss decreased (4.472290 --> 4.314292).  Saving model ...
train epoch 151 avg loss: 3.26518 (A-MSE: 2.92544) avg lploss: 0.00000
train epoch 152 avg loss: 3.29017 (A-MSE: 2.94853) avg lploss: 0.00000
train epoch 153 avg loss: 3.45958 (A-MSE: 3.10315) avg lploss: 0.00000
train epoch 154 avg loss: 3.86374 (A-MSE: 3.45749) avg lploss: 0.00000
train epoch 155 avg loss: 3.43452 (A-MSE: 3.06964) avg lploss: 0.00000
==> val epoch 155 avg loss: 4.40113 (A-MSE: 3.92151) avg lploss: 0.00000
==> test epoch 155 avg loss: 4.57716 (A-MSE: 4.14051) avg lploss: 0.00000
*** Best Val Loss: 4.31429 	 Best Test Loss: 4.57027 	 Best epoch 150
EarlyStopping counter: 1 out of 50
train epoch 156 avg loss: 3.13419 (A-MSE: 2.80618) avg lploss: 0.00000
train epoch 157 avg loss: 3.29777 (A-MSE: 2.95553) avg lploss: 0.00000
train epoch 158 avg loss: 3.28778 (A-MSE: 2.95042) avg lploss: 0.00000
train epoch 159 avg loss: 3.73594 (A-MSE: 3.34191) avg lploss: 0.00000
train epoch 160 avg loss: 3.20148 (A-MSE: 2.86623) avg lploss: 0.00000
==> val epoch 160 avg loss: 4.17145 (A-MSE: 3.70717) avg lploss: 0.00000
==> test epoch 160 avg loss: 4.27035 (A-MSE: 3.83593) avg lploss: 0.00000
*** Best Val Loss: 4.17145 	 Best Test Loss: 4.27035 	 Best epoch 160
Validation loss decreased (4.314292 --> 4.171450).  Saving model ...
train epoch 161 avg loss: 3.32982 (A-MSE: 2.97555) avg lploss: 0.00000
train epoch 162 avg loss: 3.21979 (A-MSE: 2.88718) avg lploss: 0.00000
train epoch 163 avg loss: 3.04986 (A-MSE: 2.73144) avg lploss: 0.00000
train epoch 164 avg loss: 3.34950 (A-MSE: 3.00449) avg lploss: 0.00000
train epoch 165 avg loss: 3.08761 (A-MSE: 2.76973) avg lploss: 0.00000
==> val epoch 165 avg loss: 3.99592 (A-MSE: 3.58773) avg lploss: 0.00000
==> test epoch 165 avg loss: 4.08436 (A-MSE: 3.70672) avg lploss: 0.00000
*** Best Val Loss: 3.99592 	 Best Test Loss: 4.08436 	 Best epoch 165
Validation loss decreased (4.171450 --> 3.995922).  Saving model ...
train epoch 166 avg loss: 3.03960 (A-MSE: 2.72160) avg lploss: 0.00000
train epoch 167 avg loss: 3.13146 (A-MSE: 2.80363) avg lploss: 0.00000
train epoch 168 avg loss: 2.94810 (A-MSE: 2.64296) avg lploss: 0.00000
train epoch 169 avg loss: 2.95020 (A-MSE: 2.64780) avg lploss: 0.00000
train epoch 170 avg loss: 3.03861 (A-MSE: 2.71822) avg lploss: 0.00000
==> val epoch 170 avg loss: 3.93985 (A-MSE: 3.50137) avg lploss: 0.00000
==> test epoch 170 avg loss: 4.14416 (A-MSE: 3.71868) avg lploss: 0.00000
*** Best Val Loss: 3.93985 	 Best Test Loss: 4.14416 	 Best epoch 170
Validation loss decreased (3.995922 --> 3.939847).  Saving model ...
train epoch 171 avg loss: 2.78397 (A-MSE: 2.49267) avg lploss: 0.00000
train epoch 172 avg loss: 2.83167 (A-MSE: 2.53598) avg lploss: 0.00000
train epoch 173 avg loss: 2.80784 (A-MSE: 2.51352) avg lploss: 0.00000
train epoch 174 avg loss: 2.72943 (A-MSE: 2.44869) avg lploss: 0.00000
train epoch 175 avg loss: 2.87007 (A-MSE: 2.57038) avg lploss: 0.00000
==> val epoch 175 avg loss: 4.18337 (A-MSE: 3.70878) avg lploss: 0.00000
==> test epoch 175 avg loss: 4.48409 (A-MSE: 4.00913) avg lploss: 0.00000
*** Best Val Loss: 3.93985 	 Best Test Loss: 4.14416 	 Best epoch 170
EarlyStopping counter: 1 out of 50
train epoch 176 avg loss: 3.27173 (A-MSE: 2.93415) avg lploss: 0.00000
train epoch 177 avg loss: 2.84780 (A-MSE: 2.53774) avg lploss: 0.00000
train epoch 178 avg loss: 3.04905 (A-MSE: 2.73324) avg lploss: 0.00000
train epoch 179 avg loss: 3.18411 (A-MSE: 2.85067) avg lploss: 0.00000
train epoch 180 avg loss: 3.62539 (A-MSE: 3.25131) avg lploss: 0.00000
==> val epoch 180 avg loss: 4.71212 (A-MSE: 4.18853) avg lploss: 0.00000
==> test epoch 180 avg loss: 4.81691 (A-MSE: 4.33038) avg lploss: 0.00000
*** Best Val Loss: 3.93985 	 Best Test Loss: 4.14416 	 Best epoch 170
EarlyStopping counter: 2 out of 50
train epoch 181 avg loss: 3.26206 (A-MSE: 2.92170) avg lploss: 0.00000
train epoch 182 avg loss: 2.96096 (A-MSE: 2.65337) avg lploss: 0.00000
train epoch 183 avg loss: 2.61316 (A-MSE: 2.34303) avg lploss: 0.00000
train epoch 184 avg loss: 2.85553 (A-MSE: 2.55395) avg lploss: 0.00000
train epoch 185 avg loss: 2.77063 (A-MSE: 2.48402) avg lploss: 0.00000
==> val epoch 185 avg loss: 4.05710 (A-MSE: 3.60168) avg lploss: 0.00000
==> test epoch 185 avg loss: 4.25315 (A-MSE: 3.80613) avg lploss: 0.00000
*** Best Val Loss: 3.93985 	 Best Test Loss: 4.14416 	 Best epoch 170
EarlyStopping counter: 3 out of 50
train epoch 186 avg loss: 2.58453 (A-MSE: 2.31626) avg lploss: 0.00000
train epoch 187 avg loss: 2.81156 (A-MSE: 2.51633) avg lploss: 0.00000
train epoch 188 avg loss: 3.27376 (A-MSE: 2.92675) avg lploss: 0.00000
train epoch 189 avg loss: 2.91460 (A-MSE: 2.60929) avg lploss: 0.00000
train epoch 190 avg loss: 2.84912 (A-MSE: 2.55431) avg lploss: 0.00000
==> val epoch 190 avg loss: 3.47785 (A-MSE: 3.12786) avg lploss: 0.00000
==> test epoch 190 avg loss: 3.59954 (A-MSE: 3.26554) avg lploss: 0.00000
*** Best Val Loss: 3.47785 	 Best Test Loss: 3.59954 	 Best epoch 190
Validation loss decreased (3.939847 --> 3.477851).  Saving model ...
train epoch 191 avg loss: 2.69830 (A-MSE: 2.41296) avg lploss: 0.00000
train epoch 192 avg loss: 2.74217 (A-MSE: 2.47095) avg lploss: 0.00000
train epoch 193 avg loss: 2.56455 (A-MSE: 2.29354) avg lploss: 0.00000
train epoch 194 avg loss: 2.54351 (A-MSE: 2.27765) avg lploss: 0.00000
train epoch 195 avg loss: 2.82953 (A-MSE: 2.54276) avg lploss: 0.00000
==> val epoch 195 avg loss: 4.00545 (A-MSE: 3.55643) avg lploss: 0.00000
==> test epoch 195 avg loss: 4.10130 (A-MSE: 3.66763) avg lploss: 0.00000
*** Best Val Loss: 3.47785 	 Best Test Loss: 3.59954 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 2.53433 (A-MSE: 2.25961) avg lploss: 0.00000
train epoch 197 avg loss: 2.59974 (A-MSE: 2.32446) avg lploss: 0.00000
train epoch 198 avg loss: 2.53097 (A-MSE: 2.25653) avg lploss: 0.00000
train epoch 199 avg loss: 2.56929 (A-MSE: 2.29476) avg lploss: 0.00000
train epoch 200 avg loss: 2.57377 (A-MSE: 2.30700) avg lploss: 0.00000
==> val epoch 200 avg loss: 3.40491 (A-MSE: 3.00381) avg lploss: 0.00000
==> test epoch 200 avg loss: 3.42807 (A-MSE: 3.05496) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
Validation loss decreased (3.477851 --> 3.404906).  Saving model ...
train epoch 201 avg loss: 2.35872 (A-MSE: 2.11248) avg lploss: 0.00000
train epoch 202 avg loss: 2.31183 (A-MSE: 2.06608) avg lploss: 0.00000
train epoch 203 avg loss: 2.62062 (A-MSE: 2.34167) avg lploss: 0.00000
train epoch 204 avg loss: 2.66569 (A-MSE: 2.39134) avg lploss: 0.00000
train epoch 205 avg loss: 2.61791 (A-MSE: 2.33786) avg lploss: 0.00000
==> val epoch 205 avg loss: 3.67334 (A-MSE: 3.31112) avg lploss: 0.00000
==> test epoch 205 avg loss: 3.78895 (A-MSE: 3.42811) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 2.44804 (A-MSE: 2.18789) avg lploss: 0.00000
train epoch 207 avg loss: 2.48317 (A-MSE: 2.21870) avg lploss: 0.00000
train epoch 208 avg loss: 2.54064 (A-MSE: 2.27063) avg lploss: 0.00000
train epoch 209 avg loss: 2.57285 (A-MSE: 2.30093) avg lploss: 0.00000
train epoch 210 avg loss: 2.44649 (A-MSE: 2.19033) avg lploss: 0.00000
==> val epoch 210 avg loss: 3.74615 (A-MSE: 3.34964) avg lploss: 0.00000
==> test epoch 210 avg loss: 3.82366 (A-MSE: 3.44787) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
EarlyStopping counter: 2 out of 50
train epoch 211 avg loss: 2.39661 (A-MSE: 2.13696) avg lploss: 0.00000
train epoch 212 avg loss: 2.42306 (A-MSE: 2.17218) avg lploss: 0.00000
train epoch 213 avg loss: 2.32107 (A-MSE: 2.08418) avg lploss: 0.00000
train epoch 214 avg loss: 2.38807 (A-MSE: 2.13413) avg lploss: 0.00000
train epoch 215 avg loss: 2.27048 (A-MSE: 2.02196) avg lploss: 0.00000
==> val epoch 215 avg loss: 3.56656 (A-MSE: 3.18746) avg lploss: 0.00000
==> test epoch 215 avg loss: 3.67624 (A-MSE: 3.30194) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
EarlyStopping counter: 3 out of 50
train epoch 216 avg loss: 2.55184 (A-MSE: 2.28870) avg lploss: 0.00000
train epoch 217 avg loss: 2.50552 (A-MSE: 2.24195) avg lploss: 0.00000
train epoch 218 avg loss: 2.44783 (A-MSE: 2.19390) avg lploss: 0.00000
train epoch 219 avg loss: 2.35049 (A-MSE: 2.09394) avg lploss: 0.00000
train epoch 220 avg loss: 2.27630 (A-MSE: 2.03088) avg lploss: 0.00000
==> val epoch 220 avg loss: 3.88173 (A-MSE: 3.41334) avg lploss: 0.00000
==> test epoch 220 avg loss: 4.13929 (A-MSE: 3.67467) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
EarlyStopping counter: 4 out of 50
train epoch 221 avg loss: 2.47690 (A-MSE: 2.21241) avg lploss: 0.00000
train epoch 222 avg loss: 2.65588 (A-MSE: 2.37676) avg lploss: 0.00000
train epoch 223 avg loss: 2.24954 (A-MSE: 2.00651) avg lploss: 0.00000
train epoch 224 avg loss: 2.28036 (A-MSE: 2.03859) avg lploss: 0.00000
train epoch 225 avg loss: 2.37331 (A-MSE: 2.12476) avg lploss: 0.00000
==> val epoch 225 avg loss: 3.45017 (A-MSE: 3.04654) avg lploss: 0.00000
==> test epoch 225 avg loss: 3.59913 (A-MSE: 3.19500) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
EarlyStopping counter: 5 out of 50
train epoch 226 avg loss: 2.36858 (A-MSE: 2.12182) avg lploss: 0.00000
train epoch 227 avg loss: 2.38278 (A-MSE: 2.12998) avg lploss: 0.00000
train epoch 228 avg loss: 2.29997 (A-MSE: 2.05504) avg lploss: 0.00000
train epoch 229 avg loss: 2.13891 (A-MSE: 1.91219) avg lploss: 0.00000
train epoch 230 avg loss: 2.03564 (A-MSE: 1.81806) avg lploss: 0.00000
==> val epoch 230 avg loss: 4.12258 (A-MSE: 3.67087) avg lploss: 0.00000
==> test epoch 230 avg loss: 4.42069 (A-MSE: 3.95583) avg lploss: 0.00000
*** Best Val Loss: 3.40491 	 Best Test Loss: 3.42807 	 Best epoch 200
EarlyStopping counter: 6 out of 50
train epoch 231 avg loss: 2.30925 (A-MSE: 2.05681) avg lploss: 0.00000
train epoch 232 avg loss: 2.37804 (A-MSE: 2.13120) avg lploss: 0.00000
train epoch 233 avg loss: 2.27542 (A-MSE: 2.02890) avg lploss: 0.00000
train epoch 234 avg loss: 2.19193 (A-MSE: 1.95989) avg lploss: 0.00000
train epoch 235 avg loss: 2.12950 (A-MSE: 1.90184) avg lploss: 0.00000
==> val epoch 235 avg loss: 2.99506 (A-MSE: 2.65655) avg lploss: 0.00000
==> test epoch 235 avg loss: 3.19038 (A-MSE: 2.85623) avg lploss: 0.00000
*** Best Val Loss: 2.99506 	 Best Test Loss: 3.19038 	 Best epoch 235
Validation loss decreased (3.404906 --> 2.995062).  Saving model ...
train epoch 236 avg loss: 2.01776 (A-MSE: 1.79693) avg lploss: 0.00000
train epoch 237 avg loss: 2.23394 (A-MSE: 1.99602) avg lploss: 0.00000
train epoch 238 avg loss: 2.58739 (A-MSE: 2.30910) avg lploss: 0.00000
train epoch 239 avg loss: 2.08907 (A-MSE: 1.86127) avg lploss: 0.00000
train epoch 240 avg loss: 2.10745 (A-MSE: 1.87630) avg lploss: 0.00000
==> val epoch 240 avg loss: 3.36134 (A-MSE: 3.01281) avg lploss: 0.00000
==> test epoch 240 avg loss: 3.47927 (A-MSE: 3.14176) avg lploss: 0.00000
*** Best Val Loss: 2.99506 	 Best Test Loss: 3.19038 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 2.20049 (A-MSE: 1.97340) avg lploss: 0.00000
train epoch 242 avg loss: 2.04347 (A-MSE: 1.82149) avg lploss: 0.00000
train epoch 243 avg loss: 2.06386 (A-MSE: 1.84182) avg lploss: 0.00000
train epoch 244 avg loss: 2.17628 (A-MSE: 1.93571) avg lploss: 0.00000
train epoch 245 avg loss: 2.36517 (A-MSE: 2.12246) avg lploss: 0.00000
==> val epoch 245 avg loss: 3.17197 (A-MSE: 2.82484) avg lploss: 0.00000
==> test epoch 245 avg loss: 3.45718 (A-MSE: 3.10294) avg lploss: 0.00000
*** Best Val Loss: 2.99506 	 Best Test Loss: 3.19038 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 2.06597 (A-MSE: 1.83900) avg lploss: 0.00000
train epoch 247 avg loss: 2.21962 (A-MSE: 1.98230) avg lploss: 0.00000
train epoch 248 avg loss: 2.12512 (A-MSE: 1.90083) avg lploss: 0.00000
train epoch 249 avg loss: 2.25325 (A-MSE: 2.01210) avg lploss: 0.00000
train epoch 250 avg loss: 2.23595 (A-MSE: 1.99134) avg lploss: 0.00000
==> val epoch 250 avg loss: 3.02983 (A-MSE: 2.70176) avg lploss: 0.00000
==> test epoch 250 avg loss: 3.20584 (A-MSE: 2.87318) avg lploss: 0.00000
*** Best Val Loss: 2.99506 	 Best Test Loss: 3.19038 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 1.91719 (A-MSE: 1.71183) avg lploss: 0.00000
train epoch 252 avg loss: 2.10050 (A-MSE: 1.87367) avg lploss: 0.00000
train epoch 253 avg loss: 2.06538 (A-MSE: 1.84372) avg lploss: 0.00000
train epoch 254 avg loss: 2.00626 (A-MSE: 1.78884) avg lploss: 0.00000
train epoch 255 avg loss: 2.09315 (A-MSE: 1.86818) avg lploss: 0.00000
==> val epoch 255 avg loss: 2.89395 (A-MSE: 2.56753) avg lploss: 0.00000
==> test epoch 255 avg loss: 2.99866 (A-MSE: 2.68259) avg lploss: 0.00000
*** Best Val Loss: 2.89395 	 Best Test Loss: 2.99866 	 Best epoch 255
Validation loss decreased (2.995062 --> 2.893946).  Saving model ...
train epoch 256 avg loss: 2.21235 (A-MSE: 1.97361) avg lploss: 0.00000
train epoch 257 avg loss: 2.17057 (A-MSE: 1.93284) avg lploss: 0.00000
train epoch 258 avg loss: 1.90479 (A-MSE: 1.69863) avg lploss: 0.00000
train epoch 259 avg loss: 2.00633 (A-MSE: 1.79257) avg lploss: 0.00000
train epoch 260 avg loss: 1.95920 (A-MSE: 1.74815) avg lploss: 0.00000
==> val epoch 260 avg loss: 3.04073 (A-MSE: 2.69269) avg lploss: 0.00000
==> test epoch 260 avg loss: 3.27250 (A-MSE: 2.90992) avg lploss: 0.00000
*** Best Val Loss: 2.89395 	 Best Test Loss: 2.99866 	 Best epoch 255
EarlyStopping counter: 1 out of 50
train epoch 261 avg loss: 2.01255 (A-MSE: 1.79426) avg lploss: 0.00000
train epoch 262 avg loss: 1.97796 (A-MSE: 1.76521) avg lploss: 0.00000
train epoch 263 avg loss: 1.87885 (A-MSE: 1.67421) avg lploss: 0.00000
train epoch 264 avg loss: 1.86129 (A-MSE: 1.65938) avg lploss: 0.00000
train epoch 265 avg loss: 1.83531 (A-MSE: 1.63371) avg lploss: 0.00000
==> val epoch 265 avg loss: 2.99414 (A-MSE: 2.66491) avg lploss: 0.00000
==> test epoch 265 avg loss: 3.16398 (A-MSE: 2.83252) avg lploss: 0.00000
*** Best Val Loss: 2.89395 	 Best Test Loss: 2.99866 	 Best epoch 255
EarlyStopping counter: 2 out of 50
train epoch 266 avg loss: 1.91550 (A-MSE: 1.70744) avg lploss: 0.00000
train epoch 267 avg loss: 1.95766 (A-MSE: 1.75234) avg lploss: 0.00000
train epoch 268 avg loss: 1.78474 (A-MSE: 1.59235) avg lploss: 0.00000
train epoch 269 avg loss: 1.81560 (A-MSE: 1.62692) avg lploss: 0.00000
train epoch 270 avg loss: 1.89009 (A-MSE: 1.67939) avg lploss: 0.00000
==> val epoch 270 avg loss: 3.04036 (A-MSE: 2.70511) avg lploss: 0.00000
==> test epoch 270 avg loss: 3.29907 (A-MSE: 2.96726) avg lploss: 0.00000
*** Best Val Loss: 2.89395 	 Best Test Loss: 2.99866 	 Best epoch 255
EarlyStopping counter: 3 out of 50
train epoch 271 avg loss: 1.84973 (A-MSE: 1.64900) avg lploss: 0.00000
train epoch 272 avg loss: 1.80449 (A-MSE: 1.61331) avg lploss: 0.00000
train epoch 273 avg loss: 1.91674 (A-MSE: 1.70655) avg lploss: 0.00000
train epoch 274 avg loss: 1.89583 (A-MSE: 1.68379) avg lploss: 0.00000
train epoch 275 avg loss: 1.84662 (A-MSE: 1.65015) avg lploss: 0.00000
==> val epoch 275 avg loss: 2.80978 (A-MSE: 2.47728) avg lploss: 0.00000
==> test epoch 275 avg loss: 3.06535 (A-MSE: 2.72200) avg lploss: 0.00000
*** Best Val Loss: 2.80978 	 Best Test Loss: 3.06535 	 Best epoch 275
Validation loss decreased (2.893946 --> 2.809784).  Saving model ...
train epoch 276 avg loss: 1.82096 (A-MSE: 1.62117) avg lploss: 0.00000
train epoch 277 avg loss: 1.89372 (A-MSE: 1.68711) avg lploss: 0.00000
train epoch 278 avg loss: 1.86583 (A-MSE: 1.66207) avg lploss: 0.00000
train epoch 279 avg loss: 2.08899 (A-MSE: 1.86207) avg lploss: 0.00000
train epoch 280 avg loss: 2.22101 (A-MSE: 1.98753) avg lploss: 0.00000
==> val epoch 280 avg loss: 2.83464 (A-MSE: 2.52835) avg lploss: 0.00000
==> test epoch 280 avg loss: 3.04349 (A-MSE: 2.73037) avg lploss: 0.00000
*** Best Val Loss: 2.80978 	 Best Test Loss: 3.06535 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 1.97841 (A-MSE: 1.76352) avg lploss: 0.00000
train epoch 282 avg loss: 1.97421 (A-MSE: 1.76854) avg lploss: 0.00000
train epoch 283 avg loss: 1.72717 (A-MSE: 1.54050) avg lploss: 0.00000
train epoch 284 avg loss: 1.91021 (A-MSE: 1.70310) avg lploss: 0.00000
train epoch 285 avg loss: 1.86650 (A-MSE: 1.66281) avg lploss: 0.00000
==> val epoch 285 avg loss: 3.16753 (A-MSE: 2.83299) avg lploss: 0.00000
==> test epoch 285 avg loss: 3.36209 (A-MSE: 3.02526) avg lploss: 0.00000
*** Best Val Loss: 2.80978 	 Best Test Loss: 3.06535 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 1.94370 (A-MSE: 1.73439) avg lploss: 0.00000
train epoch 287 avg loss: 1.82066 (A-MSE: 1.62323) avg lploss: 0.00000
train epoch 288 avg loss: 1.76257 (A-MSE: 1.57591) avg lploss: 0.00000
train epoch 289 avg loss: 1.70747 (A-MSE: 1.51948) avg lploss: 0.00000
train epoch 290 avg loss: 1.64305 (A-MSE: 1.46783) avg lploss: 0.00000
==> val epoch 290 avg loss: 2.64911 (A-MSE: 2.34747) avg lploss: 0.00000
==> test epoch 290 avg loss: 2.77454 (A-MSE: 2.47607) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
Validation loss decreased (2.809784 --> 2.649109).  Saving model ...
train epoch 291 avg loss: 2.18701 (A-MSE: 1.95752) avg lploss: 0.00000
train epoch 292 avg loss: 1.92195 (A-MSE: 1.71589) avg lploss: 0.00000
train epoch 293 avg loss: 1.81933 (A-MSE: 1.61936) avg lploss: 0.00000
train epoch 294 avg loss: 1.84258 (A-MSE: 1.64554) avg lploss: 0.00000
train epoch 295 avg loss: 1.84182 (A-MSE: 1.64399) avg lploss: 0.00000
==> val epoch 295 avg loss: 3.07367 (A-MSE: 2.71782) avg lploss: 0.00000
==> test epoch 295 avg loss: 3.25100 (A-MSE: 2.89053) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 1.89342 (A-MSE: 1.68741) avg lploss: 0.00000
train epoch 297 avg loss: 1.76207 (A-MSE: 1.57145) avg lploss: 0.00000
train epoch 298 avg loss: 1.87165 (A-MSE: 1.66921) avg lploss: 0.00000
train epoch 299 avg loss: 1.66411 (A-MSE: 1.48749) avg lploss: 0.00000
train epoch 300 avg loss: 1.73273 (A-MSE: 1.54198) avg lploss: 0.00000
==> val epoch 300 avg loss: 2.69834 (A-MSE: 2.39472) avg lploss: 0.00000
==> test epoch 300 avg loss: 2.89104 (A-MSE: 2.58512) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 1.72859 (A-MSE: 1.54999) avg lploss: 0.00000
train epoch 302 avg loss: 1.78795 (A-MSE: 1.59100) avg lploss: 0.00000
train epoch 303 avg loss: 1.73196 (A-MSE: 1.54207) avg lploss: 0.00000
train epoch 304 avg loss: 1.63540 (A-MSE: 1.45838) avg lploss: 0.00000
train epoch 305 avg loss: 1.67421 (A-MSE: 1.48515) avg lploss: 0.00000
==> val epoch 305 avg loss: 2.83813 (A-MSE: 2.51995) avg lploss: 0.00000
==> test epoch 305 avg loss: 3.14453 (A-MSE: 2.80918) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 3 out of 50
train epoch 306 avg loss: 1.66208 (A-MSE: 1.48125) avg lploss: 0.00000
train epoch 307 avg loss: 1.80156 (A-MSE: 1.60638) avg lploss: 0.00000
train epoch 308 avg loss: 1.82100 (A-MSE: 1.62944) avg lploss: 0.00000
train epoch 309 avg loss: 1.60146 (A-MSE: 1.42506) avg lploss: 0.00000
train epoch 310 avg loss: 1.64800 (A-MSE: 1.46855) avg lploss: 0.00000
==> val epoch 310 avg loss: 3.10970 (A-MSE: 2.78065) avg lploss: 0.00000
==> test epoch 310 avg loss: 3.36985 (A-MSE: 3.03115) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 4 out of 50
train epoch 311 avg loss: 1.68331 (A-MSE: 1.50684) avg lploss: 0.00000
train epoch 312 avg loss: 1.65119 (A-MSE: 1.47149) avg lploss: 0.00000
train epoch 313 avg loss: 1.59592 (A-MSE: 1.43021) avg lploss: 0.00000
train epoch 314 avg loss: 1.58225 (A-MSE: 1.40956) avg lploss: 0.00000
train epoch 315 avg loss: 1.75187 (A-MSE: 1.56264) avg lploss: 0.00000
==> val epoch 315 avg loss: 2.99834 (A-MSE: 2.69404) avg lploss: 0.00000
==> test epoch 315 avg loss: 3.37305 (A-MSE: 3.05015) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 5 out of 50
train epoch 316 avg loss: 1.79406 (A-MSE: 1.60711) avg lploss: 0.00000
train epoch 317 avg loss: 1.68922 (A-MSE: 1.50475) avg lploss: 0.00000
train epoch 318 avg loss: 1.82995 (A-MSE: 1.63967) avg lploss: 0.00000
train epoch 319 avg loss: 1.75709 (A-MSE: 1.57275) avg lploss: 0.00000
train epoch 320 avg loss: 2.19640 (A-MSE: 1.96606) avg lploss: 0.00000
==> val epoch 320 avg loss: 3.73762 (A-MSE: 3.29277) avg lploss: 0.00000
==> test epoch 320 avg loss: 3.75584 (A-MSE: 3.33751) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 6 out of 50
train epoch 321 avg loss: 2.25784 (A-MSE: 2.00647) avg lploss: 0.00000
train epoch 322 avg loss: 1.86348 (A-MSE: 1.65713) avg lploss: 0.00000
train epoch 323 avg loss: 1.51856 (A-MSE: 1.35375) avg lploss: 0.00000
train epoch 324 avg loss: 1.63690 (A-MSE: 1.46597) avg lploss: 0.00000
train epoch 325 avg loss: 1.78083 (A-MSE: 1.58492) avg lploss: 0.00000
==> val epoch 325 avg loss: 2.85592 (A-MSE: 2.56926) avg lploss: 0.00000
==> test epoch 325 avg loss: 3.16687 (A-MSE: 2.87699) avg lploss: 0.00000
*** Best Val Loss: 2.64911 	 Best Test Loss: 2.77454 	 Best epoch 290
EarlyStopping counter: 7 out of 50
train epoch 326 avg loss: 1.61395 (A-MSE: 1.44044) avg lploss: 0.00000
train epoch 327 avg loss: 1.52471 (A-MSE: 1.35794) avg lploss: 0.00000
train epoch 328 avg loss: 1.46282 (A-MSE: 1.30451) avg lploss: 0.00000
train epoch 329 avg loss: 1.49167 (A-MSE: 1.32580) avg lploss: 0.00000
train epoch 330 avg loss: 1.61212 (A-MSE: 1.43905) avg lploss: 0.00000
==> val epoch 330 avg loss: 2.30003 (A-MSE: 2.05840) avg lploss: 0.00000
==> test epoch 330 avg loss: 2.57922 (A-MSE: 2.32310) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
Validation loss decreased (2.649109 --> 2.300028).  Saving model ...
train epoch 331 avg loss: 1.61135 (A-MSE: 1.43484) avg lploss: 0.00000
train epoch 332 avg loss: 1.58215 (A-MSE: 1.41289) avg lploss: 0.00000
train epoch 333 avg loss: 1.55441 (A-MSE: 1.38023) avg lploss: 0.00000
train epoch 334 avg loss: 1.55339 (A-MSE: 1.38429) avg lploss: 0.00000
train epoch 335 avg loss: 1.71713 (A-MSE: 1.53015) avg lploss: 0.00000
==> val epoch 335 avg loss: 3.09690 (A-MSE: 2.79214) avg lploss: 0.00000
==> test epoch 335 avg loss: 3.41129 (A-MSE: 3.08905) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 1 out of 50
train epoch 336 avg loss: 1.67314 (A-MSE: 1.49063) avg lploss: 0.00000
train epoch 337 avg loss: 1.70652 (A-MSE: 1.52477) avg lploss: 0.00000
train epoch 338 avg loss: 1.54080 (A-MSE: 1.37394) avg lploss: 0.00000
train epoch 339 avg loss: 1.49666 (A-MSE: 1.33450) avg lploss: 0.00000
train epoch 340 avg loss: 1.45909 (A-MSE: 1.30240) avg lploss: 0.00000
==> val epoch 340 avg loss: 2.55513 (A-MSE: 2.28314) avg lploss: 0.00000
==> test epoch 340 avg loss: 2.94208 (A-MSE: 2.64442) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 2 out of 50
train epoch 341 avg loss: 1.69465 (A-MSE: 1.51283) avg lploss: 0.00000
train epoch 342 avg loss: 1.54181 (A-MSE: 1.37495) avg lploss: 0.00000
train epoch 343 avg loss: 1.43664 (A-MSE: 1.27742) avg lploss: 0.00000
train epoch 344 avg loss: 1.36579 (A-MSE: 1.21868) avg lploss: 0.00000
train epoch 345 avg loss: 1.36005 (A-MSE: 1.20977) avg lploss: 0.00000
==> val epoch 345 avg loss: 2.36969 (A-MSE: 2.12575) avg lploss: 0.00000
==> test epoch 345 avg loss: 2.57566 (A-MSE: 2.32195) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 3 out of 50
train epoch 346 avg loss: 1.42434 (A-MSE: 1.27640) avg lploss: 0.00000
train epoch 347 avg loss: 1.47816 (A-MSE: 1.31599) avg lploss: 0.00000
train epoch 348 avg loss: 1.52823 (A-MSE: 1.36029) avg lploss: 0.00000
train epoch 349 avg loss: 1.67657 (A-MSE: 1.50184) avg lploss: 0.00000
train epoch 350 avg loss: 1.52570 (A-MSE: 1.35743) avg lploss: 0.00000
==> val epoch 350 avg loss: 2.98614 (A-MSE: 2.66396) avg lploss: 0.00000
==> test epoch 350 avg loss: 3.27802 (A-MSE: 2.94041) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 4 out of 50
train epoch 351 avg loss: 1.60652 (A-MSE: 1.43589) avg lploss: 0.00000
train epoch 352 avg loss: 1.69104 (A-MSE: 1.51214) avg lploss: 0.00000
train epoch 353 avg loss: 1.55576 (A-MSE: 1.38808) avg lploss: 0.00000
train epoch 354 avg loss: 1.53441 (A-MSE: 1.36779) avg lploss: 0.00000
train epoch 355 avg loss: 1.55047 (A-MSE: 1.38221) avg lploss: 0.00000
==> val epoch 355 avg loss: 3.11240 (A-MSE: 2.77329) avg lploss: 0.00000
==> test epoch 355 avg loss: 3.32944 (A-MSE: 2.98929) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 5 out of 50
train epoch 356 avg loss: 1.53061 (A-MSE: 1.36829) avg lploss: 0.00000
train epoch 357 avg loss: 1.35759 (A-MSE: 1.20505) avg lploss: 0.00000
train epoch 358 avg loss: 1.33665 (A-MSE: 1.18848) avg lploss: 0.00000
train epoch 359 avg loss: 1.42578 (A-MSE: 1.27256) avg lploss: 0.00000
train epoch 360 avg loss: 1.41239 (A-MSE: 1.25427) avg lploss: 0.00000
==> val epoch 360 avg loss: 2.51661 (A-MSE: 2.25510) avg lploss: 0.00000
==> test epoch 360 avg loss: 2.88798 (A-MSE: 2.59785) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 6 out of 50
train epoch 361 avg loss: 1.44202 (A-MSE: 1.28394) avg lploss: 0.00000
train epoch 362 avg loss: 1.48888 (A-MSE: 1.32668) avg lploss: 0.00000
train epoch 363 avg loss: 1.29250 (A-MSE: 1.15367) avg lploss: 0.00000
train epoch 364 avg loss: 1.31148 (A-MSE: 1.16947) avg lploss: 0.00000
train epoch 365 avg loss: 1.53327 (A-MSE: 1.36916) avg lploss: 0.00000
==> val epoch 365 avg loss: 2.88146 (A-MSE: 2.56209) avg lploss: 0.00000
==> test epoch 365 avg loss: 3.12907 (A-MSE: 2.79588) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 7 out of 50
train epoch 366 avg loss: 1.58729 (A-MSE: 1.41106) avg lploss: 0.00000
train epoch 367 avg loss: 1.52466 (A-MSE: 1.35467) avg lploss: 0.00000
train epoch 368 avg loss: 1.45842 (A-MSE: 1.30102) avg lploss: 0.00000
train epoch 369 avg loss: 1.44387 (A-MSE: 1.28795) avg lploss: 0.00000
train epoch 370 avg loss: 1.37018 (A-MSE: 1.22056) avg lploss: 0.00000
==> val epoch 370 avg loss: 2.36436 (A-MSE: 2.10964) avg lploss: 0.00000
==> test epoch 370 avg loss: 2.66662 (A-MSE: 2.39236) avg lploss: 0.00000
*** Best Val Loss: 2.30003 	 Best Test Loss: 2.57922 	 Best epoch 330
EarlyStopping counter: 8 out of 50
train epoch 371 avg loss: 1.39149 (A-MSE: 1.24313) avg lploss: 0.00000
train epoch 372 avg loss: 1.34990 (A-MSE: 1.20508) avg lploss: 0.00000
train epoch 373 avg loss: 1.32059 (A-MSE: 1.17488) avg lploss: 0.00000
train epoch 374 avg loss: 1.36605 (A-MSE: 1.21855) avg lploss: 0.00000
train epoch 375 avg loss: 1.40110 (A-MSE: 1.24464) avg lploss: 0.00000
==> val epoch 375 avg loss: 2.25877 (A-MSE: 2.00302) avg lploss: 0.00000
==> test epoch 375 avg loss: 2.51800 (A-MSE: 2.24672) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
Validation loss decreased (2.300028 --> 2.258769).  Saving model ...
train epoch 376 avg loss: 1.40869 (A-MSE: 1.25847) avg lploss: 0.00000
train epoch 377 avg loss: 1.61887 (A-MSE: 1.43548) avg lploss: 0.00000
train epoch 378 avg loss: 1.45101 (A-MSE: 1.29878) avg lploss: 0.00000
train epoch 379 avg loss: 1.34025 (A-MSE: 1.19660) avg lploss: 0.00000
train epoch 380 avg loss: 1.30488 (A-MSE: 1.16331) avg lploss: 0.00000
==> val epoch 380 avg loss: 2.29611 (A-MSE: 2.05148) avg lploss: 0.00000
==> test epoch 380 avg loss: 2.49534 (A-MSE: 2.25045) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 1 out of 50
train epoch 381 avg loss: 1.25200 (A-MSE: 1.11754) avg lploss: 0.00000
train epoch 382 avg loss: 1.24293 (A-MSE: 1.10602) avg lploss: 0.00000
train epoch 383 avg loss: 1.28121 (A-MSE: 1.14181) avg lploss: 0.00000
train epoch 384 avg loss: 1.25824 (A-MSE: 1.11893) avg lploss: 0.00000
train epoch 385 avg loss: 1.23874 (A-MSE: 1.10027) avg lploss: 0.00000
==> val epoch 385 avg loss: 2.97025 (A-MSE: 2.65558) avg lploss: 0.00000
==> test epoch 385 avg loss: 3.19443 (A-MSE: 2.87259) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 2 out of 50
train epoch 386 avg loss: 1.31476 (A-MSE: 1.17208) avg lploss: 0.00000
train epoch 387 avg loss: 1.55864 (A-MSE: 1.39432) avg lploss: 0.00000
train epoch 388 avg loss: 1.54917 (A-MSE: 1.37983) avg lploss: 0.00000
train epoch 389 avg loss: 1.34469 (A-MSE: 1.19478) avg lploss: 0.00000
train epoch 390 avg loss: 1.67972 (A-MSE: 1.49106) avg lploss: 0.00000
==> val epoch 390 avg loss: 2.62868 (A-MSE: 2.32589) avg lploss: 0.00000
==> test epoch 390 avg loss: 2.87612 (A-MSE: 2.55731) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 3 out of 50
train epoch 391 avg loss: 1.41471 (A-MSE: 1.27095) avg lploss: 0.00000
train epoch 392 avg loss: 1.42176 (A-MSE: 1.26062) avg lploss: 0.00000
train epoch 393 avg loss: 1.38366 (A-MSE: 1.23519) avg lploss: 0.00000
train epoch 394 avg loss: 1.29523 (A-MSE: 1.15456) avg lploss: 0.00000
train epoch 395 avg loss: 1.29385 (A-MSE: 1.14980) avg lploss: 0.00000
==> val epoch 395 avg loss: 2.29815 (A-MSE: 2.05909) avg lploss: 0.00000
==> test epoch 395 avg loss: 2.59712 (A-MSE: 2.34649) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 4 out of 50
train epoch 396 avg loss: 1.35355 (A-MSE: 1.21345) avg lploss: 0.00000
train epoch 397 avg loss: 1.28781 (A-MSE: 1.14877) avg lploss: 0.00000
train epoch 398 avg loss: 1.32417 (A-MSE: 1.17749) avg lploss: 0.00000
train epoch 399 avg loss: 1.20682 (A-MSE: 1.07518) avg lploss: 0.00000
train epoch 400 avg loss: 1.20730 (A-MSE: 1.07253) avg lploss: 0.00000
==> val epoch 400 avg loss: 2.48596 (A-MSE: 2.24439) avg lploss: 0.00000
==> test epoch 400 avg loss: 2.69624 (A-MSE: 2.44790) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 5 out of 50
train epoch 401 avg loss: 1.23480 (A-MSE: 1.09667) avg lploss: 0.00000
train epoch 402 avg loss: 1.24199 (A-MSE: 1.10556) avg lploss: 0.00000
train epoch 403 avg loss: 1.29031 (A-MSE: 1.15223) avg lploss: 0.00000
train epoch 404 avg loss: 1.26075 (A-MSE: 1.12272) avg lploss: 0.00000
train epoch 405 avg loss: 1.28575 (A-MSE: 1.14435) avg lploss: 0.00000
==> val epoch 405 avg loss: 2.45345 (A-MSE: 2.20082) avg lploss: 0.00000
==> test epoch 405 avg loss: 2.71198 (A-MSE: 2.44416) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 6 out of 50
train epoch 406 avg loss: 1.22556 (A-MSE: 1.09475) avg lploss: 0.00000
train epoch 407 avg loss: 1.31711 (A-MSE: 1.17641) avg lploss: 0.00000
train epoch 408 avg loss: 1.23659 (A-MSE: 1.09598) avg lploss: 0.00000
train epoch 409 avg loss: 1.18118 (A-MSE: 1.05200) avg lploss: 0.00000
train epoch 410 avg loss: 1.19518 (A-MSE: 1.06565) avg lploss: 0.00000
==> val epoch 410 avg loss: 2.28927 (A-MSE: 2.03877) avg lploss: 0.00000
==> test epoch 410 avg loss: 2.59555 (A-MSE: 2.32934) avg lploss: 0.00000
*** Best Val Loss: 2.25877 	 Best Test Loss: 2.51800 	 Best epoch 375
EarlyStopping counter: 7 out of 50
train epoch 411 avg loss: 1.23211 (A-MSE: 1.09895) avg lploss: 0.00000
train epoch 412 avg loss: 1.19045 (A-MSE: 1.05732) avg lploss: 0.00000
train epoch 413 avg loss: 1.25889 (A-MSE: 1.12349) avg lploss: 0.00000
train epoch 414 avg loss: 1.39996 (A-MSE: 1.25495) avg lploss: 0.00000
train epoch 415 avg loss: 1.42266 (A-MSE: 1.26903) avg lploss: 0.00000
==> val epoch 415 avg loss: 2.08619 (A-MSE: 1.86560) avg lploss: 0.00000
==> test epoch 415 avg loss: 2.41300 (A-MSE: 2.17753) avg lploss: 0.00000
*** Best Val Loss: 2.08619 	 Best Test Loss: 2.41300 	 Best epoch 415
Validation loss decreased (2.258769 --> 2.086193).  Saving model ...
train epoch 416 avg loss: 1.46647 (A-MSE: 1.30492) avg lploss: 0.00000
train epoch 417 avg loss: 1.33029 (A-MSE: 1.18841) avg lploss: 0.00000
train epoch 418 avg loss: 1.22996 (A-MSE: 1.08753) avg lploss: 0.00000
train epoch 419 avg loss: 1.32564 (A-MSE: 1.17796) avg lploss: 0.00000
train epoch 420 avg loss: 1.25680 (A-MSE: 1.12060) avg lploss: 0.00000
==> val epoch 420 avg loss: 2.97905 (A-MSE: 2.66613) avg lploss: 0.00000
==> test epoch 420 avg loss: 3.07417 (A-MSE: 2.76777) avg lploss: 0.00000
*** Best Val Loss: 2.08619 	 Best Test Loss: 2.41300 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 1.37727 (A-MSE: 1.22529) avg lploss: 0.00000
train epoch 422 avg loss: 1.44994 (A-MSE: 1.29771) avg lploss: 0.00000
train epoch 423 avg loss: 1.24178 (A-MSE: 1.10767) avg lploss: 0.00000
train epoch 424 avg loss: 1.29016 (A-MSE: 1.14355) avg lploss: 0.00000
train epoch 425 avg loss: 1.15131 (A-MSE: 1.02966) avg lploss: 0.00000
==> val epoch 425 avg loss: 2.25880 (A-MSE: 2.00897) avg lploss: 0.00000
==> test epoch 425 avg loss: 2.53344 (A-MSE: 2.27188) avg lploss: 0.00000
*** Best Val Loss: 2.08619 	 Best Test Loss: 2.41300 	 Best epoch 415
EarlyStopping counter: 2 out of 50
train epoch 426 avg loss: 1.18712 (A-MSE: 1.05458) avg lploss: 0.00000
train epoch 427 avg loss: 1.22844 (A-MSE: 1.09032) avg lploss: 0.00000
train epoch 428 avg loss: 1.18713 (A-MSE: 1.05609) avg lploss: 0.00000
train epoch 429 avg loss: 1.19349 (A-MSE: 1.06426) avg lploss: 0.00000
train epoch 430 avg loss: 1.31391 (A-MSE: 1.16666) avg lploss: 0.00000
==> val epoch 430 avg loss: 2.22347 (A-MSE: 2.00177) avg lploss: 0.00000
==> test epoch 430 avg loss: 2.42286 (A-MSE: 2.19776) avg lploss: 0.00000
*** Best Val Loss: 2.08619 	 Best Test Loss: 2.41300 	 Best epoch 415
EarlyStopping counter: 3 out of 50
train epoch 431 avg loss: 1.35022 (A-MSE: 1.20490) avg lploss: 0.00000
train epoch 432 avg loss: 1.33460 (A-MSE: 1.18201) avg lploss: 0.00000
train epoch 433 avg loss: 1.20110 (A-MSE: 1.07180) avg lploss: 0.00000
train epoch 434 avg loss: 1.24320 (A-MSE: 1.10476) avg lploss: 0.00000
train epoch 435 avg loss: 1.22436 (A-MSE: 1.09039) avg lploss: 0.00000
==> val epoch 435 avg loss: 2.07877 (A-MSE: 1.84821) avg lploss: 0.00000
==> test epoch 435 avg loss: 2.28043 (A-MSE: 2.04673) avg lploss: 0.00000
*** Best Val Loss: 2.07877 	 Best Test Loss: 2.28043 	 Best epoch 435
Validation loss decreased (2.086193 --> 2.078767).  Saving model ...
train epoch 436 avg loss: 1.05300 (A-MSE: 0.93208) avg lploss: 0.00000
train epoch 437 avg loss: 1.04683 (A-MSE: 0.92824) avg lploss: 0.00000
train epoch 438 avg loss: 1.14015 (A-MSE: 1.01258) avg lploss: 0.00000
train epoch 439 avg loss: 1.29580 (A-MSE: 1.15651) avg lploss: 0.00000
train epoch 440 avg loss: 1.18406 (A-MSE: 1.05408) avg lploss: 0.00000
==> val epoch 440 avg loss: 2.14035 (A-MSE: 1.90820) avg lploss: 0.00000
==> test epoch 440 avg loss: 2.28743 (A-MSE: 2.05014) avg lploss: 0.00000
*** Best Val Loss: 2.07877 	 Best Test Loss: 2.28043 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 1.07537 (A-MSE: 0.95324) avg lploss: 0.00000
train epoch 442 avg loss: 1.10369 (A-MSE: 0.98355) avg lploss: 0.00000
train epoch 443 avg loss: 1.10868 (A-MSE: 0.98800) avg lploss: 0.00000
train epoch 444 avg loss: 1.13041 (A-MSE: 1.00320) avg lploss: 0.00000
train epoch 445 avg loss: 1.09888 (A-MSE: 0.97688) avg lploss: 0.00000
==> val epoch 445 avg loss: 2.25266 (A-MSE: 1.99940) avg lploss: 0.00000
==> test epoch 445 avg loss: 2.41953 (A-MSE: 2.16964) avg lploss: 0.00000
*** Best Val Loss: 2.07877 	 Best Test Loss: 2.28043 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 1.09832 (A-MSE: 0.98161) avg lploss: 0.00000
train epoch 447 avg loss: 1.00859 (A-MSE: 0.89563) avg lploss: 0.00000
train epoch 448 avg loss: 1.00758 (A-MSE: 0.89266) avg lploss: 0.00000
train epoch 449 avg loss: 1.08849 (A-MSE: 0.96752) avg lploss: 0.00000
train epoch 450 avg loss: 1.19284 (A-MSE: 1.05822) avg lploss: 0.00000
==> val epoch 450 avg loss: 2.16487 (A-MSE: 1.92311) avg lploss: 0.00000
==> test epoch 450 avg loss: 2.36947 (A-MSE: 2.12473) avg lploss: 0.00000
*** Best Val Loss: 2.07877 	 Best Test Loss: 2.28043 	 Best epoch 435
EarlyStopping counter: 3 out of 50
train epoch 451 avg loss: 1.31747 (A-MSE: 1.17491) avg lploss: 0.00000
train epoch 452 avg loss: 1.43100 (A-MSE: 1.27572) avg lploss: 0.00000
train epoch 453 avg loss: 1.20741 (A-MSE: 1.07640) avg lploss: 0.00000
train epoch 454 avg loss: 1.16914 (A-MSE: 1.03843) avg lploss: 0.00000
train epoch 455 avg loss: 1.17241 (A-MSE: 1.04621) avg lploss: 0.00000
==> val epoch 455 avg loss: 2.78051 (A-MSE: 2.50145) avg lploss: 0.00000
==> test epoch 455 avg loss: 2.77023 (A-MSE: 2.51190) avg lploss: 0.00000
*** Best Val Loss: 2.07877 	 Best Test Loss: 2.28043 	 Best epoch 435
EarlyStopping counter: 4 out of 50
train epoch 456 avg loss: 1.39016 (A-MSE: 1.23650) avg lploss: 0.00000
train epoch 457 avg loss: 1.26137 (A-MSE: 1.12022) avg lploss: 0.00000
train epoch 458 avg loss: 1.16044 (A-MSE: 1.03577) avg lploss: 0.00000
train epoch 459 avg loss: 1.08708 (A-MSE: 0.97065) avg lploss: 0.00000
train epoch 460 avg loss: 1.39775 (A-MSE: 1.24762) avg lploss: 0.00000
==> val epoch 460 avg loss: 2.49019 (A-MSE: 2.23027) avg lploss: 0.00000
==> test epoch 460 avg loss: 2.69651 (A-MSE: 2.43047) avg lploss: 0.00000
*** Best Val Loss: 2.07877 	 Best Test Loss: 2.28043 	 Best epoch 435
EarlyStopping counter: 5 out of 50
train epoch 461 avg loss: 1.27047 (A-MSE: 1.13422) avg lploss: 0.00000
train epoch 462 avg loss: 1.18380 (A-MSE: 1.05823) avg lploss: 0.00000
train epoch 463 avg loss: 1.10234 (A-MSE: 0.98053) avg lploss: 0.00000
train epoch 464 avg loss: 1.11655 (A-MSE: 0.98858) avg lploss: 0.00000
train epoch 465 avg loss: 1.03034 (A-MSE: 0.91586) avg lploss: 0.00000
==> val epoch 465 avg loss: 2.01425 (A-MSE: 1.79704) avg lploss: 0.00000
==> test epoch 465 avg loss: 2.27557 (A-MSE: 2.04467) avg lploss: 0.00000
*** Best Val Loss: 2.01425 	 Best Test Loss: 2.27557 	 Best epoch 465
Validation loss decreased (2.078767 --> 2.014250).  Saving model ...
train epoch 466 avg loss: 0.97862 (A-MSE: 0.86929) avg lploss: 0.00000
train epoch 467 avg loss: 1.01848 (A-MSE: 0.90557) avg lploss: 0.00000
train epoch 468 avg loss: 1.09738 (A-MSE: 0.97233) avg lploss: 0.00000
train epoch 469 avg loss: 1.08225 (A-MSE: 0.96479) avg lploss: 0.00000
train epoch 470 avg loss: 1.13514 (A-MSE: 1.01071) avg lploss: 0.00000
==> val epoch 470 avg loss: 2.33857 (A-MSE: 2.07627) avg lploss: 0.00000
==> test epoch 470 avg loss: 2.59443 (A-MSE: 2.32589) avg lploss: 0.00000
*** Best Val Loss: 2.01425 	 Best Test Loss: 2.27557 	 Best epoch 465
EarlyStopping counter: 1 out of 50
train epoch 471 avg loss: 1.08320 (A-MSE: 0.95982) avg lploss: 0.00000
train epoch 472 avg loss: 1.10329 (A-MSE: 0.98016) avg lploss: 0.00000
train epoch 473 avg loss: 0.98791 (A-MSE: 0.87858) avg lploss: 0.00000
train epoch 474 avg loss: 1.06446 (A-MSE: 0.94659) avg lploss: 0.00000
train epoch 475 avg loss: 1.06520 (A-MSE: 0.94533) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.89810 (A-MSE: 1.68763) avg lploss: 0.00000
==> test epoch 475 avg loss: 2.19686 (A-MSE: 1.97195) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
Validation loss decreased (2.014250 --> 1.898100).  Saving model ...
train epoch 476 avg loss: 1.03583 (A-MSE: 0.92594) avg lploss: 0.00000
train epoch 477 avg loss: 1.12546 (A-MSE: 0.99553) avg lploss: 0.00000
train epoch 478 avg loss: 1.03550 (A-MSE: 0.92265) avg lploss: 0.00000
train epoch 479 avg loss: 1.09474 (A-MSE: 0.97634) avg lploss: 0.00000
train epoch 480 avg loss: 1.07983 (A-MSE: 0.95472) avg lploss: 0.00000
==> val epoch 480 avg loss: 2.34237 (A-MSE: 2.11184) avg lploss: 0.00000
==> test epoch 480 avg loss: 2.50073 (A-MSE: 2.26496) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 1 out of 50
train epoch 481 avg loss: 1.05300 (A-MSE: 0.93636) avg lploss: 0.00000
train epoch 482 avg loss: 1.05020 (A-MSE: 0.92999) avg lploss: 0.00000
train epoch 483 avg loss: 1.10782 (A-MSE: 0.98635) avg lploss: 0.00000
train epoch 484 avg loss: 1.07790 (A-MSE: 0.95802) avg lploss: 0.00000
train epoch 485 avg loss: 1.12848 (A-MSE: 1.00521) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.94289 (A-MSE: 1.72269) avg lploss: 0.00000
==> test epoch 485 avg loss: 2.15763 (A-MSE: 1.92991) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 2 out of 50
train epoch 486 avg loss: 1.03821 (A-MSE: 0.92278) avg lploss: 0.00000
train epoch 487 avg loss: 0.99400 (A-MSE: 0.88473) avg lploss: 0.00000
train epoch 488 avg loss: 0.92524 (A-MSE: 0.81960) avg lploss: 0.00000
train epoch 489 avg loss: 0.97769 (A-MSE: 0.86939) avg lploss: 0.00000
train epoch 490 avg loss: 1.09804 (A-MSE: 0.97439) avg lploss: 0.00000
==> val epoch 490 avg loss: 2.05519 (A-MSE: 1.84007) avg lploss: 0.00000
==> test epoch 490 avg loss: 2.24581 (A-MSE: 2.02156) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 3 out of 50
train epoch 491 avg loss: 1.00111 (A-MSE: 0.89019) avg lploss: 0.00000
train epoch 492 avg loss: 0.93726 (A-MSE: 0.83007) avg lploss: 0.00000
train epoch 493 avg loss: 0.97524 (A-MSE: 0.86655) avg lploss: 0.00000
train epoch 494 avg loss: 1.05621 (A-MSE: 0.94262) avg lploss: 0.00000
train epoch 495 avg loss: 1.10668 (A-MSE: 0.98899) avg lploss: 0.00000
==> val epoch 495 avg loss: 2.31096 (A-MSE: 2.06498) avg lploss: 0.00000
==> test epoch 495 avg loss: 2.65484 (A-MSE: 2.39733) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 4 out of 50
train epoch 496 avg loss: 1.14438 (A-MSE: 1.01314) avg lploss: 0.00000
train epoch 497 avg loss: 0.96746 (A-MSE: 0.86314) avg lploss: 0.00000
train epoch 498 avg loss: 1.00582 (A-MSE: 0.89276) avg lploss: 0.00000
train epoch 499 avg loss: 1.11465 (A-MSE: 0.98822) avg lploss: 0.00000
train epoch 500 avg loss: 1.05277 (A-MSE: 0.93760) avg lploss: 0.00000
==> val epoch 500 avg loss: 2.27958 (A-MSE: 2.01537) avg lploss: 0.00000
==> test epoch 500 avg loss: 2.50260 (A-MSE: 2.24062) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 5 out of 50
train epoch 501 avg loss: 1.00203 (A-MSE: 0.89157) avg lploss: 0.00000
train epoch 502 avg loss: 0.97655 (A-MSE: 0.86612) avg lploss: 0.00000
train epoch 503 avg loss: 0.95703 (A-MSE: 0.84926) avg lploss: 0.00000
train epoch 504 avg loss: 1.02934 (A-MSE: 0.91618) avg lploss: 0.00000
train epoch 505 avg loss: 1.01862 (A-MSE: 0.90729) avg lploss: 0.00000
==> val epoch 505 avg loss: 1.90097 (A-MSE: 1.69057) avg lploss: 0.00000
==> test epoch 505 avg loss: 2.27480 (A-MSE: 2.04575) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 6 out of 50
train epoch 506 avg loss: 0.93782 (A-MSE: 0.83299) avg lploss: 0.00000
train epoch 507 avg loss: 0.92108 (A-MSE: 0.81814) avg lploss: 0.00000
train epoch 508 avg loss: 0.96541 (A-MSE: 0.85647) avg lploss: 0.00000
train epoch 509 avg loss: 0.96194 (A-MSE: 0.84964) avg lploss: 0.00000
train epoch 510 avg loss: 0.92856 (A-MSE: 0.82759) avg lploss: 0.00000
==> val epoch 510 avg loss: 2.21017 (A-MSE: 1.97216) avg lploss: 0.00000
==> test epoch 510 avg loss: 2.38019 (A-MSE: 2.13388) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 7 out of 50
train epoch 511 avg loss: 0.98195 (A-MSE: 0.87529) avg lploss: 0.00000
train epoch 512 avg loss: 0.95720 (A-MSE: 0.85409) avg lploss: 0.00000
train epoch 513 avg loss: 1.00909 (A-MSE: 0.89751) avg lploss: 0.00000
train epoch 514 avg loss: 0.90582 (A-MSE: 0.80240) avg lploss: 0.00000
train epoch 515 avg loss: 0.82033 (A-MSE: 0.72749) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.91319 (A-MSE: 1.69356) avg lploss: 0.00000
==> test epoch 515 avg loss: 2.08502 (A-MSE: 1.86379) avg lploss: 0.00000
*** Best Val Loss: 1.89810 	 Best Test Loss: 2.19686 	 Best epoch 475
EarlyStopping counter: 8 out of 50
train epoch 516 avg loss: 0.87310 (A-MSE: 0.77533) avg lploss: 0.00000
train epoch 517 avg loss: 0.91663 (A-MSE: 0.81266) avg lploss: 0.00000
train epoch 518 avg loss: 0.88857 (A-MSE: 0.79065) avg lploss: 0.00000
train epoch 519 avg loss: 0.98798 (A-MSE: 0.87736) avg lploss: 0.00000
train epoch 520 avg loss: 1.01157 (A-MSE: 0.90187) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.79431 (A-MSE: 1.59773) avg lploss: 0.00000
==> test epoch 520 avg loss: 2.02644 (A-MSE: 1.82423) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
Validation loss decreased (1.898100 --> 1.794309).  Saving model ...
train epoch 521 avg loss: 0.94152 (A-MSE: 0.84037) avg lploss: 0.00000
train epoch 522 avg loss: 0.93930 (A-MSE: 0.83188) avg lploss: 0.00000
train epoch 523 avg loss: 0.97313 (A-MSE: 0.86243) avg lploss: 0.00000
train epoch 524 avg loss: 0.91307 (A-MSE: 0.81267) avg lploss: 0.00000
train epoch 525 avg loss: 1.03370 (A-MSE: 0.92509) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.80102 (A-MSE: 1.60084) avg lploss: 0.00000
==> test epoch 525 avg loss: 2.15146 (A-MSE: 1.94549) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 1 out of 50
train epoch 526 avg loss: 1.02875 (A-MSE: 0.92059) avg lploss: 0.00000
train epoch 527 avg loss: 0.93913 (A-MSE: 0.83515) avg lploss: 0.00000
train epoch 528 avg loss: 0.96783 (A-MSE: 0.85751) avg lploss: 0.00000
train epoch 529 avg loss: 1.02714 (A-MSE: 0.91839) avg lploss: 0.00000
train epoch 530 avg loss: 0.93545 (A-MSE: 0.83079) avg lploss: 0.00000
==> val epoch 530 avg loss: 2.16915 (A-MSE: 1.94541) avg lploss: 0.00000
==> test epoch 530 avg loss: 2.33293 (A-MSE: 2.09830) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 2 out of 50
train epoch 531 avg loss: 0.96222 (A-MSE: 0.86415) avg lploss: 0.00000
train epoch 532 avg loss: 0.92464 (A-MSE: 0.82072) avg lploss: 0.00000
train epoch 533 avg loss: 1.03486 (A-MSE: 0.91682) avg lploss: 0.00000
train epoch 534 avg loss: 0.96686 (A-MSE: 0.85897) avg lploss: 0.00000
train epoch 535 avg loss: 0.91536 (A-MSE: 0.82321) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.85057 (A-MSE: 1.63376) avg lploss: 0.00000
==> test epoch 535 avg loss: 2.02615 (A-MSE: 1.80885) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 3 out of 50
train epoch 536 avg loss: 0.85659 (A-MSE: 0.75757) avg lploss: 0.00000
train epoch 537 avg loss: 0.91348 (A-MSE: 0.81266) avg lploss: 0.00000
train epoch 538 avg loss: 0.89601 (A-MSE: 0.79649) avg lploss: 0.00000
train epoch 539 avg loss: 0.85596 (A-MSE: 0.76326) avg lploss: 0.00000
train epoch 540 avg loss: 0.86536 (A-MSE: 0.76784) avg lploss: 0.00000
==> val epoch 540 avg loss: 1.97921 (A-MSE: 1.74160) avg lploss: 0.00000
==> test epoch 540 avg loss: 2.15736 (A-MSE: 1.92065) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 4 out of 50
train epoch 541 avg loss: 0.88433 (A-MSE: 0.78228) avg lploss: 0.00000
train epoch 542 avg loss: 0.86819 (A-MSE: 0.76915) avg lploss: 0.00000
train epoch 543 avg loss: 0.97988 (A-MSE: 0.87115) avg lploss: 0.00000
train epoch 544 avg loss: 1.07339 (A-MSE: 0.96498) avg lploss: 0.00000
train epoch 545 avg loss: 1.08620 (A-MSE: 0.96119) avg lploss: 0.00000
==> val epoch 545 avg loss: 2.16159 (A-MSE: 1.95463) avg lploss: 0.00000
==> test epoch 545 avg loss: 2.40952 (A-MSE: 2.17600) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 5 out of 50
train epoch 546 avg loss: 0.99452 (A-MSE: 0.88862) avg lploss: 0.00000
train epoch 547 avg loss: 0.93965 (A-MSE: 0.83717) avg lploss: 0.00000
train epoch 548 avg loss: 0.81152 (A-MSE: 0.72073) avg lploss: 0.00000
train epoch 549 avg loss: 0.81752 (A-MSE: 0.72348) avg lploss: 0.00000
train epoch 550 avg loss: 0.81311 (A-MSE: 0.72173) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.90805 (A-MSE: 1.68950) avg lploss: 0.00000
==> test epoch 550 avg loss: 2.18522 (A-MSE: 1.94517) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 6 out of 50
train epoch 551 avg loss: 1.04075 (A-MSE: 0.92611) avg lploss: 0.00000
train epoch 552 avg loss: 1.05932 (A-MSE: 0.94558) avg lploss: 0.00000
train epoch 553 avg loss: 1.00672 (A-MSE: 0.89401) avg lploss: 0.00000
train epoch 554 avg loss: 0.87199 (A-MSE: 0.77515) avg lploss: 0.00000
train epoch 555 avg loss: 0.90066 (A-MSE: 0.79645) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.97597 (A-MSE: 1.75839) avg lploss: 0.00000
==> test epoch 555 avg loss: 2.14472 (A-MSE: 1.92189) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 7 out of 50
train epoch 556 avg loss: 0.92130 (A-MSE: 0.82136) avg lploss: 0.00000
train epoch 557 avg loss: 0.94243 (A-MSE: 0.83498) avg lploss: 0.00000
train epoch 558 avg loss: 0.88598 (A-MSE: 0.78401) avg lploss: 0.00000
train epoch 559 avg loss: 0.88314 (A-MSE: 0.79005) avg lploss: 0.00000
train epoch 560 avg loss: 0.88939 (A-MSE: 0.79049) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.84093 (A-MSE: 1.64077) avg lploss: 0.00000
==> test epoch 560 avg loss: 2.17122 (A-MSE: 1.94859) avg lploss: 0.00000
*** Best Val Loss: 1.79431 	 Best Test Loss: 2.02644 	 Best epoch 520
EarlyStopping counter: 8 out of 50
train epoch 561 avg loss: 0.82312 (A-MSE: 0.72809) avg lploss: 0.00000
train epoch 562 avg loss: 0.80827 (A-MSE: 0.71747) avg lploss: 0.00000
train epoch 563 avg loss: 0.82447 (A-MSE: 0.72988) avg lploss: 0.00000
train epoch 564 avg loss: 0.83294 (A-MSE: 0.73842) avg lploss: 0.00000
train epoch 565 avg loss: 0.80869 (A-MSE: 0.71561) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.73947 (A-MSE: 1.55949) avg lploss: 0.00000
==> test epoch 565 avg loss: 1.91295 (A-MSE: 1.72018) avg lploss: 0.00000
*** Best Val Loss: 1.73947 	 Best Test Loss: 1.91295 	 Best epoch 565
Validation loss decreased (1.794309 --> 1.739466).  Saving model ...
train epoch 566 avg loss: 0.81476 (A-MSE: 0.72577) avg lploss: 0.00000
train epoch 567 avg loss: 0.89124 (A-MSE: 0.78833) avg lploss: 0.00000
train epoch 568 avg loss: 0.85438 (A-MSE: 0.75785) avg lploss: 0.00000
train epoch 569 avg loss: 0.83339 (A-MSE: 0.74003) avg lploss: 0.00000
train epoch 570 avg loss: 0.82572 (A-MSE: 0.73347) avg lploss: 0.00000
==> val epoch 570 avg loss: 1.66245 (A-MSE: 1.48714) avg lploss: 0.00000
==> test epoch 570 avg loss: 1.94958 (A-MSE: 1.76981) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
Validation loss decreased (1.739466 --> 1.662445).  Saving model ...
train epoch 571 avg loss: 0.92262 (A-MSE: 0.82688) avg lploss: 0.00000
train epoch 572 avg loss: 0.83457 (A-MSE: 0.73973) avg lploss: 0.00000
train epoch 573 avg loss: 0.79026 (A-MSE: 0.70047) avg lploss: 0.00000
train epoch 574 avg loss: 0.79355 (A-MSE: 0.70529) avg lploss: 0.00000
train epoch 575 avg loss: 0.76214 (A-MSE: 0.67723) avg lploss: 0.00000
==> val epoch 575 avg loss: 1.73502 (A-MSE: 1.53499) avg lploss: 0.00000
==> test epoch 575 avg loss: 1.97740 (A-MSE: 1.76750) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
EarlyStopping counter: 1 out of 50
train epoch 576 avg loss: 0.77130 (A-MSE: 0.68484) avg lploss: 0.00000
train epoch 577 avg loss: 0.80161 (A-MSE: 0.71187) avg lploss: 0.00000
train epoch 578 avg loss: 0.78368 (A-MSE: 0.69665) avg lploss: 0.00000
train epoch 579 avg loss: 0.91315 (A-MSE: 0.81042) avg lploss: 0.00000
train epoch 580 avg loss: 0.85421 (A-MSE: 0.76091) avg lploss: 0.00000
==> val epoch 580 avg loss: 1.89160 (A-MSE: 1.68104) avg lploss: 0.00000
==> test epoch 580 avg loss: 2.11488 (A-MSE: 1.89385) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
EarlyStopping counter: 2 out of 50
train epoch 581 avg loss: 0.79514 (A-MSE: 0.70354) avg lploss: 0.00000
train epoch 582 avg loss: 0.81739 (A-MSE: 0.72602) avg lploss: 0.00000
train epoch 583 avg loss: 0.80502 (A-MSE: 0.71447) avg lploss: 0.00000
train epoch 584 avg loss: 0.95175 (A-MSE: 0.85563) avg lploss: 0.00000
train epoch 585 avg loss: 0.86699 (A-MSE: 0.76866) avg lploss: 0.00000
==> val epoch 585 avg loss: 2.06166 (A-MSE: 1.84454) avg lploss: 0.00000
==> test epoch 585 avg loss: 2.14030 (A-MSE: 1.91470) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
EarlyStopping counter: 3 out of 50
train epoch 586 avg loss: 0.79077 (A-MSE: 0.70088) avg lploss: 0.00000
train epoch 587 avg loss: 0.83482 (A-MSE: 0.73962) avg lploss: 0.00000
train epoch 588 avg loss: 0.86716 (A-MSE: 0.76758) avg lploss: 0.00000
train epoch 589 avg loss: 0.81403 (A-MSE: 0.72098) avg lploss: 0.00000
train epoch 590 avg loss: 0.88811 (A-MSE: 0.79110) avg lploss: 0.00000
==> val epoch 590 avg loss: 1.94245 (A-MSE: 1.71563) avg lploss: 0.00000
==> test epoch 590 avg loss: 2.24957 (A-MSE: 2.00461) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
EarlyStopping counter: 4 out of 50
train epoch 591 avg loss: 0.78300 (A-MSE: 0.68882) avg lploss: 0.00000
train epoch 592 avg loss: 0.79014 (A-MSE: 0.70112) avg lploss: 0.00000
train epoch 593 avg loss: 0.72673 (A-MSE: 0.64624) avg lploss: 0.00000
train epoch 594 avg loss: 0.82239 (A-MSE: 0.72873) avg lploss: 0.00000
train epoch 595 avg loss: 0.83118 (A-MSE: 0.73853) avg lploss: 0.00000
==> val epoch 595 avg loss: 1.71491 (A-MSE: 1.53120) avg lploss: 0.00000
==> test epoch 595 avg loss: 2.01883 (A-MSE: 1.80872) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
EarlyStopping counter: 5 out of 50
train epoch 596 avg loss: 0.81269 (A-MSE: 0.72519) avg lploss: 0.00000
train epoch 597 avg loss: 0.82884 (A-MSE: 0.73587) avg lploss: 0.00000
train epoch 598 avg loss: 0.85313 (A-MSE: 0.75980) avg lploss: 0.00000
train epoch 599 avg loss: 0.84102 (A-MSE: 0.74474) avg lploss: 0.00000
train epoch 600 avg loss: 0.82809 (A-MSE: 0.73614) avg lploss: 0.00000
==> val epoch 600 avg loss: 1.67939 (A-MSE: 1.48508) avg lploss: 0.00000
==> test epoch 600 avg loss: 1.93971 (A-MSE: 1.73966) avg lploss: 0.00000
*** Best Val Loss: 1.66245 	 Best Test Loss: 1.94958 	 Best epoch 570
EarlyStopping counter: 6 out of 50
train epoch 601 avg loss: 0.75175 (A-MSE: 0.66999) avg lploss: 0.00000
train epoch 602 avg loss: 0.70222 (A-MSE: 0.62197) avg lploss: 0.00000
train epoch 603 avg loss: 0.74899 (A-MSE: 0.66253) avg lploss: 0.00000
train epoch 604 avg loss: 0.76397 (A-MSE: 0.67701) avg lploss: 0.00000
train epoch 605 avg loss: 0.82076 (A-MSE: 0.73070) avg lploss: 0.00000
==> val epoch 605 avg loss: 1.65531 (A-MSE: 1.48176) avg lploss: 0.00000
==> test epoch 605 avg loss: 1.81723 (A-MSE: 1.63148) avg lploss: 0.00000
*** Best Val Loss: 1.65531 	 Best Test Loss: 1.81723 	 Best epoch 605
Validation loss decreased (1.662445 --> 1.655311).  Saving model ...
train epoch 606 avg loss: 0.77217 (A-MSE: 0.68110) avg lploss: 0.00000
train epoch 607 avg loss: 0.75724 (A-MSE: 0.67412) avg lploss: 0.00000
train epoch 608 avg loss: 0.74759 (A-MSE: 0.66122) avg lploss: 0.00000
train epoch 609 avg loss: 0.84361 (A-MSE: 0.75060) avg lploss: 0.00000
train epoch 610 avg loss: 0.74112 (A-MSE: 0.65823) avg lploss: 0.00000
==> val epoch 610 avg loss: 1.78371 (A-MSE: 1.57633) avg lploss: 0.00000
==> test epoch 610 avg loss: 2.05951 (A-MSE: 1.83655) avg lploss: 0.00000
*** Best Val Loss: 1.65531 	 Best Test Loss: 1.81723 	 Best epoch 605
EarlyStopping counter: 1 out of 50
train epoch 611 avg loss: 0.76127 (A-MSE: 0.67742) avg lploss: 0.00000
train epoch 612 avg loss: 0.80876 (A-MSE: 0.71643) avg lploss: 0.00000
train epoch 613 avg loss: 0.86985 (A-MSE: 0.77062) avg lploss: 0.00000
train epoch 614 avg loss: 0.85029 (A-MSE: 0.75265) avg lploss: 0.00000
train epoch 615 avg loss: 0.79118 (A-MSE: 0.70604) avg lploss: 0.00000
==> val epoch 615 avg loss: 1.59368 (A-MSE: 1.41461) avg lploss: 0.00000
==> test epoch 615 avg loss: 1.72131 (A-MSE: 1.53978) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
Validation loss decreased (1.655311 --> 1.593676).  Saving model ...
train epoch 616 avg loss: 0.78887 (A-MSE: 0.70272) avg lploss: 0.00000
train epoch 617 avg loss: 0.74381 (A-MSE: 0.65994) avg lploss: 0.00000
train epoch 618 avg loss: 0.76129 (A-MSE: 0.67222) avg lploss: 0.00000
train epoch 619 avg loss: 0.83399 (A-MSE: 0.74187) avg lploss: 0.00000
train epoch 620 avg loss: 0.78587 (A-MSE: 0.69786) avg lploss: 0.00000
==> val epoch 620 avg loss: 1.67229 (A-MSE: 1.48590) avg lploss: 0.00000
==> test epoch 620 avg loss: 2.02911 (A-MSE: 1.82305) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.71684 (A-MSE: 0.63760) avg lploss: 0.00000
train epoch 622 avg loss: 0.74243 (A-MSE: 0.65350) avg lploss: 0.00000
train epoch 623 avg loss: 0.68967 (A-MSE: 0.61020) avg lploss: 0.00000
train epoch 624 avg loss: 0.73897 (A-MSE: 0.65775) avg lploss: 0.00000
train epoch 625 avg loss: 0.74105 (A-MSE: 0.65751) avg lploss: 0.00000
==> val epoch 625 avg loss: 1.76928 (A-MSE: 1.57134) avg lploss: 0.00000
==> test epoch 625 avg loss: 1.86759 (A-MSE: 1.67220) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.80510 (A-MSE: 0.71448) avg lploss: 0.00000
train epoch 627 avg loss: 0.70767 (A-MSE: 0.63086) avg lploss: 0.00000
train epoch 628 avg loss: 0.74851 (A-MSE: 0.66178) avg lploss: 0.00000
train epoch 629 avg loss: 0.82175 (A-MSE: 0.73217) avg lploss: 0.00000
train epoch 630 avg loss: 0.85411 (A-MSE: 0.75428) avg lploss: 0.00000
==> val epoch 630 avg loss: 2.08309 (A-MSE: 1.85546) avg lploss: 0.00000
==> test epoch 630 avg loss: 2.40189 (A-MSE: 2.14656) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 3 out of 50
train epoch 631 avg loss: 0.86731 (A-MSE: 0.76561) avg lploss: 0.00000
train epoch 632 avg loss: 0.85136 (A-MSE: 0.75932) avg lploss: 0.00000
train epoch 633 avg loss: 0.72120 (A-MSE: 0.64088) avg lploss: 0.00000
train epoch 634 avg loss: 0.70007 (A-MSE: 0.62226) avg lploss: 0.00000
train epoch 635 avg loss: 0.66203 (A-MSE: 0.58547) avg lploss: 0.00000
==> val epoch 635 avg loss: 1.76060 (A-MSE: 1.56976) avg lploss: 0.00000
==> test epoch 635 avg loss: 1.87615 (A-MSE: 1.68482) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 4 out of 50
train epoch 636 avg loss: 0.70882 (A-MSE: 0.62706) avg lploss: 0.00000
train epoch 637 avg loss: 0.69828 (A-MSE: 0.62090) avg lploss: 0.00000
train epoch 638 avg loss: 0.77282 (A-MSE: 0.68354) avg lploss: 0.00000
train epoch 639 avg loss: 0.78443 (A-MSE: 0.69511) avg lploss: 0.00000
train epoch 640 avg loss: 0.73516 (A-MSE: 0.65479) avg lploss: 0.00000
==> val epoch 640 avg loss: 1.63380 (A-MSE: 1.44627) avg lploss: 0.00000
==> test epoch 640 avg loss: 1.77202 (A-MSE: 1.58661) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 5 out of 50
train epoch 641 avg loss: 0.74258 (A-MSE: 0.65865) avg lploss: 0.00000
train epoch 642 avg loss: 0.76596 (A-MSE: 0.68311) avg lploss: 0.00000
train epoch 643 avg loss: 0.70350 (A-MSE: 0.61969) avg lploss: 0.00000
train epoch 644 avg loss: 0.77822 (A-MSE: 0.69117) avg lploss: 0.00000
train epoch 645 avg loss: 0.80831 (A-MSE: 0.71513) avg lploss: 0.00000
==> val epoch 645 avg loss: 1.71078 (A-MSE: 1.51626) avg lploss: 0.00000
==> test epoch 645 avg loss: 1.80293 (A-MSE: 1.60477) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 6 out of 50
train epoch 646 avg loss: 0.67627 (A-MSE: 0.59955) avg lploss: 0.00000
train epoch 647 avg loss: 0.68726 (A-MSE: 0.61136) avg lploss: 0.00000
train epoch 648 avg loss: 0.71897 (A-MSE: 0.63628) avg lploss: 0.00000
train epoch 649 avg loss: 0.65535 (A-MSE: 0.58091) avg lploss: 0.00000
train epoch 650 avg loss: 0.72736 (A-MSE: 0.64665) avg lploss: 0.00000
==> val epoch 650 avg loss: 1.75760 (A-MSE: 1.56979) avg lploss: 0.00000
==> test epoch 650 avg loss: 1.96715 (A-MSE: 1.77461) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 7 out of 50
train epoch 651 avg loss: 0.79946 (A-MSE: 0.71265) avg lploss: 0.00000
train epoch 652 avg loss: 0.71084 (A-MSE: 0.62794) avg lploss: 0.00000
train epoch 653 avg loss: 0.69306 (A-MSE: 0.61448) avg lploss: 0.00000
train epoch 654 avg loss: 0.79208 (A-MSE: 0.70404) avg lploss: 0.00000
train epoch 655 avg loss: 0.72483 (A-MSE: 0.64423) avg lploss: 0.00000
==> val epoch 655 avg loss: 1.91448 (A-MSE: 1.69854) avg lploss: 0.00000
==> test epoch 655 avg loss: 2.02805 (A-MSE: 1.80343) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 8 out of 50
train epoch 656 avg loss: 0.69772 (A-MSE: 0.61674) avg lploss: 0.00000
train epoch 657 avg loss: 0.63461 (A-MSE: 0.56258) avg lploss: 0.00000
train epoch 658 avg loss: 0.62088 (A-MSE: 0.54836) avg lploss: 0.00000
train epoch 659 avg loss: 0.68875 (A-MSE: 0.61059) avg lploss: 0.00000
train epoch 660 avg loss: 0.68225 (A-MSE: 0.60475) avg lploss: 0.00000
==> val epoch 660 avg loss: 1.82370 (A-MSE: 1.61938) avg lploss: 0.00000
==> test epoch 660 avg loss: 1.85854 (A-MSE: 1.65910) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 9 out of 50
train epoch 661 avg loss: 0.63959 (A-MSE: 0.56724) avg lploss: 0.00000
train epoch 662 avg loss: 0.70879 (A-MSE: 0.62590) avg lploss: 0.00000
train epoch 663 avg loss: 0.67937 (A-MSE: 0.60114) avg lploss: 0.00000
train epoch 664 avg loss: 0.64866 (A-MSE: 0.57587) avg lploss: 0.00000
train epoch 665 avg loss: 0.64072 (A-MSE: 0.56837) avg lploss: 0.00000
==> val epoch 665 avg loss: 1.60858 (A-MSE: 1.42961) avg lploss: 0.00000
==> test epoch 665 avg loss: 1.84379 (A-MSE: 1.64393) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 10 out of 50
train epoch 666 avg loss: 0.68055 (A-MSE: 0.60157) avg lploss: 0.00000
train epoch 667 avg loss: 0.67300 (A-MSE: 0.59671) avg lploss: 0.00000
train epoch 668 avg loss: 0.68914 (A-MSE: 0.61338) avg lploss: 0.00000
train epoch 669 avg loss: 0.77911 (A-MSE: 0.69251) avg lploss: 0.00000
train epoch 670 avg loss: 0.73760 (A-MSE: 0.65532) avg lploss: 0.00000
==> val epoch 670 avg loss: 1.60212 (A-MSE: 1.41164) avg lploss: 0.00000
==> test epoch 670 avg loss: 1.87256 (A-MSE: 1.66870) avg lploss: 0.00000
*** Best Val Loss: 1.59368 	 Best Test Loss: 1.72131 	 Best epoch 615
EarlyStopping counter: 11 out of 50
train epoch 671 avg loss: 0.78734 (A-MSE: 0.70144) avg lploss: 0.00000
train epoch 672 avg loss: 0.78441 (A-MSE: 0.69948) avg lploss: 0.00000
train epoch 673 avg loss: 0.80273 (A-MSE: 0.71213) avg lploss: 0.00000
train epoch 674 avg loss: 0.73441 (A-MSE: 0.65233) avg lploss: 0.00000
train epoch 675 avg loss: 0.76862 (A-MSE: 0.67916) avg lploss: 0.00000
==> val epoch 675 avg loss: 1.57010 (A-MSE: 1.39904) avg lploss: 0.00000
==> test epoch 675 avg loss: 1.89647 (A-MSE: 1.70748) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
Validation loss decreased (1.593676 --> 1.570100).  Saving model ...
train epoch 676 avg loss: 0.69379 (A-MSE: 0.61531) avg lploss: 0.00000
train epoch 677 avg loss: 0.66213 (A-MSE: 0.58802) avg lploss: 0.00000
train epoch 678 avg loss: 0.66094 (A-MSE: 0.58390) avg lploss: 0.00000
train epoch 679 avg loss: 0.73500 (A-MSE: 0.65176) avg lploss: 0.00000
train epoch 680 avg loss: 0.83171 (A-MSE: 0.74017) avg lploss: 0.00000
==> val epoch 680 avg loss: 1.63762 (A-MSE: 1.45373) avg lploss: 0.00000
==> test epoch 680 avg loss: 1.77288 (A-MSE: 1.58237) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 1 out of 50
train epoch 681 avg loss: 0.69262 (A-MSE: 0.61241) avg lploss: 0.00000
train epoch 682 avg loss: 0.73428 (A-MSE: 0.64960) avg lploss: 0.00000
train epoch 683 avg loss: 0.68466 (A-MSE: 0.60866) avg lploss: 0.00000
train epoch 684 avg loss: 0.73008 (A-MSE: 0.64796) avg lploss: 0.00000
train epoch 685 avg loss: 0.70684 (A-MSE: 0.62595) avg lploss: 0.00000
==> val epoch 685 avg loss: 1.81743 (A-MSE: 1.60772) avg lploss: 0.00000
==> test epoch 685 avg loss: 1.95093 (A-MSE: 1.75144) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 2 out of 50
train epoch 686 avg loss: 0.76847 (A-MSE: 0.67893) avg lploss: 0.00000
train epoch 687 avg loss: 0.73891 (A-MSE: 0.65353) avg lploss: 0.00000
train epoch 688 avg loss: 0.65978 (A-MSE: 0.58697) avg lploss: 0.00000
train epoch 689 avg loss: 0.64948 (A-MSE: 0.57461) avg lploss: 0.00000
train epoch 690 avg loss: 0.62348 (A-MSE: 0.55035) avg lploss: 0.00000
==> val epoch 690 avg loss: 1.65920 (A-MSE: 1.48424) avg lploss: 0.00000
==> test epoch 690 avg loss: 1.67230 (A-MSE: 1.49682) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 3 out of 50
train epoch 691 avg loss: 0.65632 (A-MSE: 0.57888) avg lploss: 0.00000
train epoch 692 avg loss: 0.68440 (A-MSE: 0.60403) avg lploss: 0.00000
train epoch 693 avg loss: 0.73730 (A-MSE: 0.65501) avg lploss: 0.00000
train epoch 694 avg loss: 0.71453 (A-MSE: 0.63594) avg lploss: 0.00000
train epoch 695 avg loss: 0.72843 (A-MSE: 0.64918) avg lploss: 0.00000
==> val epoch 695 avg loss: 1.79366 (A-MSE: 1.60163) avg lploss: 0.00000
==> test epoch 695 avg loss: 1.98386 (A-MSE: 1.77940) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 4 out of 50
train epoch 696 avg loss: 0.69523 (A-MSE: 0.61678) avg lploss: 0.00000
train epoch 697 avg loss: 0.65732 (A-MSE: 0.58286) avg lploss: 0.00000
train epoch 698 avg loss: 0.70860 (A-MSE: 0.62557) avg lploss: 0.00000
train epoch 699 avg loss: 0.71135 (A-MSE: 0.63432) avg lploss: 0.00000
train epoch 700 avg loss: 0.63978 (A-MSE: 0.56882) avg lploss: 0.00000
==> val epoch 700 avg loss: 1.59433 (A-MSE: 1.42006) avg lploss: 0.00000
==> test epoch 700 avg loss: 1.67992 (A-MSE: 1.50254) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 5 out of 50
train epoch 701 avg loss: 0.71081 (A-MSE: 0.62965) avg lploss: 0.00000
train epoch 702 avg loss: 0.68105 (A-MSE: 0.60598) avg lploss: 0.00000
train epoch 703 avg loss: 0.62044 (A-MSE: 0.54961) avg lploss: 0.00000
train epoch 704 avg loss: 0.65369 (A-MSE: 0.57883) avg lploss: 0.00000
train epoch 705 avg loss: 0.64549 (A-MSE: 0.57167) avg lploss: 0.00000
==> val epoch 705 avg loss: 1.63173 (A-MSE: 1.44978) avg lploss: 0.00000
==> test epoch 705 avg loss: 1.67726 (A-MSE: 1.49628) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 6 out of 50
train epoch 706 avg loss: 0.60402 (A-MSE: 0.53634) avg lploss: 0.00000
train epoch 707 avg loss: 0.60158 (A-MSE: 0.53123) avg lploss: 0.00000
train epoch 708 avg loss: 0.61694 (A-MSE: 0.54854) avg lploss: 0.00000
train epoch 709 avg loss: 0.63362 (A-MSE: 0.56038) avg lploss: 0.00000
train epoch 710 avg loss: 0.61013 (A-MSE: 0.54023) avg lploss: 0.00000
==> val epoch 710 avg loss: 1.74507 (A-MSE: 1.56287) avg lploss: 0.00000
==> test epoch 710 avg loss: 1.93085 (A-MSE: 1.72677) avg lploss: 0.00000
*** Best Val Loss: 1.57010 	 Best Test Loss: 1.89647 	 Best epoch 675
EarlyStopping counter: 7 out of 50
train epoch 711 avg loss: 0.61010 (A-MSE: 0.54132) avg lploss: 0.00000
train epoch 712 avg loss: 0.63207 (A-MSE: 0.56264) avg lploss: 0.00000
train epoch 713 avg loss: 0.64124 (A-MSE: 0.56503) avg lploss: 0.00000
train epoch 714 avg loss: 0.59604 (A-MSE: 0.52962) avg lploss: 0.00000
train epoch 715 avg loss: 0.60453 (A-MSE: 0.53663) avg lploss: 0.00000
==> val epoch 715 avg loss: 1.49013 (A-MSE: 1.32167) avg lploss: 0.00000
==> test epoch 715 avg loss: 1.57070 (A-MSE: 1.40848) avg lploss: 0.00000
*** Best Val Loss: 1.49013 	 Best Test Loss: 1.57070 	 Best epoch 715
Validation loss decreased (1.570100 --> 1.490130).  Saving model ...
train epoch 716 avg loss: 0.57862 (A-MSE: 0.51299) avg lploss: 0.00000
train epoch 717 avg loss: 0.67104 (A-MSE: 0.59677) avg lploss: 0.00000
train epoch 718 avg loss: 0.63662 (A-MSE: 0.56157) avg lploss: 0.00000
train epoch 719 avg loss: 0.62122 (A-MSE: 0.55245) avg lploss: 0.00000
train epoch 720 avg loss: 0.58868 (A-MSE: 0.52100) avg lploss: 0.00000
==> val epoch 720 avg loss: 1.62982 (A-MSE: 1.43585) avg lploss: 0.00000
==> test epoch 720 avg loss: 1.80737 (A-MSE: 1.61491) avg lploss: 0.00000
*** Best Val Loss: 1.49013 	 Best Test Loss: 1.57070 	 Best epoch 715
EarlyStopping counter: 1 out of 50
train epoch 721 avg loss: 0.62706 (A-MSE: 0.55830) avg lploss: 0.00000
train epoch 722 avg loss: 0.66292 (A-MSE: 0.59199) avg lploss: 0.00000
train epoch 723 avg loss: 0.64551 (A-MSE: 0.57395) avg lploss: 0.00000
train epoch 724 avg loss: 0.67003 (A-MSE: 0.59208) avg lploss: 0.00000
train epoch 725 avg loss: 0.60966 (A-MSE: 0.54100) avg lploss: 0.00000
==> val epoch 725 avg loss: 1.50697 (A-MSE: 1.33022) avg lploss: 0.00000
==> test epoch 725 avg loss: 1.68327 (A-MSE: 1.49940) avg lploss: 0.00000
*** Best Val Loss: 1.49013 	 Best Test Loss: 1.57070 	 Best epoch 715
EarlyStopping counter: 2 out of 50
train epoch 726 avg loss: 0.58371 (A-MSE: 0.51711) avg lploss: 0.00000
train epoch 727 avg loss: 0.66013 (A-MSE: 0.58327) avg lploss: 0.00000
train epoch 728 avg loss: 0.63758 (A-MSE: 0.56150) avg lploss: 0.00000
train epoch 729 avg loss: 0.59432 (A-MSE: 0.52762) avg lploss: 0.00000
train epoch 730 avg loss: 0.63133 (A-MSE: 0.55909) avg lploss: 0.00000
==> val epoch 730 avg loss: 1.68058 (A-MSE: 1.49670) avg lploss: 0.00000
==> test epoch 730 avg loss: 1.95870 (A-MSE: 1.75565) avg lploss: 0.00000
*** Best Val Loss: 1.49013 	 Best Test Loss: 1.57070 	 Best epoch 715
EarlyStopping counter: 3 out of 50
train epoch 731 avg loss: 0.59916 (A-MSE: 0.53207) avg lploss: 0.00000
train epoch 732 avg loss: 0.63665 (A-MSE: 0.56617) avg lploss: 0.00000
train epoch 733 avg loss: 0.68312 (A-MSE: 0.60254) avg lploss: 0.00000
train epoch 734 avg loss: 0.66086 (A-MSE: 0.58748) avg lploss: 0.00000
train epoch 735 avg loss: 0.60162 (A-MSE: 0.53317) avg lploss: 0.00000
==> val epoch 735 avg loss: 1.44964 (A-MSE: 1.29538) avg lploss: 0.00000
==> test epoch 735 avg loss: 1.57672 (A-MSE: 1.41253) avg lploss: 0.00000
*** Best Val Loss: 1.44964 	 Best Test Loss: 1.57672 	 Best epoch 735
Validation loss decreased (1.490130 --> 1.449640).  Saving model ...
train epoch 736 avg loss: 0.59161 (A-MSE: 0.52648) avg lploss: 0.00000
train epoch 737 avg loss: 0.59149 (A-MSE: 0.52240) avg lploss: 0.00000
train epoch 738 avg loss: 0.62197 (A-MSE: 0.54936) avg lploss: 0.00000
train epoch 739 avg loss: 0.57406 (A-MSE: 0.50946) avg lploss: 0.00000
train epoch 740 avg loss: 0.56426 (A-MSE: 0.50074) avg lploss: 0.00000
==> val epoch 740 avg loss: 1.66228 (A-MSE: 1.47979) avg lploss: 0.00000
==> test epoch 740 avg loss: 1.72286 (A-MSE: 1.54636) avg lploss: 0.00000
*** Best Val Loss: 1.44964 	 Best Test Loss: 1.57672 	 Best epoch 735
EarlyStopping counter: 1 out of 50
train epoch 741 avg loss: 0.59289 (A-MSE: 0.52331) avg lploss: 0.00000
train epoch 742 avg loss: 0.60197 (A-MSE: 0.53256) avg lploss: 0.00000
train epoch 743 avg loss: 0.59612 (A-MSE: 0.52611) avg lploss: 0.00000
train epoch 744 avg loss: 0.72803 (A-MSE: 0.64540) avg lploss: 0.00000
train epoch 745 avg loss: 0.64092 (A-MSE: 0.57131) avg lploss: 0.00000
==> val epoch 745 avg loss: 1.66628 (A-MSE: 1.49425) avg lploss: 0.00000
==> test epoch 745 avg loss: 1.79080 (A-MSE: 1.60000) avg lploss: 0.00000
*** Best Val Loss: 1.44964 	 Best Test Loss: 1.57672 	 Best epoch 735
EarlyStopping counter: 2 out of 50
train epoch 746 avg loss: 0.59742 (A-MSE: 0.53063) avg lploss: 0.00000
train epoch 747 avg loss: 0.58793 (A-MSE: 0.52141) avg lploss: 0.00000
train epoch 748 avg loss: 0.55898 (A-MSE: 0.49289) avg lploss: 0.00000
train epoch 749 avg loss: 0.59533 (A-MSE: 0.52657) avg lploss: 0.00000
train epoch 750 avg loss: 0.57975 (A-MSE: 0.51367) avg lploss: 0.00000
==> val epoch 750 avg loss: 1.55950 (A-MSE: 1.39137) avg lploss: 0.00000
==> test epoch 750 avg loss: 1.70830 (A-MSE: 1.52887) avg lploss: 0.00000
*** Best Val Loss: 1.44964 	 Best Test Loss: 1.57672 	 Best epoch 735
EarlyStopping counter: 3 out of 50
train epoch 751 avg loss: 0.55662 (A-MSE: 0.49270) avg lploss: 0.00000
train epoch 752 avg loss: 0.54089 (A-MSE: 0.47758) avg lploss: 0.00000
train epoch 753 avg loss: 0.59931 (A-MSE: 0.52878) avg lploss: 0.00000
train epoch 754 avg loss: 0.60066 (A-MSE: 0.53115) avg lploss: 0.00000
train epoch 755 avg loss: 0.60202 (A-MSE: 0.53416) avg lploss: 0.00000
==> val epoch 755 avg loss: 1.42730 (A-MSE: 1.26779) avg lploss: 0.00000
==> test epoch 755 avg loss: 1.64129 (A-MSE: 1.45758) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
Validation loss decreased (1.449640 --> 1.427300).  Saving model ...
train epoch 756 avg loss: 0.61534 (A-MSE: 0.54759) avg lploss: 0.00000
train epoch 757 avg loss: 0.60531 (A-MSE: 0.53607) avg lploss: 0.00000
train epoch 758 avg loss: 0.52836 (A-MSE: 0.46707) avg lploss: 0.00000
train epoch 759 avg loss: 0.53848 (A-MSE: 0.47269) avg lploss: 0.00000
train epoch 760 avg loss: 0.57677 (A-MSE: 0.51071) avg lploss: 0.00000
==> val epoch 760 avg loss: 1.47779 (A-MSE: 1.30160) avg lploss: 0.00000
==> test epoch 760 avg loss: 1.65019 (A-MSE: 1.47968) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 1 out of 50
train epoch 761 avg loss: 0.64585 (A-MSE: 0.57062) avg lploss: 0.00000
train epoch 762 avg loss: 0.55523 (A-MSE: 0.48611) avg lploss: 0.00000
train epoch 763 avg loss: 0.62291 (A-MSE: 0.55508) avg lploss: 0.00000
train epoch 764 avg loss: 0.61976 (A-MSE: 0.55251) avg lploss: 0.00000
train epoch 765 avg loss: 0.59694 (A-MSE: 0.52580) avg lploss: 0.00000
==> val epoch 765 avg loss: 1.57425 (A-MSE: 1.38332) avg lploss: 0.00000
==> test epoch 765 avg loss: 1.74746 (A-MSE: 1.54875) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 2 out of 50
train epoch 766 avg loss: 0.55016 (A-MSE: 0.48362) avg lploss: 0.00000
train epoch 767 avg loss: 0.55265 (A-MSE: 0.48763) avg lploss: 0.00000
train epoch 768 avg loss: 0.54187 (A-MSE: 0.48163) avg lploss: 0.00000
train epoch 769 avg loss: 0.57069 (A-MSE: 0.50315) avg lploss: 0.00000
train epoch 770 avg loss: 0.55500 (A-MSE: 0.48975) avg lploss: 0.00000
==> val epoch 770 avg loss: 1.48039 (A-MSE: 1.30478) avg lploss: 0.00000
==> test epoch 770 avg loss: 1.64183 (A-MSE: 1.45910) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 3 out of 50
train epoch 771 avg loss: 0.58223 (A-MSE: 0.51669) avg lploss: 0.00000
train epoch 772 avg loss: 0.60919 (A-MSE: 0.53773) avg lploss: 0.00000
train epoch 773 avg loss: 0.60963 (A-MSE: 0.53803) avg lploss: 0.00000
train epoch 774 avg loss: 0.55905 (A-MSE: 0.49346) avg lploss: 0.00000
train epoch 775 avg loss: 0.60655 (A-MSE: 0.53647) avg lploss: 0.00000
==> val epoch 775 avg loss: 1.43373 (A-MSE: 1.29227) avg lploss: 0.00000
==> test epoch 775 avg loss: 1.57774 (A-MSE: 1.42379) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 4 out of 50
train epoch 776 avg loss: 0.51578 (A-MSE: 0.45546) avg lploss: 0.00000
train epoch 777 avg loss: 0.52920 (A-MSE: 0.46479) avg lploss: 0.00000
train epoch 778 avg loss: 0.66570 (A-MSE: 0.59246) avg lploss: 0.00000
train epoch 779 avg loss: 0.63226 (A-MSE: 0.55741) avg lploss: 0.00000
train epoch 780 avg loss: 0.56907 (A-MSE: 0.50486) avg lploss: 0.00000
==> val epoch 780 avg loss: 1.91558 (A-MSE: 1.69056) avg lploss: 0.00000
==> test epoch 780 avg loss: 2.02954 (A-MSE: 1.80733) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 5 out of 50
train epoch 781 avg loss: 0.59662 (A-MSE: 0.52919) avg lploss: 0.00000
train epoch 782 avg loss: 0.55318 (A-MSE: 0.49039) avg lploss: 0.00000
train epoch 783 avg loss: 0.51080 (A-MSE: 0.45206) avg lploss: 0.00000
train epoch 784 avg loss: 0.54299 (A-MSE: 0.47879) avg lploss: 0.00000
train epoch 785 avg loss: 0.60740 (A-MSE: 0.53926) avg lploss: 0.00000
==> val epoch 785 avg loss: 1.46644 (A-MSE: 1.27185) avg lploss: 0.00000
==> test epoch 785 avg loss: 1.61765 (A-MSE: 1.42418) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 6 out of 50
train epoch 786 avg loss: 0.59090 (A-MSE: 0.51879) avg lploss: 0.00000
train epoch 787 avg loss: 0.60998 (A-MSE: 0.54121) avg lploss: 0.00000
train epoch 788 avg loss: 0.56003 (A-MSE: 0.49757) avg lploss: 0.00000
train epoch 789 avg loss: 0.56769 (A-MSE: 0.49795) avg lploss: 0.00000
train epoch 790 avg loss: 0.56917 (A-MSE: 0.50033) avg lploss: 0.00000
==> val epoch 790 avg loss: 1.55521 (A-MSE: 1.39001) avg lploss: 0.00000
==> test epoch 790 avg loss: 1.73580 (A-MSE: 1.56969) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 7 out of 50
train epoch 791 avg loss: 0.58273 (A-MSE: 0.51633) avg lploss: 0.00000
train epoch 792 avg loss: 0.57142 (A-MSE: 0.50934) avg lploss: 0.00000
train epoch 793 avg loss: 0.53247 (A-MSE: 0.46951) avg lploss: 0.00000
train epoch 794 avg loss: 0.52908 (A-MSE: 0.46689) avg lploss: 0.00000
train epoch 795 avg loss: 0.56388 (A-MSE: 0.49692) avg lploss: 0.00000
==> val epoch 795 avg loss: 1.73563 (A-MSE: 1.54429) avg lploss: 0.00000
==> test epoch 795 avg loss: 1.93344 (A-MSE: 1.74021) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 8 out of 50
train epoch 796 avg loss: 0.61712 (A-MSE: 0.54360) avg lploss: 0.00000
train epoch 797 avg loss: 0.56383 (A-MSE: 0.50018) avg lploss: 0.00000
train epoch 798 avg loss: 0.53518 (A-MSE: 0.46943) avg lploss: 0.00000
train epoch 799 avg loss: 0.53241 (A-MSE: 0.47072) avg lploss: 0.00000
train epoch 800 avg loss: 0.50825 (A-MSE: 0.44814) avg lploss: 0.00000
==> val epoch 800 avg loss: 1.62483 (A-MSE: 1.44127) avg lploss: 0.00000
==> test epoch 800 avg loss: 1.71788 (A-MSE: 1.52535) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 9 out of 50
train epoch 801 avg loss: 0.49692 (A-MSE: 0.43769) avg lploss: 0.00000
train epoch 802 avg loss: 0.48815 (A-MSE: 0.42925) avg lploss: 0.00000
train epoch 803 avg loss: 0.50004 (A-MSE: 0.44179) avg lploss: 0.00000
train epoch 804 avg loss: 0.53630 (A-MSE: 0.47208) avg lploss: 0.00000
train epoch 805 avg loss: 0.52140 (A-MSE: 0.45850) avg lploss: 0.00000
==> val epoch 805 avg loss: 1.65147 (A-MSE: 1.46634) avg lploss: 0.00000
==> test epoch 805 avg loss: 1.75272 (A-MSE: 1.56671) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 10 out of 50
train epoch 806 avg loss: 0.49351 (A-MSE: 0.43559) avg lploss: 0.00000
train epoch 807 avg loss: 0.48750 (A-MSE: 0.42844) avg lploss: 0.00000
train epoch 808 avg loss: 0.50721 (A-MSE: 0.44707) avg lploss: 0.00000
train epoch 809 avg loss: 0.52275 (A-MSE: 0.46107) avg lploss: 0.00000
train epoch 810 avg loss: 0.51994 (A-MSE: 0.45638) avg lploss: 0.00000
==> val epoch 810 avg loss: 1.53287 (A-MSE: 1.37759) avg lploss: 0.00000
==> test epoch 810 avg loss: 1.73354 (A-MSE: 1.56324) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 11 out of 50
train epoch 811 avg loss: 0.52068 (A-MSE: 0.46069) avg lploss: 0.00000
train epoch 812 avg loss: 0.49826 (A-MSE: 0.43838) avg lploss: 0.00000
train epoch 813 avg loss: 0.50975 (A-MSE: 0.44821) avg lploss: 0.00000
train epoch 814 avg loss: 0.53039 (A-MSE: 0.46770) avg lploss: 0.00000
train epoch 815 avg loss: 0.51730 (A-MSE: 0.45745) avg lploss: 0.00000
==> val epoch 815 avg loss: 1.79399 (A-MSE: 1.58642) avg lploss: 0.00000
==> test epoch 815 avg loss: 2.11307 (A-MSE: 1.86553) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 12 out of 50
train epoch 816 avg loss: 0.50078 (A-MSE: 0.44221) avg lploss: 0.00000
train epoch 817 avg loss: 0.49375 (A-MSE: 0.43439) avg lploss: 0.00000
train epoch 818 avg loss: 0.53469 (A-MSE: 0.47011) avg lploss: 0.00000
train epoch 819 avg loss: 0.57447 (A-MSE: 0.50672) avg lploss: 0.00000
train epoch 820 avg loss: 0.51554 (A-MSE: 0.45614) avg lploss: 0.00000
==> val epoch 820 avg loss: 1.46940 (A-MSE: 1.29125) avg lploss: 0.00000
==> test epoch 820 avg loss: 1.54575 (A-MSE: 1.36865) avg lploss: 0.00000
*** Best Val Loss: 1.42730 	 Best Test Loss: 1.64129 	 Best epoch 755
EarlyStopping counter: 13 out of 50
train epoch 821 avg loss: 0.55537 (A-MSE: 0.48814) avg lploss: 0.00000
train epoch 822 avg loss: 0.56663 (A-MSE: 0.50237) avg lploss: 0.00000
train epoch 823 avg loss: 0.53962 (A-MSE: 0.47470) avg lploss: 0.00000
train epoch 824 avg loss: 0.48954 (A-MSE: 0.43264) avg lploss: 0.00000
train epoch 825 avg loss: 0.45901 (A-MSE: 0.40199) avg lploss: 0.00000
==> val epoch 825 avg loss: 1.36034 (A-MSE: 1.20024) avg lploss: 0.00000
==> test epoch 825 avg loss: 1.54772 (A-MSE: 1.37587) avg lploss: 0.00000
*** Best Val Loss: 1.36034 	 Best Test Loss: 1.54772 	 Best epoch 825
Validation loss decreased (1.427300 --> 1.360337).  Saving model ...
train epoch 826 avg loss: 0.47972 (A-MSE: 0.42118) avg lploss: 0.00000
train epoch 827 avg loss: 0.53177 (A-MSE: 0.46971) avg lploss: 0.00000
train epoch 828 avg loss: 0.55170 (A-MSE: 0.49106) avg lploss: 0.00000
train epoch 829 avg loss: 0.48270 (A-MSE: 0.42751) avg lploss: 0.00000
train epoch 830 avg loss: 0.48051 (A-MSE: 0.42112) avg lploss: 0.00000
==> val epoch 830 avg loss: 1.38464 (A-MSE: 1.23296) avg lploss: 0.00000
==> test epoch 830 avg loss: 1.54853 (A-MSE: 1.37471) avg lploss: 0.00000
*** Best Val Loss: 1.36034 	 Best Test Loss: 1.54772 	 Best epoch 825
EarlyStopping counter: 1 out of 50
train epoch 831 avg loss: 0.57732 (A-MSE: 0.50514) avg lploss: 0.00000
train epoch 832 avg loss: 0.59484 (A-MSE: 0.52400) avg lploss: 0.00000
train epoch 833 avg loss: 0.52648 (A-MSE: 0.46416) avg lploss: 0.00000
train epoch 834 avg loss: 0.50181 (A-MSE: 0.44407) avg lploss: 0.00000
train epoch 835 avg loss: 0.48535 (A-MSE: 0.42931) avg lploss: 0.00000
==> val epoch 835 avg loss: 1.56750 (A-MSE: 1.40672) avg lploss: 0.00000
==> test epoch 835 avg loss: 1.69452 (A-MSE: 1.52406) avg lploss: 0.00000
*** Best Val Loss: 1.36034 	 Best Test Loss: 1.54772 	 Best epoch 825
EarlyStopping counter: 2 out of 50
train epoch 836 avg loss: 0.52063 (A-MSE: 0.45983) avg lploss: 0.00000
train epoch 837 avg loss: 0.59443 (A-MSE: 0.52539) avg lploss: 0.00000
train epoch 838 avg loss: 0.51304 (A-MSE: 0.45294) avg lploss: 0.00000
train epoch 839 avg loss: 0.48293 (A-MSE: 0.42623) avg lploss: 0.00000
train epoch 840 avg loss: 0.47518 (A-MSE: 0.41898) avg lploss: 0.00000
==> val epoch 840 avg loss: 1.38533 (A-MSE: 1.24786) avg lploss: 0.00000
==> test epoch 840 avg loss: 1.52893 (A-MSE: 1.37875) avg lploss: 0.00000
*** Best Val Loss: 1.36034 	 Best Test Loss: 1.54772 	 Best epoch 825
EarlyStopping counter: 3 out of 50
train epoch 841 avg loss: 0.55180 (A-MSE: 0.48467) avg lploss: 0.00000
train epoch 842 avg loss: 0.54546 (A-MSE: 0.47993) avg lploss: 0.00000
train epoch 843 avg loss: 0.44149 (A-MSE: 0.38940) avg lploss: 0.00000
train epoch 844 avg loss: 0.43016 (A-MSE: 0.37733) avg lploss: 0.00000
train epoch 845 avg loss: 0.45807 (A-MSE: 0.40423) avg lploss: 0.00000
==> val epoch 845 avg loss: 1.41077 (A-MSE: 1.25874) avg lploss: 0.00000
==> test epoch 845 avg loss: 1.59359 (A-MSE: 1.42171) avg lploss: 0.00000
*** Best Val Loss: 1.36034 	 Best Test Loss: 1.54772 	 Best epoch 825
EarlyStopping counter: 4 out of 50
train epoch 846 avg loss: 0.44139 (A-MSE: 0.39090) avg lploss: 0.00000
train epoch 847 avg loss: 0.43936 (A-MSE: 0.39000) avg lploss: 0.00000
train epoch 848 avg loss: 0.47202 (A-MSE: 0.41631) avg lploss: 0.00000
train epoch 849 avg loss: 0.53084 (A-MSE: 0.46513) avg lploss: 0.00000
train epoch 850 avg loss: 0.50311 (A-MSE: 0.44199) avg lploss: 0.00000
==> val epoch 850 avg loss: 1.28454 (A-MSE: 1.15560) avg lploss: 0.00000
==> test epoch 850 avg loss: 1.44244 (A-MSE: 1.31188) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
Validation loss decreased (1.360337 --> 1.284535).  Saving model ...
train epoch 851 avg loss: 0.46819 (A-MSE: 0.41235) avg lploss: 0.00000
train epoch 852 avg loss: 0.49307 (A-MSE: 0.43577) avg lploss: 0.00000
train epoch 853 avg loss: 0.48783 (A-MSE: 0.43293) avg lploss: 0.00000
train epoch 854 avg loss: 0.47739 (A-MSE: 0.42069) avg lploss: 0.00000
train epoch 855 avg loss: 0.57547 (A-MSE: 0.50340) avg lploss: 0.00000
==> val epoch 855 avg loss: 1.48914 (A-MSE: 1.32597) avg lploss: 0.00000
==> test epoch 855 avg loss: 1.63080 (A-MSE: 1.46702) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 1 out of 50
train epoch 856 avg loss: 0.53275 (A-MSE: 0.47137) avg lploss: 0.00000
train epoch 857 avg loss: 0.49139 (A-MSE: 0.43240) avg lploss: 0.00000
train epoch 858 avg loss: 0.46884 (A-MSE: 0.41204) avg lploss: 0.00000
train epoch 859 avg loss: 0.48482 (A-MSE: 0.42741) avg lploss: 0.00000
train epoch 860 avg loss: 0.46567 (A-MSE: 0.41170) avg lploss: 0.00000
==> val epoch 860 avg loss: 1.37580 (A-MSE: 1.21721) avg lploss: 0.00000
==> test epoch 860 avg loss: 1.52511 (A-MSE: 1.35651) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 2 out of 50
train epoch 861 avg loss: 0.44211 (A-MSE: 0.38928) avg lploss: 0.00000
train epoch 862 avg loss: 0.43523 (A-MSE: 0.38282) avg lploss: 0.00000
train epoch 863 avg loss: 0.43612 (A-MSE: 0.38643) avg lploss: 0.00000
train epoch 864 avg loss: 0.51337 (A-MSE: 0.45415) avg lploss: 0.00000
train epoch 865 avg loss: 0.52487 (A-MSE: 0.46240) avg lploss: 0.00000
==> val epoch 865 avg loss: 1.44376 (A-MSE: 1.29418) avg lploss: 0.00000
==> test epoch 865 avg loss: 1.73479 (A-MSE: 1.55651) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 3 out of 50
train epoch 866 avg loss: 0.45020 (A-MSE: 0.39865) avg lploss: 0.00000
train epoch 867 avg loss: 0.44297 (A-MSE: 0.39088) avg lploss: 0.00000
train epoch 868 avg loss: 0.42817 (A-MSE: 0.37913) avg lploss: 0.00000
train epoch 869 avg loss: 0.48782 (A-MSE: 0.43156) avg lploss: 0.00000
train epoch 870 avg loss: 0.49171 (A-MSE: 0.43444) avg lploss: 0.00000
==> val epoch 870 avg loss: 1.43007 (A-MSE: 1.27246) avg lploss: 0.00000
==> test epoch 870 avg loss: 1.55275 (A-MSE: 1.38794) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 4 out of 50
train epoch 871 avg loss: 0.46545 (A-MSE: 0.40869) avg lploss: 0.00000
train epoch 872 avg loss: 0.48338 (A-MSE: 0.42566) avg lploss: 0.00000
train epoch 873 avg loss: 0.51962 (A-MSE: 0.46211) avg lploss: 0.00000
train epoch 874 avg loss: 0.60397 (A-MSE: 0.52626) avg lploss: 0.00000
train epoch 875 avg loss: 0.56714 (A-MSE: 0.49987) avg lploss: 0.00000
==> val epoch 875 avg loss: 1.34098 (A-MSE: 1.19178) avg lploss: 0.00000
==> test epoch 875 avg loss: 1.50794 (A-MSE: 1.35460) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 5 out of 50
train epoch 876 avg loss: 0.44206 (A-MSE: 0.38995) avg lploss: 0.00000
train epoch 877 avg loss: 0.55600 (A-MSE: 0.49011) avg lploss: 0.00000
train epoch 878 avg loss: 0.62053 (A-MSE: 0.54664) avg lploss: 0.00000
train epoch 879 avg loss: 0.48194 (A-MSE: 0.42589) avg lploss: 0.00000
train epoch 880 avg loss: 0.43912 (A-MSE: 0.38633) avg lploss: 0.00000
==> val epoch 880 avg loss: 1.33150 (A-MSE: 1.20316) avg lploss: 0.00000
==> test epoch 880 avg loss: 1.46049 (A-MSE: 1.31518) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 6 out of 50
train epoch 881 avg loss: 0.44408 (A-MSE: 0.39291) avg lploss: 0.00000
train epoch 882 avg loss: 0.43769 (A-MSE: 0.38310) avg lploss: 0.00000
train epoch 883 avg loss: 0.43364 (A-MSE: 0.38253) avg lploss: 0.00000
train epoch 884 avg loss: 0.45235 (A-MSE: 0.40248) avg lploss: 0.00000
train epoch 885 avg loss: 0.42199 (A-MSE: 0.37325) avg lploss: 0.00000
==> val epoch 885 avg loss: 1.53873 (A-MSE: 1.37508) avg lploss: 0.00000
==> test epoch 885 avg loss: 1.68333 (A-MSE: 1.50317) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 7 out of 50
train epoch 886 avg loss: 0.45358 (A-MSE: 0.40124) avg lploss: 0.00000
train epoch 887 avg loss: 0.46032 (A-MSE: 0.40879) avg lploss: 0.00000
train epoch 888 avg loss: 0.43309 (A-MSE: 0.38100) avg lploss: 0.00000
train epoch 889 avg loss: 0.45577 (A-MSE: 0.40313) avg lploss: 0.00000
train epoch 890 avg loss: 0.45476 (A-MSE: 0.40018) avg lploss: 0.00000
==> val epoch 890 avg loss: 1.35506 (A-MSE: 1.20024) avg lploss: 0.00000
==> test epoch 890 avg loss: 1.48151 (A-MSE: 1.31919) avg lploss: 0.00000
*** Best Val Loss: 1.28454 	 Best Test Loss: 1.44244 	 Best epoch 850
EarlyStopping counter: 8 out of 50
train epoch 891 avg loss: 0.43881 (A-MSE: 0.38841) avg lploss: 0.00000
train epoch 892 avg loss: 0.43374 (A-MSE: 0.38425) avg lploss: 0.00000
train epoch 893 avg loss: 0.47118 (A-MSE: 0.41617) avg lploss: 0.00000
train epoch 894 avg loss: 0.45038 (A-MSE: 0.39975) avg lploss: 0.00000
train epoch 895 avg loss: 0.40616 (A-MSE: 0.35766) avg lploss: 0.00000
==> val epoch 895 avg loss: 1.11865 (A-MSE: 1.01244) avg lploss: 0.00000
==> test epoch 895 avg loss: 1.21311 (A-MSE: 1.10222) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
Validation loss decreased (1.284535 --> 1.118653).  Saving model ...
train epoch 896 avg loss: 0.39994 (A-MSE: 0.35169) avg lploss: 0.00000
train epoch 897 avg loss: 0.42519 (A-MSE: 0.37393) avg lploss: 0.00000
train epoch 898 avg loss: 0.44063 (A-MSE: 0.39113) avg lploss: 0.00000
train epoch 899 avg loss: 0.40773 (A-MSE: 0.35905) avg lploss: 0.00000
train epoch 900 avg loss: 0.43851 (A-MSE: 0.39177) avg lploss: 0.00000
==> val epoch 900 avg loss: 1.44202 (A-MSE: 1.28833) avg lploss: 0.00000
==> test epoch 900 avg loss: 1.53717 (A-MSE: 1.38755) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 1 out of 50
train epoch 901 avg loss: 0.42021 (A-MSE: 0.37090) avg lploss: 0.00000
train epoch 902 avg loss: 0.41319 (A-MSE: 0.36622) avg lploss: 0.00000
train epoch 903 avg loss: 0.44448 (A-MSE: 0.39322) avg lploss: 0.00000
train epoch 904 avg loss: 0.44907 (A-MSE: 0.39720) avg lploss: 0.00000
train epoch 905 avg loss: 0.45746 (A-MSE: 0.40417) avg lploss: 0.00000
==> val epoch 905 avg loss: 1.34224 (A-MSE: 1.22202) avg lploss: 0.00000
==> test epoch 905 avg loss: 1.43594 (A-MSE: 1.31443) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 2 out of 50
train epoch 906 avg loss: 0.42997 (A-MSE: 0.37444) avg lploss: 0.00000
train epoch 907 avg loss: 0.41288 (A-MSE: 0.36371) avg lploss: 0.00000
train epoch 908 avg loss: 0.36536 (A-MSE: 0.32307) avg lploss: 0.00000
train epoch 909 avg loss: 0.35826 (A-MSE: 0.31750) avg lploss: 0.00000
train epoch 910 avg loss: 0.39532 (A-MSE: 0.35033) avg lploss: 0.00000
==> val epoch 910 avg loss: 1.24037 (A-MSE: 1.13111) avg lploss: 0.00000
==> test epoch 910 avg loss: 1.37152 (A-MSE: 1.24062) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 3 out of 50
train epoch 911 avg loss: 0.41112 (A-MSE: 0.36375) avg lploss: 0.00000
train epoch 912 avg loss: 0.43854 (A-MSE: 0.38748) avg lploss: 0.00000
train epoch 913 avg loss: 0.50303 (A-MSE: 0.44853) avg lploss: 0.00000
train epoch 914 avg loss: 0.58362 (A-MSE: 0.52120) avg lploss: 0.00000
train epoch 915 avg loss: 0.50508 (A-MSE: 0.44367) avg lploss: 0.00000
==> val epoch 915 avg loss: 1.29192 (A-MSE: 1.14869) avg lploss: 0.00000
==> test epoch 915 avg loss: 1.50168 (A-MSE: 1.34253) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 4 out of 50
train epoch 916 avg loss: 0.43998 (A-MSE: 0.39029) avg lploss: 0.00000
train epoch 917 avg loss: 0.45887 (A-MSE: 0.40535) avg lploss: 0.00000
train epoch 918 avg loss: 0.39328 (A-MSE: 0.34929) avg lploss: 0.00000
train epoch 919 avg loss: 0.39847 (A-MSE: 0.35202) avg lploss: 0.00000
train epoch 920 avg loss: 0.43082 (A-MSE: 0.38210) avg lploss: 0.00000
==> val epoch 920 avg loss: 1.17702 (A-MSE: 1.05795) avg lploss: 0.00000
==> test epoch 920 avg loss: 1.27380 (A-MSE: 1.14081) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 5 out of 50
train epoch 921 avg loss: 0.40537 (A-MSE: 0.35896) avg lploss: 0.00000
train epoch 922 avg loss: 0.40938 (A-MSE: 0.36286) avg lploss: 0.00000
train epoch 923 avg loss: 0.39326 (A-MSE: 0.34759) avg lploss: 0.00000
train epoch 924 avg loss: 0.36783 (A-MSE: 0.32505) avg lploss: 0.00000
train epoch 925 avg loss: 0.38954 (A-MSE: 0.34149) avg lploss: 0.00000
==> val epoch 925 avg loss: 1.43547 (A-MSE: 1.29236) avg lploss: 0.00000
==> test epoch 925 avg loss: 1.58139 (A-MSE: 1.43094) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 6 out of 50
train epoch 926 avg loss: 0.41713 (A-MSE: 0.37292) avg lploss: 0.00000
train epoch 927 avg loss: 0.45928 (A-MSE: 0.40697) avg lploss: 0.00000
train epoch 928 avg loss: 0.40731 (A-MSE: 0.35867) avg lploss: 0.00000
train epoch 929 avg loss: 0.37871 (A-MSE: 0.33476) avg lploss: 0.00000
train epoch 930 avg loss: 0.40485 (A-MSE: 0.35753) avg lploss: 0.00000
==> val epoch 930 avg loss: 1.35077 (A-MSE: 1.21705) avg lploss: 0.00000
==> test epoch 930 avg loss: 1.42933 (A-MSE: 1.28426) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 7 out of 50
train epoch 931 avg loss: 0.43019 (A-MSE: 0.37789) avg lploss: 0.00000
train epoch 932 avg loss: 0.45181 (A-MSE: 0.39879) avg lploss: 0.00000
train epoch 933 avg loss: 0.49992 (A-MSE: 0.44594) avg lploss: 0.00000
train epoch 934 avg loss: 1.89603 (A-MSE: 1.64714) avg lploss: 0.00000
train epoch 935 avg loss: 1.29134 (A-MSE: 1.12994) avg lploss: 0.00000
==> val epoch 935 avg loss: 1.42014 (A-MSE: 1.26876) avg lploss: 0.00000
==> test epoch 935 avg loss: 1.55561 (A-MSE: 1.39218) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 8 out of 50
train epoch 936 avg loss: 0.72010 (A-MSE: 0.63031) avg lploss: 0.00000
train epoch 937 avg loss: 0.59988 (A-MSE: 0.53049) avg lploss: 0.00000
train epoch 938 avg loss: 0.51670 (A-MSE: 0.45160) avg lploss: 0.00000
train epoch 939 avg loss: 0.48799 (A-MSE: 0.43083) avg lploss: 0.00000
train epoch 940 avg loss: 0.53259 (A-MSE: 0.47098) avg lploss: 0.00000
==> val epoch 940 avg loss: 1.19306 (A-MSE: 1.07574) avg lploss: 0.00000
==> test epoch 940 avg loss: 1.34872 (A-MSE: 1.23123) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 9 out of 50
train epoch 941 avg loss: 0.46190 (A-MSE: 0.40775) avg lploss: 0.00000
train epoch 942 avg loss: 0.41730 (A-MSE: 0.36761) avg lploss: 0.00000
train epoch 943 avg loss: 0.43948 (A-MSE: 0.39030) avg lploss: 0.00000
train epoch 944 avg loss: 0.44037 (A-MSE: 0.38994) avg lploss: 0.00000
train epoch 945 avg loss: 0.42485 (A-MSE: 0.37598) avg lploss: 0.00000
==> val epoch 945 avg loss: 1.28560 (A-MSE: 1.16207) avg lploss: 0.00000
==> test epoch 945 avg loss: 1.42814 (A-MSE: 1.29175) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 10 out of 50
train epoch 946 avg loss: 0.39537 (A-MSE: 0.34761) avg lploss: 0.00000
train epoch 947 avg loss: 0.36567 (A-MSE: 0.32073) avg lploss: 0.00000
train epoch 948 avg loss: 0.35081 (A-MSE: 0.30935) avg lploss: 0.00000
train epoch 949 avg loss: 0.34184 (A-MSE: 0.30215) avg lploss: 0.00000
train epoch 950 avg loss: 0.38259 (A-MSE: 0.33574) avg lploss: 0.00000
==> val epoch 950 avg loss: 1.14784 (A-MSE: 1.03561) avg lploss: 0.00000
==> test epoch 950 avg loss: 1.33445 (A-MSE: 1.20741) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 11 out of 50
train epoch 951 avg loss: 0.36847 (A-MSE: 0.32773) avg lploss: 0.00000
train epoch 952 avg loss: 0.45205 (A-MSE: 0.39677) avg lploss: 0.00000
train epoch 953 avg loss: 0.46224 (A-MSE: 0.41063) avg lploss: 0.00000
train epoch 954 avg loss: 0.42440 (A-MSE: 0.37462) avg lploss: 0.00000
train epoch 955 avg loss: 0.43848 (A-MSE: 0.38559) avg lploss: 0.00000
==> val epoch 955 avg loss: 1.12860 (A-MSE: 1.03083) avg lploss: 0.00000
==> test epoch 955 avg loss: 1.31386 (A-MSE: 1.20056) avg lploss: 0.00000
*** Best Val Loss: 1.11865 	 Best Test Loss: 1.21311 	 Best epoch 895
EarlyStopping counter: 12 out of 50
train epoch 956 avg loss: 0.37114 (A-MSE: 0.32690) avg lploss: 0.00000
train epoch 957 avg loss: 0.35706 (A-MSE: 0.31684) avg lploss: 0.00000
train epoch 958 avg loss: 0.34490 (A-MSE: 0.30504) avg lploss: 0.00000
train epoch 959 avg loss: 0.32430 (A-MSE: 0.28577) avg lploss: 0.00000
train epoch 960 avg loss: 0.37424 (A-MSE: 0.32791) avg lploss: 0.00000
==> val epoch 960 avg loss: 1.10995 (A-MSE: 1.01088) avg lploss: 0.00000
==> test epoch 960 avg loss: 1.21638 (A-MSE: 1.11396) avg lploss: 0.00000
*** Best Val Loss: 1.10995 	 Best Test Loss: 1.21638 	 Best epoch 960
Validation loss decreased (1.118653 --> 1.109952).  Saving model ...
train epoch 961 avg loss: 0.37601 (A-MSE: 0.33049) avg lploss: 0.00000
train epoch 962 avg loss: 0.35999 (A-MSE: 0.31839) avg lploss: 0.00000
train epoch 963 avg loss: 0.36894 (A-MSE: 0.32664) avg lploss: 0.00000
train epoch 964 avg loss: 0.35365 (A-MSE: 0.31303) avg lploss: 0.00000
train epoch 965 avg loss: 0.33916 (A-MSE: 0.29869) avg lploss: 0.00000
==> val epoch 965 avg loss: 1.23407 (A-MSE: 1.10858) avg lploss: 0.00000
==> test epoch 965 avg loss: 1.36151 (A-MSE: 1.23115) avg lploss: 0.00000
*** Best Val Loss: 1.10995 	 Best Test Loss: 1.21638 	 Best epoch 960
EarlyStopping counter: 1 out of 50
train epoch 966 avg loss: 0.36088 (A-MSE: 0.32027) avg lploss: 0.00000
train epoch 967 avg loss: 0.37440 (A-MSE: 0.33416) avg lploss: 0.00000
train epoch 968 avg loss: 0.37279 (A-MSE: 0.32958) avg lploss: 0.00000
train epoch 969 avg loss: 0.35666 (A-MSE: 0.31793) avg lploss: 0.00000
train epoch 970 avg loss: 0.31958 (A-MSE: 0.28305) avg lploss: 0.00000
==> val epoch 970 avg loss: 1.10951 (A-MSE: 1.00362) avg lploss: 0.00000
==> test epoch 970 avg loss: 1.17900 (A-MSE: 1.06866) avg lploss: 0.00000
*** Best Val Loss: 1.10951 	 Best Test Loss: 1.17900 	 Best epoch 970
Validation loss decreased (1.109952 --> 1.109514).  Saving model ...
train epoch 971 avg loss: 0.31549 (A-MSE: 0.27808) avg lploss: 0.00000
train epoch 972 avg loss: 0.35823 (A-MSE: 0.31551) avg lploss: 0.00000
train epoch 973 avg loss: 0.36814 (A-MSE: 0.32606) avg lploss: 0.00000
train epoch 974 avg loss: 0.33389 (A-MSE: 0.29550) avg lploss: 0.00000
train epoch 975 avg loss: 0.36718 (A-MSE: 0.32661) avg lploss: 0.00000
==> val epoch 975 avg loss: 1.13990 (A-MSE: 1.02178) avg lploss: 0.00000
==> test epoch 975 avg loss: 1.16925 (A-MSE: 1.06081) avg lploss: 0.00000
*** Best Val Loss: 1.10951 	 Best Test Loss: 1.17900 	 Best epoch 970
EarlyStopping counter: 1 out of 50
train epoch 976 avg loss: 0.35692 (A-MSE: 0.31673) avg lploss: 0.00000
train epoch 977 avg loss: 0.36496 (A-MSE: 0.32317) avg lploss: 0.00000
train epoch 978 avg loss: 0.35934 (A-MSE: 0.31889) avg lploss: 0.00000
train epoch 979 avg loss: 0.41157 (A-MSE: 0.36163) avg lploss: 0.00000
train epoch 980 avg loss: 0.39519 (A-MSE: 0.34686) avg lploss: 0.00000
==> val epoch 980 avg loss: 1.18218 (A-MSE: 1.06401) avg lploss: 0.00000
==> test epoch 980 avg loss: 1.37951 (A-MSE: 1.24501) avg lploss: 0.00000
*** Best Val Loss: 1.10951 	 Best Test Loss: 1.17900 	 Best epoch 970
EarlyStopping counter: 2 out of 50
train epoch 981 avg loss: 0.35505 (A-MSE: 0.31383) avg lploss: 0.00000
train epoch 982 avg loss: 0.33418 (A-MSE: 0.29479) avg lploss: 0.00000
train epoch 983 avg loss: 0.34118 (A-MSE: 0.30129) avg lploss: 0.00000
train epoch 984 avg loss: 0.34025 (A-MSE: 0.30107) avg lploss: 0.00000
train epoch 985 avg loss: 0.33470 (A-MSE: 0.29718) avg lploss: 0.00000
==> val epoch 985 avg loss: 1.32812 (A-MSE: 1.15643) avg lploss: 0.00000
==> test epoch 985 avg loss: 1.40300 (A-MSE: 1.25265) avg lploss: 0.00000
*** Best Val Loss: 1.10951 	 Best Test Loss: 1.17900 	 Best epoch 970
EarlyStopping counter: 3 out of 50
train epoch 986 avg loss: 0.37532 (A-MSE: 0.32952) avg lploss: 0.00000
train epoch 987 avg loss: 0.43200 (A-MSE: 0.38209) avg lploss: 0.00000
train epoch 988 avg loss: 0.40454 (A-MSE: 0.35758) avg lploss: 0.00000
train epoch 989 avg loss: 0.37781 (A-MSE: 0.33478) avg lploss: 0.00000
train epoch 990 avg loss: 0.40660 (A-MSE: 0.36055) avg lploss: 0.00000
==> val epoch 990 avg loss: 1.10832 (A-MSE: 1.01648) avg lploss: 0.00000
==> test epoch 990 avg loss: 1.19691 (A-MSE: 1.10511) avg lploss: 0.00000
*** Best Val Loss: 1.10832 	 Best Test Loss: 1.19691 	 Best epoch 990
Validation loss decreased (1.109514 --> 1.108322).  Saving model ...
train epoch 991 avg loss: 0.39336 (A-MSE: 0.34671) avg lploss: 0.00000
train epoch 992 avg loss: 0.35993 (A-MSE: 0.31665) avg lploss: 0.00000
train epoch 993 avg loss: 0.37274 (A-MSE: 0.33143) avg lploss: 0.00000
train epoch 994 avg loss: 0.35770 (A-MSE: 0.31429) avg lploss: 0.00000
train epoch 995 avg loss: 0.31948 (A-MSE: 0.28149) avg lploss: 0.00000
==> val epoch 995 avg loss: 1.13658 (A-MSE: 1.03400) avg lploss: 0.00000
==> test epoch 995 avg loss: 1.27879 (A-MSE: 1.16601) avg lploss: 0.00000
*** Best Val Loss: 1.10832 	 Best Test Loss: 1.19691 	 Best epoch 990
EarlyStopping counter: 1 out of 50
train epoch 996 avg loss: 0.31737 (A-MSE: 0.28107) avg lploss: 0.00000
train epoch 997 avg loss: 0.30722 (A-MSE: 0.27087) avg lploss: 0.00000
train epoch 998 avg loss: 0.32767 (A-MSE: 0.28971) avg lploss: 0.00000
train epoch 999 avg loss: 0.33067 (A-MSE: 0.29083) avg lploss: 0.00000
train epoch 1000 avg loss: 0.36334 (A-MSE: 0.32428) avg lploss: 0.00000
==> val epoch 1000 avg loss: 1.18300 (A-MSE: 1.05927) avg lploss: 0.00000
==> test epoch 1000 avg loss: 1.35248 (A-MSE: 1.23157) avg lploss: 0.00000
*** Best Val Loss: 1.10832 	 Best Test Loss: 1.19691 	 Best epoch 990
EarlyStopping counter: 2 out of 50
train epoch 1001 avg loss: 0.43673 (A-MSE: 0.38154) avg lploss: 0.00000
train epoch 1002 avg loss: 0.34023 (A-MSE: 0.30272) avg lploss: 0.00000
train epoch 1003 avg loss: 0.34896 (A-MSE: 0.30987) avg lploss: 0.00000
train epoch 1004 avg loss: 0.31954 (A-MSE: 0.28179) avg lploss: 0.00000
train epoch 1005 avg loss: 0.29061 (A-MSE: 0.25638) avg lploss: 0.00000
==> val epoch 1005 avg loss: 1.08559 (A-MSE: 0.98433) avg lploss: 0.00000
==> test epoch 1005 avg loss: 1.13082 (A-MSE: 1.03395) avg lploss: 0.00000
*** Best Val Loss: 1.08559 	 Best Test Loss: 1.13082 	 Best epoch 1005
Validation loss decreased (1.108322 --> 1.085591).  Saving model ...
train epoch 1006 avg loss: 0.34210 (A-MSE: 0.30471) avg lploss: 0.00000
train epoch 1007 avg loss: 0.32342 (A-MSE: 0.28451) avg lploss: 0.00000
train epoch 1008 avg loss: 0.35254 (A-MSE: 0.31067) avg lploss: 0.00000
train epoch 1009 avg loss: 0.38285 (A-MSE: 0.33874) avg lploss: 0.00000
train epoch 1010 avg loss: 0.39458 (A-MSE: 0.34910) avg lploss: 0.00000
==> val epoch 1010 avg loss: 1.05374 (A-MSE: 0.95746) avg lploss: 0.00000
==> test epoch 1010 avg loss: 1.14039 (A-MSE: 1.05446) avg lploss: 0.00000
*** Best Val Loss: 1.05374 	 Best Test Loss: 1.14039 	 Best epoch 1010
Validation loss decreased (1.085591 --> 1.053741).  Saving model ...
train epoch 1011 avg loss: 0.32009 (A-MSE: 0.28381) avg lploss: 0.00000
train epoch 1012 avg loss: 0.31038 (A-MSE: 0.27447) avg lploss: 0.00000
train epoch 1013 avg loss: 0.31551 (A-MSE: 0.27930) avg lploss: 0.00000
train epoch 1014 avg loss: 0.34561 (A-MSE: 0.30553) avg lploss: 0.00000
train epoch 1015 avg loss: 0.31852 (A-MSE: 0.28163) avg lploss: 0.00000
==> val epoch 1015 avg loss: 1.11416 (A-MSE: 1.01150) avg lploss: 0.00000
==> test epoch 1015 avg loss: 1.25020 (A-MSE: 1.13117) avg lploss: 0.00000
*** Best Val Loss: 1.05374 	 Best Test Loss: 1.14039 	 Best epoch 1010
EarlyStopping counter: 1 out of 50
train epoch 1016 avg loss: 0.33016 (A-MSE: 0.29094) avg lploss: 0.00000
train epoch 1017 avg loss: 0.30023 (A-MSE: 0.26474) avg lploss: 0.00000
train epoch 1018 avg loss: 0.29766 (A-MSE: 0.26493) avg lploss: 0.00000
train epoch 1019 avg loss: 0.31887 (A-MSE: 0.28062) avg lploss: 0.00000
train epoch 1020 avg loss: 0.32909 (A-MSE: 0.29183) avg lploss: 0.00000
==> val epoch 1020 avg loss: 1.06562 (A-MSE: 0.96077) avg lploss: 0.00000
==> test epoch 1020 avg loss: 1.22966 (A-MSE: 1.12311) avg lploss: 0.00000
*** Best Val Loss: 1.05374 	 Best Test Loss: 1.14039 	 Best epoch 1010
EarlyStopping counter: 2 out of 50
train epoch 1021 avg loss: 0.31199 (A-MSE: 0.27548) avg lploss: 0.00000
train epoch 1022 avg loss: 0.31254 (A-MSE: 0.27879) avg lploss: 0.00000
train epoch 1023 avg loss: 0.30521 (A-MSE: 0.26948) avg lploss: 0.00000
train epoch 1024 avg loss: 0.37312 (A-MSE: 0.32792) avg lploss: 0.00000
train epoch 1025 avg loss: 0.34578 (A-MSE: 0.30492) avg lploss: 0.00000
==> val epoch 1025 avg loss: 1.04597 (A-MSE: 0.94875) avg lploss: 0.00000
==> test epoch 1025 avg loss: 1.26211 (A-MSE: 1.15827) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
Validation loss decreased (1.053741 --> 1.045966).  Saving model ...
train epoch 1026 avg loss: 0.33366 (A-MSE: 0.29559) avg lploss: 0.00000
train epoch 1027 avg loss: 0.38002 (A-MSE: 0.33335) avg lploss: 0.00000
train epoch 1028 avg loss: 0.32482 (A-MSE: 0.28566) avg lploss: 0.00000
train epoch 1029 avg loss: 0.30537 (A-MSE: 0.27054) avg lploss: 0.00000
train epoch 1030 avg loss: 0.30297 (A-MSE: 0.26843) avg lploss: 0.00000
==> val epoch 1030 avg loss: 1.07602 (A-MSE: 0.97505) avg lploss: 0.00000
==> test epoch 1030 avg loss: 1.14341 (A-MSE: 1.04892) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
EarlyStopping counter: 1 out of 50
train epoch 1031 avg loss: 0.29952 (A-MSE: 0.26516) avg lploss: 0.00000
train epoch 1032 avg loss: 0.31092 (A-MSE: 0.27395) avg lploss: 0.00000
train epoch 1033 avg loss: 0.33548 (A-MSE: 0.29354) avg lploss: 0.00000
train epoch 1034 avg loss: 0.35143 (A-MSE: 0.30990) avg lploss: 0.00000
train epoch 1035 avg loss: 0.33453 (A-MSE: 0.29624) avg lploss: 0.00000
==> val epoch 1035 avg loss: 1.06789 (A-MSE: 0.97768) avg lploss: 0.00000
==> test epoch 1035 avg loss: 1.16964 (A-MSE: 1.07867) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
EarlyStopping counter: 2 out of 50
train epoch 1036 avg loss: 0.31829 (A-MSE: 0.28110) avg lploss: 0.00000
train epoch 1037 avg loss: 0.32470 (A-MSE: 0.28742) avg lploss: 0.00000
train epoch 1038 avg loss: 0.35861 (A-MSE: 0.31824) avg lploss: 0.00000
train epoch 1039 avg loss: 0.37163 (A-MSE: 0.33001) avg lploss: 0.00000
train epoch 1040 avg loss: 0.30011 (A-MSE: 0.26577) avg lploss: 0.00000
==> val epoch 1040 avg loss: 1.13978 (A-MSE: 1.03903) avg lploss: 0.00000
==> test epoch 1040 avg loss: 1.22686 (A-MSE: 1.13663) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
EarlyStopping counter: 3 out of 50
train epoch 1041 avg loss: 0.29684 (A-MSE: 0.26182) avg lploss: 0.00000
train epoch 1042 avg loss: 0.33781 (A-MSE: 0.29783) avg lploss: 0.00000
train epoch 1043 avg loss: 0.31631 (A-MSE: 0.28080) avg lploss: 0.00000
train epoch 1044 avg loss: 0.33801 (A-MSE: 0.29793) avg lploss: 0.00000
train epoch 1045 avg loss: 0.33281 (A-MSE: 0.29608) avg lploss: 0.00000
==> val epoch 1045 avg loss: 1.24812 (A-MSE: 1.12177) avg lploss: 0.00000
==> test epoch 1045 avg loss: 1.32212 (A-MSE: 1.20898) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
EarlyStopping counter: 4 out of 50
train epoch 1046 avg loss: 0.32328 (A-MSE: 0.28695) avg lploss: 0.00000
train epoch 1047 avg loss: 0.31326 (A-MSE: 0.27414) avg lploss: 0.00000
train epoch 1048 avg loss: 0.30448 (A-MSE: 0.27000) avg lploss: 0.00000
train epoch 1049 avg loss: 0.31860 (A-MSE: 0.28330) avg lploss: 0.00000
train epoch 1050 avg loss: 0.32907 (A-MSE: 0.29075) avg lploss: 0.00000
==> val epoch 1050 avg loss: 1.24900 (A-MSE: 1.10641) avg lploss: 0.00000
==> test epoch 1050 avg loss: 1.31438 (A-MSE: 1.18574) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
EarlyStopping counter: 5 out of 50
train epoch 1051 avg loss: 0.32840 (A-MSE: 0.28901) avg lploss: 0.00000
train epoch 1052 avg loss: 0.29096 (A-MSE: 0.25597) avg lploss: 0.00000
train epoch 1053 avg loss: 0.25967 (A-MSE: 0.22908) avg lploss: 0.00000
train epoch 1054 avg loss: 0.27793 (A-MSE: 0.24580) avg lploss: 0.00000
train epoch 1055 avg loss: 0.30005 (A-MSE: 0.26609) avg lploss: 0.00000
==> val epoch 1055 avg loss: 1.05838 (A-MSE: 0.96331) avg lploss: 0.00000
==> test epoch 1055 avg loss: 1.11827 (A-MSE: 1.03211) avg lploss: 0.00000
*** Best Val Loss: 1.04597 	 Best Test Loss: 1.26211 	 Best epoch 1025
EarlyStopping counter: 6 out of 50
train epoch 1056 avg loss: 0.27903 (A-MSE: 0.24782) avg lploss: 0.00000
train epoch 1057 avg loss: 0.28596 (A-MSE: 0.25449) avg lploss: 0.00000
train epoch 1058 avg loss: 0.34378 (A-MSE: 0.30563) avg lploss: 0.00000
train epoch 1059 avg loss: 0.35244 (A-MSE: 0.31057) avg lploss: 0.00000
train epoch 1060 avg loss: 0.35111 (A-MSE: 0.30997) avg lploss: 0.00000
==> val epoch 1060 avg loss: 1.02468 (A-MSE: 0.93814) avg lploss: 0.00000
==> test epoch 1060 avg loss: 1.12609 (A-MSE: 1.03548) avg lploss: 0.00000
*** Best Val Loss: 1.02468 	 Best Test Loss: 1.12609 	 Best epoch 1060
Validation loss decreased (1.045966 --> 1.024677).  Saving model ...
train epoch 1061 avg loss: 0.34794 (A-MSE: 0.30715) avg lploss: 0.00000
train epoch 1062 avg loss: 0.31247 (A-MSE: 0.27539) avg lploss: 0.00000
train epoch 1063 avg loss: 0.30827 (A-MSE: 0.27608) avg lploss: 0.00000
train epoch 1064 avg loss: 0.31546 (A-MSE: 0.27843) avg lploss: 0.00000
train epoch 1065 avg loss: 0.34571 (A-MSE: 0.30924) avg lploss: 0.00000
==> val epoch 1065 avg loss: 1.01114 (A-MSE: 0.91454) avg lploss: 0.00000
==> test epoch 1065 avg loss: 1.05524 (A-MSE: 0.97982) avg lploss: 0.00000
*** Best Val Loss: 1.01114 	 Best Test Loss: 1.05524 	 Best epoch 1065
Validation loss decreased (1.024677 --> 1.011142).  Saving model ...
train epoch 1066 avg loss: 0.40179 (A-MSE: 0.35549) avg lploss: 0.00000
train epoch 1067 avg loss: 0.39082 (A-MSE: 0.34411) avg lploss: 0.00000
train epoch 1068 avg loss: 0.33275 (A-MSE: 0.29337) avg lploss: 0.00000
train epoch 1069 avg loss: 0.30072 (A-MSE: 0.26480) avg lploss: 0.00000
train epoch 1070 avg loss: 0.29798 (A-MSE: 0.26386) avg lploss: 0.00000
==> val epoch 1070 avg loss: 1.01942 (A-MSE: 0.92238) avg lploss: 0.00000
==> test epoch 1070 avg loss: 1.08872 (A-MSE: 0.99694) avg lploss: 0.00000
*** Best Val Loss: 1.01114 	 Best Test Loss: 1.05524 	 Best epoch 1065
EarlyStopping counter: 1 out of 50
train epoch 1071 avg loss: 0.37480 (A-MSE: 0.33087) avg lploss: 0.00000
train epoch 1072 avg loss: 0.34369 (A-MSE: 0.30436) avg lploss: 0.00000
train epoch 1073 avg loss: 0.28223 (A-MSE: 0.25160) avg lploss: 0.00000
train epoch 1074 avg loss: 0.27447 (A-MSE: 0.24310) avg lploss: 0.00000
train epoch 1075 avg loss: 0.27149 (A-MSE: 0.23983) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.93042 (A-MSE: 0.83795) avg lploss: 0.00000
==> test epoch 1075 avg loss: 1.02331 (A-MSE: 0.94181) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
Validation loss decreased (1.011142 --> 0.930418).  Saving model ...
train epoch 1076 avg loss: 0.26468 (A-MSE: 0.23484) avg lploss: 0.00000
train epoch 1077 avg loss: 0.27072 (A-MSE: 0.23892) avg lploss: 0.00000
train epoch 1078 avg loss: 0.29560 (A-MSE: 0.26083) avg lploss: 0.00000
train epoch 1079 avg loss: 0.30367 (A-MSE: 0.26891) avg lploss: 0.00000
train epoch 1080 avg loss: 0.27038 (A-MSE: 0.23941) avg lploss: 0.00000
==> val epoch 1080 avg loss: 1.03822 (A-MSE: 0.94357) avg lploss: 0.00000
==> test epoch 1080 avg loss: 1.13378 (A-MSE: 1.04473) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 1 out of 50
train epoch 1081 avg loss: 0.29234 (A-MSE: 0.25908) avg lploss: 0.00000
train epoch 1082 avg loss: 0.38622 (A-MSE: 0.33911) avg lploss: 0.00000
train epoch 1083 avg loss: 0.36841 (A-MSE: 0.32643) avg lploss: 0.00000
train epoch 1084 avg loss: 0.31589 (A-MSE: 0.28147) avg lploss: 0.00000
train epoch 1085 avg loss: 0.33183 (A-MSE: 0.29315) avg lploss: 0.00000
==> val epoch 1085 avg loss: 1.08536 (A-MSE: 0.98250) avg lploss: 0.00000
==> test epoch 1085 avg loss: 1.19217 (A-MSE: 1.09235) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 2 out of 50
train epoch 1086 avg loss: 0.30093 (A-MSE: 0.26685) avg lploss: 0.00000
train epoch 1087 avg loss: 0.27316 (A-MSE: 0.24163) avg lploss: 0.00000
train epoch 1088 avg loss: 0.25080 (A-MSE: 0.22224) avg lploss: 0.00000
train epoch 1089 avg loss: 0.25623 (A-MSE: 0.22695) avg lploss: 0.00000
train epoch 1090 avg loss: 0.25958 (A-MSE: 0.22876) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.94961 (A-MSE: 0.85232) avg lploss: 0.00000
==> test epoch 1090 avg loss: 1.05393 (A-MSE: 0.95282) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 3 out of 50
train epoch 1091 avg loss: 0.25367 (A-MSE: 0.22515) avg lploss: 0.00000
train epoch 1092 avg loss: 0.29127 (A-MSE: 0.25916) avg lploss: 0.00000
train epoch 1093 avg loss: 0.27543 (A-MSE: 0.24231) avg lploss: 0.00000
train epoch 1094 avg loss: 0.29075 (A-MSE: 0.25752) avg lploss: 0.00000
train epoch 1095 avg loss: 0.31017 (A-MSE: 0.27632) avg lploss: 0.00000
==> val epoch 1095 avg loss: 1.12857 (A-MSE: 1.02453) avg lploss: 0.00000
==> test epoch 1095 avg loss: 1.21771 (A-MSE: 1.11906) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 4 out of 50
train epoch 1096 avg loss: 0.31157 (A-MSE: 0.27368) avg lploss: 0.00000
train epoch 1097 avg loss: 0.33856 (A-MSE: 0.29681) avg lploss: 0.00000
train epoch 1098 avg loss: 0.30009 (A-MSE: 0.26458) avg lploss: 0.00000
train epoch 1099 avg loss: 0.29792 (A-MSE: 0.26386) avg lploss: 0.00000
train epoch 1100 avg loss: 0.29868 (A-MSE: 0.26256) avg lploss: 0.00000
==> val epoch 1100 avg loss: 1.00448 (A-MSE: 0.90779) avg lploss: 0.00000
==> test epoch 1100 avg loss: 1.16054 (A-MSE: 1.06537) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 5 out of 50
train epoch 1101 avg loss: 0.28967 (A-MSE: 0.25563) avg lploss: 0.00000
train epoch 1102 avg loss: 0.30821 (A-MSE: 0.27440) avg lploss: 0.00000
train epoch 1103 avg loss: 0.33712 (A-MSE: 0.29945) avg lploss: 0.00000
train epoch 1104 avg loss: 0.30965 (A-MSE: 0.27371) avg lploss: 0.00000
train epoch 1105 avg loss: 0.28480 (A-MSE: 0.25087) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.99835 (A-MSE: 0.89225) avg lploss: 0.00000
==> test epoch 1105 avg loss: 1.14775 (A-MSE: 1.03431) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 6 out of 50
train epoch 1106 avg loss: 0.29840 (A-MSE: 0.26307) avg lploss: 0.00000
train epoch 1107 avg loss: 0.27581 (A-MSE: 0.24432) avg lploss: 0.00000
train epoch 1108 avg loss: 0.27067 (A-MSE: 0.23859) avg lploss: 0.00000
train epoch 1109 avg loss: 0.24826 (A-MSE: 0.21895) avg lploss: 0.00000
train epoch 1110 avg loss: 0.28656 (A-MSE: 0.25348) avg lploss: 0.00000
==> val epoch 1110 avg loss: 1.01253 (A-MSE: 0.92228) avg lploss: 0.00000
==> test epoch 1110 avg loss: 1.17057 (A-MSE: 1.07358) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 7 out of 50
train epoch 1111 avg loss: 0.29513 (A-MSE: 0.26120) avg lploss: 0.00000
train epoch 1112 avg loss: 0.30490 (A-MSE: 0.26865) avg lploss: 0.00000
train epoch 1113 avg loss: 0.36995 (A-MSE: 0.32152) avg lploss: 0.00000
train epoch 1114 avg loss: 0.59132 (A-MSE: 0.51526) avg lploss: 0.00000
train epoch 1115 avg loss: 0.41597 (A-MSE: 0.37141) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.99589 (A-MSE: 0.88797) avg lploss: 0.00000
==> test epoch 1115 avg loss: 1.11696 (A-MSE: 1.01126) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 8 out of 50
train epoch 1116 avg loss: 0.33529 (A-MSE: 0.29713) avg lploss: 0.00000
train epoch 1117 avg loss: 0.30917 (A-MSE: 0.27309) avg lploss: 0.00000
train epoch 1118 avg loss: 0.32051 (A-MSE: 0.28387) avg lploss: 0.00000
train epoch 1119 avg loss: 0.30935 (A-MSE: 0.27359) avg lploss: 0.00000
train epoch 1120 avg loss: 0.30787 (A-MSE: 0.27145) avg lploss: 0.00000
==> val epoch 1120 avg loss: 1.03328 (A-MSE: 0.92024) avg lploss: 0.00000
==> test epoch 1120 avg loss: 1.15013 (A-MSE: 1.03757) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 9 out of 50
train epoch 1121 avg loss: 0.26279 (A-MSE: 0.23268) avg lploss: 0.00000
train epoch 1122 avg loss: 0.26476 (A-MSE: 0.23403) avg lploss: 0.00000
train epoch 1123 avg loss: 0.29818 (A-MSE: 0.26479) avg lploss: 0.00000
train epoch 1124 avg loss: 0.29809 (A-MSE: 0.26357) avg lploss: 0.00000
train epoch 1125 avg loss: 0.28504 (A-MSE: 0.25209) avg lploss: 0.00000
==> val epoch 1125 avg loss: 1.16107 (A-MSE: 1.02832) avg lploss: 0.00000
==> test epoch 1125 avg loss: 1.24001 (A-MSE: 1.11467) avg lploss: 0.00000
*** Best Val Loss: 0.93042 	 Best Test Loss: 1.02331 	 Best epoch 1075
EarlyStopping counter: 10 out of 50
train epoch 1126 avg loss: 0.28813 (A-MSE: 0.25409) avg lploss: 0.00000
train epoch 1127 avg loss: 0.29713 (A-MSE: 0.26353) avg lploss: 0.00000
train epoch 1128 avg loss: 0.30821 (A-MSE: 0.27181) avg lploss: 0.00000
train epoch 1129 avg loss: 0.29129 (A-MSE: 0.25747) avg lploss: 0.00000
train epoch 1130 avg loss: 0.25235 (A-MSE: 0.22332) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.89691 (A-MSE: 0.79961) avg lploss: 0.00000
==> test epoch 1130 avg loss: 1.00883 (A-MSE: 0.90671) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00883 	 Best epoch 1130
Validation loss decreased (0.930418 --> 0.896913).  Saving model ...
train epoch 1131 avg loss: 0.25916 (A-MSE: 0.22905) avg lploss: 0.00000
train epoch 1132 avg loss: 0.23569 (A-MSE: 0.20845) avg lploss: 0.00000
train epoch 1133 avg loss: 0.23790 (A-MSE: 0.20906) avg lploss: 0.00000
train epoch 1134 avg loss: 0.23459 (A-MSE: 0.20592) avg lploss: 0.00000
train epoch 1135 avg loss: 0.24660 (A-MSE: 0.21964) avg lploss: 0.00000
==> val epoch 1135 avg loss: 1.02919 (A-MSE: 0.91568) avg lploss: 0.00000
==> test epoch 1135 avg loss: 1.16948 (A-MSE: 1.05350) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00883 	 Best epoch 1130
EarlyStopping counter: 1 out of 50
train epoch 1136 avg loss: 0.23547 (A-MSE: 0.20891) avg lploss: 0.00000
train epoch 1137 avg loss: 0.24194 (A-MSE: 0.21499) avg lploss: 0.00000
train epoch 1138 avg loss: 0.25623 (A-MSE: 0.22514) avg lploss: 0.00000
train epoch 1139 avg loss: 0.27179 (A-MSE: 0.23898) avg lploss: 0.00000
train epoch 1140 avg loss: 0.27641 (A-MSE: 0.24363) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.91068 (A-MSE: 0.81803) avg lploss: 0.00000
==> test epoch 1140 avg loss: 1.08905 (A-MSE: 0.98116) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00883 	 Best epoch 1130
EarlyStopping counter: 2 out of 50
train epoch 1141 avg loss: 0.26303 (A-MSE: 0.23233) avg lploss: 0.00000
train epoch 1142 avg loss: 0.29246 (A-MSE: 0.26001) avg lploss: 0.00000
train epoch 1143 avg loss: 0.29654 (A-MSE: 0.26412) avg lploss: 0.00000
train epoch 1144 avg loss: 0.28125 (A-MSE: 0.24882) avg lploss: 0.00000
train epoch 1145 avg loss: 0.26545 (A-MSE: 0.23361) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.93926 (A-MSE: 0.84686) avg lploss: 0.00000
==> test epoch 1145 avg loss: 1.01418 (A-MSE: 0.92025) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00883 	 Best epoch 1130
EarlyStopping counter: 3 out of 50
train epoch 1146 avg loss: 0.24813 (A-MSE: 0.21978) avg lploss: 0.00000
train epoch 1147 avg loss: 0.27527 (A-MSE: 0.24334) avg lploss: 0.00000
train epoch 1148 avg loss: 0.28983 (A-MSE: 0.25584) avg lploss: 0.00000
train epoch 1149 avg loss: 0.25303 (A-MSE: 0.22346) avg lploss: 0.00000
train epoch 1150 avg loss: 0.22833 (A-MSE: 0.20209) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.90805 (A-MSE: 0.80879) avg lploss: 0.00000
==> test epoch 1150 avg loss: 1.02034 (A-MSE: 0.91673) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00883 	 Best epoch 1130
EarlyStopping counter: 4 out of 50
train epoch 1151 avg loss: 0.23409 (A-MSE: 0.20668) avg lploss: 0.00000
train epoch 1152 avg loss: 0.26483 (A-MSE: 0.23241) avg lploss: 0.00000
train epoch 1153 avg loss: 0.24214 (A-MSE: 0.21307) avg lploss: 0.00000
train epoch 1154 avg loss: 0.23327 (A-MSE: 0.20563) avg lploss: 0.00000
train epoch 1155 avg loss: 0.24759 (A-MSE: 0.21988) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.99387 (A-MSE: 0.87407) avg lploss: 0.00000
==> test epoch 1155 avg loss: 1.06763 (A-MSE: 0.96099) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00883 	 Best epoch 1130
EarlyStopping counter: 5 out of 50
train epoch 1156 avg loss: 0.30224 (A-MSE: 0.26642) avg lploss: 0.00000
train epoch 1157 avg loss: 0.30529 (A-MSE: 0.26896) avg lploss: 0.00000
train epoch 1158 avg loss: 0.28418 (A-MSE: 0.25110) avg lploss: 0.00000
train epoch 1159 avg loss: 0.28461 (A-MSE: 0.25038) avg lploss: 0.00000
train epoch 1160 avg loss: 0.22957 (A-MSE: 0.20533) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.87144 (A-MSE: 0.76746) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.93849 (A-MSE: 0.84227) avg lploss: 0.00000
*** Best Val Loss: 0.87144 	 Best Test Loss: 0.93849 	 Best epoch 1160
Validation loss decreased (0.896913 --> 0.871441).  Saving model ...
train epoch 1161 avg loss: 0.22640 (A-MSE: 0.19906) avg lploss: 0.00000
train epoch 1162 avg loss: 0.30336 (A-MSE: 0.26801) avg lploss: 0.00000
train epoch 1163 avg loss: 0.34777 (A-MSE: 0.30477) avg lploss: 0.00000
train epoch 1164 avg loss: 0.27176 (A-MSE: 0.24010) avg lploss: 0.00000
train epoch 1165 avg loss: 0.24345 (A-MSE: 0.21262) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.92865 (A-MSE: 0.82234) avg lploss: 0.00000
==> test epoch 1165 avg loss: 1.05512 (A-MSE: 0.94533) avg lploss: 0.00000
*** Best Val Loss: 0.87144 	 Best Test Loss: 0.93849 	 Best epoch 1160
EarlyStopping counter: 1 out of 50
train epoch 1166 avg loss: 0.24027 (A-MSE: 0.21244) avg lploss: 0.00000
train epoch 1167 avg loss: 0.25316 (A-MSE: 0.22283) avg lploss: 0.00000
train epoch 1168 avg loss: 0.23767 (A-MSE: 0.20840) avg lploss: 0.00000
train epoch 1169 avg loss: 0.25299 (A-MSE: 0.22344) avg lploss: 0.00000
train epoch 1170 avg loss: 0.26839 (A-MSE: 0.23665) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.97840 (A-MSE: 0.86552) avg lploss: 0.00000
==> test epoch 1170 avg loss: 1.07121 (A-MSE: 0.95056) avg lploss: 0.00000
*** Best Val Loss: 0.87144 	 Best Test Loss: 0.93849 	 Best epoch 1160
EarlyStopping counter: 2 out of 50
train epoch 1171 avg loss: 0.26542 (A-MSE: 0.23480) avg lploss: 0.00000
train epoch 1172 avg loss: 0.25800 (A-MSE: 0.22739) avg lploss: 0.00000
train epoch 1173 avg loss: 0.25298 (A-MSE: 0.22584) avg lploss: 0.00000
train epoch 1174 avg loss: 0.25163 (A-MSE: 0.22272) avg lploss: 0.00000
train epoch 1175 avg loss: 0.27814 (A-MSE: 0.24855) avg lploss: 0.00000
==> val epoch 1175 avg loss: 1.04278 (A-MSE: 0.92660) avg lploss: 0.00000
==> test epoch 1175 avg loss: 1.08669 (A-MSE: 0.98655) avg lploss: 0.00000
*** Best Val Loss: 0.87144 	 Best Test Loss: 0.93849 	 Best epoch 1160
EarlyStopping counter: 3 out of 50
train epoch 1176 avg loss: 0.28876 (A-MSE: 0.25169) avg lploss: 0.00000
train epoch 1177 avg loss: 0.24313 (A-MSE: 0.21499) avg lploss: 0.00000
train epoch 1178 avg loss: 0.28338 (A-MSE: 0.25045) avg lploss: 0.00000
train epoch 1179 avg loss: 0.26174 (A-MSE: 0.23072) avg lploss: 0.00000
train epoch 1180 avg loss: 0.22533 (A-MSE: 0.19878) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.87144 (A-MSE: 0.77396) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.99128 (A-MSE: 0.89862) avg lploss: 0.00000
*** Best Val Loss: 0.87144 	 Best Test Loss: 0.99128 	 Best epoch 1180
Validation loss decreased (0.871441 --> 0.871439).  Saving model ...
train epoch 1181 avg loss: 0.26554 (A-MSE: 0.23486) avg lploss: 0.00000
train epoch 1182 avg loss: 0.27775 (A-MSE: 0.24443) avg lploss: 0.00000
train epoch 1183 avg loss: 0.24493 (A-MSE: 0.21562) avg lploss: 0.00000
train epoch 1184 avg loss: 0.25331 (A-MSE: 0.22482) avg lploss: 0.00000
train epoch 1185 avg loss: 0.24364 (A-MSE: 0.21658) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.93539 (A-MSE: 0.84030) avg lploss: 0.00000
==> test epoch 1185 avg loss: 1.10443 (A-MSE: 0.99377) avg lploss: 0.00000
*** Best Val Loss: 0.87144 	 Best Test Loss: 0.99128 	 Best epoch 1180
EarlyStopping counter: 1 out of 50
train epoch 1186 avg loss: 0.28115 (A-MSE: 0.24866) avg lploss: 0.00000
train epoch 1187 avg loss: 0.28914 (A-MSE: 0.25351) avg lploss: 0.00000
train epoch 1188 avg loss: 0.23577 (A-MSE: 0.20872) avg lploss: 0.00000
train epoch 1189 avg loss: 0.23195 (A-MSE: 0.20404) avg lploss: 0.00000
train epoch 1190 avg loss: 0.22871 (A-MSE: 0.20254) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.82672 (A-MSE: 0.74050) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.97666 (A-MSE: 0.87498) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
Validation loss decreased (0.871439 --> 0.826724).  Saving model ...
train epoch 1191 avg loss: 0.29117 (A-MSE: 0.25544) avg lploss: 0.00000
train epoch 1192 avg loss: 0.24964 (A-MSE: 0.22075) avg lploss: 0.00000
train epoch 1193 avg loss: 0.29533 (A-MSE: 0.26180) avg lploss: 0.00000
train epoch 1194 avg loss: 0.27888 (A-MSE: 0.24505) avg lploss: 0.00000
train epoch 1195 avg loss: 0.24919 (A-MSE: 0.21989) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.91286 (A-MSE: 0.81602) avg lploss: 0.00000
==> test epoch 1195 avg loss: 1.05359 (A-MSE: 0.94512) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 1 out of 50
train epoch 1196 avg loss: 0.24665 (A-MSE: 0.21969) avg lploss: 0.00000
train epoch 1197 avg loss: 0.27940 (A-MSE: 0.24594) avg lploss: 0.00000
train epoch 1198 avg loss: 0.30067 (A-MSE: 0.26573) avg lploss: 0.00000
train epoch 1199 avg loss: 0.29759 (A-MSE: 0.26413) avg lploss: 0.00000
train epoch 1200 avg loss: 0.26856 (A-MSE: 0.23710) avg lploss: 0.00000
==> val epoch 1200 avg loss: 1.10497 (A-MSE: 0.96825) avg lploss: 0.00000
==> test epoch 1200 avg loss: 1.18706 (A-MSE: 1.05633) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 2 out of 50
train epoch 1201 avg loss: 0.29527 (A-MSE: 0.25954) avg lploss: 0.00000
train epoch 1202 avg loss: 0.29063 (A-MSE: 0.25704) avg lploss: 0.00000
train epoch 1203 avg loss: 0.26877 (A-MSE: 0.23652) avg lploss: 0.00000
train epoch 1204 avg loss: 0.26125 (A-MSE: 0.23138) avg lploss: 0.00000
train epoch 1205 avg loss: 0.24494 (A-MSE: 0.21631) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.88938 (A-MSE: 0.79055) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.95821 (A-MSE: 0.86669) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 3 out of 50
train epoch 1206 avg loss: 0.21984 (A-MSE: 0.19496) avg lploss: 0.00000
train epoch 1207 avg loss: 0.22480 (A-MSE: 0.19874) avg lploss: 0.00000
train epoch 1208 avg loss: 0.27527 (A-MSE: 0.24352) avg lploss: 0.00000
train epoch 1209 avg loss: 0.23125 (A-MSE: 0.20244) avg lploss: 0.00000
train epoch 1210 avg loss: 0.22510 (A-MSE: 0.20264) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.96076 (A-MSE: 0.84208) avg lploss: 0.00000
==> test epoch 1210 avg loss: 1.10284 (A-MSE: 0.97628) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 4 out of 50
train epoch 1211 avg loss: 0.20926 (A-MSE: 0.18515) avg lploss: 0.00000
train epoch 1212 avg loss: 0.22423 (A-MSE: 0.19644) avg lploss: 0.00000
train epoch 1213 avg loss: 0.24511 (A-MSE: 0.21779) avg lploss: 0.00000
train epoch 1214 avg loss: 0.23575 (A-MSE: 0.21002) avg lploss: 0.00000
train epoch 1215 avg loss: 0.22089 (A-MSE: 0.19512) avg lploss: 0.00000
==> val epoch 1215 avg loss: 1.10238 (A-MSE: 0.96524) avg lploss: 0.00000
==> test epoch 1215 avg loss: 1.22521 (A-MSE: 1.09146) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 5 out of 50
train epoch 1216 avg loss: 0.25474 (A-MSE: 0.22618) avg lploss: 0.00000
train epoch 1217 avg loss: 0.26279 (A-MSE: 0.23157) avg lploss: 0.00000
train epoch 1218 avg loss: 0.22952 (A-MSE: 0.20350) avg lploss: 0.00000
train epoch 1219 avg loss: 0.22106 (A-MSE: 0.19497) avg lploss: 0.00000
train epoch 1220 avg loss: 0.21344 (A-MSE: 0.18945) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.94052 (A-MSE: 0.83273) avg lploss: 0.00000
==> test epoch 1220 avg loss: 1.07614 (A-MSE: 0.96111) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 6 out of 50
train epoch 1221 avg loss: 0.22242 (A-MSE: 0.19632) avg lploss: 0.00000
train epoch 1222 avg loss: 0.22624 (A-MSE: 0.20052) avg lploss: 0.00000
train epoch 1223 avg loss: 0.24401 (A-MSE: 0.21444) avg lploss: 0.00000
train epoch 1224 avg loss: 0.23595 (A-MSE: 0.20904) avg lploss: 0.00000
train epoch 1225 avg loss: 0.21383 (A-MSE: 0.18917) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.89763 (A-MSE: 0.79050) avg lploss: 0.00000
==> test epoch 1225 avg loss: 1.06564 (A-MSE: 0.94099) avg lploss: 0.00000
*** Best Val Loss: 0.82672 	 Best Test Loss: 0.97666 	 Best epoch 1190
EarlyStopping counter: 7 out of 50
train epoch 1226 avg loss: 0.20478 (A-MSE: 0.18073) avg lploss: 0.00000
train epoch 1227 avg loss: 0.21666 (A-MSE: 0.19061) avg lploss: 0.00000
train epoch 1228 avg loss: 0.25156 (A-MSE: 0.22065) avg lploss: 0.00000
train epoch 1229 avg loss: 0.22779 (A-MSE: 0.20235) avg lploss: 0.00000
train epoch 1230 avg loss: 0.22944 (A-MSE: 0.20306) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.82285 (A-MSE: 0.73145) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.94989 (A-MSE: 0.85900) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
Validation loss decreased (0.826724 --> 0.822846).  Saving model ...
train epoch 1231 avg loss: 0.21097 (A-MSE: 0.18657) avg lploss: 0.00000
train epoch 1232 avg loss: 0.20950 (A-MSE: 0.18467) avg lploss: 0.00000
train epoch 1233 avg loss: 0.20217 (A-MSE: 0.17909) avg lploss: 0.00000
train epoch 1234 avg loss: 0.23917 (A-MSE: 0.21274) avg lploss: 0.00000
train epoch 1235 avg loss: 0.23439 (A-MSE: 0.20661) avg lploss: 0.00000
==> val epoch 1235 avg loss: 1.00709 (A-MSE: 0.87573) avg lploss: 0.00000
==> test epoch 1235 avg loss: 1.10452 (A-MSE: 0.97943) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 1 out of 50
train epoch 1236 avg loss: 0.26665 (A-MSE: 0.23485) avg lploss: 0.00000
train epoch 1237 avg loss: 0.26384 (A-MSE: 0.23320) avg lploss: 0.00000
train epoch 1238 avg loss: 0.24566 (A-MSE: 0.21731) avg lploss: 0.00000
train epoch 1239 avg loss: 0.22962 (A-MSE: 0.20473) avg lploss: 0.00000
train epoch 1240 avg loss: 0.25902 (A-MSE: 0.23050) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.86109 (A-MSE: 0.77747) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.96064 (A-MSE: 0.87977) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 2 out of 50
train epoch 1241 avg loss: 0.25882 (A-MSE: 0.22940) avg lploss: 0.00000
train epoch 1242 avg loss: 0.21549 (A-MSE: 0.19168) avg lploss: 0.00000
train epoch 1243 avg loss: 0.22848 (A-MSE: 0.20265) avg lploss: 0.00000
train epoch 1244 avg loss: 0.21942 (A-MSE: 0.19432) avg lploss: 0.00000
train epoch 1245 avg loss: 0.19851 (A-MSE: 0.17486) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.89498 (A-MSE: 0.78872) avg lploss: 0.00000
==> test epoch 1245 avg loss: 1.00190 (A-MSE: 0.89295) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 3 out of 50
train epoch 1246 avg loss: 0.18955 (A-MSE: 0.16703) avg lploss: 0.00000
train epoch 1247 avg loss: 0.21294 (A-MSE: 0.18883) avg lploss: 0.00000
train epoch 1248 avg loss: 0.20884 (A-MSE: 0.18346) avg lploss: 0.00000
train epoch 1249 avg loss: 0.21235 (A-MSE: 0.18828) avg lploss: 0.00000
train epoch 1250 avg loss: 0.20765 (A-MSE: 0.18454) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.96593 (A-MSE: 0.85339) avg lploss: 0.00000
==> test epoch 1250 avg loss: 1.11059 (A-MSE: 0.98058) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 4 out of 50
train epoch 1251 avg loss: 0.21073 (A-MSE: 0.18715) avg lploss: 0.00000
train epoch 1252 avg loss: 0.20946 (A-MSE: 0.18393) avg lploss: 0.00000
train epoch 1253 avg loss: 0.22843 (A-MSE: 0.20237) avg lploss: 0.00000
train epoch 1254 avg loss: 0.22448 (A-MSE: 0.19912) avg lploss: 0.00000
train epoch 1255 avg loss: 0.21498 (A-MSE: 0.19253) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.93064 (A-MSE: 0.83214) avg lploss: 0.00000
==> test epoch 1255 avg loss: 1.10804 (A-MSE: 0.98963) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 5 out of 50
train epoch 1256 avg loss: 0.21613 (A-MSE: 0.19086) avg lploss: 0.00000
train epoch 1257 avg loss: 0.23792 (A-MSE: 0.21106) avg lploss: 0.00000
train epoch 1258 avg loss: 0.24475 (A-MSE: 0.21711) avg lploss: 0.00000
train epoch 1259 avg loss: 0.23779 (A-MSE: 0.20856) avg lploss: 0.00000
train epoch 1260 avg loss: 0.23468 (A-MSE: 0.20802) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.84735 (A-MSE: 0.75080) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.95349 (A-MSE: 0.85122) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 6 out of 50
train epoch 1261 avg loss: 0.22400 (A-MSE: 0.19922) avg lploss: 0.00000
train epoch 1262 avg loss: 0.26496 (A-MSE: 0.23654) avg lploss: 0.00000
train epoch 1263 avg loss: 0.23041 (A-MSE: 0.20393) avg lploss: 0.00000
train epoch 1264 avg loss: 0.22012 (A-MSE: 0.19491) avg lploss: 0.00000
train epoch 1265 avg loss: 0.19338 (A-MSE: 0.17102) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.82347 (A-MSE: 0.72805) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.94665 (A-MSE: 0.84457) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 7 out of 50
train epoch 1266 avg loss: 0.18394 (A-MSE: 0.16327) avg lploss: 0.00000
train epoch 1267 avg loss: 0.19132 (A-MSE: 0.17074) avg lploss: 0.00000
train epoch 1268 avg loss: 0.23114 (A-MSE: 0.20427) avg lploss: 0.00000
train epoch 1269 avg loss: 0.22715 (A-MSE: 0.20119) avg lploss: 0.00000
train epoch 1270 avg loss: 0.22672 (A-MSE: 0.19985) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.89803 (A-MSE: 0.80833) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.98442 (A-MSE: 0.89654) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 8 out of 50
train epoch 1271 avg loss: 0.22654 (A-MSE: 0.20136) avg lploss: 0.00000
train epoch 1272 avg loss: 0.21604 (A-MSE: 0.19035) avg lploss: 0.00000
train epoch 1273 avg loss: 0.18343 (A-MSE: 0.16345) avg lploss: 0.00000
train epoch 1274 avg loss: 0.19218 (A-MSE: 0.17039) avg lploss: 0.00000
train epoch 1275 avg loss: 0.20153 (A-MSE: 0.17682) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.82493 (A-MSE: 0.73810) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.96725 (A-MSE: 0.87428) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 9 out of 50
train epoch 1276 avg loss: 0.18704 (A-MSE: 0.16672) avg lploss: 0.00000
train epoch 1277 avg loss: 0.22658 (A-MSE: 0.20120) avg lploss: 0.00000
train epoch 1278 avg loss: 0.20136 (A-MSE: 0.17860) avg lploss: 0.00000
train epoch 1279 avg loss: 0.21054 (A-MSE: 0.18709) avg lploss: 0.00000
train epoch 1280 avg loss: 0.19822 (A-MSE: 0.17624) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.86557 (A-MSE: 0.76774) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.96943 (A-MSE: 0.86861) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 10 out of 50
train epoch 1281 avg loss: 0.20284 (A-MSE: 0.17986) avg lploss: 0.00000
train epoch 1282 avg loss: 0.22642 (A-MSE: 0.20070) avg lploss: 0.00000
train epoch 1283 avg loss: 0.24762 (A-MSE: 0.22042) avg lploss: 0.00000
train epoch 1284 avg loss: 0.21897 (A-MSE: 0.19447) avg lploss: 0.00000
train epoch 1285 avg loss: 0.19692 (A-MSE: 0.17323) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.97349 (A-MSE: 0.86637) avg lploss: 0.00000
==> test epoch 1285 avg loss: 1.04445 (A-MSE: 0.94889) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 11 out of 50
train epoch 1286 avg loss: 0.20354 (A-MSE: 0.18127) avg lploss: 0.00000
train epoch 1287 avg loss: 0.18007 (A-MSE: 0.16090) avg lploss: 0.00000
train epoch 1288 avg loss: 0.18705 (A-MSE: 0.16429) avg lploss: 0.00000
train epoch 1289 avg loss: 0.19031 (A-MSE: 0.16914) avg lploss: 0.00000
train epoch 1290 avg loss: 0.22310 (A-MSE: 0.19859) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.86245 (A-MSE: 0.78116) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.96364 (A-MSE: 0.87751) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 12 out of 50
train epoch 1291 avg loss: 0.25182 (A-MSE: 0.22233) avg lploss: 0.00000
train epoch 1292 avg loss: 0.24570 (A-MSE: 0.21501) avg lploss: 0.00000
train epoch 1293 avg loss: 0.21989 (A-MSE: 0.19437) avg lploss: 0.00000
train epoch 1294 avg loss: 0.23410 (A-MSE: 0.20742) avg lploss: 0.00000
train epoch 1295 avg loss: 0.23206 (A-MSE: 0.20546) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.98413 (A-MSE: 0.85985) avg lploss: 0.00000
==> test epoch 1295 avg loss: 1.04433 (A-MSE: 0.93795) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 13 out of 50
train epoch 1296 avg loss: 108.39451 (A-MSE: 101.69980) avg lploss: 0.00000
train epoch 1297 avg loss: 24180775709.52240 (A-MSE: 23863655295.97150) avg lploss: 0.00000
train epoch 1298 avg loss: 55242.47827 (A-MSE: 59312.50500) avg lploss: 0.00000
train epoch 1299 avg loss: 16471.22043 (A-MSE: 17044.23224) avg lploss: 0.00000
train epoch 1300 avg loss: 4994.35831 (A-MSE: 4920.48122) avg lploss: 0.00000
==> val epoch 1300 avg loss: 3968.85562 (A-MSE: 3649.59237) avg lploss: 0.00000
==> test epoch 1300 avg loss: 3728.43257 (A-MSE: 3580.78831) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 14 out of 50
train epoch 1301 avg loss: 3199.99884 (A-MSE: 3137.62787) avg lploss: 0.00000
train epoch 1302 avg loss: 2623.97481 (A-MSE: 2582.87958) avg lploss: 0.00000
train epoch 1303 avg loss: 2204.90298 (A-MSE: 2160.02293) avg lploss: 0.00000
train epoch 1304 avg loss: 100360.19761 (A-MSE: 94939.73203) avg lploss: 0.00000
train epoch 1305 avg loss: 24605.56042 (A-MSE: 22134.37689) avg lploss: 0.00000
==> val epoch 1305 avg loss: 6381.38977 (A-MSE: 5483.20612) avg lploss: 0.00000
==> test epoch 1305 avg loss: 6264.88550 (A-MSE: 5290.64955) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 15 out of 50
train epoch 1306 avg loss: 3712.44127 (A-MSE: 3943.44801) avg lploss: 0.00000
train epoch 1307 avg loss: 2518.75832 (A-MSE: 2734.89870) avg lploss: 0.00000
train epoch 1308 avg loss: 2529.57259 (A-MSE: 2536.53774) avg lploss: 0.00000
train epoch 1309 avg loss: 2213.92127 (A-MSE: 2050.52807) avg lploss: 0.00000
train epoch 1310 avg loss: 2114.43068 (A-MSE: 1959.16939) avg lploss: 0.00000
==> val epoch 1310 avg loss: 2122.60516 (A-MSE: 2178.18056) avg lploss: 0.00000
==> test epoch 1310 avg loss: 2244.91515 (A-MSE: 2234.02281) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 16 out of 50
train epoch 1311 avg loss: 2444.89949 (A-MSE: 2264.84165) avg lploss: 0.00000
train epoch 1312 avg loss: 2257.30688 (A-MSE: 2103.33431) avg lploss: 0.00000
train epoch 1313 avg loss: 2483.15779 (A-MSE: 2232.90553) avg lploss: 0.00000
train epoch 1314 avg loss: 2845.53003 (A-MSE: 2838.51863) avg lploss: 0.00000
train epoch 1315 avg loss: 3281.98848 (A-MSE: 3220.05927) avg lploss: 0.00000
==> val epoch 1315 avg loss: 2653.28097 (A-MSE: 2605.25000) avg lploss: 0.00000
==> test epoch 1315 avg loss: 2673.67440 (A-MSE: 2616.30885) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 17 out of 50
train epoch 1316 avg loss: 2821.16460 (A-MSE: 2687.89764) avg lploss: 0.00000
train epoch 1317 avg loss: 2631.09985 (A-MSE: 2573.33012) avg lploss: 0.00000
train epoch 1318 avg loss: 2743.32558 (A-MSE: 2546.25317) avg lploss: 0.00000
train epoch 1319 avg loss: 2559.31697 (A-MSE: 2365.13947) avg lploss: 0.00000
train epoch 1320 avg loss: 4221.86372 (A-MSE: 4988.38794) avg lploss: 0.00000
==> val epoch 1320 avg loss: 3785.09647 (A-MSE: 3150.71285) avg lploss: 0.00000
==> test epoch 1320 avg loss: 3709.96188 (A-MSE: 3040.83259) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 18 out of 50
train epoch 1321 avg loss: 5509.35959 (A-MSE: 4881.15927) avg lploss: 0.00000
train epoch 1322 avg loss: 3252.41847 (A-MSE: 2929.57404) avg lploss: 0.00000
train epoch 1323 avg loss: 2937.24283 (A-MSE: 2464.60966) avg lploss: 0.00000
train epoch 1324 avg loss: 3348.86433 (A-MSE: 2993.20908) avg lploss: 0.00000
train epoch 1325 avg loss: 2548.78722 (A-MSE: 2536.61401) avg lploss: 0.00000
==> val epoch 1325 avg loss: 2610.28629 (A-MSE: 2464.03634) avg lploss: 0.00000
==> test epoch 1325 avg loss: 2565.37815 (A-MSE: 2493.87720) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 19 out of 50
train epoch 1326 avg loss: 2385.70515 (A-MSE: 2250.29456) avg lploss: 0.00000
train epoch 1327 avg loss: 2308.15234 (A-MSE: 2120.28941) avg lploss: 0.00000
train epoch 1328 avg loss: 2156.19276 (A-MSE: 2047.23836) avg lploss: 0.00000
train epoch 1329 avg loss: 2108.46006 (A-MSE: 1962.79411) avg lploss: 0.00000
train epoch 1330 avg loss: 8461.26206 (A-MSE: 7266.06333) avg lploss: 0.00000
==> val epoch 1330 avg loss: 45339.61543 (A-MSE: 30632.22881) avg lploss: 0.00000
==> test epoch 1330 avg loss: 43436.59253 (A-MSE: 27917.46602) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 20 out of 50
train epoch 1331 avg loss: 29320.25873 (A-MSE: 22904.22211) avg lploss: 0.00000
train epoch 1332 avg loss: 5990.85321 (A-MSE: 5211.63197) avg lploss: 0.00000
train epoch 1333 avg loss: 2579.82037 (A-MSE: 2471.55678) avg lploss: 0.00000
train epoch 1334 avg loss: 2196.22981 (A-MSE: 2171.64707) avg lploss: 0.00000
train epoch 1335 avg loss: 2146.31521 (A-MSE: 2136.85416) avg lploss: 0.00000
==> val epoch 1335 avg loss: 2278.68090 (A-MSE: 2074.18398) avg lploss: 0.00000
==> test epoch 1335 avg loss: 2380.67795 (A-MSE: 2120.77175) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 21 out of 50
train epoch 1336 avg loss: 2406.17828 (A-MSE: 2112.95624) avg lploss: 0.00000
train epoch 1337 avg loss: 2263.93552 (A-MSE: 1968.41648) avg lploss: 0.00000
train epoch 1338 avg loss: 2515.17831 (A-MSE: 2404.05113) avg lploss: 0.00000
train epoch 1339 avg loss: 2415.63843 (A-MSE: 2425.09900) avg lploss: 0.00000
train epoch 1340 avg loss: 2227.54858 (A-MSE: 2320.42953) avg lploss: 0.00000
==> val epoch 1340 avg loss: 2016.35380 (A-MSE: 2031.32045) avg lploss: 0.00000
==> test epoch 1340 avg loss: 2022.14672 (A-MSE: 2021.80640) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 22 out of 50
train epoch 1341 avg loss: 1664.89874 (A-MSE: 1772.06780) avg lploss: 0.00000
train epoch 1342 avg loss: 1420.73029 (A-MSE: 1556.61784) avg lploss: 0.00000
train epoch 1343 avg loss: 1249.46359 (A-MSE: 1391.10900) avg lploss: 0.00000
train epoch 1344 avg loss: 1398.32148 (A-MSE: 1507.36924) avg lploss: 0.00000
train epoch 1345 avg loss: 1502.66273 (A-MSE: 1586.67180) avg lploss: 0.00000
==> val epoch 1345 avg loss: 1171.29086 (A-MSE: 1244.95175) avg lploss: 0.00000
==> test epoch 1345 avg loss: 1182.74878 (A-MSE: 1236.70826) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 23 out of 50
train epoch 1346 avg loss: 1097.33380 (A-MSE: 1149.78486) avg lploss: 0.00000
train epoch 1347 avg loss: 1046.21239 (A-MSE: 1121.78373) avg lploss: 0.00000
train epoch 1348 avg loss: 1026.77940 (A-MSE: 1111.18944) avg lploss: 0.00000
train epoch 1349 avg loss: 989.92292 (A-MSE: 1073.87045) avg lploss: 0.00000
train epoch 1350 avg loss: 1086.40232 (A-MSE: 1174.07922) avg lploss: 0.00000
==> val epoch 1350 avg loss: 1219.56138 (A-MSE: 1226.48276) avg lploss: 0.00000
==> test epoch 1350 avg loss: 1213.30786 (A-MSE: 1229.77111) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 24 out of 50
train epoch 1351 avg loss: 1204.08925 (A-MSE: 1248.05561) avg lploss: 0.00000
train epoch 1352 avg loss: 1202.02078 (A-MSE: 1188.36082) avg lploss: 0.00000
train epoch 1353 avg loss: 1166.17150 (A-MSE: 1155.42792) avg lploss: 0.00000
train epoch 1354 avg loss: 1120.21758 (A-MSE: 1153.30122) avg lploss: 0.00000
train epoch 1355 avg loss: 959.16906 (A-MSE: 963.72052) avg lploss: 0.00000
==> val epoch 1355 avg loss: 855.70707 (A-MSE: 860.52194) avg lploss: 0.00000
==> test epoch 1355 avg loss: 828.97204 (A-MSE: 818.18513) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 25 out of 50
train epoch 1356 avg loss: 899.91859 (A-MSE: 907.92218) avg lploss: 0.00000
train epoch 1357 avg loss: 872.28218 (A-MSE: 871.39277) avg lploss: 0.00000
train epoch 1358 avg loss: 871.01046 (A-MSE: 879.96093) avg lploss: 0.00000
train epoch 1359 avg loss: 1152.18831 (A-MSE: 1195.67873) avg lploss: 0.00000
train epoch 1360 avg loss: 1186.77852 (A-MSE: 1221.88069) avg lploss: 0.00000
==> val epoch 1360 avg loss: 1100.17395 (A-MSE: 1143.70616) avg lploss: 0.00000
==> test epoch 1360 avg loss: 1074.11215 (A-MSE: 1103.22307) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 26 out of 50
train epoch 1361 avg loss: 1015.57849 (A-MSE: 1042.03553) avg lploss: 0.00000
train epoch 1362 avg loss: 1006.56153 (A-MSE: 1011.18326) avg lploss: 0.00000
train epoch 1363 avg loss: 957.75633 (A-MSE: 974.74493) avg lploss: 0.00000
train epoch 1364 avg loss: 901.50616 (A-MSE: 920.65534) avg lploss: 0.00000
train epoch 1365 avg loss: 917.47859 (A-MSE: 920.45790) avg lploss: 0.00000
==> val epoch 1365 avg loss: 914.93899 (A-MSE: 919.19706) avg lploss: 0.00000
==> test epoch 1365 avg loss: 886.06686 (A-MSE: 887.64903) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 27 out of 50
train epoch 1366 avg loss: 883.81240 (A-MSE: 884.40712) avg lploss: 0.00000
train epoch 1367 avg loss: 840.72713 (A-MSE: 857.82504) avg lploss: 0.00000
train epoch 1368 avg loss: 822.63256 (A-MSE: 838.53551) avg lploss: 0.00000
train epoch 1369 avg loss: 835.03059 (A-MSE: 838.32289) avg lploss: 0.00000
train epoch 1370 avg loss: 845.82586 (A-MSE: 841.78093) avg lploss: 0.00000
==> val epoch 1370 avg loss: 862.81622 (A-MSE: 858.98243) avg lploss: 0.00000
==> test epoch 1370 avg loss: 835.79577 (A-MSE: 851.59716) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 28 out of 50
train epoch 1371 avg loss: 817.63817 (A-MSE: 842.95897) avg lploss: 0.00000
train epoch 1372 avg loss: 836.32058 (A-MSE: 882.78971) avg lploss: 0.00000
train epoch 1373 avg loss: 785.93929 (A-MSE: 818.06165) avg lploss: 0.00000
train epoch 1374 avg loss: 1119.21983 (A-MSE: 1066.12263) avg lploss: 0.00000
train epoch 1375 avg loss: 1270.65171 (A-MSE: 1207.28999) avg lploss: 0.00000
==> val epoch 1375 avg loss: 1206.40047 (A-MSE: 1144.10302) avg lploss: 0.00000
==> test epoch 1375 avg loss: 1191.60855 (A-MSE: 1157.92820) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 29 out of 50
train epoch 1376 avg loss: 1188.76057 (A-MSE: 1129.29399) avg lploss: 0.00000
train epoch 1377 avg loss: 1150.01397 (A-MSE: 1095.57289) avg lploss: 0.00000
train epoch 1378 avg loss: 1130.18770 (A-MSE: 1086.81908) avg lploss: 0.00000
train epoch 1379 avg loss: 1116.71710 (A-MSE: 1070.00390) avg lploss: 0.00000
train epoch 1380 avg loss: 1117.44365 (A-MSE: 1063.87315) avg lploss: 0.00000
==> val epoch 1380 avg loss: 1077.65266 (A-MSE: 1033.03195) avg lploss: 0.00000
==> test epoch 1380 avg loss: 1067.76169 (A-MSE: 1049.77926) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 30 out of 50
train epoch 1381 avg loss: 1104.22887 (A-MSE: 1054.91772) avg lploss: 0.00000
train epoch 1382 avg loss: 1084.32053 (A-MSE: 1042.49330) avg lploss: 0.00000
train epoch 1383 avg loss: 1061.57016 (A-MSE: 1031.69557) avg lploss: 0.00000
train epoch 1384 avg loss: 1049.81711 (A-MSE: 1023.68863) avg lploss: 0.00000
train epoch 1385 avg loss: 1049.21045 (A-MSE: 1016.01186) avg lploss: 0.00000
==> val epoch 1385 avg loss: 1015.27456 (A-MSE: 993.00798) avg lploss: 0.00000
==> test epoch 1385 avg loss: 1023.24614 (A-MSE: 1011.26820) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 31 out of 50
train epoch 1386 avg loss: 1034.07887 (A-MSE: 1016.58202) avg lploss: 0.00000
train epoch 1387 avg loss: 1022.87125 (A-MSE: 1008.37216) avg lploss: 0.00000
train epoch 1388 avg loss: 1015.56425 (A-MSE: 1004.77072) avg lploss: 0.00000
train epoch 1389 avg loss: 1014.05419 (A-MSE: 1003.48356) avg lploss: 0.00000
train epoch 1390 avg loss: 1019.30516 (A-MSE: 1004.32710) avg lploss: 0.00000
==> val epoch 1390 avg loss: 984.58462 (A-MSE: 980.71558) avg lploss: 0.00000
==> test epoch 1390 avg loss: 975.05695 (A-MSE: 992.74932) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 32 out of 50
train epoch 1391 avg loss: 1003.00298 (A-MSE: 992.45835) avg lploss: 0.00000
train epoch 1392 avg loss: 999.96249 (A-MSE: 989.35892) avg lploss: 0.00000
train epoch 1393 avg loss: 1006.19896 (A-MSE: 987.43364) avg lploss: 0.00000
train epoch 1394 avg loss: 980.74134 (A-MSE: 965.32353) avg lploss: 0.00000
train epoch 1395 avg loss: 985.67085 (A-MSE: 978.59841) avg lploss: 0.00000
==> val epoch 1395 avg loss: 953.76212 (A-MSE: 942.85324) avg lploss: 0.00000
==> test epoch 1395 avg loss: 970.18763 (A-MSE: 976.07055) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 33 out of 50
train epoch 1396 avg loss: 1000.30865 (A-MSE: 982.91090) avg lploss: 0.00000
train epoch 1397 avg loss: 1004.90617 (A-MSE: 988.68960) avg lploss: 0.00000
train epoch 1398 avg loss: 994.49282 (A-MSE: 983.82493) avg lploss: 0.00000
train epoch 1399 avg loss: 990.16558 (A-MSE: 985.40575) avg lploss: 0.00000
train epoch 1400 avg loss: 983.25856 (A-MSE: 977.74706) avg lploss: 0.00000
==> val epoch 1400 avg loss: 944.14855 (A-MSE: 919.25009) avg lploss: 0.00000
==> test epoch 1400 avg loss: 946.71803 (A-MSE: 948.27856) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 34 out of 50
train epoch 1401 avg loss: 974.11404 (A-MSE: 964.88726) avg lploss: 0.00000
train epoch 1402 avg loss: 963.00764 (A-MSE: 963.08863) avg lploss: 0.00000
train epoch 1403 avg loss: 963.00717 (A-MSE: 958.15452) avg lploss: 0.00000
train epoch 1404 avg loss: 944.04874 (A-MSE: 943.21273) avg lploss: 0.00000
train epoch 1405 avg loss: 919.56259 (A-MSE: 922.45662) avg lploss: 0.00000
==> val epoch 1405 avg loss: 906.51388 (A-MSE: 890.42891) avg lploss: 0.00000
==> test epoch 1405 avg loss: 912.55729 (A-MSE: 910.39777) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 35 out of 50
train epoch 1406 avg loss: 915.76207 (A-MSE: 920.04578) avg lploss: 0.00000
train epoch 1407 avg loss: 910.84236 (A-MSE: 897.48563) avg lploss: 0.00000
train epoch 1408 avg loss: 873.31237 (A-MSE: 868.55560) avg lploss: 0.00000
train epoch 1409 avg loss: 866.91811 (A-MSE: 860.69583) avg lploss: 0.00000
train epoch 1410 avg loss: 873.20347 (A-MSE: 856.99487) avg lploss: 0.00000
==> val epoch 1410 avg loss: 895.79795 (A-MSE: 861.79781) avg lploss: 0.00000
==> test epoch 1410 avg loss: 885.58335 (A-MSE: 880.65008) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 36 out of 50
train epoch 1411 avg loss: 865.68734 (A-MSE: 849.81775) avg lploss: 0.00000
train epoch 1412 avg loss: 864.46637 (A-MSE: 864.44680) avg lploss: 0.00000
train epoch 1413 avg loss: 838.52873 (A-MSE: 860.03847) avg lploss: 0.00000
train epoch 1414 avg loss: 887.85288 (A-MSE: 890.53136) avg lploss: 0.00000
train epoch 1415 avg loss: 883.08295 (A-MSE: 883.84278) avg lploss: 0.00000
==> val epoch 1415 avg loss: 866.39390 (A-MSE: 855.78592) avg lploss: 0.00000
==> test epoch 1415 avg loss: 871.06986 (A-MSE: 868.23156) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 37 out of 50
train epoch 1416 avg loss: 874.78796 (A-MSE: 871.57075) avg lploss: 0.00000
train epoch 1417 avg loss: 861.58965 (A-MSE: 862.59513) avg lploss: 0.00000
train epoch 1418 avg loss: 1022.27197 (A-MSE: 1018.10449) avg lploss: 0.00000
train epoch 1419 avg loss: 949.68928 (A-MSE: 991.71088) avg lploss: 0.00000
train epoch 1420 avg loss: 945.88720 (A-MSE: 984.64086) avg lploss: 0.00000
==> val epoch 1420 avg loss: 946.82131 (A-MSE: 976.43387) avg lploss: 0.00000
==> test epoch 1420 avg loss: 910.57046 (A-MSE: 949.01542) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 38 out of 50
train epoch 1421 avg loss: 972.89343 (A-MSE: 1013.03727) avg lploss: 0.00000
train epoch 1422 avg loss: 979.43673 (A-MSE: 1026.49566) avg lploss: 0.00000
train epoch 1423 avg loss: 933.58673 (A-MSE: 989.86832) avg lploss: 0.00000
train epoch 1424 avg loss: 912.14747 (A-MSE: 955.45269) avg lploss: 0.00000
train epoch 1425 avg loss: 909.25354 (A-MSE: 951.19430) avg lploss: 0.00000
==> val epoch 1425 avg loss: 920.87786 (A-MSE: 921.71702) avg lploss: 0.00000
==> test epoch 1425 avg loss: 915.68295 (A-MSE: 910.06838) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 39 out of 50
train epoch 1426 avg loss: 905.29911 (A-MSE: 938.36429) avg lploss: 0.00000
train epoch 1427 avg loss: 890.53815 (A-MSE: 927.81151) avg lploss: 0.00000
train epoch 1428 avg loss: 881.68432 (A-MSE: 916.82872) avg lploss: 0.00000
train epoch 1429 avg loss: 876.49376 (A-MSE: 906.11968) avg lploss: 0.00000
train epoch 1430 avg loss: 859.65200 (A-MSE: 894.79408) avg lploss: 0.00000
==> val epoch 1430 avg loss: 833.05788 (A-MSE: 851.02450) avg lploss: 0.00000
==> test epoch 1430 avg loss: 830.27039 (A-MSE: 847.50824) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 40 out of 50
train epoch 1431 avg loss: 862.17456 (A-MSE: 889.15586) avg lploss: 0.00000
train epoch 1432 avg loss: 1126.95385 (A-MSE: 1171.06827) avg lploss: 0.00000
train epoch 1433 avg loss: 3603.81262 (A-MSE: 3518.34775) avg lploss: 0.00000
train epoch 1434 avg loss: 2215.03484 (A-MSE: 2204.16409) avg lploss: 0.00000
train epoch 1435 avg loss: 1042.27436 (A-MSE: 1103.05474) avg lploss: 0.00000
==> val epoch 1435 avg loss: 945.11183 (A-MSE: 933.28070) avg lploss: 0.00000
==> test epoch 1435 avg loss: 920.81082 (A-MSE: 928.54612) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 41 out of 50
train epoch 1436 avg loss: 954.14824 (A-MSE: 965.28486) avg lploss: 0.00000
train epoch 1437 avg loss: 932.09402 (A-MSE: 945.27090) avg lploss: 0.00000
train epoch 1438 avg loss: 875.89433 (A-MSE: 901.29402) avg lploss: 0.00000
train epoch 1439 avg loss: 853.69235 (A-MSE: 881.03691) avg lploss: 0.00000
train epoch 1440 avg loss: 854.77455 (A-MSE: 879.94118) avg lploss: 0.00000
==> val epoch 1440 avg loss: 862.67752 (A-MSE: 854.26214) avg lploss: 0.00000
==> test epoch 1440 avg loss: 830.26935 (A-MSE: 847.58176) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 42 out of 50
train epoch 1441 avg loss: 852.99388 (A-MSE: 871.56469) avg lploss: 0.00000
train epoch 1442 avg loss: 954.58995 (A-MSE: 998.02893) avg lploss: 0.00000
train epoch 1443 avg loss: 881.63752 (A-MSE: 893.13136) avg lploss: 0.00000
train epoch 1444 avg loss: 832.85397 (A-MSE: 842.77908) avg lploss: 0.00000
train epoch 1445 avg loss: 813.31997 (A-MSE: 808.12711) avg lploss: 0.00000
==> val epoch 1445 avg loss: 801.28634 (A-MSE: 782.49294) avg lploss: 0.00000
==> test epoch 1445 avg loss: 790.25812 (A-MSE: 797.28132) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 43 out of 50
train epoch 1446 avg loss: 785.20905 (A-MSE: 757.85869) avg lploss: 0.00000
train epoch 1447 avg loss: 759.80083 (A-MSE: 736.40093) avg lploss: 0.00000
train epoch 1448 avg loss: 740.06139 (A-MSE: 723.16070) avg lploss: 0.00000
train epoch 1449 avg loss: 740.35183 (A-MSE: 719.32836) avg lploss: 0.00000
train epoch 1450 avg loss: 778.15474 (A-MSE: 747.93549) avg lploss: 0.00000
==> val epoch 1450 avg loss: 837.47277 (A-MSE: 790.79403) avg lploss: 0.00000
==> test epoch 1450 avg loss: 818.49714 (A-MSE: 813.36349) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 44 out of 50
train epoch 1451 avg loss: 804.56745 (A-MSE: 783.66578) avg lploss: 0.00000
train epoch 1452 avg loss: 730.49763 (A-MSE: 740.61058) avg lploss: 0.00000
train epoch 1453 avg loss: 680.40262 (A-MSE: 708.57185) avg lploss: 0.00000
train epoch 1454 avg loss: 673.22404 (A-MSE: 697.76379) avg lploss: 0.00000
train epoch 1455 avg loss: 738.98973 (A-MSE: 747.57870) avg lploss: 0.00000
==> val epoch 1455 avg loss: 740.18182 (A-MSE: 741.20395) avg lploss: 0.00000
==> test epoch 1455 avg loss: 740.40197 (A-MSE: 765.54583) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 45 out of 50
train epoch 1456 avg loss: 746.19337 (A-MSE: 740.28951) avg lploss: 0.00000
train epoch 1457 avg loss: 746.00159 (A-MSE: 754.57084) avg lploss: 0.00000
train epoch 1458 avg loss: 894.04556 (A-MSE: 881.97525) avg lploss: 0.00000
train epoch 1459 avg loss: 846.17413 (A-MSE: 849.67254) avg lploss: 0.00000
train epoch 1460 avg loss: 862.22563 (A-MSE: 868.24221) avg lploss: 0.00000
==> val epoch 1460 avg loss: 829.09804 (A-MSE: 846.73454) avg lploss: 0.00000
==> test epoch 1460 avg loss: 827.16751 (A-MSE: 867.01628) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 46 out of 50
train epoch 1461 avg loss: 857.55399 (A-MSE: 868.69189) avg lploss: 0.00000
train epoch 1462 avg loss: 863.89796 (A-MSE: 901.58433) avg lploss: 0.00000
train epoch 1463 avg loss: 923.26326 (A-MSE: 968.55507) avg lploss: 0.00000
train epoch 1464 avg loss: 954.21251 (A-MSE: 987.20840) avg lploss: 0.00000
train epoch 1465 avg loss: 948.99408 (A-MSE: 982.91749) avg lploss: 0.00000
==> val epoch 1465 avg loss: 911.02096 (A-MSE: 926.46898) avg lploss: 0.00000
==> test epoch 1465 avg loss: 931.48677 (A-MSE: 933.56151) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 47 out of 50
train epoch 1466 avg loss: 889.58432 (A-MSE: 907.77764) avg lploss: 0.00000
train epoch 1467 avg loss: 937.16043 (A-MSE: 954.99420) avg lploss: 0.00000
train epoch 1468 avg loss: 894.52422 (A-MSE: 910.86079) avg lploss: 0.00000
train epoch 1469 avg loss: 1027.56441 (A-MSE: 1076.39125) avg lploss: 0.00000
train epoch 1470 avg loss: 1286.78178 (A-MSE: 1340.82819) avg lploss: 0.00000
==> val epoch 1470 avg loss: 1242.71027 (A-MSE: 1399.82250) avg lploss: 0.00000
==> test epoch 1470 avg loss: 1167.55119 (A-MSE: 1351.23841) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 48 out of 50
train epoch 1471 avg loss: 1213.77287 (A-MSE: 1293.22945) avg lploss: 0.00000
train epoch 1472 avg loss: 1066.24929 (A-MSE: 1209.85073) avg lploss: 0.00000
train epoch 1473 avg loss: 1120.28587 (A-MSE: 1184.99351) avg lploss: 0.00000
train epoch 1474 avg loss: 1135.90374 (A-MSE: 1168.87798) avg lploss: 0.00000
train epoch 1475 avg loss: 966.85935 (A-MSE: 1032.21431) avg lploss: 0.00000
==> val epoch 1475 avg loss: 1024.11017 (A-MSE: 1122.86904) avg lploss: 0.00000
==> test epoch 1475 avg loss: 944.23082 (A-MSE: 1049.27939) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 49 out of 50
train epoch 1476 avg loss: 993.26901 (A-MSE: 1055.76851) avg lploss: 0.00000
train epoch 1477 avg loss: 986.66006 (A-MSE: 1050.55006) avg lploss: 0.00000
train epoch 1478 avg loss: 996.49140 (A-MSE: 1059.31600) avg lploss: 0.00000
train epoch 1479 avg loss: 923.40989 (A-MSE: 1021.52145) avg lploss: 0.00000
train epoch 1480 avg loss: 955.86516 (A-MSE: 1046.14874) avg lploss: 0.00000
==> val epoch 1480 avg loss: 1053.93644 (A-MSE: 1143.17200) avg lploss: 0.00000
==> test epoch 1480 avg loss: 1051.88831 (A-MSE: 1141.53478) avg lploss: 0.00000
*** Best Val Loss: 0.82285 	 Best Test Loss: 0.94989 	 Best epoch 1230
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.229441
best_lp = 0.000000
best_val = 0.822846
best_test = 0.949891
best_epoch = 1230
best_train = 0.229441, best_lp = 0.000000, best_val = 0.822846, best_test = 0.949891, best_epoch = 1230
Job completed at Sat Dec  6 08:21:17 CET 2025
