Running N-body with num_modes=3 for seed 4
Job ID: 3830365, Array Task ID: 4
Namespace(batch_size=100, config_by_file='configs/nbody_modes3_seed4.json', cuda=True, data_dir='simulation/dataset', decoder_layer=1, dropout=0.5, epochs=5000, exp_name='nbody_modes3_seed4', flat=False, interaction_layer=3, lambda_link=1, lambda_momentum=0.0, log_interval=1, lr=0.0001, max_training_samples=3000, model='egno', n_cluster=3, n_layers=4, nf=64, no_cuda=False, norm=False, num_modes=3, num_timesteps=5, outf='exp_results', patience=50, pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, use_last_snapshots=False, weight_decay=1e-08)
EGNO(
  (layers): ModuleList(
    (0-3): 4 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=131, out_features=64, bias=True)
            (1): SiLU()
            (2): Linear(in_features=64, out_features=64, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): SiLU()
          (2): Linear(in_features=64, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): SiLU()
          (2): Linear(in_features=64, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=64, bias=True)
          (1): SiLU()
          (2): Linear(in_features=64, out_features=64, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=33, out_features=64, bias=True)
  (time_conv_modules): ModuleList(
    (0-3): 4 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-3): 4 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/nbody_modes3_seed4/saved_model.pth
train epoch 0 avg loss: 32.26133 avg lploss: 0.00000
==> val epoch 0 avg loss: 0.37836 avg lploss: 0.00000
==> test epoch 0 avg loss: 0.46742 avg lploss: 0.00000
*** Best Val Loss: 0.37836 	 Best Test Loss: 0.46742 	 Best epoch 0
Validation loss decreased (inf --> 0.378362).  Saving model ...
train epoch 1 avg loss: 0.34171 avg lploss: 0.00000
train epoch 2 avg loss: 0.26658 avg lploss: 0.00000
train epoch 3 avg loss: 0.22149 avg lploss: 0.00000
train epoch 4 avg loss: 0.18483 avg lploss: 0.00000
train epoch 5 avg loss: 0.16191 avg lploss: 0.00000
==> val epoch 5 avg loss: 0.14353 avg lploss: 0.00000
==> test epoch 5 avg loss: 0.20693 avg lploss: 0.00000
*** Best Val Loss: 0.14353 	 Best Test Loss: 0.20693 	 Best epoch 5
Validation loss decreased (0.378362 --> 0.143534).  Saving model ...
train epoch 6 avg loss: 0.14937 avg lploss: 0.00000
train epoch 7 avg loss: 0.14049 avg lploss: 0.00000
train epoch 8 avg loss: 0.13234 avg lploss: 0.00000
train epoch 9 avg loss: 0.12809 avg lploss: 0.00000
train epoch 10 avg loss: 0.12087 avg lploss: 0.00000
==> val epoch 10 avg loss: 0.11551 avg lploss: 0.00000
==> test epoch 10 avg loss: 0.13424 avg lploss: 0.00000
*** Best Val Loss: 0.11551 	 Best Test Loss: 0.13424 	 Best epoch 10
Validation loss decreased (0.143534 --> 0.115512).  Saving model ...
train epoch 11 avg loss: 0.11846 avg lploss: 0.00000
train epoch 12 avg loss: 0.11380 avg lploss: 0.00000
train epoch 13 avg loss: 0.11090 avg lploss: 0.00000
train epoch 14 avg loss: 0.10837 avg lploss: 0.00000
train epoch 15 avg loss: 0.10509 avg lploss: 0.00000
==> val epoch 15 avg loss: 0.10172 avg lploss: 0.00000
==> test epoch 15 avg loss: 0.10894 avg lploss: 0.00000
*** Best Val Loss: 0.10172 	 Best Test Loss: 0.10894 	 Best epoch 15
Validation loss decreased (0.115512 --> 0.101719).  Saving model ...
train epoch 16 avg loss: 0.10203 avg lploss: 0.00000
train epoch 17 avg loss: 0.09878 avg lploss: 0.00000
train epoch 18 avg loss: 0.09509 avg lploss: 0.00000
train epoch 19 avg loss: 0.09112 avg lploss: 0.00000
train epoch 20 avg loss: 0.08688 avg lploss: 0.00000
==> val epoch 20 avg loss: 0.08371 avg lploss: 0.00000
==> test epoch 20 avg loss: 0.08565 avg lploss: 0.00000
*** Best Val Loss: 0.08371 	 Best Test Loss: 0.08565 	 Best epoch 20
Validation loss decreased (0.101719 --> 0.083714).  Saving model ...
train epoch 21 avg loss: 0.08234 avg lploss: 0.00000
train epoch 22 avg loss: 0.07826 avg lploss: 0.00000
train epoch 23 avg loss: 0.07540 avg lploss: 0.00000
train epoch 24 avg loss: 0.07344 avg lploss: 0.00000
train epoch 25 avg loss: 0.07212 avg lploss: 0.00000
==> val epoch 25 avg loss: 0.07130 avg lploss: 0.00000
==> test epoch 25 avg loss: 0.07136 avg lploss: 0.00000
*** Best Val Loss: 0.07130 	 Best Test Loss: 0.07136 	 Best epoch 25
Validation loss decreased (0.083714 --> 0.071302).  Saving model ...
train epoch 26 avg loss: 0.07106 avg lploss: 0.00000
train epoch 27 avg loss: 0.07020 avg lploss: 0.00000
train epoch 28 avg loss: 0.06937 avg lploss: 0.00000
train epoch 29 avg loss: 0.06864 avg lploss: 0.00000
train epoch 30 avg loss: 0.06801 avg lploss: 0.00000
==> val epoch 30 avg loss: 0.06742 avg lploss: 0.00000
==> test epoch 30 avg loss: 0.06729 avg lploss: 0.00000
*** Best Val Loss: 0.06742 	 Best Test Loss: 0.06729 	 Best epoch 30
Validation loss decreased (0.071302 --> 0.067420).  Saving model ...
train epoch 31 avg loss: 0.06744 avg lploss: 0.00000
train epoch 32 avg loss: 0.06687 avg lploss: 0.00000
train epoch 33 avg loss: 0.06641 avg lploss: 0.00000
train epoch 34 avg loss: 0.06596 avg lploss: 0.00000
train epoch 35 avg loss: 0.06559 avg lploss: 0.00000
==> val epoch 35 avg loss: 0.06503 avg lploss: 0.00000
==> test epoch 35 avg loss: 0.06480 avg lploss: 0.00000
*** Best Val Loss: 0.06503 	 Best Test Loss: 0.06480 	 Best epoch 35
Validation loss decreased (0.067420 --> 0.065031).  Saving model ...
train epoch 36 avg loss: 0.06521 avg lploss: 0.00000
train epoch 37 avg loss: 0.06489 avg lploss: 0.00000
train epoch 38 avg loss: 0.06457 avg lploss: 0.00000
train epoch 39 avg loss: 0.06430 avg lploss: 0.00000
train epoch 40 avg loss: 0.06401 avg lploss: 0.00000
==> val epoch 40 avg loss: 0.06352 avg lploss: 0.00000
==> test epoch 40 avg loss: 0.06319 avg lploss: 0.00000
*** Best Val Loss: 0.06352 	 Best Test Loss: 0.06319 	 Best epoch 40
Validation loss decreased (0.065031 --> 0.063522).  Saving model ...
train epoch 41 avg loss: 0.06375 avg lploss: 0.00000
train epoch 42 avg loss: 0.06348 avg lploss: 0.00000
train epoch 43 avg loss: 0.06322 avg lploss: 0.00000
train epoch 44 avg loss: 0.06298 avg lploss: 0.00000
train epoch 45 avg loss: 0.06273 avg lploss: 0.00000
==> val epoch 45 avg loss: 0.06231 avg lploss: 0.00000
==> test epoch 45 avg loss: 0.06165 avg lploss: 0.00000
*** Best Val Loss: 0.06231 	 Best Test Loss: 0.06165 	 Best epoch 45
Validation loss decreased (0.063522 --> 0.062312).  Saving model ...
train epoch 46 avg loss: 0.06251 avg lploss: 0.00000
train epoch 47 avg loss: 0.06225 avg lploss: 0.00000
train epoch 48 avg loss: 0.06200 avg lploss: 0.00000
train epoch 49 avg loss: 0.06179 avg lploss: 0.00000
train epoch 50 avg loss: 0.06155 avg lploss: 0.00000
==> val epoch 50 avg loss: 0.06118 avg lploss: 0.00000
==> test epoch 50 avg loss: 0.06025 avg lploss: 0.00000
*** Best Val Loss: 0.06118 	 Best Test Loss: 0.06025 	 Best epoch 50
Validation loss decreased (0.062312 --> 0.061184).  Saving model ...
train epoch 51 avg loss: 0.06131 avg lploss: 0.00000
train epoch 52 avg loss: 0.06108 avg lploss: 0.00000
train epoch 53 avg loss: 0.06086 avg lploss: 0.00000
train epoch 54 avg loss: 0.06063 avg lploss: 0.00000
train epoch 55 avg loss: 0.06041 avg lploss: 0.00000
==> val epoch 55 avg loss: 0.06010 avg lploss: 0.00000
==> test epoch 55 avg loss: 0.05889 avg lploss: 0.00000
*** Best Val Loss: 0.06010 	 Best Test Loss: 0.05889 	 Best epoch 55
Validation loss decreased (0.061184 --> 0.060096).  Saving model ...
train epoch 56 avg loss: 0.06019 avg lploss: 0.00000
train epoch 57 avg loss: 0.05997 avg lploss: 0.00000
train epoch 58 avg loss: 0.05975 avg lploss: 0.00000
train epoch 59 avg loss: 0.05954 avg lploss: 0.00000
train epoch 60 avg loss: 0.05934 avg lploss: 0.00000
==> val epoch 60 avg loss: 0.05907 avg lploss: 0.00000
==> test epoch 60 avg loss: 0.05770 avg lploss: 0.00000
*** Best Val Loss: 0.05907 	 Best Test Loss: 0.05770 	 Best epoch 60
Validation loss decreased (0.060096 --> 0.059066).  Saving model ...
train epoch 61 avg loss: 0.05912 avg lploss: 0.00000
train epoch 62 avg loss: 0.05892 avg lploss: 0.00000
train epoch 63 avg loss: 0.05871 avg lploss: 0.00000
train epoch 64 avg loss: 0.05851 avg lploss: 0.00000
train epoch 65 avg loss: 0.05830 avg lploss: 0.00000
==> val epoch 65 avg loss: 0.05807 avg lploss: 0.00000
==> test epoch 65 avg loss: 0.05665 avg lploss: 0.00000
*** Best Val Loss: 0.05807 	 Best Test Loss: 0.05665 	 Best epoch 65
Validation loss decreased (0.059066 --> 0.058070).  Saving model ...
train epoch 66 avg loss: 0.05810 avg lploss: 0.00000
train epoch 67 avg loss: 0.05789 avg lploss: 0.00000
train epoch 68 avg loss: 0.05768 avg lploss: 0.00000
train epoch 69 avg loss: 0.05748 avg lploss: 0.00000
train epoch 70 avg loss: 0.05728 avg lploss: 0.00000
==> val epoch 70 avg loss: 0.05705 avg lploss: 0.00000
==> test epoch 70 avg loss: 0.05558 avg lploss: 0.00000
*** Best Val Loss: 0.05705 	 Best Test Loss: 0.05558 	 Best epoch 70
Validation loss decreased (0.058070 --> 0.057047).  Saving model ...
train epoch 71 avg loss: 0.05706 avg lploss: 0.00000
train epoch 72 avg loss: 0.05683 avg lploss: 0.00000
train epoch 73 avg loss: 0.05662 avg lploss: 0.00000
train epoch 74 avg loss: 0.05640 avg lploss: 0.00000
train epoch 75 avg loss: 0.05618 avg lploss: 0.00000
==> val epoch 75 avg loss: 0.05596 avg lploss: 0.00000
==> test epoch 75 avg loss: 0.05462 avg lploss: 0.00000
*** Best Val Loss: 0.05596 	 Best Test Loss: 0.05462 	 Best epoch 75
Validation loss decreased (0.057047 --> 0.055959).  Saving model ...
train epoch 76 avg loss: 0.05594 avg lploss: 0.00000
train epoch 77 avg loss: 0.05569 avg lploss: 0.00000
train epoch 78 avg loss: 0.05546 avg lploss: 0.00000
train epoch 79 avg loss: 0.05520 avg lploss: 0.00000
train epoch 80 avg loss: 0.05494 avg lploss: 0.00000
==> val epoch 80 avg loss: 0.05469 avg lploss: 0.00000
==> test epoch 80 avg loss: 0.05337 avg lploss: 0.00000
*** Best Val Loss: 0.05469 	 Best Test Loss: 0.05337 	 Best epoch 80
Validation loss decreased (0.055959 --> 0.054691).  Saving model ...
train epoch 81 avg loss: 0.05466 avg lploss: 0.00000
train epoch 82 avg loss: 0.05438 avg lploss: 0.00000
train epoch 83 avg loss: 0.05408 avg lploss: 0.00000
train epoch 84 avg loss: 0.05379 avg lploss: 0.00000
train epoch 85 avg loss: 0.05349 avg lploss: 0.00000
==> val epoch 85 avg loss: 0.05318 avg lploss: 0.00000
==> test epoch 85 avg loss: 0.05190 avg lploss: 0.00000
*** Best Val Loss: 0.05318 	 Best Test Loss: 0.05190 	 Best epoch 85
Validation loss decreased (0.054691 --> 0.053178).  Saving model ...
train epoch 86 avg loss: 0.05316 avg lploss: 0.00000
train epoch 87 avg loss: 0.05282 avg lploss: 0.00000
train epoch 88 avg loss: 0.05247 avg lploss: 0.00000
train epoch 89 avg loss: 0.05212 avg lploss: 0.00000
train epoch 90 avg loss: 0.05173 avg lploss: 0.00000
==> val epoch 90 avg loss: 0.05138 avg lploss: 0.00000
==> test epoch 90 avg loss: 0.05022 avg lploss: 0.00000
*** Best Val Loss: 0.05138 	 Best Test Loss: 0.05022 	 Best epoch 90
Validation loss decreased (0.053178 --> 0.051382).  Saving model ...
train epoch 91 avg loss: 0.05135 avg lploss: 0.00000
train epoch 92 avg loss: 0.05095 avg lploss: 0.00000
train epoch 93 avg loss: 0.05053 avg lploss: 0.00000
train epoch 94 avg loss: 0.05011 avg lploss: 0.00000
train epoch 95 avg loss: 0.04968 avg lploss: 0.00000
==> val epoch 95 avg loss: 0.04921 avg lploss: 0.00000
==> test epoch 95 avg loss: 0.04816 avg lploss: 0.00000
*** Best Val Loss: 0.04921 	 Best Test Loss: 0.04816 	 Best epoch 95
Validation loss decreased (0.051382 --> 0.049206).  Saving model ...
train epoch 96 avg loss: 0.04922 avg lploss: 0.00000
train epoch 97 avg loss: 0.04874 avg lploss: 0.00000
train epoch 98 avg loss: 0.04826 avg lploss: 0.00000
train epoch 99 avg loss: 0.04778 avg lploss: 0.00000
train epoch 100 avg loss: 0.04727 avg lploss: 0.00000
==> val epoch 100 avg loss: 0.04672 avg lploss: 0.00000
==> test epoch 100 avg loss: 0.04585 avg lploss: 0.00000
*** Best Val Loss: 0.04672 	 Best Test Loss: 0.04585 	 Best epoch 100
Validation loss decreased (0.049206 --> 0.046718).  Saving model ...
train epoch 101 avg loss: 0.04675 avg lploss: 0.00000
train epoch 102 avg loss: 0.04623 avg lploss: 0.00000
train epoch 103 avg loss: 0.04571 avg lploss: 0.00000
train epoch 104 avg loss: 0.04518 avg lploss: 0.00000
train epoch 105 avg loss: 0.04464 avg lploss: 0.00000
==> val epoch 105 avg loss: 0.04410 avg lploss: 0.00000
==> test epoch 105 avg loss: 0.04335 avg lploss: 0.00000
*** Best Val Loss: 0.04410 	 Best Test Loss: 0.04335 	 Best epoch 105
Validation loss decreased (0.046718 --> 0.044097).  Saving model ...
train epoch 106 avg loss: 0.04415 avg lploss: 0.00000
train epoch 107 avg loss: 0.04360 avg lploss: 0.00000
train epoch 108 avg loss: 0.04303 avg lploss: 0.00000
train epoch 109 avg loss: 0.04251 avg lploss: 0.00000
train epoch 110 avg loss: 0.04199 avg lploss: 0.00000
==> val epoch 110 avg loss: 0.04149 avg lploss: 0.00000
==> test epoch 110 avg loss: 0.04094 avg lploss: 0.00000
*** Best Val Loss: 0.04149 	 Best Test Loss: 0.04094 	 Best epoch 110
Validation loss decreased (0.044097 --> 0.041494).  Saving model ...
train epoch 111 avg loss: 0.04144 avg lploss: 0.00000
train epoch 112 avg loss: 0.04093 avg lploss: 0.00000
train epoch 113 avg loss: 0.04044 avg lploss: 0.00000
train epoch 114 avg loss: 0.03990 avg lploss: 0.00000
train epoch 115 avg loss: 0.03944 avg lploss: 0.00000
==> val epoch 115 avg loss: 0.03903 avg lploss: 0.00000
==> test epoch 115 avg loss: 0.03880 avg lploss: 0.00000
*** Best Val Loss: 0.03903 	 Best Test Loss: 0.03880 	 Best epoch 115
Validation loss decreased (0.041494 --> 0.039026).  Saving model ...
train epoch 116 avg loss: 0.03892 avg lploss: 0.00000
train epoch 117 avg loss: 0.03843 avg lploss: 0.00000
train epoch 118 avg loss: 0.03797 avg lploss: 0.00000
train epoch 119 avg loss: 0.03751 avg lploss: 0.00000
train epoch 120 avg loss: 0.03706 avg lploss: 0.00000
==> val epoch 120 avg loss: 0.03674 avg lploss: 0.00000
==> test epoch 120 avg loss: 0.03653 avg lploss: 0.00000
*** Best Val Loss: 0.03674 	 Best Test Loss: 0.03653 	 Best epoch 120
Validation loss decreased (0.039026 --> 0.036745).  Saving model ...
train epoch 121 avg loss: 0.03659 avg lploss: 0.00000
train epoch 122 avg loss: 0.03619 avg lploss: 0.00000
train epoch 123 avg loss: 0.03574 avg lploss: 0.00000
train epoch 124 avg loss: 0.03534 avg lploss: 0.00000
train epoch 125 avg loss: 0.03489 avg lploss: 0.00000
==> val epoch 125 avg loss: 0.03463 avg lploss: 0.00000
==> test epoch 125 avg loss: 0.03459 avg lploss: 0.00000
*** Best Val Loss: 0.03463 	 Best Test Loss: 0.03459 	 Best epoch 125
Validation loss decreased (0.036745 --> 0.034626).  Saving model ...
train epoch 126 avg loss: 0.03451 avg lploss: 0.00000
train epoch 127 avg loss: 0.03408 avg lploss: 0.00000
train epoch 128 avg loss: 0.03371 avg lploss: 0.00000
train epoch 129 avg loss: 0.03328 avg lploss: 0.00000
train epoch 130 avg loss: 0.03288 avg lploss: 0.00000
==> val epoch 130 avg loss: 0.03259 avg lploss: 0.00000
==> test epoch 130 avg loss: 0.03296 avg lploss: 0.00000
*** Best Val Loss: 0.03259 	 Best Test Loss: 0.03296 	 Best epoch 130
Validation loss decreased (0.034626 --> 0.032586).  Saving model ...
train epoch 131 avg loss: 0.03248 avg lploss: 0.00000
train epoch 132 avg loss: 0.03208 avg lploss: 0.00000
train epoch 133 avg loss: 0.03165 avg lploss: 0.00000
train epoch 134 avg loss: 0.03124 avg lploss: 0.00000
train epoch 135 avg loss: 0.03082 avg lploss: 0.00000
==> val epoch 135 avg loss: 0.03047 avg lploss: 0.00000
==> test epoch 135 avg loss: 0.03093 avg lploss: 0.00000
*** Best Val Loss: 0.03047 	 Best Test Loss: 0.03093 	 Best epoch 135
Validation loss decreased (0.032586 --> 0.030466).  Saving model ...
train epoch 136 avg loss: 0.03040 avg lploss: 0.00000
train epoch 137 avg loss: 0.02997 avg lploss: 0.00000
train epoch 138 avg loss: 0.02955 avg lploss: 0.00000
train epoch 139 avg loss: 0.02909 avg lploss: 0.00000
train epoch 140 avg loss: 0.02860 avg lploss: 0.00000
==> val epoch 140 avg loss: 0.02820 avg lploss: 0.00000
==> test epoch 140 avg loss: 0.02882 avg lploss: 0.00000
*** Best Val Loss: 0.02820 	 Best Test Loss: 0.02882 	 Best epoch 140
Validation loss decreased (0.030466 --> 0.028196).  Saving model ...
train epoch 141 avg loss: 0.02819 avg lploss: 0.00000
train epoch 142 avg loss: 0.02772 avg lploss: 0.00000
train epoch 143 avg loss: 0.02720 avg lploss: 0.00000
train epoch 144 avg loss: 0.02674 avg lploss: 0.00000
train epoch 145 avg loss: 0.02624 avg lploss: 0.00000
==> val epoch 145 avg loss: 0.02583 avg lploss: 0.00000
==> test epoch 145 avg loss: 0.02669 avg lploss: 0.00000
*** Best Val Loss: 0.02583 	 Best Test Loss: 0.02669 	 Best epoch 145
Validation loss decreased (0.028196 --> 0.025834).  Saving model ...
train epoch 146 avg loss: 0.02575 avg lploss: 0.00000
train epoch 147 avg loss: 0.02530 avg lploss: 0.00000
train epoch 148 avg loss: 0.02475 avg lploss: 0.00000
train epoch 149 avg loss: 0.02427 avg lploss: 0.00000
train epoch 150 avg loss: 0.02384 avg lploss: 0.00000
==> val epoch 150 avg loss: 0.02337 avg lploss: 0.00000
==> test epoch 150 avg loss: 0.02424 avg lploss: 0.00000
*** Best Val Loss: 0.02337 	 Best Test Loss: 0.02424 	 Best epoch 150
Validation loss decreased (0.025834 --> 0.023370).  Saving model ...
train epoch 151 avg loss: 0.02330 avg lploss: 0.00000
train epoch 152 avg loss: 0.02284 avg lploss: 0.00000
train epoch 153 avg loss: 0.02242 avg lploss: 0.00000
train epoch 154 avg loss: 0.02201 avg lploss: 0.00000
train epoch 155 avg loss: 0.02163 avg lploss: 0.00000
==> val epoch 155 avg loss: 0.02141 avg lploss: 0.00000
==> test epoch 155 avg loss: 0.02219 avg lploss: 0.00000
*** Best Val Loss: 0.02141 	 Best Test Loss: 0.02219 	 Best epoch 155
Validation loss decreased (0.023370 --> 0.021410).  Saving model ...
train epoch 156 avg loss: 0.02132 avg lploss: 0.00000
train epoch 157 avg loss: 0.02098 avg lploss: 0.00000
train epoch 158 avg loss: 0.02070 avg lploss: 0.00000
train epoch 159 avg loss: 0.02039 avg lploss: 0.00000
train epoch 160 avg loss: 0.02023 avg lploss: 0.00000
==> val epoch 160 avg loss: 0.01991 avg lploss: 0.00000
==> test epoch 160 avg loss: 0.02049 avg lploss: 0.00000
*** Best Val Loss: 0.01991 	 Best Test Loss: 0.02049 	 Best epoch 160
Validation loss decreased (0.021410 --> 0.019913).  Saving model ...
train epoch 161 avg loss: 0.01986 avg lploss: 0.00000
train epoch 162 avg loss: 0.01964 avg lploss: 0.00000
train epoch 163 avg loss: 0.01941 avg lploss: 0.00000
train epoch 164 avg loss: 0.01922 avg lploss: 0.00000
train epoch 165 avg loss: 0.01904 avg lploss: 0.00000
==> val epoch 165 avg loss: 0.01877 avg lploss: 0.00000
==> test epoch 165 avg loss: 0.01908 avg lploss: 0.00000
*** Best Val Loss: 0.01877 	 Best Test Loss: 0.01908 	 Best epoch 165
Validation loss decreased (0.019913 --> 0.018771).  Saving model ...
train epoch 166 avg loss: 0.01882 avg lploss: 0.00000
train epoch 167 avg loss: 0.01867 avg lploss: 0.00000
train epoch 168 avg loss: 0.01861 avg lploss: 0.00000
train epoch 169 avg loss: 0.01851 avg lploss: 0.00000
train epoch 170 avg loss: 0.01817 avg lploss: 0.00000
==> val epoch 170 avg loss: 0.01783 avg lploss: 0.00000
==> test epoch 170 avg loss: 0.01759 avg lploss: 0.00000
*** Best Val Loss: 0.01783 	 Best Test Loss: 0.01759 	 Best epoch 170
Validation loss decreased (0.018771 --> 0.017831).  Saving model ...
train epoch 171 avg loss: 0.01823 avg lploss: 0.00000
train epoch 172 avg loss: 0.01781 avg lploss: 0.00000
train epoch 173 avg loss: 0.01779 avg lploss: 0.00000
train epoch 174 avg loss: 0.01773 avg lploss: 0.00000
train epoch 175 avg loss: 0.01743 avg lploss: 0.00000
==> val epoch 175 avg loss: 0.01713 avg lploss: 0.00000
==> test epoch 175 avg loss: 0.01694 avg lploss: 0.00000
*** Best Val Loss: 0.01713 	 Best Test Loss: 0.01694 	 Best epoch 175
Validation loss decreased (0.017831 --> 0.017128).  Saving model ...
train epoch 176 avg loss: 0.01727 avg lploss: 0.00000
train epoch 177 avg loss: 0.01714 avg lploss: 0.00000
train epoch 178 avg loss: 0.01703 avg lploss: 0.00000
train epoch 179 avg loss: 0.01690 avg lploss: 0.00000
train epoch 180 avg loss: 0.01683 avg lploss: 0.00000
==> val epoch 180 avg loss: 0.01656 avg lploss: 0.00000
==> test epoch 180 avg loss: 0.01612 avg lploss: 0.00000
*** Best Val Loss: 0.01656 	 Best Test Loss: 0.01612 	 Best epoch 180
Validation loss decreased (0.017128 --> 0.016565).  Saving model ...
train epoch 181 avg loss: 0.01676 avg lploss: 0.00000
train epoch 182 avg loss: 0.01664 avg lploss: 0.00000
train epoch 183 avg loss: 0.01657 avg lploss: 0.00000
train epoch 184 avg loss: 0.01649 avg lploss: 0.00000
train epoch 185 avg loss: 0.01651 avg lploss: 0.00000
==> val epoch 185 avg loss: 0.01623 avg lploss: 0.00000
==> test epoch 185 avg loss: 0.01585 avg lploss: 0.00000
*** Best Val Loss: 0.01623 	 Best Test Loss: 0.01585 	 Best epoch 185
Validation loss decreased (0.016565 --> 0.016232).  Saving model ...
train epoch 186 avg loss: 0.01632 avg lploss: 0.00000
train epoch 187 avg loss: 0.01629 avg lploss: 0.00000
train epoch 188 avg loss: 0.01622 avg lploss: 0.00000
train epoch 189 avg loss: 0.01614 avg lploss: 0.00000
train epoch 190 avg loss: 0.01613 avg lploss: 0.00000
==> val epoch 190 avg loss: 0.01612 avg lploss: 0.00000
==> test epoch 190 avg loss: 0.01552 avg lploss: 0.00000
*** Best Val Loss: 0.01612 	 Best Test Loss: 0.01552 	 Best epoch 190
Validation loss decreased (0.016232 --> 0.016119).  Saving model ...
train epoch 191 avg loss: 0.01613 avg lploss: 0.00000
train epoch 192 avg loss: 0.01595 avg lploss: 0.00000
train epoch 193 avg loss: 0.01584 avg lploss: 0.00000
train epoch 194 avg loss: 0.01583 avg lploss: 0.00000
train epoch 195 avg loss: 0.01579 avg lploss: 0.00000
==> val epoch 195 avg loss: 0.01551 avg lploss: 0.00000
==> test epoch 195 avg loss: 0.01510 avg lploss: 0.00000
*** Best Val Loss: 0.01551 	 Best Test Loss: 0.01510 	 Best epoch 195
Validation loss decreased (0.016119 --> 0.015508).  Saving model ...
train epoch 196 avg loss: 0.01581 avg lploss: 0.00000
train epoch 197 avg loss: 0.01592 avg lploss: 0.00000
train epoch 198 avg loss: 0.01585 avg lploss: 0.00000
train epoch 199 avg loss: 0.01564 avg lploss: 0.00000
train epoch 200 avg loss: 0.01551 avg lploss: 0.00000
==> val epoch 200 avg loss: 0.01530 avg lploss: 0.00000
==> test epoch 200 avg loss: 0.01478 avg lploss: 0.00000
*** Best Val Loss: 0.01530 	 Best Test Loss: 0.01478 	 Best epoch 200
Validation loss decreased (0.015508 --> 0.015303).  Saving model ...
train epoch 201 avg loss: 0.01547 avg lploss: 0.00000
train epoch 202 avg loss: 0.01542 avg lploss: 0.00000
train epoch 203 avg loss: 0.01544 avg lploss: 0.00000
train epoch 204 avg loss: 0.01535 avg lploss: 0.00000
train epoch 205 avg loss: 0.01535 avg lploss: 0.00000
==> val epoch 205 avg loss: 0.01512 avg lploss: 0.00000
==> test epoch 205 avg loss: 0.01455 avg lploss: 0.00000
*** Best Val Loss: 0.01512 	 Best Test Loss: 0.01455 	 Best epoch 205
Validation loss decreased (0.015303 --> 0.015125).  Saving model ...
train epoch 206 avg loss: 0.01539 avg lploss: 0.00000
train epoch 207 avg loss: 0.01532 avg lploss: 0.00000
train epoch 208 avg loss: 0.01542 avg lploss: 0.00000
train epoch 209 avg loss: 0.01528 avg lploss: 0.00000
train epoch 210 avg loss: 0.01525 avg lploss: 0.00000
==> val epoch 210 avg loss: 0.01498 avg lploss: 0.00000
==> test epoch 210 avg loss: 0.01452 avg lploss: 0.00000
*** Best Val Loss: 0.01498 	 Best Test Loss: 0.01452 	 Best epoch 210
Validation loss decreased (0.015125 --> 0.014976).  Saving model ...
train epoch 211 avg loss: 0.01513 avg lploss: 0.00000
train epoch 212 avg loss: 0.01512 avg lploss: 0.00000
train epoch 213 avg loss: 0.01513 avg lploss: 0.00000
train epoch 214 avg loss: 0.01511 avg lploss: 0.00000
train epoch 215 avg loss: 0.01517 avg lploss: 0.00000
==> val epoch 215 avg loss: 0.01483 avg lploss: 0.00000
==> test epoch 215 avg loss: 0.01438 avg lploss: 0.00000
*** Best Val Loss: 0.01483 	 Best Test Loss: 0.01438 	 Best epoch 215
Validation loss decreased (0.014976 --> 0.014833).  Saving model ...
train epoch 216 avg loss: 0.01506 avg lploss: 0.00000
train epoch 217 avg loss: 0.01498 avg lploss: 0.00000
train epoch 218 avg loss: 0.01504 avg lploss: 0.00000
train epoch 219 avg loss: 0.01500 avg lploss: 0.00000
train epoch 220 avg loss: 0.01494 avg lploss: 0.00000
==> val epoch 220 avg loss: 0.01476 avg lploss: 0.00000
==> test epoch 220 avg loss: 0.01428 avg lploss: 0.00000
*** Best Val Loss: 0.01476 	 Best Test Loss: 0.01428 	 Best epoch 220
Validation loss decreased (0.014833 --> 0.014762).  Saving model ...
train epoch 221 avg loss: 0.01491 avg lploss: 0.00000
train epoch 222 avg loss: 0.01495 avg lploss: 0.00000
train epoch 223 avg loss: 0.01488 avg lploss: 0.00000
train epoch 224 avg loss: 0.01484 avg lploss: 0.00000
train epoch 225 avg loss: 0.01483 avg lploss: 0.00000
==> val epoch 225 avg loss: 0.01457 avg lploss: 0.00000
==> test epoch 225 avg loss: 0.01413 avg lploss: 0.00000
*** Best Val Loss: 0.01457 	 Best Test Loss: 0.01413 	 Best epoch 225
Validation loss decreased (0.014762 --> 0.014566).  Saving model ...
train epoch 226 avg loss: 0.01481 avg lploss: 0.00000
train epoch 227 avg loss: 0.01479 avg lploss: 0.00000
train epoch 228 avg loss: 0.01484 avg lploss: 0.00000
train epoch 229 avg loss: 0.01487 avg lploss: 0.00000
train epoch 230 avg loss: 0.01479 avg lploss: 0.00000
==> val epoch 230 avg loss: 0.01454 avg lploss: 0.00000
==> test epoch 230 avg loss: 0.01407 avg lploss: 0.00000
*** Best Val Loss: 0.01454 	 Best Test Loss: 0.01407 	 Best epoch 230
Validation loss decreased (0.014566 --> 0.014544).  Saving model ...
train epoch 231 avg loss: 0.01474 avg lploss: 0.00000
train epoch 232 avg loss: 0.01470 avg lploss: 0.00000
train epoch 233 avg loss: 0.01467 avg lploss: 0.00000
train epoch 234 avg loss: 0.01461 avg lploss: 0.00000
train epoch 235 avg loss: 0.01462 avg lploss: 0.00000
==> val epoch 235 avg loss: 0.01438 avg lploss: 0.00000
==> test epoch 235 avg loss: 0.01401 avg lploss: 0.00000
*** Best Val Loss: 0.01438 	 Best Test Loss: 0.01401 	 Best epoch 235
Validation loss decreased (0.014544 --> 0.014379).  Saving model ...
train epoch 236 avg loss: 0.01472 avg lploss: 0.00000
train epoch 237 avg loss: 0.01468 avg lploss: 0.00000
train epoch 238 avg loss: 0.01476 avg lploss: 0.00000
train epoch 239 avg loss: 0.01477 avg lploss: 0.00000
train epoch 240 avg loss: 0.01464 avg lploss: 0.00000
==> val epoch 240 avg loss: 0.01443 avg lploss: 0.00000
==> test epoch 240 avg loss: 0.01379 avg lploss: 0.00000
*** Best Val Loss: 0.01438 	 Best Test Loss: 0.01401 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.01458 avg lploss: 0.00000
train epoch 242 avg loss: 0.01454 avg lploss: 0.00000
train epoch 243 avg loss: 0.01456 avg lploss: 0.00000
train epoch 244 avg loss: 0.01447 avg lploss: 0.00000
train epoch 245 avg loss: 0.01446 avg lploss: 0.00000
==> val epoch 245 avg loss: 0.01428 avg lploss: 0.00000
==> test epoch 245 avg loss: 0.01364 avg lploss: 0.00000
*** Best Val Loss: 0.01428 	 Best Test Loss: 0.01364 	 Best epoch 245
Validation loss decreased (0.014379 --> 0.014279).  Saving model ...
train epoch 246 avg loss: 0.01452 avg lploss: 0.00000
train epoch 247 avg loss: 0.01445 avg lploss: 0.00000
train epoch 248 avg loss: 0.01447 avg lploss: 0.00000
train epoch 249 avg loss: 0.01451 avg lploss: 0.00000
train epoch 250 avg loss: 0.01450 avg lploss: 0.00000
==> val epoch 250 avg loss: 0.01421 avg lploss: 0.00000
==> test epoch 250 avg loss: 0.01357 avg lploss: 0.00000
*** Best Val Loss: 0.01421 	 Best Test Loss: 0.01357 	 Best epoch 250
Validation loss decreased (0.014279 --> 0.014211).  Saving model ...
train epoch 251 avg loss: 0.01441 avg lploss: 0.00000
train epoch 252 avg loss: 0.01453 avg lploss: 0.00000
train epoch 253 avg loss: 0.01457 avg lploss: 0.00000
train epoch 254 avg loss: 0.01439 avg lploss: 0.00000
train epoch 255 avg loss: 0.01441 avg lploss: 0.00000
==> val epoch 255 avg loss: 0.01410 avg lploss: 0.00000
==> test epoch 255 avg loss: 0.01340 avg lploss: 0.00000
*** Best Val Loss: 0.01410 	 Best Test Loss: 0.01340 	 Best epoch 255
Validation loss decreased (0.014211 --> 0.014102).  Saving model ...
train epoch 256 avg loss: 0.01432 avg lploss: 0.00000
train epoch 257 avg loss: 0.01437 avg lploss: 0.00000
train epoch 258 avg loss: 0.01429 avg lploss: 0.00000
train epoch 259 avg loss: 0.01425 avg lploss: 0.00000
train epoch 260 avg loss: 0.01423 avg lploss: 0.00000
==> val epoch 260 avg loss: 0.01398 avg lploss: 0.00000
==> test epoch 260 avg loss: 0.01329 avg lploss: 0.00000
*** Best Val Loss: 0.01398 	 Best Test Loss: 0.01329 	 Best epoch 260
Validation loss decreased (0.014102 --> 0.013984).  Saving model ...
train epoch 261 avg loss: 0.01419 avg lploss: 0.00000
train epoch 262 avg loss: 0.01416 avg lploss: 0.00000
train epoch 263 avg loss: 0.01416 avg lploss: 0.00000
train epoch 264 avg loss: 0.01413 avg lploss: 0.00000
train epoch 265 avg loss: 0.01409 avg lploss: 0.00000
==> val epoch 265 avg loss: 0.01399 avg lploss: 0.00000
==> test epoch 265 avg loss: 0.01324 avg lploss: 0.00000
*** Best Val Loss: 0.01398 	 Best Test Loss: 0.01329 	 Best epoch 260
EarlyStopping counter: 1 out of 50
train epoch 266 avg loss: 0.01415 avg lploss: 0.00000
train epoch 267 avg loss: 0.01412 avg lploss: 0.00000
train epoch 268 avg loss: 0.01402 avg lploss: 0.00000
train epoch 269 avg loss: 0.01401 avg lploss: 0.00000
train epoch 270 avg loss: 0.01402 avg lploss: 0.00000
==> val epoch 270 avg loss: 0.01382 avg lploss: 0.00000
==> test epoch 270 avg loss: 0.01311 avg lploss: 0.00000
*** Best Val Loss: 0.01382 	 Best Test Loss: 0.01311 	 Best epoch 270
Validation loss decreased (0.013984 --> 0.013817).  Saving model ...
train epoch 271 avg loss: 0.01405 avg lploss: 0.00000
train epoch 272 avg loss: 0.01402 avg lploss: 0.00000
train epoch 273 avg loss: 0.01396 avg lploss: 0.00000
train epoch 274 avg loss: 0.01395 avg lploss: 0.00000
train epoch 275 avg loss: 0.01393 avg lploss: 0.00000
==> val epoch 275 avg loss: 0.01370 avg lploss: 0.00000
==> test epoch 275 avg loss: 0.01303 avg lploss: 0.00000
*** Best Val Loss: 0.01370 	 Best Test Loss: 0.01303 	 Best epoch 275
Validation loss decreased (0.013817 --> 0.013701).  Saving model ...
train epoch 276 avg loss: 0.01387 avg lploss: 0.00000
train epoch 277 avg loss: 0.01395 avg lploss: 0.00000
train epoch 278 avg loss: 0.01387 avg lploss: 0.00000
train epoch 279 avg loss: 0.01386 avg lploss: 0.00000
train epoch 280 avg loss: 0.01382 avg lploss: 0.00000
==> val epoch 280 avg loss: 0.01366 avg lploss: 0.00000
==> test epoch 280 avg loss: 0.01295 avg lploss: 0.00000
*** Best Val Loss: 0.01366 	 Best Test Loss: 0.01295 	 Best epoch 280
Validation loss decreased (0.013701 --> 0.013656).  Saving model ...
train epoch 281 avg loss: 0.01384 avg lploss: 0.00000
train epoch 282 avg loss: 0.01381 avg lploss: 0.00000
train epoch 283 avg loss: 0.01383 avg lploss: 0.00000
train epoch 284 avg loss: 0.01376 avg lploss: 0.00000
train epoch 285 avg loss: 0.01381 avg lploss: 0.00000
==> val epoch 285 avg loss: 0.01359 avg lploss: 0.00000
==> test epoch 285 avg loss: 0.01303 avg lploss: 0.00000
*** Best Val Loss: 0.01359 	 Best Test Loss: 0.01303 	 Best epoch 285
Validation loss decreased (0.013656 --> 0.013593).  Saving model ...
train epoch 286 avg loss: 0.01387 avg lploss: 0.00000
train epoch 287 avg loss: 0.01379 avg lploss: 0.00000
train epoch 288 avg loss: 0.01375 avg lploss: 0.00000
train epoch 289 avg loss: 0.01363 avg lploss: 0.00000
train epoch 290 avg loss: 0.01368 avg lploss: 0.00000
==> val epoch 290 avg loss: 0.01388 avg lploss: 0.00000
==> test epoch 290 avg loss: 0.01319 avg lploss: 0.00000
*** Best Val Loss: 0.01359 	 Best Test Loss: 0.01303 	 Best epoch 285
EarlyStopping counter: 1 out of 50
train epoch 291 avg loss: 0.01382 avg lploss: 0.00000
train epoch 292 avg loss: 0.01362 avg lploss: 0.00000
train epoch 293 avg loss: 0.01356 avg lploss: 0.00000
train epoch 294 avg loss: 0.01351 avg lploss: 0.00000
train epoch 295 avg loss: 0.01349 avg lploss: 0.00000
==> val epoch 295 avg loss: 0.01322 avg lploss: 0.00000
==> test epoch 295 avg loss: 0.01262 avg lploss: 0.00000
*** Best Val Loss: 0.01322 	 Best Test Loss: 0.01262 	 Best epoch 295
Validation loss decreased (0.013593 --> 0.013221).  Saving model ...
train epoch 296 avg loss: 0.01343 avg lploss: 0.00000
train epoch 297 avg loss: 0.01349 avg lploss: 0.00000
train epoch 298 avg loss: 0.01352 avg lploss: 0.00000
train epoch 299 avg loss: 0.01338 avg lploss: 0.00000
train epoch 300 avg loss: 0.01336 avg lploss: 0.00000
==> val epoch 300 avg loss: 0.01313 avg lploss: 0.00000
==> test epoch 300 avg loss: 0.01251 avg lploss: 0.00000
*** Best Val Loss: 0.01313 	 Best Test Loss: 0.01251 	 Best epoch 300
Validation loss decreased (0.013221 --> 0.013128).  Saving model ...
train epoch 301 avg loss: 0.01333 avg lploss: 0.00000
train epoch 302 avg loss: 0.01334 avg lploss: 0.00000
train epoch 303 avg loss: 0.01336 avg lploss: 0.00000
train epoch 304 avg loss: 0.01327 avg lploss: 0.00000
train epoch 305 avg loss: 0.01327 avg lploss: 0.00000
==> val epoch 305 avg loss: 0.01307 avg lploss: 0.00000
==> test epoch 305 avg loss: 0.01249 avg lploss: 0.00000
*** Best Val Loss: 0.01307 	 Best Test Loss: 0.01249 	 Best epoch 305
Validation loss decreased (0.013128 --> 0.013067).  Saving model ...
train epoch 306 avg loss: 0.01324 avg lploss: 0.00000
train epoch 307 avg loss: 0.01318 avg lploss: 0.00000
train epoch 308 avg loss: 0.01323 avg lploss: 0.00000
train epoch 309 avg loss: 0.01328 avg lploss: 0.00000
train epoch 310 avg loss: 0.01318 avg lploss: 0.00000
==> val epoch 310 avg loss: 0.01286 avg lploss: 0.00000
==> test epoch 310 avg loss: 0.01227 avg lploss: 0.00000
*** Best Val Loss: 0.01286 	 Best Test Loss: 0.01227 	 Best epoch 310
Validation loss decreased (0.013067 --> 0.012863).  Saving model ...
train epoch 311 avg loss: 0.01308 avg lploss: 0.00000
train epoch 312 avg loss: 0.01309 avg lploss: 0.00000
train epoch 313 avg loss: 0.01320 avg lploss: 0.00000
train epoch 314 avg loss: 0.01304 avg lploss: 0.00000
train epoch 315 avg loss: 0.01297 avg lploss: 0.00000
==> val epoch 315 avg loss: 0.01276 avg lploss: 0.00000
==> test epoch 315 avg loss: 0.01216 avg lploss: 0.00000
*** Best Val Loss: 0.01276 	 Best Test Loss: 0.01216 	 Best epoch 315
Validation loss decreased (0.012863 --> 0.012763).  Saving model ...
train epoch 316 avg loss: 0.01299 avg lploss: 0.00000
train epoch 317 avg loss: 0.01298 avg lploss: 0.00000
train epoch 318 avg loss: 0.01292 avg lploss: 0.00000
train epoch 319 avg loss: 0.01292 avg lploss: 0.00000
train epoch 320 avg loss: 0.01299 avg lploss: 0.00000
==> val epoch 320 avg loss: 0.01267 avg lploss: 0.00000
==> test epoch 320 avg loss: 0.01210 avg lploss: 0.00000
*** Best Val Loss: 0.01267 	 Best Test Loss: 0.01210 	 Best epoch 320
Validation loss decreased (0.012763 --> 0.012672).  Saving model ...
train epoch 321 avg loss: 0.01284 avg lploss: 0.00000
train epoch 322 avg loss: 0.01289 avg lploss: 0.00000
train epoch 323 avg loss: 0.01291 avg lploss: 0.00000
train epoch 324 avg loss: 0.01284 avg lploss: 0.00000
train epoch 325 avg loss: 0.01282 avg lploss: 0.00000
==> val epoch 325 avg loss: 0.01255 avg lploss: 0.00000
==> test epoch 325 avg loss: 0.01207 avg lploss: 0.00000
*** Best Val Loss: 0.01255 	 Best Test Loss: 0.01207 	 Best epoch 325
Validation loss decreased (0.012672 --> 0.012552).  Saving model ...
train epoch 326 avg loss: 0.01274 avg lploss: 0.00000
train epoch 327 avg loss: 0.01277 avg lploss: 0.00000
train epoch 328 avg loss: 0.01274 avg lploss: 0.00000
train epoch 329 avg loss: 0.01276 avg lploss: 0.00000
train epoch 330 avg loss: 0.01268 avg lploss: 0.00000
==> val epoch 330 avg loss: 0.01245 avg lploss: 0.00000
==> test epoch 330 avg loss: 0.01200 avg lploss: 0.00000
*** Best Val Loss: 0.01245 	 Best Test Loss: 0.01200 	 Best epoch 330
Validation loss decreased (0.012552 --> 0.012453).  Saving model ...
train epoch 331 avg loss: 0.01267 avg lploss: 0.00000
train epoch 332 avg loss: 0.01265 avg lploss: 0.00000
train epoch 333 avg loss: 0.01270 avg lploss: 0.00000
train epoch 334 avg loss: 0.01267 avg lploss: 0.00000
train epoch 335 avg loss: 0.01261 avg lploss: 0.00000
==> val epoch 335 avg loss: 0.01242 avg lploss: 0.00000
==> test epoch 335 avg loss: 0.01194 avg lploss: 0.00000
*** Best Val Loss: 0.01242 	 Best Test Loss: 0.01194 	 Best epoch 335
Validation loss decreased (0.012453 --> 0.012417).  Saving model ...
train epoch 336 avg loss: 0.01258 avg lploss: 0.00000
train epoch 337 avg loss: 0.01257 avg lploss: 0.00000
train epoch 338 avg loss: 0.01246 avg lploss: 0.00000
train epoch 339 avg loss: 0.01259 avg lploss: 0.00000
train epoch 340 avg loss: 0.01258 avg lploss: 0.00000
==> val epoch 340 avg loss: 0.01264 avg lploss: 0.00000
==> test epoch 340 avg loss: 0.01214 avg lploss: 0.00000
*** Best Val Loss: 0.01242 	 Best Test Loss: 0.01194 	 Best epoch 335
EarlyStopping counter: 1 out of 50
train epoch 341 avg loss: 0.01255 avg lploss: 0.00000
train epoch 342 avg loss: 0.01247 avg lploss: 0.00000
train epoch 343 avg loss: 0.01246 avg lploss: 0.00000
train epoch 344 avg loss: 0.01234 avg lploss: 0.00000
train epoch 345 avg loss: 0.01244 avg lploss: 0.00000
==> val epoch 345 avg loss: 0.01208 avg lploss: 0.00000
==> test epoch 345 avg loss: 0.01178 avg lploss: 0.00000
*** Best Val Loss: 0.01208 	 Best Test Loss: 0.01178 	 Best epoch 345
Validation loss decreased (0.012417 --> 0.012075).  Saving model ...
train epoch 346 avg loss: 0.01234 avg lploss: 0.00000
train epoch 347 avg loss: 0.01234 avg lploss: 0.00000
train epoch 348 avg loss: 0.01234 avg lploss: 0.00000
train epoch 349 avg loss: 0.01232 avg lploss: 0.00000
train epoch 350 avg loss: 0.01229 avg lploss: 0.00000
==> val epoch 350 avg loss: 0.01210 avg lploss: 0.00000
==> test epoch 350 avg loss: 0.01174 avg lploss: 0.00000
*** Best Val Loss: 0.01208 	 Best Test Loss: 0.01178 	 Best epoch 345
EarlyStopping counter: 1 out of 50
train epoch 351 avg loss: 0.01222 avg lploss: 0.00000
train epoch 352 avg loss: 0.01221 avg lploss: 0.00000
train epoch 353 avg loss: 0.01229 avg lploss: 0.00000
train epoch 354 avg loss: 0.01215 avg lploss: 0.00000
train epoch 355 avg loss: 0.01215 avg lploss: 0.00000
==> val epoch 355 avg loss: 0.01189 avg lploss: 0.00000
==> test epoch 355 avg loss: 0.01146 avg lploss: 0.00000
*** Best Val Loss: 0.01189 	 Best Test Loss: 0.01146 	 Best epoch 355
Validation loss decreased (0.012075 --> 0.011894).  Saving model ...
train epoch 356 avg loss: 0.01247 avg lploss: 0.00000
train epoch 357 avg loss: 0.01214 avg lploss: 0.00000
train epoch 358 avg loss: 0.01217 avg lploss: 0.00000
train epoch 359 avg loss: 0.01211 avg lploss: 0.00000
train epoch 360 avg loss: 0.01206 avg lploss: 0.00000
==> val epoch 360 avg loss: 0.01189 avg lploss: 0.00000
==> test epoch 360 avg loss: 0.01157 avg lploss: 0.00000
*** Best Val Loss: 0.01189 	 Best Test Loss: 0.01157 	 Best epoch 360
Validation loss decreased (0.011894 --> 0.011893).  Saving model ...
train epoch 361 avg loss: 0.01200 avg lploss: 0.00000
train epoch 362 avg loss: 0.01195 avg lploss: 0.00000
train epoch 363 avg loss: 0.01190 avg lploss: 0.00000
train epoch 364 avg loss: 0.01192 avg lploss: 0.00000
train epoch 365 avg loss: 0.01194 avg lploss: 0.00000
==> val epoch 365 avg loss: 0.01167 avg lploss: 0.00000
==> test epoch 365 avg loss: 0.01139 avg lploss: 0.00000
*** Best Val Loss: 0.01167 	 Best Test Loss: 0.01139 	 Best epoch 365
Validation loss decreased (0.011893 --> 0.011670).  Saving model ...
train epoch 366 avg loss: 0.01182 avg lploss: 0.00000
train epoch 367 avg loss: 0.01187 avg lploss: 0.00000
train epoch 368 avg loss: 0.01188 avg lploss: 0.00000
train epoch 369 avg loss: 0.01185 avg lploss: 0.00000
train epoch 370 avg loss: 0.01181 avg lploss: 0.00000
==> val epoch 370 avg loss: 0.01155 avg lploss: 0.00000
==> test epoch 370 avg loss: 0.01134 avg lploss: 0.00000
*** Best Val Loss: 0.01155 	 Best Test Loss: 0.01134 	 Best epoch 370
Validation loss decreased (0.011670 --> 0.011551).  Saving model ...
train epoch 371 avg loss: 0.01177 avg lploss: 0.00000
train epoch 372 avg loss: 0.01171 avg lploss: 0.00000
train epoch 373 avg loss: 0.01170 avg lploss: 0.00000
train epoch 374 avg loss: 0.01177 avg lploss: 0.00000
train epoch 375 avg loss: 0.01184 avg lploss: 0.00000
==> val epoch 375 avg loss: 0.01187 avg lploss: 0.00000
==> test epoch 375 avg loss: 0.01180 avg lploss: 0.00000
*** Best Val Loss: 0.01155 	 Best Test Loss: 0.01134 	 Best epoch 370
EarlyStopping counter: 1 out of 50
train epoch 376 avg loss: 0.01195 avg lploss: 0.00000
train epoch 377 avg loss: 0.01169 avg lploss: 0.00000
train epoch 378 avg loss: 0.01167 avg lploss: 0.00000
train epoch 379 avg loss: 0.01159 avg lploss: 0.00000
train epoch 380 avg loss: 0.01158 avg lploss: 0.00000
==> val epoch 380 avg loss: 0.01152 avg lploss: 0.00000
==> test epoch 380 avg loss: 0.01132 avg lploss: 0.00000
*** Best Val Loss: 0.01152 	 Best Test Loss: 0.01132 	 Best epoch 380
Validation loss decreased (0.011551 --> 0.011522).  Saving model ...
train epoch 381 avg loss: 0.01162 avg lploss: 0.00000
train epoch 382 avg loss: 0.01164 avg lploss: 0.00000
train epoch 383 avg loss: 0.01151 avg lploss: 0.00000
train epoch 384 avg loss: 0.01147 avg lploss: 0.00000
train epoch 385 avg loss: 0.01164 avg lploss: 0.00000
==> val epoch 385 avg loss: 0.01131 avg lploss: 0.00000
==> test epoch 385 avg loss: 0.01126 avg lploss: 0.00000
*** Best Val Loss: 0.01131 	 Best Test Loss: 0.01126 	 Best epoch 385
Validation loss decreased (0.011522 --> 0.011312).  Saving model ...
train epoch 386 avg loss: 0.01150 avg lploss: 0.00000
train epoch 387 avg loss: 0.01152 avg lploss: 0.00000
train epoch 388 avg loss: 0.01166 avg lploss: 0.00000
train epoch 389 avg loss: 0.01154 avg lploss: 0.00000
train epoch 390 avg loss: 0.01148 avg lploss: 0.00000
==> val epoch 390 avg loss: 0.01154 avg lploss: 0.00000
==> test epoch 390 avg loss: 0.01117 avg lploss: 0.00000
*** Best Val Loss: 0.01131 	 Best Test Loss: 0.01126 	 Best epoch 385
EarlyStopping counter: 1 out of 50
train epoch 391 avg loss: 0.01138 avg lploss: 0.00000
train epoch 392 avg loss: 0.01136 avg lploss: 0.00000
train epoch 393 avg loss: 0.01132 avg lploss: 0.00000
train epoch 394 avg loss: 0.01134 avg lploss: 0.00000
train epoch 395 avg loss: 0.01128 avg lploss: 0.00000
==> val epoch 395 avg loss: 0.01113 avg lploss: 0.00000
==> test epoch 395 avg loss: 0.01081 avg lploss: 0.00000
*** Best Val Loss: 0.01113 	 Best Test Loss: 0.01081 	 Best epoch 395
Validation loss decreased (0.011312 --> 0.011127).  Saving model ...
train epoch 396 avg loss: 0.01131 avg lploss: 0.00000
train epoch 397 avg loss: 0.01152 avg lploss: 0.00000
train epoch 398 avg loss: 0.01133 avg lploss: 0.00000
train epoch 399 avg loss: 0.01135 avg lploss: 0.00000
train epoch 400 avg loss: 0.01126 avg lploss: 0.00000
==> val epoch 400 avg loss: 0.01108 avg lploss: 0.00000
==> test epoch 400 avg loss: 0.01086 avg lploss: 0.00000
*** Best Val Loss: 0.01108 	 Best Test Loss: 0.01086 	 Best epoch 400
Validation loss decreased (0.011127 --> 0.011075).  Saving model ...
train epoch 401 avg loss: 0.01135 avg lploss: 0.00000
train epoch 402 avg loss: 0.01126 avg lploss: 0.00000
train epoch 403 avg loss: 0.01120 avg lploss: 0.00000
train epoch 404 avg loss: 0.01117 avg lploss: 0.00000
train epoch 405 avg loss: 0.01117 avg lploss: 0.00000
==> val epoch 405 avg loss: 0.01101 avg lploss: 0.00000
==> test epoch 405 avg loss: 0.01079 avg lploss: 0.00000
*** Best Val Loss: 0.01101 	 Best Test Loss: 0.01079 	 Best epoch 405
Validation loss decreased (0.011075 --> 0.011005).  Saving model ...
train epoch 406 avg loss: 0.01117 avg lploss: 0.00000
train epoch 407 avg loss: 0.01107 avg lploss: 0.00000
train epoch 408 avg loss: 0.01127 avg lploss: 0.00000
train epoch 409 avg loss: 0.01107 avg lploss: 0.00000
train epoch 410 avg loss: 0.01105 avg lploss: 0.00000
==> val epoch 410 avg loss: 0.01099 avg lploss: 0.00000
==> test epoch 410 avg loss: 0.01085 avg lploss: 0.00000
*** Best Val Loss: 0.01099 	 Best Test Loss: 0.01085 	 Best epoch 410
Validation loss decreased (0.011005 --> 0.010990).  Saving model ...
train epoch 411 avg loss: 0.01109 avg lploss: 0.00000
train epoch 412 avg loss: 0.01126 avg lploss: 0.00000
train epoch 413 avg loss: 0.01149 avg lploss: 0.00000
train epoch 414 avg loss: 0.01107 avg lploss: 0.00000
train epoch 415 avg loss: 0.01101 avg lploss: 0.00000
==> val epoch 415 avg loss: 0.01091 avg lploss: 0.00000
==> test epoch 415 avg loss: 0.01053 avg lploss: 0.00000
*** Best Val Loss: 0.01091 	 Best Test Loss: 0.01053 	 Best epoch 415
Validation loss decreased (0.010990 --> 0.010908).  Saving model ...
train epoch 416 avg loss: 0.01096 avg lploss: 0.00000
train epoch 417 avg loss: 0.01097 avg lploss: 0.00000
train epoch 418 avg loss: 0.01092 avg lploss: 0.00000
train epoch 419 avg loss: 0.01102 avg lploss: 0.00000
train epoch 420 avg loss: 0.01092 avg lploss: 0.00000
==> val epoch 420 avg loss: 0.01079 avg lploss: 0.00000
==> test epoch 420 avg loss: 0.01051 avg lploss: 0.00000
*** Best Val Loss: 0.01079 	 Best Test Loss: 0.01051 	 Best epoch 420
Validation loss decreased (0.010908 --> 0.010789).  Saving model ...
train epoch 421 avg loss: 0.01094 avg lploss: 0.00000
train epoch 422 avg loss: 0.01088 avg lploss: 0.00000
train epoch 423 avg loss: 0.01085 avg lploss: 0.00000
train epoch 424 avg loss: 0.01085 avg lploss: 0.00000
train epoch 425 avg loss: 0.01080 avg lploss: 0.00000
==> val epoch 425 avg loss: 0.01077 avg lploss: 0.00000
==> test epoch 425 avg loss: 0.01039 avg lploss: 0.00000
*** Best Val Loss: 0.01077 	 Best Test Loss: 0.01039 	 Best epoch 425
Validation loss decreased (0.010789 --> 0.010773).  Saving model ...
train epoch 426 avg loss: 0.01097 avg lploss: 0.00000
train epoch 427 avg loss: 0.01096 avg lploss: 0.00000
train epoch 428 avg loss: 0.01088 avg lploss: 0.00000
train epoch 429 avg loss: 0.01089 avg lploss: 0.00000
train epoch 430 avg loss: 0.01079 avg lploss: 0.00000
==> val epoch 430 avg loss: 0.01072 avg lploss: 0.00000
==> test epoch 430 avg loss: 0.01046 avg lploss: 0.00000
*** Best Val Loss: 0.01072 	 Best Test Loss: 0.01046 	 Best epoch 430
Validation loss decreased (0.010773 --> 0.010722).  Saving model ...
train epoch 431 avg loss: 0.01069 avg lploss: 0.00000
train epoch 432 avg loss: 0.01066 avg lploss: 0.00000
train epoch 433 avg loss: 0.01071 avg lploss: 0.00000
train epoch 434 avg loss: 0.01068 avg lploss: 0.00000
train epoch 435 avg loss: 0.01082 avg lploss: 0.00000
==> val epoch 435 avg loss: 0.01060 avg lploss: 0.00000
==> test epoch 435 avg loss: 0.01028 avg lploss: 0.00000
*** Best Val Loss: 0.01060 	 Best Test Loss: 0.01028 	 Best epoch 435
Validation loss decreased (0.010722 --> 0.010599).  Saving model ...
train epoch 436 avg loss: 0.01073 avg lploss: 0.00000
train epoch 437 avg loss: 0.01067 avg lploss: 0.00000
train epoch 438 avg loss: 0.01078 avg lploss: 0.00000
train epoch 439 avg loss: 0.01073 avg lploss: 0.00000
train epoch 440 avg loss: 0.01065 avg lploss: 0.00000
==> val epoch 440 avg loss: 0.01064 avg lploss: 0.00000
==> test epoch 440 avg loss: 0.01057 avg lploss: 0.00000
*** Best Val Loss: 0.01060 	 Best Test Loss: 0.01028 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 0.01057 avg lploss: 0.00000
train epoch 442 avg loss: 0.01066 avg lploss: 0.00000
train epoch 443 avg loss: 0.01078 avg lploss: 0.00000
train epoch 444 avg loss: 0.01053 avg lploss: 0.00000
train epoch 445 avg loss: 0.01062 avg lploss: 0.00000
==> val epoch 445 avg loss: 0.01061 avg lploss: 0.00000
==> test epoch 445 avg loss: 0.01052 avg lploss: 0.00000
*** Best Val Loss: 0.01060 	 Best Test Loss: 0.01028 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 0.01067 avg lploss: 0.00000
train epoch 447 avg loss: 0.01049 avg lploss: 0.00000
train epoch 448 avg loss: 0.01046 avg lploss: 0.00000
train epoch 449 avg loss: 0.01054 avg lploss: 0.00000
train epoch 450 avg loss: 0.01051 avg lploss: 0.00000
==> val epoch 450 avg loss: 0.01033 avg lploss: 0.00000
==> test epoch 450 avg loss: 0.01008 avg lploss: 0.00000
*** Best Val Loss: 0.01033 	 Best Test Loss: 0.01008 	 Best epoch 450
Validation loss decreased (0.010599 --> 0.010326).  Saving model ...
train epoch 451 avg loss: 0.01053 avg lploss: 0.00000
train epoch 452 avg loss: 0.01083 avg lploss: 0.00000
train epoch 453 avg loss: 0.01064 avg lploss: 0.00000
train epoch 454 avg loss: 0.01037 avg lploss: 0.00000
train epoch 455 avg loss: 0.01036 avg lploss: 0.00000
==> val epoch 455 avg loss: 0.01032 avg lploss: 0.00000
==> test epoch 455 avg loss: 0.00991 avg lploss: 0.00000
*** Best Val Loss: 0.01032 	 Best Test Loss: 0.00991 	 Best epoch 455
Validation loss decreased (0.010326 --> 0.010319).  Saving model ...
train epoch 456 avg loss: 0.01043 avg lploss: 0.00000
train epoch 457 avg loss: 0.01056 avg lploss: 0.00000
train epoch 458 avg loss: 0.01043 avg lploss: 0.00000
train epoch 459 avg loss: 0.01043 avg lploss: 0.00000
train epoch 460 avg loss: 0.01035 avg lploss: 0.00000
==> val epoch 460 avg loss: 0.01030 avg lploss: 0.00000
==> test epoch 460 avg loss: 0.00995 avg lploss: 0.00000
*** Best Val Loss: 0.01030 	 Best Test Loss: 0.00995 	 Best epoch 460
Validation loss decreased (0.010319 --> 0.010297).  Saving model ...
train epoch 461 avg loss: 0.01036 avg lploss: 0.00000
train epoch 462 avg loss: 0.01030 avg lploss: 0.00000
train epoch 463 avg loss: 0.01029 avg lploss: 0.00000
train epoch 464 avg loss: 0.01029 avg lploss: 0.00000
train epoch 465 avg loss: 0.01024 avg lploss: 0.00000
==> val epoch 465 avg loss: 0.01027 avg lploss: 0.00000
==> test epoch 465 avg loss: 0.01016 avg lploss: 0.00000
*** Best Val Loss: 0.01027 	 Best Test Loss: 0.01016 	 Best epoch 465
Validation loss decreased (0.010297 --> 0.010266).  Saving model ...
train epoch 466 avg loss: 0.01023 avg lploss: 0.00000
train epoch 467 avg loss: 0.01045 avg lploss: 0.00000
train epoch 468 avg loss: 0.01036 avg lploss: 0.00000
train epoch 469 avg loss: 0.01040 avg lploss: 0.00000
train epoch 470 avg loss: 0.01017 avg lploss: 0.00000
==> val epoch 470 avg loss: 0.01021 avg lploss: 0.00000
==> test epoch 470 avg loss: 0.00998 avg lploss: 0.00000
*** Best Val Loss: 0.01021 	 Best Test Loss: 0.00998 	 Best epoch 470
Validation loss decreased (0.010266 --> 0.010207).  Saving model ...
train epoch 471 avg loss: 0.01015 avg lploss: 0.00000
train epoch 472 avg loss: 0.01017 avg lploss: 0.00000
train epoch 473 avg loss: 0.01018 avg lploss: 0.00000
train epoch 474 avg loss: 0.01020 avg lploss: 0.00000
train epoch 475 avg loss: 0.01012 avg lploss: 0.00000
==> val epoch 475 avg loss: 0.01021 avg lploss: 0.00000
==> test epoch 475 avg loss: 0.00996 avg lploss: 0.00000
*** Best Val Loss: 0.01021 	 Best Test Loss: 0.00998 	 Best epoch 470
EarlyStopping counter: 1 out of 50
train epoch 476 avg loss: 0.01034 avg lploss: 0.00000
train epoch 477 avg loss: 0.01016 avg lploss: 0.00000
train epoch 478 avg loss: 0.01009 avg lploss: 0.00000
train epoch 479 avg loss: 0.01029 avg lploss: 0.00000
train epoch 480 avg loss: 0.01018 avg lploss: 0.00000
==> val epoch 480 avg loss: 0.01008 avg lploss: 0.00000
==> test epoch 480 avg loss: 0.00972 avg lploss: 0.00000
*** Best Val Loss: 0.01008 	 Best Test Loss: 0.00972 	 Best epoch 480
Validation loss decreased (0.010207 --> 0.010081).  Saving model ...
train epoch 481 avg loss: 0.01003 avg lploss: 0.00000
train epoch 482 avg loss: 0.01003 avg lploss: 0.00000
train epoch 483 avg loss: 0.01019 avg lploss: 0.00000
train epoch 484 avg loss: 0.01049 avg lploss: 0.00000
train epoch 485 avg loss: 0.01044 avg lploss: 0.00000
==> val epoch 485 avg loss: 0.01018 avg lploss: 0.00000
==> test epoch 485 avg loss: 0.00993 avg lploss: 0.00000
*** Best Val Loss: 0.01008 	 Best Test Loss: 0.00972 	 Best epoch 480
EarlyStopping counter: 1 out of 50
train epoch 486 avg loss: 0.01003 avg lploss: 0.00000
train epoch 487 avg loss: 0.01001 avg lploss: 0.00000
train epoch 488 avg loss: 0.01004 avg lploss: 0.00000
train epoch 489 avg loss: 0.00995 avg lploss: 0.00000
train epoch 490 avg loss: 0.00994 avg lploss: 0.00000
==> val epoch 490 avg loss: 0.01000 avg lploss: 0.00000
==> test epoch 490 avg loss: 0.00966 avg lploss: 0.00000
*** Best Val Loss: 0.01000 	 Best Test Loss: 0.00966 	 Best epoch 490
Validation loss decreased (0.010081 --> 0.010002).  Saving model ...
train epoch 491 avg loss: 0.01001 avg lploss: 0.00000
train epoch 492 avg loss: 0.00993 avg lploss: 0.00000
train epoch 493 avg loss: 0.00996 avg lploss: 0.00000
train epoch 494 avg loss: 0.00992 avg lploss: 0.00000
train epoch 495 avg loss: 0.00995 avg lploss: 0.00000
==> val epoch 495 avg loss: 0.00989 avg lploss: 0.00000
==> test epoch 495 avg loss: 0.00970 avg lploss: 0.00000
*** Best Val Loss: 0.00989 	 Best Test Loss: 0.00970 	 Best epoch 495
Validation loss decreased (0.010002 --> 0.009889).  Saving model ...
train epoch 496 avg loss: 0.01025 avg lploss: 0.00000
train epoch 497 avg loss: 0.01018 avg lploss: 0.00000
train epoch 498 avg loss: 0.00985 avg lploss: 0.00000
train epoch 499 avg loss: 0.01006 avg lploss: 0.00000
train epoch 500 avg loss: 0.01059 avg lploss: 0.00000
==> val epoch 500 avg loss: 0.01006 avg lploss: 0.00000
==> test epoch 500 avg loss: 0.01002 avg lploss: 0.00000
*** Best Val Loss: 0.00989 	 Best Test Loss: 0.00970 	 Best epoch 495
EarlyStopping counter: 1 out of 50
train epoch 501 avg loss: 0.01035 avg lploss: 0.00000
train epoch 502 avg loss: 0.01066 avg lploss: 0.00000
train epoch 503 avg loss: 0.01024 avg lploss: 0.00000
train epoch 504 avg loss: 0.01031 avg lploss: 0.00000
train epoch 505 avg loss: 0.01005 avg lploss: 0.00000
==> val epoch 505 avg loss: 0.01006 avg lploss: 0.00000
==> test epoch 505 avg loss: 0.00959 avg lploss: 0.00000
*** Best Val Loss: 0.00989 	 Best Test Loss: 0.00970 	 Best epoch 495
EarlyStopping counter: 2 out of 50
train epoch 506 avg loss: 0.01010 avg lploss: 0.00000
train epoch 507 avg loss: 0.00977 avg lploss: 0.00000
train epoch 508 avg loss: 0.00978 avg lploss: 0.00000
train epoch 509 avg loss: 0.00982 avg lploss: 0.00000
train epoch 510 avg loss: 0.00976 avg lploss: 0.00000
==> val epoch 510 avg loss: 0.00970 avg lploss: 0.00000
==> test epoch 510 avg loss: 0.00930 avg lploss: 0.00000
*** Best Val Loss: 0.00970 	 Best Test Loss: 0.00930 	 Best epoch 510
Validation loss decreased (0.009889 --> 0.009703).  Saving model ...
train epoch 511 avg loss: 0.00971 avg lploss: 0.00000
train epoch 512 avg loss: 0.00976 avg lploss: 0.00000
train epoch 513 avg loss: 0.00996 avg lploss: 0.00000
train epoch 514 avg loss: 0.00982 avg lploss: 0.00000
train epoch 515 avg loss: 0.00962 avg lploss: 0.00000
==> val epoch 515 avg loss: 0.00977 avg lploss: 0.00000
==> test epoch 515 avg loss: 0.00933 avg lploss: 0.00000
*** Best Val Loss: 0.00970 	 Best Test Loss: 0.00930 	 Best epoch 510
EarlyStopping counter: 1 out of 50
train epoch 516 avg loss: 0.00969 avg lploss: 0.00000
train epoch 517 avg loss: 0.00966 avg lploss: 0.00000
train epoch 518 avg loss: 0.00964 avg lploss: 0.00000
train epoch 519 avg loss: 0.00961 avg lploss: 0.00000
train epoch 520 avg loss: 0.00976 avg lploss: 0.00000
==> val epoch 520 avg loss: 0.00969 avg lploss: 0.00000
==> test epoch 520 avg loss: 0.00924 avg lploss: 0.00000
*** Best Val Loss: 0.00969 	 Best Test Loss: 0.00924 	 Best epoch 520
Validation loss decreased (0.009703 --> 0.009688).  Saving model ...
train epoch 521 avg loss: 0.00961 avg lploss: 0.00000
train epoch 522 avg loss: 0.00961 avg lploss: 0.00000
train epoch 523 avg loss: 0.00957 avg lploss: 0.00000
train epoch 524 avg loss: 0.00969 avg lploss: 0.00000
train epoch 525 avg loss: 0.00963 avg lploss: 0.00000
==> val epoch 525 avg loss: 0.00960 avg lploss: 0.00000
==> test epoch 525 avg loss: 0.00911 avg lploss: 0.00000
*** Best Val Loss: 0.00960 	 Best Test Loss: 0.00911 	 Best epoch 525
Validation loss decreased (0.009688 --> 0.009603).  Saving model ...
train epoch 526 avg loss: 0.00952 avg lploss: 0.00000
train epoch 527 avg loss: 0.00983 avg lploss: 0.00000
train epoch 528 avg loss: 0.00969 avg lploss: 0.00000
train epoch 529 avg loss: 0.00950 avg lploss: 0.00000
train epoch 530 avg loss: 0.00964 avg lploss: 0.00000
==> val epoch 530 avg loss: 0.00958 avg lploss: 0.00000
==> test epoch 530 avg loss: 0.00916 avg lploss: 0.00000
*** Best Val Loss: 0.00958 	 Best Test Loss: 0.00916 	 Best epoch 530
Validation loss decreased (0.009603 --> 0.009577).  Saving model ...
train epoch 531 avg loss: 0.00968 avg lploss: 0.00000
train epoch 532 avg loss: 0.00947 avg lploss: 0.00000
train epoch 533 avg loss: 0.00964 avg lploss: 0.00000
train epoch 534 avg loss: 0.00986 avg lploss: 0.00000
train epoch 535 avg loss: 0.01149 avg lploss: 0.00000
==> val epoch 535 avg loss: 0.01088 avg lploss: 0.00000
==> test epoch 535 avg loss: 0.01047 avg lploss: 0.00000
*** Best Val Loss: 0.00958 	 Best Test Loss: 0.00916 	 Best epoch 530
EarlyStopping counter: 1 out of 50
train epoch 536 avg loss: 0.01029 avg lploss: 0.00000
train epoch 537 avg loss: 0.00976 avg lploss: 0.00000
train epoch 538 avg loss: 0.00956 avg lploss: 0.00000
train epoch 539 avg loss: 0.00947 avg lploss: 0.00000
train epoch 540 avg loss: 0.00948 avg lploss: 0.00000
==> val epoch 540 avg loss: 0.00972 avg lploss: 0.00000
==> test epoch 540 avg loss: 0.00928 avg lploss: 0.00000
*** Best Val Loss: 0.00958 	 Best Test Loss: 0.00916 	 Best epoch 530
EarlyStopping counter: 2 out of 50
train epoch 541 avg loss: 0.00994 avg lploss: 0.00000
train epoch 542 avg loss: 0.01102 avg lploss: 0.00000
train epoch 543 avg loss: 0.00993 avg lploss: 0.00000
train epoch 544 avg loss: 0.00950 avg lploss: 0.00000
train epoch 545 avg loss: 0.00946 avg lploss: 0.00000
==> val epoch 545 avg loss: 0.00944 avg lploss: 0.00000
==> test epoch 545 avg loss: 0.00906 avg lploss: 0.00000
*** Best Val Loss: 0.00944 	 Best Test Loss: 0.00906 	 Best epoch 545
Validation loss decreased (0.009577 --> 0.009441).  Saving model ...
train epoch 546 avg loss: 0.00943 avg lploss: 0.00000
train epoch 547 avg loss: 0.00935 avg lploss: 0.00000
train epoch 548 avg loss: 0.00938 avg lploss: 0.00000
train epoch 549 avg loss: 0.00943 avg lploss: 0.00000
train epoch 550 avg loss: 0.00938 avg lploss: 0.00000
==> val epoch 550 avg loss: 0.00964 avg lploss: 0.00000
==> test epoch 550 avg loss: 0.00927 avg lploss: 0.00000
*** Best Val Loss: 0.00944 	 Best Test Loss: 0.00906 	 Best epoch 545
EarlyStopping counter: 1 out of 50
train epoch 551 avg loss: 0.00940 avg lploss: 0.00000
train epoch 552 avg loss: 0.00936 avg lploss: 0.00000
train epoch 553 avg loss: 0.00941 avg lploss: 0.00000
train epoch 554 avg loss: 0.00933 avg lploss: 0.00000
train epoch 555 avg loss: 0.00936 avg lploss: 0.00000
==> val epoch 555 avg loss: 0.00982 avg lploss: 0.00000
==> test epoch 555 avg loss: 0.00925 avg lploss: 0.00000
*** Best Val Loss: 0.00944 	 Best Test Loss: 0.00906 	 Best epoch 545
EarlyStopping counter: 2 out of 50
train epoch 556 avg loss: 0.00957 avg lploss: 0.00000
train epoch 557 avg loss: 0.00935 avg lploss: 0.00000
train epoch 558 avg loss: 0.00919 avg lploss: 0.00000
train epoch 559 avg loss: 0.00923 avg lploss: 0.00000
train epoch 560 avg loss: 0.00925 avg lploss: 0.00000
==> val epoch 560 avg loss: 0.00943 avg lploss: 0.00000
==> test epoch 560 avg loss: 0.00905 avg lploss: 0.00000
*** Best Val Loss: 0.00943 	 Best Test Loss: 0.00905 	 Best epoch 560
Validation loss decreased (0.009441 --> 0.009425).  Saving model ...
train epoch 561 avg loss: 0.00924 avg lploss: 0.00000
train epoch 562 avg loss: 0.00950 avg lploss: 0.00000
train epoch 563 avg loss: 0.00933 avg lploss: 0.00000
train epoch 564 avg loss: 0.00922 avg lploss: 0.00000
train epoch 565 avg loss: 0.00921 avg lploss: 0.00000
==> val epoch 565 avg loss: 0.00923 avg lploss: 0.00000
==> test epoch 565 avg loss: 0.00886 avg lploss: 0.00000
*** Best Val Loss: 0.00923 	 Best Test Loss: 0.00886 	 Best epoch 565
Validation loss decreased (0.009425 --> 0.009232).  Saving model ...
train epoch 566 avg loss: 0.00920 avg lploss: 0.00000
train epoch 567 avg loss: 0.00930 avg lploss: 0.00000
train epoch 568 avg loss: 0.00925 avg lploss: 0.00000
train epoch 569 avg loss: 0.00941 avg lploss: 0.00000
train epoch 570 avg loss: 0.00927 avg lploss: 0.00000
==> val epoch 570 avg loss: 0.00933 avg lploss: 0.00000
==> test epoch 570 avg loss: 0.00895 avg lploss: 0.00000
*** Best Val Loss: 0.00923 	 Best Test Loss: 0.00886 	 Best epoch 565
EarlyStopping counter: 1 out of 50
train epoch 571 avg loss: 0.00909 avg lploss: 0.00000
train epoch 572 avg loss: 0.00916 avg lploss: 0.00000
train epoch 573 avg loss: 0.00920 avg lploss: 0.00000
train epoch 574 avg loss: 0.00915 avg lploss: 0.00000
train epoch 575 avg loss: 0.00911 avg lploss: 0.00000
==> val epoch 575 avg loss: 0.00917 avg lploss: 0.00000
==> test epoch 575 avg loss: 0.00888 avg lploss: 0.00000
*** Best Val Loss: 0.00917 	 Best Test Loss: 0.00888 	 Best epoch 575
Validation loss decreased (0.009232 --> 0.009173).  Saving model ...
train epoch 576 avg loss: 0.00932 avg lploss: 0.00000
train epoch 577 avg loss: 0.00921 avg lploss: 0.00000
train epoch 578 avg loss: 0.00916 avg lploss: 0.00000
train epoch 579 avg loss: 0.00919 avg lploss: 0.00000
train epoch 580 avg loss: 0.00910 avg lploss: 0.00000
==> val epoch 580 avg loss: 0.00920 avg lploss: 0.00000
==> test epoch 580 avg loss: 0.00877 avg lploss: 0.00000
*** Best Val Loss: 0.00917 	 Best Test Loss: 0.00888 	 Best epoch 575
EarlyStopping counter: 1 out of 50
train epoch 581 avg loss: 0.00915 avg lploss: 0.00000
train epoch 582 avg loss: 0.00937 avg lploss: 0.00000
train epoch 583 avg loss: 0.00948 avg lploss: 0.00000
train epoch 584 avg loss: 0.00939 avg lploss: 0.00000
train epoch 585 avg loss: 0.00957 avg lploss: 0.00000
==> val epoch 585 avg loss: 0.00922 avg lploss: 0.00000
==> test epoch 585 avg loss: 0.00901 avg lploss: 0.00000
*** Best Val Loss: 0.00917 	 Best Test Loss: 0.00888 	 Best epoch 575
EarlyStopping counter: 2 out of 50
train epoch 586 avg loss: 0.00920 avg lploss: 0.00000
train epoch 587 avg loss: 0.00944 avg lploss: 0.00000
train epoch 588 avg loss: 0.01019 avg lploss: 0.00000
train epoch 589 avg loss: 0.01095 avg lploss: 0.00000
train epoch 590 avg loss: 0.01196 avg lploss: 0.00000
==> val epoch 590 avg loss: 0.01567 avg lploss: 0.00000
==> test epoch 590 avg loss: 0.14554 avg lploss: 0.00000
*** Best Val Loss: 0.00917 	 Best Test Loss: 0.00888 	 Best epoch 575
EarlyStopping counter: 3 out of 50
train epoch 591 avg loss: 0.02040 avg lploss: 0.00000
train epoch 592 avg loss: 0.01601 avg lploss: 0.00000
train epoch 593 avg loss: 0.01275 avg lploss: 0.00000
train epoch 594 avg loss: 0.01013 avg lploss: 0.00000
train epoch 595 avg loss: 0.01003 avg lploss: 0.00000
==> val epoch 595 avg loss: 0.00959 avg lploss: 0.00000
==> test epoch 595 avg loss: 0.00967 avg lploss: 0.00000
*** Best Val Loss: 0.00917 	 Best Test Loss: 0.00888 	 Best epoch 575
EarlyStopping counter: 4 out of 50
train epoch 596 avg loss: 0.00956 avg lploss: 0.00000
train epoch 597 avg loss: 0.00947 avg lploss: 0.00000
train epoch 598 avg loss: 0.00939 avg lploss: 0.00000
train epoch 599 avg loss: 0.00924 avg lploss: 0.00000
train epoch 600 avg loss: 0.00920 avg lploss: 0.00000
==> val epoch 600 avg loss: 0.00923 avg lploss: 0.00000
==> test epoch 600 avg loss: 0.00893 avg lploss: 0.00000
*** Best Val Loss: 0.00917 	 Best Test Loss: 0.00888 	 Best epoch 575
EarlyStopping counter: 5 out of 50
train epoch 601 avg loss: 0.00915 avg lploss: 0.00000
train epoch 602 avg loss: 0.00913 avg lploss: 0.00000
train epoch 603 avg loss: 0.00913 avg lploss: 0.00000
train epoch 604 avg loss: 0.00915 avg lploss: 0.00000
train epoch 605 avg loss: 0.00919 avg lploss: 0.00000
==> val epoch 605 avg loss: 0.00910 avg lploss: 0.00000
==> test epoch 605 avg loss: 0.00886 avg lploss: 0.00000
*** Best Val Loss: 0.00910 	 Best Test Loss: 0.00886 	 Best epoch 605
Validation loss decreased (0.009173 --> 0.009098).  Saving model ...
train epoch 606 avg loss: 0.00922 avg lploss: 0.00000
train epoch 607 avg loss: 0.00910 avg lploss: 0.00000
train epoch 608 avg loss: 0.00907 avg lploss: 0.00000
train epoch 609 avg loss: 0.00901 avg lploss: 0.00000
train epoch 610 avg loss: 0.00898 avg lploss: 0.00000
==> val epoch 610 avg loss: 0.00895 avg lploss: 0.00000
==> test epoch 610 avg loss: 0.00871 avg lploss: 0.00000
*** Best Val Loss: 0.00895 	 Best Test Loss: 0.00871 	 Best epoch 610
Validation loss decreased (0.009098 --> 0.008954).  Saving model ...
train epoch 611 avg loss: 0.00895 avg lploss: 0.00000
train epoch 612 avg loss: 0.00896 avg lploss: 0.00000
train epoch 613 avg loss: 0.00900 avg lploss: 0.00000
train epoch 614 avg loss: 0.00907 avg lploss: 0.00000
train epoch 615 avg loss: 0.00903 avg lploss: 0.00000
==> val epoch 615 avg loss: 0.00890 avg lploss: 0.00000
==> test epoch 615 avg loss: 0.00862 avg lploss: 0.00000
*** Best Val Loss: 0.00890 	 Best Test Loss: 0.00862 	 Best epoch 615
Validation loss decreased (0.008954 --> 0.008904).  Saving model ...
train epoch 616 avg loss: 0.00892 avg lploss: 0.00000
train epoch 617 avg loss: 0.00895 avg lploss: 0.00000
train epoch 618 avg loss: 0.00895 avg lploss: 0.00000
train epoch 619 avg loss: 0.00894 avg lploss: 0.00000
train epoch 620 avg loss: 0.00889 avg lploss: 0.00000
==> val epoch 620 avg loss: 0.00895 avg lploss: 0.00000
==> test epoch 620 avg loss: 0.00863 avg lploss: 0.00000
*** Best Val Loss: 0.00890 	 Best Test Loss: 0.00862 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.00893 avg lploss: 0.00000
train epoch 622 avg loss: 0.00892 avg lploss: 0.00000
train epoch 623 avg loss: 0.00906 avg lploss: 0.00000
train epoch 624 avg loss: 0.00913 avg lploss: 0.00000
train epoch 625 avg loss: 0.00907 avg lploss: 0.00000
==> val epoch 625 avg loss: 0.00892 avg lploss: 0.00000
==> test epoch 625 avg loss: 0.00862 avg lploss: 0.00000
*** Best Val Loss: 0.00890 	 Best Test Loss: 0.00862 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.00879 avg lploss: 0.00000
train epoch 627 avg loss: 0.00877 avg lploss: 0.00000
train epoch 628 avg loss: 0.00911 avg lploss: 0.00000
train epoch 629 avg loss: 0.00896 avg lploss: 0.00000
train epoch 630 avg loss: 0.00900 avg lploss: 0.00000
==> val epoch 630 avg loss: 0.00879 avg lploss: 0.00000
==> test epoch 630 avg loss: 0.00851 avg lploss: 0.00000
*** Best Val Loss: 0.00879 	 Best Test Loss: 0.00851 	 Best epoch 630
Validation loss decreased (0.008904 --> 0.008791).  Saving model ...
train epoch 631 avg loss: 0.00891 avg lploss: 0.00000
train epoch 632 avg loss: 0.00882 avg lploss: 0.00000
train epoch 633 avg loss: 0.00880 avg lploss: 0.00000
train epoch 634 avg loss: 0.00888 avg lploss: 0.00000
train epoch 635 avg loss: 0.00880 avg lploss: 0.00000
==> val epoch 635 avg loss: 0.00880 avg lploss: 0.00000
==> test epoch 635 avg loss: 0.00855 avg lploss: 0.00000
*** Best Val Loss: 0.00879 	 Best Test Loss: 0.00851 	 Best epoch 630
EarlyStopping counter: 1 out of 50
train epoch 636 avg loss: 0.00880 avg lploss: 0.00000
train epoch 637 avg loss: 0.00871 avg lploss: 0.00000
train epoch 638 avg loss: 0.00874 avg lploss: 0.00000
train epoch 639 avg loss: 0.00881 avg lploss: 0.00000
train epoch 640 avg loss: 0.00869 avg lploss: 0.00000
==> val epoch 640 avg loss: 0.00884 avg lploss: 0.00000
==> test epoch 640 avg loss: 0.00857 avg lploss: 0.00000
*** Best Val Loss: 0.00879 	 Best Test Loss: 0.00851 	 Best epoch 630
EarlyStopping counter: 2 out of 50
train epoch 641 avg loss: 0.00866 avg lploss: 0.00000
train epoch 642 avg loss: 0.00869 avg lploss: 0.00000
train epoch 643 avg loss: 0.00869 avg lploss: 0.00000
train epoch 644 avg loss: 0.00871 avg lploss: 0.00000
train epoch 645 avg loss: 0.00867 avg lploss: 0.00000
==> val epoch 645 avg loss: 0.00909 avg lploss: 0.00000
==> test epoch 645 avg loss: 0.00871 avg lploss: 0.00000
*** Best Val Loss: 0.00879 	 Best Test Loss: 0.00851 	 Best epoch 630
EarlyStopping counter: 3 out of 50
train epoch 646 avg loss: 0.00884 avg lploss: 0.00000
train epoch 647 avg loss: 0.00885 avg lploss: 0.00000
train epoch 648 avg loss: 0.00862 avg lploss: 0.00000
train epoch 649 avg loss: 0.00887 avg lploss: 0.00000
train epoch 650 avg loss: 0.00881 avg lploss: 0.00000
==> val epoch 650 avg loss: 0.00893 avg lploss: 0.00000
==> test epoch 650 avg loss: 0.00887 avg lploss: 0.00000
*** Best Val Loss: 0.00879 	 Best Test Loss: 0.00851 	 Best epoch 630
EarlyStopping counter: 4 out of 50
train epoch 651 avg loss: 0.00874 avg lploss: 0.00000
train epoch 652 avg loss: 0.00863 avg lploss: 0.00000
train epoch 653 avg loss: 0.00871 avg lploss: 0.00000
train epoch 654 avg loss: 0.00864 avg lploss: 0.00000
train epoch 655 avg loss: 0.00867 avg lploss: 0.00000
==> val epoch 655 avg loss: 0.00872 avg lploss: 0.00000
==> test epoch 655 avg loss: 0.00844 avg lploss: 0.00000
*** Best Val Loss: 0.00872 	 Best Test Loss: 0.00844 	 Best epoch 655
Validation loss decreased (0.008791 --> 0.008722).  Saving model ...
train epoch 656 avg loss: 0.00868 avg lploss: 0.00000
train epoch 657 avg loss: 0.00868 avg lploss: 0.00000
train epoch 658 avg loss: 0.00862 avg lploss: 0.00000
train epoch 659 avg loss: 0.00870 avg lploss: 0.00000
train epoch 660 avg loss: 0.00861 avg lploss: 0.00000
==> val epoch 660 avg loss: 0.00880 avg lploss: 0.00000
==> test epoch 660 avg loss: 0.00850 avg lploss: 0.00000
*** Best Val Loss: 0.00872 	 Best Test Loss: 0.00844 	 Best epoch 655
EarlyStopping counter: 1 out of 50
train epoch 661 avg loss: 0.00857 avg lploss: 0.00000
train epoch 662 avg loss: 0.00855 avg lploss: 0.00000
train epoch 663 avg loss: 0.00851 avg lploss: 0.00000
train epoch 664 avg loss: 0.00861 avg lploss: 0.00000
train epoch 665 avg loss: 0.00858 avg lploss: 0.00000
==> val epoch 665 avg loss: 0.00861 avg lploss: 0.00000
==> test epoch 665 avg loss: 0.00835 avg lploss: 0.00000
*** Best Val Loss: 0.00861 	 Best Test Loss: 0.00835 	 Best epoch 665
Validation loss decreased (0.008722 --> 0.008611).  Saving model ...
train epoch 666 avg loss: 0.00855 avg lploss: 0.00000
train epoch 667 avg loss: 0.00848 avg lploss: 0.00000
train epoch 668 avg loss: 0.00853 avg lploss: 0.00000
train epoch 669 avg loss: 0.00844 avg lploss: 0.00000
train epoch 670 avg loss: 0.00859 avg lploss: 0.00000
==> val epoch 670 avg loss: 0.00894 avg lploss: 0.00000
==> test epoch 670 avg loss: 0.00874 avg lploss: 0.00000
*** Best Val Loss: 0.00861 	 Best Test Loss: 0.00835 	 Best epoch 665
EarlyStopping counter: 1 out of 50
train epoch 671 avg loss: 0.00867 avg lploss: 0.00000
train epoch 672 avg loss: 0.00865 avg lploss: 0.00000
train epoch 673 avg loss: 0.00842 avg lploss: 0.00000
train epoch 674 avg loss: 0.00851 avg lploss: 0.00000
train epoch 675 avg loss: 0.00846 avg lploss: 0.00000
==> val epoch 675 avg loss: 0.00857 avg lploss: 0.00000
==> test epoch 675 avg loss: 0.00842 avg lploss: 0.00000
*** Best Val Loss: 0.00857 	 Best Test Loss: 0.00842 	 Best epoch 675
Validation loss decreased (0.008611 --> 0.008571).  Saving model ...
train epoch 676 avg loss: 0.00848 avg lploss: 0.00000
train epoch 677 avg loss: 0.00842 avg lploss: 0.00000
train epoch 678 avg loss: 0.00912 avg lploss: 0.00000
train epoch 679 avg loss: 0.01145 avg lploss: 0.00000
train epoch 680 avg loss: 0.00896 avg lploss: 0.00000
==> val epoch 680 avg loss: 0.00859 avg lploss: 0.00000
==> test epoch 680 avg loss: 0.00840 avg lploss: 0.00000
*** Best Val Loss: 0.00857 	 Best Test Loss: 0.00842 	 Best epoch 675
EarlyStopping counter: 1 out of 50
train epoch 681 avg loss: 0.00859 avg lploss: 0.00000
train epoch 682 avg loss: 0.00853 avg lploss: 0.00000
train epoch 683 avg loss: 0.00841 avg lploss: 0.00000
train epoch 684 avg loss: 0.00842 avg lploss: 0.00000
train epoch 685 avg loss: 0.00848 avg lploss: 0.00000
==> val epoch 685 avg loss: 0.00852 avg lploss: 0.00000
==> test epoch 685 avg loss: 0.00834 avg lploss: 0.00000
*** Best Val Loss: 0.00852 	 Best Test Loss: 0.00834 	 Best epoch 685
Validation loss decreased (0.008571 --> 0.008519).  Saving model ...
train epoch 686 avg loss: 0.00841 avg lploss: 0.00000
train epoch 687 avg loss: 0.00840 avg lploss: 0.00000
train epoch 688 avg loss: 0.00842 avg lploss: 0.00000
train epoch 689 avg loss: 0.00856 avg lploss: 0.00000
train epoch 690 avg loss: 0.00848 avg lploss: 0.00000
==> val epoch 690 avg loss: 0.00863 avg lploss: 0.00000
==> test epoch 690 avg loss: 0.00852 avg lploss: 0.00000
*** Best Val Loss: 0.00852 	 Best Test Loss: 0.00834 	 Best epoch 685
EarlyStopping counter: 1 out of 50
train epoch 691 avg loss: 0.00835 avg lploss: 0.00000
train epoch 692 avg loss: 0.00833 avg lploss: 0.00000
train epoch 693 avg loss: 0.00866 avg lploss: 0.00000
train epoch 694 avg loss: 0.00853 avg lploss: 0.00000
train epoch 695 avg loss: 0.00845 avg lploss: 0.00000
==> val epoch 695 avg loss: 0.00854 avg lploss: 0.00000
==> test epoch 695 avg loss: 0.00827 avg lploss: 0.00000
*** Best Val Loss: 0.00852 	 Best Test Loss: 0.00834 	 Best epoch 685
EarlyStopping counter: 2 out of 50
train epoch 696 avg loss: 0.00841 avg lploss: 0.00000
train epoch 697 avg loss: 0.00844 avg lploss: 0.00000
train epoch 698 avg loss: 0.00841 avg lploss: 0.00000
train epoch 699 avg loss: 0.00826 avg lploss: 0.00000
train epoch 700 avg loss: 0.00828 avg lploss: 0.00000
==> val epoch 700 avg loss: 0.00844 avg lploss: 0.00000
==> test epoch 700 avg loss: 0.00826 avg lploss: 0.00000
*** Best Val Loss: 0.00844 	 Best Test Loss: 0.00826 	 Best epoch 700
Validation loss decreased (0.008519 --> 0.008444).  Saving model ...
train epoch 701 avg loss: 0.00832 avg lploss: 0.00000
train epoch 702 avg loss: 0.00830 avg lploss: 0.00000
train epoch 703 avg loss: 0.00831 avg lploss: 0.00000
train epoch 704 avg loss: 0.00841 avg lploss: 0.00000
train epoch 705 avg loss: 0.00833 avg lploss: 0.00000
==> val epoch 705 avg loss: 0.00837 avg lploss: 0.00000
==> test epoch 705 avg loss: 0.00816 avg lploss: 0.00000
*** Best Val Loss: 0.00837 	 Best Test Loss: 0.00816 	 Best epoch 705
Validation loss decreased (0.008444 --> 0.008369).  Saving model ...
train epoch 706 avg loss: 0.00821 avg lploss: 0.00000
train epoch 707 avg loss: 0.00818 avg lploss: 0.00000
train epoch 708 avg loss: 0.00823 avg lploss: 0.00000
train epoch 709 avg loss: 0.00822 avg lploss: 0.00000
train epoch 710 avg loss: 0.00828 avg lploss: 0.00000
==> val epoch 710 avg loss: 0.00862 avg lploss: 0.00000
==> test epoch 710 avg loss: 0.00827 avg lploss: 0.00000
*** Best Val Loss: 0.00837 	 Best Test Loss: 0.00816 	 Best epoch 705
EarlyStopping counter: 1 out of 50
train epoch 711 avg loss: 0.00822 avg lploss: 0.00000
train epoch 712 avg loss: 0.00821 avg lploss: 0.00000
train epoch 713 avg loss: 0.00836 avg lploss: 0.00000
train epoch 714 avg loss: 0.00835 avg lploss: 0.00000
train epoch 715 avg loss: 0.00819 avg lploss: 0.00000
==> val epoch 715 avg loss: 0.00861 avg lploss: 0.00000
==> test epoch 715 avg loss: 0.00836 avg lploss: 0.00000
*** Best Val Loss: 0.00837 	 Best Test Loss: 0.00816 	 Best epoch 705
EarlyStopping counter: 2 out of 50
train epoch 716 avg loss: 0.00829 avg lploss: 0.00000
train epoch 717 avg loss: 0.00815 avg lploss: 0.00000
train epoch 718 avg loss: 0.00818 avg lploss: 0.00000
train epoch 719 avg loss: 0.00811 avg lploss: 0.00000
train epoch 720 avg loss: 0.00816 avg lploss: 0.00000
==> val epoch 720 avg loss: 0.00851 avg lploss: 0.00000
==> test epoch 720 avg loss: 0.00830 avg lploss: 0.00000
*** Best Val Loss: 0.00837 	 Best Test Loss: 0.00816 	 Best epoch 705
EarlyStopping counter: 3 out of 50
train epoch 721 avg loss: 0.00823 avg lploss: 0.00000
train epoch 722 avg loss: 0.00815 avg lploss: 0.00000
train epoch 723 avg loss: 0.00846 avg lploss: 0.00000
train epoch 724 avg loss: 0.00861 avg lploss: 0.00000
train epoch 725 avg loss: 0.00829 avg lploss: 0.00000
==> val epoch 725 avg loss: 0.00852 avg lploss: 0.00000
==> test epoch 725 avg loss: 0.00833 avg lploss: 0.00000
*** Best Val Loss: 0.00837 	 Best Test Loss: 0.00816 	 Best epoch 705
EarlyStopping counter: 4 out of 50
train epoch 726 avg loss: 0.00820 avg lploss: 0.00000
train epoch 727 avg loss: 0.00805 avg lploss: 0.00000
train epoch 728 avg loss: 0.00813 avg lploss: 0.00000
train epoch 729 avg loss: 0.00800 avg lploss: 0.00000
train epoch 730 avg loss: 0.00815 avg lploss: 0.00000
==> val epoch 730 avg loss: 0.00828 avg lploss: 0.00000
==> test epoch 730 avg loss: 0.00815 avg lploss: 0.00000
*** Best Val Loss: 0.00828 	 Best Test Loss: 0.00815 	 Best epoch 730
Validation loss decreased (0.008369 --> 0.008281).  Saving model ...
train epoch 731 avg loss: 0.00811 avg lploss: 0.00000
train epoch 732 avg loss: 0.00815 avg lploss: 0.00000
train epoch 733 avg loss: 0.00818 avg lploss: 0.00000
train epoch 734 avg loss: 0.00829 avg lploss: 0.00000
train epoch 735 avg loss: 0.00844 avg lploss: 0.00000
==> val epoch 735 avg loss: 0.00893 avg lploss: 0.00000
==> test epoch 735 avg loss: 0.00879 avg lploss: 0.00000
*** Best Val Loss: 0.00828 	 Best Test Loss: 0.00815 	 Best epoch 730
EarlyStopping counter: 1 out of 50
train epoch 736 avg loss: 0.00861 avg lploss: 0.00000
train epoch 737 avg loss: 0.00849 avg lploss: 0.00000
train epoch 738 avg loss: 0.00868 avg lploss: 0.00000
train epoch 739 avg loss: 0.00856 avg lploss: 0.00000
train epoch 740 avg loss: 0.00837 avg lploss: 0.00000
==> val epoch 740 avg loss: 0.00871 avg lploss: 0.00000
==> test epoch 740 avg loss: 0.00841 avg lploss: 0.00000
*** Best Val Loss: 0.00828 	 Best Test Loss: 0.00815 	 Best epoch 730
EarlyStopping counter: 2 out of 50
train epoch 741 avg loss: 0.00817 avg lploss: 0.00000
train epoch 742 avg loss: 0.00805 avg lploss: 0.00000
train epoch 743 avg loss: 0.00805 avg lploss: 0.00000
train epoch 744 avg loss: 0.00803 avg lploss: 0.00000
train epoch 745 avg loss: 0.00793 avg lploss: 0.00000
==> val epoch 745 avg loss: 0.00824 avg lploss: 0.00000
==> test epoch 745 avg loss: 0.00804 avg lploss: 0.00000
*** Best Val Loss: 0.00824 	 Best Test Loss: 0.00804 	 Best epoch 745
Validation loss decreased (0.008281 --> 0.008242).  Saving model ...
train epoch 746 avg loss: 0.00802 avg lploss: 0.00000
train epoch 747 avg loss: 0.00800 avg lploss: 0.00000
train epoch 748 avg loss: 0.00799 avg lploss: 0.00000
train epoch 749 avg loss: 0.00792 avg lploss: 0.00000
train epoch 750 avg loss: 0.00798 avg lploss: 0.00000
==> val epoch 750 avg loss: 0.00815 avg lploss: 0.00000
==> test epoch 750 avg loss: 0.00790 avg lploss: 0.00000
*** Best Val Loss: 0.00815 	 Best Test Loss: 0.00790 	 Best epoch 750
Validation loss decreased (0.008242 --> 0.008154).  Saving model ...
train epoch 751 avg loss: 0.00800 avg lploss: 0.00000
train epoch 752 avg loss: 0.00798 avg lploss: 0.00000
train epoch 753 avg loss: 0.00797 avg lploss: 0.00000
train epoch 754 avg loss: 0.00794 avg lploss: 0.00000
train epoch 755 avg loss: 0.00792 avg lploss: 0.00000
==> val epoch 755 avg loss: 0.00818 avg lploss: 0.00000
==> test epoch 755 avg loss: 0.00800 avg lploss: 0.00000
*** Best Val Loss: 0.00815 	 Best Test Loss: 0.00790 	 Best epoch 750
EarlyStopping counter: 1 out of 50
train epoch 756 avg loss: 0.00795 avg lploss: 0.00000
train epoch 757 avg loss: 0.00792 avg lploss: 0.00000
train epoch 758 avg loss: 0.00786 avg lploss: 0.00000
train epoch 759 avg loss: 0.00790 avg lploss: 0.00000
train epoch 760 avg loss: 0.00791 avg lploss: 0.00000
==> val epoch 760 avg loss: 0.00811 avg lploss: 0.00000
==> test epoch 760 avg loss: 0.00790 avg lploss: 0.00000
*** Best Val Loss: 0.00811 	 Best Test Loss: 0.00790 	 Best epoch 760
Validation loss decreased (0.008154 --> 0.008112).  Saving model ...
train epoch 761 avg loss: 0.00786 avg lploss: 0.00000
train epoch 762 avg loss: 0.00791 avg lploss: 0.00000
train epoch 763 avg loss: 0.00813 avg lploss: 0.00000
train epoch 764 avg loss: 0.00882 avg lploss: 0.00000
train epoch 765 avg loss: 0.00809 avg lploss: 0.00000
==> val epoch 765 avg loss: 0.00818 avg lploss: 0.00000
==> test epoch 765 avg loss: 0.00800 avg lploss: 0.00000
*** Best Val Loss: 0.00811 	 Best Test Loss: 0.00790 	 Best epoch 760
EarlyStopping counter: 1 out of 50
train epoch 766 avg loss: 0.00789 avg lploss: 0.00000
train epoch 767 avg loss: 0.00799 avg lploss: 0.00000
train epoch 768 avg loss: 0.00788 avg lploss: 0.00000
train epoch 769 avg loss: 0.00787 avg lploss: 0.00000
train epoch 770 avg loss: 0.00784 avg lploss: 0.00000
==> val epoch 770 avg loss: 0.00805 avg lploss: 0.00000
==> test epoch 770 avg loss: 0.00784 avg lploss: 0.00000
*** Best Val Loss: 0.00805 	 Best Test Loss: 0.00784 	 Best epoch 770
Validation loss decreased (0.008112 --> 0.008048).  Saving model ...
train epoch 771 avg loss: 0.00796 avg lploss: 0.00000
train epoch 772 avg loss: 0.00800 avg lploss: 0.00000
train epoch 773 avg loss: 0.00794 avg lploss: 0.00000
train epoch 774 avg loss: 0.00788 avg lploss: 0.00000
train epoch 775 avg loss: 0.00793 avg lploss: 0.00000
==> val epoch 775 avg loss: 0.00818 avg lploss: 0.00000
==> test epoch 775 avg loss: 0.00800 avg lploss: 0.00000
*** Best Val Loss: 0.00805 	 Best Test Loss: 0.00784 	 Best epoch 770
EarlyStopping counter: 1 out of 50
train epoch 776 avg loss: 0.00794 avg lploss: 0.00000
train epoch 777 avg loss: 0.00780 avg lploss: 0.00000
train epoch 778 avg loss: 0.00779 avg lploss: 0.00000
train epoch 779 avg loss: 0.00782 avg lploss: 0.00000
train epoch 780 avg loss: 0.00787 avg lploss: 0.00000
==> val epoch 780 avg loss: 0.00808 avg lploss: 0.00000
==> test epoch 780 avg loss: 0.00794 avg lploss: 0.00000
*** Best Val Loss: 0.00805 	 Best Test Loss: 0.00784 	 Best epoch 770
EarlyStopping counter: 2 out of 50
train epoch 781 avg loss: 0.00782 avg lploss: 0.00000
train epoch 782 avg loss: 0.00789 avg lploss: 0.00000
train epoch 783 avg loss: 0.00809 avg lploss: 0.00000
train epoch 784 avg loss: 0.00802 avg lploss: 0.00000
train epoch 785 avg loss: 0.00783 avg lploss: 0.00000
==> val epoch 785 avg loss: 0.00789 avg lploss: 0.00000
==> test epoch 785 avg loss: 0.00771 avg lploss: 0.00000
*** Best Val Loss: 0.00789 	 Best Test Loss: 0.00771 	 Best epoch 785
Validation loss decreased (0.008048 --> 0.007893).  Saving model ...
train epoch 786 avg loss: 0.00785 avg lploss: 0.00000
train epoch 787 avg loss: 0.00799 avg lploss: 0.00000
train epoch 788 avg loss: 0.00780 avg lploss: 0.00000
train epoch 789 avg loss: 0.00774 avg lploss: 0.00000
train epoch 790 avg loss: 0.00778 avg lploss: 0.00000
==> val epoch 790 avg loss: 0.00809 avg lploss: 0.00000
==> test epoch 790 avg loss: 0.00795 avg lploss: 0.00000
*** Best Val Loss: 0.00789 	 Best Test Loss: 0.00771 	 Best epoch 785
EarlyStopping counter: 1 out of 50
train epoch 791 avg loss: 0.00838 avg lploss: 0.00000
train epoch 792 avg loss: 0.00854 avg lploss: 0.00000
train epoch 793 avg loss: 0.00811 avg lploss: 0.00000
train epoch 794 avg loss: 0.00775 avg lploss: 0.00000
train epoch 795 avg loss: 0.00777 avg lploss: 0.00000
==> val epoch 795 avg loss: 0.00791 avg lploss: 0.00000
==> test epoch 795 avg loss: 0.00781 avg lploss: 0.00000
*** Best Val Loss: 0.00789 	 Best Test Loss: 0.00771 	 Best epoch 785
EarlyStopping counter: 2 out of 50
train epoch 796 avg loss: 0.00766 avg lploss: 0.00000
train epoch 797 avg loss: 0.00775 avg lploss: 0.00000
train epoch 798 avg loss: 0.00774 avg lploss: 0.00000
train epoch 799 avg loss: 0.00767 avg lploss: 0.00000
train epoch 800 avg loss: 0.00770 avg lploss: 0.00000
==> val epoch 800 avg loss: 0.00796 avg lploss: 0.00000
==> test epoch 800 avg loss: 0.00777 avg lploss: 0.00000
*** Best Val Loss: 0.00789 	 Best Test Loss: 0.00771 	 Best epoch 785
EarlyStopping counter: 3 out of 50
train epoch 801 avg loss: 0.00770 avg lploss: 0.00000
train epoch 802 avg loss: 0.00776 avg lploss: 0.00000
train epoch 803 avg loss: 0.00769 avg lploss: 0.00000
train epoch 804 avg loss: 0.00768 avg lploss: 0.00000
train epoch 805 avg loss: 0.00769 avg lploss: 0.00000
==> val epoch 805 avg loss: 0.00788 avg lploss: 0.00000
==> test epoch 805 avg loss: 0.00771 avg lploss: 0.00000
*** Best Val Loss: 0.00788 	 Best Test Loss: 0.00771 	 Best epoch 805
Validation loss decreased (0.007893 --> 0.007875).  Saving model ...
train epoch 806 avg loss: 0.00761 avg lploss: 0.00000
train epoch 807 avg loss: 0.00760 avg lploss: 0.00000
train epoch 808 avg loss: 0.00760 avg lploss: 0.00000
train epoch 809 avg loss: 0.00768 avg lploss: 0.00000
train epoch 810 avg loss: 0.00766 avg lploss: 0.00000
==> val epoch 810 avg loss: 0.00792 avg lploss: 0.00000
==> test epoch 810 avg loss: 0.00775 avg lploss: 0.00000
*** Best Val Loss: 0.00788 	 Best Test Loss: 0.00771 	 Best epoch 805
EarlyStopping counter: 1 out of 50
train epoch 811 avg loss: 0.00757 avg lploss: 0.00000
train epoch 812 avg loss: 0.00756 avg lploss: 0.00000
train epoch 813 avg loss: 0.00769 avg lploss: 0.00000
train epoch 814 avg loss: 0.00770 avg lploss: 0.00000
train epoch 815 avg loss: 0.00770 avg lploss: 0.00000
==> val epoch 815 avg loss: 0.00782 avg lploss: 0.00000
==> test epoch 815 avg loss: 0.00778 avg lploss: 0.00000
*** Best Val Loss: 0.00782 	 Best Test Loss: 0.00778 	 Best epoch 815
Validation loss decreased (0.007875 --> 0.007821).  Saving model ...
train epoch 816 avg loss: 0.00772 avg lploss: 0.00000
train epoch 817 avg loss: 0.00765 avg lploss: 0.00000
train epoch 818 avg loss: 0.00980 avg lploss: 0.00000
train epoch 819 avg loss: 0.00911 avg lploss: 0.00000
train epoch 820 avg loss: 0.00794 avg lploss: 0.00000
==> val epoch 820 avg loss: 0.00782 avg lploss: 0.00000
==> test epoch 820 avg loss: 0.00773 avg lploss: 0.00000
*** Best Val Loss: 0.00782 	 Best Test Loss: 0.00773 	 Best epoch 820
Validation loss decreased (0.007821 --> 0.007817).  Saving model ...
train epoch 821 avg loss: 0.00778 avg lploss: 0.00000
train epoch 822 avg loss: 0.00762 avg lploss: 0.00000
train epoch 823 avg loss: 0.00762 avg lploss: 0.00000
train epoch 824 avg loss: 0.00760 avg lploss: 0.00000
train epoch 825 avg loss: 0.00773 avg lploss: 0.00000
==> val epoch 825 avg loss: 0.00782 avg lploss: 0.00000
==> test epoch 825 avg loss: 0.00767 avg lploss: 0.00000
*** Best Val Loss: 0.00782 	 Best Test Loss: 0.00767 	 Best epoch 825
Validation loss decreased (0.007817 --> 0.007817).  Saving model ...
train epoch 826 avg loss: 0.00756 avg lploss: 0.00000
train epoch 827 avg loss: 0.00805 avg lploss: 0.00000
train epoch 828 avg loss: 0.00819 avg lploss: 0.00000
train epoch 829 avg loss: 0.00803 avg lploss: 0.00000
train epoch 830 avg loss: 0.00756 avg lploss: 0.00000
==> val epoch 830 avg loss: 0.00767 avg lploss: 0.00000
==> test epoch 830 avg loss: 0.00757 avg lploss: 0.00000
*** Best Val Loss: 0.00767 	 Best Test Loss: 0.00757 	 Best epoch 830
Validation loss decreased (0.007817 --> 0.007670).  Saving model ...
train epoch 831 avg loss: 0.00754 avg lploss: 0.00000
train epoch 832 avg loss: 0.00754 avg lploss: 0.00000
train epoch 833 avg loss: 0.00756 avg lploss: 0.00000
train epoch 834 avg loss: 0.00752 avg lploss: 0.00000
train epoch 835 avg loss: 0.00753 avg lploss: 0.00000
==> val epoch 835 avg loss: 0.00768 avg lploss: 0.00000
==> test epoch 835 avg loss: 0.00759 avg lploss: 0.00000
*** Best Val Loss: 0.00767 	 Best Test Loss: 0.00757 	 Best epoch 830
EarlyStopping counter: 1 out of 50
train epoch 836 avg loss: 0.00746 avg lploss: 0.00000
train epoch 837 avg loss: 0.00756 avg lploss: 0.00000
train epoch 838 avg loss: 0.00756 avg lploss: 0.00000
train epoch 839 avg loss: 0.00754 avg lploss: 0.00000
train epoch 840 avg loss: 0.00745 avg lploss: 0.00000
==> val epoch 840 avg loss: 0.00780 avg lploss: 0.00000
==> test epoch 840 avg loss: 0.00767 avg lploss: 0.00000
*** Best Val Loss: 0.00767 	 Best Test Loss: 0.00757 	 Best epoch 830
EarlyStopping counter: 2 out of 50
train epoch 841 avg loss: 0.00747 avg lploss: 0.00000
train epoch 842 avg loss: 0.00740 avg lploss: 0.00000
train epoch 843 avg loss: 0.00748 avg lploss: 0.00000
train epoch 844 avg loss: 0.00744 avg lploss: 0.00000
train epoch 845 avg loss: 0.00749 avg lploss: 0.00000
==> val epoch 845 avg loss: 0.00767 avg lploss: 0.00000
==> test epoch 845 avg loss: 0.00759 avg lploss: 0.00000
*** Best Val Loss: 0.00767 	 Best Test Loss: 0.00759 	 Best epoch 845
Validation loss decreased (0.007670 --> 0.007668).  Saving model ...
train epoch 846 avg loss: 0.00741 avg lploss: 0.00000
train epoch 847 avg loss: 0.00742 avg lploss: 0.00000
train epoch 848 avg loss: 0.00745 avg lploss: 0.00000
train epoch 849 avg loss: 0.00742 avg lploss: 0.00000
train epoch 850 avg loss: 0.00745 avg lploss: 0.00000
==> val epoch 850 avg loss: 0.00771 avg lploss: 0.00000
==> test epoch 850 avg loss: 0.00762 avg lploss: 0.00000
*** Best Val Loss: 0.00767 	 Best Test Loss: 0.00759 	 Best epoch 845
EarlyStopping counter: 1 out of 50
train epoch 851 avg loss: 0.00745 avg lploss: 0.00000
train epoch 852 avg loss: 0.00749 avg lploss: 0.00000
train epoch 853 avg loss: 0.00744 avg lploss: 0.00000
train epoch 854 avg loss: 0.00770 avg lploss: 0.00000
train epoch 855 avg loss: 0.00765 avg lploss: 0.00000
==> val epoch 855 avg loss: 0.00772 avg lploss: 0.00000
==> test epoch 855 avg loss: 0.00757 avg lploss: 0.00000
*** Best Val Loss: 0.00767 	 Best Test Loss: 0.00759 	 Best epoch 845
EarlyStopping counter: 2 out of 50
train epoch 856 avg loss: 0.00746 avg lploss: 0.00000
train epoch 857 avg loss: 0.00738 avg lploss: 0.00000
train epoch 858 avg loss: 0.00739 avg lploss: 0.00000
train epoch 859 avg loss: 0.00740 avg lploss: 0.00000
train epoch 860 avg loss: 0.00742 avg lploss: 0.00000
==> val epoch 860 avg loss: 0.00766 avg lploss: 0.00000
==> test epoch 860 avg loss: 0.00751 avg lploss: 0.00000
*** Best Val Loss: 0.00766 	 Best Test Loss: 0.00751 	 Best epoch 860
Validation loss decreased (0.007668 --> 0.007657).  Saving model ...
train epoch 861 avg loss: 0.00751 avg lploss: 0.00000
train epoch 862 avg loss: 0.00743 avg lploss: 0.00000
train epoch 863 avg loss: 0.00735 avg lploss: 0.00000
train epoch 864 avg loss: 0.00732 avg lploss: 0.00000
train epoch 865 avg loss: 0.00735 avg lploss: 0.00000
==> val epoch 865 avg loss: 0.00752 avg lploss: 0.00000
==> test epoch 865 avg loss: 0.00740 avg lploss: 0.00000
*** Best Val Loss: 0.00752 	 Best Test Loss: 0.00740 	 Best epoch 865
Validation loss decreased (0.007657 --> 0.007518).  Saving model ...
train epoch 866 avg loss: 0.00733 avg lploss: 0.00000
train epoch 867 avg loss: 0.00742 avg lploss: 0.00000
train epoch 868 avg loss: 0.00749 avg lploss: 0.00000
train epoch 869 avg loss: 0.00736 avg lploss: 0.00000
train epoch 870 avg loss: 0.00752 avg lploss: 0.00000
==> val epoch 870 avg loss: 0.00774 avg lploss: 0.00000
==> test epoch 870 avg loss: 0.00759 avg lploss: 0.00000
*** Best Val Loss: 0.00752 	 Best Test Loss: 0.00740 	 Best epoch 865
EarlyStopping counter: 1 out of 50
train epoch 871 avg loss: 0.00744 avg lploss: 0.00000
train epoch 872 avg loss: 0.00731 avg lploss: 0.00000
train epoch 873 avg loss: 0.00730 avg lploss: 0.00000
train epoch 874 avg loss: 0.00740 avg lploss: 0.00000
train epoch 875 avg loss: 0.00745 avg lploss: 0.00000
==> val epoch 875 avg loss: 0.00766 avg lploss: 0.00000
==> test epoch 875 avg loss: 0.00757 avg lploss: 0.00000
*** Best Val Loss: 0.00752 	 Best Test Loss: 0.00740 	 Best epoch 865
EarlyStopping counter: 2 out of 50
train epoch 876 avg loss: 0.00734 avg lploss: 0.00000
train epoch 877 avg loss: 0.00749 avg lploss: 0.00000
train epoch 878 avg loss: 0.00730 avg lploss: 0.00000
train epoch 879 avg loss: 0.00728 avg lploss: 0.00000
train epoch 880 avg loss: 0.00738 avg lploss: 0.00000
==> val epoch 880 avg loss: 0.00754 avg lploss: 0.00000
==> test epoch 880 avg loss: 0.00753 avg lploss: 0.00000
*** Best Val Loss: 0.00752 	 Best Test Loss: 0.00740 	 Best epoch 865
EarlyStopping counter: 3 out of 50
train epoch 881 avg loss: 0.00730 avg lploss: 0.00000
train epoch 882 avg loss: 0.00722 avg lploss: 0.00000
train epoch 883 avg loss: 0.00729 avg lploss: 0.00000
train epoch 884 avg loss: 0.00729 avg lploss: 0.00000
train epoch 885 avg loss: 0.00727 avg lploss: 0.00000
==> val epoch 885 avg loss: 0.00754 avg lploss: 0.00000
==> test epoch 885 avg loss: 0.00755 avg lploss: 0.00000
*** Best Val Loss: 0.00752 	 Best Test Loss: 0.00740 	 Best epoch 865
EarlyStopping counter: 4 out of 50
train epoch 886 avg loss: 0.00725 avg lploss: 0.00000
train epoch 887 avg loss: 0.00721 avg lploss: 0.00000
train epoch 888 avg loss: 0.00720 avg lploss: 0.00000
train epoch 889 avg loss: 0.00718 avg lploss: 0.00000
train epoch 890 avg loss: 0.00720 avg lploss: 0.00000
==> val epoch 890 avg loss: 0.00743 avg lploss: 0.00000
==> test epoch 890 avg loss: 0.00735 avg lploss: 0.00000
*** Best Val Loss: 0.00743 	 Best Test Loss: 0.00735 	 Best epoch 890
Validation loss decreased (0.007518 --> 0.007431).  Saving model ...
train epoch 891 avg loss: 0.00729 avg lploss: 0.00000
train epoch 892 avg loss: 0.00736 avg lploss: 0.00000
train epoch 893 avg loss: 0.00771 avg lploss: 0.00000
train epoch 894 avg loss: 0.00801 avg lploss: 0.00000
train epoch 895 avg loss: 0.00762 avg lploss: 0.00000
==> val epoch 895 avg loss: 0.00765 avg lploss: 0.00000
==> test epoch 895 avg loss: 0.00803 avg lploss: 0.00000
*** Best Val Loss: 0.00743 	 Best Test Loss: 0.00735 	 Best epoch 890
EarlyStopping counter: 1 out of 50
train epoch 896 avg loss: 0.00740 avg lploss: 0.00000
train epoch 897 avg loss: 0.00719 avg lploss: 0.00000
train epoch 898 avg loss: 0.00720 avg lploss: 0.00000
train epoch 899 avg loss: 0.00725 avg lploss: 0.00000
train epoch 900 avg loss: 0.00709 avg lploss: 0.00000
==> val epoch 900 avg loss: 0.00737 avg lploss: 0.00000
==> test epoch 900 avg loss: 0.00733 avg lploss: 0.00000
*** Best Val Loss: 0.00737 	 Best Test Loss: 0.00733 	 Best epoch 900
Validation loss decreased (0.007431 --> 0.007366).  Saving model ...
train epoch 901 avg loss: 0.00717 avg lploss: 0.00000
train epoch 902 avg loss: 0.00713 avg lploss: 0.00000
train epoch 903 avg loss: 0.00723 avg lploss: 0.00000
train epoch 904 avg loss: 0.00714 avg lploss: 0.00000
train epoch 905 avg loss: 0.00711 avg lploss: 0.00000
==> val epoch 905 avg loss: 0.00740 avg lploss: 0.00000
==> test epoch 905 avg loss: 0.00738 avg lploss: 0.00000
*** Best Val Loss: 0.00737 	 Best Test Loss: 0.00733 	 Best epoch 900
EarlyStopping counter: 1 out of 50
train epoch 906 avg loss: 0.00706 avg lploss: 0.00000
train epoch 907 avg loss: 0.00706 avg lploss: 0.00000
train epoch 908 avg loss: 0.00710 avg lploss: 0.00000
train epoch 909 avg loss: 0.00714 avg lploss: 0.00000
train epoch 910 avg loss: 0.00713 avg lploss: 0.00000
==> val epoch 910 avg loss: 0.00733 avg lploss: 0.00000
==> test epoch 910 avg loss: 0.00726 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00726 	 Best epoch 910
Validation loss decreased (0.007366 --> 0.007332).  Saving model ...
train epoch 911 avg loss: 0.00710 avg lploss: 0.00000
train epoch 912 avg loss: 0.00724 avg lploss: 0.00000
train epoch 913 avg loss: 0.00720 avg lploss: 0.00000
train epoch 914 avg loss: 0.00718 avg lploss: 0.00000
train epoch 915 avg loss: 0.00707 avg lploss: 0.00000
==> val epoch 915 avg loss: 0.00746 avg lploss: 0.00000
==> test epoch 915 avg loss: 0.00735 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00726 	 Best epoch 910
EarlyStopping counter: 1 out of 50
train epoch 916 avg loss: 0.00711 avg lploss: 0.00000
train epoch 917 avg loss: 0.00704 avg lploss: 0.00000
train epoch 918 avg loss: 0.00711 avg lploss: 0.00000
train epoch 919 avg loss: 0.00704 avg lploss: 0.00000
train epoch 920 avg loss: 0.00709 avg lploss: 0.00000
==> val epoch 920 avg loss: 0.00747 avg lploss: 0.00000
==> test epoch 920 avg loss: 0.00750 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00726 	 Best epoch 910
EarlyStopping counter: 2 out of 50
train epoch 921 avg loss: 0.00721 avg lploss: 0.00000
train epoch 922 avg loss: 0.00720 avg lploss: 0.00000
train epoch 923 avg loss: 0.01171 avg lploss: 0.00000
train epoch 924 avg loss: 0.00954 avg lploss: 0.00000
train epoch 925 avg loss: 0.00820 avg lploss: 0.00000
==> val epoch 925 avg loss: 0.00781 avg lploss: 0.00000
==> test epoch 925 avg loss: 0.00758 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00726 	 Best epoch 910
EarlyStopping counter: 3 out of 50
train epoch 926 avg loss: 0.00773 avg lploss: 0.00000
train epoch 927 avg loss: 0.00755 avg lploss: 0.00000
train epoch 928 avg loss: 0.00741 avg lploss: 0.00000
train epoch 929 avg loss: 0.00725 avg lploss: 0.00000
train epoch 930 avg loss: 0.00726 avg lploss: 0.00000
==> val epoch 930 avg loss: 0.00750 avg lploss: 0.00000
==> test epoch 930 avg loss: 0.00731 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00726 	 Best epoch 910
EarlyStopping counter: 4 out of 50
train epoch 931 avg loss: 0.00729 avg lploss: 0.00000
train epoch 932 avg loss: 0.00726 avg lploss: 0.00000
train epoch 933 avg loss: 0.00717 avg lploss: 0.00000
train epoch 934 avg loss: 0.00706 avg lploss: 0.00000
train epoch 935 avg loss: 0.00706 avg lploss: 0.00000
==> val epoch 935 avg loss: 0.00733 avg lploss: 0.00000
==> test epoch 935 avg loss: 0.00718 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00718 	 Best epoch 935
Validation loss decreased (0.007332 --> 0.007328).  Saving model ...
train epoch 936 avg loss: 0.00712 avg lploss: 0.00000
train epoch 937 avg loss: 0.00713 avg lploss: 0.00000
train epoch 938 avg loss: 0.00710 avg lploss: 0.00000
train epoch 939 avg loss: 0.00708 avg lploss: 0.00000
train epoch 940 avg loss: 0.00709 avg lploss: 0.00000
==> val epoch 940 avg loss: 0.00736 avg lploss: 0.00000
==> test epoch 940 avg loss: 0.00730 avg lploss: 0.00000
*** Best Val Loss: 0.00733 	 Best Test Loss: 0.00718 	 Best epoch 935
EarlyStopping counter: 1 out of 50
train epoch 941 avg loss: 0.00708 avg lploss: 0.00000
train epoch 942 avg loss: 0.00713 avg lploss: 0.00000
train epoch 943 avg loss: 0.00709 avg lploss: 0.00000
train epoch 944 avg loss: 0.00693 avg lploss: 0.00000
train epoch 945 avg loss: 0.00695 avg lploss: 0.00000
==> val epoch 945 avg loss: 0.00732 avg lploss: 0.00000
==> test epoch 945 avg loss: 0.00716 avg lploss: 0.00000
*** Best Val Loss: 0.00732 	 Best Test Loss: 0.00716 	 Best epoch 945
Validation loss decreased (0.007328 --> 0.007325).  Saving model ...
train epoch 946 avg loss: 0.00701 avg lploss: 0.00000
train epoch 947 avg loss: 0.00694 avg lploss: 0.00000
train epoch 948 avg loss: 0.00694 avg lploss: 0.00000
train epoch 949 avg loss: 0.00687 avg lploss: 0.00000
train epoch 950 avg loss: 0.00688 avg lploss: 0.00000
==> val epoch 950 avg loss: 0.00733 avg lploss: 0.00000
==> test epoch 950 avg loss: 0.00720 avg lploss: 0.00000
*** Best Val Loss: 0.00732 	 Best Test Loss: 0.00716 	 Best epoch 945
EarlyStopping counter: 1 out of 50
train epoch 951 avg loss: 0.00692 avg lploss: 0.00000
train epoch 952 avg loss: 0.00694 avg lploss: 0.00000
train epoch 953 avg loss: 0.00698 avg lploss: 0.00000
train epoch 954 avg loss: 0.00720 avg lploss: 0.00000
train epoch 955 avg loss: 0.00708 avg lploss: 0.00000
==> val epoch 955 avg loss: 0.00734 avg lploss: 0.00000
==> test epoch 955 avg loss: 0.00724 avg lploss: 0.00000
*** Best Val Loss: 0.00732 	 Best Test Loss: 0.00716 	 Best epoch 945
EarlyStopping counter: 2 out of 50
train epoch 956 avg loss: 0.00695 avg lploss: 0.00000
train epoch 957 avg loss: 0.00686 avg lploss: 0.00000
train epoch 958 avg loss: 0.00691 avg lploss: 0.00000
train epoch 959 avg loss: 0.00687 avg lploss: 0.00000
train epoch 960 avg loss: 0.00690 avg lploss: 0.00000
==> val epoch 960 avg loss: 0.00725 avg lploss: 0.00000
==> test epoch 960 avg loss: 0.00710 avg lploss: 0.00000
*** Best Val Loss: 0.00725 	 Best Test Loss: 0.00710 	 Best epoch 960
Validation loss decreased (0.007325 --> 0.007252).  Saving model ...
train epoch 961 avg loss: 0.00694 avg lploss: 0.00000
train epoch 962 avg loss: 0.00686 avg lploss: 0.00000
train epoch 963 avg loss: 0.00691 avg lploss: 0.00000
train epoch 964 avg loss: 0.00680 avg lploss: 0.00000
train epoch 965 avg loss: 0.00691 avg lploss: 0.00000
==> val epoch 965 avg loss: 0.00729 avg lploss: 0.00000
==> test epoch 965 avg loss: 0.00714 avg lploss: 0.00000
*** Best Val Loss: 0.00725 	 Best Test Loss: 0.00710 	 Best epoch 960
EarlyStopping counter: 1 out of 50
train epoch 966 avg loss: 0.00688 avg lploss: 0.00000
train epoch 967 avg loss: 0.00679 avg lploss: 0.00000
train epoch 968 avg loss: 0.00678 avg lploss: 0.00000
train epoch 969 avg loss: 0.00696 avg lploss: 0.00000
train epoch 970 avg loss: 0.00699 avg lploss: 0.00000
==> val epoch 970 avg loss: 0.00765 avg lploss: 0.00000
==> test epoch 970 avg loss: 0.00753 avg lploss: 0.00000
*** Best Val Loss: 0.00725 	 Best Test Loss: 0.00710 	 Best epoch 960
EarlyStopping counter: 2 out of 50
train epoch 971 avg loss: 0.00693 avg lploss: 0.00000
train epoch 972 avg loss: 0.00682 avg lploss: 0.00000
train epoch 973 avg loss: 0.00672 avg lploss: 0.00000
train epoch 974 avg loss: 0.00673 avg lploss: 0.00000
train epoch 975 avg loss: 0.00679 avg lploss: 0.00000
==> val epoch 975 avg loss: 0.00711 avg lploss: 0.00000
==> test epoch 975 avg loss: 0.00704 avg lploss: 0.00000
*** Best Val Loss: 0.00711 	 Best Test Loss: 0.00704 	 Best epoch 975
Validation loss decreased (0.007252 --> 0.007114).  Saving model ...
train epoch 976 avg loss: 0.00674 avg lploss: 0.00000
train epoch 977 avg loss: 0.00670 avg lploss: 0.00000
train epoch 978 avg loss: 0.00674 avg lploss: 0.00000
train epoch 979 avg loss: 0.00673 avg lploss: 0.00000
train epoch 980 avg loss: 0.00673 avg lploss: 0.00000
==> val epoch 980 avg loss: 0.00717 avg lploss: 0.00000
==> test epoch 980 avg loss: 0.00708 avg lploss: 0.00000
*** Best Val Loss: 0.00711 	 Best Test Loss: 0.00704 	 Best epoch 975
EarlyStopping counter: 1 out of 50
train epoch 981 avg loss: 0.00675 avg lploss: 0.00000
train epoch 982 avg loss: 0.00672 avg lploss: 0.00000
train epoch 983 avg loss: 0.00679 avg lploss: 0.00000
train epoch 984 avg loss: 0.00686 avg lploss: 0.00000
train epoch 985 avg loss: 0.00695 avg lploss: 0.00000
==> val epoch 985 avg loss: 0.00734 avg lploss: 0.00000
==> test epoch 985 avg loss: 0.00720 avg lploss: 0.00000
*** Best Val Loss: 0.00711 	 Best Test Loss: 0.00704 	 Best epoch 975
EarlyStopping counter: 2 out of 50
train epoch 986 avg loss: 0.00674 avg lploss: 0.00000
train epoch 987 avg loss: 0.00688 avg lploss: 0.00000
train epoch 988 avg loss: 0.00695 avg lploss: 0.00000
train epoch 989 avg loss: 0.00679 avg lploss: 0.00000
train epoch 990 avg loss: 0.00678 avg lploss: 0.00000
==> val epoch 990 avg loss: 0.00721 avg lploss: 0.00000
==> test epoch 990 avg loss: 0.00707 avg lploss: 0.00000
*** Best Val Loss: 0.00711 	 Best Test Loss: 0.00704 	 Best epoch 975
EarlyStopping counter: 3 out of 50
train epoch 991 avg loss: 0.00666 avg lploss: 0.00000
train epoch 992 avg loss: 0.00700 avg lploss: 0.00000
train epoch 993 avg loss: 0.00685 avg lploss: 0.00000
train epoch 994 avg loss: 0.00676 avg lploss: 0.00000
train epoch 995 avg loss: 0.00666 avg lploss: 0.00000
==> val epoch 995 avg loss: 0.00711 avg lploss: 0.00000
==> test epoch 995 avg loss: 0.00704 avg lploss: 0.00000
*** Best Val Loss: 0.00711 	 Best Test Loss: 0.00704 	 Best epoch 995
Validation loss decreased (0.007114 --> 0.007110).  Saving model ...
train epoch 996 avg loss: 0.00667 avg lploss: 0.00000
train epoch 997 avg loss: 0.00672 avg lploss: 0.00000
train epoch 998 avg loss: 0.00664 avg lploss: 0.00000
train epoch 999 avg loss: 0.00659 avg lploss: 0.00000
train epoch 1000 avg loss: 0.00662 avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.00709 avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.00699 avg lploss: 0.00000
*** Best Val Loss: 0.00709 	 Best Test Loss: 0.00699 	 Best epoch 1000
Validation loss decreased (0.007110 --> 0.007087).  Saving model ...
train epoch 1001 avg loss: 0.00659 avg lploss: 0.00000
train epoch 1002 avg loss: 0.00669 avg lploss: 0.00000
train epoch 1003 avg loss: 0.00674 avg lploss: 0.00000
train epoch 1004 avg loss: 0.00684 avg lploss: 0.00000
train epoch 1005 avg loss: 0.00663 avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.00722 avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.00705 avg lploss: 0.00000
*** Best Val Loss: 0.00709 	 Best Test Loss: 0.00699 	 Best epoch 1000
EarlyStopping counter: 1 out of 50
train epoch 1006 avg loss: 0.00664 avg lploss: 0.00000
train epoch 1007 avg loss: 0.00662 avg lploss: 0.00000
train epoch 1008 avg loss: 0.00660 avg lploss: 0.00000
train epoch 1009 avg loss: 0.00657 avg lploss: 0.00000
train epoch 1010 avg loss: 0.00654 avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.00717 avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.00697 avg lploss: 0.00000
*** Best Val Loss: 0.00709 	 Best Test Loss: 0.00699 	 Best epoch 1000
EarlyStopping counter: 2 out of 50
train epoch 1011 avg loss: 0.00694 avg lploss: 0.00000
train epoch 1012 avg loss: 0.00676 avg lploss: 0.00000
train epoch 1013 avg loss: 0.00671 avg lploss: 0.00000
train epoch 1014 avg loss: 0.00660 avg lploss: 0.00000
train epoch 1015 avg loss: 0.00654 avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.00696 avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.00684 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
Validation loss decreased (0.007087 --> 0.006958).  Saving model ...
train epoch 1016 avg loss: 0.00644 avg lploss: 0.00000
train epoch 1017 avg loss: 0.00656 avg lploss: 0.00000
train epoch 1018 avg loss: 0.00650 avg lploss: 0.00000
train epoch 1019 avg loss: 0.00660 avg lploss: 0.00000
train epoch 1020 avg loss: 0.00664 avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.00707 avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.00691 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 1 out of 50
train epoch 1021 avg loss: 0.00650 avg lploss: 0.00000
train epoch 1022 avg loss: 0.00651 avg lploss: 0.00000
train epoch 1023 avg loss: 0.00652 avg lploss: 0.00000
train epoch 1024 avg loss: 0.00660 avg lploss: 0.00000
train epoch 1025 avg loss: 0.00655 avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.00711 avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.00702 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 2 out of 50
train epoch 1026 avg loss: 0.00659 avg lploss: 0.00000
train epoch 1027 avg loss: 0.00663 avg lploss: 0.00000
train epoch 1028 avg loss: 0.00646 avg lploss: 0.00000
train epoch 1029 avg loss: 0.00640 avg lploss: 0.00000
train epoch 1030 avg loss: 0.00646 avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.00707 avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.00692 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 3 out of 50
train epoch 1031 avg loss: 0.00654 avg lploss: 0.00000
train epoch 1032 avg loss: 0.00671 avg lploss: 0.00000
train epoch 1033 avg loss: 0.00666 avg lploss: 0.00000
train epoch 1034 avg loss: 0.00651 avg lploss: 0.00000
train epoch 1035 avg loss: 0.00686 avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.00712 avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.00700 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 4 out of 50
train epoch 1036 avg loss: 0.00665 avg lploss: 0.00000
train epoch 1037 avg loss: 0.00645 avg lploss: 0.00000
train epoch 1038 avg loss: 0.00663 avg lploss: 0.00000
train epoch 1039 avg loss: 0.00648 avg lploss: 0.00000
train epoch 1040 avg loss: 0.00648 avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.00697 avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.00682 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 5 out of 50
train epoch 1041 avg loss: 0.00649 avg lploss: 0.00000
train epoch 1042 avg loss: 0.00651 avg lploss: 0.00000
train epoch 1043 avg loss: 0.00642 avg lploss: 0.00000
train epoch 1044 avg loss: 0.00647 avg lploss: 0.00000
train epoch 1045 avg loss: 0.00635 avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.00696 avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.00679 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 6 out of 50
train epoch 1046 avg loss: 0.00637 avg lploss: 0.00000
train epoch 1047 avg loss: 0.00647 avg lploss: 0.00000
train epoch 1048 avg loss: 0.00639 avg lploss: 0.00000
train epoch 1049 avg loss: 0.00645 avg lploss: 0.00000
train epoch 1050 avg loss: 0.00652 avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.00754 avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.00730 avg lploss: 0.00000
*** Best Val Loss: 0.00696 	 Best Test Loss: 0.00684 	 Best epoch 1015
EarlyStopping counter: 7 out of 50
train epoch 1051 avg loss: 0.00655 avg lploss: 0.00000
train epoch 1052 avg loss: 0.00640 avg lploss: 0.00000
train epoch 1053 avg loss: 0.00648 avg lploss: 0.00000
train epoch 1054 avg loss: 0.00639 avg lploss: 0.00000
train epoch 1055 avg loss: 0.00634 avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.00691 avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.00682 avg lploss: 0.00000
*** Best Val Loss: 0.00691 	 Best Test Loss: 0.00682 	 Best epoch 1055
Validation loss decreased (0.006958 --> 0.006909).  Saving model ...
train epoch 1056 avg loss: 0.00650 avg lploss: 0.00000
train epoch 1057 avg loss: 0.00654 avg lploss: 0.00000
train epoch 1058 avg loss: 0.00652 avg lploss: 0.00000
train epoch 1059 avg loss: 0.00638 avg lploss: 0.00000
train epoch 1060 avg loss: 0.00634 avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.00694 avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.00680 avg lploss: 0.00000
*** Best Val Loss: 0.00691 	 Best Test Loss: 0.00682 	 Best epoch 1055
EarlyStopping counter: 1 out of 50
train epoch 1061 avg loss: 0.00637 avg lploss: 0.00000
train epoch 1062 avg loss: 0.00633 avg lploss: 0.00000
train epoch 1063 avg loss: 0.00632 avg lploss: 0.00000
train epoch 1064 avg loss: 0.00635 avg lploss: 0.00000
train epoch 1065 avg loss: 0.00641 avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.00697 avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.00674 avg lploss: 0.00000
*** Best Val Loss: 0.00691 	 Best Test Loss: 0.00682 	 Best epoch 1055
EarlyStopping counter: 2 out of 50
train epoch 1066 avg loss: 0.00628 avg lploss: 0.00000
train epoch 1067 avg loss: 0.00627 avg lploss: 0.00000
train epoch 1068 avg loss: 0.00638 avg lploss: 0.00000
train epoch 1069 avg loss: 0.00646 avg lploss: 0.00000
train epoch 1070 avg loss: 0.00634 avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.00688 avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.00671 avg lploss: 0.00000
*** Best Val Loss: 0.00688 	 Best Test Loss: 0.00671 	 Best epoch 1070
Validation loss decreased (0.006909 --> 0.006879).  Saving model ...
train epoch 1071 avg loss: 0.00629 avg lploss: 0.00000
train epoch 1072 avg loss: 0.00637 avg lploss: 0.00000
train epoch 1073 avg loss: 0.00629 avg lploss: 0.00000
train epoch 1074 avg loss: 0.00623 avg lploss: 0.00000
train epoch 1075 avg loss: 0.00625 avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.00732 avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.00712 avg lploss: 0.00000
*** Best Val Loss: 0.00688 	 Best Test Loss: 0.00671 	 Best epoch 1070
EarlyStopping counter: 1 out of 50
train epoch 1076 avg loss: 0.00633 avg lploss: 0.00000
train epoch 1077 avg loss: 0.00625 avg lploss: 0.00000
train epoch 1078 avg loss: 0.00627 avg lploss: 0.00000
train epoch 1079 avg loss: 0.00639 avg lploss: 0.00000
train epoch 1080 avg loss: 0.00616 avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.00701 avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.00682 avg lploss: 0.00000
*** Best Val Loss: 0.00688 	 Best Test Loss: 0.00671 	 Best epoch 1070
EarlyStopping counter: 2 out of 50
train epoch 1081 avg loss: 0.00621 avg lploss: 0.00000
train epoch 1082 avg loss: 0.00646 avg lploss: 0.00000
train epoch 1083 avg loss: 0.00631 avg lploss: 0.00000
train epoch 1084 avg loss: 0.00632 avg lploss: 0.00000
train epoch 1085 avg loss: 0.00629 avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.00692 avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.00671 avg lploss: 0.00000
*** Best Val Loss: 0.00688 	 Best Test Loss: 0.00671 	 Best epoch 1070
EarlyStopping counter: 3 out of 50
train epoch 1086 avg loss: 0.00638 avg lploss: 0.00000
train epoch 1087 avg loss: 0.00638 avg lploss: 0.00000
train epoch 1088 avg loss: 0.00629 avg lploss: 0.00000
train epoch 1089 avg loss: 0.00632 avg lploss: 0.00000
train epoch 1090 avg loss: 0.00619 avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.00683 avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.00666 avg lploss: 0.00000
*** Best Val Loss: 0.00683 	 Best Test Loss: 0.00666 	 Best epoch 1090
Validation loss decreased (0.006879 --> 0.006829).  Saving model ...
train epoch 1091 avg loss: 0.00620 avg lploss: 0.00000
train epoch 1092 avg loss: 0.00617 avg lploss: 0.00000
train epoch 1093 avg loss: 0.00645 avg lploss: 0.00000
train epoch 1094 avg loss: 0.00729 avg lploss: 0.00000
train epoch 1095 avg loss: 0.00646 avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.00710 avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.00689 avg lploss: 0.00000
*** Best Val Loss: 0.00683 	 Best Test Loss: 0.00666 	 Best epoch 1090
EarlyStopping counter: 1 out of 50
train epoch 1096 avg loss: 0.00629 avg lploss: 0.00000
train epoch 1097 avg loss: 0.00622 avg lploss: 0.00000
train epoch 1098 avg loss: 0.00618 avg lploss: 0.00000
train epoch 1099 avg loss: 0.00624 avg lploss: 0.00000
train epoch 1100 avg loss: 0.00620 avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.00687 avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.00665 avg lploss: 0.00000
*** Best Val Loss: 0.00683 	 Best Test Loss: 0.00666 	 Best epoch 1090
EarlyStopping counter: 2 out of 50
train epoch 1101 avg loss: 0.00621 avg lploss: 0.00000
train epoch 1102 avg loss: 0.00623 avg lploss: 0.00000
train epoch 1103 avg loss: 0.00614 avg lploss: 0.00000
train epoch 1104 avg loss: 0.00619 avg lploss: 0.00000
train epoch 1105 avg loss: 0.00645 avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.00723 avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.00700 avg lploss: 0.00000
*** Best Val Loss: 0.00683 	 Best Test Loss: 0.00666 	 Best epoch 1090
EarlyStopping counter: 3 out of 50
train epoch 1106 avg loss: 0.00618 avg lploss: 0.00000
train epoch 1107 avg loss: 0.00607 avg lploss: 0.00000
train epoch 1108 avg loss: 0.00613 avg lploss: 0.00000
train epoch 1109 avg loss: 0.00638 avg lploss: 0.00000
train epoch 1110 avg loss: 0.01007 avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.00926 avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.00880 avg lploss: 0.00000
*** Best Val Loss: 0.00683 	 Best Test Loss: 0.00666 	 Best epoch 1090
EarlyStopping counter: 4 out of 50
train epoch 1111 avg loss: 0.00796 avg lploss: 0.00000
train epoch 1112 avg loss: 0.00660 avg lploss: 0.00000
train epoch 1113 avg loss: 0.00639 avg lploss: 0.00000
train epoch 1114 avg loss: 0.00624 avg lploss: 0.00000
train epoch 1115 avg loss: 0.00618 avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.00674 avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.00648 avg lploss: 0.00000
*** Best Val Loss: 0.00674 	 Best Test Loss: 0.00648 	 Best epoch 1115
Validation loss decreased (0.006829 --> 0.006740).  Saving model ...
train epoch 1116 avg loss: 0.00620 avg lploss: 0.00000
train epoch 1117 avg loss: 0.00613 avg lploss: 0.00000
train epoch 1118 avg loss: 0.00621 avg lploss: 0.00000
train epoch 1119 avg loss: 0.00608 avg lploss: 0.00000
train epoch 1120 avg loss: 0.00604 avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.00668 avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.00648 avg lploss: 0.00000
*** Best Val Loss: 0.00668 	 Best Test Loss: 0.00648 	 Best epoch 1120
Validation loss decreased (0.006740 --> 0.006683).  Saving model ...
train epoch 1121 avg loss: 0.00606 avg lploss: 0.00000
train epoch 1122 avg loss: 0.00616 avg lploss: 0.00000
train epoch 1123 avg loss: 0.00610 avg lploss: 0.00000
train epoch 1124 avg loss: 0.00603 avg lploss: 0.00000
train epoch 1125 avg loss: 0.00620 avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.00672 avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.00656 avg lploss: 0.00000
*** Best Val Loss: 0.00668 	 Best Test Loss: 0.00648 	 Best epoch 1120
EarlyStopping counter: 1 out of 50
train epoch 1126 avg loss: 0.00610 avg lploss: 0.00000
train epoch 1127 avg loss: 0.00602 avg lploss: 0.00000
train epoch 1128 avg loss: 0.00604 avg lploss: 0.00000
train epoch 1129 avg loss: 0.00597 avg lploss: 0.00000
train epoch 1130 avg loss: 0.00598 avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.00685 avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.00673 avg lploss: 0.00000
*** Best Val Loss: 0.00668 	 Best Test Loss: 0.00648 	 Best epoch 1120
EarlyStopping counter: 2 out of 50
train epoch 1131 avg loss: 0.00608 avg lploss: 0.00000
train epoch 1132 avg loss: 0.00614 avg lploss: 0.00000
train epoch 1133 avg loss: 0.00600 avg lploss: 0.00000
train epoch 1134 avg loss: 0.00602 avg lploss: 0.00000
train epoch 1135 avg loss: 0.00600 avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.00667 avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.00653 avg lploss: 0.00000
*** Best Val Loss: 0.00667 	 Best Test Loss: 0.00653 	 Best epoch 1135
Validation loss decreased (0.006683 --> 0.006675).  Saving model ...
train epoch 1136 avg loss: 0.00595 avg lploss: 0.00000
train epoch 1137 avg loss: 0.00596 avg lploss: 0.00000
train epoch 1138 avg loss: 0.00597 avg lploss: 0.00000
train epoch 1139 avg loss: 0.00600 avg lploss: 0.00000
train epoch 1140 avg loss: 0.00601 avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.00671 avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.00653 avg lploss: 0.00000
*** Best Val Loss: 0.00667 	 Best Test Loss: 0.00653 	 Best epoch 1135
EarlyStopping counter: 1 out of 50
train epoch 1141 avg loss: 0.00604 avg lploss: 0.00000
train epoch 1142 avg loss: 0.00602 avg lploss: 0.00000
train epoch 1143 avg loss: 0.00599 avg lploss: 0.00000
train epoch 1144 avg loss: 0.00588 avg lploss: 0.00000
train epoch 1145 avg loss: 0.00592 avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.00668 avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.00649 avg lploss: 0.00000
*** Best Val Loss: 0.00667 	 Best Test Loss: 0.00653 	 Best epoch 1135
EarlyStopping counter: 2 out of 50
train epoch 1146 avg loss: 0.00598 avg lploss: 0.00000
train epoch 1147 avg loss: 0.00588 avg lploss: 0.00000
train epoch 1148 avg loss: 0.00587 avg lploss: 0.00000
train epoch 1149 avg loss: 0.00589 avg lploss: 0.00000
train epoch 1150 avg loss: 0.00592 avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.00674 avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.00667 avg lploss: 0.00000
*** Best Val Loss: 0.00667 	 Best Test Loss: 0.00653 	 Best epoch 1135
EarlyStopping counter: 3 out of 50
train epoch 1151 avg loss: 0.00620 avg lploss: 0.00000
train epoch 1152 avg loss: 0.00610 avg lploss: 0.00000
train epoch 1153 avg loss: 0.00589 avg lploss: 0.00000
train epoch 1154 avg loss: 0.00592 avg lploss: 0.00000
train epoch 1155 avg loss: 0.00587 avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.00661 avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.00649 avg lploss: 0.00000
*** Best Val Loss: 0.00661 	 Best Test Loss: 0.00649 	 Best epoch 1155
Validation loss decreased (0.006675 --> 0.006613).  Saving model ...
train epoch 1156 avg loss: 0.00596 avg lploss: 0.00000
train epoch 1157 avg loss: 0.00590 avg lploss: 0.00000
train epoch 1158 avg loss: 0.00595 avg lploss: 0.00000
train epoch 1159 avg loss: 0.00593 avg lploss: 0.00000
train epoch 1160 avg loss: 0.00593 avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.00662 avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.00644 avg lploss: 0.00000
*** Best Val Loss: 0.00661 	 Best Test Loss: 0.00649 	 Best epoch 1155
EarlyStopping counter: 1 out of 50
train epoch 1161 avg loss: 0.00583 avg lploss: 0.00000
train epoch 1162 avg loss: 0.00587 avg lploss: 0.00000
train epoch 1163 avg loss: 0.00590 avg lploss: 0.00000
train epoch 1164 avg loss: 0.00604 avg lploss: 0.00000
train epoch 1165 avg loss: 0.00588 avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.00673 avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.00665 avg lploss: 0.00000
*** Best Val Loss: 0.00661 	 Best Test Loss: 0.00649 	 Best epoch 1155
EarlyStopping counter: 2 out of 50
train epoch 1166 avg loss: 0.00600 avg lploss: 0.00000
train epoch 1167 avg loss: 0.00584 avg lploss: 0.00000
train epoch 1168 avg loss: 0.00589 avg lploss: 0.00000
train epoch 1169 avg loss: 0.00589 avg lploss: 0.00000
train epoch 1170 avg loss: 0.00592 avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.00687 avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.00682 avg lploss: 0.00000
*** Best Val Loss: 0.00661 	 Best Test Loss: 0.00649 	 Best epoch 1155
EarlyStopping counter: 3 out of 50
train epoch 1171 avg loss: 0.00592 avg lploss: 0.00000
train epoch 1172 avg loss: 0.00582 avg lploss: 0.00000
train epoch 1173 avg loss: 0.00581 avg lploss: 0.00000
train epoch 1174 avg loss: 0.00578 avg lploss: 0.00000
train epoch 1175 avg loss: 0.00598 avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.00671 avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.00656 avg lploss: 0.00000
*** Best Val Loss: 0.00661 	 Best Test Loss: 0.00649 	 Best epoch 1155
EarlyStopping counter: 4 out of 50
train epoch 1176 avg loss: 0.00592 avg lploss: 0.00000
train epoch 1177 avg loss: 0.00586 avg lploss: 0.00000
train epoch 1178 avg loss: 0.00578 avg lploss: 0.00000
train epoch 1179 avg loss: 0.00574 avg lploss: 0.00000
train epoch 1180 avg loss: 0.00592 avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.00659 avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.00638 avg lploss: 0.00000
*** Best Val Loss: 0.00659 	 Best Test Loss: 0.00638 	 Best epoch 1180
Validation loss decreased (0.006613 --> 0.006588).  Saving model ...
train epoch 1181 avg loss: 0.00578 avg lploss: 0.00000
train epoch 1182 avg loss: 0.00585 avg lploss: 0.00000
train epoch 1183 avg loss: 0.00579 avg lploss: 0.00000
train epoch 1184 avg loss: 0.00573 avg lploss: 0.00000
train epoch 1185 avg loss: 0.00574 avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.00671 avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.00652 avg lploss: 0.00000
*** Best Val Loss: 0.00659 	 Best Test Loss: 0.00638 	 Best epoch 1180
EarlyStopping counter: 1 out of 50
train epoch 1186 avg loss: 0.00567 avg lploss: 0.00000
train epoch 1187 avg loss: 0.00579 avg lploss: 0.00000
train epoch 1188 avg loss: 0.00581 avg lploss: 0.00000
train epoch 1189 avg loss: 0.00590 avg lploss: 0.00000
train epoch 1190 avg loss: 0.00584 avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.00666 avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.00650 avg lploss: 0.00000
*** Best Val Loss: 0.00659 	 Best Test Loss: 0.00638 	 Best epoch 1180
EarlyStopping counter: 2 out of 50
train epoch 1191 avg loss: 0.00587 avg lploss: 0.00000
train epoch 1192 avg loss: 0.00569 avg lploss: 0.00000
train epoch 1193 avg loss: 0.00571 avg lploss: 0.00000
train epoch 1194 avg loss: 0.00571 avg lploss: 0.00000
train epoch 1195 avg loss: 0.00601 avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.00686 avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.00668 avg lploss: 0.00000
*** Best Val Loss: 0.00659 	 Best Test Loss: 0.00638 	 Best epoch 1180
EarlyStopping counter: 3 out of 50
train epoch 1196 avg loss: 0.00583 avg lploss: 0.00000
train epoch 1197 avg loss: 0.00570 avg lploss: 0.00000
train epoch 1198 avg loss: 0.00574 avg lploss: 0.00000
train epoch 1199 avg loss: 0.00567 avg lploss: 0.00000
train epoch 1200 avg loss: 0.00573 avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.00651 avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.00632 avg lploss: 0.00000
*** Best Val Loss: 0.00651 	 Best Test Loss: 0.00632 	 Best epoch 1200
Validation loss decreased (0.006588 --> 0.006506).  Saving model ...
train epoch 1201 avg loss: 0.00564 avg lploss: 0.00000
train epoch 1202 avg loss: 0.00573 avg lploss: 0.00000
train epoch 1203 avg loss: 0.00565 avg lploss: 0.00000
train epoch 1204 avg loss: 0.00571 avg lploss: 0.00000
train epoch 1205 avg loss: 0.00576 avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.00655 avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.00637 avg lploss: 0.00000
*** Best Val Loss: 0.00651 	 Best Test Loss: 0.00632 	 Best epoch 1200
EarlyStopping counter: 1 out of 50
train epoch 1206 avg loss: 0.00571 avg lploss: 0.00000
train epoch 1207 avg loss: 0.00563 avg lploss: 0.00000
train epoch 1208 avg loss: 0.00570 avg lploss: 0.00000
train epoch 1209 avg loss: 0.00574 avg lploss: 0.00000
train epoch 1210 avg loss: 0.00567 avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.00671 avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.00651 avg lploss: 0.00000
*** Best Val Loss: 0.00651 	 Best Test Loss: 0.00632 	 Best epoch 1200
EarlyStopping counter: 2 out of 50
train epoch 1211 avg loss: 0.00570 avg lploss: 0.00000
train epoch 1212 avg loss: 0.00565 avg lploss: 0.00000
train epoch 1213 avg loss: 0.00584 avg lploss: 0.00000
train epoch 1214 avg loss: 0.00565 avg lploss: 0.00000
train epoch 1215 avg loss: 0.00561 avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.00648 avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.00629 avg lploss: 0.00000
*** Best Val Loss: 0.00648 	 Best Test Loss: 0.00629 	 Best epoch 1215
Validation loss decreased (0.006506 --> 0.006475).  Saving model ...
train epoch 1216 avg loss: 0.00562 avg lploss: 0.00000
train epoch 1217 avg loss: 0.00561 avg lploss: 0.00000
train epoch 1218 avg loss: 0.00568 avg lploss: 0.00000
train epoch 1219 avg loss: 0.00610 avg lploss: 0.00000
train epoch 1220 avg loss: 0.00569 avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.00644 avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.00629 avg lploss: 0.00000
*** Best Val Loss: 0.00644 	 Best Test Loss: 0.00629 	 Best epoch 1220
Validation loss decreased (0.006475 --> 0.006445).  Saving model ...
train epoch 1221 avg loss: 0.00567 avg lploss: 0.00000
train epoch 1222 avg loss: 0.00568 avg lploss: 0.00000
train epoch 1223 avg loss: 0.00574 avg lploss: 0.00000
train epoch 1224 avg loss: 0.00563 avg lploss: 0.00000
train epoch 1225 avg loss: 0.00567 avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.00654 avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.00644 avg lploss: 0.00000
*** Best Val Loss: 0.00644 	 Best Test Loss: 0.00629 	 Best epoch 1220
EarlyStopping counter: 1 out of 50
train epoch 1226 avg loss: 0.00565 avg lploss: 0.00000
train epoch 1227 avg loss: 0.00561 avg lploss: 0.00000
train epoch 1228 avg loss: 0.00556 avg lploss: 0.00000
train epoch 1229 avg loss: 0.00567 avg lploss: 0.00000
train epoch 1230 avg loss: 0.00561 avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.00659 avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.00637 avg lploss: 0.00000
*** Best Val Loss: 0.00644 	 Best Test Loss: 0.00629 	 Best epoch 1220
EarlyStopping counter: 2 out of 50
train epoch 1231 avg loss: 0.00561 avg lploss: 0.00000
train epoch 1232 avg loss: 0.00554 avg lploss: 0.00000
train epoch 1233 avg loss: 0.00553 avg lploss: 0.00000
train epoch 1234 avg loss: 0.00553 avg lploss: 0.00000
train epoch 1235 avg loss: 0.00549 avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.00640 avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.00620 avg lploss: 0.00000
*** Best Val Loss: 0.00640 	 Best Test Loss: 0.00620 	 Best epoch 1235
Validation loss decreased (0.006445 --> 0.006404).  Saving model ...
train epoch 1236 avg loss: 0.00551 avg lploss: 0.00000
train epoch 1237 avg loss: 0.00555 avg lploss: 0.00000
train epoch 1238 avg loss: 0.00553 avg lploss: 0.00000
train epoch 1239 avg loss: 0.00556 avg lploss: 0.00000
train epoch 1240 avg loss: 0.00569 avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.00641 avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.00618 avg lploss: 0.00000
*** Best Val Loss: 0.00640 	 Best Test Loss: 0.00620 	 Best epoch 1235
EarlyStopping counter: 1 out of 50
train epoch 1241 avg loss: 0.00559 avg lploss: 0.00000
train epoch 1242 avg loss: 0.00559 avg lploss: 0.00000
train epoch 1243 avg loss: 0.00556 avg lploss: 0.00000
train epoch 1244 avg loss: 0.00553 avg lploss: 0.00000
train epoch 1245 avg loss: 0.00552 avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.00647 avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.00630 avg lploss: 0.00000
*** Best Val Loss: 0.00640 	 Best Test Loss: 0.00620 	 Best epoch 1235
EarlyStopping counter: 2 out of 50
train epoch 1246 avg loss: 0.00544 avg lploss: 0.00000
train epoch 1247 avg loss: 0.00547 avg lploss: 0.00000
train epoch 1248 avg loss: 0.00553 avg lploss: 0.00000
train epoch 1249 avg loss: 0.00563 avg lploss: 0.00000
train epoch 1250 avg loss: 0.00560 avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.00637 avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.00625 avg lploss: 0.00000
*** Best Val Loss: 0.00637 	 Best Test Loss: 0.00625 	 Best epoch 1250
Validation loss decreased (0.006404 --> 0.006366).  Saving model ...
train epoch 1251 avg loss: 0.00547 avg lploss: 0.00000
train epoch 1252 avg loss: 0.00577 avg lploss: 0.00000
train epoch 1253 avg loss: 0.00556 avg lploss: 0.00000
train epoch 1254 avg loss: 0.00557 avg lploss: 0.00000
train epoch 1255 avg loss: 0.00548 avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.00680 avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.00656 avg lploss: 0.00000
*** Best Val Loss: 0.00637 	 Best Test Loss: 0.00625 	 Best epoch 1250
EarlyStopping counter: 1 out of 50
train epoch 1256 avg loss: 0.00557 avg lploss: 0.00000
train epoch 1257 avg loss: 0.00557 avg lploss: 0.00000
train epoch 1258 avg loss: 0.00549 avg lploss: 0.00000
train epoch 1259 avg loss: 0.00552 avg lploss: 0.00000
train epoch 1260 avg loss: 0.00551 avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.00646 avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.00620 avg lploss: 0.00000
*** Best Val Loss: 0.00637 	 Best Test Loss: 0.00625 	 Best epoch 1250
EarlyStopping counter: 2 out of 50
train epoch 1261 avg loss: 0.00543 avg lploss: 0.00000
train epoch 1262 avg loss: 0.00538 avg lploss: 0.00000
train epoch 1263 avg loss: 0.00553 avg lploss: 0.00000
train epoch 1264 avg loss: 0.00545 avg lploss: 0.00000
train epoch 1265 avg loss: 0.00561 avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.00687 avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.00669 avg lploss: 0.00000
*** Best Val Loss: 0.00637 	 Best Test Loss: 0.00625 	 Best epoch 1250
EarlyStopping counter: 3 out of 50
train epoch 1266 avg loss: 0.00559 avg lploss: 0.00000
train epoch 1267 avg loss: 0.00545 avg lploss: 0.00000
train epoch 1268 avg loss: 0.00556 avg lploss: 0.00000
train epoch 1269 avg loss: 0.00546 avg lploss: 0.00000
train epoch 1270 avg loss: 0.00539 avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.00634 avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.00613 avg lploss: 0.00000
*** Best Val Loss: 0.00634 	 Best Test Loss: 0.00613 	 Best epoch 1270
Validation loss decreased (0.006366 --> 0.006343).  Saving model ...
train epoch 1271 avg loss: 0.00536 avg lploss: 0.00000
train epoch 1272 avg loss: 0.00538 avg lploss: 0.00000
train epoch 1273 avg loss: 0.00542 avg lploss: 0.00000
train epoch 1274 avg loss: 0.00541 avg lploss: 0.00000
train epoch 1275 avg loss: 0.00542 avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.00647 avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.00628 avg lploss: 0.00000
*** Best Val Loss: 0.00634 	 Best Test Loss: 0.00613 	 Best epoch 1270
EarlyStopping counter: 1 out of 50
train epoch 1276 avg loss: 0.00545 avg lploss: 0.00000
train epoch 1277 avg loss: 0.00537 avg lploss: 0.00000
train epoch 1278 avg loss: 0.00533 avg lploss: 0.00000
train epoch 1279 avg loss: 0.00538 avg lploss: 0.00000
train epoch 1280 avg loss: 0.00543 avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.00634 avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.00612 avg lploss: 0.00000
*** Best Val Loss: 0.00634 	 Best Test Loss: 0.00612 	 Best epoch 1280
Validation loss decreased (0.006343 --> 0.006335).  Saving model ...
train epoch 1281 avg loss: 0.00551 avg lploss: 0.00000
train epoch 1282 avg loss: 0.00570 avg lploss: 0.00000
train epoch 1283 avg loss: 0.00558 avg lploss: 0.00000
train epoch 1284 avg loss: 0.00540 avg lploss: 0.00000
train epoch 1285 avg loss: 0.00541 avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.00635 avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.00614 avg lploss: 0.00000
*** Best Val Loss: 0.00634 	 Best Test Loss: 0.00612 	 Best epoch 1280
EarlyStopping counter: 1 out of 50
train epoch 1286 avg loss: 0.00541 avg lploss: 0.00000
train epoch 1287 avg loss: 0.00539 avg lploss: 0.00000
train epoch 1288 avg loss: 0.00539 avg lploss: 0.00000
train epoch 1289 avg loss: 0.00531 avg lploss: 0.00000
train epoch 1290 avg loss: 0.00525 avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.00624 avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.00612 avg lploss: 0.00000
*** Best Val Loss: 0.00624 	 Best Test Loss: 0.00612 	 Best epoch 1290
Validation loss decreased (0.006335 --> 0.006237).  Saving model ...
train epoch 1291 avg loss: 0.00531 avg lploss: 0.00000
train epoch 1292 avg loss: 0.00532 avg lploss: 0.00000
train epoch 1293 avg loss: 0.00530 avg lploss: 0.00000
train epoch 1294 avg loss: 0.00544 avg lploss: 0.00000
train epoch 1295 avg loss: 0.00545 avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.00643 avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.00624 avg lploss: 0.00000
*** Best Val Loss: 0.00624 	 Best Test Loss: 0.00612 	 Best epoch 1290
EarlyStopping counter: 1 out of 50
train epoch 1296 avg loss: 0.00554 avg lploss: 0.00000
train epoch 1297 avg loss: 0.00529 avg lploss: 0.00000
train epoch 1298 avg loss: 0.00535 avg lploss: 0.00000
train epoch 1299 avg loss: 0.00529 avg lploss: 0.00000
train epoch 1300 avg loss: 0.00537 avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.00627 avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.00608 avg lploss: 0.00000
*** Best Val Loss: 0.00624 	 Best Test Loss: 0.00612 	 Best epoch 1290
EarlyStopping counter: 2 out of 50
train epoch 1301 avg loss: 0.00539 avg lploss: 0.00000
train epoch 1302 avg loss: 0.00526 avg lploss: 0.00000
train epoch 1303 avg loss: 0.00534 avg lploss: 0.00000
train epoch 1304 avg loss: 0.00533 avg lploss: 0.00000
train epoch 1305 avg loss: 0.00538 avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.00628 avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.00603 avg lploss: 0.00000
*** Best Val Loss: 0.00624 	 Best Test Loss: 0.00612 	 Best epoch 1290
EarlyStopping counter: 3 out of 50
train epoch 1306 avg loss: 0.00539 avg lploss: 0.00000
train epoch 1307 avg loss: 0.00530 avg lploss: 0.00000
train epoch 1308 avg loss: 0.00526 avg lploss: 0.00000
train epoch 1309 avg loss: 0.00530 avg lploss: 0.00000
train epoch 1310 avg loss: 0.00534 avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.00644 avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.00618 avg lploss: 0.00000
*** Best Val Loss: 0.00624 	 Best Test Loss: 0.00612 	 Best epoch 1290
EarlyStopping counter: 4 out of 50
train epoch 1311 avg loss: 0.00524 avg lploss: 0.00000
train epoch 1312 avg loss: 0.00512 avg lploss: 0.00000
train epoch 1313 avg loss: 0.00522 avg lploss: 0.00000
train epoch 1314 avg loss: 0.00525 avg lploss: 0.00000
train epoch 1315 avg loss: 0.00521 avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.00619 avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.00596 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00596 	 Best epoch 1315
Validation loss decreased (0.006237 --> 0.006193).  Saving model ...
train epoch 1316 avg loss: 0.00517 avg lploss: 0.00000
train epoch 1317 avg loss: 0.00530 avg lploss: 0.00000
train epoch 1318 avg loss: 0.00532 avg lploss: 0.00000
train epoch 1319 avg loss: 0.00533 avg lploss: 0.00000
train epoch 1320 avg loss: 0.00525 avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.00639 avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.00619 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00596 	 Best epoch 1315
EarlyStopping counter: 1 out of 50
train epoch 1321 avg loss: 0.00520 avg lploss: 0.00000
train epoch 1322 avg loss: 0.00515 avg lploss: 0.00000
train epoch 1323 avg loss: 0.00513 avg lploss: 0.00000
train epoch 1324 avg loss: 0.00518 avg lploss: 0.00000
train epoch 1325 avg loss: 0.00514 avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.00619 avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.00598 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00598 	 Best epoch 1325
Validation loss decreased (0.006193 --> 0.006189).  Saving model ...
train epoch 1326 avg loss: 0.00518 avg lploss: 0.00000
train epoch 1327 avg loss: 0.00517 avg lploss: 0.00000
train epoch 1328 avg loss: 0.00510 avg lploss: 0.00000
train epoch 1329 avg loss: 0.00516 avg lploss: 0.00000
train epoch 1330 avg loss: 0.00525 avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.00642 avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.00618 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00598 	 Best epoch 1325
EarlyStopping counter: 1 out of 50
train epoch 1331 avg loss: 0.00515 avg lploss: 0.00000
train epoch 1332 avg loss: 0.00518 avg lploss: 0.00000
train epoch 1333 avg loss: 0.00518 avg lploss: 0.00000
train epoch 1334 avg loss: 0.00515 avg lploss: 0.00000
train epoch 1335 avg loss: 0.00520 avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.00622 avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.00596 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00598 	 Best epoch 1325
EarlyStopping counter: 2 out of 50
train epoch 1336 avg loss: 0.00511 avg lploss: 0.00000
train epoch 1337 avg loss: 0.00506 avg lploss: 0.00000
train epoch 1338 avg loss: 0.00514 avg lploss: 0.00000
train epoch 1339 avg loss: 0.00542 avg lploss: 0.00000
train epoch 1340 avg loss: 0.00520 avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.00623 avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.00595 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00598 	 Best epoch 1325
EarlyStopping counter: 3 out of 50
train epoch 1341 avg loss: 0.00518 avg lploss: 0.00000
train epoch 1342 avg loss: 0.00503 avg lploss: 0.00000
train epoch 1343 avg loss: 0.00504 avg lploss: 0.00000
train epoch 1344 avg loss: 0.00510 avg lploss: 0.00000
train epoch 1345 avg loss: 0.00518 avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.00629 avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.00601 avg lploss: 0.00000
*** Best Val Loss: 0.00619 	 Best Test Loss: 0.00598 	 Best epoch 1325
EarlyStopping counter: 4 out of 50
train epoch 1346 avg loss: 0.00521 avg lploss: 0.00000
train epoch 1347 avg loss: 0.00510 avg lploss: 0.00000
train epoch 1348 avg loss: 0.00503 avg lploss: 0.00000
train epoch 1349 avg loss: 0.00502 avg lploss: 0.00000
train epoch 1350 avg loss: 0.00504 avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.00616 avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.00592 avg lploss: 0.00000
*** Best Val Loss: 0.00616 	 Best Test Loss: 0.00592 	 Best epoch 1350
Validation loss decreased (0.006189 --> 0.006161).  Saving model ...
train epoch 1351 avg loss: 0.00505 avg lploss: 0.00000
train epoch 1352 avg loss: 0.00506 avg lploss: 0.00000
train epoch 1353 avg loss: 0.00505 avg lploss: 0.00000
train epoch 1354 avg loss: 0.00507 avg lploss: 0.00000
train epoch 1355 avg loss: 0.00510 avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.00630 avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.00601 avg lploss: 0.00000
*** Best Val Loss: 0.00616 	 Best Test Loss: 0.00592 	 Best epoch 1350
EarlyStopping counter: 1 out of 50
train epoch 1356 avg loss: 0.00509 avg lploss: 0.00000
train epoch 1357 avg loss: 0.00517 avg lploss: 0.00000
train epoch 1358 avg loss: 0.00512 avg lploss: 0.00000
train epoch 1359 avg loss: 0.00497 avg lploss: 0.00000
train epoch 1360 avg loss: 0.00500 avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.00649 avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.00627 avg lploss: 0.00000
*** Best Val Loss: 0.00616 	 Best Test Loss: 0.00592 	 Best epoch 1350
EarlyStopping counter: 2 out of 50
train epoch 1361 avg loss: 0.00509 avg lploss: 0.00000
train epoch 1362 avg loss: 0.00508 avg lploss: 0.00000
train epoch 1363 avg loss: 0.00509 avg lploss: 0.00000
train epoch 1364 avg loss: 0.00523 avg lploss: 0.00000
train epoch 1365 avg loss: 0.00509 avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.00624 avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.00595 avg lploss: 0.00000
*** Best Val Loss: 0.00616 	 Best Test Loss: 0.00592 	 Best epoch 1350
EarlyStopping counter: 3 out of 50
train epoch 1366 avg loss: 0.00508 avg lploss: 0.00000
train epoch 1367 avg loss: 0.00499 avg lploss: 0.00000
train epoch 1368 avg loss: 0.00496 avg lploss: 0.00000
train epoch 1369 avg loss: 0.00494 avg lploss: 0.00000
train epoch 1370 avg loss: 0.00517 avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.00614 avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.00583 avg lploss: 0.00000
*** Best Val Loss: 0.00614 	 Best Test Loss: 0.00583 	 Best epoch 1370
Validation loss decreased (0.006161 --> 0.006137).  Saving model ...
train epoch 1371 avg loss: 0.00523 avg lploss: 0.00000
train epoch 1372 avg loss: 0.00511 avg lploss: 0.00000
train epoch 1373 avg loss: 0.00498 avg lploss: 0.00000
train epoch 1374 avg loss: 0.00496 avg lploss: 0.00000
train epoch 1375 avg loss: 0.00500 avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.00617 avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.00593 avg lploss: 0.00000
*** Best Val Loss: 0.00614 	 Best Test Loss: 0.00583 	 Best epoch 1370
EarlyStopping counter: 1 out of 50
train epoch 1376 avg loss: 0.00499 avg lploss: 0.00000
train epoch 1377 avg loss: 0.00496 avg lploss: 0.00000
train epoch 1378 avg loss: 0.00498 avg lploss: 0.00000
train epoch 1379 avg loss: 0.00491 avg lploss: 0.00000
train epoch 1380 avg loss: 0.00503 avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.00620 avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.00592 avg lploss: 0.00000
*** Best Val Loss: 0.00614 	 Best Test Loss: 0.00583 	 Best epoch 1370
EarlyStopping counter: 2 out of 50
train epoch 1381 avg loss: 0.00500 avg lploss: 0.00000
train epoch 1382 avg loss: 0.00506 avg lploss: 0.00000
train epoch 1383 avg loss: 0.00497 avg lploss: 0.00000
train epoch 1384 avg loss: 0.00515 avg lploss: 0.00000
train epoch 1385 avg loss: 0.00503 avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.00603 avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.00577 avg lploss: 0.00000
*** Best Val Loss: 0.00603 	 Best Test Loss: 0.00577 	 Best epoch 1385
Validation loss decreased (0.006137 --> 0.006029).  Saving model ...
train epoch 1386 avg loss: 0.00494 avg lploss: 0.00000
train epoch 1387 avg loss: 0.00494 avg lploss: 0.00000
train epoch 1388 avg loss: 0.00491 avg lploss: 0.00000
train epoch 1389 avg loss: 0.00488 avg lploss: 0.00000
train epoch 1390 avg loss: 0.00495 avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.00631 avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.00619 avg lploss: 0.00000
*** Best Val Loss: 0.00603 	 Best Test Loss: 0.00577 	 Best epoch 1385
EarlyStopping counter: 1 out of 50
train epoch 1391 avg loss: 0.00510 avg lploss: 0.00000
train epoch 1392 avg loss: 0.00488 avg lploss: 0.00000
train epoch 1393 avg loss: 0.00493 avg lploss: 0.00000
train epoch 1394 avg loss: 0.00483 avg lploss: 0.00000
train epoch 1395 avg loss: 0.00493 avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.00632 avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.00599 avg lploss: 0.00000
*** Best Val Loss: 0.00603 	 Best Test Loss: 0.00577 	 Best epoch 1385
EarlyStopping counter: 2 out of 50
train epoch 1396 avg loss: 0.00493 avg lploss: 0.00000
train epoch 1397 avg loss: 0.00494 avg lploss: 0.00000
train epoch 1398 avg loss: 0.00488 avg lploss: 0.00000
train epoch 1399 avg loss: 0.00487 avg lploss: 0.00000
train epoch 1400 avg loss: 0.00489 avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.00625 avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.00593 avg lploss: 0.00000
*** Best Val Loss: 0.00603 	 Best Test Loss: 0.00577 	 Best epoch 1385
EarlyStopping counter: 3 out of 50
train epoch 1401 avg loss: 0.00499 avg lploss: 0.00000
train epoch 1402 avg loss: 0.00482 avg lploss: 0.00000
train epoch 1403 avg loss: 0.00482 avg lploss: 0.00000
train epoch 1404 avg loss: 0.00494 avg lploss: 0.00000
train epoch 1405 avg loss: 0.00491 avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.00615 avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.00588 avg lploss: 0.00000
*** Best Val Loss: 0.00603 	 Best Test Loss: 0.00577 	 Best epoch 1385
EarlyStopping counter: 4 out of 50
train epoch 1406 avg loss: 0.00482 avg lploss: 0.00000
train epoch 1407 avg loss: 0.00481 avg lploss: 0.00000
train epoch 1408 avg loss: 0.00490 avg lploss: 0.00000
train epoch 1409 avg loss: 0.00490 avg lploss: 0.00000
train epoch 1410 avg loss: 0.00485 avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.00607 avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.00581 avg lploss: 0.00000
*** Best Val Loss: 0.00603 	 Best Test Loss: 0.00577 	 Best epoch 1385
EarlyStopping counter: 5 out of 50
train epoch 1411 avg loss: 0.00480 avg lploss: 0.00000
train epoch 1412 avg loss: 0.00494 avg lploss: 0.00000
train epoch 1413 avg loss: 0.00496 avg lploss: 0.00000
train epoch 1414 avg loss: 0.00485 avg lploss: 0.00000
train epoch 1415 avg loss: 0.00495 avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.00599 avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.00579 avg lploss: 0.00000
*** Best Val Loss: 0.00599 	 Best Test Loss: 0.00579 	 Best epoch 1415
Validation loss decreased (0.006029 --> 0.005989).  Saving model ...
train epoch 1416 avg loss: 0.00492 avg lploss: 0.00000
train epoch 1417 avg loss: 0.00496 avg lploss: 0.00000
train epoch 1418 avg loss: 0.00490 avg lploss: 0.00000
train epoch 1419 avg loss: 0.00483 avg lploss: 0.00000
train epoch 1420 avg loss: 0.00483 avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.00612 avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.00595 avg lploss: 0.00000
*** Best Val Loss: 0.00599 	 Best Test Loss: 0.00579 	 Best epoch 1415
EarlyStopping counter: 1 out of 50
train epoch 1421 avg loss: 0.00481 avg lploss: 0.00000
train epoch 1422 avg loss: 0.00488 avg lploss: 0.00000
train epoch 1423 avg loss: 0.00482 avg lploss: 0.00000
train epoch 1424 avg loss: 0.00479 avg lploss: 0.00000
train epoch 1425 avg loss: 0.00489 avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.00607 avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.00578 avg lploss: 0.00000
*** Best Val Loss: 0.00599 	 Best Test Loss: 0.00579 	 Best epoch 1415
EarlyStopping counter: 2 out of 50
train epoch 1426 avg loss: 0.00475 avg lploss: 0.00000
train epoch 1427 avg loss: 0.00473 avg lploss: 0.00000
train epoch 1428 avg loss: 0.00471 avg lploss: 0.00000
train epoch 1429 avg loss: 0.00466 avg lploss: 0.00000
train epoch 1430 avg loss: 0.00471 avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.00606 avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.00573 avg lploss: 0.00000
*** Best Val Loss: 0.00599 	 Best Test Loss: 0.00579 	 Best epoch 1415
EarlyStopping counter: 3 out of 50
train epoch 1431 avg loss: 0.00468 avg lploss: 0.00000
train epoch 1432 avg loss: 0.00472 avg lploss: 0.00000
train epoch 1433 avg loss: 0.00477 avg lploss: 0.00000
train epoch 1434 avg loss: 0.00490 avg lploss: 0.00000
train epoch 1435 avg loss: 0.00475 avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.00599 avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.00570 avg lploss: 0.00000
*** Best Val Loss: 0.00599 	 Best Test Loss: 0.00579 	 Best epoch 1415
EarlyStopping counter: 4 out of 50
train epoch 1436 avg loss: 0.00478 avg lploss: 0.00000
train epoch 1437 avg loss: 0.00474 avg lploss: 0.00000
train epoch 1438 avg loss: 0.00467 avg lploss: 0.00000
train epoch 1439 avg loss: 0.00461 avg lploss: 0.00000
train epoch 1440 avg loss: 0.00474 avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.00597 avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.00568 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
Validation loss decreased (0.005989 --> 0.005972).  Saving model ...
train epoch 1441 avg loss: 0.00472 avg lploss: 0.00000
train epoch 1442 avg loss: 0.00464 avg lploss: 0.00000
train epoch 1443 avg loss: 0.00466 avg lploss: 0.00000
train epoch 1444 avg loss: 0.00469 avg lploss: 0.00000
train epoch 1445 avg loss: 0.00480 avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.00617 avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.00587 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 1 out of 50
train epoch 1446 avg loss: 0.00477 avg lploss: 0.00000
train epoch 1447 avg loss: 0.00482 avg lploss: 0.00000
train epoch 1448 avg loss: 0.00488 avg lploss: 0.00000
train epoch 1449 avg loss: 0.00472 avg lploss: 0.00000
train epoch 1450 avg loss: 0.00463 avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.00599 avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.00567 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 2 out of 50
train epoch 1451 avg loss: 0.00470 avg lploss: 0.00000
train epoch 1452 avg loss: 0.00469 avg lploss: 0.00000
train epoch 1453 avg loss: 0.00466 avg lploss: 0.00000
train epoch 1454 avg loss: 0.00469 avg lploss: 0.00000
train epoch 1455 avg loss: 0.00480 avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.00600 avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.00574 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 3 out of 50
train epoch 1456 avg loss: 0.00456 avg lploss: 0.00000
train epoch 1457 avg loss: 0.00465 avg lploss: 0.00000
train epoch 1458 avg loss: 0.00481 avg lploss: 0.00000
train epoch 1459 avg loss: 0.00464 avg lploss: 0.00000
train epoch 1460 avg loss: 0.00459 avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.00605 avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.00576 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 4 out of 50
train epoch 1461 avg loss: 0.00480 avg lploss: 0.00000
train epoch 1462 avg loss: 0.00468 avg lploss: 0.00000
train epoch 1463 avg loss: 0.00470 avg lploss: 0.00000
train epoch 1464 avg loss: 0.00466 avg lploss: 0.00000
train epoch 1465 avg loss: 0.00459 avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.00620 avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.00597 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 5 out of 50
train epoch 1466 avg loss: 0.00461 avg lploss: 0.00000
train epoch 1467 avg loss: 0.00460 avg lploss: 0.00000
train epoch 1468 avg loss: 0.00458 avg lploss: 0.00000
train epoch 1469 avg loss: 0.00456 avg lploss: 0.00000
train epoch 1470 avg loss: 0.00457 avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.00604 avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.00574 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 6 out of 50
train epoch 1471 avg loss: 0.00465 avg lploss: 0.00000
train epoch 1472 avg loss: 0.00461 avg lploss: 0.00000
train epoch 1473 avg loss: 0.00455 avg lploss: 0.00000
train epoch 1474 avg loss: 0.00465 avg lploss: 0.00000
train epoch 1475 avg loss: 0.00467 avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.00600 avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.00573 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 7 out of 50
train epoch 1476 avg loss: 0.00459 avg lploss: 0.00000
train epoch 1477 avg loss: 0.00457 avg lploss: 0.00000
train epoch 1478 avg loss: 0.00458 avg lploss: 0.00000
train epoch 1479 avg loss: 0.00470 avg lploss: 0.00000
train epoch 1480 avg loss: 0.00461 avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.00600 avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.00575 avg lploss: 0.00000
*** Best Val Loss: 0.00597 	 Best Test Loss: 0.00568 	 Best epoch 1440
EarlyStopping counter: 8 out of 50
train epoch 1481 avg loss: 0.00453 avg lploss: 0.00000
train epoch 1482 avg loss: 0.00448 avg lploss: 0.00000
train epoch 1483 avg loss: 0.00450 avg lploss: 0.00000
train epoch 1484 avg loss: 0.00464 avg lploss: 0.00000
train epoch 1485 avg loss: 0.00445 avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.00591 avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.00562 avg lploss: 0.00000
*** Best Val Loss: 0.00591 	 Best Test Loss: 0.00562 	 Best epoch 1485
Validation loss decreased (0.005972 --> 0.005913).  Saving model ...
train epoch 1486 avg loss: 0.00449 avg lploss: 0.00000
train epoch 1487 avg loss: 0.00453 avg lploss: 0.00000
train epoch 1488 avg loss: 0.00454 avg lploss: 0.00000
train epoch 1489 avg loss: 0.00445 avg lploss: 0.00000
train epoch 1490 avg loss: 0.00453 avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.00600 avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.00573 avg lploss: 0.00000
*** Best Val Loss: 0.00591 	 Best Test Loss: 0.00562 	 Best epoch 1485
EarlyStopping counter: 1 out of 50
train epoch 1491 avg loss: 0.00447 avg lploss: 0.00000
train epoch 1492 avg loss: 0.00471 avg lploss: 0.00000
train epoch 1493 avg loss: 0.00460 avg lploss: 0.00000
train epoch 1494 avg loss: 0.00457 avg lploss: 0.00000
train epoch 1495 avg loss: 0.00462 avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.00625 avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.00595 avg lploss: 0.00000
*** Best Val Loss: 0.00591 	 Best Test Loss: 0.00562 	 Best epoch 1485
EarlyStopping counter: 2 out of 50
train epoch 1496 avg loss: 0.00451 avg lploss: 0.00000
train epoch 1497 avg loss: 0.00455 avg lploss: 0.00000
train epoch 1498 avg loss: 0.00451 avg lploss: 0.00000
train epoch 1499 avg loss: 0.00451 avg lploss: 0.00000
train epoch 1500 avg loss: 0.00442 avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.00591 avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.00562 avg lploss: 0.00000
*** Best Val Loss: 0.00591 	 Best Test Loss: 0.00562 	 Best epoch 1485
EarlyStopping counter: 3 out of 50
train epoch 1501 avg loss: 0.00453 avg lploss: 0.00000
train epoch 1502 avg loss: 0.00448 avg lploss: 0.00000
train epoch 1503 avg loss: 0.00447 avg lploss: 0.00000
train epoch 1504 avg loss: 0.00440 avg lploss: 0.00000
train epoch 1505 avg loss: 0.00437 avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.00595 avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.00564 avg lploss: 0.00000
*** Best Val Loss: 0.00591 	 Best Test Loss: 0.00562 	 Best epoch 1485
EarlyStopping counter: 4 out of 50
train epoch 1506 avg loss: 0.00448 avg lploss: 0.00000
train epoch 1507 avg loss: 0.00447 avg lploss: 0.00000
train epoch 1508 avg loss: 0.00444 avg lploss: 0.00000
train epoch 1509 avg loss: 0.00443 avg lploss: 0.00000
train epoch 1510 avg loss: 0.00450 avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.00627 avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.00601 avg lploss: 0.00000
*** Best Val Loss: 0.00591 	 Best Test Loss: 0.00562 	 Best epoch 1485
EarlyStopping counter: 5 out of 50
train epoch 1511 avg loss: 0.00446 avg lploss: 0.00000
train epoch 1512 avg loss: 0.00440 avg lploss: 0.00000
train epoch 1513 avg loss: 0.00441 avg lploss: 0.00000
train epoch 1514 avg loss: 0.00450 avg lploss: 0.00000
train epoch 1515 avg loss: 0.00440 avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.00589 avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.00555 avg lploss: 0.00000
*** Best Val Loss: 0.00589 	 Best Test Loss: 0.00555 	 Best epoch 1515
Validation loss decreased (0.005913 --> 0.005893).  Saving model ...
train epoch 1516 avg loss: 0.00450 avg lploss: 0.00000
train epoch 1517 avg loss: 0.00434 avg lploss: 0.00000
train epoch 1518 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1519 avg loss: 0.00435 avg lploss: 0.00000
train epoch 1520 avg loss: 0.00444 avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.00588 avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.00551 avg lploss: 0.00000
*** Best Val Loss: 0.00588 	 Best Test Loss: 0.00551 	 Best epoch 1520
Validation loss decreased (0.005893 --> 0.005878).  Saving model ...
train epoch 1521 avg loss: 0.00451 avg lploss: 0.00000
train epoch 1522 avg loss: 0.00443 avg lploss: 0.00000
train epoch 1523 avg loss: 0.00438 avg lploss: 0.00000
train epoch 1524 avg loss: 0.00435 avg lploss: 0.00000
train epoch 1525 avg loss: 0.00435 avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.00594 avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.00563 avg lploss: 0.00000
*** Best Val Loss: 0.00588 	 Best Test Loss: 0.00551 	 Best epoch 1520
EarlyStopping counter: 1 out of 50
train epoch 1526 avg loss: 0.00438 avg lploss: 0.00000
train epoch 1527 avg loss: 0.00447 avg lploss: 0.00000
train epoch 1528 avg loss: 0.00434 avg lploss: 0.00000
train epoch 1529 avg loss: 0.00434 avg lploss: 0.00000
train epoch 1530 avg loss: 0.00447 avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.00593 avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.00564 avg lploss: 0.00000
*** Best Val Loss: 0.00588 	 Best Test Loss: 0.00551 	 Best epoch 1520
EarlyStopping counter: 2 out of 50
train epoch 1531 avg loss: 0.00433 avg lploss: 0.00000
train epoch 1532 avg loss: 0.00431 avg lploss: 0.00000
train epoch 1533 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1534 avg loss: 0.00433 avg lploss: 0.00000
train epoch 1535 avg loss: 0.00435 avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.00593 avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00588 	 Best Test Loss: 0.00551 	 Best epoch 1520
EarlyStopping counter: 3 out of 50
train epoch 1536 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1537 avg loss: 0.00428 avg lploss: 0.00000
train epoch 1538 avg loss: 0.00429 avg lploss: 0.00000
train epoch 1539 avg loss: 0.00433 avg lploss: 0.00000
train epoch 1540 avg loss: 0.00446 avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.00598 avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.00566 avg lploss: 0.00000
*** Best Val Loss: 0.00588 	 Best Test Loss: 0.00551 	 Best epoch 1520
EarlyStopping counter: 4 out of 50
train epoch 1541 avg loss: 0.00434 avg lploss: 0.00000
train epoch 1542 avg loss: 0.00436 avg lploss: 0.00000
train epoch 1543 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1544 avg loss: 0.00436 avg lploss: 0.00000
train epoch 1545 avg loss: 0.00435 avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.00590 avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.00554 avg lploss: 0.00000
*** Best Val Loss: 0.00588 	 Best Test Loss: 0.00551 	 Best epoch 1520
EarlyStopping counter: 5 out of 50
train epoch 1546 avg loss: 0.00424 avg lploss: 0.00000
train epoch 1547 avg loss: 0.00434 avg lploss: 0.00000
train epoch 1548 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1549 avg loss: 0.00465 avg lploss: 0.00000
train epoch 1550 avg loss: 0.00439 avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.00583 avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.00555 avg lploss: 0.00000
*** Best Val Loss: 0.00583 	 Best Test Loss: 0.00555 	 Best epoch 1550
Validation loss decreased (0.005878 --> 0.005826).  Saving model ...
train epoch 1551 avg loss: 0.00425 avg lploss: 0.00000
train epoch 1552 avg loss: 0.00429 avg lploss: 0.00000
train epoch 1553 avg loss: 0.00433 avg lploss: 0.00000
train epoch 1554 avg loss: 0.00423 avg lploss: 0.00000
train epoch 1555 avg loss: 0.00428 avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.00588 avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.00555 avg lploss: 0.00000
*** Best Val Loss: 0.00583 	 Best Test Loss: 0.00555 	 Best epoch 1550
EarlyStopping counter: 1 out of 50
train epoch 1556 avg loss: 0.00440 avg lploss: 0.00000
train epoch 1557 avg loss: 0.00427 avg lploss: 0.00000
train epoch 1558 avg loss: 0.00431 avg lploss: 0.00000
train epoch 1559 avg loss: 0.00421 avg lploss: 0.00000
train epoch 1560 avg loss: 0.00425 avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.00581 avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.00541 avg lploss: 0.00000
*** Best Val Loss: 0.00581 	 Best Test Loss: 0.00541 	 Best epoch 1560
Validation loss decreased (0.005826 --> 0.005814).  Saving model ...
train epoch 1561 avg loss: 0.00421 avg lploss: 0.00000
train epoch 1562 avg loss: 0.00427 avg lploss: 0.00000
train epoch 1563 avg loss: 0.00415 avg lploss: 0.00000
train epoch 1564 avg loss: 0.00416 avg lploss: 0.00000
train epoch 1565 avg loss: 0.00418 avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.00578 avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.00547 avg lploss: 0.00000
*** Best Val Loss: 0.00578 	 Best Test Loss: 0.00547 	 Best epoch 1565
Validation loss decreased (0.005814 --> 0.005784).  Saving model ...
train epoch 1566 avg loss: 0.00439 avg lploss: 0.00000
train epoch 1567 avg loss: 0.00425 avg lploss: 0.00000
train epoch 1568 avg loss: 0.00427 avg lploss: 0.00000
train epoch 1569 avg loss: 0.00442 avg lploss: 0.00000
train epoch 1570 avg loss: 0.00428 avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.00597 avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.00567 avg lploss: 0.00000
*** Best Val Loss: 0.00578 	 Best Test Loss: 0.00547 	 Best epoch 1565
EarlyStopping counter: 1 out of 50
train epoch 1571 avg loss: 0.00416 avg lploss: 0.00000
train epoch 1572 avg loss: 0.00415 avg lploss: 0.00000
train epoch 1573 avg loss: 0.00415 avg lploss: 0.00000
train epoch 1574 avg loss: 0.00411 avg lploss: 0.00000
train epoch 1575 avg loss: 0.00419 avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.00596 avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.00563 avg lploss: 0.00000
*** Best Val Loss: 0.00578 	 Best Test Loss: 0.00547 	 Best epoch 1565
EarlyStopping counter: 2 out of 50
train epoch 1576 avg loss: 0.00426 avg lploss: 0.00000
train epoch 1577 avg loss: 0.00439 avg lploss: 0.00000
train epoch 1578 avg loss: 0.00418 avg lploss: 0.00000
train epoch 1579 avg loss: 0.00415 avg lploss: 0.00000
train epoch 1580 avg loss: 0.00417 avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.00593 avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.00564 avg lploss: 0.00000
*** Best Val Loss: 0.00578 	 Best Test Loss: 0.00547 	 Best epoch 1565
EarlyStopping counter: 3 out of 50
train epoch 1581 avg loss: 0.00412 avg lploss: 0.00000
train epoch 1582 avg loss: 0.00418 avg lploss: 0.00000
train epoch 1583 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1584 avg loss: 0.00415 avg lploss: 0.00000
train epoch 1585 avg loss: 0.00414 avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.00585 avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00578 	 Best Test Loss: 0.00547 	 Best epoch 1565
EarlyStopping counter: 4 out of 50
train epoch 1586 avg loss: 0.00420 avg lploss: 0.00000
train epoch 1587 avg loss: 0.00420 avg lploss: 0.00000
train epoch 1588 avg loss: 0.00420 avg lploss: 0.00000
train epoch 1589 avg loss: 0.00418 avg lploss: 0.00000
train epoch 1590 avg loss: 0.00407 avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.00574 avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.00535 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
Validation loss decreased (0.005784 --> 0.005742).  Saving model ...
train epoch 1591 avg loss: 0.00406 avg lploss: 0.00000
train epoch 1592 avg loss: 0.00404 avg lploss: 0.00000
train epoch 1593 avg loss: 0.00414 avg lploss: 0.00000
train epoch 1594 avg loss: 0.00428 avg lploss: 0.00000
train epoch 1595 avg loss: 0.00408 avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.00588 avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
EarlyStopping counter: 1 out of 50
train epoch 1596 avg loss: 0.00424 avg lploss: 0.00000
train epoch 1597 avg loss: 0.00401 avg lploss: 0.00000
train epoch 1598 avg loss: 0.00401 avg lploss: 0.00000
train epoch 1599 avg loss: 0.00410 avg lploss: 0.00000
train epoch 1600 avg loss: 0.00407 avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.00578 avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.00544 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
EarlyStopping counter: 2 out of 50
train epoch 1601 avg loss: 0.00408 avg lploss: 0.00000
train epoch 1602 avg loss: 0.00402 avg lploss: 0.00000
train epoch 1603 avg loss: 0.00408 avg lploss: 0.00000
train epoch 1604 avg loss: 0.00413 avg lploss: 0.00000
train epoch 1605 avg loss: 0.00402 avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.00576 avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.00556 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
EarlyStopping counter: 3 out of 50
train epoch 1606 avg loss: 0.00406 avg lploss: 0.00000
train epoch 1607 avg loss: 0.00404 avg lploss: 0.00000
train epoch 1608 avg loss: 0.00412 avg lploss: 0.00000
train epoch 1609 avg loss: 0.00399 avg lploss: 0.00000
train epoch 1610 avg loss: 0.00404 avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.00575 avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.00544 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
EarlyStopping counter: 4 out of 50
train epoch 1611 avg loss: 0.00397 avg lploss: 0.00000
train epoch 1612 avg loss: 0.00404 avg lploss: 0.00000
train epoch 1613 avg loss: 0.00398 avg lploss: 0.00000
train epoch 1614 avg loss: 0.00403 avg lploss: 0.00000
train epoch 1615 avg loss: 0.00404 avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.00588 avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.00559 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
EarlyStopping counter: 5 out of 50
train epoch 1616 avg loss: 0.00404 avg lploss: 0.00000
train epoch 1617 avg loss: 0.00417 avg lploss: 0.00000
train epoch 1618 avg loss: 0.00401 avg lploss: 0.00000
train epoch 1619 avg loss: 0.00399 avg lploss: 0.00000
train epoch 1620 avg loss: 0.00404 avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.00591 avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.00556 avg lploss: 0.00000
*** Best Val Loss: 0.00574 	 Best Test Loss: 0.00535 	 Best epoch 1590
EarlyStopping counter: 6 out of 50
train epoch 1621 avg loss: 0.00401 avg lploss: 0.00000
train epoch 1622 avg loss: 0.00392 avg lploss: 0.00000
train epoch 1623 avg loss: 0.00396 avg lploss: 0.00000
train epoch 1624 avg loss: 0.00437 avg lploss: 0.00000
train epoch 1625 avg loss: 0.00426 avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.00572 avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.00539 avg lploss: 0.00000
*** Best Val Loss: 0.00572 	 Best Test Loss: 0.00539 	 Best epoch 1625
Validation loss decreased (0.005742 --> 0.005719).  Saving model ...
train epoch 1626 avg loss: 0.00390 avg lploss: 0.00000
train epoch 1627 avg loss: 0.00391 avg lploss: 0.00000
train epoch 1628 avg loss: 0.00407 avg lploss: 0.00000
train epoch 1629 avg loss: 0.00402 avg lploss: 0.00000
train epoch 1630 avg loss: 0.00394 avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.00578 avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.00543 avg lploss: 0.00000
*** Best Val Loss: 0.00572 	 Best Test Loss: 0.00539 	 Best epoch 1625
EarlyStopping counter: 1 out of 50
train epoch 1631 avg loss: 0.00392 avg lploss: 0.00000
train epoch 1632 avg loss: 0.00395 avg lploss: 0.00000
train epoch 1633 avg loss: 0.00385 avg lploss: 0.00000
train epoch 1634 avg loss: 0.00395 avg lploss: 0.00000
train epoch 1635 avg loss: 0.00397 avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.00584 avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00572 	 Best Test Loss: 0.00539 	 Best epoch 1625
EarlyStopping counter: 2 out of 50
train epoch 1636 avg loss: 0.00396 avg lploss: 0.00000
train epoch 1637 avg loss: 0.00411 avg lploss: 0.00000
train epoch 1638 avg loss: 0.00388 avg lploss: 0.00000
train epoch 1639 avg loss: 0.00395 avg lploss: 0.00000
train epoch 1640 avg loss: 0.00393 avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.00583 avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.00548 avg lploss: 0.00000
*** Best Val Loss: 0.00572 	 Best Test Loss: 0.00539 	 Best epoch 1625
EarlyStopping counter: 3 out of 50
train epoch 1641 avg loss: 0.00395 avg lploss: 0.00000
train epoch 1642 avg loss: 0.00397 avg lploss: 0.00000
train epoch 1643 avg loss: 0.00397 avg lploss: 0.00000
train epoch 1644 avg loss: 0.00395 avg lploss: 0.00000
train epoch 1645 avg loss: 0.00381 avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.00578 avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.00541 avg lploss: 0.00000
*** Best Val Loss: 0.00572 	 Best Test Loss: 0.00539 	 Best epoch 1625
EarlyStopping counter: 4 out of 50
train epoch 1646 avg loss: 0.00386 avg lploss: 0.00000
train epoch 1647 avg loss: 0.00382 avg lploss: 0.00000
train epoch 1648 avg loss: 0.00396 avg lploss: 0.00000
train epoch 1649 avg loss: 0.00380 avg lploss: 0.00000
train epoch 1650 avg loss: 0.00392 avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.00571 avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.00541 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
Validation loss decreased (0.005719 --> 0.005709).  Saving model ...
train epoch 1651 avg loss: 0.00385 avg lploss: 0.00000
train epoch 1652 avg loss: 0.00386 avg lploss: 0.00000
train epoch 1653 avg loss: 0.00389 avg lploss: 0.00000
train epoch 1654 avg loss: 0.00386 avg lploss: 0.00000
train epoch 1655 avg loss: 0.00391 avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.00587 avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.00560 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
EarlyStopping counter: 1 out of 50
train epoch 1656 avg loss: 0.00389 avg lploss: 0.00000
train epoch 1657 avg loss: 0.00384 avg lploss: 0.00000
train epoch 1658 avg loss: 0.00390 avg lploss: 0.00000
train epoch 1659 avg loss: 0.00390 avg lploss: 0.00000
train epoch 1660 avg loss: 0.00384 avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.00574 avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.00542 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
EarlyStopping counter: 2 out of 50
train epoch 1661 avg loss: 0.00381 avg lploss: 0.00000
train epoch 1662 avg loss: 0.00398 avg lploss: 0.00000
train epoch 1663 avg loss: 0.00380 avg lploss: 0.00000
train epoch 1664 avg loss: 0.00391 avg lploss: 0.00000
train epoch 1665 avg loss: 0.00374 avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.00581 avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.00541 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
EarlyStopping counter: 3 out of 50
train epoch 1666 avg loss: 0.00387 avg lploss: 0.00000
train epoch 1667 avg loss: 0.00385 avg lploss: 0.00000
train epoch 1668 avg loss: 0.00371 avg lploss: 0.00000
train epoch 1669 avg loss: 0.00381 avg lploss: 0.00000
train epoch 1670 avg loss: 0.00377 avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.00580 avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.00547 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
EarlyStopping counter: 4 out of 50
train epoch 1671 avg loss: 0.00374 avg lploss: 0.00000
train epoch 1672 avg loss: 0.00388 avg lploss: 0.00000
train epoch 1673 avg loss: 0.00381 avg lploss: 0.00000
train epoch 1674 avg loss: 0.00405 avg lploss: 0.00000
train epoch 1675 avg loss: 0.00391 avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.00593 avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.00555 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
EarlyStopping counter: 5 out of 50
train epoch 1676 avg loss: 0.00386 avg lploss: 0.00000
train epoch 1677 avg loss: 0.00378 avg lploss: 0.00000
train epoch 1678 avg loss: 0.00376 avg lploss: 0.00000
train epoch 1679 avg loss: 0.00373 avg lploss: 0.00000
train epoch 1680 avg loss: 0.00373 avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.00586 avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.00549 avg lploss: 0.00000
*** Best Val Loss: 0.00571 	 Best Test Loss: 0.00541 	 Best epoch 1650
EarlyStopping counter: 6 out of 50
train epoch 1681 avg loss: 0.00375 avg lploss: 0.00000
train epoch 1682 avg loss: 0.00374 avg lploss: 0.00000
train epoch 1683 avg loss: 0.00376 avg lploss: 0.00000
train epoch 1684 avg loss: 0.00374 avg lploss: 0.00000
train epoch 1685 avg loss: 0.00377 avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.00566 avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.00531 avg lploss: 0.00000
*** Best Val Loss: 0.00566 	 Best Test Loss: 0.00531 	 Best epoch 1685
Validation loss decreased (0.005709 --> 0.005660).  Saving model ...
train epoch 1686 avg loss: 0.00375 avg lploss: 0.00000
train epoch 1687 avg loss: 0.00379 avg lploss: 0.00000
train epoch 1688 avg loss: 0.00371 avg lploss: 0.00000
train epoch 1689 avg loss: 0.00369 avg lploss: 0.00000
train epoch 1690 avg loss: 0.00372 avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.00570 avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.00538 avg lploss: 0.00000
*** Best Val Loss: 0.00566 	 Best Test Loss: 0.00531 	 Best epoch 1685
EarlyStopping counter: 1 out of 50
train epoch 1691 avg loss: 0.00374 avg lploss: 0.00000
train epoch 1692 avg loss: 0.00390 avg lploss: 0.00000
train epoch 1693 avg loss: 0.00372 avg lploss: 0.00000
train epoch 1694 avg loss: 0.00366 avg lploss: 0.00000
train epoch 1695 avg loss: 0.00379 avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.00584 avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.00546 avg lploss: 0.00000
*** Best Val Loss: 0.00566 	 Best Test Loss: 0.00531 	 Best epoch 1685
EarlyStopping counter: 2 out of 50
train epoch 1696 avg loss: 0.00378 avg lploss: 0.00000
train epoch 1697 avg loss: 0.00372 avg lploss: 0.00000
train epoch 1698 avg loss: 0.00369 avg lploss: 0.00000
train epoch 1699 avg loss: 0.00379 avg lploss: 0.00000
train epoch 1700 avg loss: 0.00379 avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.00574 avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.00545 avg lploss: 0.00000
*** Best Val Loss: 0.00566 	 Best Test Loss: 0.00531 	 Best epoch 1685
EarlyStopping counter: 3 out of 50
train epoch 1701 avg loss: 0.00365 avg lploss: 0.00000
train epoch 1702 avg loss: 0.00373 avg lploss: 0.00000
train epoch 1703 avg loss: 0.00388 avg lploss: 0.00000
train epoch 1704 avg loss: 0.00367 avg lploss: 0.00000
train epoch 1705 avg loss: 0.00371 avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.00569 avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.00540 avg lploss: 0.00000
*** Best Val Loss: 0.00566 	 Best Test Loss: 0.00531 	 Best epoch 1685
EarlyStopping counter: 4 out of 50
train epoch 1706 avg loss: 0.00361 avg lploss: 0.00000
train epoch 1707 avg loss: 0.00358 avg lploss: 0.00000
train epoch 1708 avg loss: 0.00368 avg lploss: 0.00000
train epoch 1709 avg loss: 0.00376 avg lploss: 0.00000
train epoch 1710 avg loss: 0.00370 avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.00562 avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.00537 avg lploss: 0.00000
*** Best Val Loss: 0.00562 	 Best Test Loss: 0.00537 	 Best epoch 1710
Validation loss decreased (0.005660 --> 0.005620).  Saving model ...
train epoch 1711 avg loss: 0.00369 avg lploss: 0.00000
train epoch 1712 avg loss: 0.00367 avg lploss: 0.00000
train epoch 1713 avg loss: 0.00369 avg lploss: 0.00000
train epoch 1714 avg loss: 0.00390 avg lploss: 0.00000
train epoch 1715 avg loss: 0.00379 avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.00582 avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.00552 avg lploss: 0.00000
*** Best Val Loss: 0.00562 	 Best Test Loss: 0.00537 	 Best epoch 1710
EarlyStopping counter: 1 out of 50
train epoch 1716 avg loss: 0.00385 avg lploss: 0.00000
train epoch 1717 avg loss: 0.00371 avg lploss: 0.00000
train epoch 1718 avg loss: 0.00368 avg lploss: 0.00000
train epoch 1719 avg loss: 0.00369 avg lploss: 0.00000
train epoch 1720 avg loss: 0.00369 avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.00600 avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.00556 avg lploss: 0.00000
*** Best Val Loss: 0.00562 	 Best Test Loss: 0.00537 	 Best epoch 1710
EarlyStopping counter: 2 out of 50
train epoch 1721 avg loss: 0.00374 avg lploss: 0.00000
train epoch 1722 avg loss: 0.00371 avg lploss: 0.00000
train epoch 1723 avg loss: 0.00361 avg lploss: 0.00000
train epoch 1724 avg loss: 0.00362 avg lploss: 0.00000
train epoch 1725 avg loss: 0.00361 avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.00575 avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.00547 avg lploss: 0.00000
*** Best Val Loss: 0.00562 	 Best Test Loss: 0.00537 	 Best epoch 1710
EarlyStopping counter: 3 out of 50
train epoch 1726 avg loss: 0.00365 avg lploss: 0.00000
train epoch 1727 avg loss: 0.00361 avg lploss: 0.00000
train epoch 1728 avg loss: 0.00365 avg lploss: 0.00000
train epoch 1729 avg loss: 0.00357 avg lploss: 0.00000
train epoch 1730 avg loss: 0.00359 avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.00559 avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.00535 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
Validation loss decreased (0.005620 --> 0.005594).  Saving model ...
train epoch 1731 avg loss: 0.00356 avg lploss: 0.00000
train epoch 1732 avg loss: 0.00363 avg lploss: 0.00000
train epoch 1733 avg loss: 0.00367 avg lploss: 0.00000
train epoch 1734 avg loss: 0.00361 avg lploss: 0.00000
train epoch 1735 avg loss: 0.00361 avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.00583 avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.00559 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 1 out of 50
train epoch 1736 avg loss: 0.00359 avg lploss: 0.00000
train epoch 1737 avg loss: 0.00362 avg lploss: 0.00000
train epoch 1738 avg loss: 0.00360 avg lploss: 0.00000
train epoch 1739 avg loss: 0.00352 avg lploss: 0.00000
train epoch 1740 avg loss: 0.00356 avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.00582 avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.00543 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 2 out of 50
train epoch 1741 avg loss: 0.00379 avg lploss: 0.00000
train epoch 1742 avg loss: 0.00371 avg lploss: 0.00000
train epoch 1743 avg loss: 0.00355 avg lploss: 0.00000
train epoch 1744 avg loss: 0.00355 avg lploss: 0.00000
train epoch 1745 avg loss: 0.00347 avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.00572 avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.00547 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 3 out of 50
train epoch 1746 avg loss: 0.00358 avg lploss: 0.00000
train epoch 1747 avg loss: 0.00358 avg lploss: 0.00000
train epoch 1748 avg loss: 0.00362 avg lploss: 0.00000
train epoch 1749 avg loss: 0.00366 avg lploss: 0.00000
train epoch 1750 avg loss: 0.00361 avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.00560 avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.00537 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 4 out of 50
train epoch 1751 avg loss: 0.00350 avg lploss: 0.00000
train epoch 1752 avg loss: 0.00351 avg lploss: 0.00000
train epoch 1753 avg loss: 0.00360 avg lploss: 0.00000
train epoch 1754 avg loss: 0.00353 avg lploss: 0.00000
train epoch 1755 avg loss: 0.00347 avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.00566 avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.00542 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 5 out of 50
train epoch 1756 avg loss: 0.00350 avg lploss: 0.00000
train epoch 1757 avg loss: 0.00354 avg lploss: 0.00000
train epoch 1758 avg loss: 0.00357 avg lploss: 0.00000
train epoch 1759 avg loss: 0.00378 avg lploss: 0.00000
train epoch 1760 avg loss: 0.00365 avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.00570 avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.00543 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 6 out of 50
train epoch 1761 avg loss: 0.00347 avg lploss: 0.00000
train epoch 1762 avg loss: 0.00354 avg lploss: 0.00000
train epoch 1763 avg loss: 0.00358 avg lploss: 0.00000
train epoch 1764 avg loss: 0.00351 avg lploss: 0.00000
train epoch 1765 avg loss: 0.00345 avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.00580 avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.00560 avg lploss: 0.00000
*** Best Val Loss: 0.00559 	 Best Test Loss: 0.00535 	 Best epoch 1730
EarlyStopping counter: 7 out of 50
train epoch 1766 avg loss: 0.00345 avg lploss: 0.00000
train epoch 1767 avg loss: 0.00344 avg lploss: 0.00000
train epoch 1768 avg loss: 0.00343 avg lploss: 0.00000
train epoch 1769 avg loss: 0.00344 avg lploss: 0.00000
train epoch 1770 avg loss: 0.00337 avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.00552 avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.00528 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
Validation loss decreased (0.005594 --> 0.005523).  Saving model ...
train epoch 1771 avg loss: 0.00345 avg lploss: 0.00000
train epoch 1772 avg loss: 0.00356 avg lploss: 0.00000
train epoch 1773 avg loss: 0.00348 avg lploss: 0.00000
train epoch 1774 avg loss: 0.00339 avg lploss: 0.00000
train epoch 1775 avg loss: 0.00330 avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.00570 avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.00539 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 1 out of 50
train epoch 1776 avg loss: 0.00341 avg lploss: 0.00000
train epoch 1777 avg loss: 0.00338 avg lploss: 0.00000
train epoch 1778 avg loss: 0.00342 avg lploss: 0.00000
train epoch 1779 avg loss: 0.00353 avg lploss: 0.00000
train epoch 1780 avg loss: 0.00366 avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.00572 avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.00549 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 2 out of 50
train epoch 1781 avg loss: 0.00342 avg lploss: 0.00000
train epoch 1782 avg loss: 0.00346 avg lploss: 0.00000
train epoch 1783 avg loss: 0.00338 avg lploss: 0.00000
train epoch 1784 avg loss: 0.00339 avg lploss: 0.00000
train epoch 1785 avg loss: 0.00335 avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.00558 avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.00541 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 3 out of 50
train epoch 1786 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1787 avg loss: 0.00329 avg lploss: 0.00000
train epoch 1788 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1789 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1790 avg loss: 0.00333 avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.00561 avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.00530 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 4 out of 50
train epoch 1791 avg loss: 0.00342 avg lploss: 0.00000
train epoch 1792 avg loss: 0.00338 avg lploss: 0.00000
train epoch 1793 avg loss: 0.00345 avg lploss: 0.00000
train epoch 1794 avg loss: 0.00337 avg lploss: 0.00000
train epoch 1795 avg loss: 0.00350 avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.00571 avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.00540 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 5 out of 50
train epoch 1796 avg loss: 0.00347 avg lploss: 0.00000
train epoch 1797 avg loss: 0.00341 avg lploss: 0.00000
train epoch 1798 avg loss: 0.00353 avg lploss: 0.00000
train epoch 1799 avg loss: 0.00344 avg lploss: 0.00000
train epoch 1800 avg loss: 0.00347 avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.00602 avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.00570 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 6 out of 50
train epoch 1801 avg loss: 0.00350 avg lploss: 0.00000
train epoch 1802 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1803 avg loss: 0.00331 avg lploss: 0.00000
train epoch 1804 avg loss: 0.00330 avg lploss: 0.00000
train epoch 1805 avg loss: 0.00346 avg lploss: 0.00000
==> val epoch 1805 avg loss: 0.00566 avg lploss: 0.00000
==> test epoch 1805 avg loss: 0.00541 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 7 out of 50
train epoch 1806 avg loss: 0.00327 avg lploss: 0.00000
train epoch 1807 avg loss: 0.00350 avg lploss: 0.00000
train epoch 1808 avg loss: 0.00339 avg lploss: 0.00000
train epoch 1809 avg loss: 0.00332 avg lploss: 0.00000
train epoch 1810 avg loss: 0.00339 avg lploss: 0.00000
==> val epoch 1810 avg loss: 0.00570 avg lploss: 0.00000
==> test epoch 1810 avg loss: 0.00552 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 8 out of 50
train epoch 1811 avg loss: 0.00331 avg lploss: 0.00000
train epoch 1812 avg loss: 0.00324 avg lploss: 0.00000
train epoch 1813 avg loss: 0.00344 avg lploss: 0.00000
train epoch 1814 avg loss: 0.00332 avg lploss: 0.00000
train epoch 1815 avg loss: 0.00333 avg lploss: 0.00000
==> val epoch 1815 avg loss: 0.00556 avg lploss: 0.00000
==> test epoch 1815 avg loss: 0.00536 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 9 out of 50
train epoch 1816 avg loss: 0.00322 avg lploss: 0.00000
train epoch 1817 avg loss: 0.00325 avg lploss: 0.00000
train epoch 1818 avg loss: 0.00322 avg lploss: 0.00000
train epoch 1819 avg loss: 0.00330 avg lploss: 0.00000
train epoch 1820 avg loss: 0.00327 avg lploss: 0.00000
==> val epoch 1820 avg loss: 0.00564 avg lploss: 0.00000
==> test epoch 1820 avg loss: 0.00542 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 10 out of 50
train epoch 1821 avg loss: 0.00328 avg lploss: 0.00000
train epoch 1822 avg loss: 0.00338 avg lploss: 0.00000
train epoch 1823 avg loss: 0.00349 avg lploss: 0.00000
train epoch 1824 avg loss: 0.00328 avg lploss: 0.00000
train epoch 1825 avg loss: 0.00322 avg lploss: 0.00000
==> val epoch 1825 avg loss: 0.00562 avg lploss: 0.00000
==> test epoch 1825 avg loss: 0.00542 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 11 out of 50
train epoch 1826 avg loss: 0.00319 avg lploss: 0.00000
train epoch 1827 avg loss: 0.00323 avg lploss: 0.00000
train epoch 1828 avg loss: 0.00320 avg lploss: 0.00000
train epoch 1829 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1830 avg loss: 0.00331 avg lploss: 0.00000
==> val epoch 1830 avg loss: 0.00566 avg lploss: 0.00000
==> test epoch 1830 avg loss: 0.00530 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 12 out of 50
train epoch 1831 avg loss: 0.00316 avg lploss: 0.00000
train epoch 1832 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1833 avg loss: 0.00335 avg lploss: 0.00000
train epoch 1834 avg loss: 0.00334 avg lploss: 0.00000
train epoch 1835 avg loss: 0.00325 avg lploss: 0.00000
==> val epoch 1835 avg loss: 0.00573 avg lploss: 0.00000
==> test epoch 1835 avg loss: 0.00554 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 13 out of 50
train epoch 1836 avg loss: 0.00325 avg lploss: 0.00000
train epoch 1837 avg loss: 0.00328 avg lploss: 0.00000
train epoch 1838 avg loss: 0.00322 avg lploss: 0.00000
train epoch 1839 avg loss: 0.00314 avg lploss: 0.00000
train epoch 1840 avg loss: 0.00332 avg lploss: 0.00000
==> val epoch 1840 avg loss: 0.00602 avg lploss: 0.00000
==> test epoch 1840 avg loss: 0.00571 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 14 out of 50
train epoch 1841 avg loss: 0.00330 avg lploss: 0.00000
train epoch 1842 avg loss: 0.00318 avg lploss: 0.00000
train epoch 1843 avg loss: 0.00314 avg lploss: 0.00000
train epoch 1844 avg loss: 0.00324 avg lploss: 0.00000
train epoch 1845 avg loss: 0.00334 avg lploss: 0.00000
==> val epoch 1845 avg loss: 0.00591 avg lploss: 0.00000
==> test epoch 1845 avg loss: 0.00576 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 15 out of 50
train epoch 1846 avg loss: 0.00329 avg lploss: 0.00000
train epoch 1847 avg loss: 0.00330 avg lploss: 0.00000
train epoch 1848 avg loss: 0.00313 avg lploss: 0.00000
train epoch 1849 avg loss: 0.00315 avg lploss: 0.00000
train epoch 1850 avg loss: 0.00330 avg lploss: 0.00000
==> val epoch 1850 avg loss: 0.00597 avg lploss: 0.00000
==> test epoch 1850 avg loss: 0.00562 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 16 out of 50
train epoch 1851 avg loss: 0.00313 avg lploss: 0.00000
train epoch 1852 avg loss: 0.00315 avg lploss: 0.00000
train epoch 1853 avg loss: 0.00319 avg lploss: 0.00000
train epoch 1854 avg loss: 0.00307 avg lploss: 0.00000
train epoch 1855 avg loss: 0.00312 avg lploss: 0.00000
==> val epoch 1855 avg loss: 0.00574 avg lploss: 0.00000
==> test epoch 1855 avg loss: 0.00536 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 17 out of 50
train epoch 1856 avg loss: 0.00318 avg lploss: 0.00000
train epoch 1857 avg loss: 0.00306 avg lploss: 0.00000
train epoch 1858 avg loss: 0.00322 avg lploss: 0.00000
train epoch 1859 avg loss: 0.00313 avg lploss: 0.00000
train epoch 1860 avg loss: 0.00311 avg lploss: 0.00000
==> val epoch 1860 avg loss: 0.00565 avg lploss: 0.00000
==> test epoch 1860 avg loss: 0.00538 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 18 out of 50
train epoch 1861 avg loss: 0.00314 avg lploss: 0.00000
train epoch 1862 avg loss: 0.00309 avg lploss: 0.00000
train epoch 1863 avg loss: 0.00323 avg lploss: 0.00000
train epoch 1864 avg loss: 0.00310 avg lploss: 0.00000
train epoch 1865 avg loss: 0.00315 avg lploss: 0.00000
==> val epoch 1865 avg loss: 0.00572 avg lploss: 0.00000
==> test epoch 1865 avg loss: 0.00545 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 19 out of 50
train epoch 1866 avg loss: 0.00306 avg lploss: 0.00000
train epoch 1867 avg loss: 0.00304 avg lploss: 0.00000
train epoch 1868 avg loss: 0.00314 avg lploss: 0.00000
train epoch 1869 avg loss: 0.00307 avg lploss: 0.00000
train epoch 1870 avg loss: 0.00305 avg lploss: 0.00000
==> val epoch 1870 avg loss: 0.00567 avg lploss: 0.00000
==> test epoch 1870 avg loss: 0.00543 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 20 out of 50
train epoch 1871 avg loss: 0.00312 avg lploss: 0.00000
train epoch 1872 avg loss: 0.00313 avg lploss: 0.00000
train epoch 1873 avg loss: 0.00318 avg lploss: 0.00000
train epoch 1874 avg loss: 0.00314 avg lploss: 0.00000
train epoch 1875 avg loss: 0.00312 avg lploss: 0.00000
==> val epoch 1875 avg loss: 0.00573 avg lploss: 0.00000
==> test epoch 1875 avg loss: 0.00551 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 21 out of 50
train epoch 1876 avg loss: 0.00312 avg lploss: 0.00000
train epoch 1877 avg loss: 0.00324 avg lploss: 0.00000
train epoch 1878 avg loss: 0.00317 avg lploss: 0.00000
train epoch 1879 avg loss: 0.00307 avg lploss: 0.00000
train epoch 1880 avg loss: 0.00323 avg lploss: 0.00000
==> val epoch 1880 avg loss: 0.00579 avg lploss: 0.00000
==> test epoch 1880 avg loss: 0.00569 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 22 out of 50
train epoch 1881 avg loss: 0.00356 avg lploss: 0.00000
train epoch 1882 avg loss: 0.00338 avg lploss: 0.00000
train epoch 1883 avg loss: 0.00312 avg lploss: 0.00000
train epoch 1884 avg loss: 0.00302 avg lploss: 0.00000
train epoch 1885 avg loss: 0.00305 avg lploss: 0.00000
==> val epoch 1885 avg loss: 0.00559 avg lploss: 0.00000
==> test epoch 1885 avg loss: 0.00534 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 23 out of 50
train epoch 1886 avg loss: 0.00304 avg lploss: 0.00000
train epoch 1887 avg loss: 0.00303 avg lploss: 0.00000
train epoch 1888 avg loss: 0.00301 avg lploss: 0.00000
train epoch 1889 avg loss: 0.00316 avg lploss: 0.00000
train epoch 1890 avg loss: 0.00306 avg lploss: 0.00000
==> val epoch 1890 avg loss: 0.00587 avg lploss: 0.00000
==> test epoch 1890 avg loss: 0.00543 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 24 out of 50
train epoch 1891 avg loss: 0.00311 avg lploss: 0.00000
train epoch 1892 avg loss: 0.00303 avg lploss: 0.00000
train epoch 1893 avg loss: 0.00300 avg lploss: 0.00000
train epoch 1894 avg loss: 0.00303 avg lploss: 0.00000
train epoch 1895 avg loss: 0.00296 avg lploss: 0.00000
==> val epoch 1895 avg loss: 0.00570 avg lploss: 0.00000
==> test epoch 1895 avg loss: 0.00537 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 25 out of 50
train epoch 1896 avg loss: 0.00306 avg lploss: 0.00000
train epoch 1897 avg loss: 0.00301 avg lploss: 0.00000
train epoch 1898 avg loss: 0.00301 avg lploss: 0.00000
train epoch 1899 avg loss: 0.00302 avg lploss: 0.00000
train epoch 1900 avg loss: 0.00299 avg lploss: 0.00000
==> val epoch 1900 avg loss: 0.00577 avg lploss: 0.00000
==> test epoch 1900 avg loss: 0.00546 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 26 out of 50
train epoch 1901 avg loss: 0.00297 avg lploss: 0.00000
train epoch 1902 avg loss: 0.00294 avg lploss: 0.00000
train epoch 1903 avg loss: 0.00301 avg lploss: 0.00000
train epoch 1904 avg loss: 0.00296 avg lploss: 0.00000
train epoch 1905 avg loss: 0.00299 avg lploss: 0.00000
==> val epoch 1905 avg loss: 0.00586 avg lploss: 0.00000
==> test epoch 1905 avg loss: 0.00554 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 27 out of 50
train epoch 1906 avg loss: 0.00295 avg lploss: 0.00000
train epoch 1907 avg loss: 0.00300 avg lploss: 0.00000
train epoch 1908 avg loss: 0.00312 avg lploss: 0.00000
train epoch 1909 avg loss: 0.00305 avg lploss: 0.00000
train epoch 1910 avg loss: 0.00300 avg lploss: 0.00000
==> val epoch 1910 avg loss: 0.00575 avg lploss: 0.00000
==> test epoch 1910 avg loss: 0.00554 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 28 out of 50
train epoch 1911 avg loss: 0.00296 avg lploss: 0.00000
train epoch 1912 avg loss: 0.00298 avg lploss: 0.00000
train epoch 1913 avg loss: 0.00299 avg lploss: 0.00000
train epoch 1914 avg loss: 0.00289 avg lploss: 0.00000
train epoch 1915 avg loss: 0.00292 avg lploss: 0.00000
==> val epoch 1915 avg loss: 0.00578 avg lploss: 0.00000
==> test epoch 1915 avg loss: 0.00555 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 29 out of 50
train epoch 1916 avg loss: 0.00298 avg lploss: 0.00000
train epoch 1917 avg loss: 0.00298 avg lploss: 0.00000
train epoch 1918 avg loss: 0.00296 avg lploss: 0.00000
train epoch 1919 avg loss: 0.00304 avg lploss: 0.00000
train epoch 1920 avg loss: 0.00314 avg lploss: 0.00000
==> val epoch 1920 avg loss: 0.00571 avg lploss: 0.00000
==> test epoch 1920 avg loss: 0.00551 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 30 out of 50
train epoch 1921 avg loss: 0.00294 avg lploss: 0.00000
train epoch 1922 avg loss: 0.00291 avg lploss: 0.00000
train epoch 1923 avg loss: 0.00294 avg lploss: 0.00000
train epoch 1924 avg loss: 0.00293 avg lploss: 0.00000
train epoch 1925 avg loss: 0.00289 avg lploss: 0.00000
==> val epoch 1925 avg loss: 0.00602 avg lploss: 0.00000
==> test epoch 1925 avg loss: 0.00572 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 31 out of 50
train epoch 1926 avg loss: 0.00302 avg lploss: 0.00000
train epoch 1927 avg loss: 0.00296 avg lploss: 0.00000
train epoch 1928 avg loss: 0.00305 avg lploss: 0.00000
train epoch 1929 avg loss: 0.00292 avg lploss: 0.00000
train epoch 1930 avg loss: 0.00290 avg lploss: 0.00000
==> val epoch 1930 avg loss: 0.00560 avg lploss: 0.00000
==> test epoch 1930 avg loss: 0.00534 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 32 out of 50
train epoch 1931 avg loss: 0.00299 avg lploss: 0.00000
train epoch 1932 avg loss: 0.00293 avg lploss: 0.00000
train epoch 1933 avg loss: 0.00292 avg lploss: 0.00000
train epoch 1934 avg loss: 0.00298 avg lploss: 0.00000
train epoch 1935 avg loss: 0.00290 avg lploss: 0.00000
==> val epoch 1935 avg loss: 0.00570 avg lploss: 0.00000
==> test epoch 1935 avg loss: 0.00537 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 33 out of 50
train epoch 1936 avg loss: 0.00300 avg lploss: 0.00000
train epoch 1937 avg loss: 0.00291 avg lploss: 0.00000
train epoch 1938 avg loss: 0.00289 avg lploss: 0.00000
train epoch 1939 avg loss: 0.00309 avg lploss: 0.00000
train epoch 1940 avg loss: 0.00299 avg lploss: 0.00000
==> val epoch 1940 avg loss: 0.00564 avg lploss: 0.00000
==> test epoch 1940 avg loss: 0.00545 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 34 out of 50
train epoch 1941 avg loss: 0.00293 avg lploss: 0.00000
train epoch 1942 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1943 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1944 avg loss: 0.00293 avg lploss: 0.00000
train epoch 1945 avg loss: 0.00290 avg lploss: 0.00000
==> val epoch 1945 avg loss: 0.00560 avg lploss: 0.00000
==> test epoch 1945 avg loss: 0.00548 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 35 out of 50
train epoch 1946 avg loss: 0.00283 avg lploss: 0.00000
train epoch 1947 avg loss: 0.00282 avg lploss: 0.00000
train epoch 1948 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1949 avg loss: 0.00284 avg lploss: 0.00000
train epoch 1950 avg loss: 0.00289 avg lploss: 0.00000
==> val epoch 1950 avg loss: 0.00581 avg lploss: 0.00000
==> test epoch 1950 avg loss: 0.00546 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 36 out of 50
train epoch 1951 avg loss: 0.00295 avg lploss: 0.00000
train epoch 1952 avg loss: 0.00299 avg lploss: 0.00000
train epoch 1953 avg loss: 0.00300 avg lploss: 0.00000
train epoch 1954 avg loss: 0.00303 avg lploss: 0.00000
train epoch 1955 avg loss: 0.00289 avg lploss: 0.00000
==> val epoch 1955 avg loss: 0.00576 avg lploss: 0.00000
==> test epoch 1955 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 37 out of 50
train epoch 1956 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1957 avg loss: 0.00290 avg lploss: 0.00000
train epoch 1958 avg loss: 0.00280 avg lploss: 0.00000
train epoch 1959 avg loss: 0.00279 avg lploss: 0.00000
train epoch 1960 avg loss: 0.00300 avg lploss: 0.00000
==> val epoch 1960 avg loss: 0.00561 avg lploss: 0.00000
==> test epoch 1960 avg loss: 0.00537 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 38 out of 50
train epoch 1961 avg loss: 0.00289 avg lploss: 0.00000
train epoch 1962 avg loss: 0.00294 avg lploss: 0.00000
train epoch 1963 avg loss: 0.00279 avg lploss: 0.00000
train epoch 1964 avg loss: 0.00303 avg lploss: 0.00000
train epoch 1965 avg loss: 0.00277 avg lploss: 0.00000
==> val epoch 1965 avg loss: 0.00563 avg lploss: 0.00000
==> test epoch 1965 avg loss: 0.00534 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 39 out of 50
train epoch 1966 avg loss: 0.00282 avg lploss: 0.00000
train epoch 1967 avg loss: 0.00295 avg lploss: 0.00000
train epoch 1968 avg loss: 0.00285 avg lploss: 0.00000
train epoch 1969 avg loss: 0.00282 avg lploss: 0.00000
train epoch 1970 avg loss: 0.00275 avg lploss: 0.00000
==> val epoch 1970 avg loss: 0.00574 avg lploss: 0.00000
==> test epoch 1970 avg loss: 0.00542 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 40 out of 50
train epoch 1971 avg loss: 0.00278 avg lploss: 0.00000
train epoch 1972 avg loss: 0.00286 avg lploss: 0.00000
train epoch 1973 avg loss: 0.00286 avg lploss: 0.00000
train epoch 1974 avg loss: 0.00291 avg lploss: 0.00000
train epoch 1975 avg loss: 0.00284 avg lploss: 0.00000
==> val epoch 1975 avg loss: 0.00581 avg lploss: 0.00000
==> test epoch 1975 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 41 out of 50
train epoch 1976 avg loss: 0.00299 avg lploss: 0.00000
train epoch 1977 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1978 avg loss: 0.00273 avg lploss: 0.00000
train epoch 1979 avg loss: 0.00277 avg lploss: 0.00000
train epoch 1980 avg loss: 0.00278 avg lploss: 0.00000
==> val epoch 1980 avg loss: 0.00557 avg lploss: 0.00000
==> test epoch 1980 avg loss: 0.00538 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 42 out of 50
train epoch 1981 avg loss: 0.00269 avg lploss: 0.00000
train epoch 1982 avg loss: 0.00275 avg lploss: 0.00000
train epoch 1983 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1984 avg loss: 0.00274 avg lploss: 0.00000
train epoch 1985 avg loss: 0.00275 avg lploss: 0.00000
==> val epoch 1985 avg loss: 0.00568 avg lploss: 0.00000
==> test epoch 1985 avg loss: 0.00545 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 43 out of 50
train epoch 1986 avg loss: 0.00276 avg lploss: 0.00000
train epoch 1987 avg loss: 0.00277 avg lploss: 0.00000
train epoch 1988 avg loss: 0.00270 avg lploss: 0.00000
train epoch 1989 avg loss: 0.00280 avg lploss: 0.00000
train epoch 1990 avg loss: 0.00304 avg lploss: 0.00000
==> val epoch 1990 avg loss: 0.00589 avg lploss: 0.00000
==> test epoch 1990 avg loss: 0.00559 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 44 out of 50
train epoch 1991 avg loss: 0.00434 avg lploss: 0.00000
train epoch 1992 avg loss: 0.00445 avg lploss: 0.00000
train epoch 1993 avg loss: 0.00319 avg lploss: 0.00000
train epoch 1994 avg loss: 0.00291 avg lploss: 0.00000
train epoch 1995 avg loss: 0.00277 avg lploss: 0.00000
==> val epoch 1995 avg loss: 0.00576 avg lploss: 0.00000
==> test epoch 1995 avg loss: 0.00536 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 45 out of 50
train epoch 1996 avg loss: 0.00281 avg lploss: 0.00000
train epoch 1997 avg loss: 0.00273 avg lploss: 0.00000
train epoch 1998 avg loss: 0.00274 avg lploss: 0.00000
train epoch 1999 avg loss: 0.00280 avg lploss: 0.00000
train epoch 2000 avg loss: 0.00275 avg lploss: 0.00000
==> val epoch 2000 avg loss: 0.00601 avg lploss: 0.00000
==> test epoch 2000 avg loss: 0.00556 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 46 out of 50
train epoch 2001 avg loss: 0.00291 avg lploss: 0.00000
train epoch 2002 avg loss: 0.00273 avg lploss: 0.00000
train epoch 2003 avg loss: 0.00281 avg lploss: 0.00000
train epoch 2004 avg loss: 0.00279 avg lploss: 0.00000
train epoch 2005 avg loss: 0.00273 avg lploss: 0.00000
==> val epoch 2005 avg loss: 0.00569 avg lploss: 0.00000
==> test epoch 2005 avg loss: 0.00535 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 47 out of 50
train epoch 2006 avg loss: 0.00264 avg lploss: 0.00000
train epoch 2007 avg loss: 0.00273 avg lploss: 0.00000
train epoch 2008 avg loss: 0.00265 avg lploss: 0.00000
train epoch 2009 avg loss: 0.00269 avg lploss: 0.00000
train epoch 2010 avg loss: 0.00269 avg lploss: 0.00000
==> val epoch 2010 avg loss: 0.00579 avg lploss: 0.00000
==> test epoch 2010 avg loss: 0.00553 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 48 out of 50
train epoch 2011 avg loss: 0.00269 avg lploss: 0.00000
train epoch 2012 avg loss: 0.00277 avg lploss: 0.00000
train epoch 2013 avg loss: 0.00281 avg lploss: 0.00000
train epoch 2014 avg loss: 0.00269 avg lploss: 0.00000
train epoch 2015 avg loss: 0.00266 avg lploss: 0.00000
==> val epoch 2015 avg loss: 0.00561 avg lploss: 0.00000
==> test epoch 2015 avg loss: 0.00531 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 49 out of 50
train epoch 2016 avg loss: 0.00266 avg lploss: 0.00000
train epoch 2017 avg loss: 0.00281 avg lploss: 0.00000
train epoch 2018 avg loss: 0.00261 avg lploss: 0.00000
train epoch 2019 avg loss: 0.00260 avg lploss: 0.00000
train epoch 2020 avg loss: 0.00259 avg lploss: 0.00000
==> val epoch 2020 avg loss: 0.00573 avg lploss: 0.00000
==> test epoch 2020 avg loss: 0.00542 avg lploss: 0.00000
*** Best Val Loss: 0.00552 	 Best Test Loss: 0.00528 	 Best epoch 1770
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train_f_mse = 0.003365
best_val_f_mse = 0.005523
best_test_f_mse = 0.005276
best_test_a_mse = 0.002266
best_epoch = 1770
best_train_f_mse = 0.003365, best_val_f_mse = 0.005523, best_test_f_mse = 0.005276, best_test_a_mse = 0.002266, best_epoch = 1770
Training completed for seed 4 with num_modes=3
