Date              = Fri Dec 12 17:53:44 CET 2025
Hostname          = mel2053
Array Task ID     = 1
Running config: configs/mocap_run_seed1.json
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_seed1.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_seed1', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/mocap', pooling_layer=3, seed=1, test_interval=5, time_emb_dim=32, use_h_conv=True, use_x_conv=True, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/mocap/mocap_run_seed1/saved_model.pth
train epoch 0 avg loss: 5187.92876 (A-MSE: 5160.66074) avg lploss: 0.00000
==> val epoch 0 avg loss: 95.94234 (A-MSE: 84.67270) avg lploss: 0.00000
==> test epoch 0 avg loss: 91.40929 (A-MSE: 80.68502) avg lploss: 0.00000
*** Best Val Loss: 95.94234 	 Best Test Loss: 91.40929 	 Best epoch 0
Validation loss decreased (inf --> 95.942340).  Saving model ...
train epoch 1 avg loss: 91.93302 (A-MSE: 81.25582) avg lploss: 0.00000
train epoch 2 avg loss: 94.79913 (A-MSE: 85.35176) avg lploss: 0.00000
train epoch 3 avg loss: 77.13187 (A-MSE: 67.95467) avg lploss: 0.00000
train epoch 4 avg loss: 58.15868 (A-MSE: 51.41469) avg lploss: 0.00000
train epoch 5 avg loss: 41.96993 (A-MSE: 37.10609) avg lploss: 0.00000
==> val epoch 5 avg loss: 36.24360 (A-MSE: 31.86272) avg lploss: 0.00000
==> test epoch 5 avg loss: 35.07495 (A-MSE: 30.92017) avg lploss: 0.00000
*** Best Val Loss: 36.24360 	 Best Test Loss: 35.07495 	 Best epoch 5
Validation loss decreased (95.942340 --> 36.243599).  Saving model ...
train epoch 6 avg loss: 32.32609 (A-MSE: 28.48249) avg lploss: 0.00000
train epoch 7 avg loss: 24.41445 (A-MSE: 21.65017) avg lploss: 0.00000
train epoch 8 avg loss: 21.77732 (A-MSE: 19.37676) avg lploss: 0.00000
train epoch 9 avg loss: 19.27570 (A-MSE: 17.10705) avg lploss: 0.00000
train epoch 10 avg loss: 18.20007 (A-MSE: 16.08563) avg lploss: 0.00000
==> val epoch 10 avg loss: 17.40581 (A-MSE: 15.75104) avg lploss: 0.00000
==> test epoch 10 avg loss: 16.22485 (A-MSE: 14.68353) avg lploss: 0.00000
*** Best Val Loss: 17.40581 	 Best Test Loss: 16.22485 	 Best epoch 10
Validation loss decreased (36.243599 --> 17.405807).  Saving model ...
train epoch 11 avg loss: 17.09551 (A-MSE: 15.17294) avg lploss: 0.00000
train epoch 12 avg loss: 16.67661 (A-MSE: 14.79998) avg lploss: 0.00000
train epoch 13 avg loss: 15.54353 (A-MSE: 13.76511) avg lploss: 0.00000
train epoch 14 avg loss: 13.59904 (A-MSE: 12.02573) avg lploss: 0.00000
train epoch 15 avg loss: 12.50782 (A-MSE: 11.08648) avg lploss: 0.00000
==> val epoch 15 avg loss: 12.22915 (A-MSE: 10.65032) avg lploss: 0.00000
==> test epoch 15 avg loss: 11.41229 (A-MSE: 9.95692) avg lploss: 0.00000
*** Best Val Loss: 12.22915 	 Best Test Loss: 11.41229 	 Best epoch 15
Validation loss decreased (17.405807 --> 12.229153).  Saving model ...
train epoch 16 avg loss: 11.31120 (A-MSE: 10.04658) avg lploss: 0.00000
train epoch 17 avg loss: 10.94559 (A-MSE: 9.68577) avg lploss: 0.00000
train epoch 18 avg loss: 9.79808 (A-MSE: 8.67608) avg lploss: 0.00000
train epoch 19 avg loss: 9.32196 (A-MSE: 8.24108) avg lploss: 0.00000
train epoch 20 avg loss: 8.60974 (A-MSE: 7.68475) avg lploss: 0.00000
==> val epoch 20 avg loss: 8.76852 (A-MSE: 7.72129) avg lploss: 0.00000
==> test epoch 20 avg loss: 8.61799 (A-MSE: 7.63080) avg lploss: 0.00000
*** Best Val Loss: 8.76852 	 Best Test Loss: 8.61799 	 Best epoch 20
Validation loss decreased (12.229153 --> 8.768520).  Saving model ...
train epoch 21 avg loss: 8.21388 (A-MSE: 7.27752) avg lploss: 0.00000
train epoch 22 avg loss: 7.84413 (A-MSE: 6.95413) avg lploss: 0.00000
train epoch 23 avg loss: 7.37346 (A-MSE: 6.55919) avg lploss: 0.00000
train epoch 24 avg loss: 7.88411 (A-MSE: 7.02956) avg lploss: 0.00000
train epoch 25 avg loss: 7.42611 (A-MSE: 6.62065) avg lploss: 0.00000
==> val epoch 25 avg loss: 7.41236 (A-MSE: 6.43694) avg lploss: 0.00000
==> test epoch 25 avg loss: 7.47903 (A-MSE: 6.54283) avg lploss: 0.00000
*** Best Val Loss: 7.41236 	 Best Test Loss: 7.47903 	 Best epoch 25
Validation loss decreased (8.768520 --> 7.412356).  Saving model ...
train epoch 26 avg loss: 6.74709 (A-MSE: 6.00690) avg lploss: 0.00000
train epoch 27 avg loss: 6.91334 (A-MSE: 6.18906) avg lploss: 0.00000
train epoch 28 avg loss: 6.68244 (A-MSE: 5.98083) avg lploss: 0.00000
train epoch 29 avg loss: 6.43748 (A-MSE: 5.77030) avg lploss: 0.00000
train epoch 30 avg loss: 6.03388 (A-MSE: 5.39307) avg lploss: 0.00000
==> val epoch 30 avg loss: 5.98566 (A-MSE: 5.47895) avg lploss: 0.00000
==> test epoch 30 avg loss: 6.01702 (A-MSE: 5.53642) avg lploss: 0.00000
*** Best Val Loss: 5.98566 	 Best Test Loss: 6.01702 	 Best epoch 30
Validation loss decreased (7.412356 --> 5.985658).  Saving model ...
train epoch 31 avg loss: 6.08923 (A-MSE: 5.47156) avg lploss: 0.00000
train epoch 32 avg loss: 5.64972 (A-MSE: 5.05967) avg lploss: 0.00000
train epoch 33 avg loss: 5.57882 (A-MSE: 5.02309) avg lploss: 0.00000
train epoch 34 avg loss: 5.49492 (A-MSE: 4.94560) avg lploss: 0.00000
train epoch 35 avg loss: 5.56125 (A-MSE: 5.00509) avg lploss: 0.00000
==> val epoch 35 avg loss: 6.22391 (A-MSE: 5.59393) avg lploss: 0.00000
==> test epoch 35 avg loss: 6.17513 (A-MSE: 5.57095) avg lploss: 0.00000
*** Best Val Loss: 5.98566 	 Best Test Loss: 6.01702 	 Best epoch 30
EarlyStopping counter: 1 out of 50
train epoch 36 avg loss: 5.64237 (A-MSE: 5.08582) avg lploss: 0.00000
train epoch 37 avg loss: 5.47377 (A-MSE: 4.91962) avg lploss: 0.00000
train epoch 38 avg loss: 4.99535 (A-MSE: 4.51455) avg lploss: 0.00000
train epoch 39 avg loss: 4.83131 (A-MSE: 4.35958) avg lploss: 0.00000
train epoch 40 avg loss: 4.83316 (A-MSE: 4.36579) avg lploss: 0.00000
==> val epoch 40 avg loss: 5.45781 (A-MSE: 5.08764) avg lploss: 0.00000
==> test epoch 40 avg loss: 5.20447 (A-MSE: 4.87299) avg lploss: 0.00000
*** Best Val Loss: 5.45781 	 Best Test Loss: 5.20447 	 Best epoch 40
Validation loss decreased (5.985658 --> 5.457815).  Saving model ...
train epoch 41 avg loss: 5.00285 (A-MSE: 4.53418) avg lploss: 0.00000
train epoch 42 avg loss: 5.01525 (A-MSE: 4.51339) avg lploss: 0.00000
train epoch 43 avg loss: 4.69792 (A-MSE: 4.25113) avg lploss: 0.00000
train epoch 44 avg loss: 4.79715 (A-MSE: 4.34168) avg lploss: 0.00000
train epoch 45 avg loss: 4.66007 (A-MSE: 4.22398) avg lploss: 0.00000
==> val epoch 45 avg loss: 4.64565 (A-MSE: 4.24814) avg lploss: 0.00000
==> test epoch 45 avg loss: 4.67696 (A-MSE: 4.29517) avg lploss: 0.00000
*** Best Val Loss: 4.64565 	 Best Test Loss: 4.67696 	 Best epoch 45
Validation loss decreased (5.457815 --> 4.645647).  Saving model ...
train epoch 46 avg loss: 4.34956 (A-MSE: 3.93651) avg lploss: 0.00000
train epoch 47 avg loss: 4.42269 (A-MSE: 4.01435) avg lploss: 0.00000
train epoch 48 avg loss: 4.19946 (A-MSE: 3.79908) avg lploss: 0.00000
train epoch 49 avg loss: 4.28312 (A-MSE: 3.89095) avg lploss: 0.00000
train epoch 50 avg loss: 4.22928 (A-MSE: 3.82427) avg lploss: 0.00000
==> val epoch 50 avg loss: 4.27590 (A-MSE: 3.83561) avg lploss: 0.00000
==> test epoch 50 avg loss: 4.24476 (A-MSE: 3.82396) avg lploss: 0.00000
*** Best Val Loss: 4.27590 	 Best Test Loss: 4.24476 	 Best epoch 50
Validation loss decreased (4.645647 --> 4.275896).  Saving model ...
train epoch 51 avg loss: 4.24380 (A-MSE: 3.85044) avg lploss: 0.00000
train epoch 52 avg loss: 4.23379 (A-MSE: 3.81833) avg lploss: 0.00000
train epoch 53 avg loss: 3.93496 (A-MSE: 3.57030) avg lploss: 0.00000
train epoch 54 avg loss: 3.71661 (A-MSE: 3.37050) avg lploss: 0.00000
train epoch 55 avg loss: 4.00277 (A-MSE: 3.61897) avg lploss: 0.00000
==> val epoch 55 avg loss: 3.93059 (A-MSE: 3.61615) avg lploss: 0.00000
==> test epoch 55 avg loss: 4.04105 (A-MSE: 3.72738) avg lploss: 0.00000
*** Best Val Loss: 3.93059 	 Best Test Loss: 4.04105 	 Best epoch 55
Validation loss decreased (4.275896 --> 3.930593).  Saving model ...
train epoch 56 avg loss: 3.77811 (A-MSE: 3.43208) avg lploss: 0.00000
train epoch 57 avg loss: 3.73811 (A-MSE: 3.37510) avg lploss: 0.00000
train epoch 58 avg loss: 3.36693 (A-MSE: 3.06588) avg lploss: 0.00000
train epoch 59 avg loss: 3.40050 (A-MSE: 3.08522) avg lploss: 0.00000
train epoch 60 avg loss: 3.28783 (A-MSE: 2.98314) avg lploss: 0.00000
==> val epoch 60 avg loss: 3.89749 (A-MSE: 3.59718) avg lploss: 0.00000
==> test epoch 60 avg loss: 3.99450 (A-MSE: 3.69445) avg lploss: 0.00000
*** Best Val Loss: 3.89749 	 Best Test Loss: 3.99450 	 Best epoch 60
Validation loss decreased (3.930593 --> 3.897493).  Saving model ...
train epoch 61 avg loss: 3.46344 (A-MSE: 3.13020) avg lploss: 0.00000
train epoch 62 avg loss: 3.28529 (A-MSE: 2.97767) avg lploss: 0.00000
train epoch 63 avg loss: 3.42842 (A-MSE: 3.09694) avg lploss: 0.00000
train epoch 64 avg loss: 3.21777 (A-MSE: 2.92625) avg lploss: 0.00000
train epoch 65 avg loss: 3.29073 (A-MSE: 2.96417) avg lploss: 0.00000
==> val epoch 65 avg loss: 3.37302 (A-MSE: 3.12829) avg lploss: 0.00000
==> test epoch 65 avg loss: 3.47132 (A-MSE: 3.22198) avg lploss: 0.00000
*** Best Val Loss: 3.37302 	 Best Test Loss: 3.47132 	 Best epoch 65
Validation loss decreased (3.897493 --> 3.373022).  Saving model ...
train epoch 66 avg loss: 2.87829 (A-MSE: 2.60560) avg lploss: 0.00000
train epoch 67 avg loss: 2.97878 (A-MSE: 2.70153) avg lploss: 0.00000
train epoch 68 avg loss: 3.00031 (A-MSE: 2.70204) avg lploss: 0.00000
train epoch 69 avg loss: 3.06920 (A-MSE: 2.78321) avg lploss: 0.00000
train epoch 70 avg loss: 2.87861 (A-MSE: 2.61218) avg lploss: 0.00000
==> val epoch 70 avg loss: 3.25962 (A-MSE: 2.98651) avg lploss: 0.00000
==> test epoch 70 avg loss: 3.48377 (A-MSE: 3.20211) avg lploss: 0.00000
*** Best Val Loss: 3.25962 	 Best Test Loss: 3.48377 	 Best epoch 70
Validation loss decreased (3.373022 --> 3.259618).  Saving model ...
train epoch 71 avg loss: 2.74873 (A-MSE: 2.48418) avg lploss: 0.00000
train epoch 72 avg loss: 2.74373 (A-MSE: 2.47279) avg lploss: 0.00000
train epoch 73 avg loss: 2.76722 (A-MSE: 2.50542) avg lploss: 0.00000
train epoch 74 avg loss: 2.77251 (A-MSE: 2.49981) avg lploss: 0.00000
train epoch 75 avg loss: 2.99650 (A-MSE: 2.69887) avg lploss: 0.00000
==> val epoch 75 avg loss: 3.37659 (A-MSE: 3.14305) avg lploss: 0.00000
==> test epoch 75 avg loss: 3.51535 (A-MSE: 3.27450) avg lploss: 0.00000
*** Best Val Loss: 3.25962 	 Best Test Loss: 3.48377 	 Best epoch 70
EarlyStopping counter: 1 out of 50
train epoch 76 avg loss: 2.82743 (A-MSE: 2.55384) avg lploss: 0.00000
train epoch 77 avg loss: 2.80763 (A-MSE: 2.53451) avg lploss: 0.00000
train epoch 78 avg loss: 2.68648 (A-MSE: 2.42118) avg lploss: 0.00000
train epoch 79 avg loss: 2.53853 (A-MSE: 2.29058) avg lploss: 0.00000
train epoch 80 avg loss: 2.64825 (A-MSE: 2.39373) avg lploss: 0.00000
==> val epoch 80 avg loss: 3.80240 (A-MSE: 3.47472) avg lploss: 0.00000
==> test epoch 80 avg loss: 3.77467 (A-MSE: 3.45585) avg lploss: 0.00000
*** Best Val Loss: 3.25962 	 Best Test Loss: 3.48377 	 Best epoch 70
EarlyStopping counter: 2 out of 50
train epoch 81 avg loss: 2.79702 (A-MSE: 2.54099) avg lploss: 0.00000
train epoch 82 avg loss: 2.68735 (A-MSE: 2.41642) avg lploss: 0.00000
train epoch 83 avg loss: 2.94999 (A-MSE: 2.65287) avg lploss: 0.00000
train epoch 84 avg loss: 2.53970 (A-MSE: 2.28757) avg lploss: 0.00000
train epoch 85 avg loss: 2.40611 (A-MSE: 2.17057) avg lploss: 0.00000
==> val epoch 85 avg loss: 3.15257 (A-MSE: 2.90027) avg lploss: 0.00000
==> test epoch 85 avg loss: 3.29766 (A-MSE: 3.04085) avg lploss: 0.00000
*** Best Val Loss: 3.15257 	 Best Test Loss: 3.29766 	 Best epoch 85
Validation loss decreased (3.259618 --> 3.152574).  Saving model ...
train epoch 86 avg loss: 2.37040 (A-MSE: 2.12767) avg lploss: 0.00000
train epoch 87 avg loss: 2.41103 (A-MSE: 2.15720) avg lploss: 0.00000
train epoch 88 avg loss: 2.26994 (A-MSE: 2.04375) avg lploss: 0.00000
train epoch 89 avg loss: 2.19313 (A-MSE: 1.97175) avg lploss: 0.00000
train epoch 90 avg loss: 2.32368 (A-MSE: 2.08900) avg lploss: 0.00000
==> val epoch 90 avg loss: 2.73119 (A-MSE: 2.49187) avg lploss: 0.00000
==> test epoch 90 avg loss: 2.93887 (A-MSE: 2.68128) avg lploss: 0.00000
*** Best Val Loss: 2.73119 	 Best Test Loss: 2.93887 	 Best epoch 90
Validation loss decreased (3.152574 --> 2.731191).  Saving model ...
train epoch 91 avg loss: 2.30103 (A-MSE: 2.06540) avg lploss: 0.00000
train epoch 92 avg loss: 2.21326 (A-MSE: 1.98765) avg lploss: 0.00000
train epoch 93 avg loss: 2.14565 (A-MSE: 1.92721) avg lploss: 0.00000
train epoch 94 avg loss: 2.25767 (A-MSE: 2.02419) avg lploss: 0.00000
train epoch 95 avg loss: 2.05385 (A-MSE: 1.84953) avg lploss: 0.00000
==> val epoch 95 avg loss: 2.47983 (A-MSE: 2.25198) avg lploss: 0.00000
==> test epoch 95 avg loss: 2.71221 (A-MSE: 2.46853) avg lploss: 0.00000
*** Best Val Loss: 2.47983 	 Best Test Loss: 2.71221 	 Best epoch 95
Validation loss decreased (2.731191 --> 2.479834).  Saving model ...
train epoch 96 avg loss: 2.15562 (A-MSE: 1.93083) avg lploss: 0.00000
train epoch 97 avg loss: 2.09616 (A-MSE: 1.88245) avg lploss: 0.00000
train epoch 98 avg loss: 1.95888 (A-MSE: 1.75798) avg lploss: 0.00000
train epoch 99 avg loss: 1.96574 (A-MSE: 1.75451) avg lploss: 0.00000
train epoch 100 avg loss: 1.91060 (A-MSE: 1.70800) avg lploss: 0.00000
==> val epoch 100 avg loss: 2.65136 (A-MSE: 2.43908) avg lploss: 0.00000
==> test epoch 100 avg loss: 2.70594 (A-MSE: 2.50170) avg lploss: 0.00000
*** Best Val Loss: 2.47983 	 Best Test Loss: 2.71221 	 Best epoch 95
EarlyStopping counter: 1 out of 50
train epoch 101 avg loss: 1.82422 (A-MSE: 1.63943) avg lploss: 0.00000
train epoch 102 avg loss: 1.74865 (A-MSE: 1.56188) avg lploss: 0.00000
train epoch 103 avg loss: 1.80319 (A-MSE: 1.61232) avg lploss: 0.00000
train epoch 104 avg loss: 1.86399 (A-MSE: 1.67300) avg lploss: 0.00000
train epoch 105 avg loss: 1.89090 (A-MSE: 1.70808) avg lploss: 0.00000
==> val epoch 105 avg loss: 2.41914 (A-MSE: 2.21326) avg lploss: 0.00000
==> test epoch 105 avg loss: 2.51093 (A-MSE: 2.30203) avg lploss: 0.00000
*** Best Val Loss: 2.41914 	 Best Test Loss: 2.51093 	 Best epoch 105
Validation loss decreased (2.479834 --> 2.419143).  Saving model ...
train epoch 106 avg loss: 1.93780 (A-MSE: 1.73031) avg lploss: 0.00000
train epoch 107 avg loss: 1.76948 (A-MSE: 1.58623) avg lploss: 0.00000
train epoch 108 avg loss: 1.85629 (A-MSE: 1.65854) avg lploss: 0.00000
train epoch 109 avg loss: 1.71597 (A-MSE: 1.53466) avg lploss: 0.00000
train epoch 110 avg loss: 1.79848 (A-MSE: 1.61954) avg lploss: 0.00000
==> val epoch 110 avg loss: 2.69197 (A-MSE: 2.43524) avg lploss: 0.00000
==> test epoch 110 avg loss: 2.88199 (A-MSE: 2.60876) avg lploss: 0.00000
*** Best Val Loss: 2.41914 	 Best Test Loss: 2.51093 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 1.72402 (A-MSE: 1.54083) avg lploss: 0.00000
train epoch 112 avg loss: 1.57540 (A-MSE: 1.41055) avg lploss: 0.00000
train epoch 113 avg loss: 1.54716 (A-MSE: 1.38975) avg lploss: 0.00000
train epoch 114 avg loss: 1.62346 (A-MSE: 1.45042) avg lploss: 0.00000
train epoch 115 avg loss: 1.94145 (A-MSE: 1.74883) avg lploss: 0.00000
==> val epoch 115 avg loss: 2.44270 (A-MSE: 2.20783) avg lploss: 0.00000
==> test epoch 115 avg loss: 2.70954 (A-MSE: 2.45204) avg lploss: 0.00000
*** Best Val Loss: 2.41914 	 Best Test Loss: 2.51093 	 Best epoch 105
EarlyStopping counter: 2 out of 50
train epoch 116 avg loss: 1.76329 (A-MSE: 1.58015) avg lploss: 0.00000
train epoch 117 avg loss: 1.68213 (A-MSE: 1.51094) avg lploss: 0.00000
train epoch 118 avg loss: 1.59619 (A-MSE: 1.43770) avg lploss: 0.00000
train epoch 119 avg loss: 1.50908 (A-MSE: 1.34980) avg lploss: 0.00000
train epoch 120 avg loss: 1.64463 (A-MSE: 1.47523) avg lploss: 0.00000
==> val epoch 120 avg loss: 2.33310 (A-MSE: 2.13203) avg lploss: 0.00000
==> test epoch 120 avg loss: 2.47756 (A-MSE: 2.25551) avg lploss: 0.00000
*** Best Val Loss: 2.33310 	 Best Test Loss: 2.47756 	 Best epoch 120
Validation loss decreased (2.419143 --> 2.333104).  Saving model ...
train epoch 121 avg loss: 1.52073 (A-MSE: 1.37054) avg lploss: 0.00000
train epoch 122 avg loss: 1.47134 (A-MSE: 1.32440) avg lploss: 0.00000
train epoch 123 avg loss: 1.49064 (A-MSE: 1.33914) avg lploss: 0.00000
train epoch 124 avg loss: 1.71484 (A-MSE: 1.54699) avg lploss: 0.00000
train epoch 125 avg loss: 1.47912 (A-MSE: 1.33307) avg lploss: 0.00000
==> val epoch 125 avg loss: 1.77220 (A-MSE: 1.59561) avg lploss: 0.00000
==> test epoch 125 avg loss: 1.99421 (A-MSE: 1.79474) avg lploss: 0.00000
*** Best Val Loss: 1.77220 	 Best Test Loss: 1.99421 	 Best epoch 125
Validation loss decreased (2.333104 --> 1.772204).  Saving model ...
train epoch 126 avg loss: 1.50140 (A-MSE: 1.35124) avg lploss: 0.00000
train epoch 127 avg loss: 1.37671 (A-MSE: 1.23961) avg lploss: 0.00000
train epoch 128 avg loss: 1.38397 (A-MSE: 1.24704) avg lploss: 0.00000
train epoch 129 avg loss: 1.48740 (A-MSE: 1.33086) avg lploss: 0.00000
train epoch 130 avg loss: 1.41785 (A-MSE: 1.27024) avg lploss: 0.00000
==> val epoch 130 avg loss: 1.92635 (A-MSE: 1.73338) avg lploss: 0.00000
==> test epoch 130 avg loss: 2.21558 (A-MSE: 1.99156) avg lploss: 0.00000
*** Best Val Loss: 1.77220 	 Best Test Loss: 1.99421 	 Best epoch 125
EarlyStopping counter: 1 out of 50
train epoch 131 avg loss: 1.44307 (A-MSE: 1.29444) avg lploss: 0.00000
train epoch 132 avg loss: 1.45212 (A-MSE: 1.30353) avg lploss: 0.00000
train epoch 133 avg loss: 1.56736 (A-MSE: 1.40964) avg lploss: 0.00000
train epoch 134 avg loss: 1.44444 (A-MSE: 1.29912) avg lploss: 0.00000
train epoch 135 avg loss: 1.55965 (A-MSE: 1.40642) avg lploss: 0.00000
==> val epoch 135 avg loss: 2.35354 (A-MSE: 2.14961) avg lploss: 0.00000
==> test epoch 135 avg loss: 2.46507 (A-MSE: 2.23587) avg lploss: 0.00000
*** Best Val Loss: 1.77220 	 Best Test Loss: 1.99421 	 Best epoch 125
EarlyStopping counter: 2 out of 50
train epoch 136 avg loss: 1.45766 (A-MSE: 1.31253) avg lploss: 0.00000
train epoch 137 avg loss: 1.32425 (A-MSE: 1.19695) avg lploss: 0.00000
train epoch 138 avg loss: 1.28149 (A-MSE: 1.15209) avg lploss: 0.00000
train epoch 139 avg loss: 1.49732 (A-MSE: 1.34047) avg lploss: 0.00000
train epoch 140 avg loss: 1.67365 (A-MSE: 1.50131) avg lploss: 0.00000
==> val epoch 140 avg loss: 2.13647 (A-MSE: 1.94714) avg lploss: 0.00000
==> test epoch 140 avg loss: 2.30692 (A-MSE: 2.08915) avg lploss: 0.00000
*** Best Val Loss: 1.77220 	 Best Test Loss: 1.99421 	 Best epoch 125
EarlyStopping counter: 3 out of 50
train epoch 141 avg loss: 1.34585 (A-MSE: 1.20864) avg lploss: 0.00000
train epoch 142 avg loss: 1.36575 (A-MSE: 1.22490) avg lploss: 0.00000
train epoch 143 avg loss: 1.36427 (A-MSE: 1.23253) avg lploss: 0.00000
train epoch 144 avg loss: 1.19985 (A-MSE: 1.07701) avg lploss: 0.00000
train epoch 145 avg loss: 1.26791 (A-MSE: 1.13781) avg lploss: 0.00000
==> val epoch 145 avg loss: 1.67555 (A-MSE: 1.50851) avg lploss: 0.00000
==> test epoch 145 avg loss: 1.94311 (A-MSE: 1.73605) avg lploss: 0.00000
*** Best Val Loss: 1.67555 	 Best Test Loss: 1.94311 	 Best epoch 145
Validation loss decreased (1.772204 --> 1.675550).  Saving model ...
train epoch 146 avg loss: 1.33078 (A-MSE: 1.19761) avg lploss: 0.00000
train epoch 147 avg loss: 1.19278 (A-MSE: 1.07172) avg lploss: 0.00000
train epoch 148 avg loss: 1.19131 (A-MSE: 1.07316) avg lploss: 0.00000
train epoch 149 avg loss: 1.21706 (A-MSE: 1.09469) avg lploss: 0.00000
train epoch 150 avg loss: 1.26479 (A-MSE: 1.13645) avg lploss: 0.00000
==> val epoch 150 avg loss: 1.53431 (A-MSE: 1.37835) avg lploss: 0.00000
==> test epoch 150 avg loss: 1.74318 (A-MSE: 1.56096) avg lploss: 0.00000
*** Best Val Loss: 1.53431 	 Best Test Loss: 1.74318 	 Best epoch 150
Validation loss decreased (1.675550 --> 1.534309).  Saving model ...
train epoch 151 avg loss: 1.41520 (A-MSE: 1.27578) avg lploss: 0.00000
train epoch 152 avg loss: 1.65727 (A-MSE: 1.49149) avg lploss: 0.00000
train epoch 153 avg loss: 1.30729 (A-MSE: 1.17900) avg lploss: 0.00000
train epoch 154 avg loss: 1.22543 (A-MSE: 1.10267) avg lploss: 0.00000
train epoch 155 avg loss: 1.24315 (A-MSE: 1.11998) avg lploss: 0.00000
==> val epoch 155 avg loss: 1.56127 (A-MSE: 1.41164) avg lploss: 0.00000
==> test epoch 155 avg loss: 1.70950 (A-MSE: 1.54106) avg lploss: 0.00000
*** Best Val Loss: 1.53431 	 Best Test Loss: 1.74318 	 Best epoch 150
EarlyStopping counter: 1 out of 50
train epoch 156 avg loss: 1.13976 (A-MSE: 1.02205) avg lploss: 0.00000
train epoch 157 avg loss: 1.18513 (A-MSE: 1.06361) avg lploss: 0.00000
train epoch 158 avg loss: 1.13704 (A-MSE: 1.02210) avg lploss: 0.00000
train epoch 159 avg loss: 1.14784 (A-MSE: 1.02897) avg lploss: 0.00000
train epoch 160 avg loss: 1.15140 (A-MSE: 1.03281) avg lploss: 0.00000
==> val epoch 160 avg loss: 1.55401 (A-MSE: 1.39483) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.80973 (A-MSE: 1.62835) avg lploss: 0.00000
*** Best Val Loss: 1.53431 	 Best Test Loss: 1.74318 	 Best epoch 150
EarlyStopping counter: 2 out of 50
train epoch 161 avg loss: 1.15608 (A-MSE: 1.03844) avg lploss: 0.00000
train epoch 162 avg loss: 1.25836 (A-MSE: 1.13061) avg lploss: 0.00000
train epoch 163 avg loss: 1.10970 (A-MSE: 0.99626) avg lploss: 0.00000
train epoch 164 avg loss: 1.02853 (A-MSE: 0.92343) avg lploss: 0.00000
train epoch 165 avg loss: 1.09826 (A-MSE: 0.98711) avg lploss: 0.00000
==> val epoch 165 avg loss: 1.62328 (A-MSE: 1.47682) avg lploss: 0.00000
==> test epoch 165 avg loss: 1.80709 (A-MSE: 1.63491) avg lploss: 0.00000
*** Best Val Loss: 1.53431 	 Best Test Loss: 1.74318 	 Best epoch 150
EarlyStopping counter: 3 out of 50
train epoch 166 avg loss: 1.17624 (A-MSE: 1.05537) avg lploss: 0.00000
train epoch 167 avg loss: 1.35183 (A-MSE: 1.21795) avg lploss: 0.00000
train epoch 168 avg loss: 1.37984 (A-MSE: 1.24765) avg lploss: 0.00000
train epoch 169 avg loss: 1.17727 (A-MSE: 1.05849) avg lploss: 0.00000
train epoch 170 avg loss: 1.10047 (A-MSE: 0.98777) avg lploss: 0.00000
==> val epoch 170 avg loss: 1.95748 (A-MSE: 1.74860) avg lploss: 0.00000
==> test epoch 170 avg loss: 2.05427 (A-MSE: 1.82524) avg lploss: 0.00000
*** Best Val Loss: 1.53431 	 Best Test Loss: 1.74318 	 Best epoch 150
EarlyStopping counter: 4 out of 50
train epoch 171 avg loss: 1.21561 (A-MSE: 1.09343) avg lploss: 0.00000
train epoch 172 avg loss: 0.99643 (A-MSE: 0.90111) avg lploss: 0.00000
train epoch 173 avg loss: 1.06633 (A-MSE: 0.96069) avg lploss: 0.00000
train epoch 174 avg loss: 1.06650 (A-MSE: 0.95606) avg lploss: 0.00000
train epoch 175 avg loss: 1.03690 (A-MSE: 0.93162) avg lploss: 0.00000
==> val epoch 175 avg loss: 1.43976 (A-MSE: 1.30657) avg lploss: 0.00000
==> test epoch 175 avg loss: 1.65709 (A-MSE: 1.48999) avg lploss: 0.00000
*** Best Val Loss: 1.43976 	 Best Test Loss: 1.65709 	 Best epoch 175
Validation loss decreased (1.534309 --> 1.439760).  Saving model ...
train epoch 176 avg loss: 0.94999 (A-MSE: 0.85097) avg lploss: 0.00000
train epoch 177 avg loss: 1.01903 (A-MSE: 0.91362) avg lploss: 0.00000
train epoch 178 avg loss: 1.03694 (A-MSE: 0.92536) avg lploss: 0.00000
train epoch 179 avg loss: 0.99782 (A-MSE: 0.90015) avg lploss: 0.00000
train epoch 180 avg loss: 0.99254 (A-MSE: 0.89352) avg lploss: 0.00000
==> val epoch 180 avg loss: 1.51469 (A-MSE: 1.35166) avg lploss: 0.00000
==> test epoch 180 avg loss: 1.79248 (A-MSE: 1.59786) avg lploss: 0.00000
*** Best Val Loss: 1.43976 	 Best Test Loss: 1.65709 	 Best epoch 175
EarlyStopping counter: 1 out of 50
train epoch 181 avg loss: 0.97635 (A-MSE: 0.87594) avg lploss: 0.00000
train epoch 182 avg loss: 1.27645 (A-MSE: 1.15313) avg lploss: 0.00000
train epoch 183 avg loss: 1.13346 (A-MSE: 1.01416) avg lploss: 0.00000
train epoch 184 avg loss: 1.00758 (A-MSE: 0.90759) avg lploss: 0.00000
train epoch 185 avg loss: 0.94055 (A-MSE: 0.84206) avg lploss: 0.00000
==> val epoch 185 avg loss: 1.40206 (A-MSE: 1.28634) avg lploss: 0.00000
==> test epoch 185 avg loss: 1.64320 (A-MSE: 1.50191) avg lploss: 0.00000
*** Best Val Loss: 1.40206 	 Best Test Loss: 1.64320 	 Best epoch 185
Validation loss decreased (1.439760 --> 1.402061).  Saving model ...
train epoch 186 avg loss: 1.02736 (A-MSE: 0.92347) avg lploss: 0.00000
train epoch 187 avg loss: 0.97779 (A-MSE: 0.87656) avg lploss: 0.00000
train epoch 188 avg loss: 1.02592 (A-MSE: 0.92655) avg lploss: 0.00000
train epoch 189 avg loss: 1.08895 (A-MSE: 0.98043) avg lploss: 0.00000
train epoch 190 avg loss: 0.98785 (A-MSE: 0.88941) avg lploss: 0.00000
==> val epoch 190 avg loss: 1.35892 (A-MSE: 1.23051) avg lploss: 0.00000
==> test epoch 190 avg loss: 1.52966 (A-MSE: 1.37636) avg lploss: 0.00000
*** Best Val Loss: 1.35892 	 Best Test Loss: 1.52966 	 Best epoch 190
Validation loss decreased (1.402061 --> 1.358924).  Saving model ...
train epoch 191 avg loss: 0.98694 (A-MSE: 0.88502) avg lploss: 0.00000
train epoch 192 avg loss: 0.96569 (A-MSE: 0.86207) avg lploss: 0.00000
train epoch 193 avg loss: 0.93243 (A-MSE: 0.83945) avg lploss: 0.00000
train epoch 194 avg loss: 0.97090 (A-MSE: 0.86976) avg lploss: 0.00000
train epoch 195 avg loss: 1.00188 (A-MSE: 0.89901) avg lploss: 0.00000
==> val epoch 195 avg loss: 1.34914 (A-MSE: 1.22538) avg lploss: 0.00000
==> test epoch 195 avg loss: 1.54485 (A-MSE: 1.39330) avg lploss: 0.00000
*** Best Val Loss: 1.34914 	 Best Test Loss: 1.54485 	 Best epoch 195
Validation loss decreased (1.358924 --> 1.349135).  Saving model ...
train epoch 196 avg loss: 0.94242 (A-MSE: 0.84847) avg lploss: 0.00000
train epoch 197 avg loss: 0.90730 (A-MSE: 0.81649) avg lploss: 0.00000
train epoch 198 avg loss: 0.88972 (A-MSE: 0.79864) avg lploss: 0.00000
train epoch 199 avg loss: 0.92584 (A-MSE: 0.83000) avg lploss: 0.00000
train epoch 200 avg loss: 0.98033 (A-MSE: 0.88223) avg lploss: 0.00000
==> val epoch 200 avg loss: 1.56078 (A-MSE: 1.42624) avg lploss: 0.00000
==> test epoch 200 avg loss: 1.81179 (A-MSE: 1.63648) avg lploss: 0.00000
*** Best Val Loss: 1.34914 	 Best Test Loss: 1.54485 	 Best epoch 195
EarlyStopping counter: 1 out of 50
train epoch 201 avg loss: 0.97411 (A-MSE: 0.87781) avg lploss: 0.00000
train epoch 202 avg loss: 0.95827 (A-MSE: 0.85841) avg lploss: 0.00000
train epoch 203 avg loss: 0.91332 (A-MSE: 0.82233) avg lploss: 0.00000
train epoch 204 avg loss: 0.92644 (A-MSE: 0.83023) avg lploss: 0.00000
train epoch 205 avg loss: 0.84940 (A-MSE: 0.76248) avg lploss: 0.00000
==> val epoch 205 avg loss: 1.27869 (A-MSE: 1.19100) avg lploss: 0.00000
==> test epoch 205 avg loss: 1.50599 (A-MSE: 1.38982) avg lploss: 0.00000
*** Best Val Loss: 1.27869 	 Best Test Loss: 1.50599 	 Best epoch 205
Validation loss decreased (1.349135 --> 1.278689).  Saving model ...
train epoch 206 avg loss: 0.84190 (A-MSE: 0.75795) avg lploss: 0.00000
train epoch 207 avg loss: 0.83283 (A-MSE: 0.74571) avg lploss: 0.00000
train epoch 208 avg loss: 0.84002 (A-MSE: 0.75683) avg lploss: 0.00000
train epoch 209 avg loss: 0.86758 (A-MSE: 0.77793) avg lploss: 0.00000
train epoch 210 avg loss: 0.93282 (A-MSE: 0.83481) avg lploss: 0.00000
==> val epoch 210 avg loss: 1.17141 (A-MSE: 1.07357) avg lploss: 0.00000
==> test epoch 210 avg loss: 1.36384 (A-MSE: 1.24170) avg lploss: 0.00000
*** Best Val Loss: 1.17141 	 Best Test Loss: 1.36384 	 Best epoch 210
Validation loss decreased (1.278689 --> 1.171414).  Saving model ...
train epoch 211 avg loss: 0.90899 (A-MSE: 0.81653) avg lploss: 0.00000
train epoch 212 avg loss: 0.98073 (A-MSE: 0.88233) avg lploss: 0.00000
train epoch 213 avg loss: 0.89210 (A-MSE: 0.79840) avg lploss: 0.00000
train epoch 214 avg loss: 0.90786 (A-MSE: 0.81786) avg lploss: 0.00000
train epoch 215 avg loss: 0.92802 (A-MSE: 0.82940) avg lploss: 0.00000
==> val epoch 215 avg loss: 1.16931 (A-MSE: 1.05752) avg lploss: 0.00000
==> test epoch 215 avg loss: 1.35559 (A-MSE: 1.22567) avg lploss: 0.00000
*** Best Val Loss: 1.16931 	 Best Test Loss: 1.35559 	 Best epoch 215
Validation loss decreased (1.171414 --> 1.169307).  Saving model ...
train epoch 216 avg loss: 0.88218 (A-MSE: 0.79436) avg lploss: 0.00000
train epoch 217 avg loss: 0.90008 (A-MSE: 0.81115) avg lploss: 0.00000
train epoch 218 avg loss: 0.93470 (A-MSE: 0.84572) avg lploss: 0.00000
train epoch 219 avg loss: 0.93663 (A-MSE: 0.84683) avg lploss: 0.00000
train epoch 220 avg loss: 0.91086 (A-MSE: 0.81827) avg lploss: 0.00000
==> val epoch 220 avg loss: 1.19143 (A-MSE: 1.09093) avg lploss: 0.00000
==> test epoch 220 avg loss: 1.35112 (A-MSE: 1.23231) avg lploss: 0.00000
*** Best Val Loss: 1.16931 	 Best Test Loss: 1.35559 	 Best epoch 215
EarlyStopping counter: 1 out of 50
train epoch 221 avg loss: 0.85980 (A-MSE: 0.77174) avg lploss: 0.00000
train epoch 222 avg loss: 0.96937 (A-MSE: 0.87306) avg lploss: 0.00000
train epoch 223 avg loss: 0.90665 (A-MSE: 0.81422) avg lploss: 0.00000
train epoch 224 avg loss: 0.86339 (A-MSE: 0.77582) avg lploss: 0.00000
train epoch 225 avg loss: 0.80299 (A-MSE: 0.72319) avg lploss: 0.00000
==> val epoch 225 avg loss: 1.16993 (A-MSE: 1.07733) avg lploss: 0.00000
==> test epoch 225 avg loss: 1.41373 (A-MSE: 1.29422) avg lploss: 0.00000
*** Best Val Loss: 1.16931 	 Best Test Loss: 1.35559 	 Best epoch 215
EarlyStopping counter: 2 out of 50
train epoch 226 avg loss: 0.90433 (A-MSE: 0.81829) avg lploss: 0.00000
train epoch 227 avg loss: 0.89500 (A-MSE: 0.80327) avg lploss: 0.00000
train epoch 228 avg loss: 0.83071 (A-MSE: 0.74722) avg lploss: 0.00000
train epoch 229 avg loss: 0.76659 (A-MSE: 0.68905) avg lploss: 0.00000
train epoch 230 avg loss: 0.78573 (A-MSE: 0.70377) avg lploss: 0.00000
==> val epoch 230 avg loss: 1.46768 (A-MSE: 1.32255) avg lploss: 0.00000
==> test epoch 230 avg loss: 1.53348 (A-MSE: 1.36560) avg lploss: 0.00000
*** Best Val Loss: 1.16931 	 Best Test Loss: 1.35559 	 Best epoch 215
EarlyStopping counter: 3 out of 50
train epoch 231 avg loss: 0.84028 (A-MSE: 0.75351) avg lploss: 0.00000
train epoch 232 avg loss: 0.88256 (A-MSE: 0.79815) avg lploss: 0.00000
train epoch 233 avg loss: 0.79686 (A-MSE: 0.71770) avg lploss: 0.00000
train epoch 234 avg loss: 0.88410 (A-MSE: 0.79663) avg lploss: 0.00000
train epoch 235 avg loss: 0.81059 (A-MSE: 0.72739) avg lploss: 0.00000
==> val epoch 235 avg loss: 1.15875 (A-MSE: 1.04372) avg lploss: 0.00000
==> test epoch 235 avg loss: 1.34797 (A-MSE: 1.21993) avg lploss: 0.00000
*** Best Val Loss: 1.15875 	 Best Test Loss: 1.34797 	 Best epoch 235
Validation loss decreased (1.169307 --> 1.158749).  Saving model ...
train epoch 236 avg loss: 0.81039 (A-MSE: 0.73003) avg lploss: 0.00000
train epoch 237 avg loss: 0.82336 (A-MSE: 0.73797) avg lploss: 0.00000
train epoch 238 avg loss: 0.79845 (A-MSE: 0.71402) avg lploss: 0.00000
train epoch 239 avg loss: 0.75602 (A-MSE: 0.67471) avg lploss: 0.00000
train epoch 240 avg loss: 0.75495 (A-MSE: 0.68018) avg lploss: 0.00000
==> val epoch 240 avg loss: 1.12959 (A-MSE: 1.01958) avg lploss: 0.00000
==> test epoch 240 avg loss: 1.35114 (A-MSE: 1.21677) avg lploss: 0.00000
*** Best Val Loss: 1.12959 	 Best Test Loss: 1.35114 	 Best epoch 240
Validation loss decreased (1.158749 --> 1.129594).  Saving model ...
train epoch 241 avg loss: 0.80718 (A-MSE: 0.72059) avg lploss: 0.00000
train epoch 242 avg loss: 0.77802 (A-MSE: 0.69956) avg lploss: 0.00000
train epoch 243 avg loss: 0.80610 (A-MSE: 0.72172) avg lploss: 0.00000
train epoch 244 avg loss: 0.81051 (A-MSE: 0.72794) avg lploss: 0.00000
train epoch 245 avg loss: 0.91440 (A-MSE: 0.82141) avg lploss: 0.00000
==> val epoch 245 avg loss: 1.91443 (A-MSE: 1.69010) avg lploss: 0.00000
==> test epoch 245 avg loss: 2.08068 (A-MSE: 1.83276) avg lploss: 0.00000
*** Best Val Loss: 1.12959 	 Best Test Loss: 1.35114 	 Best epoch 240
EarlyStopping counter: 1 out of 50
train epoch 246 avg loss: 0.87814 (A-MSE: 0.78543) avg lploss: 0.00000
train epoch 247 avg loss: 0.74647 (A-MSE: 0.67028) avg lploss: 0.00000
train epoch 248 avg loss: 0.69361 (A-MSE: 0.62036) avg lploss: 0.00000
train epoch 249 avg loss: 0.72219 (A-MSE: 0.64631) avg lploss: 0.00000
train epoch 250 avg loss: 0.69947 (A-MSE: 0.62798) avg lploss: 0.00000
==> val epoch 250 avg loss: 1.05797 (A-MSE: 0.96054) avg lploss: 0.00000
==> test epoch 250 avg loss: 1.25228 (A-MSE: 1.13088) avg lploss: 0.00000
*** Best Val Loss: 1.05797 	 Best Test Loss: 1.25228 	 Best epoch 250
Validation loss decreased (1.129594 --> 1.057972).  Saving model ...
train epoch 251 avg loss: 0.76100 (A-MSE: 0.68551) avg lploss: 0.00000
train epoch 252 avg loss: 0.91401 (A-MSE: 0.82325) avg lploss: 0.00000
train epoch 253 avg loss: 0.80853 (A-MSE: 0.73199) avg lploss: 0.00000
train epoch 254 avg loss: 0.87666 (A-MSE: 0.79761) avg lploss: 0.00000
train epoch 255 avg loss: 0.85076 (A-MSE: 0.76791) avg lploss: 0.00000
==> val epoch 255 avg loss: 1.11660 (A-MSE: 1.01939) avg lploss: 0.00000
==> test epoch 255 avg loss: 1.20005 (A-MSE: 1.09612) avg lploss: 0.00000
*** Best Val Loss: 1.05797 	 Best Test Loss: 1.25228 	 Best epoch 250
EarlyStopping counter: 1 out of 50
train epoch 256 avg loss: 0.75970 (A-MSE: 0.67993) avg lploss: 0.00000
train epoch 257 avg loss: 0.72577 (A-MSE: 0.64927) avg lploss: 0.00000
train epoch 258 avg loss: 0.69170 (A-MSE: 0.62168) avg lploss: 0.00000
train epoch 259 avg loss: 0.72946 (A-MSE: 0.65932) avg lploss: 0.00000
train epoch 260 avg loss: 0.72823 (A-MSE: 0.65716) avg lploss: 0.00000
==> val epoch 260 avg loss: 1.03611 (A-MSE: 0.93845) avg lploss: 0.00000
==> test epoch 260 avg loss: 1.24399 (A-MSE: 1.12422) avg lploss: 0.00000
*** Best Val Loss: 1.03611 	 Best Test Loss: 1.24399 	 Best epoch 260
Validation loss decreased (1.057972 --> 1.036109).  Saving model ...
train epoch 261 avg loss: 0.64625 (A-MSE: 0.57956) avg lploss: 0.00000
train epoch 262 avg loss: 0.81240 (A-MSE: 0.73704) avg lploss: 0.00000
train epoch 263 avg loss: 0.81868 (A-MSE: 0.72499) avg lploss: 0.00000
train epoch 264 avg loss: 0.71284 (A-MSE: 0.64063) avg lploss: 0.00000
train epoch 265 avg loss: 0.76442 (A-MSE: 0.68720) avg lploss: 0.00000
==> val epoch 265 avg loss: 1.06032 (A-MSE: 0.95903) avg lploss: 0.00000
==> test epoch 265 avg loss: 1.18675 (A-MSE: 1.07155) avg lploss: 0.00000
*** Best Val Loss: 1.03611 	 Best Test Loss: 1.24399 	 Best epoch 260
EarlyStopping counter: 1 out of 50
train epoch 266 avg loss: 0.72900 (A-MSE: 0.65400) avg lploss: 0.00000
train epoch 267 avg loss: 0.71674 (A-MSE: 0.64471) avg lploss: 0.00000
train epoch 268 avg loss: 0.75872 (A-MSE: 0.68400) avg lploss: 0.00000
train epoch 269 avg loss: 0.70437 (A-MSE: 0.62809) avg lploss: 0.00000
train epoch 270 avg loss: 0.73579 (A-MSE: 0.66061) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.99404 (A-MSE: 0.90613) avg lploss: 0.00000
==> test epoch 270 avg loss: 1.14111 (A-MSE: 1.04500) avg lploss: 0.00000
*** Best Val Loss: 0.99404 	 Best Test Loss: 1.14111 	 Best epoch 270
Validation loss decreased (1.036109 --> 0.994042).  Saving model ...
train epoch 271 avg loss: 0.65447 (A-MSE: 0.58252) avg lploss: 0.00000
train epoch 272 avg loss: 0.65758 (A-MSE: 0.59019) avg lploss: 0.00000
train epoch 273 avg loss: 0.65863 (A-MSE: 0.59140) avg lploss: 0.00000
train epoch 274 avg loss: 0.64610 (A-MSE: 0.57858) avg lploss: 0.00000
train epoch 275 avg loss: 0.69216 (A-MSE: 0.62139) avg lploss: 0.00000
==> val epoch 275 avg loss: 1.07627 (A-MSE: 0.99041) avg lploss: 0.00000
==> test epoch 275 avg loss: 1.23198 (A-MSE: 1.13308) avg lploss: 0.00000
*** Best Val Loss: 0.99404 	 Best Test Loss: 1.14111 	 Best epoch 270
EarlyStopping counter: 1 out of 50
train epoch 276 avg loss: 0.75888 (A-MSE: 0.68626) avg lploss: 0.00000
train epoch 277 avg loss: 0.78027 (A-MSE: 0.69917) avg lploss: 0.00000
train epoch 278 avg loss: 0.70156 (A-MSE: 0.63212) avg lploss: 0.00000
train epoch 279 avg loss: 0.65741 (A-MSE: 0.58403) avg lploss: 0.00000
train epoch 280 avg loss: 0.69379 (A-MSE: 0.62012) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.95728 (A-MSE: 0.87160) avg lploss: 0.00000
==> test epoch 280 avg loss: 1.10904 (A-MSE: 1.01019) avg lploss: 0.00000
*** Best Val Loss: 0.95728 	 Best Test Loss: 1.10904 	 Best epoch 280
Validation loss decreased (0.994042 --> 0.957278).  Saving model ...
train epoch 281 avg loss: 0.62461 (A-MSE: 0.56016) avg lploss: 0.00000
train epoch 282 avg loss: 0.63736 (A-MSE: 0.57150) avg lploss: 0.00000
train epoch 283 avg loss: 0.67494 (A-MSE: 0.60509) avg lploss: 0.00000
train epoch 284 avg loss: 0.68595 (A-MSE: 0.61330) avg lploss: 0.00000
train epoch 285 avg loss: 0.66274 (A-MSE: 0.59146) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.96978 (A-MSE: 0.88279) avg lploss: 0.00000
==> test epoch 285 avg loss: 1.14531 (A-MSE: 1.03831) avg lploss: 0.00000
*** Best Val Loss: 0.95728 	 Best Test Loss: 1.10904 	 Best epoch 280
EarlyStopping counter: 1 out of 50
train epoch 286 avg loss: 0.63410 (A-MSE: 0.56895) avg lploss: 0.00000
train epoch 287 avg loss: 0.70908 (A-MSE: 0.63557) avg lploss: 0.00000
train epoch 288 avg loss: 0.60718 (A-MSE: 0.54620) avg lploss: 0.00000
train epoch 289 avg loss: 0.65476 (A-MSE: 0.59121) avg lploss: 0.00000
train epoch 290 avg loss: 0.59998 (A-MSE: 0.53587) avg lploss: 0.00000
==> val epoch 290 avg loss: 1.10609 (A-MSE: 1.02003) avg lploss: 0.00000
==> test epoch 290 avg loss: 1.24581 (A-MSE: 1.14655) avg lploss: 0.00000
*** Best Val Loss: 0.95728 	 Best Test Loss: 1.10904 	 Best epoch 280
EarlyStopping counter: 2 out of 50
train epoch 291 avg loss: 0.63000 (A-MSE: 0.56806) avg lploss: 0.00000
train epoch 292 avg loss: 0.62382 (A-MSE: 0.56201) avg lploss: 0.00000
train epoch 293 avg loss: 0.63428 (A-MSE: 0.57476) avg lploss: 0.00000
train epoch 294 avg loss: 0.58910 (A-MSE: 0.53003) avg lploss: 0.00000
train epoch 295 avg loss: 0.66027 (A-MSE: 0.59483) avg lploss: 0.00000
==> val epoch 295 avg loss: 1.09434 (A-MSE: 0.99239) avg lploss: 0.00000
==> test epoch 295 avg loss: 1.25777 (A-MSE: 1.13515) avg lploss: 0.00000
*** Best Val Loss: 0.95728 	 Best Test Loss: 1.10904 	 Best epoch 280
EarlyStopping counter: 3 out of 50
train epoch 296 avg loss: 0.64072 (A-MSE: 0.57898) avg lploss: 0.00000
train epoch 297 avg loss: 0.62286 (A-MSE: 0.55795) avg lploss: 0.00000
train epoch 298 avg loss: 0.72319 (A-MSE: 0.65180) avg lploss: 0.00000
train epoch 299 avg loss: 0.77841 (A-MSE: 0.69449) avg lploss: 0.00000
train epoch 300 avg loss: 0.58206 (A-MSE: 0.52537) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.91196 (A-MSE: 0.82765) avg lploss: 0.00000
==> test epoch 300 avg loss: 1.07236 (A-MSE: 0.97341) avg lploss: 0.00000
*** Best Val Loss: 0.91196 	 Best Test Loss: 1.07236 	 Best epoch 300
Validation loss decreased (0.957278 --> 0.911956).  Saving model ...
train epoch 301 avg loss: 0.55173 (A-MSE: 0.49334) avg lploss: 0.00000
train epoch 302 avg loss: 0.57590 (A-MSE: 0.51814) avg lploss: 0.00000
train epoch 303 avg loss: 0.61220 (A-MSE: 0.54884) avg lploss: 0.00000
train epoch 304 avg loss: 0.59681 (A-MSE: 0.53748) avg lploss: 0.00000
train epoch 305 avg loss: 0.62005 (A-MSE: 0.55640) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.97380 (A-MSE: 0.88529) avg lploss: 0.00000
==> test epoch 305 avg loss: 1.09874 (A-MSE: 0.99537) avg lploss: 0.00000
*** Best Val Loss: 0.91196 	 Best Test Loss: 1.07236 	 Best epoch 300
EarlyStopping counter: 1 out of 50
train epoch 306 avg loss: 0.61394 (A-MSE: 0.55025) avg lploss: 0.00000
train epoch 307 avg loss: 0.63198 (A-MSE: 0.57237) avg lploss: 0.00000
train epoch 308 avg loss: 0.57526 (A-MSE: 0.51754) avg lploss: 0.00000
train epoch 309 avg loss: 0.58632 (A-MSE: 0.52508) avg lploss: 0.00000
train epoch 310 avg loss: 0.56139 (A-MSE: 0.50104) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.90345 (A-MSE: 0.82287) avg lploss: 0.00000
==> test epoch 310 avg loss: 1.02122 (A-MSE: 0.93414) avg lploss: 0.00000
*** Best Val Loss: 0.90345 	 Best Test Loss: 1.02122 	 Best epoch 310
Validation loss decreased (0.911956 --> 0.903448).  Saving model ...
train epoch 311 avg loss: 0.57997 (A-MSE: 0.52297) avg lploss: 0.00000
train epoch 312 avg loss: 0.57340 (A-MSE: 0.51612) avg lploss: 0.00000
train epoch 313 avg loss: 0.56893 (A-MSE: 0.51275) avg lploss: 0.00000
train epoch 314 avg loss: 0.63526 (A-MSE: 0.57411) avg lploss: 0.00000
train epoch 315 avg loss: 0.60229 (A-MSE: 0.54447) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.90440 (A-MSE: 0.81663) avg lploss: 0.00000
==> test epoch 315 avg loss: 1.04178 (A-MSE: 0.94063) avg lploss: 0.00000
*** Best Val Loss: 0.90345 	 Best Test Loss: 1.02122 	 Best epoch 310
EarlyStopping counter: 1 out of 50
train epoch 316 avg loss: 0.62874 (A-MSE: 0.56459) avg lploss: 0.00000
train epoch 317 avg loss: 0.58971 (A-MSE: 0.53123) avg lploss: 0.00000
train epoch 318 avg loss: 0.59379 (A-MSE: 0.53417) avg lploss: 0.00000
train epoch 319 avg loss: 0.57485 (A-MSE: 0.51668) avg lploss: 0.00000
train epoch 320 avg loss: 0.67852 (A-MSE: 0.61321) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.99965 (A-MSE: 0.93294) avg lploss: 0.00000
==> test epoch 320 avg loss: 1.15596 (A-MSE: 1.07868) avg lploss: 0.00000
*** Best Val Loss: 0.90345 	 Best Test Loss: 1.02122 	 Best epoch 310
EarlyStopping counter: 2 out of 50
train epoch 321 avg loss: 0.69062 (A-MSE: 0.62588) avg lploss: 0.00000
train epoch 322 avg loss: 0.67680 (A-MSE: 0.61267) avg lploss: 0.00000
train epoch 323 avg loss: 0.60147 (A-MSE: 0.54164) avg lploss: 0.00000
train epoch 324 avg loss: 0.69189 (A-MSE: 0.61946) avg lploss: 0.00000
train epoch 325 avg loss: 0.53649 (A-MSE: 0.48364) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.81005 (A-MSE: 0.74226) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.95430 (A-MSE: 0.87506) avg lploss: 0.00000
*** Best Val Loss: 0.81005 	 Best Test Loss: 0.95430 	 Best epoch 325
Validation loss decreased (0.903448 --> 0.810047).  Saving model ...
train epoch 326 avg loss: 0.53562 (A-MSE: 0.48215) avg lploss: 0.00000
train epoch 327 avg loss: 0.64930 (A-MSE: 0.58837) avg lploss: 0.00000
train epoch 328 avg loss: 0.64559 (A-MSE: 0.58183) avg lploss: 0.00000
train epoch 329 avg loss: 0.61609 (A-MSE: 0.55797) avg lploss: 0.00000
train epoch 330 avg loss: 0.55157 (A-MSE: 0.49563) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.81242 (A-MSE: 0.74354) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.95808 (A-MSE: 0.87295) avg lploss: 0.00000
*** Best Val Loss: 0.81005 	 Best Test Loss: 0.95430 	 Best epoch 325
EarlyStopping counter: 1 out of 50
train epoch 331 avg loss: 0.52365 (A-MSE: 0.47096) avg lploss: 0.00000
train epoch 332 avg loss: 0.53409 (A-MSE: 0.48128) avg lploss: 0.00000
train epoch 333 avg loss: 0.50479 (A-MSE: 0.45575) avg lploss: 0.00000
train epoch 334 avg loss: 0.51748 (A-MSE: 0.46573) avg lploss: 0.00000
train epoch 335 avg loss: 0.56900 (A-MSE: 0.51649) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.97549 (A-MSE: 0.87992) avg lploss: 0.00000
==> test epoch 335 avg loss: 1.09307 (A-MSE: 0.99099) avg lploss: 0.00000
*** Best Val Loss: 0.81005 	 Best Test Loss: 0.95430 	 Best epoch 325
EarlyStopping counter: 2 out of 50
train epoch 336 avg loss: 0.60956 (A-MSE: 0.55322) avg lploss: 0.00000
train epoch 337 avg loss: 0.58024 (A-MSE: 0.52210) avg lploss: 0.00000
train epoch 338 avg loss: 0.53076 (A-MSE: 0.47892) avg lploss: 0.00000
train epoch 339 avg loss: 0.49902 (A-MSE: 0.44787) avg lploss: 0.00000
train epoch 340 avg loss: 0.49986 (A-MSE: 0.45064) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.96311 (A-MSE: 0.89780) avg lploss: 0.00000
==> test epoch 340 avg loss: 1.08417 (A-MSE: 1.01145) avg lploss: 0.00000
*** Best Val Loss: 0.81005 	 Best Test Loss: 0.95430 	 Best epoch 325
EarlyStopping counter: 3 out of 50
train epoch 341 avg loss: 0.56384 (A-MSE: 0.50927) avg lploss: 0.00000
train epoch 342 avg loss: 0.52088 (A-MSE: 0.46900) avg lploss: 0.00000
train epoch 343 avg loss: 0.60737 (A-MSE: 0.54514) avg lploss: 0.00000
train epoch 344 avg loss: 0.70396 (A-MSE: 0.62636) avg lploss: 0.00000
train epoch 345 avg loss: 0.60120 (A-MSE: 0.54888) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.86403 (A-MSE: 0.79935) avg lploss: 0.00000
==> test epoch 345 avg loss: 1.01934 (A-MSE: 0.94798) avg lploss: 0.00000
*** Best Val Loss: 0.81005 	 Best Test Loss: 0.95430 	 Best epoch 325
EarlyStopping counter: 4 out of 50
train epoch 346 avg loss: 0.65790 (A-MSE: 0.59690) avg lploss: 0.00000
train epoch 347 avg loss: 0.68170 (A-MSE: 0.61515) avg lploss: 0.00000
train epoch 348 avg loss: 0.49799 (A-MSE: 0.45040) avg lploss: 0.00000
train epoch 349 avg loss: 0.49103 (A-MSE: 0.44452) avg lploss: 0.00000
train epoch 350 avg loss: 0.50871 (A-MSE: 0.45949) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.80444 (A-MSE: 0.73822) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.89760 (A-MSE: 0.82373) avg lploss: 0.00000
*** Best Val Loss: 0.80444 	 Best Test Loss: 0.89760 	 Best epoch 350
Validation loss decreased (0.810047 --> 0.804436).  Saving model ...
train epoch 351 avg loss: 0.51443 (A-MSE: 0.46481) avg lploss: 0.00000
train epoch 352 avg loss: 0.50372 (A-MSE: 0.45473) avg lploss: 0.00000
train epoch 353 avg loss: 0.49906 (A-MSE: 0.44886) avg lploss: 0.00000
train epoch 354 avg loss: 0.48369 (A-MSE: 0.43848) avg lploss: 0.00000
train epoch 355 avg loss: 0.54302 (A-MSE: 0.49025) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.90637 (A-MSE: 0.81899) avg lploss: 0.00000
==> test epoch 355 avg loss: 1.02972 (A-MSE: 0.93737) avg lploss: 0.00000
*** Best Val Loss: 0.80444 	 Best Test Loss: 0.89760 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.54417 (A-MSE: 0.49372) avg lploss: 0.00000
train epoch 357 avg loss: 0.51610 (A-MSE: 0.46805) avg lploss: 0.00000
train epoch 358 avg loss: 0.48281 (A-MSE: 0.43344) avg lploss: 0.00000
train epoch 359 avg loss: 0.45326 (A-MSE: 0.40775) avg lploss: 0.00000
train epoch 360 avg loss: 0.45644 (A-MSE: 0.41400) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.83908 (A-MSE: 0.76238) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.95939 (A-MSE: 0.86617) avg lploss: 0.00000
*** Best Val Loss: 0.80444 	 Best Test Loss: 0.89760 	 Best epoch 350
EarlyStopping counter: 2 out of 50
train epoch 361 avg loss: 0.50776 (A-MSE: 0.45566) avg lploss: 0.00000
train epoch 362 avg loss: 0.52547 (A-MSE: 0.47272) avg lploss: 0.00000
train epoch 363 avg loss: 0.53200 (A-MSE: 0.48104) avg lploss: 0.00000
train epoch 364 avg loss: 0.47685 (A-MSE: 0.42932) avg lploss: 0.00000
train epoch 365 avg loss: 0.49806 (A-MSE: 0.44644) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.88449 (A-MSE: 0.81638) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.99729 (A-MSE: 0.91982) avg lploss: 0.00000
*** Best Val Loss: 0.80444 	 Best Test Loss: 0.89760 	 Best epoch 350
EarlyStopping counter: 3 out of 50
train epoch 366 avg loss: 0.47635 (A-MSE: 0.42788) avg lploss: 0.00000
train epoch 367 avg loss: 0.45065 (A-MSE: 0.40713) avg lploss: 0.00000
train epoch 368 avg loss: 0.46565 (A-MSE: 0.42079) avg lploss: 0.00000
train epoch 369 avg loss: 0.47789 (A-MSE: 0.43215) avg lploss: 0.00000
train epoch 370 avg loss: 0.48037 (A-MSE: 0.43226) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.77025 (A-MSE: 0.71005) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.90254 (A-MSE: 0.83035) avg lploss: 0.00000
*** Best Val Loss: 0.77025 	 Best Test Loss: 0.90254 	 Best epoch 370
Validation loss decreased (0.804436 --> 0.770247).  Saving model ...
train epoch 371 avg loss: 0.52891 (A-MSE: 0.47856) avg lploss: 0.00000
train epoch 372 avg loss: 0.53608 (A-MSE: 0.48355) avg lploss: 0.00000
train epoch 373 avg loss: 0.48823 (A-MSE: 0.44276) avg lploss: 0.00000
train epoch 374 avg loss: 0.46301 (A-MSE: 0.41867) avg lploss: 0.00000
train epoch 375 avg loss: 0.44685 (A-MSE: 0.40327) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.92753 (A-MSE: 0.83939) avg lploss: 0.00000
==> test epoch 375 avg loss: 1.02917 (A-MSE: 0.92682) avg lploss: 0.00000
*** Best Val Loss: 0.77025 	 Best Test Loss: 0.90254 	 Best epoch 370
EarlyStopping counter: 1 out of 50
train epoch 376 avg loss: 0.46370 (A-MSE: 0.42202) avg lploss: 0.00000
train epoch 377 avg loss: 0.48171 (A-MSE: 0.43273) avg lploss: 0.00000
train epoch 378 avg loss: 0.49403 (A-MSE: 0.44908) avg lploss: 0.00000
train epoch 379 avg loss: 0.42800 (A-MSE: 0.38712) avg lploss: 0.00000
train epoch 380 avg loss: 0.44135 (A-MSE: 0.39589) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.76844 (A-MSE: 0.70617) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.89806 (A-MSE: 0.82182) avg lploss: 0.00000
*** Best Val Loss: 0.76844 	 Best Test Loss: 0.89806 	 Best epoch 380
Validation loss decreased (0.770247 --> 0.768440).  Saving model ...
train epoch 381 avg loss: 0.45145 (A-MSE: 0.40754) avg lploss: 0.00000
train epoch 382 avg loss: 0.48042 (A-MSE: 0.43438) avg lploss: 0.00000
train epoch 383 avg loss: 0.42056 (A-MSE: 0.38176) avg lploss: 0.00000
train epoch 384 avg loss: 0.41230 (A-MSE: 0.37224) avg lploss: 0.00000
train epoch 385 avg loss: 0.44290 (A-MSE: 0.39837) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.75740 (A-MSE: 0.68952) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.86049 (A-MSE: 0.78148) avg lploss: 0.00000
*** Best Val Loss: 0.75740 	 Best Test Loss: 0.86049 	 Best epoch 385
Validation loss decreased (0.768440 --> 0.757404).  Saving model ...
train epoch 386 avg loss: 0.43814 (A-MSE: 0.39565) avg lploss: 0.00000
train epoch 387 avg loss: 0.45094 (A-MSE: 0.40766) avg lploss: 0.00000
train epoch 388 avg loss: 0.43601 (A-MSE: 0.39472) avg lploss: 0.00000
train epoch 389 avg loss: 0.44238 (A-MSE: 0.40018) avg lploss: 0.00000
train epoch 390 avg loss: 0.45778 (A-MSE: 0.41458) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.72296 (A-MSE: 0.66251) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.85095 (A-MSE: 0.78571) avg lploss: 0.00000
*** Best Val Loss: 0.72296 	 Best Test Loss: 0.85095 	 Best epoch 390
Validation loss decreased (0.757404 --> 0.722958).  Saving model ...
train epoch 391 avg loss: 0.41323 (A-MSE: 0.37263) avg lploss: 0.00000
train epoch 392 avg loss: 0.42554 (A-MSE: 0.38445) avg lploss: 0.00000
train epoch 393 avg loss: 0.44878 (A-MSE: 0.40754) avg lploss: 0.00000
train epoch 394 avg loss: 0.40883 (A-MSE: 0.37037) avg lploss: 0.00000
train epoch 395 avg loss: 0.40754 (A-MSE: 0.36804) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.66719 (A-MSE: 0.61397) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.82664 (A-MSE: 0.76070) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
Validation loss decreased (0.722958 --> 0.667188).  Saving model ...
train epoch 396 avg loss: 0.41686 (A-MSE: 0.37474) avg lploss: 0.00000
train epoch 397 avg loss: 0.44045 (A-MSE: 0.39942) avg lploss: 0.00000
train epoch 398 avg loss: 0.47890 (A-MSE: 0.43266) avg lploss: 0.00000
train epoch 399 avg loss: 0.43641 (A-MSE: 0.39429) avg lploss: 0.00000
train epoch 400 avg loss: 0.49556 (A-MSE: 0.44686) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.78423 (A-MSE: 0.71942) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.90669 (A-MSE: 0.82899) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 1 out of 50
train epoch 401 avg loss: 0.46935 (A-MSE: 0.42538) avg lploss: 0.00000
train epoch 402 avg loss: 0.41723 (A-MSE: 0.37825) avg lploss: 0.00000
train epoch 403 avg loss: 0.52019 (A-MSE: 0.46686) avg lploss: 0.00000
train epoch 404 avg loss: 0.46873 (A-MSE: 0.42122) avg lploss: 0.00000
train epoch 405 avg loss: 0.45612 (A-MSE: 0.41183) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.71646 (A-MSE: 0.65011) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.87997 (A-MSE: 0.79290) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 2 out of 50
train epoch 406 avg loss: 0.41625 (A-MSE: 0.37751) avg lploss: 0.00000
train epoch 407 avg loss: 0.43432 (A-MSE: 0.38970) avg lploss: 0.00000
train epoch 408 avg loss: 0.42675 (A-MSE: 0.38505) avg lploss: 0.00000
train epoch 409 avg loss: 0.43243 (A-MSE: 0.39526) avg lploss: 0.00000
train epoch 410 avg loss: 0.46521 (A-MSE: 0.41952) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.76470 (A-MSE: 0.70097) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.91058 (A-MSE: 0.83136) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 3 out of 50
train epoch 411 avg loss: 0.45518 (A-MSE: 0.41205) avg lploss: 0.00000
train epoch 412 avg loss: 0.60314 (A-MSE: 0.54242) avg lploss: 0.00000
train epoch 413 avg loss: 0.58994 (A-MSE: 0.53098) avg lploss: 0.00000
train epoch 414 avg loss: 0.60834 (A-MSE: 0.54721) avg lploss: 0.00000
train epoch 415 avg loss: 0.47027 (A-MSE: 0.42858) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.75342 (A-MSE: 0.67655) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.88852 (A-MSE: 0.80158) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 4 out of 50
train epoch 416 avg loss: 0.41276 (A-MSE: 0.37171) avg lploss: 0.00000
train epoch 417 avg loss: 0.39910 (A-MSE: 0.35833) avg lploss: 0.00000
train epoch 418 avg loss: 0.38747 (A-MSE: 0.34946) avg lploss: 0.00000
train epoch 419 avg loss: 0.41428 (A-MSE: 0.37246) avg lploss: 0.00000
train epoch 420 avg loss: 0.39025 (A-MSE: 0.35400) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.91306 (A-MSE: 0.82653) avg lploss: 0.00000
==> test epoch 420 avg loss: 1.02808 (A-MSE: 0.92335) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 5 out of 50
train epoch 421 avg loss: 0.47733 (A-MSE: 0.43132) avg lploss: 0.00000
train epoch 422 avg loss: 0.43978 (A-MSE: 0.39844) avg lploss: 0.00000
train epoch 423 avg loss: 0.47094 (A-MSE: 0.42388) avg lploss: 0.00000
train epoch 424 avg loss: 0.45567 (A-MSE: 0.41104) avg lploss: 0.00000
train epoch 425 avg loss: 0.41168 (A-MSE: 0.37058) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.69265 (A-MSE: 0.62787) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.83419 (A-MSE: 0.75523) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 6 out of 50
train epoch 426 avg loss: 0.38813 (A-MSE: 0.35145) avg lploss: 0.00000
train epoch 427 avg loss: 0.39021 (A-MSE: 0.35141) avg lploss: 0.00000
train epoch 428 avg loss: 0.36410 (A-MSE: 0.32939) avg lploss: 0.00000
train epoch 429 avg loss: 0.37498 (A-MSE: 0.33854) avg lploss: 0.00000
train epoch 430 avg loss: 0.39576 (A-MSE: 0.35767) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.74936 (A-MSE: 0.67854) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.86173 (A-MSE: 0.77867) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 7 out of 50
train epoch 431 avg loss: 0.39869 (A-MSE: 0.36016) avg lploss: 0.00000
train epoch 432 avg loss: 0.37872 (A-MSE: 0.34111) avg lploss: 0.00000
train epoch 433 avg loss: 0.35089 (A-MSE: 0.31596) avg lploss: 0.00000
train epoch 434 avg loss: 0.36461 (A-MSE: 0.32862) avg lploss: 0.00000
train epoch 435 avg loss: 0.40338 (A-MSE: 0.36312) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.78227 (A-MSE: 0.70752) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.86893 (A-MSE: 0.78671) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 8 out of 50
train epoch 436 avg loss: 0.40692 (A-MSE: 0.36492) avg lploss: 0.00000
train epoch 437 avg loss: 0.43537 (A-MSE: 0.39579) avg lploss: 0.00000
train epoch 438 avg loss: 0.42008 (A-MSE: 0.37756) avg lploss: 0.00000
train epoch 439 avg loss: 0.37702 (A-MSE: 0.33872) avg lploss: 0.00000
train epoch 440 avg loss: 0.39638 (A-MSE: 0.35665) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.78770 (A-MSE: 0.70299) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.89283 (A-MSE: 0.80050) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 9 out of 50
train epoch 441 avg loss: 0.38936 (A-MSE: 0.35139) avg lploss: 0.00000
train epoch 442 avg loss: 0.41320 (A-MSE: 0.37516) avg lploss: 0.00000
train epoch 443 avg loss: 0.43171 (A-MSE: 0.39156) avg lploss: 0.00000
train epoch 444 avg loss: 0.39114 (A-MSE: 0.35258) avg lploss: 0.00000
train epoch 445 avg loss: 0.43943 (A-MSE: 0.39445) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.77305 (A-MSE: 0.69648) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.88344 (A-MSE: 0.79151) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 10 out of 50
train epoch 446 avg loss: 0.39597 (A-MSE: 0.35789) avg lploss: 0.00000
train epoch 447 avg loss: 0.40342 (A-MSE: 0.36626) avg lploss: 0.00000
train epoch 448 avg loss: 0.36827 (A-MSE: 0.33122) avg lploss: 0.00000
train epoch 449 avg loss: 0.44904 (A-MSE: 0.40395) avg lploss: 0.00000
train epoch 450 avg loss: 0.37698 (A-MSE: 0.34194) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.78737 (A-MSE: 0.70774) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.88075 (A-MSE: 0.78783) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 11 out of 50
train epoch 451 avg loss: 0.43657 (A-MSE: 0.39452) avg lploss: 0.00000
train epoch 452 avg loss: 0.39787 (A-MSE: 0.36012) avg lploss: 0.00000
train epoch 453 avg loss: 0.36708 (A-MSE: 0.33291) avg lploss: 0.00000
train epoch 454 avg loss: 0.34725 (A-MSE: 0.31437) avg lploss: 0.00000
train epoch 455 avg loss: 0.39771 (A-MSE: 0.35914) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.73592 (A-MSE: 0.66928) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.85931 (A-MSE: 0.77832) avg lploss: 0.00000
*** Best Val Loss: 0.66719 	 Best Test Loss: 0.82664 	 Best epoch 395
EarlyStopping counter: 12 out of 50
train epoch 456 avg loss: 0.36525 (A-MSE: 0.33063) avg lploss: 0.00000
train epoch 457 avg loss: 0.42122 (A-MSE: 0.38116) avg lploss: 0.00000
train epoch 458 avg loss: 0.37904 (A-MSE: 0.34142) avg lploss: 0.00000
train epoch 459 avg loss: 0.36863 (A-MSE: 0.33129) avg lploss: 0.00000
train epoch 460 avg loss: 0.36107 (A-MSE: 0.32592) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.60940 (A-MSE: 0.55585) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.72582 (A-MSE: 0.66411) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
Validation loss decreased (0.667188 --> 0.609401).  Saving model ...
train epoch 461 avg loss: 0.41626 (A-MSE: 0.37167) avg lploss: 0.00000
train epoch 462 avg loss: 0.43960 (A-MSE: 0.39654) avg lploss: 0.00000
train epoch 463 avg loss: 0.37462 (A-MSE: 0.33821) avg lploss: 0.00000
train epoch 464 avg loss: 0.38818 (A-MSE: 0.35145) avg lploss: 0.00000
train epoch 465 avg loss: 0.38119 (A-MSE: 0.34368) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.66696 (A-MSE: 0.60760) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.78915 (A-MSE: 0.71747) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 1 out of 50
train epoch 466 avg loss: 0.39135 (A-MSE: 0.35409) avg lploss: 0.00000
train epoch 467 avg loss: 0.39940 (A-MSE: 0.35769) avg lploss: 0.00000
train epoch 468 avg loss: 0.35358 (A-MSE: 0.31928) avg lploss: 0.00000
train epoch 469 avg loss: 0.42153 (A-MSE: 0.38039) avg lploss: 0.00000
train epoch 470 avg loss: 0.39391 (A-MSE: 0.35869) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.68656 (A-MSE: 0.62250) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.76668 (A-MSE: 0.69393) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 2 out of 50
train epoch 471 avg loss: 0.39971 (A-MSE: 0.36082) avg lploss: 0.00000
train epoch 472 avg loss: 0.41517 (A-MSE: 0.37387) avg lploss: 0.00000
train epoch 473 avg loss: 0.36454 (A-MSE: 0.32933) avg lploss: 0.00000
train epoch 474 avg loss: 0.35661 (A-MSE: 0.32115) avg lploss: 0.00000
train epoch 475 avg loss: 0.45833 (A-MSE: 0.41328) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.71146 (A-MSE: 0.64423) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.82008 (A-MSE: 0.73885) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 3 out of 50
train epoch 476 avg loss: 0.42744 (A-MSE: 0.38533) avg lploss: 0.00000
train epoch 477 avg loss: 0.39796 (A-MSE: 0.35799) avg lploss: 0.00000
train epoch 478 avg loss: 0.37699 (A-MSE: 0.34045) avg lploss: 0.00000
train epoch 479 avg loss: 0.39446 (A-MSE: 0.35454) avg lploss: 0.00000
train epoch 480 avg loss: 0.36535 (A-MSE: 0.32749) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.71235 (A-MSE: 0.64065) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.81755 (A-MSE: 0.72813) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 4 out of 50
train epoch 481 avg loss: 0.33557 (A-MSE: 0.30277) avg lploss: 0.00000
train epoch 482 avg loss: 0.37277 (A-MSE: 0.33674) avg lploss: 0.00000
train epoch 483 avg loss: 0.34721 (A-MSE: 0.31472) avg lploss: 0.00000
train epoch 484 avg loss: 0.34314 (A-MSE: 0.30994) avg lploss: 0.00000
train epoch 485 avg loss: 0.35127 (A-MSE: 0.31734) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.83172 (A-MSE: 0.73757) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.94964 (A-MSE: 0.82848) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 5 out of 50
train epoch 486 avg loss: 0.38763 (A-MSE: 0.34864) avg lploss: 0.00000
train epoch 487 avg loss: 0.39118 (A-MSE: 0.35372) avg lploss: 0.00000
train epoch 488 avg loss: 0.33317 (A-MSE: 0.30163) avg lploss: 0.00000
train epoch 489 avg loss: 0.32025 (A-MSE: 0.28857) avg lploss: 0.00000
train epoch 490 avg loss: 0.32583 (A-MSE: 0.29461) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.74693 (A-MSE: 0.66563) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.84304 (A-MSE: 0.74734) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 6 out of 50
train epoch 491 avg loss: 0.35940 (A-MSE: 0.32533) avg lploss: 0.00000
train epoch 492 avg loss: 0.44985 (A-MSE: 0.40183) avg lploss: 0.00000
train epoch 493 avg loss: 0.41559 (A-MSE: 0.37339) avg lploss: 0.00000
train epoch 494 avg loss: 0.33670 (A-MSE: 0.30456) avg lploss: 0.00000
train epoch 495 avg loss: 0.39012 (A-MSE: 0.35093) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.63749 (A-MSE: 0.57182) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.75502 (A-MSE: 0.67526) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 7 out of 50
train epoch 496 avg loss: 0.32739 (A-MSE: 0.29579) avg lploss: 0.00000
train epoch 497 avg loss: 0.31669 (A-MSE: 0.28675) avg lploss: 0.00000
train epoch 498 avg loss: 0.39661 (A-MSE: 0.35731) avg lploss: 0.00000
train epoch 499 avg loss: 0.37049 (A-MSE: 0.33565) avg lploss: 0.00000
train epoch 500 avg loss: 0.35306 (A-MSE: 0.31997) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.66403 (A-MSE: 0.59109) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.76915 (A-MSE: 0.68941) avg lploss: 0.00000
*** Best Val Loss: 0.60940 	 Best Test Loss: 0.72582 	 Best epoch 460
EarlyStopping counter: 8 out of 50
train epoch 501 avg loss: 0.43986 (A-MSE: 0.39416) avg lploss: 0.00000
train epoch 502 avg loss: 0.42133 (A-MSE: 0.38302) avg lploss: 0.00000
train epoch 503 avg loss: 0.38631 (A-MSE: 0.34876) avg lploss: 0.00000
train epoch 504 avg loss: 0.32949 (A-MSE: 0.29752) avg lploss: 0.00000
train epoch 505 avg loss: 0.33407 (A-MSE: 0.30053) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.60049 (A-MSE: 0.54341) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.70934 (A-MSE: 0.63822) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
Validation loss decreased (0.609401 --> 0.600491).  Saving model ...
train epoch 506 avg loss: 0.35109 (A-MSE: 0.31602) avg lploss: 0.00000
train epoch 507 avg loss: 0.33984 (A-MSE: 0.30709) avg lploss: 0.00000
train epoch 508 avg loss: 0.31286 (A-MSE: 0.28199) avg lploss: 0.00000
train epoch 509 avg loss: 0.33413 (A-MSE: 0.30031) avg lploss: 0.00000
train epoch 510 avg loss: 0.33170 (A-MSE: 0.29698) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.64084 (A-MSE: 0.57604) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.73769 (A-MSE: 0.66048) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 1 out of 50
train epoch 511 avg loss: 0.35591 (A-MSE: 0.32097) avg lploss: 0.00000
train epoch 512 avg loss: 0.36328 (A-MSE: 0.32850) avg lploss: 0.00000
train epoch 513 avg loss: 0.35994 (A-MSE: 0.32561) avg lploss: 0.00000
train epoch 514 avg loss: 0.40357 (A-MSE: 0.36256) avg lploss: 0.00000
train epoch 515 avg loss: 0.36550 (A-MSE: 0.32807) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.74458 (A-MSE: 0.65970) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.83266 (A-MSE: 0.73886) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 2 out of 50
train epoch 516 avg loss: 0.36746 (A-MSE: 0.32984) avg lploss: 0.00000
train epoch 517 avg loss: 0.32653 (A-MSE: 0.29393) avg lploss: 0.00000
train epoch 518 avg loss: 0.32065 (A-MSE: 0.28815) avg lploss: 0.00000
train epoch 519 avg loss: 0.34430 (A-MSE: 0.30903) avg lploss: 0.00000
train epoch 520 avg loss: 0.32711 (A-MSE: 0.29696) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.68341 (A-MSE: 0.59859) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.73480 (A-MSE: 0.65377) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 3 out of 50
train epoch 521 avg loss: 0.30196 (A-MSE: 0.27088) avg lploss: 0.00000
train epoch 522 avg loss: 0.31663 (A-MSE: 0.28606) avg lploss: 0.00000
train epoch 523 avg loss: 0.33252 (A-MSE: 0.30089) avg lploss: 0.00000
train epoch 524 avg loss: 0.36674 (A-MSE: 0.33096) avg lploss: 0.00000
train epoch 525 avg loss: 0.34753 (A-MSE: 0.31134) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.62677 (A-MSE: 0.56003) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.74739 (A-MSE: 0.66479) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 4 out of 50
train epoch 526 avg loss: 0.35528 (A-MSE: 0.32055) avg lploss: 0.00000
train epoch 527 avg loss: 0.35946 (A-MSE: 0.32290) avg lploss: 0.00000
train epoch 528 avg loss: 0.30537 (A-MSE: 0.27816) avg lploss: 0.00000
train epoch 529 avg loss: 0.29392 (A-MSE: 0.26542) avg lploss: 0.00000
train epoch 530 avg loss: 0.31947 (A-MSE: 0.28935) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.74004 (A-MSE: 0.65023) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.82536 (A-MSE: 0.71703) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 5 out of 50
train epoch 531 avg loss: 0.32875 (A-MSE: 0.29722) avg lploss: 0.00000
train epoch 532 avg loss: 0.33046 (A-MSE: 0.29619) avg lploss: 0.00000
train epoch 533 avg loss: 0.43583 (A-MSE: 0.39127) avg lploss: 0.00000
train epoch 534 avg loss: 0.35962 (A-MSE: 0.32365) avg lploss: 0.00000
train epoch 535 avg loss: 0.34900 (A-MSE: 0.31505) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.65574 (A-MSE: 0.57784) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.76494 (A-MSE: 0.67397) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 6 out of 50
train epoch 536 avg loss: 0.30887 (A-MSE: 0.27999) avg lploss: 0.00000
train epoch 537 avg loss: 0.30798 (A-MSE: 0.27490) avg lploss: 0.00000
train epoch 538 avg loss: 0.30042 (A-MSE: 0.27097) avg lploss: 0.00000
train epoch 539 avg loss: 0.29425 (A-MSE: 0.26620) avg lploss: 0.00000
train epoch 540 avg loss: 0.29146 (A-MSE: 0.26272) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.60641 (A-MSE: 0.54268) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.68238 (A-MSE: 0.62237) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 7 out of 50
train epoch 541 avg loss: 0.29528 (A-MSE: 0.26773) avg lploss: 0.00000
train epoch 542 avg loss: 0.26964 (A-MSE: 0.24276) avg lploss: 0.00000
train epoch 543 avg loss: 0.30928 (A-MSE: 0.27912) avg lploss: 0.00000
train epoch 544 avg loss: 0.31098 (A-MSE: 0.28191) avg lploss: 0.00000
train epoch 545 avg loss: 0.30585 (A-MSE: 0.27619) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.72533 (A-MSE: 0.64461) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.82154 (A-MSE: 0.72521) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 8 out of 50
train epoch 546 avg loss: 0.33791 (A-MSE: 0.30151) avg lploss: 0.00000
train epoch 547 avg loss: 0.36039 (A-MSE: 0.32382) avg lploss: 0.00000
train epoch 548 avg loss: 0.30271 (A-MSE: 0.27392) avg lploss: 0.00000
train epoch 549 avg loss: 0.32653 (A-MSE: 0.29191) avg lploss: 0.00000
train epoch 550 avg loss: 0.33207 (A-MSE: 0.29838) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.69757 (A-MSE: 0.60805) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.76798 (A-MSE: 0.67235) avg lploss: 0.00000
*** Best Val Loss: 0.60049 	 Best Test Loss: 0.70934 	 Best epoch 505
EarlyStopping counter: 9 out of 50
train epoch 551 avg loss: 0.29415 (A-MSE: 0.26554) avg lploss: 0.00000
train epoch 552 avg loss: 0.28112 (A-MSE: 0.25421) avg lploss: 0.00000
train epoch 553 avg loss: 0.32218 (A-MSE: 0.29041) avg lploss: 0.00000
train epoch 554 avg loss: 0.32830 (A-MSE: 0.29673) avg lploss: 0.00000
train epoch 555 avg loss: 0.27036 (A-MSE: 0.24516) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.52896 (A-MSE: 0.47735) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.64992 (A-MSE: 0.58654) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
Validation loss decreased (0.600491 --> 0.528957).  Saving model ...
train epoch 556 avg loss: 0.28706 (A-MSE: 0.25788) avg lploss: 0.00000
train epoch 557 avg loss: 0.27955 (A-MSE: 0.25310) avg lploss: 0.00000
train epoch 558 avg loss: 0.27086 (A-MSE: 0.24550) avg lploss: 0.00000
train epoch 559 avg loss: 0.25519 (A-MSE: 0.23012) avg lploss: 0.00000
train epoch 560 avg loss: 0.29287 (A-MSE: 0.26369) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.55571 (A-MSE: 0.49407) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.64917 (A-MSE: 0.58526) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 1 out of 50
train epoch 561 avg loss: 0.28122 (A-MSE: 0.25322) avg lploss: 0.00000
train epoch 562 avg loss: 0.30343 (A-MSE: 0.27229) avg lploss: 0.00000
train epoch 563 avg loss: 0.28028 (A-MSE: 0.25191) avg lploss: 0.00000
train epoch 564 avg loss: 0.28089 (A-MSE: 0.25472) avg lploss: 0.00000
train epoch 565 avg loss: 0.28521 (A-MSE: 0.25785) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.63588 (A-MSE: 0.55526) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.70611 (A-MSE: 0.62209) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 2 out of 50
train epoch 566 avg loss: 0.32081 (A-MSE: 0.29150) avg lploss: 0.00000
train epoch 567 avg loss: 0.30427 (A-MSE: 0.27518) avg lploss: 0.00000
train epoch 568 avg loss: 0.31503 (A-MSE: 0.28362) avg lploss: 0.00000
train epoch 569 avg loss: 0.33339 (A-MSE: 0.30066) avg lploss: 0.00000
train epoch 570 avg loss: 0.29590 (A-MSE: 0.26445) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.66868 (A-MSE: 0.59028) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.75110 (A-MSE: 0.66305) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 3 out of 50
train epoch 571 avg loss: 0.27973 (A-MSE: 0.25303) avg lploss: 0.00000
train epoch 572 avg loss: 0.29678 (A-MSE: 0.26672) avg lploss: 0.00000
train epoch 573 avg loss: 0.31410 (A-MSE: 0.28305) avg lploss: 0.00000
train epoch 574 avg loss: 0.33809 (A-MSE: 0.30512) avg lploss: 0.00000
train epoch 575 avg loss: 0.31462 (A-MSE: 0.28337) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.60647 (A-MSE: 0.53028) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.70577 (A-MSE: 0.61851) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 4 out of 50
train epoch 576 avg loss: 0.28275 (A-MSE: 0.25618) avg lploss: 0.00000
train epoch 577 avg loss: 0.25957 (A-MSE: 0.23402) avg lploss: 0.00000
train epoch 578 avg loss: 0.26319 (A-MSE: 0.23777) avg lploss: 0.00000
train epoch 579 avg loss: 0.26099 (A-MSE: 0.23711) avg lploss: 0.00000
train epoch 580 avg loss: 0.39701 (A-MSE: 0.35346) avg lploss: 0.00000
==> val epoch 580 avg loss: 1.31187 (A-MSE: 1.16002) avg lploss: 0.00000
==> test epoch 580 avg loss: 1.41219 (A-MSE: 1.23257) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 5 out of 50
train epoch 581 avg loss: 0.55755 (A-MSE: 0.49607) avg lploss: 0.00000
train epoch 582 avg loss: 0.38609 (A-MSE: 0.34663) avg lploss: 0.00000
train epoch 583 avg loss: 0.35698 (A-MSE: 0.32317) avg lploss: 0.00000
train epoch 584 avg loss: 0.31850 (A-MSE: 0.28564) avg lploss: 0.00000
train epoch 585 avg loss: 0.29624 (A-MSE: 0.26958) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.63548 (A-MSE: 0.56340) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.71330 (A-MSE: 0.62970) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 6 out of 50
train epoch 586 avg loss: 0.28883 (A-MSE: 0.26035) avg lploss: 0.00000
train epoch 587 avg loss: 0.25799 (A-MSE: 0.23469) avg lploss: 0.00000
train epoch 588 avg loss: 0.26856 (A-MSE: 0.24346) avg lploss: 0.00000
train epoch 589 avg loss: 0.29362 (A-MSE: 0.26340) avg lploss: 0.00000
train epoch 590 avg loss: 0.32266 (A-MSE: 0.28883) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.57163 (A-MSE: 0.51280) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.68391 (A-MSE: 0.61525) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 7 out of 50
train epoch 591 avg loss: 0.31440 (A-MSE: 0.28219) avg lploss: 0.00000
train epoch 592 avg loss: 0.25763 (A-MSE: 0.23314) avg lploss: 0.00000
train epoch 593 avg loss: 0.25139 (A-MSE: 0.22887) avg lploss: 0.00000
train epoch 594 avg loss: 0.26433 (A-MSE: 0.23717) avg lploss: 0.00000
train epoch 595 avg loss: 0.28704 (A-MSE: 0.25998) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.53213 (A-MSE: 0.47412) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.59586 (A-MSE: 0.53379) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 8 out of 50
train epoch 596 avg loss: 0.29294 (A-MSE: 0.26409) avg lploss: 0.00000
train epoch 597 avg loss: 0.34663 (A-MSE: 0.31604) avg lploss: 0.00000
train epoch 598 avg loss: 0.30438 (A-MSE: 0.27416) avg lploss: 0.00000
train epoch 599 avg loss: 0.33259 (A-MSE: 0.29986) avg lploss: 0.00000
train epoch 600 avg loss: 0.29194 (A-MSE: 0.26439) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.57365 (A-MSE: 0.50830) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.64449 (A-MSE: 0.57253) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 9 out of 50
train epoch 601 avg loss: 0.27539 (A-MSE: 0.24861) avg lploss: 0.00000
train epoch 602 avg loss: 0.26742 (A-MSE: 0.24182) avg lploss: 0.00000
train epoch 603 avg loss: 0.25741 (A-MSE: 0.23281) avg lploss: 0.00000
train epoch 604 avg loss: 0.31514 (A-MSE: 0.28274) avg lploss: 0.00000
train epoch 605 avg loss: 0.25577 (A-MSE: 0.23140) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.63365 (A-MSE: 0.57136) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.70069 (A-MSE: 0.62707) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 10 out of 50
train epoch 606 avg loss: 0.28192 (A-MSE: 0.25362) avg lploss: 0.00000
train epoch 607 avg loss: 0.25049 (A-MSE: 0.22641) avg lploss: 0.00000
train epoch 608 avg loss: 0.24492 (A-MSE: 0.22149) avg lploss: 0.00000
train epoch 609 avg loss: 0.27606 (A-MSE: 0.24853) avg lploss: 0.00000
train epoch 610 avg loss: 0.28668 (A-MSE: 0.26026) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.56788 (A-MSE: 0.49944) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.67511 (A-MSE: 0.59191) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 11 out of 50
train epoch 611 avg loss: 0.24921 (A-MSE: 0.22655) avg lploss: 0.00000
train epoch 612 avg loss: 0.25628 (A-MSE: 0.23120) avg lploss: 0.00000
train epoch 613 avg loss: 0.23773 (A-MSE: 0.21560) avg lploss: 0.00000
train epoch 614 avg loss: 0.24195 (A-MSE: 0.21965) avg lploss: 0.00000
train epoch 615 avg loss: 0.24142 (A-MSE: 0.21955) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.76732 (A-MSE: 0.66583) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.84367 (A-MSE: 0.72813) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 12 out of 50
train epoch 616 avg loss: 0.27580 (A-MSE: 0.24845) avg lploss: 0.00000
train epoch 617 avg loss: 0.25439 (A-MSE: 0.23052) avg lploss: 0.00000
train epoch 618 avg loss: 0.26025 (A-MSE: 0.23608) avg lploss: 0.00000
train epoch 619 avg loss: 0.28023 (A-MSE: 0.25220) avg lploss: 0.00000
train epoch 620 avg loss: 0.23996 (A-MSE: 0.21800) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.62790 (A-MSE: 0.55344) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.69460 (A-MSE: 0.61180) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 13 out of 50
train epoch 621 avg loss: 0.22486 (A-MSE: 0.20343) avg lploss: 0.00000
train epoch 622 avg loss: 0.24661 (A-MSE: 0.22243) avg lploss: 0.00000
train epoch 623 avg loss: 0.23244 (A-MSE: 0.20843) avg lploss: 0.00000
train epoch 624 avg loss: 0.23824 (A-MSE: 0.21531) avg lploss: 0.00000
train epoch 625 avg loss: 0.25734 (A-MSE: 0.23292) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.73476 (A-MSE: 0.64198) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.79316 (A-MSE: 0.68710) avg lploss: 0.00000
*** Best Val Loss: 0.52896 	 Best Test Loss: 0.64992 	 Best epoch 555
EarlyStopping counter: 14 out of 50
train epoch 626 avg loss: 0.27975 (A-MSE: 0.25287) avg lploss: 0.00000
train epoch 627 avg loss: 0.27839 (A-MSE: 0.24913) avg lploss: 0.00000
train epoch 628 avg loss: 0.28831 (A-MSE: 0.25991) avg lploss: 0.00000
train epoch 629 avg loss: 0.25368 (A-MSE: 0.22923) avg lploss: 0.00000
train epoch 630 avg loss: 0.23512 (A-MSE: 0.21239) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.52840 (A-MSE: 0.47179) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.64235 (A-MSE: 0.57226) avg lploss: 0.00000
*** Best Val Loss: 0.52840 	 Best Test Loss: 0.64235 	 Best epoch 630
Validation loss decreased (0.528957 --> 0.528400).  Saving model ...
train epoch 631 avg loss: 0.27054 (A-MSE: 0.24215) avg lploss: 0.00000
train epoch 632 avg loss: 0.28918 (A-MSE: 0.25971) avg lploss: 0.00000
train epoch 633 avg loss: 0.29913 (A-MSE: 0.26836) avg lploss: 0.00000
train epoch 634 avg loss: 0.27780 (A-MSE: 0.24795) avg lploss: 0.00000
train epoch 635 avg loss: 0.25622 (A-MSE: 0.22959) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.66245 (A-MSE: 0.58482) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.73456 (A-MSE: 0.64200) avg lploss: 0.00000
*** Best Val Loss: 0.52840 	 Best Test Loss: 0.64235 	 Best epoch 630
EarlyStopping counter: 1 out of 50
train epoch 636 avg loss: 0.25662 (A-MSE: 0.23123) avg lploss: 0.00000
train epoch 637 avg loss: 0.22289 (A-MSE: 0.20275) avg lploss: 0.00000
train epoch 638 avg loss: 0.23998 (A-MSE: 0.21653) avg lploss: 0.00000
train epoch 639 avg loss: 0.28032 (A-MSE: 0.25356) avg lploss: 0.00000
train epoch 640 avg loss: 0.25288 (A-MSE: 0.22853) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.67797 (A-MSE: 0.60138) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.73766 (A-MSE: 0.65268) avg lploss: 0.00000
*** Best Val Loss: 0.52840 	 Best Test Loss: 0.64235 	 Best epoch 630
EarlyStopping counter: 2 out of 50
train epoch 641 avg loss: 0.24068 (A-MSE: 0.21799) avg lploss: 0.00000
train epoch 642 avg loss: 0.23702 (A-MSE: 0.21507) avg lploss: 0.00000
train epoch 643 avg loss: 0.28298 (A-MSE: 0.25333) avg lploss: 0.00000
train epoch 644 avg loss: 0.24675 (A-MSE: 0.22277) avg lploss: 0.00000
train epoch 645 avg loss: 0.26801 (A-MSE: 0.23834) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.61137 (A-MSE: 0.53826) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.69085 (A-MSE: 0.61016) avg lploss: 0.00000
*** Best Val Loss: 0.52840 	 Best Test Loss: 0.64235 	 Best epoch 630
EarlyStopping counter: 3 out of 50
train epoch 646 avg loss: 0.23604 (A-MSE: 0.21495) avg lploss: 0.00000
train epoch 647 avg loss: 0.23550 (A-MSE: 0.21362) avg lploss: 0.00000
train epoch 648 avg loss: 0.22861 (A-MSE: 0.20577) avg lploss: 0.00000
train epoch 649 avg loss: 0.24133 (A-MSE: 0.21702) avg lploss: 0.00000
train epoch 650 avg loss: 0.26171 (A-MSE: 0.23777) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.67186 (A-MSE: 0.59468) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.71664 (A-MSE: 0.62753) avg lploss: 0.00000
*** Best Val Loss: 0.52840 	 Best Test Loss: 0.64235 	 Best epoch 630
EarlyStopping counter: 4 out of 50
train epoch 651 avg loss: 0.26896 (A-MSE: 0.24300) avg lploss: 0.00000
train epoch 652 avg loss: 0.24308 (A-MSE: 0.21959) avg lploss: 0.00000
train epoch 653 avg loss: 0.23470 (A-MSE: 0.21205) avg lploss: 0.00000
train epoch 654 avg loss: 0.24644 (A-MSE: 0.22184) avg lploss: 0.00000
train epoch 655 avg loss: 0.25552 (A-MSE: 0.23076) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.51702 (A-MSE: 0.45948) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.60927 (A-MSE: 0.54704) avg lploss: 0.00000
*** Best Val Loss: 0.51702 	 Best Test Loss: 0.60927 	 Best epoch 655
Validation loss decreased (0.528400 --> 0.517022).  Saving model ...
train epoch 656 avg loss: 0.26869 (A-MSE: 0.24206) avg lploss: 0.00000
train epoch 657 avg loss: 0.27627 (A-MSE: 0.24813) avg lploss: 0.00000
train epoch 658 avg loss: 0.25562 (A-MSE: 0.23200) avg lploss: 0.00000
train epoch 659 avg loss: 0.21642 (A-MSE: 0.19531) avg lploss: 0.00000
train epoch 660 avg loss: 0.25486 (A-MSE: 0.22703) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.58736 (A-MSE: 0.51106) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.64542 (A-MSE: 0.56540) avg lploss: 0.00000
*** Best Val Loss: 0.51702 	 Best Test Loss: 0.60927 	 Best epoch 655
EarlyStopping counter: 1 out of 50
train epoch 661 avg loss: 0.23094 (A-MSE: 0.20844) avg lploss: 0.00000
train epoch 662 avg loss: 0.22868 (A-MSE: 0.20680) avg lploss: 0.00000
train epoch 663 avg loss: 0.21303 (A-MSE: 0.19275) avg lploss: 0.00000
train epoch 664 avg loss: 0.22623 (A-MSE: 0.20518) avg lploss: 0.00000
train epoch 665 avg loss: 0.27491 (A-MSE: 0.24615) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.61535 (A-MSE: 0.53777) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.67234 (A-MSE: 0.58506) avg lploss: 0.00000
*** Best Val Loss: 0.51702 	 Best Test Loss: 0.60927 	 Best epoch 655
EarlyStopping counter: 2 out of 50
train epoch 666 avg loss: 0.25785 (A-MSE: 0.23298) avg lploss: 0.00000
train epoch 667 avg loss: 0.22884 (A-MSE: 0.20626) avg lploss: 0.00000
train epoch 668 avg loss: 0.24144 (A-MSE: 0.21796) avg lploss: 0.00000
train epoch 669 avg loss: 0.22808 (A-MSE: 0.20649) avg lploss: 0.00000
train epoch 670 avg loss: 0.23613 (A-MSE: 0.21067) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.49759 (A-MSE: 0.44540) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.61771 (A-MSE: 0.55412) avg lploss: 0.00000
*** Best Val Loss: 0.49759 	 Best Test Loss: 0.61771 	 Best epoch 670
Validation loss decreased (0.517022 --> 0.497588).  Saving model ...
train epoch 671 avg loss: 0.23998 (A-MSE: 0.21626) avg lploss: 0.00000
train epoch 672 avg loss: 0.22160 (A-MSE: 0.20105) avg lploss: 0.00000
train epoch 673 avg loss: 0.23438 (A-MSE: 0.21107) avg lploss: 0.00000
train epoch 674 avg loss: 0.22012 (A-MSE: 0.19813) avg lploss: 0.00000
train epoch 675 avg loss: 0.24489 (A-MSE: 0.22039) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.51493 (A-MSE: 0.46217) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.58965 (A-MSE: 0.52871) avg lploss: 0.00000
*** Best Val Loss: 0.49759 	 Best Test Loss: 0.61771 	 Best epoch 670
EarlyStopping counter: 1 out of 50
train epoch 676 avg loss: 0.22527 (A-MSE: 0.20354) avg lploss: 0.00000
train epoch 677 avg loss: 0.26156 (A-MSE: 0.23686) avg lploss: 0.00000
train epoch 678 avg loss: 0.23912 (A-MSE: 0.21626) avg lploss: 0.00000
train epoch 679 avg loss: 0.22480 (A-MSE: 0.20277) avg lploss: 0.00000
train epoch 680 avg loss: 0.22135 (A-MSE: 0.20000) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.44568 (A-MSE: 0.39695) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.51291 (A-MSE: 0.46459) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
Validation loss decreased (0.497588 --> 0.445677).  Saving model ...
train epoch 681 avg loss: 0.21101 (A-MSE: 0.18962) avg lploss: 0.00000
train epoch 682 avg loss: 0.20741 (A-MSE: 0.18670) avg lploss: 0.00000
train epoch 683 avg loss: 0.23157 (A-MSE: 0.20837) avg lploss: 0.00000
train epoch 684 avg loss: 0.27716 (A-MSE: 0.24939) avg lploss: 0.00000
train epoch 685 avg loss: 0.24912 (A-MSE: 0.22419) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.56601 (A-MSE: 0.50595) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.66085 (A-MSE: 0.58780) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 1 out of 50
train epoch 686 avg loss: 0.21219 (A-MSE: 0.19203) avg lploss: 0.00000
train epoch 687 avg loss: 0.23981 (A-MSE: 0.21687) avg lploss: 0.00000
train epoch 688 avg loss: 0.24142 (A-MSE: 0.21785) avg lploss: 0.00000
train epoch 689 avg loss: 0.21928 (A-MSE: 0.19773) avg lploss: 0.00000
train epoch 690 avg loss: 0.22763 (A-MSE: 0.20545) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.52980 (A-MSE: 0.47376) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.60649 (A-MSE: 0.54155) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 2 out of 50
train epoch 691 avg loss: 0.28692 (A-MSE: 0.25976) avg lploss: 0.00000
train epoch 692 avg loss: 0.27599 (A-MSE: 0.24870) avg lploss: 0.00000
train epoch 693 avg loss: 0.26647 (A-MSE: 0.23944) avg lploss: 0.00000
train epoch 694 avg loss: 0.22110 (A-MSE: 0.20049) avg lploss: 0.00000
train epoch 695 avg loss: 0.21476 (A-MSE: 0.19437) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.50734 (A-MSE: 0.44520) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.56411 (A-MSE: 0.50008) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 3 out of 50
train epoch 696 avg loss: 0.24031 (A-MSE: 0.21647) avg lploss: 0.00000
train epoch 697 avg loss: 0.34167 (A-MSE: 0.30171) avg lploss: 0.00000
train epoch 698 avg loss: 0.25046 (A-MSE: 0.22608) avg lploss: 0.00000
train epoch 699 avg loss: 0.21741 (A-MSE: 0.19591) avg lploss: 0.00000
train epoch 700 avg loss: 0.21931 (A-MSE: 0.19793) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.52978 (A-MSE: 0.46679) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.60358 (A-MSE: 0.54279) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 4 out of 50
train epoch 701 avg loss: 0.22638 (A-MSE: 0.20366) avg lploss: 0.00000
train epoch 702 avg loss: 0.21583 (A-MSE: 0.19381) avg lploss: 0.00000
train epoch 703 avg loss: 0.19607 (A-MSE: 0.17843) avg lploss: 0.00000
train epoch 704 avg loss: 0.21267 (A-MSE: 0.19341) avg lploss: 0.00000
train epoch 705 avg loss: 0.20489 (A-MSE: 0.18571) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.44995 (A-MSE: 0.39914) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.52240 (A-MSE: 0.47045) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 5 out of 50
train epoch 706 avg loss: 0.22239 (A-MSE: 0.20074) avg lploss: 0.00000
train epoch 707 avg loss: 0.21651 (A-MSE: 0.19503) avg lploss: 0.00000
train epoch 708 avg loss: 0.23570 (A-MSE: 0.21150) avg lploss: 0.00000
train epoch 709 avg loss: 0.20984 (A-MSE: 0.18982) avg lploss: 0.00000
train epoch 710 avg loss: 0.23536 (A-MSE: 0.21226) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.50615 (A-MSE: 0.45156) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.60526 (A-MSE: 0.54804) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 6 out of 50
train epoch 711 avg loss: 0.28692 (A-MSE: 0.25933) avg lploss: 0.00000
train epoch 712 avg loss: 0.26167 (A-MSE: 0.23789) avg lploss: 0.00000
train epoch 713 avg loss: 0.23423 (A-MSE: 0.21175) avg lploss: 0.00000
train epoch 714 avg loss: 0.21270 (A-MSE: 0.19136) avg lploss: 0.00000
train epoch 715 avg loss: 0.20344 (A-MSE: 0.18375) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.46605 (A-MSE: 0.42034) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.55474 (A-MSE: 0.50763) avg lploss: 0.00000
*** Best Val Loss: 0.44568 	 Best Test Loss: 0.51291 	 Best epoch 680
EarlyStopping counter: 7 out of 50
train epoch 716 avg loss: 0.23166 (A-MSE: 0.20638) avg lploss: 0.00000
train epoch 717 avg loss: 0.22442 (A-MSE: 0.20327) avg lploss: 0.00000
train epoch 718 avg loss: 0.20592 (A-MSE: 0.18580) avg lploss: 0.00000
train epoch 719 avg loss: 0.21560 (A-MSE: 0.19642) avg lploss: 0.00000
train epoch 720 avg loss: 0.20553 (A-MSE: 0.18517) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.43669 (A-MSE: 0.39605) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.50840 (A-MSE: 0.46133) avg lploss: 0.00000
*** Best Val Loss: 0.43669 	 Best Test Loss: 0.50840 	 Best epoch 720
Validation loss decreased (0.445677 --> 0.436690).  Saving model ...
train epoch 721 avg loss: 0.19887 (A-MSE: 0.18122) avg lploss: 0.00000
train epoch 722 avg loss: 0.22117 (A-MSE: 0.19969) avg lploss: 0.00000
train epoch 723 avg loss: 0.24161 (A-MSE: 0.21956) avg lploss: 0.00000
train epoch 724 avg loss: 0.24656 (A-MSE: 0.22210) avg lploss: 0.00000
train epoch 725 avg loss: 0.20469 (A-MSE: 0.18361) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.51007 (A-MSE: 0.45044) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.57195 (A-MSE: 0.50537) avg lploss: 0.00000
*** Best Val Loss: 0.43669 	 Best Test Loss: 0.50840 	 Best epoch 720
EarlyStopping counter: 1 out of 50
train epoch 726 avg loss: 0.21103 (A-MSE: 0.19001) avg lploss: 0.00000
train epoch 727 avg loss: 0.20159 (A-MSE: 0.18161) avg lploss: 0.00000
train epoch 728 avg loss: 0.19986 (A-MSE: 0.17937) avg lploss: 0.00000
train epoch 729 avg loss: 0.22396 (A-MSE: 0.20266) avg lploss: 0.00000
train epoch 730 avg loss: 0.21194 (A-MSE: 0.19074) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.49297 (A-MSE: 0.44040) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.56009 (A-MSE: 0.50237) avg lploss: 0.00000
*** Best Val Loss: 0.43669 	 Best Test Loss: 0.50840 	 Best epoch 720
EarlyStopping counter: 2 out of 50
train epoch 731 avg loss: 0.21144 (A-MSE: 0.19095) avg lploss: 0.00000
train epoch 732 avg loss: 0.23030 (A-MSE: 0.20864) avg lploss: 0.00000
train epoch 733 avg loss: 0.21235 (A-MSE: 0.19199) avg lploss: 0.00000
train epoch 734 avg loss: 0.24015 (A-MSE: 0.21422) avg lploss: 0.00000
train epoch 735 avg loss: 0.27288 (A-MSE: 0.24797) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.61804 (A-MSE: 0.53385) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.67765 (A-MSE: 0.59026) avg lploss: 0.00000
*** Best Val Loss: 0.43669 	 Best Test Loss: 0.50840 	 Best epoch 720
EarlyStopping counter: 3 out of 50
train epoch 736 avg loss: 0.24539 (A-MSE: 0.21912) avg lploss: 0.00000
train epoch 737 avg loss: 0.23343 (A-MSE: 0.20988) avg lploss: 0.00000
train epoch 738 avg loss: 0.19507 (A-MSE: 0.17711) avg lploss: 0.00000
train epoch 739 avg loss: 0.18755 (A-MSE: 0.17070) avg lploss: 0.00000
train epoch 740 avg loss: 0.19874 (A-MSE: 0.17875) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.44757 (A-MSE: 0.40299) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.51308 (A-MSE: 0.46762) avg lploss: 0.00000
*** Best Val Loss: 0.43669 	 Best Test Loss: 0.50840 	 Best epoch 720
EarlyStopping counter: 4 out of 50
train epoch 741 avg loss: 0.18469 (A-MSE: 0.16628) avg lploss: 0.00000
train epoch 742 avg loss: 0.20414 (A-MSE: 0.18134) avg lploss: 0.00000
train epoch 743 avg loss: 0.21804 (A-MSE: 0.19904) avg lploss: 0.00000
train epoch 744 avg loss: 0.19371 (A-MSE: 0.17617) avg lploss: 0.00000
train epoch 745 avg loss: 0.22513 (A-MSE: 0.20229) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.48243 (A-MSE: 0.42514) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.56975 (A-MSE: 0.49981) avg lploss: 0.00000
*** Best Val Loss: 0.43669 	 Best Test Loss: 0.50840 	 Best epoch 720
EarlyStopping counter: 5 out of 50
train epoch 746 avg loss: 0.22355 (A-MSE: 0.19815) avg lploss: 0.00000
train epoch 747 avg loss: 0.26286 (A-MSE: 0.23674) avg lploss: 0.00000
train epoch 748 avg loss: 0.27335 (A-MSE: 0.24602) avg lploss: 0.00000
train epoch 749 avg loss: 0.22276 (A-MSE: 0.20087) avg lploss: 0.00000
train epoch 750 avg loss: 0.20124 (A-MSE: 0.18115) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.43079 (A-MSE: 0.38405) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.51294 (A-MSE: 0.46608) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
Validation loss decreased (0.436690 --> 0.430795).  Saving model ...
train epoch 751 avg loss: 0.21526 (A-MSE: 0.19374) avg lploss: 0.00000
train epoch 752 avg loss: 0.20211 (A-MSE: 0.18184) avg lploss: 0.00000
train epoch 753 avg loss: 0.20844 (A-MSE: 0.18964) avg lploss: 0.00000
train epoch 754 avg loss: 0.20174 (A-MSE: 0.18324) avg lploss: 0.00000
train epoch 755 avg loss: 0.18535 (A-MSE: 0.16614) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.63394 (A-MSE: 0.56581) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.71251 (A-MSE: 0.62446) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 1 out of 50
train epoch 756 avg loss: 0.21458 (A-MSE: 0.19391) avg lploss: 0.00000
train epoch 757 avg loss: 0.19133 (A-MSE: 0.17208) avg lploss: 0.00000
train epoch 758 avg loss: 0.20640 (A-MSE: 0.18619) avg lploss: 0.00000
train epoch 759 avg loss: 0.18190 (A-MSE: 0.16498) avg lploss: 0.00000
train epoch 760 avg loss: 0.20967 (A-MSE: 0.19056) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.65514 (A-MSE: 0.56114) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.71024 (A-MSE: 0.59743) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 2 out of 50
train epoch 761 avg loss: 0.25042 (A-MSE: 0.22377) avg lploss: 0.00000
train epoch 762 avg loss: 0.22926 (A-MSE: 0.20514) avg lploss: 0.00000
train epoch 763 avg loss: 0.21252 (A-MSE: 0.19155) avg lploss: 0.00000
train epoch 764 avg loss: 0.19607 (A-MSE: 0.17720) avg lploss: 0.00000
train epoch 765 avg loss: 0.18718 (A-MSE: 0.17106) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.46076 (A-MSE: 0.40832) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.53385 (A-MSE: 0.48036) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 3 out of 50
train epoch 766 avg loss: 0.18508 (A-MSE: 0.16769) avg lploss: 0.00000
train epoch 767 avg loss: 0.23507 (A-MSE: 0.21160) avg lploss: 0.00000
train epoch 768 avg loss: 0.22055 (A-MSE: 0.19979) avg lploss: 0.00000
train epoch 769 avg loss: 0.21440 (A-MSE: 0.19258) avg lploss: 0.00000
train epoch 770 avg loss: 0.18951 (A-MSE: 0.17229) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.44076 (A-MSE: 0.39322) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.52099 (A-MSE: 0.46901) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 4 out of 50
train epoch 771 avg loss: 0.16422 (A-MSE: 0.14829) avg lploss: 0.00000
train epoch 772 avg loss: 0.16429 (A-MSE: 0.14731) avg lploss: 0.00000
train epoch 773 avg loss: 0.18113 (A-MSE: 0.16296) avg lploss: 0.00000
train epoch 774 avg loss: 0.17781 (A-MSE: 0.16200) avg lploss: 0.00000
train epoch 775 avg loss: 0.19578 (A-MSE: 0.17724) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.47925 (A-MSE: 0.42910) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.55296 (A-MSE: 0.49998) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 5 out of 50
train epoch 776 avg loss: 0.21545 (A-MSE: 0.19379) avg lploss: 0.00000
train epoch 777 avg loss: 0.19667 (A-MSE: 0.17700) avg lploss: 0.00000
train epoch 778 avg loss: 0.18383 (A-MSE: 0.16677) avg lploss: 0.00000
train epoch 779 avg loss: 0.16890 (A-MSE: 0.15257) avg lploss: 0.00000
train epoch 780 avg loss: 0.18414 (A-MSE: 0.16709) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.47179 (A-MSE: 0.41983) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.55409 (A-MSE: 0.49839) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 6 out of 50
train epoch 781 avg loss: 0.20005 (A-MSE: 0.18080) avg lploss: 0.00000
train epoch 782 avg loss: 0.19157 (A-MSE: 0.17359) avg lploss: 0.00000
train epoch 783 avg loss: 0.19101 (A-MSE: 0.17287) avg lploss: 0.00000
train epoch 784 avg loss: 0.21750 (A-MSE: 0.19472) avg lploss: 0.00000
train epoch 785 avg loss: 0.21821 (A-MSE: 0.19576) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.45092 (A-MSE: 0.39983) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.52886 (A-MSE: 0.47539) avg lploss: 0.00000
*** Best Val Loss: 0.43079 	 Best Test Loss: 0.51294 	 Best epoch 750
EarlyStopping counter: 7 out of 50
train epoch 786 avg loss: 0.18537 (A-MSE: 0.16698) avg lploss: 0.00000
train epoch 787 avg loss: 0.20261 (A-MSE: 0.18252) avg lploss: 0.00000
train epoch 788 avg loss: 0.18370 (A-MSE: 0.16656) avg lploss: 0.00000
train epoch 789 avg loss: 0.18081 (A-MSE: 0.16495) avg lploss: 0.00000
train epoch 790 avg loss: 0.18120 (A-MSE: 0.16311) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.41555 (A-MSE: 0.37925) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.51211 (A-MSE: 0.46582) avg lploss: 0.00000
*** Best Val Loss: 0.41555 	 Best Test Loss: 0.51211 	 Best epoch 790
Validation loss decreased (0.430795 --> 0.415547).  Saving model ...
train epoch 791 avg loss: 0.21099 (A-MSE: 0.18934) avg lploss: 0.00000
train epoch 792 avg loss: 0.17568 (A-MSE: 0.15796) avg lploss: 0.00000
train epoch 793 avg loss: 0.16406 (A-MSE: 0.14875) avg lploss: 0.00000
train epoch 794 avg loss: 0.17092 (A-MSE: 0.15473) avg lploss: 0.00000
train epoch 795 avg loss: 0.17983 (A-MSE: 0.16158) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.40865 (A-MSE: 0.36405) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.48195 (A-MSE: 0.43910) avg lploss: 0.00000
*** Best Val Loss: 0.40865 	 Best Test Loss: 0.48195 	 Best epoch 795
Validation loss decreased (0.415547 --> 0.408645).  Saving model ...
train epoch 796 avg loss: 0.18866 (A-MSE: 0.16901) avg lploss: 0.00000
train epoch 797 avg loss: 0.17943 (A-MSE: 0.16128) avg lploss: 0.00000
train epoch 798 avg loss: 0.20052 (A-MSE: 0.18193) avg lploss: 0.00000
train epoch 799 avg loss: 0.21619 (A-MSE: 0.19428) avg lploss: 0.00000
train epoch 800 avg loss: 0.21806 (A-MSE: 0.19688) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.54019 (A-MSE: 0.47997) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.60264 (A-MSE: 0.53501) avg lploss: 0.00000
*** Best Val Loss: 0.40865 	 Best Test Loss: 0.48195 	 Best epoch 795
EarlyStopping counter: 1 out of 50
train epoch 801 avg loss: 0.21450 (A-MSE: 0.19276) avg lploss: 0.00000
train epoch 802 avg loss: 0.23088 (A-MSE: 0.20906) avg lploss: 0.00000
train epoch 803 avg loss: 0.22319 (A-MSE: 0.20183) avg lploss: 0.00000
train epoch 804 avg loss: 0.20074 (A-MSE: 0.18209) avg lploss: 0.00000
train epoch 805 avg loss: 0.21676 (A-MSE: 0.19560) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.40800 (A-MSE: 0.37083) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.50308 (A-MSE: 0.46157) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
Validation loss decreased (0.408645 --> 0.408000).  Saving model ...
train epoch 806 avg loss: 0.21207 (A-MSE: 0.19208) avg lploss: 0.00000
train epoch 807 avg loss: 0.21274 (A-MSE: 0.19251) avg lploss: 0.00000
train epoch 808 avg loss: 0.20531 (A-MSE: 0.18513) avg lploss: 0.00000
train epoch 809 avg loss: 0.18934 (A-MSE: 0.17086) avg lploss: 0.00000
train epoch 810 avg loss: 0.17009 (A-MSE: 0.15332) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.43048 (A-MSE: 0.38396) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.48685 (A-MSE: 0.44112) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 1 out of 50
train epoch 811 avg loss: 0.16631 (A-MSE: 0.14867) avg lploss: 0.00000
train epoch 812 avg loss: 0.15714 (A-MSE: 0.14087) avg lploss: 0.00000
train epoch 813 avg loss: 0.17564 (A-MSE: 0.15952) avg lploss: 0.00000
train epoch 814 avg loss: 0.18797 (A-MSE: 0.16959) avg lploss: 0.00000
train epoch 815 avg loss: 0.17397 (A-MSE: 0.15731) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.44136 (A-MSE: 0.39411) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.50889 (A-MSE: 0.45385) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 2 out of 50
train epoch 816 avg loss: 0.18055 (A-MSE: 0.16370) avg lploss: 0.00000
train epoch 817 avg loss: 0.19563 (A-MSE: 0.17646) avg lploss: 0.00000
train epoch 818 avg loss: 0.18499 (A-MSE: 0.16683) avg lploss: 0.00000
train epoch 819 avg loss: 0.20324 (A-MSE: 0.18271) avg lploss: 0.00000
train epoch 820 avg loss: 0.18837 (A-MSE: 0.16979) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.45273 (A-MSE: 0.41077) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.55128 (A-MSE: 0.49835) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 3 out of 50
train epoch 821 avg loss: 0.20495 (A-MSE: 0.18565) avg lploss: 0.00000
train epoch 822 avg loss: 0.20571 (A-MSE: 0.18431) avg lploss: 0.00000
train epoch 823 avg loss: 0.20967 (A-MSE: 0.19004) avg lploss: 0.00000
train epoch 824 avg loss: 0.22328 (A-MSE: 0.20234) avg lploss: 0.00000
train epoch 825 avg loss: 0.24213 (A-MSE: 0.21702) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.42349 (A-MSE: 0.38080) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.52552 (A-MSE: 0.47602) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 4 out of 50
train epoch 826 avg loss: 0.20482 (A-MSE: 0.18412) avg lploss: 0.00000
train epoch 827 avg loss: 0.21120 (A-MSE: 0.19201) avg lploss: 0.00000
train epoch 828 avg loss: 0.18676 (A-MSE: 0.16686) avg lploss: 0.00000
train epoch 829 avg loss: 0.18565 (A-MSE: 0.16750) avg lploss: 0.00000
train epoch 830 avg loss: 0.21475 (A-MSE: 0.19407) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.46243 (A-MSE: 0.40832) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.49581 (A-MSE: 0.44570) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 5 out of 50
train epoch 831 avg loss: 0.20596 (A-MSE: 0.18620) avg lploss: 0.00000
train epoch 832 avg loss: 0.17949 (A-MSE: 0.16208) avg lploss: 0.00000
train epoch 833 avg loss: 0.17470 (A-MSE: 0.15776) avg lploss: 0.00000
train epoch 834 avg loss: 0.17745 (A-MSE: 0.15940) avg lploss: 0.00000
train epoch 835 avg loss: 0.20341 (A-MSE: 0.18268) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.55694 (A-MSE: 0.49337) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.64287 (A-MSE: 0.57240) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 6 out of 50
train epoch 836 avg loss: 0.19852 (A-MSE: 0.18097) avg lploss: 0.00000
train epoch 837 avg loss: 0.17029 (A-MSE: 0.15410) avg lploss: 0.00000
train epoch 838 avg loss: 0.16669 (A-MSE: 0.15088) avg lploss: 0.00000
train epoch 839 avg loss: 0.16204 (A-MSE: 0.14602) avg lploss: 0.00000
train epoch 840 avg loss: 0.19026 (A-MSE: 0.17166) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.65314 (A-MSE: 0.57735) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.67732 (A-MSE: 0.59757) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 7 out of 50
train epoch 841 avg loss: 0.18960 (A-MSE: 0.17080) avg lploss: 0.00000
train epoch 842 avg loss: 0.18896 (A-MSE: 0.17115) avg lploss: 0.00000
train epoch 843 avg loss: 0.18110 (A-MSE: 0.16292) avg lploss: 0.00000
train epoch 844 avg loss: 0.18021 (A-MSE: 0.16139) avg lploss: 0.00000
train epoch 845 avg loss: 0.16584 (A-MSE: 0.15011) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.48235 (A-MSE: 0.43236) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.52078 (A-MSE: 0.46824) avg lploss: 0.00000
*** Best Val Loss: 0.40800 	 Best Test Loss: 0.50308 	 Best epoch 805
EarlyStopping counter: 8 out of 50
train epoch 846 avg loss: 0.19035 (A-MSE: 0.17066) avg lploss: 0.00000
train epoch 847 avg loss: 0.19614 (A-MSE: 0.17767) avg lploss: 0.00000
train epoch 848 avg loss: 0.18542 (A-MSE: 0.16898) avg lploss: 0.00000
train epoch 849 avg loss: 0.18206 (A-MSE: 0.16386) avg lploss: 0.00000
train epoch 850 avg loss: 0.18556 (A-MSE: 0.16844) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.39837 (A-MSE: 0.35277) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.48434 (A-MSE: 0.43914) avg lploss: 0.00000
*** Best Val Loss: 0.39837 	 Best Test Loss: 0.48434 	 Best epoch 850
Validation loss decreased (0.408000 --> 0.398366).  Saving model ...
train epoch 851 avg loss: 0.21091 (A-MSE: 0.19228) avg lploss: 0.00000
train epoch 852 avg loss: 0.19352 (A-MSE: 0.17315) avg lploss: 0.00000
train epoch 853 avg loss: 0.16736 (A-MSE: 0.15098) avg lploss: 0.00000
train epoch 854 avg loss: 0.14893 (A-MSE: 0.13484) avg lploss: 0.00000
train epoch 855 avg loss: 0.14705 (A-MSE: 0.13302) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.39559 (A-MSE: 0.35105) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.46210 (A-MSE: 0.41438) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
Validation loss decreased (0.398366 --> 0.395595).  Saving model ...
train epoch 856 avg loss: 0.15518 (A-MSE: 0.14110) avg lploss: 0.00000
train epoch 857 avg loss: 0.16959 (A-MSE: 0.15221) avg lploss: 0.00000
train epoch 858 avg loss: 0.16199 (A-MSE: 0.14625) avg lploss: 0.00000
train epoch 859 avg loss: 0.17987 (A-MSE: 0.16298) avg lploss: 0.00000
train epoch 860 avg loss: 0.14648 (A-MSE: 0.13219) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.40959 (A-MSE: 0.36997) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.48331 (A-MSE: 0.43713) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 1 out of 50
train epoch 861 avg loss: 0.17488 (A-MSE: 0.15779) avg lploss: 0.00000
train epoch 862 avg loss: 0.18997 (A-MSE: 0.17230) avg lploss: 0.00000
train epoch 863 avg loss: 0.18612 (A-MSE: 0.16982) avg lploss: 0.00000
train epoch 864 avg loss: 0.19225 (A-MSE: 0.17270) avg lploss: 0.00000
train epoch 865 avg loss: 0.18126 (A-MSE: 0.16502) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.42696 (A-MSE: 0.38315) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.49652 (A-MSE: 0.45312) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 2 out of 50
train epoch 866 avg loss: 0.16578 (A-MSE: 0.14844) avg lploss: 0.00000
train epoch 867 avg loss: 0.16367 (A-MSE: 0.14775) avg lploss: 0.00000
train epoch 868 avg loss: 0.16330 (A-MSE: 0.14900) avg lploss: 0.00000
train epoch 869 avg loss: 0.17019 (A-MSE: 0.15342) avg lploss: 0.00000
train epoch 870 avg loss: 0.15288 (A-MSE: 0.13765) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.42926 (A-MSE: 0.37714) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.48903 (A-MSE: 0.43399) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 3 out of 50
train epoch 871 avg loss: 0.14961 (A-MSE: 0.13509) avg lploss: 0.00000
train epoch 872 avg loss: 0.15694 (A-MSE: 0.14181) avg lploss: 0.00000
train epoch 873 avg loss: 0.17579 (A-MSE: 0.15963) avg lploss: 0.00000
train epoch 874 avg loss: 0.26485 (A-MSE: 0.23895) avg lploss: 0.00000
train epoch 875 avg loss: 0.22568 (A-MSE: 0.20497) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.41696 (A-MSE: 0.37269) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.48090 (A-MSE: 0.44020) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 4 out of 50
train epoch 876 avg loss: 0.18859 (A-MSE: 0.16985) avg lploss: 0.00000
train epoch 877 avg loss: 0.15945 (A-MSE: 0.14475) avg lploss: 0.00000
train epoch 878 avg loss: 0.16697 (A-MSE: 0.15152) avg lploss: 0.00000
train epoch 879 avg loss: 0.15766 (A-MSE: 0.14331) avg lploss: 0.00000
train epoch 880 avg loss: 0.17152 (A-MSE: 0.15572) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.43643 (A-MSE: 0.39203) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.49419 (A-MSE: 0.45299) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 5 out of 50
train epoch 881 avg loss: 0.17605 (A-MSE: 0.15885) avg lploss: 0.00000
train epoch 882 avg loss: 0.16832 (A-MSE: 0.15194) avg lploss: 0.00000
train epoch 883 avg loss: 0.15605 (A-MSE: 0.14022) avg lploss: 0.00000
train epoch 884 avg loss: 0.15882 (A-MSE: 0.14453) avg lploss: 0.00000
train epoch 885 avg loss: 0.16775 (A-MSE: 0.15169) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.50425 (A-MSE: 0.44850) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.56990 (A-MSE: 0.50696) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 6 out of 50
train epoch 886 avg loss: 0.16645 (A-MSE: 0.15036) avg lploss: 0.00000
train epoch 887 avg loss: 0.16210 (A-MSE: 0.14676) avg lploss: 0.00000
train epoch 888 avg loss: 0.17286 (A-MSE: 0.15616) avg lploss: 0.00000
train epoch 889 avg loss: 0.20100 (A-MSE: 0.18058) avg lploss: 0.00000
train epoch 890 avg loss: 0.22369 (A-MSE: 0.20102) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.61496 (A-MSE: 0.53424) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.65404 (A-MSE: 0.57209) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 7 out of 50
train epoch 891 avg loss: 0.17743 (A-MSE: 0.15981) avg lploss: 0.00000
train epoch 892 avg loss: 0.18416 (A-MSE: 0.16607) avg lploss: 0.00000
train epoch 893 avg loss: 0.16975 (A-MSE: 0.15322) avg lploss: 0.00000
train epoch 894 avg loss: 0.16462 (A-MSE: 0.14920) avg lploss: 0.00000
train epoch 895 avg loss: 0.17590 (A-MSE: 0.15916) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.48555 (A-MSE: 0.43235) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.52156 (A-MSE: 0.46800) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 8 out of 50
train epoch 896 avg loss: 0.15965 (A-MSE: 0.14417) avg lploss: 0.00000
train epoch 897 avg loss: 0.15272 (A-MSE: 0.13840) avg lploss: 0.00000
train epoch 898 avg loss: 0.17507 (A-MSE: 0.15806) avg lploss: 0.00000
train epoch 899 avg loss: 0.17208 (A-MSE: 0.15695) avg lploss: 0.00000
train epoch 900 avg loss: 0.18606 (A-MSE: 0.16701) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.54346 (A-MSE: 0.48189) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.63243 (A-MSE: 0.55709) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 9 out of 50
train epoch 901 avg loss: 0.20615 (A-MSE: 0.18560) avg lploss: 0.00000
train epoch 902 avg loss: 0.17136 (A-MSE: 0.15420) avg lploss: 0.00000
train epoch 903 avg loss: 0.17122 (A-MSE: 0.15483) avg lploss: 0.00000
train epoch 904 avg loss: 0.15343 (A-MSE: 0.13718) avg lploss: 0.00000
train epoch 905 avg loss: 0.16106 (A-MSE: 0.14419) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.45926 (A-MSE: 0.40879) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.50483 (A-MSE: 0.45103) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 10 out of 50
train epoch 906 avg loss: 0.15885 (A-MSE: 0.14272) avg lploss: 0.00000
train epoch 907 avg loss: 0.17846 (A-MSE: 0.16179) avg lploss: 0.00000
train epoch 908 avg loss: 0.18039 (A-MSE: 0.16375) avg lploss: 0.00000
train epoch 909 avg loss: 0.20062 (A-MSE: 0.18054) avg lploss: 0.00000
train epoch 910 avg loss: 0.24014 (A-MSE: 0.21650) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.50202 (A-MSE: 0.45150) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.54180 (A-MSE: 0.48257) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 11 out of 50
train epoch 911 avg loss: 0.17856 (A-MSE: 0.16179) avg lploss: 0.00000
train epoch 912 avg loss: 0.17542 (A-MSE: 0.15787) avg lploss: 0.00000
train epoch 913 avg loss: 0.18409 (A-MSE: 0.16493) avg lploss: 0.00000
train epoch 914 avg loss: 0.19023 (A-MSE: 0.17257) avg lploss: 0.00000
train epoch 915 avg loss: 0.16180 (A-MSE: 0.14675) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.41468 (A-MSE: 0.37211) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.49568 (A-MSE: 0.44553) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 12 out of 50
train epoch 916 avg loss: 0.13378 (A-MSE: 0.12191) avg lploss: 0.00000
train epoch 917 avg loss: 0.14187 (A-MSE: 0.12837) avg lploss: 0.00000
train epoch 918 avg loss: 0.15647 (A-MSE: 0.14221) avg lploss: 0.00000
train epoch 919 avg loss: 0.16202 (A-MSE: 0.14577) avg lploss: 0.00000
train epoch 920 avg loss: 0.14727 (A-MSE: 0.13376) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.45152 (A-MSE: 0.40165) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.52037 (A-MSE: 0.46266) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 13 out of 50
train epoch 921 avg loss: 0.16304 (A-MSE: 0.14675) avg lploss: 0.00000
train epoch 922 avg loss: 0.15106 (A-MSE: 0.13750) avg lploss: 0.00000
train epoch 923 avg loss: 0.15540 (A-MSE: 0.13867) avg lploss: 0.00000
train epoch 924 avg loss: 0.16712 (A-MSE: 0.15123) avg lploss: 0.00000
train epoch 925 avg loss: 0.17699 (A-MSE: 0.16157) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.43304 (A-MSE: 0.38310) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.50778 (A-MSE: 0.45141) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 14 out of 50
train epoch 926 avg loss: 0.16856 (A-MSE: 0.15194) avg lploss: 0.00000
train epoch 927 avg loss: 0.13981 (A-MSE: 0.12701) avg lploss: 0.00000
train epoch 928 avg loss: 0.14407 (A-MSE: 0.13039) avg lploss: 0.00000
train epoch 929 avg loss: 0.14352 (A-MSE: 0.12981) avg lploss: 0.00000
train epoch 930 avg loss: 0.15221 (A-MSE: 0.13596) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.42614 (A-MSE: 0.38653) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.48269 (A-MSE: 0.43233) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 15 out of 50
train epoch 931 avg loss: 0.14437 (A-MSE: 0.13076) avg lploss: 0.00000
train epoch 932 avg loss: 0.14349 (A-MSE: 0.12966) avg lploss: 0.00000
train epoch 933 avg loss: 0.17728 (A-MSE: 0.16054) avg lploss: 0.00000
train epoch 934 avg loss: 0.18643 (A-MSE: 0.16705) avg lploss: 0.00000
train epoch 935 avg loss: 0.18855 (A-MSE: 0.16992) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.55132 (A-MSE: 0.49258) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.60876 (A-MSE: 0.53813) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 16 out of 50
train epoch 936 avg loss: 0.17439 (A-MSE: 0.15682) avg lploss: 0.00000
train epoch 937 avg loss: 0.20374 (A-MSE: 0.18401) avg lploss: 0.00000
train epoch 938 avg loss: 0.17495 (A-MSE: 0.15872) avg lploss: 0.00000
train epoch 939 avg loss: 0.16019 (A-MSE: 0.14549) avg lploss: 0.00000
train epoch 940 avg loss: 0.16192 (A-MSE: 0.14504) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.42299 (A-MSE: 0.37312) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.48663 (A-MSE: 0.43528) avg lploss: 0.00000
*** Best Val Loss: 0.39559 	 Best Test Loss: 0.46210 	 Best epoch 855
EarlyStopping counter: 17 out of 50
train epoch 941 avg loss: 0.17765 (A-MSE: 0.16061) avg lploss: 0.00000
train epoch 942 avg loss: 0.16854 (A-MSE: 0.15270) avg lploss: 0.00000
train epoch 943 avg loss: 0.16590 (A-MSE: 0.14923) avg lploss: 0.00000
train epoch 944 avg loss: 0.13562 (A-MSE: 0.12324) avg lploss: 0.00000
train epoch 945 avg loss: 0.12925 (A-MSE: 0.11622) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.38101 (A-MSE: 0.34034) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.44119 (A-MSE: 0.39500) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
Validation loss decreased (0.395595 --> 0.381010).  Saving model ...
train epoch 946 avg loss: 0.17069 (A-MSE: 0.15301) avg lploss: 0.00000
train epoch 947 avg loss: 0.19034 (A-MSE: 0.17263) avg lploss: 0.00000
train epoch 948 avg loss: 0.16188 (A-MSE: 0.14610) avg lploss: 0.00000
train epoch 949 avg loss: 0.16491 (A-MSE: 0.14906) avg lploss: 0.00000
train epoch 950 avg loss: 0.14756 (A-MSE: 0.13464) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.46942 (A-MSE: 0.40960) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.49019 (A-MSE: 0.43236) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 1 out of 50
train epoch 951 avg loss: 0.13912 (A-MSE: 0.12509) avg lploss: 0.00000
train epoch 952 avg loss: 0.16277 (A-MSE: 0.14900) avg lploss: 0.00000
train epoch 953 avg loss: 0.14089 (A-MSE: 0.12670) avg lploss: 0.00000
train epoch 954 avg loss: 0.13924 (A-MSE: 0.12559) avg lploss: 0.00000
train epoch 955 avg loss: 0.14989 (A-MSE: 0.13571) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.51591 (A-MSE: 0.45575) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.54232 (A-MSE: 0.48046) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 2 out of 50
train epoch 956 avg loss: 0.15513 (A-MSE: 0.13931) avg lploss: 0.00000
train epoch 957 avg loss: 0.17747 (A-MSE: 0.16061) avg lploss: 0.00000
train epoch 958 avg loss: 0.17360 (A-MSE: 0.15639) avg lploss: 0.00000
train epoch 959 avg loss: 0.14130 (A-MSE: 0.12731) avg lploss: 0.00000
train epoch 960 avg loss: 0.12463 (A-MSE: 0.11286) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.44181 (A-MSE: 0.39283) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.49056 (A-MSE: 0.43391) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 3 out of 50
train epoch 961 avg loss: 0.13085 (A-MSE: 0.11825) avg lploss: 0.00000
train epoch 962 avg loss: 0.16673 (A-MSE: 0.14992) avg lploss: 0.00000
train epoch 963 avg loss: 0.15145 (A-MSE: 0.13614) avg lploss: 0.00000
train epoch 964 avg loss: 0.13087 (A-MSE: 0.11872) avg lploss: 0.00000
train epoch 965 avg loss: 0.14357 (A-MSE: 0.12927) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.43970 (A-MSE: 0.38701) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.52588 (A-MSE: 0.46294) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 4 out of 50
train epoch 966 avg loss: 0.19821 (A-MSE: 0.17954) avg lploss: 0.00000
train epoch 967 avg loss: 0.18019 (A-MSE: 0.16241) avg lploss: 0.00000
train epoch 968 avg loss: 0.16425 (A-MSE: 0.14786) avg lploss: 0.00000
train epoch 969 avg loss: 0.16913 (A-MSE: 0.15248) avg lploss: 0.00000
train epoch 970 avg loss: 0.19343 (A-MSE: 0.17228) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.51843 (A-MSE: 0.46751) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.55174 (A-MSE: 0.49516) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 5 out of 50
train epoch 971 avg loss: 0.20459 (A-MSE: 0.18467) avg lploss: 0.00000
train epoch 972 avg loss: 0.16503 (A-MSE: 0.14929) avg lploss: 0.00000
train epoch 973 avg loss: 0.13969 (A-MSE: 0.12633) avg lploss: 0.00000
train epoch 974 avg loss: 0.13516 (A-MSE: 0.12305) avg lploss: 0.00000
train epoch 975 avg loss: 0.16443 (A-MSE: 0.14910) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.45830 (A-MSE: 0.40801) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.51746 (A-MSE: 0.45509) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 6 out of 50
train epoch 976 avg loss: 0.15177 (A-MSE: 0.13600) avg lploss: 0.00000
train epoch 977 avg loss: 0.15395 (A-MSE: 0.13873) avg lploss: 0.00000
train epoch 978 avg loss: 0.13828 (A-MSE: 0.12404) avg lploss: 0.00000
train epoch 979 avg loss: 0.15157 (A-MSE: 0.13727) avg lploss: 0.00000
train epoch 980 avg loss: 0.16303 (A-MSE: 0.14866) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.60294 (A-MSE: 0.53053) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.65169 (A-MSE: 0.57027) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 7 out of 50
train epoch 981 avg loss: 0.17812 (A-MSE: 0.16039) avg lploss: 0.00000
train epoch 982 avg loss: 0.13686 (A-MSE: 0.12349) avg lploss: 0.00000
train epoch 983 avg loss: 0.12677 (A-MSE: 0.11506) avg lploss: 0.00000
train epoch 984 avg loss: 0.16634 (A-MSE: 0.15081) avg lploss: 0.00000
train epoch 985 avg loss: 0.16271 (A-MSE: 0.14567) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.43683 (A-MSE: 0.39285) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.48350 (A-MSE: 0.43785) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 8 out of 50
train epoch 986 avg loss: 0.14870 (A-MSE: 0.13422) avg lploss: 0.00000
train epoch 987 avg loss: 0.14804 (A-MSE: 0.13419) avg lploss: 0.00000
train epoch 988 avg loss: 0.15099 (A-MSE: 0.13646) avg lploss: 0.00000
train epoch 989 avg loss: 0.14849 (A-MSE: 0.13432) avg lploss: 0.00000
train epoch 990 avg loss: 0.15318 (A-MSE: 0.13749) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.42601 (A-MSE: 0.37547) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.48264 (A-MSE: 0.43065) avg lploss: 0.00000
*** Best Val Loss: 0.38101 	 Best Test Loss: 0.44119 	 Best epoch 945
EarlyStopping counter: 9 out of 50
train epoch 991 avg loss: 0.14657 (A-MSE: 0.13170) avg lploss: 0.00000
train epoch 992 avg loss: 0.14201 (A-MSE: 0.12840) avg lploss: 0.00000
train epoch 993 avg loss: 0.11815 (A-MSE: 0.10676) avg lploss: 0.00000
train epoch 994 avg loss: 0.12048 (A-MSE: 0.10944) avg lploss: 0.00000
train epoch 995 avg loss: 0.14210 (A-MSE: 0.12878) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.36445 (A-MSE: 0.32909) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.45696 (A-MSE: 0.41242) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
Validation loss decreased (0.381010 --> 0.364454).  Saving model ...
train epoch 996 avg loss: 0.14980 (A-MSE: 0.13587) avg lploss: 0.00000
train epoch 997 avg loss: 0.13263 (A-MSE: 0.12008) avg lploss: 0.00000
train epoch 998 avg loss: 0.12788 (A-MSE: 0.11651) avg lploss: 0.00000
train epoch 999 avg loss: 0.15189 (A-MSE: 0.13697) avg lploss: 0.00000
train epoch 1000 avg loss: 0.19229 (A-MSE: 0.17250) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.43981 (A-MSE: 0.39625) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.50134 (A-MSE: 0.45208) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 1 out of 50
train epoch 1001 avg loss: 0.15801 (A-MSE: 0.14284) avg lploss: 0.00000
train epoch 1002 avg loss: 0.14762 (A-MSE: 0.13430) avg lploss: 0.00000
train epoch 1003 avg loss: 0.13086 (A-MSE: 0.11835) avg lploss: 0.00000
train epoch 1004 avg loss: 0.12617 (A-MSE: 0.11395) avg lploss: 0.00000
train epoch 1005 avg loss: 0.13624 (A-MSE: 0.12277) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.46442 (A-MSE: 0.40663) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.53993 (A-MSE: 0.47274) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 2 out of 50
train epoch 1006 avg loss: 0.14491 (A-MSE: 0.13119) avg lploss: 0.00000
train epoch 1007 avg loss: 0.13946 (A-MSE: 0.12515) avg lploss: 0.00000
train epoch 1008 avg loss: 0.13187 (A-MSE: 0.11896) avg lploss: 0.00000
train epoch 1009 avg loss: 0.14004 (A-MSE: 0.12582) avg lploss: 0.00000
train epoch 1010 avg loss: 0.14221 (A-MSE: 0.12866) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.57382 (A-MSE: 0.51112) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.63308 (A-MSE: 0.55865) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 3 out of 50
train epoch 1011 avg loss: 0.14830 (A-MSE: 0.13428) avg lploss: 0.00000
train epoch 1012 avg loss: 0.14669 (A-MSE: 0.13278) avg lploss: 0.00000
train epoch 1013 avg loss: 0.12722 (A-MSE: 0.11495) avg lploss: 0.00000
train epoch 1014 avg loss: 0.14080 (A-MSE: 0.12755) avg lploss: 0.00000
train epoch 1015 avg loss: 0.14512 (A-MSE: 0.12939) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.44163 (A-MSE: 0.38939) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.49431 (A-MSE: 0.43659) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 4 out of 50
train epoch 1016 avg loss: 0.17825 (A-MSE: 0.16101) avg lploss: 0.00000
train epoch 1017 avg loss: 0.21332 (A-MSE: 0.19236) avg lploss: 0.00000
train epoch 1018 avg loss: 0.16338 (A-MSE: 0.14705) avg lploss: 0.00000
train epoch 1019 avg loss: 0.13409 (A-MSE: 0.11998) avg lploss: 0.00000
train epoch 1020 avg loss: 0.15021 (A-MSE: 0.13521) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.41480 (A-MSE: 0.36774) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.49848 (A-MSE: 0.44426) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 5 out of 50
train epoch 1021 avg loss: 0.16967 (A-MSE: 0.15456) avg lploss: 0.00000
train epoch 1022 avg loss: 0.16744 (A-MSE: 0.15163) avg lploss: 0.00000
train epoch 1023 avg loss: 0.16310 (A-MSE: 0.14791) avg lploss: 0.00000
train epoch 1024 avg loss: 0.14653 (A-MSE: 0.13089) avg lploss: 0.00000
train epoch 1025 avg loss: 0.16828 (A-MSE: 0.15212) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.49715 (A-MSE: 0.42996) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.53538 (A-MSE: 0.46446) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 6 out of 50
train epoch 1026 avg loss: 0.16350 (A-MSE: 0.14649) avg lploss: 0.00000
train epoch 1027 avg loss: 0.14497 (A-MSE: 0.13081) avg lploss: 0.00000
train epoch 1028 avg loss: 0.13834 (A-MSE: 0.12534) avg lploss: 0.00000
train epoch 1029 avg loss: 0.13248 (A-MSE: 0.11873) avg lploss: 0.00000
train epoch 1030 avg loss: 0.14609 (A-MSE: 0.13196) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.38586 (A-MSE: 0.34493) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.45823 (A-MSE: 0.41003) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 7 out of 50
train epoch 1031 avg loss: 0.14778 (A-MSE: 0.13361) avg lploss: 0.00000
train epoch 1032 avg loss: 0.13913 (A-MSE: 0.12493) avg lploss: 0.00000
train epoch 1033 avg loss: 0.13852 (A-MSE: 0.12381) avg lploss: 0.00000
train epoch 1034 avg loss: 0.12714 (A-MSE: 0.11479) avg lploss: 0.00000
train epoch 1035 avg loss: 0.12508 (A-MSE: 0.11295) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.39336 (A-MSE: 0.34987) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.46053 (A-MSE: 0.40931) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 8 out of 50
train epoch 1036 avg loss: 0.13010 (A-MSE: 0.11747) avg lploss: 0.00000
train epoch 1037 avg loss: 0.12415 (A-MSE: 0.11164) avg lploss: 0.00000
train epoch 1038 avg loss: 0.14005 (A-MSE: 0.12623) avg lploss: 0.00000
train epoch 1039 avg loss: 0.14215 (A-MSE: 0.12820) avg lploss: 0.00000
train epoch 1040 avg loss: 0.14304 (A-MSE: 0.13025) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.50927 (A-MSE: 0.45326) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.53849 (A-MSE: 0.47881) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 9 out of 50
train epoch 1041 avg loss: 0.15873 (A-MSE: 0.14373) avg lploss: 0.00000
train epoch 1042 avg loss: 0.13823 (A-MSE: 0.12514) avg lploss: 0.00000
train epoch 1043 avg loss: 0.13080 (A-MSE: 0.11825) avg lploss: 0.00000
train epoch 1044 avg loss: 0.12513 (A-MSE: 0.11289) avg lploss: 0.00000
train epoch 1045 avg loss: 0.12113 (A-MSE: 0.10999) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.48187 (A-MSE: 0.42574) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.54178 (A-MSE: 0.47472) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 10 out of 50
train epoch 1046 avg loss: 0.12833 (A-MSE: 0.11620) avg lploss: 0.00000
train epoch 1047 avg loss: 0.12894 (A-MSE: 0.11580) avg lploss: 0.00000
train epoch 1048 avg loss: 0.18922 (A-MSE: 0.17084) avg lploss: 0.00000
train epoch 1049 avg loss: 0.16923 (A-MSE: 0.15220) avg lploss: 0.00000
train epoch 1050 avg loss: 0.13564 (A-MSE: 0.12254) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.42259 (A-MSE: 0.37485) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.48863 (A-MSE: 0.43426) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 11 out of 50
train epoch 1051 avg loss: 0.12911 (A-MSE: 0.11618) avg lploss: 0.00000
train epoch 1052 avg loss: 0.15043 (A-MSE: 0.13664) avg lploss: 0.00000
train epoch 1053 avg loss: 0.14653 (A-MSE: 0.13224) avg lploss: 0.00000
train epoch 1054 avg loss: 0.15486 (A-MSE: 0.13928) avg lploss: 0.00000
train epoch 1055 avg loss: 0.14191 (A-MSE: 0.12793) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.36462 (A-MSE: 0.32666) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.45765 (A-MSE: 0.41747) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 12 out of 50
train epoch 1056 avg loss: 0.14037 (A-MSE: 0.12600) avg lploss: 0.00000
train epoch 1057 avg loss: 0.12739 (A-MSE: 0.11554) avg lploss: 0.00000
train epoch 1058 avg loss: 0.13645 (A-MSE: 0.12337) avg lploss: 0.00000
train epoch 1059 avg loss: 0.14337 (A-MSE: 0.12872) avg lploss: 0.00000
train epoch 1060 avg loss: 0.13626 (A-MSE: 0.12437) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.47311 (A-MSE: 0.41871) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.52963 (A-MSE: 0.46896) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 13 out of 50
train epoch 1061 avg loss: 0.14283 (A-MSE: 0.12898) avg lploss: 0.00000
train epoch 1062 avg loss: 0.19078 (A-MSE: 0.17087) avg lploss: 0.00000
train epoch 1063 avg loss: 0.21199 (A-MSE: 0.18919) avg lploss: 0.00000
train epoch 1064 avg loss: 0.16497 (A-MSE: 0.14804) avg lploss: 0.00000
train epoch 1065 avg loss: 0.14646 (A-MSE: 0.13355) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.45314 (A-MSE: 0.40002) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.49129 (A-MSE: 0.43607) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 14 out of 50
train epoch 1066 avg loss: 0.14407 (A-MSE: 0.12955) avg lploss: 0.00000
train epoch 1067 avg loss: 0.14109 (A-MSE: 0.12776) avg lploss: 0.00000
train epoch 1068 avg loss: 0.14548 (A-MSE: 0.13214) avg lploss: 0.00000
train epoch 1069 avg loss: 0.13482 (A-MSE: 0.12202) avg lploss: 0.00000
train epoch 1070 avg loss: 0.14176 (A-MSE: 0.12736) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.44045 (A-MSE: 0.38982) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.52863 (A-MSE: 0.46846) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 15 out of 50
train epoch 1071 avg loss: 0.12655 (A-MSE: 0.11457) avg lploss: 0.00000
train epoch 1072 avg loss: 0.14234 (A-MSE: 0.12719) avg lploss: 0.00000
train epoch 1073 avg loss: 0.14209 (A-MSE: 0.12813) avg lploss: 0.00000
train epoch 1074 avg loss: 0.12052 (A-MSE: 0.10903) avg lploss: 0.00000
train epoch 1075 avg loss: 0.12144 (A-MSE: 0.10946) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.42560 (A-MSE: 0.37511) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.47813 (A-MSE: 0.42765) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 16 out of 50
train epoch 1076 avg loss: 0.11789 (A-MSE: 0.10607) avg lploss: 0.00000
train epoch 1077 avg loss: 0.11585 (A-MSE: 0.10569) avg lploss: 0.00000
train epoch 1078 avg loss: 0.11332 (A-MSE: 0.10291) avg lploss: 0.00000
train epoch 1079 avg loss: 0.13401 (A-MSE: 0.12011) avg lploss: 0.00000
train epoch 1080 avg loss: 0.12739 (A-MSE: 0.11484) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.43015 (A-MSE: 0.38734) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.49050 (A-MSE: 0.43855) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 17 out of 50
train epoch 1081 avg loss: 0.14087 (A-MSE: 0.12600) avg lploss: 0.00000
train epoch 1082 avg loss: 0.12583 (A-MSE: 0.11425) avg lploss: 0.00000
train epoch 1083 avg loss: 0.12070 (A-MSE: 0.10877) avg lploss: 0.00000
train epoch 1084 avg loss: 0.12779 (A-MSE: 0.11510) avg lploss: 0.00000
train epoch 1085 avg loss: 0.15393 (A-MSE: 0.13947) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.54355 (A-MSE: 0.47954) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.58878 (A-MSE: 0.52234) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 18 out of 50
train epoch 1086 avg loss: 0.14862 (A-MSE: 0.13369) avg lploss: 0.00000
train epoch 1087 avg loss: 0.12547 (A-MSE: 0.11430) avg lploss: 0.00000
train epoch 1088 avg loss: 0.11799 (A-MSE: 0.10683) avg lploss: 0.00000
train epoch 1089 avg loss: 0.14101 (A-MSE: 0.12677) avg lploss: 0.00000
train epoch 1090 avg loss: 0.15030 (A-MSE: 0.13642) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.42948 (A-MSE: 0.37678) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.51361 (A-MSE: 0.45371) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 19 out of 50
train epoch 1091 avg loss: 0.12651 (A-MSE: 0.11364) avg lploss: 0.00000
train epoch 1092 avg loss: 0.13063 (A-MSE: 0.11746) avg lploss: 0.00000
train epoch 1093 avg loss: 0.11400 (A-MSE: 0.10275) avg lploss: 0.00000
train epoch 1094 avg loss: 0.11901 (A-MSE: 0.10769) avg lploss: 0.00000
train epoch 1095 avg loss: 0.11071 (A-MSE: 0.10056) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.37896 (A-MSE: 0.33628) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.44734 (A-MSE: 0.39958) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 20 out of 50
train epoch 1096 avg loss: 0.12152 (A-MSE: 0.10882) avg lploss: 0.00000
train epoch 1097 avg loss: 0.13586 (A-MSE: 0.12215) avg lploss: 0.00000
train epoch 1098 avg loss: 0.12223 (A-MSE: 0.10926) avg lploss: 0.00000
train epoch 1099 avg loss: 0.11335 (A-MSE: 0.10226) avg lploss: 0.00000
train epoch 1100 avg loss: 0.10735 (A-MSE: 0.09741) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.39739 (A-MSE: 0.35030) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.45561 (A-MSE: 0.40455) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 21 out of 50
train epoch 1101 avg loss: 0.10324 (A-MSE: 0.09326) avg lploss: 0.00000
train epoch 1102 avg loss: 0.09986 (A-MSE: 0.09003) avg lploss: 0.00000
train epoch 1103 avg loss: 0.12326 (A-MSE: 0.11127) avg lploss: 0.00000
train epoch 1104 avg loss: 0.11191 (A-MSE: 0.10055) avg lploss: 0.00000
train epoch 1105 avg loss: 0.12560 (A-MSE: 0.11366) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.42612 (A-MSE: 0.37817) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.49830 (A-MSE: 0.44126) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 22 out of 50
train epoch 1106 avg loss: 0.18161 (A-MSE: 0.16328) avg lploss: 0.00000
train epoch 1107 avg loss: 0.20997 (A-MSE: 0.18904) avg lploss: 0.00000
train epoch 1108 avg loss: 0.18588 (A-MSE: 0.16774) avg lploss: 0.00000
train epoch 1109 avg loss: 0.17557 (A-MSE: 0.15681) avg lploss: 0.00000
train epoch 1110 avg loss: 0.13255 (A-MSE: 0.11899) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.43527 (A-MSE: 0.38614) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.46412 (A-MSE: 0.41525) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 23 out of 50
train epoch 1111 avg loss: 0.12040 (A-MSE: 0.10939) avg lploss: 0.00000
train epoch 1112 avg loss: 0.10343 (A-MSE: 0.09293) avg lploss: 0.00000
train epoch 1113 avg loss: 0.10569 (A-MSE: 0.09549) avg lploss: 0.00000
train epoch 1114 avg loss: 0.11624 (A-MSE: 0.10484) avg lploss: 0.00000
train epoch 1115 avg loss: 0.11493 (A-MSE: 0.10376) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.46513 (A-MSE: 0.40929) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.51102 (A-MSE: 0.44944) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 24 out of 50
train epoch 1116 avg loss: 0.10855 (A-MSE: 0.09809) avg lploss: 0.00000
train epoch 1117 avg loss: 0.12423 (A-MSE: 0.11231) avg lploss: 0.00000
train epoch 1118 avg loss: 0.10886 (A-MSE: 0.09825) avg lploss: 0.00000
train epoch 1119 avg loss: 0.11697 (A-MSE: 0.10541) avg lploss: 0.00000
train epoch 1120 avg loss: 0.12680 (A-MSE: 0.11447) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.37821 (A-MSE: 0.33202) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.42273 (A-MSE: 0.37756) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 25 out of 50
train epoch 1121 avg loss: 0.13049 (A-MSE: 0.11697) avg lploss: 0.00000
train epoch 1122 avg loss: 0.13430 (A-MSE: 0.12100) avg lploss: 0.00000
train epoch 1123 avg loss: 0.13809 (A-MSE: 0.12494) avg lploss: 0.00000
train epoch 1124 avg loss: 0.14210 (A-MSE: 0.12695) avg lploss: 0.00000
train epoch 1125 avg loss: 0.14820 (A-MSE: 0.13180) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.43028 (A-MSE: 0.37927) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.47061 (A-MSE: 0.42382) avg lploss: 0.00000
*** Best Val Loss: 0.36445 	 Best Test Loss: 0.45696 	 Best epoch 995
EarlyStopping counter: 26 out of 50
train epoch 1126 avg loss: 0.14133 (A-MSE: 0.12793) avg lploss: 0.00000
train epoch 1127 avg loss: 0.14188 (A-MSE: 0.12783) avg lploss: 0.00000
train epoch 1128 avg loss: 0.11566 (A-MSE: 0.10450) avg lploss: 0.00000
train epoch 1129 avg loss: 0.12072 (A-MSE: 0.10914) avg lploss: 0.00000
train epoch 1130 avg loss: 0.11593 (A-MSE: 0.10452) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.35741 (A-MSE: 0.31489) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.45872 (A-MSE: 0.40434) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
Validation loss decreased (0.364454 --> 0.357407).  Saving model ...
train epoch 1131 avg loss: 0.11516 (A-MSE: 0.10395) avg lploss: 0.00000
train epoch 1132 avg loss: 0.17360 (A-MSE: 0.15408) avg lploss: 0.00000
train epoch 1133 avg loss: 0.19860 (A-MSE: 0.17755) avg lploss: 0.00000
train epoch 1134 avg loss: 0.17426 (A-MSE: 0.15652) avg lploss: 0.00000
train epoch 1135 avg loss: 0.12380 (A-MSE: 0.11101) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.45892 (A-MSE: 0.40555) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.51581 (A-MSE: 0.45055) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 1 out of 50
train epoch 1136 avg loss: 0.12643 (A-MSE: 0.11333) avg lploss: 0.00000
train epoch 1137 avg loss: 0.12619 (A-MSE: 0.11311) avg lploss: 0.00000
train epoch 1138 avg loss: 0.11070 (A-MSE: 0.10034) avg lploss: 0.00000
train epoch 1139 avg loss: 0.12853 (A-MSE: 0.11549) avg lploss: 0.00000
train epoch 1140 avg loss: 0.13835 (A-MSE: 0.12492) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.43448 (A-MSE: 0.38227) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.49128 (A-MSE: 0.43947) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 2 out of 50
train epoch 1141 avg loss: 0.12681 (A-MSE: 0.11393) avg lploss: 0.00000
train epoch 1142 avg loss: 0.12020 (A-MSE: 0.10913) avg lploss: 0.00000
train epoch 1143 avg loss: 0.11595 (A-MSE: 0.10493) avg lploss: 0.00000
train epoch 1144 avg loss: 0.12554 (A-MSE: 0.11287) avg lploss: 0.00000
train epoch 1145 avg loss: 0.12094 (A-MSE: 0.10865) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.40700 (A-MSE: 0.36275) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.46836 (A-MSE: 0.41774) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 3 out of 50
train epoch 1146 avg loss: 0.11650 (A-MSE: 0.10462) avg lploss: 0.00000
train epoch 1147 avg loss: 0.12863 (A-MSE: 0.11607) avg lploss: 0.00000
train epoch 1148 avg loss: 0.12135 (A-MSE: 0.10905) avg lploss: 0.00000
train epoch 1149 avg loss: 0.10984 (A-MSE: 0.09821) avg lploss: 0.00000
train epoch 1150 avg loss: 0.11905 (A-MSE: 0.10781) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.40932 (A-MSE: 0.36052) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.46857 (A-MSE: 0.41380) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 4 out of 50
train epoch 1151 avg loss: 0.11207 (A-MSE: 0.10078) avg lploss: 0.00000
train epoch 1152 avg loss: 0.09200 (A-MSE: 0.08299) avg lploss: 0.00000
train epoch 1153 avg loss: 0.09394 (A-MSE: 0.08493) avg lploss: 0.00000
train epoch 1154 avg loss: 0.09947 (A-MSE: 0.09062) avg lploss: 0.00000
train epoch 1155 avg loss: 0.10578 (A-MSE: 0.09565) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.43624 (A-MSE: 0.38056) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.49965 (A-MSE: 0.43793) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 5 out of 50
train epoch 1156 avg loss: 0.10359 (A-MSE: 0.09331) avg lploss: 0.00000
train epoch 1157 avg loss: 0.10237 (A-MSE: 0.09187) avg lploss: 0.00000
train epoch 1158 avg loss: 0.10486 (A-MSE: 0.09451) avg lploss: 0.00000
train epoch 1159 avg loss: 0.11903 (A-MSE: 0.10702) avg lploss: 0.00000
train epoch 1160 avg loss: 0.10233 (A-MSE: 0.09197) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.38700 (A-MSE: 0.33720) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.43799 (A-MSE: 0.38775) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 6 out of 50
train epoch 1161 avg loss: 0.12215 (A-MSE: 0.10932) avg lploss: 0.00000
train epoch 1162 avg loss: 0.12019 (A-MSE: 0.10869) avg lploss: 0.00000
train epoch 1163 avg loss: 0.12721 (A-MSE: 0.11410) avg lploss: 0.00000
train epoch 1164 avg loss: 0.11165 (A-MSE: 0.10087) avg lploss: 0.00000
train epoch 1165 avg loss: 0.11427 (A-MSE: 0.10229) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.36470 (A-MSE: 0.32576) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.43032 (A-MSE: 0.38365) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 7 out of 50
train epoch 1166 avg loss: 0.16469 (A-MSE: 0.14926) avg lploss: 0.00000
train epoch 1167 avg loss: 0.13903 (A-MSE: 0.12592) avg lploss: 0.00000
train epoch 1168 avg loss: 0.13147 (A-MSE: 0.11970) avg lploss: 0.00000
train epoch 1169 avg loss: 0.10953 (A-MSE: 0.09860) avg lploss: 0.00000
train epoch 1170 avg loss: 0.10026 (A-MSE: 0.09044) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.40061 (A-MSE: 0.35242) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.46925 (A-MSE: 0.41469) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 8 out of 50
train epoch 1171 avg loss: 0.11402 (A-MSE: 0.10199) avg lploss: 0.00000
train epoch 1172 avg loss: 0.11613 (A-MSE: 0.10485) avg lploss: 0.00000
train epoch 1173 avg loss: 0.10694 (A-MSE: 0.09565) avg lploss: 0.00000
train epoch 1174 avg loss: 0.11271 (A-MSE: 0.10150) avg lploss: 0.00000
train epoch 1175 avg loss: 0.12666 (A-MSE: 0.11407) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.39483 (A-MSE: 0.35083) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.45471 (A-MSE: 0.40961) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 9 out of 50
train epoch 1176 avg loss: 0.15690 (A-MSE: 0.14060) avg lploss: 0.00000
train epoch 1177 avg loss: 0.13437 (A-MSE: 0.12209) avg lploss: 0.00000
train epoch 1178 avg loss: 0.11791 (A-MSE: 0.10552) avg lploss: 0.00000
train epoch 1179 avg loss: 0.12036 (A-MSE: 0.10900) avg lploss: 0.00000
train epoch 1180 avg loss: 0.10624 (A-MSE: 0.09511) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.41920 (A-MSE: 0.36832) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.48880 (A-MSE: 0.42871) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 10 out of 50
train epoch 1181 avg loss: 0.10368 (A-MSE: 0.09273) avg lploss: 0.00000
train epoch 1182 avg loss: 0.11666 (A-MSE: 0.10478) avg lploss: 0.00000
train epoch 1183 avg loss: 0.14516 (A-MSE: 0.13075) avg lploss: 0.00000
train epoch 1184 avg loss: 0.14035 (A-MSE: 0.12725) avg lploss: 0.00000
train epoch 1185 avg loss: 0.13453 (A-MSE: 0.11937) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.42646 (A-MSE: 0.37635) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.49485 (A-MSE: 0.43924) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 11 out of 50
train epoch 1186 avg loss: 0.12617 (A-MSE: 0.11418) avg lploss: 0.00000
train epoch 1187 avg loss: 0.11898 (A-MSE: 0.10692) avg lploss: 0.00000
train epoch 1188 avg loss: 0.11132 (A-MSE: 0.10050) avg lploss: 0.00000
train epoch 1189 avg loss: 0.10908 (A-MSE: 0.09836) avg lploss: 0.00000
train epoch 1190 avg loss: 0.10457 (A-MSE: 0.09505) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.42543 (A-MSE: 0.37299) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.48284 (A-MSE: 0.43138) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 12 out of 50
train epoch 1191 avg loss: 0.10043 (A-MSE: 0.09110) avg lploss: 0.00000
train epoch 1192 avg loss: 0.09710 (A-MSE: 0.08711) avg lploss: 0.00000
train epoch 1193 avg loss: 0.09219 (A-MSE: 0.08316) avg lploss: 0.00000
train epoch 1194 avg loss: 0.09249 (A-MSE: 0.08398) avg lploss: 0.00000
train epoch 1195 avg loss: 0.10318 (A-MSE: 0.09335) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.41053 (A-MSE: 0.36521) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.46662 (A-MSE: 0.41802) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 13 out of 50
train epoch 1196 avg loss: 0.12116 (A-MSE: 0.10862) avg lploss: 0.00000
train epoch 1197 avg loss: 0.12223 (A-MSE: 0.10930) avg lploss: 0.00000
train epoch 1198 avg loss: 0.13685 (A-MSE: 0.12313) avg lploss: 0.00000
train epoch 1199 avg loss: 0.15482 (A-MSE: 0.13933) avg lploss: 0.00000
train epoch 1200 avg loss: 0.15501 (A-MSE: 0.13828) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.43155 (A-MSE: 0.38144) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.47979 (A-MSE: 0.42648) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 14 out of 50
train epoch 1201 avg loss: 0.11864 (A-MSE: 0.10611) avg lploss: 0.00000
train epoch 1202 avg loss: 0.10673 (A-MSE: 0.09634) avg lploss: 0.00000
train epoch 1203 avg loss: 0.10335 (A-MSE: 0.09355) avg lploss: 0.00000
train epoch 1204 avg loss: 0.09529 (A-MSE: 0.08747) avg lploss: 0.00000
train epoch 1205 avg loss: 0.10893 (A-MSE: 0.09751) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.41970 (A-MSE: 0.36499) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.47360 (A-MSE: 0.41395) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 15 out of 50
train epoch 1206 avg loss: 0.10215 (A-MSE: 0.09177) avg lploss: 0.00000
train epoch 1207 avg loss: 0.09850 (A-MSE: 0.08832) avg lploss: 0.00000
train epoch 1208 avg loss: 0.09963 (A-MSE: 0.08955) avg lploss: 0.00000
train epoch 1209 avg loss: 0.09172 (A-MSE: 0.08253) avg lploss: 0.00000
train epoch 1210 avg loss: 0.08994 (A-MSE: 0.08162) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.38978 (A-MSE: 0.34862) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.46720 (A-MSE: 0.41447) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 16 out of 50
train epoch 1211 avg loss: 0.09055 (A-MSE: 0.08227) avg lploss: 0.00000
train epoch 1212 avg loss: 0.08931 (A-MSE: 0.08066) avg lploss: 0.00000
train epoch 1213 avg loss: 0.11905 (A-MSE: 0.10666) avg lploss: 0.00000
train epoch 1214 avg loss: 0.11649 (A-MSE: 0.10381) avg lploss: 0.00000
train epoch 1215 avg loss: 0.13623 (A-MSE: 0.12242) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.51278 (A-MSE: 0.44390) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.57336 (A-MSE: 0.49624) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 17 out of 50
train epoch 1216 avg loss: 0.12558 (A-MSE: 0.11291) avg lploss: 0.00000
train epoch 1217 avg loss: 0.13314 (A-MSE: 0.11948) avg lploss: 0.00000
train epoch 1218 avg loss: 0.11035 (A-MSE: 0.10002) avg lploss: 0.00000
train epoch 1219 avg loss: 0.12096 (A-MSE: 0.10970) avg lploss: 0.00000
train epoch 1220 avg loss: 0.14502 (A-MSE: 0.13059) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.42477 (A-MSE: 0.38276) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.51648 (A-MSE: 0.46079) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 18 out of 50
train epoch 1221 avg loss: 0.13105 (A-MSE: 0.11792) avg lploss: 0.00000
train epoch 1222 avg loss: 0.13807 (A-MSE: 0.12432) avg lploss: 0.00000
train epoch 1223 avg loss: 0.11979 (A-MSE: 0.10820) avg lploss: 0.00000
train epoch 1224 avg loss: 0.12076 (A-MSE: 0.10866) avg lploss: 0.00000
train epoch 1225 avg loss: 0.11606 (A-MSE: 0.10524) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.47212 (A-MSE: 0.42505) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.51581 (A-MSE: 0.45819) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 19 out of 50
train epoch 1226 avg loss: 0.13996 (A-MSE: 0.12573) avg lploss: 0.00000
train epoch 1227 avg loss: 0.12827 (A-MSE: 0.11656) avg lploss: 0.00000
train epoch 1228 avg loss: 0.11011 (A-MSE: 0.09883) avg lploss: 0.00000
train epoch 1229 avg loss: 0.10137 (A-MSE: 0.09101) avg lploss: 0.00000
train epoch 1230 avg loss: 0.09891 (A-MSE: 0.08837) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.44579 (A-MSE: 0.38962) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.49750 (A-MSE: 0.43383) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 20 out of 50
train epoch 1231 avg loss: 0.10131 (A-MSE: 0.09169) avg lploss: 0.00000
train epoch 1232 avg loss: 0.09342 (A-MSE: 0.08477) avg lploss: 0.00000
train epoch 1233 avg loss: 0.09914 (A-MSE: 0.08945) avg lploss: 0.00000
train epoch 1234 avg loss: 0.10134 (A-MSE: 0.09102) avg lploss: 0.00000
train epoch 1235 avg loss: 0.08659 (A-MSE: 0.07863) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.40210 (A-MSE: 0.35364) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.46498 (A-MSE: 0.40798) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 21 out of 50
train epoch 1236 avg loss: 0.09526 (A-MSE: 0.08620) avg lploss: 0.00000
train epoch 1237 avg loss: 0.10126 (A-MSE: 0.09158) avg lploss: 0.00000
train epoch 1238 avg loss: 0.14407 (A-MSE: 0.13053) avg lploss: 0.00000
train epoch 1239 avg loss: 0.13477 (A-MSE: 0.12139) avg lploss: 0.00000
train epoch 1240 avg loss: 0.12297 (A-MSE: 0.11080) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.39836 (A-MSE: 0.35380) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.46156 (A-MSE: 0.40960) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 22 out of 50
train epoch 1241 avg loss: 0.12052 (A-MSE: 0.10812) avg lploss: 0.00000
train epoch 1242 avg loss: 0.11324 (A-MSE: 0.10171) avg lploss: 0.00000
train epoch 1243 avg loss: 0.12406 (A-MSE: 0.11165) avg lploss: 0.00000
train epoch 1244 avg loss: 0.11920 (A-MSE: 0.10776) avg lploss: 0.00000
train epoch 1245 avg loss: 0.11344 (A-MSE: 0.10134) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.39868 (A-MSE: 0.34685) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.46718 (A-MSE: 0.40658) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 23 out of 50
train epoch 1246 avg loss: 0.10097 (A-MSE: 0.09148) avg lploss: 0.00000
train epoch 1247 avg loss: 0.11032 (A-MSE: 0.09852) avg lploss: 0.00000
train epoch 1248 avg loss: 0.11777 (A-MSE: 0.10595) avg lploss: 0.00000
train epoch 1249 avg loss: 0.10099 (A-MSE: 0.09091) avg lploss: 0.00000
train epoch 1250 avg loss: 0.10081 (A-MSE: 0.09052) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.41905 (A-MSE: 0.37455) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.46075 (A-MSE: 0.40971) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 24 out of 50
train epoch 1251 avg loss: 0.09044 (A-MSE: 0.08089) avg lploss: 0.00000
train epoch 1252 avg loss: 0.11045 (A-MSE: 0.09965) avg lploss: 0.00000
train epoch 1253 avg loss: 0.10348 (A-MSE: 0.09297) avg lploss: 0.00000
train epoch 1254 avg loss: 0.09954 (A-MSE: 0.08911) avg lploss: 0.00000
train epoch 1255 avg loss: 0.09985 (A-MSE: 0.09021) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.45847 (A-MSE: 0.40528) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.51872 (A-MSE: 0.45604) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 25 out of 50
train epoch 1256 avg loss: 0.10438 (A-MSE: 0.09410) avg lploss: 0.00000
train epoch 1257 avg loss: 0.08851 (A-MSE: 0.07995) avg lploss: 0.00000
train epoch 1258 avg loss: 0.09211 (A-MSE: 0.08320) avg lploss: 0.00000
train epoch 1259 avg loss: 0.11072 (A-MSE: 0.09910) avg lploss: 0.00000
train epoch 1260 avg loss: 0.11047 (A-MSE: 0.09910) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.36315 (A-MSE: 0.32107) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.44104 (A-MSE: 0.39255) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 26 out of 50
train epoch 1261 avg loss: 0.11324 (A-MSE: 0.10269) avg lploss: 0.00000
train epoch 1262 avg loss: 0.11050 (A-MSE: 0.09773) avg lploss: 0.00000
train epoch 1263 avg loss: 0.11885 (A-MSE: 0.10723) avg lploss: 0.00000
train epoch 1264 avg loss: 0.10615 (A-MSE: 0.09502) avg lploss: 0.00000
train epoch 1265 avg loss: 0.10724 (A-MSE: 0.09681) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.42348 (A-MSE: 0.37336) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.48326 (A-MSE: 0.42100) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 27 out of 50
train epoch 1266 avg loss: 0.10030 (A-MSE: 0.08981) avg lploss: 0.00000
train epoch 1267 avg loss: 0.09354 (A-MSE: 0.08483) avg lploss: 0.00000
train epoch 1268 avg loss: 0.12118 (A-MSE: 0.10862) avg lploss: 0.00000
train epoch 1269 avg loss: 0.12545 (A-MSE: 0.11384) avg lploss: 0.00000
train epoch 1270 avg loss: 0.12131 (A-MSE: 0.10937) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.44516 (A-MSE: 0.39111) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.50742 (A-MSE: 0.45063) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 28 out of 50
train epoch 1271 avg loss: 0.11927 (A-MSE: 0.10754) avg lploss: 0.00000
train epoch 1272 avg loss: 0.11311 (A-MSE: 0.10154) avg lploss: 0.00000
train epoch 1273 avg loss: 0.10322 (A-MSE: 0.09252) avg lploss: 0.00000
train epoch 1274 avg loss: 0.09284 (A-MSE: 0.08439) avg lploss: 0.00000
train epoch 1275 avg loss: 0.09277 (A-MSE: 0.08471) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.42036 (A-MSE: 0.36972) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.48655 (A-MSE: 0.42564) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 29 out of 50
train epoch 1276 avg loss: 0.09217 (A-MSE: 0.08242) avg lploss: 0.00000
train epoch 1277 avg loss: 0.09302 (A-MSE: 0.08345) avg lploss: 0.00000
train epoch 1278 avg loss: 0.09744 (A-MSE: 0.08799) avg lploss: 0.00000
train epoch 1279 avg loss: 0.12790 (A-MSE: 0.11497) avg lploss: 0.00000
train epoch 1280 avg loss: 0.13219 (A-MSE: 0.12016) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.43540 (A-MSE: 0.38436) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.49642 (A-MSE: 0.44045) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 30 out of 50
train epoch 1281 avg loss: 0.11554 (A-MSE: 0.10336) avg lploss: 0.00000
train epoch 1282 avg loss: 0.10622 (A-MSE: 0.09580) avg lploss: 0.00000
train epoch 1283 avg loss: 0.09674 (A-MSE: 0.08759) avg lploss: 0.00000
train epoch 1284 avg loss: 0.09347 (A-MSE: 0.08530) avg lploss: 0.00000
train epoch 1285 avg loss: 0.10016 (A-MSE: 0.09069) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.42992 (A-MSE: 0.38154) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.51142 (A-MSE: 0.44937) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 31 out of 50
train epoch 1286 avg loss: 0.09260 (A-MSE: 0.08330) avg lploss: 0.00000
train epoch 1287 avg loss: 0.09251 (A-MSE: 0.08325) avg lploss: 0.00000
train epoch 1288 avg loss: 0.07460 (A-MSE: 0.06735) avg lploss: 0.00000
train epoch 1289 avg loss: 0.08724 (A-MSE: 0.07867) avg lploss: 0.00000
train epoch 1290 avg loss: 0.10179 (A-MSE: 0.09097) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.38758 (A-MSE: 0.34515) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.45998 (A-MSE: 0.40843) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 32 out of 50
train epoch 1291 avg loss: 0.09018 (A-MSE: 0.08107) avg lploss: 0.00000
train epoch 1292 avg loss: 0.08880 (A-MSE: 0.08067) avg lploss: 0.00000
train epoch 1293 avg loss: 0.09170 (A-MSE: 0.08257) avg lploss: 0.00000
train epoch 1294 avg loss: 0.09390 (A-MSE: 0.08504) avg lploss: 0.00000
train epoch 1295 avg loss: 0.10523 (A-MSE: 0.09438) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.38988 (A-MSE: 0.34390) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.46820 (A-MSE: 0.41603) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 33 out of 50
train epoch 1296 avg loss: 0.11118 (A-MSE: 0.10025) avg lploss: 0.00000
train epoch 1297 avg loss: 0.10036 (A-MSE: 0.09010) avg lploss: 0.00000
train epoch 1298 avg loss: 0.10039 (A-MSE: 0.09030) avg lploss: 0.00000
train epoch 1299 avg loss: 0.10256 (A-MSE: 0.09210) avg lploss: 0.00000
train epoch 1300 avg loss: 0.09236 (A-MSE: 0.08372) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.38922 (A-MSE: 0.34518) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.46753 (A-MSE: 0.41570) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 34 out of 50
train epoch 1301 avg loss: 0.10644 (A-MSE: 0.09567) avg lploss: 0.00000
train epoch 1302 avg loss: 0.11470 (A-MSE: 0.10267) avg lploss: 0.00000
train epoch 1303 avg loss: 0.10341 (A-MSE: 0.09331) avg lploss: 0.00000
train epoch 1304 avg loss: 0.08314 (A-MSE: 0.07477) avg lploss: 0.00000
train epoch 1305 avg loss: 0.09296 (A-MSE: 0.08348) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.43907 (A-MSE: 0.38676) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.49854 (A-MSE: 0.44274) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 35 out of 50
train epoch 1306 avg loss: 0.08569 (A-MSE: 0.07697) avg lploss: 0.00000
train epoch 1307 avg loss: 0.08360 (A-MSE: 0.07532) avg lploss: 0.00000
train epoch 1308 avg loss: 0.09230 (A-MSE: 0.08341) avg lploss: 0.00000
train epoch 1309 avg loss: 0.09018 (A-MSE: 0.08122) avg lploss: 0.00000
train epoch 1310 avg loss: 0.09798 (A-MSE: 0.08887) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.40471 (A-MSE: 0.36262) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.46764 (A-MSE: 0.41981) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 36 out of 50
train epoch 1311 avg loss: 0.12716 (A-MSE: 0.11433) avg lploss: 0.00000
train epoch 1312 avg loss: 0.15516 (A-MSE: 0.13968) avg lploss: 0.00000
train epoch 1313 avg loss: 0.12808 (A-MSE: 0.11553) avg lploss: 0.00000
train epoch 1314 avg loss: 0.10120 (A-MSE: 0.09011) avg lploss: 0.00000
train epoch 1315 avg loss: 0.10041 (A-MSE: 0.09101) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.38243 (A-MSE: 0.34167) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.44963 (A-MSE: 0.40555) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 37 out of 50
train epoch 1316 avg loss: 0.11294 (A-MSE: 0.10179) avg lploss: 0.00000
train epoch 1317 avg loss: 0.11651 (A-MSE: 0.10530) avg lploss: 0.00000
train epoch 1318 avg loss: 0.10606 (A-MSE: 0.09490) avg lploss: 0.00000
train epoch 1319 avg loss: 0.09972 (A-MSE: 0.08971) avg lploss: 0.00000
train epoch 1320 avg loss: 0.11667 (A-MSE: 0.10372) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.42846 (A-MSE: 0.37383) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.46908 (A-MSE: 0.41456) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 38 out of 50
train epoch 1321 avg loss: 0.10248 (A-MSE: 0.09244) avg lploss: 0.00000
train epoch 1322 avg loss: 0.08945 (A-MSE: 0.07952) avg lploss: 0.00000
train epoch 1323 avg loss: 0.09056 (A-MSE: 0.08120) avg lploss: 0.00000
train epoch 1324 avg loss: 0.08867 (A-MSE: 0.08047) avg lploss: 0.00000
train epoch 1325 avg loss: 0.09225 (A-MSE: 0.08234) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.37828 (A-MSE: 0.33557) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.45483 (A-MSE: 0.40600) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 39 out of 50
train epoch 1326 avg loss: 0.07980 (A-MSE: 0.07190) avg lploss: 0.00000
train epoch 1327 avg loss: 0.09178 (A-MSE: 0.08282) avg lploss: 0.00000
train epoch 1328 avg loss: 0.12341 (A-MSE: 0.11207) avg lploss: 0.00000
train epoch 1329 avg loss: 0.11471 (A-MSE: 0.10136) avg lploss: 0.00000
train epoch 1330 avg loss: 0.09671 (A-MSE: 0.08768) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.45250 (A-MSE: 0.40375) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.53229 (A-MSE: 0.46931) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 40 out of 50
train epoch 1331 avg loss: 0.10230 (A-MSE: 0.09170) avg lploss: 0.00000
train epoch 1332 avg loss: 0.08936 (A-MSE: 0.08044) avg lploss: 0.00000
train epoch 1333 avg loss: 0.08883 (A-MSE: 0.08012) avg lploss: 0.00000
train epoch 1334 avg loss: 0.09709 (A-MSE: 0.08833) avg lploss: 0.00000
train epoch 1335 avg loss: 0.14897 (A-MSE: 0.13413) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.47072 (A-MSE: 0.40395) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.50166 (A-MSE: 0.43608) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 41 out of 50
train epoch 1336 avg loss: 0.15469 (A-MSE: 0.13801) avg lploss: 0.00000
train epoch 1337 avg loss: 0.14339 (A-MSE: 0.12907) avg lploss: 0.00000
train epoch 1338 avg loss: 0.10588 (A-MSE: 0.09523) avg lploss: 0.00000
train epoch 1339 avg loss: 0.12959 (A-MSE: 0.11609) avg lploss: 0.00000
train epoch 1340 avg loss: 0.13727 (A-MSE: 0.12308) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.39535 (A-MSE: 0.35077) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.47803 (A-MSE: 0.42857) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 42 out of 50
train epoch 1341 avg loss: 0.11504 (A-MSE: 0.10302) avg lploss: 0.00000
train epoch 1342 avg loss: 0.11941 (A-MSE: 0.10686) avg lploss: 0.00000
train epoch 1343 avg loss: 0.12289 (A-MSE: 0.11008) avg lploss: 0.00000
train epoch 1344 avg loss: 0.09906 (A-MSE: 0.08889) avg lploss: 0.00000
train epoch 1345 avg loss: 0.08138 (A-MSE: 0.07312) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.36102 (A-MSE: 0.31970) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.42704 (A-MSE: 0.37969) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 43 out of 50
train epoch 1346 avg loss: 0.07883 (A-MSE: 0.07030) avg lploss: 0.00000
train epoch 1347 avg loss: 0.07795 (A-MSE: 0.07033) avg lploss: 0.00000
train epoch 1348 avg loss: 0.07845 (A-MSE: 0.07060) avg lploss: 0.00000
train epoch 1349 avg loss: 0.08483 (A-MSE: 0.07622) avg lploss: 0.00000
train epoch 1350 avg loss: 0.08130 (A-MSE: 0.07289) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.40833 (A-MSE: 0.35872) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.45101 (A-MSE: 0.40109) avg lploss: 0.00000
*** Best Val Loss: 0.35741 	 Best Test Loss: 0.45872 	 Best epoch 1130
EarlyStopping counter: 44 out of 50
train epoch 1351 avg loss: 0.09161 (A-MSE: 0.08282) avg lploss: 0.00000
train epoch 1352 avg loss: 0.11599 (A-MSE: 0.10478) avg lploss: 0.00000
train epoch 1353 avg loss: 0.14814 (A-MSE: 0.13110) avg lploss: 0.00000
train epoch 1354 avg loss: 0.11996 (A-MSE: 0.10812) avg lploss: 0.00000
train epoch 1355 avg loss: 0.10485 (A-MSE: 0.09403) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.33739 (A-MSE: 0.29893) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.41530 (A-MSE: 0.37356) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
Validation loss decreased (0.357407 --> 0.337392).  Saving model ...
train epoch 1356 avg loss: 0.10979 (A-MSE: 0.09750) avg lploss: 0.00000
train epoch 1357 avg loss: 0.09721 (A-MSE: 0.08764) avg lploss: 0.00000
train epoch 1358 avg loss: 0.09708 (A-MSE: 0.08727) avg lploss: 0.00000
train epoch 1359 avg loss: 0.10324 (A-MSE: 0.09369) avg lploss: 0.00000
train epoch 1360 avg loss: 0.09751 (A-MSE: 0.08887) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.40359 (A-MSE: 0.35450) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.45709 (A-MSE: 0.40640) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 1 out of 50
train epoch 1361 avg loss: 0.09146 (A-MSE: 0.08210) avg lploss: 0.00000
train epoch 1362 avg loss: 0.08889 (A-MSE: 0.08069) avg lploss: 0.00000
train epoch 1363 avg loss: 0.10005 (A-MSE: 0.09069) avg lploss: 0.00000
train epoch 1364 avg loss: 0.11382 (A-MSE: 0.10210) avg lploss: 0.00000
train epoch 1365 avg loss: 0.09520 (A-MSE: 0.08594) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.41838 (A-MSE: 0.36677) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.46007 (A-MSE: 0.40552) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 2 out of 50
train epoch 1366 avg loss: 0.09203 (A-MSE: 0.08273) avg lploss: 0.00000
train epoch 1367 avg loss: 0.08887 (A-MSE: 0.07971) avg lploss: 0.00000
train epoch 1368 avg loss: 0.08154 (A-MSE: 0.07285) avg lploss: 0.00000
train epoch 1369 avg loss: 0.08396 (A-MSE: 0.07546) avg lploss: 0.00000
train epoch 1370 avg loss: 0.11458 (A-MSE: 0.10384) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.41093 (A-MSE: 0.35740) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.47851 (A-MSE: 0.42576) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 3 out of 50
train epoch 1371 avg loss: 0.11695 (A-MSE: 0.10434) avg lploss: 0.00000
train epoch 1372 avg loss: 0.12701 (A-MSE: 0.11259) avg lploss: 0.00000
train epoch 1373 avg loss: 0.09384 (A-MSE: 0.08497) avg lploss: 0.00000
train epoch 1374 avg loss: 0.09157 (A-MSE: 0.08317) avg lploss: 0.00000
train epoch 1375 avg loss: 0.10859 (A-MSE: 0.09682) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.36439 (A-MSE: 0.32101) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.44226 (A-MSE: 0.38979) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 4 out of 50
train epoch 1376 avg loss: 0.09575 (A-MSE: 0.08604) avg lploss: 0.00000
train epoch 1377 avg loss: 0.10748 (A-MSE: 0.09676) avg lploss: 0.00000
train epoch 1378 avg loss: 0.10340 (A-MSE: 0.09267) avg lploss: 0.00000
train epoch 1379 avg loss: 0.10648 (A-MSE: 0.09553) avg lploss: 0.00000
train epoch 1380 avg loss: 0.08282 (A-MSE: 0.07469) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.36902 (A-MSE: 0.32486) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.43786 (A-MSE: 0.38751) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 5 out of 50
train epoch 1381 avg loss: 0.07568 (A-MSE: 0.06830) avg lploss: 0.00000
train epoch 1382 avg loss: 0.08080 (A-MSE: 0.07305) avg lploss: 0.00000
train epoch 1383 avg loss: 0.08473 (A-MSE: 0.07602) avg lploss: 0.00000
train epoch 1384 avg loss: 0.08338 (A-MSE: 0.07606) avg lploss: 0.00000
train epoch 1385 avg loss: 0.10715 (A-MSE: 0.09682) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.41345 (A-MSE: 0.36410) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.47740 (A-MSE: 0.42022) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 6 out of 50
train epoch 1386 avg loss: 0.13395 (A-MSE: 0.12136) avg lploss: 0.00000
train epoch 1387 avg loss: 0.11258 (A-MSE: 0.10212) avg lploss: 0.00000
train epoch 1388 avg loss: 0.13312 (A-MSE: 0.11959) avg lploss: 0.00000
train epoch 1389 avg loss: 0.12367 (A-MSE: 0.10991) avg lploss: 0.00000
train epoch 1390 avg loss: 0.10897 (A-MSE: 0.09768) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.42842 (A-MSE: 0.37820) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.47527 (A-MSE: 0.41584) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 7 out of 50
train epoch 1391 avg loss: 0.09299 (A-MSE: 0.08313) avg lploss: 0.00000
train epoch 1392 avg loss: 0.08911 (A-MSE: 0.08002) avg lploss: 0.00000
train epoch 1393 avg loss: 0.07918 (A-MSE: 0.07151) avg lploss: 0.00000
train epoch 1394 avg loss: 0.08754 (A-MSE: 0.07784) avg lploss: 0.00000
train epoch 1395 avg loss: 0.08814 (A-MSE: 0.07980) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.40623 (A-MSE: 0.36204) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.46751 (A-MSE: 0.41805) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 8 out of 50
train epoch 1396 avg loss: 0.08403 (A-MSE: 0.07560) avg lploss: 0.00000
train epoch 1397 avg loss: 0.08331 (A-MSE: 0.07466) avg lploss: 0.00000
train epoch 1398 avg loss: 0.09458 (A-MSE: 0.08548) avg lploss: 0.00000
train epoch 1399 avg loss: 0.09349 (A-MSE: 0.08468) avg lploss: 0.00000
train epoch 1400 avg loss: 0.10503 (A-MSE: 0.09427) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.42905 (A-MSE: 0.37998) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.49701 (A-MSE: 0.44397) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 9 out of 50
train epoch 1401 avg loss: 0.11821 (A-MSE: 0.10646) avg lploss: 0.00000
train epoch 1402 avg loss: 0.17503 (A-MSE: 0.15879) avg lploss: 0.00000
train epoch 1403 avg loss: 0.13582 (A-MSE: 0.12160) avg lploss: 0.00000
train epoch 1404 avg loss: 0.12244 (A-MSE: 0.11138) avg lploss: 0.00000
train epoch 1405 avg loss: 0.09490 (A-MSE: 0.08558) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.39568 (A-MSE: 0.34872) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.44375 (A-MSE: 0.39111) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 10 out of 50
train epoch 1406 avg loss: 0.07499 (A-MSE: 0.06699) avg lploss: 0.00000
train epoch 1407 avg loss: 0.07166 (A-MSE: 0.06429) avg lploss: 0.00000
train epoch 1408 avg loss: 0.07199 (A-MSE: 0.06438) avg lploss: 0.00000
train epoch 1409 avg loss: 0.06059 (A-MSE: 0.05470) avg lploss: 0.00000
train epoch 1410 avg loss: 0.06797 (A-MSE: 0.06153) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.41824 (A-MSE: 0.36969) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.47710 (A-MSE: 0.41858) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 11 out of 50
train epoch 1411 avg loss: 0.08556 (A-MSE: 0.07681) avg lploss: 0.00000
train epoch 1412 avg loss: 0.07791 (A-MSE: 0.06945) avg lploss: 0.00000
train epoch 1413 avg loss: 0.07067 (A-MSE: 0.06358) avg lploss: 0.00000
train epoch 1414 avg loss: 0.07239 (A-MSE: 0.06549) avg lploss: 0.00000
train epoch 1415 avg loss: 0.07041 (A-MSE: 0.06350) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.39102 (A-MSE: 0.34367) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.44514 (A-MSE: 0.39429) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 12 out of 50
train epoch 1416 avg loss: 0.06851 (A-MSE: 0.06163) avg lploss: 0.00000
train epoch 1417 avg loss: 0.07182 (A-MSE: 0.06436) avg lploss: 0.00000
train epoch 1418 avg loss: 0.07102 (A-MSE: 0.06401) avg lploss: 0.00000
train epoch 1419 avg loss: 0.07227 (A-MSE: 0.06505) avg lploss: 0.00000
train epoch 1420 avg loss: 0.07775 (A-MSE: 0.07024) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.42351 (A-MSE: 0.37755) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.47095 (A-MSE: 0.41872) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 13 out of 50
train epoch 1421 avg loss: 0.09662 (A-MSE: 0.08663) avg lploss: 0.00000
train epoch 1422 avg loss: 0.08451 (A-MSE: 0.07670) avg lploss: 0.00000
train epoch 1423 avg loss: 0.09093 (A-MSE: 0.08209) avg lploss: 0.00000
train epoch 1424 avg loss: 0.09792 (A-MSE: 0.08713) avg lploss: 0.00000
train epoch 1425 avg loss: 0.11562 (A-MSE: 0.10373) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.36282 (A-MSE: 0.31980) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.48430 (A-MSE: 0.42512) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 14 out of 50
train epoch 1426 avg loss: 0.14507 (A-MSE: 0.13019) avg lploss: 0.00000
train epoch 1427 avg loss: 0.11095 (A-MSE: 0.09979) avg lploss: 0.00000
train epoch 1428 avg loss: 0.08503 (A-MSE: 0.07553) avg lploss: 0.00000
train epoch 1429 avg loss: 0.07851 (A-MSE: 0.07078) avg lploss: 0.00000
train epoch 1430 avg loss: 0.08767 (A-MSE: 0.07879) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.43031 (A-MSE: 0.38101) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.47900 (A-MSE: 0.42250) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 15 out of 50
train epoch 1431 avg loss: 0.10433 (A-MSE: 0.09397) avg lploss: 0.00000
train epoch 1432 avg loss: 0.09607 (A-MSE: 0.08612) avg lploss: 0.00000
train epoch 1433 avg loss: 0.07642 (A-MSE: 0.06826) avg lploss: 0.00000
train epoch 1434 avg loss: 0.07527 (A-MSE: 0.06819) avg lploss: 0.00000
train epoch 1435 avg loss: 0.07381 (A-MSE: 0.06620) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.36114 (A-MSE: 0.32121) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.43684 (A-MSE: 0.38659) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 16 out of 50
train epoch 1436 avg loss: 0.07240 (A-MSE: 0.06546) avg lploss: 0.00000
train epoch 1437 avg loss: 0.06980 (A-MSE: 0.06279) avg lploss: 0.00000
train epoch 1438 avg loss: 0.06190 (A-MSE: 0.05557) avg lploss: 0.00000
train epoch 1439 avg loss: 0.07260 (A-MSE: 0.06585) avg lploss: 0.00000
train epoch 1440 avg loss: 0.07347 (A-MSE: 0.06536) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.43512 (A-MSE: 0.38495) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.50111 (A-MSE: 0.43935) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 17 out of 50
train epoch 1441 avg loss: 0.08133 (A-MSE: 0.07404) avg lploss: 0.00000
train epoch 1442 avg loss: 0.07971 (A-MSE: 0.07275) avg lploss: 0.00000
train epoch 1443 avg loss: 0.09847 (A-MSE: 0.08881) avg lploss: 0.00000
train epoch 1444 avg loss: 0.09578 (A-MSE: 0.08599) avg lploss: 0.00000
train epoch 1445 avg loss: 0.07484 (A-MSE: 0.06730) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.40261 (A-MSE: 0.36201) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.47281 (A-MSE: 0.41955) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 18 out of 50
train epoch 1446 avg loss: 0.06892 (A-MSE: 0.06200) avg lploss: 0.00000
train epoch 1447 avg loss: 0.08249 (A-MSE: 0.07449) avg lploss: 0.00000
train epoch 1448 avg loss: 0.08326 (A-MSE: 0.07437) avg lploss: 0.00000
train epoch 1449 avg loss: 0.08961 (A-MSE: 0.08087) avg lploss: 0.00000
train epoch 1450 avg loss: 0.08904 (A-MSE: 0.08017) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.38114 (A-MSE: 0.33712) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.45735 (A-MSE: 0.40735) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 19 out of 50
train epoch 1451 avg loss: 0.07902 (A-MSE: 0.07118) avg lploss: 0.00000
train epoch 1452 avg loss: 0.09025 (A-MSE: 0.08149) avg lploss: 0.00000
train epoch 1453 avg loss: 0.09857 (A-MSE: 0.08897) avg lploss: 0.00000
train epoch 1454 avg loss: 0.09290 (A-MSE: 0.08348) avg lploss: 0.00000
train epoch 1455 avg loss: 0.08100 (A-MSE: 0.07325) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.34790 (A-MSE: 0.31052) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.42239 (A-MSE: 0.37862) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 20 out of 50
train epoch 1456 avg loss: 0.08445 (A-MSE: 0.07583) avg lploss: 0.00000
train epoch 1457 avg loss: 0.09336 (A-MSE: 0.08394) avg lploss: 0.00000
train epoch 1458 avg loss: 0.10006 (A-MSE: 0.09026) avg lploss: 0.00000
train epoch 1459 avg loss: 0.12563 (A-MSE: 0.11323) avg lploss: 0.00000
train epoch 1460 avg loss: 0.13935 (A-MSE: 0.12488) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.43402 (A-MSE: 0.37933) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.47870 (A-MSE: 0.42396) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 21 out of 50
train epoch 1461 avg loss: 0.10608 (A-MSE: 0.09555) avg lploss: 0.00000
train epoch 1462 avg loss: 0.09147 (A-MSE: 0.08254) avg lploss: 0.00000
train epoch 1463 avg loss: 0.08393 (A-MSE: 0.07462) avg lploss: 0.00000
train epoch 1464 avg loss: 0.09341 (A-MSE: 0.08295) avg lploss: 0.00000
train epoch 1465 avg loss: 0.08563 (A-MSE: 0.07728) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.38833 (A-MSE: 0.34488) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.44990 (A-MSE: 0.39720) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 22 out of 50
train epoch 1466 avg loss: 0.08411 (A-MSE: 0.07574) avg lploss: 0.00000
train epoch 1467 avg loss: 0.07912 (A-MSE: 0.07109) avg lploss: 0.00000
train epoch 1468 avg loss: 0.08656 (A-MSE: 0.07759) avg lploss: 0.00000
train epoch 1469 avg loss: 0.07686 (A-MSE: 0.06930) avg lploss: 0.00000
train epoch 1470 avg loss: 0.07933 (A-MSE: 0.07174) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.36697 (A-MSE: 0.32775) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.43511 (A-MSE: 0.38743) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 23 out of 50
train epoch 1471 avg loss: 0.07829 (A-MSE: 0.07076) avg lploss: 0.00000
train epoch 1472 avg loss: 0.07113 (A-MSE: 0.06396) avg lploss: 0.00000
train epoch 1473 avg loss: 0.07327 (A-MSE: 0.06574) avg lploss: 0.00000
train epoch 1474 avg loss: 0.08837 (A-MSE: 0.07988) avg lploss: 0.00000
train epoch 1475 avg loss: 0.08540 (A-MSE: 0.07740) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.39645 (A-MSE: 0.35016) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.45561 (A-MSE: 0.40219) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 24 out of 50
train epoch 1476 avg loss: 0.07281 (A-MSE: 0.06538) avg lploss: 0.00000
train epoch 1477 avg loss: 0.10183 (A-MSE: 0.09168) avg lploss: 0.00000
train epoch 1478 avg loss: 0.10120 (A-MSE: 0.09064) avg lploss: 0.00000
train epoch 1479 avg loss: 0.09503 (A-MSE: 0.08444) avg lploss: 0.00000
train epoch 1480 avg loss: 0.08191 (A-MSE: 0.07335) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.40036 (A-MSE: 0.35703) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.47916 (A-MSE: 0.42228) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 25 out of 50
train epoch 1481 avg loss: 0.09017 (A-MSE: 0.08083) avg lploss: 0.00000
train epoch 1482 avg loss: 0.07612 (A-MSE: 0.06946) avg lploss: 0.00000
train epoch 1483 avg loss: 0.07174 (A-MSE: 0.06413) avg lploss: 0.00000
train epoch 1484 avg loss: 0.07204 (A-MSE: 0.06462) avg lploss: 0.00000
train epoch 1485 avg loss: 0.07244 (A-MSE: 0.06565) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.41824 (A-MSE: 0.36929) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.44938 (A-MSE: 0.39849) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 26 out of 50
train epoch 1486 avg loss: 0.07168 (A-MSE: 0.06407) avg lploss: 0.00000
train epoch 1487 avg loss: 0.07321 (A-MSE: 0.06593) avg lploss: 0.00000
train epoch 1488 avg loss: 0.06972 (A-MSE: 0.06261) avg lploss: 0.00000
train epoch 1489 avg loss: 0.08052 (A-MSE: 0.07260) avg lploss: 0.00000
train epoch 1490 avg loss: 0.07788 (A-MSE: 0.07015) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.37354 (A-MSE: 0.33064) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.44656 (A-MSE: 0.39931) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 27 out of 50
train epoch 1491 avg loss: 0.07414 (A-MSE: 0.06606) avg lploss: 0.00000
train epoch 1492 avg loss: 0.07194 (A-MSE: 0.06533) avg lploss: 0.00000
train epoch 1493 avg loss: 0.07593 (A-MSE: 0.06787) avg lploss: 0.00000
train epoch 1494 avg loss: 0.09184 (A-MSE: 0.08156) avg lploss: 0.00000
train epoch 1495 avg loss: 0.08726 (A-MSE: 0.07899) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.37840 (A-MSE: 0.33985) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.44067 (A-MSE: 0.39637) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 28 out of 50
train epoch 1496 avg loss: 0.06929 (A-MSE: 0.06289) avg lploss: 0.00000
train epoch 1497 avg loss: 0.07264 (A-MSE: 0.06534) avg lploss: 0.00000
train epoch 1498 avg loss: 0.07284 (A-MSE: 0.06599) avg lploss: 0.00000
train epoch 1499 avg loss: 0.09383 (A-MSE: 0.08416) avg lploss: 0.00000
train epoch 1500 avg loss: 0.08792 (A-MSE: 0.07961) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.41860 (A-MSE: 0.37016) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.45911 (A-MSE: 0.41149) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 29 out of 50
train epoch 1501 avg loss: 0.08519 (A-MSE: 0.07697) avg lploss: 0.00000
train epoch 1502 avg loss: 0.08060 (A-MSE: 0.07309) avg lploss: 0.00000
train epoch 1503 avg loss: 0.07259 (A-MSE: 0.06572) avg lploss: 0.00000
train epoch 1504 avg loss: 0.07706 (A-MSE: 0.07071) avg lploss: 0.00000
train epoch 1505 avg loss: 0.06533 (A-MSE: 0.05866) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.42514 (A-MSE: 0.37937) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.46448 (A-MSE: 0.41463) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 30 out of 50
train epoch 1506 avg loss: 0.06709 (A-MSE: 0.06076) avg lploss: 0.00000
train epoch 1507 avg loss: 0.06904 (A-MSE: 0.06198) avg lploss: 0.00000
train epoch 1508 avg loss: 0.06739 (A-MSE: 0.06059) avg lploss: 0.00000
train epoch 1509 avg loss: 0.06447 (A-MSE: 0.05893) avg lploss: 0.00000
train epoch 1510 avg loss: 0.06697 (A-MSE: 0.06040) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.34599 (A-MSE: 0.30842) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.42086 (A-MSE: 0.37337) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 31 out of 50
train epoch 1511 avg loss: 0.08516 (A-MSE: 0.07634) avg lploss: 0.00000
train epoch 1512 avg loss: 0.07988 (A-MSE: 0.07199) avg lploss: 0.00000
train epoch 1513 avg loss: 0.06513 (A-MSE: 0.05873) avg lploss: 0.00000
train epoch 1514 avg loss: 0.05705 (A-MSE: 0.05174) avg lploss: 0.00000
train epoch 1515 avg loss: 0.06121 (A-MSE: 0.05504) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.37937 (A-MSE: 0.34202) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.44830 (A-MSE: 0.40413) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 32 out of 50
train epoch 1516 avg loss: 0.07278 (A-MSE: 0.06533) avg lploss: 0.00000
train epoch 1517 avg loss: 0.08260 (A-MSE: 0.07444) avg lploss: 0.00000
train epoch 1518 avg loss: 0.08619 (A-MSE: 0.07753) avg lploss: 0.00000
train epoch 1519 avg loss: 0.08293 (A-MSE: 0.07385) avg lploss: 0.00000
train epoch 1520 avg loss: 0.06997 (A-MSE: 0.06354) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.37039 (A-MSE: 0.32773) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.42874 (A-MSE: 0.37697) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 33 out of 50
train epoch 1521 avg loss: 0.07339 (A-MSE: 0.06608) avg lploss: 0.00000
train epoch 1522 avg loss: 0.07226 (A-MSE: 0.06486) avg lploss: 0.00000
train epoch 1523 avg loss: 0.06824 (A-MSE: 0.06079) avg lploss: 0.00000
train epoch 1524 avg loss: 0.06813 (A-MSE: 0.06129) avg lploss: 0.00000
train epoch 1525 avg loss: 0.07552 (A-MSE: 0.06717) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.39769 (A-MSE: 0.35649) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.47630 (A-MSE: 0.42265) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 34 out of 50
train epoch 1526 avg loss: 0.08001 (A-MSE: 0.07245) avg lploss: 0.00000
train epoch 1527 avg loss: 0.07212 (A-MSE: 0.06462) avg lploss: 0.00000
train epoch 1528 avg loss: 0.07235 (A-MSE: 0.06497) avg lploss: 0.00000
train epoch 1529 avg loss: 0.06475 (A-MSE: 0.05907) avg lploss: 0.00000
train epoch 1530 avg loss: 0.06272 (A-MSE: 0.05673) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.36830 (A-MSE: 0.32892) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.43868 (A-MSE: 0.38961) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 35 out of 50
train epoch 1531 avg loss: 0.06495 (A-MSE: 0.05871) avg lploss: 0.00000
train epoch 1532 avg loss: 0.06889 (A-MSE: 0.06191) avg lploss: 0.00000
train epoch 1533 avg loss: 0.06781 (A-MSE: 0.06120) avg lploss: 0.00000
train epoch 1534 avg loss: 0.07336 (A-MSE: 0.06600) avg lploss: 0.00000
train epoch 1535 avg loss: 0.07264 (A-MSE: 0.06604) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.39560 (A-MSE: 0.35391) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.48201 (A-MSE: 0.43006) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 36 out of 50
train epoch 1536 avg loss: 0.06821 (A-MSE: 0.06227) avg lploss: 0.00000
train epoch 1537 avg loss: 0.07032 (A-MSE: 0.06291) avg lploss: 0.00000
train epoch 1538 avg loss: 0.07370 (A-MSE: 0.06646) avg lploss: 0.00000
train epoch 1539 avg loss: 0.06406 (A-MSE: 0.05728) avg lploss: 0.00000
train epoch 1540 avg loss: 0.07971 (A-MSE: 0.07117) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.40586 (A-MSE: 0.35394) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.46738 (A-MSE: 0.40615) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 37 out of 50
train epoch 1541 avg loss: 0.07502 (A-MSE: 0.06684) avg lploss: 0.00000
train epoch 1542 avg loss: 0.07642 (A-MSE: 0.06937) avg lploss: 0.00000
train epoch 1543 avg loss: 0.09130 (A-MSE: 0.08181) avg lploss: 0.00000
train epoch 1544 avg loss: 0.09255 (A-MSE: 0.08331) avg lploss: 0.00000
train epoch 1545 avg loss: 0.08329 (A-MSE: 0.07486) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.38351 (A-MSE: 0.34203) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.46690 (A-MSE: 0.41283) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 38 out of 50
train epoch 1546 avg loss: 0.07577 (A-MSE: 0.06804) avg lploss: 0.00000
train epoch 1547 avg loss: 0.06633 (A-MSE: 0.05937) avg lploss: 0.00000
train epoch 1548 avg loss: 0.07815 (A-MSE: 0.07005) avg lploss: 0.00000
train epoch 1549 avg loss: 0.07719 (A-MSE: 0.06939) avg lploss: 0.00000
train epoch 1550 avg loss: 0.06926 (A-MSE: 0.06247) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.41689 (A-MSE: 0.36948) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.45976 (A-MSE: 0.40849) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 39 out of 50
train epoch 1551 avg loss: 0.06308 (A-MSE: 0.05669) avg lploss: 0.00000
train epoch 1552 avg loss: 0.06912 (A-MSE: 0.06237) avg lploss: 0.00000
train epoch 1553 avg loss: 0.07571 (A-MSE: 0.06789) avg lploss: 0.00000
train epoch 1554 avg loss: 0.08755 (A-MSE: 0.07882) avg lploss: 0.00000
train epoch 1555 avg loss: 0.07384 (A-MSE: 0.06689) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.37721 (A-MSE: 0.33354) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.45043 (A-MSE: 0.39591) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 40 out of 50
train epoch 1556 avg loss: 0.08147 (A-MSE: 0.07352) avg lploss: 0.00000
train epoch 1557 avg loss: 0.07818 (A-MSE: 0.07043) avg lploss: 0.00000
train epoch 1558 avg loss: 0.07974 (A-MSE: 0.07164) avg lploss: 0.00000
train epoch 1559 avg loss: 0.06924 (A-MSE: 0.06323) avg lploss: 0.00000
train epoch 1560 avg loss: 0.06760 (A-MSE: 0.06133) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.42387 (A-MSE: 0.37794) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.47928 (A-MSE: 0.42663) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 41 out of 50
train epoch 1561 avg loss: 0.06969 (A-MSE: 0.06292) avg lploss: 0.00000
train epoch 1562 avg loss: 0.07001 (A-MSE: 0.06276) avg lploss: 0.00000
train epoch 1563 avg loss: 0.07614 (A-MSE: 0.06851) avg lploss: 0.00000
train epoch 1564 avg loss: 0.08441 (A-MSE: 0.07577) avg lploss: 0.00000
train epoch 1565 avg loss: 0.07923 (A-MSE: 0.07104) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.35959 (A-MSE: 0.32224) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.44215 (A-MSE: 0.39232) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 42 out of 50
train epoch 1566 avg loss: 0.07590 (A-MSE: 0.06902) avg lploss: 0.00000
train epoch 1567 avg loss: 0.06818 (A-MSE: 0.06109) avg lploss: 0.00000
train epoch 1568 avg loss: 0.06838 (A-MSE: 0.06162) avg lploss: 0.00000
train epoch 1569 avg loss: 0.07498 (A-MSE: 0.06731) avg lploss: 0.00000
train epoch 1570 avg loss: 0.06621 (A-MSE: 0.05955) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.41558 (A-MSE: 0.37094) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.48560 (A-MSE: 0.42883) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 43 out of 50
train epoch 1571 avg loss: 0.06933 (A-MSE: 0.06244) avg lploss: 0.00000
train epoch 1572 avg loss: 0.07058 (A-MSE: 0.06404) avg lploss: 0.00000
train epoch 1573 avg loss: 0.07382 (A-MSE: 0.06609) avg lploss: 0.00000
train epoch 1574 avg loss: 0.08138 (A-MSE: 0.07311) avg lploss: 0.00000
train epoch 1575 avg loss: 0.08177 (A-MSE: 0.07356) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.46572 (A-MSE: 0.42150) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.51411 (A-MSE: 0.45857) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 44 out of 50
train epoch 1576 avg loss: 0.09335 (A-MSE: 0.08497) avg lploss: 0.00000
train epoch 1577 avg loss: 0.09965 (A-MSE: 0.09105) avg lploss: 0.00000
train epoch 1578 avg loss: 0.08685 (A-MSE: 0.07877) avg lploss: 0.00000
train epoch 1579 avg loss: 0.08596 (A-MSE: 0.07682) avg lploss: 0.00000
train epoch 1580 avg loss: 0.08274 (A-MSE: 0.07405) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.36224 (A-MSE: 0.32186) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.43784 (A-MSE: 0.38766) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 45 out of 50
train epoch 1581 avg loss: 0.06678 (A-MSE: 0.06033) avg lploss: 0.00000
train epoch 1582 avg loss: 0.07692 (A-MSE: 0.06965) avg lploss: 0.00000
train epoch 1583 avg loss: 0.08551 (A-MSE: 0.07717) avg lploss: 0.00000
train epoch 1584 avg loss: 0.08513 (A-MSE: 0.07609) avg lploss: 0.00000
train epoch 1585 avg loss: 0.08861 (A-MSE: 0.08046) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.39242 (A-MSE: 0.34665) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.44216 (A-MSE: 0.39030) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 46 out of 50
train epoch 1586 avg loss: 0.08375 (A-MSE: 0.07519) avg lploss: 0.00000
train epoch 1587 avg loss: 0.06710 (A-MSE: 0.06060) avg lploss: 0.00000
train epoch 1588 avg loss: 0.06228 (A-MSE: 0.05591) avg lploss: 0.00000
train epoch 1589 avg loss: 0.06623 (A-MSE: 0.05980) avg lploss: 0.00000
train epoch 1590 avg loss: 0.07377 (A-MSE: 0.06631) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.34106 (A-MSE: 0.30307) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.42686 (A-MSE: 0.37947) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 47 out of 50
train epoch 1591 avg loss: 0.07163 (A-MSE: 0.06500) avg lploss: 0.00000
train epoch 1592 avg loss: 0.07915 (A-MSE: 0.07113) avg lploss: 0.00000
train epoch 1593 avg loss: 0.07699 (A-MSE: 0.06928) avg lploss: 0.00000
train epoch 1594 avg loss: 0.07349 (A-MSE: 0.06608) avg lploss: 0.00000
train epoch 1595 avg loss: 0.06149 (A-MSE: 0.05544) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.34892 (A-MSE: 0.31343) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.40024 (A-MSE: 0.35852) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 48 out of 50
train epoch 1596 avg loss: 0.05220 (A-MSE: 0.04708) avg lploss: 0.00000
train epoch 1597 avg loss: 0.05946 (A-MSE: 0.05384) avg lploss: 0.00000
train epoch 1598 avg loss: 0.07274 (A-MSE: 0.06555) avg lploss: 0.00000
train epoch 1599 avg loss: 0.06103 (A-MSE: 0.05485) avg lploss: 0.00000
train epoch 1600 avg loss: 0.05832 (A-MSE: 0.05262) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.41537 (A-MSE: 0.37525) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.47674 (A-MSE: 0.42650) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 49 out of 50
train epoch 1601 avg loss: 0.06401 (A-MSE: 0.05813) avg lploss: 0.00000
train epoch 1602 avg loss: 0.06249 (A-MSE: 0.05640) avg lploss: 0.00000
train epoch 1603 avg loss: 0.06020 (A-MSE: 0.05381) avg lploss: 0.00000
train epoch 1604 avg loss: 0.06849 (A-MSE: 0.06167) avg lploss: 0.00000
train epoch 1605 avg loss: 0.07663 (A-MSE: 0.06865) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.38293 (A-MSE: 0.33999) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.45262 (A-MSE: 0.40385) avg lploss: 0.00000
*** Best Val Loss: 0.33739 	 Best Test Loss: 0.41530 	 Best epoch 1355
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.104853
best_lp = 0.000000
best_val = 0.337392
best_test = 0.415297
best_epoch = 1355
best_train = 0.104853, best_lp = 0.000000, best_val = 0.337392, best_test = 0.415297, best_epoch = 1355
Job completed at Fri Dec 12 18:09:55 CET 2025
