Date              = Mon Dec  8 22:50:21 CET 2025
Hostname          = mel2022
Array Task ID     = 14
Running config: configs/table7_mocap_variant_III_seed5.json
Namespace(batch_size=12, case='run', config_by_file='configs/table7_mocap_variant_III_seed5.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='table7_mocap_variant_III_seed5', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/table7_mocap', pooling_layer=3, seed=5, test_interval=5, time_emb_dim=32, use_h_conv=False, use_x_conv=False, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
)
Model saved to /project/scratch/p200981/egno/logs/table7_mocap/table7_mocap_variant_III_seed5/saved_model.pth
train epoch 0 avg loss: 98.63159 (A-MSE: 89.56033) avg lploss: 0.00000
==> val epoch 0 avg loss: 46.22986 (A-MSE: 38.70250) avg lploss: 0.00000
==> test epoch 0 avg loss: 43.97145 (A-MSE: 36.80686) avg lploss: 0.00000
*** Best Val Loss: 46.22986 	 Best Test Loss: 43.97145 	 Best epoch 0
Validation loss decreased (inf --> 46.229856).  Saving model ...
train epoch 1 avg loss: 30.65028 (A-MSE: 26.24366) avg lploss: 0.00000
train epoch 2 avg loss: 17.32935 (A-MSE: 14.53675) avg lploss: 0.00000
train epoch 3 avg loss: 14.32046 (A-MSE: 11.94189) avg lploss: 0.00000
train epoch 4 avg loss: 13.13708 (A-MSE: 10.84594) avg lploss: 0.00000
train epoch 5 avg loss: 12.10661 (A-MSE: 10.00499) avg lploss: 0.00000
==> val epoch 5 avg loss: 11.30344 (A-MSE: 9.30046) avg lploss: 0.00000
==> test epoch 5 avg loss: 10.88677 (A-MSE: 8.96607) avg lploss: 0.00000
*** Best Val Loss: 11.30344 	 Best Test Loss: 10.88677 	 Best epoch 5
Validation loss decreased (46.229856 --> 11.303441).  Saving model ...
train epoch 6 avg loss: 11.03636 (A-MSE: 9.07553) avg lploss: 0.00000
train epoch 7 avg loss: 9.94398 (A-MSE: 8.21076) avg lploss: 0.00000
train epoch 8 avg loss: 9.24527 (A-MSE: 7.66808) avg lploss: 0.00000
train epoch 9 avg loss: 8.75297 (A-MSE: 7.28961) avg lploss: 0.00000
train epoch 10 avg loss: 7.98363 (A-MSE: 6.65740) avg lploss: 0.00000
==> val epoch 10 avg loss: 7.38365 (A-MSE: 6.06226) avg lploss: 0.00000
==> test epoch 10 avg loss: 7.15937 (A-MSE: 5.89735) avg lploss: 0.00000
*** Best Val Loss: 7.38365 	 Best Test Loss: 7.15937 	 Best epoch 10
Validation loss decreased (11.303441 --> 7.383650).  Saving model ...
train epoch 11 avg loss: 7.13387 (A-MSE: 5.95911) avg lploss: 0.00000
train epoch 12 avg loss: 6.78837 (A-MSE: 5.71655) avg lploss: 0.00000
train epoch 13 avg loss: 6.61256 (A-MSE: 5.59669) avg lploss: 0.00000
train epoch 14 avg loss: 6.14581 (A-MSE: 5.20871) avg lploss: 0.00000
train epoch 15 avg loss: 5.54380 (A-MSE: 4.70943) avg lploss: 0.00000
==> val epoch 15 avg loss: 5.28938 (A-MSE: 4.58713) avg lploss: 0.00000
==> test epoch 15 avg loss: 5.24823 (A-MSE: 4.56670) avg lploss: 0.00000
*** Best Val Loss: 5.28938 	 Best Test Loss: 5.24823 	 Best epoch 15
Validation loss decreased (7.383650 --> 5.289379).  Saving model ...
train epoch 16 avg loss: 5.48936 (A-MSE: 4.68912) avg lploss: 0.00000
train epoch 17 avg loss: 5.16670 (A-MSE: 4.41931) avg lploss: 0.00000
train epoch 18 avg loss: 4.85957 (A-MSE: 4.19289) avg lploss: 0.00000
train epoch 19 avg loss: 4.56538 (A-MSE: 3.95120) avg lploss: 0.00000
train epoch 20 avg loss: 4.79900 (A-MSE: 4.11904) avg lploss: 0.00000
==> val epoch 20 avg loss: 4.82320 (A-MSE: 4.11450) avg lploss: 0.00000
==> test epoch 20 avg loss: 4.80010 (A-MSE: 4.13945) avg lploss: 0.00000
*** Best Val Loss: 4.82320 	 Best Test Loss: 4.80010 	 Best epoch 20
Validation loss decreased (5.289379 --> 4.823195).  Saving model ...
train epoch 21 avg loss: 4.33076 (A-MSE: 3.73821) avg lploss: 0.00000
train epoch 22 avg loss: 3.96319 (A-MSE: 3.41730) avg lploss: 0.00000
train epoch 23 avg loss: 3.76770 (A-MSE: 3.22599) avg lploss: 0.00000
train epoch 24 avg loss: 3.80915 (A-MSE: 3.25082) avg lploss: 0.00000
train epoch 25 avg loss: 3.54136 (A-MSE: 3.02659) avg lploss: 0.00000
==> val epoch 25 avg loss: 3.79497 (A-MSE: 3.14025) avg lploss: 0.00000
==> test epoch 25 avg loss: 3.77261 (A-MSE: 3.16967) avg lploss: 0.00000
*** Best Val Loss: 3.79497 	 Best Test Loss: 3.77261 	 Best epoch 25
Validation loss decreased (4.823195 --> 3.794970).  Saving model ...
train epoch 26 avg loss: 3.47793 (A-MSE: 2.95542) avg lploss: 0.00000
train epoch 27 avg loss: 3.58532 (A-MSE: 3.04558) avg lploss: 0.00000
train epoch 28 avg loss: 3.41336 (A-MSE: 2.92186) avg lploss: 0.00000
train epoch 29 avg loss: 3.40386 (A-MSE: 2.90963) avg lploss: 0.00000
train epoch 30 avg loss: 3.36962 (A-MSE: 2.85579) avg lploss: 0.00000
==> val epoch 30 avg loss: 3.49050 (A-MSE: 3.01501) avg lploss: 0.00000
==> test epoch 30 avg loss: 3.64592 (A-MSE: 3.20923) avg lploss: 0.00000
*** Best Val Loss: 3.49050 	 Best Test Loss: 3.64592 	 Best epoch 30
Validation loss decreased (3.794970 --> 3.490502).  Saving model ...
train epoch 31 avg loss: 3.22452 (A-MSE: 2.76120) avg lploss: 0.00000
train epoch 32 avg loss: 3.25424 (A-MSE: 2.76380) avg lploss: 0.00000
train epoch 33 avg loss: 3.11170 (A-MSE: 2.63982) avg lploss: 0.00000
train epoch 34 avg loss: 3.05342 (A-MSE: 2.59970) avg lploss: 0.00000
train epoch 35 avg loss: 2.98567 (A-MSE: 2.54173) avg lploss: 0.00000
==> val epoch 35 avg loss: 3.38051 (A-MSE: 2.96510) avg lploss: 0.00000
==> test epoch 35 avg loss: 3.49570 (A-MSE: 3.12142) avg lploss: 0.00000
*** Best Val Loss: 3.38051 	 Best Test Loss: 3.49570 	 Best epoch 35
Validation loss decreased (3.490502 --> 3.380510).  Saving model ...
train epoch 36 avg loss: 2.96280 (A-MSE: 2.49342) avg lploss: 0.00000
train epoch 37 avg loss: 2.74667 (A-MSE: 2.33312) avg lploss: 0.00000
train epoch 38 avg loss: 2.82657 (A-MSE: 2.41087) avg lploss: 0.00000
train epoch 39 avg loss: 2.74259 (A-MSE: 2.32200) avg lploss: 0.00000
train epoch 40 avg loss: 2.67680 (A-MSE: 2.28414) avg lploss: 0.00000
==> val epoch 40 avg loss: 2.78833 (A-MSE: 2.37633) avg lploss: 0.00000
==> test epoch 40 avg loss: 2.81726 (A-MSE: 2.44611) avg lploss: 0.00000
*** Best Val Loss: 2.78833 	 Best Test Loss: 2.81726 	 Best epoch 40
Validation loss decreased (3.380510 --> 2.788325).  Saving model ...
train epoch 41 avg loss: 2.48020 (A-MSE: 2.10266) avg lploss: 0.00000
train epoch 42 avg loss: 2.43669 (A-MSE: 2.07250) avg lploss: 0.00000
train epoch 43 avg loss: 2.50855 (A-MSE: 2.12562) avg lploss: 0.00000
train epoch 44 avg loss: 2.33576 (A-MSE: 1.99162) avg lploss: 0.00000
train epoch 45 avg loss: 2.35297 (A-MSE: 1.99854) avg lploss: 0.00000
==> val epoch 45 avg loss: 2.55847 (A-MSE: 2.16002) avg lploss: 0.00000
==> test epoch 45 avg loss: 2.61614 (A-MSE: 2.24986) avg lploss: 0.00000
*** Best Val Loss: 2.55847 	 Best Test Loss: 2.61614 	 Best epoch 45
Validation loss decreased (2.788325 --> 2.558468).  Saving model ...
train epoch 46 avg loss: 2.28355 (A-MSE: 1.93292) avg lploss: 0.00000
train epoch 47 avg loss: 2.26245 (A-MSE: 1.92454) avg lploss: 0.00000
train epoch 48 avg loss: 2.10813 (A-MSE: 1.79600) avg lploss: 0.00000
train epoch 49 avg loss: 2.13191 (A-MSE: 1.80734) avg lploss: 0.00000
train epoch 50 avg loss: 2.01869 (A-MSE: 1.71969) avg lploss: 0.00000
==> val epoch 50 avg loss: 2.48091 (A-MSE: 2.09507) avg lploss: 0.00000
==> test epoch 50 avg loss: 2.67283 (A-MSE: 2.30144) avg lploss: 0.00000
*** Best Val Loss: 2.48091 	 Best Test Loss: 2.67283 	 Best epoch 50
Validation loss decreased (2.558468 --> 2.480905).  Saving model ...
train epoch 51 avg loss: 2.06612 (A-MSE: 1.76691) avg lploss: 0.00000
train epoch 52 avg loss: 2.09219 (A-MSE: 1.78209) avg lploss: 0.00000
train epoch 53 avg loss: 2.03306 (A-MSE: 1.73418) avg lploss: 0.00000
train epoch 54 avg loss: 2.07815 (A-MSE: 1.76421) avg lploss: 0.00000
train epoch 55 avg loss: 1.96163 (A-MSE: 1.68138) avg lploss: 0.00000
==> val epoch 55 avg loss: 2.09104 (A-MSE: 1.75141) avg lploss: 0.00000
==> test epoch 55 avg loss: 2.16080 (A-MSE: 1.84412) avg lploss: 0.00000
*** Best Val Loss: 2.09104 	 Best Test Loss: 2.16080 	 Best epoch 55
Validation loss decreased (2.480905 --> 2.091039).  Saving model ...
train epoch 56 avg loss: 1.90375 (A-MSE: 1.62179) avg lploss: 0.00000
train epoch 57 avg loss: 2.14878 (A-MSE: 1.81914) avg lploss: 0.00000
train epoch 58 avg loss: 2.00432 (A-MSE: 1.71604) avg lploss: 0.00000
train epoch 59 avg loss: 1.87349 (A-MSE: 1.59515) avg lploss: 0.00000
train epoch 60 avg loss: 1.78829 (A-MSE: 1.52650) avg lploss: 0.00000
==> val epoch 60 avg loss: 2.19962 (A-MSE: 1.79935) avg lploss: 0.00000
==> test epoch 60 avg loss: 2.32413 (A-MSE: 1.94548) avg lploss: 0.00000
*** Best Val Loss: 2.09104 	 Best Test Loss: 2.16080 	 Best epoch 55
EarlyStopping counter: 1 out of 50
train epoch 61 avg loss: 1.82586 (A-MSE: 1.55485) avg lploss: 0.00000
train epoch 62 avg loss: 1.76043 (A-MSE: 1.49816) avg lploss: 0.00000
train epoch 63 avg loss: 2.00494 (A-MSE: 1.72475) avg lploss: 0.00000
train epoch 64 avg loss: 1.93149 (A-MSE: 1.64745) avg lploss: 0.00000
train epoch 65 avg loss: 1.76097 (A-MSE: 1.50313) avg lploss: 0.00000
==> val epoch 65 avg loss: 1.97992 (A-MSE: 1.63450) avg lploss: 0.00000
==> test epoch 65 avg loss: 2.02897 (A-MSE: 1.71022) avg lploss: 0.00000
*** Best Val Loss: 1.97992 	 Best Test Loss: 2.02897 	 Best epoch 65
Validation loss decreased (2.091039 --> 1.979924).  Saving model ...
train epoch 66 avg loss: 1.76734 (A-MSE: 1.50797) avg lploss: 0.00000
train epoch 67 avg loss: 1.72335 (A-MSE: 1.48148) avg lploss: 0.00000
train epoch 68 avg loss: 1.67939 (A-MSE: 1.42706) avg lploss: 0.00000
train epoch 69 avg loss: 1.58601 (A-MSE: 1.35406) avg lploss: 0.00000
train epoch 70 avg loss: 1.54089 (A-MSE: 1.31305) avg lploss: 0.00000
==> val epoch 70 avg loss: 1.86620 (A-MSE: 1.57016) avg lploss: 0.00000
==> test epoch 70 avg loss: 2.05334 (A-MSE: 1.77430) avg lploss: 0.00000
*** Best Val Loss: 1.86620 	 Best Test Loss: 2.05334 	 Best epoch 70
Validation loss decreased (1.979924 --> 1.866197).  Saving model ...
train epoch 71 avg loss: 1.60653 (A-MSE: 1.37770) avg lploss: 0.00000
train epoch 72 avg loss: 1.52267 (A-MSE: 1.30104) avg lploss: 0.00000
train epoch 73 avg loss: 1.58271 (A-MSE: 1.34268) avg lploss: 0.00000
train epoch 74 avg loss: 1.60951 (A-MSE: 1.38296) avg lploss: 0.00000
train epoch 75 avg loss: 1.59264 (A-MSE: 1.36709) avg lploss: 0.00000
==> val epoch 75 avg loss: 1.82545 (A-MSE: 1.50465) avg lploss: 0.00000
==> test epoch 75 avg loss: 1.89726 (A-MSE: 1.60596) avg lploss: 0.00000
*** Best Val Loss: 1.82545 	 Best Test Loss: 1.89726 	 Best epoch 75
Validation loss decreased (1.866197 --> 1.825449).  Saving model ...
train epoch 76 avg loss: 1.54062 (A-MSE: 1.31490) avg lploss: 0.00000
train epoch 77 avg loss: 1.49233 (A-MSE: 1.28116) avg lploss: 0.00000
train epoch 78 avg loss: 1.60046 (A-MSE: 1.37113) avg lploss: 0.00000
train epoch 79 avg loss: 1.78268 (A-MSE: 1.52232) avg lploss: 0.00000
train epoch 80 avg loss: 1.51369 (A-MSE: 1.30146) avg lploss: 0.00000
==> val epoch 80 avg loss: 1.59116 (A-MSE: 1.35267) avg lploss: 0.00000
==> test epoch 80 avg loss: 1.67582 (A-MSE: 1.46129) avg lploss: 0.00000
*** Best Val Loss: 1.59116 	 Best Test Loss: 1.67582 	 Best epoch 80
Validation loss decreased (1.825449 --> 1.591158).  Saving model ...
train epoch 81 avg loss: 1.37577 (A-MSE: 1.17727) avg lploss: 0.00000
train epoch 82 avg loss: 1.48715 (A-MSE: 1.27314) avg lploss: 0.00000
train epoch 83 avg loss: 1.50996 (A-MSE: 1.28904) avg lploss: 0.00000
train epoch 84 avg loss: 1.43817 (A-MSE: 1.22988) avg lploss: 0.00000
train epoch 85 avg loss: 1.36235 (A-MSE: 1.17205) avg lploss: 0.00000
==> val epoch 85 avg loss: 1.49321 (A-MSE: 1.25991) avg lploss: 0.00000
==> test epoch 85 avg loss: 1.55068 (A-MSE: 1.33733) avg lploss: 0.00000
*** Best Val Loss: 1.49321 	 Best Test Loss: 1.55068 	 Best epoch 85
Validation loss decreased (1.591158 --> 1.493207).  Saving model ...
train epoch 86 avg loss: 1.35059 (A-MSE: 1.15482) avg lploss: 0.00000
train epoch 87 avg loss: 1.42586 (A-MSE: 1.22631) avg lploss: 0.00000
train epoch 88 avg loss: 1.45698 (A-MSE: 1.23788) avg lploss: 0.00000
train epoch 89 avg loss: 1.35470 (A-MSE: 1.17446) avg lploss: 0.00000
train epoch 90 avg loss: 1.27157 (A-MSE: 1.09163) avg lploss: 0.00000
==> val epoch 90 avg loss: 1.42729 (A-MSE: 1.20074) avg lploss: 0.00000
==> test epoch 90 avg loss: 1.46164 (A-MSE: 1.26272) avg lploss: 0.00000
*** Best Val Loss: 1.42729 	 Best Test Loss: 1.46164 	 Best epoch 90
Validation loss decreased (1.493207 --> 1.427288).  Saving model ...
train epoch 91 avg loss: 1.36491 (A-MSE: 1.17766) avg lploss: 0.00000
train epoch 92 avg loss: 1.47837 (A-MSE: 1.27046) avg lploss: 0.00000
train epoch 93 avg loss: 1.35986 (A-MSE: 1.16341) avg lploss: 0.00000
train epoch 94 avg loss: 1.34381 (A-MSE: 1.14516) avg lploss: 0.00000
train epoch 95 avg loss: 1.34184 (A-MSE: 1.14990) avg lploss: 0.00000
==> val epoch 95 avg loss: 1.64665 (A-MSE: 1.43048) avg lploss: 0.00000
==> test epoch 95 avg loss: 1.70725 (A-MSE: 1.53233) avg lploss: 0.00000
*** Best Val Loss: 1.42729 	 Best Test Loss: 1.46164 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 1.33198 (A-MSE: 1.15087) avg lploss: 0.00000
train epoch 97 avg loss: 1.27042 (A-MSE: 1.08832) avg lploss: 0.00000
train epoch 98 avg loss: 1.37572 (A-MSE: 1.17964) avg lploss: 0.00000
train epoch 99 avg loss: 1.27951 (A-MSE: 1.09220) avg lploss: 0.00000
train epoch 100 avg loss: 1.20734 (A-MSE: 1.03450) avg lploss: 0.00000
==> val epoch 100 avg loss: 1.36156 (A-MSE: 1.14582) avg lploss: 0.00000
==> test epoch 100 avg loss: 1.42958 (A-MSE: 1.24272) avg lploss: 0.00000
*** Best Val Loss: 1.36156 	 Best Test Loss: 1.42958 	 Best epoch 100
Validation loss decreased (1.427288 --> 1.361562).  Saving model ...
train epoch 101 avg loss: 1.34783 (A-MSE: 1.16296) avg lploss: 0.00000
train epoch 102 avg loss: 1.28987 (A-MSE: 1.10441) avg lploss: 0.00000
train epoch 103 avg loss: 1.17716 (A-MSE: 1.00375) avg lploss: 0.00000
train epoch 104 avg loss: 1.25504 (A-MSE: 1.07713) avg lploss: 0.00000
train epoch 105 avg loss: 1.19360 (A-MSE: 1.02633) avg lploss: 0.00000
==> val epoch 105 avg loss: 1.32680 (A-MSE: 1.12365) avg lploss: 0.00000
==> test epoch 105 avg loss: 1.39273 (A-MSE: 1.21777) avg lploss: 0.00000
*** Best Val Loss: 1.32680 	 Best Test Loss: 1.39273 	 Best epoch 105
Validation loss decreased (1.361562 --> 1.326804).  Saving model ...
train epoch 106 avg loss: 1.15759 (A-MSE: 0.99828) avg lploss: 0.00000
train epoch 107 avg loss: 1.14020 (A-MSE: 0.97852) avg lploss: 0.00000
train epoch 108 avg loss: 1.16331 (A-MSE: 0.99360) avg lploss: 0.00000
train epoch 109 avg loss: 1.24815 (A-MSE: 1.07103) avg lploss: 0.00000
train epoch 110 avg loss: 1.38477 (A-MSE: 1.19353) avg lploss: 0.00000
==> val epoch 110 avg loss: 1.40374 (A-MSE: 1.21295) avg lploss: 0.00000
==> test epoch 110 avg loss: 1.41211 (A-MSE: 1.26408) avg lploss: 0.00000
*** Best Val Loss: 1.32680 	 Best Test Loss: 1.39273 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 1.16195 (A-MSE: 0.99131) avg lploss: 0.00000
train epoch 112 avg loss: 1.14770 (A-MSE: 0.97655) avg lploss: 0.00000
train epoch 113 avg loss: 1.04487 (A-MSE: 0.89485) avg lploss: 0.00000
train epoch 114 avg loss: 1.03240 (A-MSE: 0.88525) avg lploss: 0.00000
train epoch 115 avg loss: 0.97992 (A-MSE: 0.83738) avg lploss: 0.00000
==> val epoch 115 avg loss: 1.20082 (A-MSE: 1.01483) avg lploss: 0.00000
==> test epoch 115 avg loss: 1.25905 (A-MSE: 1.10106) avg lploss: 0.00000
*** Best Val Loss: 1.20082 	 Best Test Loss: 1.25905 	 Best epoch 115
Validation loss decreased (1.326804 --> 1.200820).  Saving model ...
train epoch 116 avg loss: 1.00991 (A-MSE: 0.86926) avg lploss: 0.00000
train epoch 117 avg loss: 0.96637 (A-MSE: 0.82647) avg lploss: 0.00000
train epoch 118 avg loss: 1.11861 (A-MSE: 0.95355) avg lploss: 0.00000
train epoch 119 avg loss: 0.91108 (A-MSE: 0.78024) avg lploss: 0.00000
train epoch 120 avg loss: 0.88962 (A-MSE: 0.76086) avg lploss: 0.00000
==> val epoch 120 avg loss: 1.07750 (A-MSE: 0.90050) avg lploss: 0.00000
==> test epoch 120 avg loss: 1.11994 (A-MSE: 0.97027) avg lploss: 0.00000
*** Best Val Loss: 1.07750 	 Best Test Loss: 1.11994 	 Best epoch 120
Validation loss decreased (1.200820 --> 1.077504).  Saving model ...
train epoch 121 avg loss: 0.92917 (A-MSE: 0.79378) avg lploss: 0.00000
train epoch 122 avg loss: 1.00331 (A-MSE: 0.85803) avg lploss: 0.00000
train epoch 123 avg loss: 1.03863 (A-MSE: 0.88754) avg lploss: 0.00000
train epoch 124 avg loss: 1.10586 (A-MSE: 0.95251) avg lploss: 0.00000
train epoch 125 avg loss: 0.98890 (A-MSE: 0.85120) avg lploss: 0.00000
==> val epoch 125 avg loss: 1.09434 (A-MSE: 0.92227) avg lploss: 0.00000
==> test epoch 125 avg loss: 1.18250 (A-MSE: 1.03326) avg lploss: 0.00000
*** Best Val Loss: 1.07750 	 Best Test Loss: 1.11994 	 Best epoch 120
EarlyStopping counter: 1 out of 50
train epoch 126 avg loss: 0.94239 (A-MSE: 0.80996) avg lploss: 0.00000
train epoch 127 avg loss: 0.98689 (A-MSE: 0.85350) avg lploss: 0.00000
train epoch 128 avg loss: 1.14665 (A-MSE: 0.97965) avg lploss: 0.00000
train epoch 129 avg loss: 1.04252 (A-MSE: 0.89416) avg lploss: 0.00000
train epoch 130 avg loss: 1.00799 (A-MSE: 0.85784) avg lploss: 0.00000
==> val epoch 130 avg loss: 1.12217 (A-MSE: 0.94992) avg lploss: 0.00000
==> test epoch 130 avg loss: 1.15702 (A-MSE: 1.00299) avg lploss: 0.00000
*** Best Val Loss: 1.07750 	 Best Test Loss: 1.11994 	 Best epoch 120
EarlyStopping counter: 2 out of 50
train epoch 131 avg loss: 0.91347 (A-MSE: 0.78297) avg lploss: 0.00000
train epoch 132 avg loss: 0.86218 (A-MSE: 0.73731) avg lploss: 0.00000
train epoch 133 avg loss: 0.81121 (A-MSE: 0.68821) avg lploss: 0.00000
train epoch 134 avg loss: 0.81281 (A-MSE: 0.69150) avg lploss: 0.00000
train epoch 135 avg loss: 0.90011 (A-MSE: 0.77272) avg lploss: 0.00000
==> val epoch 135 avg loss: 1.11466 (A-MSE: 0.93817) avg lploss: 0.00000
==> test epoch 135 avg loss: 1.15199 (A-MSE: 0.99489) avg lploss: 0.00000
*** Best Val Loss: 1.07750 	 Best Test Loss: 1.11994 	 Best epoch 120
EarlyStopping counter: 3 out of 50
train epoch 136 avg loss: 0.88862 (A-MSE: 0.76149) avg lploss: 0.00000
train epoch 137 avg loss: 0.84217 (A-MSE: 0.72156) avg lploss: 0.00000
train epoch 138 avg loss: 0.85889 (A-MSE: 0.72979) avg lploss: 0.00000
train epoch 139 avg loss: 0.88612 (A-MSE: 0.76415) avg lploss: 0.00000
train epoch 140 avg loss: 0.90956 (A-MSE: 0.77669) avg lploss: 0.00000
==> val epoch 140 avg loss: 1.38695 (A-MSE: 1.17197) avg lploss: 0.00000
==> test epoch 140 avg loss: 1.33643 (A-MSE: 1.15053) avg lploss: 0.00000
*** Best Val Loss: 1.07750 	 Best Test Loss: 1.11994 	 Best epoch 120
EarlyStopping counter: 4 out of 50
train epoch 141 avg loss: 0.98845 (A-MSE: 0.85917) avg lploss: 0.00000
train epoch 142 avg loss: 1.03598 (A-MSE: 0.88719) avg lploss: 0.00000
train epoch 143 avg loss: 0.89074 (A-MSE: 0.75374) avg lploss: 0.00000
train epoch 144 avg loss: 0.77514 (A-MSE: 0.66066) avg lploss: 0.00000
train epoch 145 avg loss: 0.88183 (A-MSE: 0.75418) avg lploss: 0.00000
==> val epoch 145 avg loss: 1.16562 (A-MSE: 0.98361) avg lploss: 0.00000
==> test epoch 145 avg loss: 1.34420 (A-MSE: 1.18097) avg lploss: 0.00000
*** Best Val Loss: 1.07750 	 Best Test Loss: 1.11994 	 Best epoch 120
EarlyStopping counter: 5 out of 50
train epoch 146 avg loss: 0.92207 (A-MSE: 0.78962) avg lploss: 0.00000
train epoch 147 avg loss: 0.95953 (A-MSE: 0.82829) avg lploss: 0.00000
train epoch 148 avg loss: 0.81999 (A-MSE: 0.69847) avg lploss: 0.00000
train epoch 149 avg loss: 0.74074 (A-MSE: 0.63705) avg lploss: 0.00000
train epoch 150 avg loss: 0.78275 (A-MSE: 0.66199) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.97453 (A-MSE: 0.82480) avg lploss: 0.00000
==> test epoch 150 avg loss: 1.09395 (A-MSE: 0.96310) avg lploss: 0.00000
*** Best Val Loss: 0.97453 	 Best Test Loss: 1.09395 	 Best epoch 150
Validation loss decreased (1.077504 --> 0.974525).  Saving model ...
train epoch 151 avg loss: 0.78927 (A-MSE: 0.66716) avg lploss: 0.00000
train epoch 152 avg loss: 0.80421 (A-MSE: 0.68718) avg lploss: 0.00000
train epoch 153 avg loss: 0.70966 (A-MSE: 0.59917) avg lploss: 0.00000
train epoch 154 avg loss: 0.69306 (A-MSE: 0.58970) avg lploss: 0.00000
train epoch 155 avg loss: 0.68035 (A-MSE: 0.57825) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.86467 (A-MSE: 0.73432) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.93580 (A-MSE: 0.81921) avg lploss: 0.00000
*** Best Val Loss: 0.86467 	 Best Test Loss: 0.93580 	 Best epoch 155
Validation loss decreased (0.974525 --> 0.864668).  Saving model ...
train epoch 156 avg loss: 0.66092 (A-MSE: 0.56372) avg lploss: 0.00000
train epoch 157 avg loss: 0.66347 (A-MSE: 0.56538) avg lploss: 0.00000
train epoch 158 avg loss: 0.69948 (A-MSE: 0.59536) avg lploss: 0.00000
train epoch 159 avg loss: 0.74080 (A-MSE: 0.63048) avg lploss: 0.00000
train epoch 160 avg loss: 0.69863 (A-MSE: 0.59665) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.99772 (A-MSE: 0.82823) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.14999 (A-MSE: 1.00147) avg lploss: 0.00000
*** Best Val Loss: 0.86467 	 Best Test Loss: 0.93580 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 0.72269 (A-MSE: 0.62382) avg lploss: 0.00000
train epoch 162 avg loss: 0.70203 (A-MSE: 0.59996) avg lploss: 0.00000
train epoch 163 avg loss: 0.74618 (A-MSE: 0.63772) avg lploss: 0.00000
train epoch 164 avg loss: 0.67647 (A-MSE: 0.57493) avg lploss: 0.00000
train epoch 165 avg loss: 0.63191 (A-MSE: 0.53518) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.88059 (A-MSE: 0.72939) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.93312 (A-MSE: 0.79793) avg lploss: 0.00000
*** Best Val Loss: 0.86467 	 Best Test Loss: 0.93580 	 Best epoch 155
EarlyStopping counter: 2 out of 50
train epoch 166 avg loss: 0.67588 (A-MSE: 0.57149) avg lploss: 0.00000
train epoch 167 avg loss: 0.62033 (A-MSE: 0.52966) avg lploss: 0.00000
train epoch 168 avg loss: 0.62496 (A-MSE: 0.53842) avg lploss: 0.00000
train epoch 169 avg loss: 0.63971 (A-MSE: 0.53999) avg lploss: 0.00000
train epoch 170 avg loss: 0.62532 (A-MSE: 0.53481) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.93558 (A-MSE: 0.76248) avg lploss: 0.00000
==> test epoch 170 avg loss: 1.01333 (A-MSE: 0.86086) avg lploss: 0.00000
*** Best Val Loss: 0.86467 	 Best Test Loss: 0.93580 	 Best epoch 155
EarlyStopping counter: 3 out of 50
train epoch 171 avg loss: 0.63527 (A-MSE: 0.54313) avg lploss: 0.00000
train epoch 172 avg loss: 0.70780 (A-MSE: 0.59727) avg lploss: 0.00000
train epoch 173 avg loss: 0.65261 (A-MSE: 0.55195) avg lploss: 0.00000
train epoch 174 avg loss: 0.56604 (A-MSE: 0.48410) avg lploss: 0.00000
train epoch 175 avg loss: 0.59154 (A-MSE: 0.50616) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.79261 (A-MSE: 0.65576) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.88479 (A-MSE: 0.76286) avg lploss: 0.00000
*** Best Val Loss: 0.79261 	 Best Test Loss: 0.88479 	 Best epoch 175
Validation loss decreased (0.864668 --> 0.792611).  Saving model ...
train epoch 176 avg loss: 0.60190 (A-MSE: 0.51554) avg lploss: 0.00000
train epoch 177 avg loss: 0.58394 (A-MSE: 0.50167) avg lploss: 0.00000
train epoch 178 avg loss: 0.61120 (A-MSE: 0.52495) avg lploss: 0.00000
train epoch 179 avg loss: 0.67855 (A-MSE: 0.58677) avg lploss: 0.00000
train epoch 180 avg loss: 0.74126 (A-MSE: 0.63170) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.97937 (A-MSE: 0.81953) avg lploss: 0.00000
==> test epoch 180 avg loss: 1.08268 (A-MSE: 0.94072) avg lploss: 0.00000
*** Best Val Loss: 0.79261 	 Best Test Loss: 0.88479 	 Best epoch 175
EarlyStopping counter: 1 out of 50
train epoch 181 avg loss: 0.60700 (A-MSE: 0.51415) avg lploss: 0.00000
train epoch 182 avg loss: 0.67046 (A-MSE: 0.57722) avg lploss: 0.00000
train epoch 183 avg loss: 0.91494 (A-MSE: 0.78684) avg lploss: 0.00000
train epoch 184 avg loss: 0.86077 (A-MSE: 0.73971) avg lploss: 0.00000
train epoch 185 avg loss: 0.74926 (A-MSE: 0.64259) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.99065 (A-MSE: 0.84074) avg lploss: 0.00000
==> test epoch 185 avg loss: 1.11103 (A-MSE: 0.97174) avg lploss: 0.00000
*** Best Val Loss: 0.79261 	 Best Test Loss: 0.88479 	 Best epoch 175
EarlyStopping counter: 2 out of 50
train epoch 186 avg loss: 0.61705 (A-MSE: 0.52595) avg lploss: 0.00000
train epoch 187 avg loss: 0.70602 (A-MSE: 0.60488) avg lploss: 0.00000
train epoch 188 avg loss: 0.65917 (A-MSE: 0.56798) avg lploss: 0.00000
train epoch 189 avg loss: 0.55520 (A-MSE: 0.47181) avg lploss: 0.00000
train epoch 190 avg loss: 0.53515 (A-MSE: 0.45617) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.72333 (A-MSE: 0.60769) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.75309 (A-MSE: 0.65636) avg lploss: 0.00000
*** Best Val Loss: 0.72333 	 Best Test Loss: 0.75309 	 Best epoch 190
Validation loss decreased (0.792611 --> 0.723335).  Saving model ...
train epoch 191 avg loss: 0.53726 (A-MSE: 0.45810) avg lploss: 0.00000
train epoch 192 avg loss: 0.56362 (A-MSE: 0.48196) avg lploss: 0.00000
train epoch 193 avg loss: 0.63008 (A-MSE: 0.53594) avg lploss: 0.00000
train epoch 194 avg loss: 0.62338 (A-MSE: 0.53461) avg lploss: 0.00000
train epoch 195 avg loss: 0.62218 (A-MSE: 0.54200) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.75973 (A-MSE: 0.62443) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.80204 (A-MSE: 0.68400) avg lploss: 0.00000
*** Best Val Loss: 0.72333 	 Best Test Loss: 0.75309 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 0.56323 (A-MSE: 0.47603) avg lploss: 0.00000
train epoch 197 avg loss: 0.63986 (A-MSE: 0.54696) avg lploss: 0.00000
train epoch 198 avg loss: 0.54925 (A-MSE: 0.46458) avg lploss: 0.00000
train epoch 199 avg loss: 0.50961 (A-MSE: 0.43415) avg lploss: 0.00000
train epoch 200 avg loss: 0.50787 (A-MSE: 0.43304) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.70467 (A-MSE: 0.58320) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.74883 (A-MSE: 0.64675) avg lploss: 0.00000
*** Best Val Loss: 0.70467 	 Best Test Loss: 0.74883 	 Best epoch 200
Validation loss decreased (0.723335 --> 0.704672).  Saving model ...
train epoch 201 avg loss: 0.53920 (A-MSE: 0.46195) avg lploss: 0.00000
train epoch 202 avg loss: 0.56337 (A-MSE: 0.47781) avg lploss: 0.00000
train epoch 203 avg loss: 0.54954 (A-MSE: 0.46767) avg lploss: 0.00000
train epoch 204 avg loss: 0.51229 (A-MSE: 0.44244) avg lploss: 0.00000
train epoch 205 avg loss: 0.50725 (A-MSE: 0.43125) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.73975 (A-MSE: 0.61236) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.81358 (A-MSE: 0.70594) avg lploss: 0.00000
*** Best Val Loss: 0.70467 	 Best Test Loss: 0.74883 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 0.50853 (A-MSE: 0.43572) avg lploss: 0.00000
train epoch 207 avg loss: 0.51810 (A-MSE: 0.44341) avg lploss: 0.00000
train epoch 208 avg loss: 0.48767 (A-MSE: 0.41521) avg lploss: 0.00000
train epoch 209 avg loss: 0.46958 (A-MSE: 0.39957) avg lploss: 0.00000
train epoch 210 avg loss: 0.46565 (A-MSE: 0.39677) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.70646 (A-MSE: 0.59273) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.76644 (A-MSE: 0.66981) avg lploss: 0.00000
*** Best Val Loss: 0.70467 	 Best Test Loss: 0.74883 	 Best epoch 200
EarlyStopping counter: 2 out of 50
train epoch 211 avg loss: 0.53651 (A-MSE: 0.46071) avg lploss: 0.00000
train epoch 212 avg loss: 0.51935 (A-MSE: 0.44866) avg lploss: 0.00000
train epoch 213 avg loss: 0.56770 (A-MSE: 0.47860) avg lploss: 0.00000
train epoch 214 avg loss: 0.63219 (A-MSE: 0.54876) avg lploss: 0.00000
train epoch 215 avg loss: 0.57807 (A-MSE: 0.49848) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.71284 (A-MSE: 0.58798) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.78146 (A-MSE: 0.67476) avg lploss: 0.00000
*** Best Val Loss: 0.70467 	 Best Test Loss: 0.74883 	 Best epoch 200
EarlyStopping counter: 3 out of 50
train epoch 216 avg loss: 0.46247 (A-MSE: 0.39623) avg lploss: 0.00000
train epoch 217 avg loss: 0.46747 (A-MSE: 0.39485) avg lploss: 0.00000
train epoch 218 avg loss: 0.47132 (A-MSE: 0.40707) avg lploss: 0.00000
train epoch 219 avg loss: 0.58502 (A-MSE: 0.50378) avg lploss: 0.00000
train epoch 220 avg loss: 0.47681 (A-MSE: 0.40431) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.67611 (A-MSE: 0.56403) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.69210 (A-MSE: 0.60176) avg lploss: 0.00000
*** Best Val Loss: 0.67611 	 Best Test Loss: 0.69210 	 Best epoch 220
Validation loss decreased (0.704672 --> 0.676107).  Saving model ...
train epoch 221 avg loss: 0.44611 (A-MSE: 0.38364) avg lploss: 0.00000
train epoch 222 avg loss: 0.47669 (A-MSE: 0.40628) avg lploss: 0.00000
train epoch 223 avg loss: 0.47799 (A-MSE: 0.40629) avg lploss: 0.00000
train epoch 224 avg loss: 0.52011 (A-MSE: 0.44767) avg lploss: 0.00000
train epoch 225 avg loss: 0.44632 (A-MSE: 0.37834) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.74308 (A-MSE: 0.62039) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.85109 (A-MSE: 0.74194) avg lploss: 0.00000
*** Best Val Loss: 0.67611 	 Best Test Loss: 0.69210 	 Best epoch 220
EarlyStopping counter: 1 out of 50
train epoch 226 avg loss: 0.45179 (A-MSE: 0.38911) avg lploss: 0.00000
train epoch 227 avg loss: 0.47117 (A-MSE: 0.40441) avg lploss: 0.00000
train epoch 228 avg loss: 0.44922 (A-MSE: 0.38318) avg lploss: 0.00000
train epoch 229 avg loss: 0.54901 (A-MSE: 0.48008) avg lploss: 0.00000
train epoch 230 avg loss: 0.58468 (A-MSE: 0.50431) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.93670 (A-MSE: 0.78341) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.93154 (A-MSE: 0.80157) avg lploss: 0.00000
*** Best Val Loss: 0.67611 	 Best Test Loss: 0.69210 	 Best epoch 220
EarlyStopping counter: 2 out of 50
train epoch 231 avg loss: 0.53386 (A-MSE: 0.45269) avg lploss: 0.00000
train epoch 232 avg loss: 0.57034 (A-MSE: 0.49014) avg lploss: 0.00000
train epoch 233 avg loss: 0.55845 (A-MSE: 0.47493) avg lploss: 0.00000
train epoch 234 avg loss: 0.48551 (A-MSE: 0.41912) avg lploss: 0.00000
train epoch 235 avg loss: 0.48526 (A-MSE: 0.41381) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.61815 (A-MSE: 0.52132) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.66529 (A-MSE: 0.58465) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
Validation loss decreased (0.676107 --> 0.618151).  Saving model ...
train epoch 236 avg loss: 0.47620 (A-MSE: 0.41500) avg lploss: 0.00000
train epoch 237 avg loss: 0.48500 (A-MSE: 0.41211) avg lploss: 0.00000
train epoch 238 avg loss: 0.50279 (A-MSE: 0.42180) avg lploss: 0.00000
train epoch 239 avg loss: 0.48247 (A-MSE: 0.41500) avg lploss: 0.00000
train epoch 240 avg loss: 0.48653 (A-MSE: 0.41562) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.76332 (A-MSE: 0.65391) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.83096 (A-MSE: 0.73060) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.51931 (A-MSE: 0.44699) avg lploss: 0.00000
train epoch 242 avg loss: 0.45947 (A-MSE: 0.39360) avg lploss: 0.00000
train epoch 243 avg loss: 0.45851 (A-MSE: 0.39100) avg lploss: 0.00000
train epoch 244 avg loss: 0.39703 (A-MSE: 0.34275) avg lploss: 0.00000
train epoch 245 avg loss: 0.43506 (A-MSE: 0.37371) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.66490 (A-MSE: 0.55567) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.72378 (A-MSE: 0.63027) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.39265 (A-MSE: 0.33826) avg lploss: 0.00000
train epoch 247 avg loss: 0.43466 (A-MSE: 0.37517) avg lploss: 0.00000
train epoch 248 avg loss: 0.45651 (A-MSE: 0.38729) avg lploss: 0.00000
train epoch 249 avg loss: 0.39485 (A-MSE: 0.34038) avg lploss: 0.00000
train epoch 250 avg loss: 0.38769 (A-MSE: 0.33171) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.76568 (A-MSE: 0.64183) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.80626 (A-MSE: 0.69956) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 0.38686 (A-MSE: 0.33174) avg lploss: 0.00000
train epoch 252 avg loss: 0.41154 (A-MSE: 0.35178) avg lploss: 0.00000
train epoch 253 avg loss: 0.42818 (A-MSE: 0.36529) avg lploss: 0.00000
train epoch 254 avg loss: 0.39901 (A-MSE: 0.34281) avg lploss: 0.00000
train epoch 255 avg loss: 0.40603 (A-MSE: 0.34869) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.77799 (A-MSE: 0.65307) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.81036 (A-MSE: 0.70529) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 4 out of 50
train epoch 256 avg loss: 0.38649 (A-MSE: 0.33155) avg lploss: 0.00000
train epoch 257 avg loss: 0.36759 (A-MSE: 0.31278) avg lploss: 0.00000
train epoch 258 avg loss: 0.43794 (A-MSE: 0.37694) avg lploss: 0.00000
train epoch 259 avg loss: 0.43123 (A-MSE: 0.37277) avg lploss: 0.00000
train epoch 260 avg loss: 0.45274 (A-MSE: 0.38992) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.76225 (A-MSE: 0.64408) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.88595 (A-MSE: 0.77384) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 5 out of 50
train epoch 261 avg loss: 0.51432 (A-MSE: 0.44570) avg lploss: 0.00000
train epoch 262 avg loss: 0.50675 (A-MSE: 0.43493) avg lploss: 0.00000
train epoch 263 avg loss: 0.40216 (A-MSE: 0.34189) avg lploss: 0.00000
train epoch 264 avg loss: 0.46170 (A-MSE: 0.39831) avg lploss: 0.00000
train epoch 265 avg loss: 0.40940 (A-MSE: 0.34872) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.64971 (A-MSE: 0.53890) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.68213 (A-MSE: 0.58918) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 6 out of 50
train epoch 266 avg loss: 0.42110 (A-MSE: 0.36019) avg lploss: 0.00000
train epoch 267 avg loss: 0.40303 (A-MSE: 0.34752) avg lploss: 0.00000
train epoch 268 avg loss: 0.40392 (A-MSE: 0.34876) avg lploss: 0.00000
train epoch 269 avg loss: 0.41007 (A-MSE: 0.35098) avg lploss: 0.00000
train epoch 270 avg loss: 0.41813 (A-MSE: 0.36288) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.81759 (A-MSE: 0.67264) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.83920 (A-MSE: 0.71291) avg lploss: 0.00000
*** Best Val Loss: 0.61815 	 Best Test Loss: 0.66529 	 Best epoch 235
EarlyStopping counter: 7 out of 50
train epoch 271 avg loss: 0.42667 (A-MSE: 0.36429) avg lploss: 0.00000
train epoch 272 avg loss: 0.40682 (A-MSE: 0.35064) avg lploss: 0.00000
train epoch 273 avg loss: 0.39896 (A-MSE: 0.34535) avg lploss: 0.00000
train epoch 274 avg loss: 0.38582 (A-MSE: 0.32731) avg lploss: 0.00000
train epoch 275 avg loss: 0.37635 (A-MSE: 0.32379) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.60753 (A-MSE: 0.51113) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.67042 (A-MSE: 0.59056) avg lploss: 0.00000
*** Best Val Loss: 0.60753 	 Best Test Loss: 0.67042 	 Best epoch 275
Validation loss decreased (0.618151 --> 0.607534).  Saving model ...
train epoch 276 avg loss: 0.38983 (A-MSE: 0.33313) avg lploss: 0.00000
train epoch 277 avg loss: 0.44140 (A-MSE: 0.38233) avg lploss: 0.00000
train epoch 278 avg loss: 0.39009 (A-MSE: 0.33642) avg lploss: 0.00000
train epoch 279 avg loss: 0.39533 (A-MSE: 0.33796) avg lploss: 0.00000
train epoch 280 avg loss: 0.37908 (A-MSE: 0.32499) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.68126 (A-MSE: 0.57285) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.70747 (A-MSE: 0.61652) avg lploss: 0.00000
*** Best Val Loss: 0.60753 	 Best Test Loss: 0.67042 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 0.41059 (A-MSE: 0.35304) avg lploss: 0.00000
train epoch 282 avg loss: 0.36287 (A-MSE: 0.31368) avg lploss: 0.00000
train epoch 283 avg loss: 0.44886 (A-MSE: 0.38550) avg lploss: 0.00000
train epoch 284 avg loss: 0.40932 (A-MSE: 0.35284) avg lploss: 0.00000
train epoch 285 avg loss: 0.49912 (A-MSE: 0.42809) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.65126 (A-MSE: 0.54236) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.63320 (A-MSE: 0.53926) avg lploss: 0.00000
*** Best Val Loss: 0.60753 	 Best Test Loss: 0.67042 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 0.43266 (A-MSE: 0.37265) avg lploss: 0.00000
train epoch 287 avg loss: 0.34356 (A-MSE: 0.29602) avg lploss: 0.00000
train epoch 288 avg loss: 0.33783 (A-MSE: 0.28812) avg lploss: 0.00000
train epoch 289 avg loss: 0.33379 (A-MSE: 0.28584) avg lploss: 0.00000
train epoch 290 avg loss: 0.35185 (A-MSE: 0.29960) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.52925 (A-MSE: 0.45199) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.60180 (A-MSE: 0.53712) avg lploss: 0.00000
*** Best Val Loss: 0.52925 	 Best Test Loss: 0.60180 	 Best epoch 290
Validation loss decreased (0.607534 --> 0.529253).  Saving model ...
train epoch 291 avg loss: 0.34569 (A-MSE: 0.29967) avg lploss: 0.00000
train epoch 292 avg loss: 0.39869 (A-MSE: 0.34334) avg lploss: 0.00000
train epoch 293 avg loss: 0.35376 (A-MSE: 0.30659) avg lploss: 0.00000
train epoch 294 avg loss: 0.32951 (A-MSE: 0.28265) avg lploss: 0.00000
train epoch 295 avg loss: 0.32680 (A-MSE: 0.27714) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.53192 (A-MSE: 0.45218) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.61618 (A-MSE: 0.54400) avg lploss: 0.00000
*** Best Val Loss: 0.52925 	 Best Test Loss: 0.60180 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 0.31703 (A-MSE: 0.27126) avg lploss: 0.00000
train epoch 297 avg loss: 0.32535 (A-MSE: 0.28131) avg lploss: 0.00000
train epoch 298 avg loss: 0.38486 (A-MSE: 0.32662) avg lploss: 0.00000
train epoch 299 avg loss: 0.41459 (A-MSE: 0.35602) avg lploss: 0.00000
train epoch 300 avg loss: 0.38252 (A-MSE: 0.33081) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.54328 (A-MSE: 0.45862) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.58094 (A-MSE: 0.51063) avg lploss: 0.00000
*** Best Val Loss: 0.52925 	 Best Test Loss: 0.60180 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 0.37783 (A-MSE: 0.32664) avg lploss: 0.00000
train epoch 302 avg loss: 0.34582 (A-MSE: 0.29595) avg lploss: 0.00000
train epoch 303 avg loss: 0.32055 (A-MSE: 0.27526) avg lploss: 0.00000
train epoch 304 avg loss: 0.34498 (A-MSE: 0.29112) avg lploss: 0.00000
train epoch 305 avg loss: 0.32504 (A-MSE: 0.27758) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.50375 (A-MSE: 0.42631) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.56290 (A-MSE: 0.49259) avg lploss: 0.00000
*** Best Val Loss: 0.50375 	 Best Test Loss: 0.56290 	 Best epoch 305
Validation loss decreased (0.529253 --> 0.503751).  Saving model ...
train epoch 306 avg loss: 0.30233 (A-MSE: 0.26171) avg lploss: 0.00000
train epoch 307 avg loss: 0.33711 (A-MSE: 0.29179) avg lploss: 0.00000
train epoch 308 avg loss: 0.33547 (A-MSE: 0.28944) avg lploss: 0.00000
train epoch 309 avg loss: 0.33082 (A-MSE: 0.28263) avg lploss: 0.00000
train epoch 310 avg loss: 0.31229 (A-MSE: 0.27155) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.59129 (A-MSE: 0.49681) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.69764 (A-MSE: 0.60571) avg lploss: 0.00000
*** Best Val Loss: 0.50375 	 Best Test Loss: 0.56290 	 Best epoch 305
EarlyStopping counter: 1 out of 50
train epoch 311 avg loss: 0.32580 (A-MSE: 0.27831) avg lploss: 0.00000
train epoch 312 avg loss: 0.33479 (A-MSE: 0.28697) avg lploss: 0.00000
train epoch 313 avg loss: 0.40132 (A-MSE: 0.34669) avg lploss: 0.00000
train epoch 314 avg loss: 0.39543 (A-MSE: 0.34166) avg lploss: 0.00000
train epoch 315 avg loss: 0.35378 (A-MSE: 0.30204) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.51584 (A-MSE: 0.43506) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.58259 (A-MSE: 0.50946) avg lploss: 0.00000
*** Best Val Loss: 0.50375 	 Best Test Loss: 0.56290 	 Best epoch 305
EarlyStopping counter: 2 out of 50
train epoch 316 avg loss: 0.29778 (A-MSE: 0.25493) avg lploss: 0.00000
train epoch 317 avg loss: 0.30551 (A-MSE: 0.26150) avg lploss: 0.00000
train epoch 318 avg loss: 0.29354 (A-MSE: 0.25347) avg lploss: 0.00000
train epoch 319 avg loss: 0.32378 (A-MSE: 0.27960) avg lploss: 0.00000
train epoch 320 avg loss: 0.46086 (A-MSE: 0.40164) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.67069 (A-MSE: 0.57225) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.75512 (A-MSE: 0.66971) avg lploss: 0.00000
*** Best Val Loss: 0.50375 	 Best Test Loss: 0.56290 	 Best epoch 305
EarlyStopping counter: 3 out of 50
train epoch 321 avg loss: 0.44098 (A-MSE: 0.37828) avg lploss: 0.00000
train epoch 322 avg loss: 0.33313 (A-MSE: 0.28808) avg lploss: 0.00000
train epoch 323 avg loss: 0.29604 (A-MSE: 0.25538) avg lploss: 0.00000
train epoch 324 avg loss: 0.30056 (A-MSE: 0.25506) avg lploss: 0.00000
train epoch 325 avg loss: 0.26583 (A-MSE: 0.22884) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.47821 (A-MSE: 0.40702) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.52052 (A-MSE: 0.45267) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
Validation loss decreased (0.503751 --> 0.478208).  Saving model ...
train epoch 326 avg loss: 0.28635 (A-MSE: 0.24486) avg lploss: 0.00000
train epoch 327 avg loss: 0.28548 (A-MSE: 0.24620) avg lploss: 0.00000
train epoch 328 avg loss: 0.33735 (A-MSE: 0.28957) avg lploss: 0.00000
train epoch 329 avg loss: 0.33048 (A-MSE: 0.28440) avg lploss: 0.00000
train epoch 330 avg loss: 0.35665 (A-MSE: 0.30529) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.55716 (A-MSE: 0.49156) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.64501 (A-MSE: 0.58217) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 1 out of 50
train epoch 331 avg loss: 0.33541 (A-MSE: 0.28931) avg lploss: 0.00000
train epoch 332 avg loss: 0.29015 (A-MSE: 0.24955) avg lploss: 0.00000
train epoch 333 avg loss: 0.27641 (A-MSE: 0.23632) avg lploss: 0.00000
train epoch 334 avg loss: 0.32865 (A-MSE: 0.28613) avg lploss: 0.00000
train epoch 335 avg loss: 0.29811 (A-MSE: 0.25709) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.49169 (A-MSE: 0.41698) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.52468 (A-MSE: 0.46463) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 2 out of 50
train epoch 336 avg loss: 0.27777 (A-MSE: 0.23892) avg lploss: 0.00000
train epoch 337 avg loss: 0.29288 (A-MSE: 0.25355) avg lploss: 0.00000
train epoch 338 avg loss: 0.28981 (A-MSE: 0.25106) avg lploss: 0.00000
train epoch 339 avg loss: 0.28742 (A-MSE: 0.24564) avg lploss: 0.00000
train epoch 340 avg loss: 0.30310 (A-MSE: 0.26309) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.53313 (A-MSE: 0.46209) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.58331 (A-MSE: 0.52055) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 3 out of 50
train epoch 341 avg loss: 0.28532 (A-MSE: 0.24457) avg lploss: 0.00000
train epoch 342 avg loss: 0.27309 (A-MSE: 0.23410) avg lploss: 0.00000
train epoch 343 avg loss: 0.30132 (A-MSE: 0.25746) avg lploss: 0.00000
train epoch 344 avg loss: 0.29292 (A-MSE: 0.25294) avg lploss: 0.00000
train epoch 345 avg loss: 0.30511 (A-MSE: 0.26307) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.48678 (A-MSE: 0.41050) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.53616 (A-MSE: 0.46898) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 4 out of 50
train epoch 346 avg loss: 0.26833 (A-MSE: 0.23027) avg lploss: 0.00000
train epoch 347 avg loss: 0.26720 (A-MSE: 0.22841) avg lploss: 0.00000
train epoch 348 avg loss: 0.29234 (A-MSE: 0.25197) avg lploss: 0.00000
train epoch 349 avg loss: 0.29302 (A-MSE: 0.24979) avg lploss: 0.00000
train epoch 350 avg loss: 0.26405 (A-MSE: 0.22983) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.52645 (A-MSE: 0.45007) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.54343 (A-MSE: 0.48154) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 5 out of 50
train epoch 351 avg loss: 0.25689 (A-MSE: 0.22110) avg lploss: 0.00000
train epoch 352 avg loss: 0.26711 (A-MSE: 0.23021) avg lploss: 0.00000
train epoch 353 avg loss: 0.28492 (A-MSE: 0.24732) avg lploss: 0.00000
train epoch 354 avg loss: 0.29821 (A-MSE: 0.25695) avg lploss: 0.00000
train epoch 355 avg loss: 0.31016 (A-MSE: 0.26837) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.50932 (A-MSE: 0.44272) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.54210 (A-MSE: 0.48000) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 6 out of 50
train epoch 356 avg loss: 0.27894 (A-MSE: 0.23892) avg lploss: 0.00000
train epoch 357 avg loss: 0.32388 (A-MSE: 0.28184) avg lploss: 0.00000
train epoch 358 avg loss: 0.29469 (A-MSE: 0.25366) avg lploss: 0.00000
train epoch 359 avg loss: 0.28156 (A-MSE: 0.24214) avg lploss: 0.00000
train epoch 360 avg loss: 0.25583 (A-MSE: 0.22124) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.55233 (A-MSE: 0.47202) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.55526 (A-MSE: 0.48554) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 7 out of 50
train epoch 361 avg loss: 0.28686 (A-MSE: 0.24548) avg lploss: 0.00000
train epoch 362 avg loss: 0.29334 (A-MSE: 0.25351) avg lploss: 0.00000
train epoch 363 avg loss: 0.25547 (A-MSE: 0.21981) avg lploss: 0.00000
train epoch 364 avg loss: 0.28148 (A-MSE: 0.24540) avg lploss: 0.00000
train epoch 365 avg loss: 0.31873 (A-MSE: 0.27641) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.48582 (A-MSE: 0.41068) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.49642 (A-MSE: 0.43420) avg lploss: 0.00000
*** Best Val Loss: 0.47821 	 Best Test Loss: 0.52052 	 Best epoch 325
EarlyStopping counter: 8 out of 50
train epoch 366 avg loss: 0.26148 (A-MSE: 0.22612) avg lploss: 0.00000
train epoch 367 avg loss: 0.27288 (A-MSE: 0.23530) avg lploss: 0.00000
train epoch 368 avg loss: 0.33320 (A-MSE: 0.28866) avg lploss: 0.00000
train epoch 369 avg loss: 0.27673 (A-MSE: 0.23788) avg lploss: 0.00000
train epoch 370 avg loss: 0.23779 (A-MSE: 0.20436) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.45026 (A-MSE: 0.38603) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.50000 (A-MSE: 0.44675) avg lploss: 0.00000
*** Best Val Loss: 0.45026 	 Best Test Loss: 0.50000 	 Best epoch 370
Validation loss decreased (0.478208 --> 0.450255).  Saving model ...
train epoch 371 avg loss: 0.25643 (A-MSE: 0.22058) avg lploss: 0.00000
train epoch 372 avg loss: 0.23924 (A-MSE: 0.20626) avg lploss: 0.00000
train epoch 373 avg loss: 0.23974 (A-MSE: 0.20797) avg lploss: 0.00000
train epoch 374 avg loss: 0.25993 (A-MSE: 0.22386) avg lploss: 0.00000
train epoch 375 avg loss: 0.25834 (A-MSE: 0.22260) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.49736 (A-MSE: 0.43252) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.50090 (A-MSE: 0.44357) avg lploss: 0.00000
*** Best Val Loss: 0.45026 	 Best Test Loss: 0.50000 	 Best epoch 370
EarlyStopping counter: 1 out of 50
train epoch 376 avg loss: 0.25505 (A-MSE: 0.22095) avg lploss: 0.00000
train epoch 377 avg loss: 0.26373 (A-MSE: 0.22991) avg lploss: 0.00000
train epoch 378 avg loss: 0.27649 (A-MSE: 0.23805) avg lploss: 0.00000
train epoch 379 avg loss: 0.26319 (A-MSE: 0.22743) avg lploss: 0.00000
train epoch 380 avg loss: 0.28316 (A-MSE: 0.24585) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.46081 (A-MSE: 0.39038) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.49090 (A-MSE: 0.42557) avg lploss: 0.00000
*** Best Val Loss: 0.45026 	 Best Test Loss: 0.50000 	 Best epoch 370
EarlyStopping counter: 2 out of 50
train epoch 381 avg loss: 0.25762 (A-MSE: 0.21932) avg lploss: 0.00000
train epoch 382 avg loss: 0.26699 (A-MSE: 0.23321) avg lploss: 0.00000
train epoch 383 avg loss: 0.28726 (A-MSE: 0.25104) avg lploss: 0.00000
train epoch 384 avg loss: 0.27192 (A-MSE: 0.23448) avg lploss: 0.00000
train epoch 385 avg loss: 0.23964 (A-MSE: 0.20660) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.49697 (A-MSE: 0.43001) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.52353 (A-MSE: 0.46773) avg lploss: 0.00000
*** Best Val Loss: 0.45026 	 Best Test Loss: 0.50000 	 Best epoch 370
EarlyStopping counter: 3 out of 50
train epoch 386 avg loss: 0.30007 (A-MSE: 0.26147) avg lploss: 0.00000
train epoch 387 avg loss: 0.30720 (A-MSE: 0.26875) avg lploss: 0.00000
train epoch 388 avg loss: 0.32069 (A-MSE: 0.27753) avg lploss: 0.00000
train epoch 389 avg loss: 0.27164 (A-MSE: 0.23345) avg lploss: 0.00000
train epoch 390 avg loss: 0.26066 (A-MSE: 0.22332) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.46701 (A-MSE: 0.39667) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.52224 (A-MSE: 0.46400) avg lploss: 0.00000
*** Best Val Loss: 0.45026 	 Best Test Loss: 0.50000 	 Best epoch 370
EarlyStopping counter: 4 out of 50
train epoch 391 avg loss: 0.23677 (A-MSE: 0.20545) avg lploss: 0.00000
train epoch 392 avg loss: 0.22769 (A-MSE: 0.19522) avg lploss: 0.00000
train epoch 393 avg loss: 0.25999 (A-MSE: 0.22602) avg lploss: 0.00000
train epoch 394 avg loss: 0.26316 (A-MSE: 0.22922) avg lploss: 0.00000
train epoch 395 avg loss: 0.24990 (A-MSE: 0.21505) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.45877 (A-MSE: 0.39386) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.49603 (A-MSE: 0.44101) avg lploss: 0.00000
*** Best Val Loss: 0.45026 	 Best Test Loss: 0.50000 	 Best epoch 370
EarlyStopping counter: 5 out of 50
train epoch 396 avg loss: 0.25578 (A-MSE: 0.22187) avg lploss: 0.00000
train epoch 397 avg loss: 0.23440 (A-MSE: 0.20270) avg lploss: 0.00000
train epoch 398 avg loss: 0.23797 (A-MSE: 0.20486) avg lploss: 0.00000
train epoch 399 avg loss: 0.22795 (A-MSE: 0.19775) avg lploss: 0.00000
train epoch 400 avg loss: 0.22766 (A-MSE: 0.19685) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.43871 (A-MSE: 0.38209) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.50180 (A-MSE: 0.44855) avg lploss: 0.00000
*** Best Val Loss: 0.43871 	 Best Test Loss: 0.50180 	 Best epoch 400
Validation loss decreased (0.450255 --> 0.438712).  Saving model ...
train epoch 401 avg loss: 0.22333 (A-MSE: 0.19412) avg lploss: 0.00000
train epoch 402 avg loss: 0.21588 (A-MSE: 0.18651) avg lploss: 0.00000
train epoch 403 avg loss: 0.26509 (A-MSE: 0.22881) avg lploss: 0.00000
train epoch 404 avg loss: 0.29225 (A-MSE: 0.25251) avg lploss: 0.00000
train epoch 405 avg loss: 0.28728 (A-MSE: 0.25109) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.55834 (A-MSE: 0.49493) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.55101 (A-MSE: 0.49901) avg lploss: 0.00000
*** Best Val Loss: 0.43871 	 Best Test Loss: 0.50180 	 Best epoch 400
EarlyStopping counter: 1 out of 50
train epoch 406 avg loss: 0.26590 (A-MSE: 0.22906) avg lploss: 0.00000
train epoch 407 avg loss: 0.28480 (A-MSE: 0.25163) avg lploss: 0.00000
train epoch 408 avg loss: 0.28363 (A-MSE: 0.24505) avg lploss: 0.00000
train epoch 409 avg loss: 0.27768 (A-MSE: 0.24125) avg lploss: 0.00000
train epoch 410 avg loss: 0.30315 (A-MSE: 0.26093) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.43648 (A-MSE: 0.37654) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.45556 (A-MSE: 0.40265) avg lploss: 0.00000
*** Best Val Loss: 0.43648 	 Best Test Loss: 0.45556 	 Best epoch 410
Validation loss decreased (0.438712 --> 0.436478).  Saving model ...
train epoch 411 avg loss: 0.23897 (A-MSE: 0.20699) avg lploss: 0.00000
train epoch 412 avg loss: 0.31045 (A-MSE: 0.26789) avg lploss: 0.00000
train epoch 413 avg loss: 0.34935 (A-MSE: 0.29995) avg lploss: 0.00000
train epoch 414 avg loss: 0.27592 (A-MSE: 0.23692) avg lploss: 0.00000
train epoch 415 avg loss: 0.23622 (A-MSE: 0.20263) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.42314 (A-MSE: 0.37208) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.45765 (A-MSE: 0.41326) avg lploss: 0.00000
*** Best Val Loss: 0.42314 	 Best Test Loss: 0.45765 	 Best epoch 415
Validation loss decreased (0.436478 --> 0.423145).  Saving model ...
train epoch 416 avg loss: 0.22287 (A-MSE: 0.19329) avg lploss: 0.00000
train epoch 417 avg loss: 0.22697 (A-MSE: 0.19655) avg lploss: 0.00000
train epoch 418 avg loss: 0.24321 (A-MSE: 0.21197) avg lploss: 0.00000
train epoch 419 avg loss: 0.28664 (A-MSE: 0.24706) avg lploss: 0.00000
train epoch 420 avg loss: 0.26792 (A-MSE: 0.23115) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.46068 (A-MSE: 0.39232) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.49669 (A-MSE: 0.43578) avg lploss: 0.00000
*** Best Val Loss: 0.42314 	 Best Test Loss: 0.45765 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 0.23008 (A-MSE: 0.19960) avg lploss: 0.00000
train epoch 422 avg loss: 0.22077 (A-MSE: 0.19102) avg lploss: 0.00000
train epoch 423 avg loss: 0.21177 (A-MSE: 0.18484) avg lploss: 0.00000
train epoch 424 avg loss: 0.26808 (A-MSE: 0.23431) avg lploss: 0.00000
train epoch 425 avg loss: 0.29105 (A-MSE: 0.25290) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.44171 (A-MSE: 0.37865) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.44738 (A-MSE: 0.39392) avg lploss: 0.00000
*** Best Val Loss: 0.42314 	 Best Test Loss: 0.45765 	 Best epoch 415
EarlyStopping counter: 2 out of 50
train epoch 426 avg loss: 0.25637 (A-MSE: 0.22153) avg lploss: 0.00000
train epoch 427 avg loss: 0.25631 (A-MSE: 0.22256) avg lploss: 0.00000
train epoch 428 avg loss: 0.23511 (A-MSE: 0.20211) avg lploss: 0.00000
train epoch 429 avg loss: 0.19890 (A-MSE: 0.17274) avg lploss: 0.00000
train epoch 430 avg loss: 0.20282 (A-MSE: 0.17723) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.41291 (A-MSE: 0.36278) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.43773 (A-MSE: 0.39795) avg lploss: 0.00000
*** Best Val Loss: 0.41291 	 Best Test Loss: 0.43773 	 Best epoch 430
Validation loss decreased (0.423145 --> 0.412910).  Saving model ...
train epoch 431 avg loss: 0.20620 (A-MSE: 0.17833) avg lploss: 0.00000
train epoch 432 avg loss: 0.26953 (A-MSE: 0.23426) avg lploss: 0.00000
train epoch 433 avg loss: 0.25610 (A-MSE: 0.22048) avg lploss: 0.00000
train epoch 434 avg loss: 0.24303 (A-MSE: 0.21181) avg lploss: 0.00000
train epoch 435 avg loss: 0.20578 (A-MSE: 0.17891) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.41142 (A-MSE: 0.35689) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.42832 (A-MSE: 0.37968) avg lploss: 0.00000
*** Best Val Loss: 0.41142 	 Best Test Loss: 0.42832 	 Best epoch 435
Validation loss decreased (0.412910 --> 0.411419).  Saving model ...
train epoch 436 avg loss: 0.23576 (A-MSE: 0.20324) avg lploss: 0.00000
train epoch 437 avg loss: 0.31086 (A-MSE: 0.27003) avg lploss: 0.00000
train epoch 438 avg loss: 0.27041 (A-MSE: 0.23578) avg lploss: 0.00000
train epoch 439 avg loss: 0.23172 (A-MSE: 0.20142) avg lploss: 0.00000
train epoch 440 avg loss: 0.28050 (A-MSE: 0.24296) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.55449 (A-MSE: 0.48259) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.59671 (A-MSE: 0.53068) avg lploss: 0.00000
*** Best Val Loss: 0.41142 	 Best Test Loss: 0.42832 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 0.26188 (A-MSE: 0.22688) avg lploss: 0.00000
train epoch 442 avg loss: 0.26088 (A-MSE: 0.22682) avg lploss: 0.00000
train epoch 443 avg loss: 0.25834 (A-MSE: 0.22631) avg lploss: 0.00000
train epoch 444 avg loss: 0.26705 (A-MSE: 0.23319) avg lploss: 0.00000
train epoch 445 avg loss: 0.22854 (A-MSE: 0.19665) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.52732 (A-MSE: 0.47064) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.56643 (A-MSE: 0.51760) avg lploss: 0.00000
*** Best Val Loss: 0.41142 	 Best Test Loss: 0.42832 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 0.22963 (A-MSE: 0.20032) avg lploss: 0.00000
train epoch 447 avg loss: 0.21071 (A-MSE: 0.18044) avg lploss: 0.00000
train epoch 448 avg loss: 0.21590 (A-MSE: 0.18719) avg lploss: 0.00000
train epoch 449 avg loss: 0.20100 (A-MSE: 0.17453) avg lploss: 0.00000
train epoch 450 avg loss: 0.20124 (A-MSE: 0.17379) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.39064 (A-MSE: 0.34264) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.43526 (A-MSE: 0.39729) avg lploss: 0.00000
*** Best Val Loss: 0.39064 	 Best Test Loss: 0.43526 	 Best epoch 450
Validation loss decreased (0.411419 --> 0.390643).  Saving model ...
train epoch 451 avg loss: 0.19326 (A-MSE: 0.16892) avg lploss: 0.00000
train epoch 452 avg loss: 0.23345 (A-MSE: 0.20270) avg lploss: 0.00000
train epoch 453 avg loss: 0.46886 (A-MSE: 0.39753) avg lploss: 0.00000
train epoch 454 avg loss: 0.44646 (A-MSE: 0.38565) avg lploss: 0.00000
train epoch 455 avg loss: 0.31101 (A-MSE: 0.26943) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.46549 (A-MSE: 0.39250) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.48831 (A-MSE: 0.42713) avg lploss: 0.00000
*** Best Val Loss: 0.39064 	 Best Test Loss: 0.43526 	 Best epoch 450
EarlyStopping counter: 1 out of 50
train epoch 456 avg loss: 0.23845 (A-MSE: 0.20851) avg lploss: 0.00000
train epoch 457 avg loss: 0.23522 (A-MSE: 0.20600) avg lploss: 0.00000
train epoch 458 avg loss: 0.22109 (A-MSE: 0.19086) avg lploss: 0.00000
train epoch 459 avg loss: 0.27813 (A-MSE: 0.24315) avg lploss: 0.00000
train epoch 460 avg loss: 0.25868 (A-MSE: 0.22269) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.45228 (A-MSE: 0.39073) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.48598 (A-MSE: 0.43263) avg lploss: 0.00000
*** Best Val Loss: 0.39064 	 Best Test Loss: 0.43526 	 Best epoch 450
EarlyStopping counter: 2 out of 50
train epoch 461 avg loss: 0.25660 (A-MSE: 0.22341) avg lploss: 0.00000
train epoch 462 avg loss: 0.19590 (A-MSE: 0.17251) avg lploss: 0.00000
train epoch 463 avg loss: 0.19609 (A-MSE: 0.17032) avg lploss: 0.00000
train epoch 464 avg loss: 0.21464 (A-MSE: 0.18808) avg lploss: 0.00000
train epoch 465 avg loss: 0.19866 (A-MSE: 0.17181) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.39979 (A-MSE: 0.35003) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.46182 (A-MSE: 0.41571) avg lploss: 0.00000
*** Best Val Loss: 0.39064 	 Best Test Loss: 0.43526 	 Best epoch 450
EarlyStopping counter: 3 out of 50
train epoch 466 avg loss: 0.21616 (A-MSE: 0.18684) avg lploss: 0.00000
train epoch 467 avg loss: 0.20177 (A-MSE: 0.17488) avg lploss: 0.00000
train epoch 468 avg loss: 0.20102 (A-MSE: 0.17406) avg lploss: 0.00000
train epoch 469 avg loss: 0.21537 (A-MSE: 0.18912) avg lploss: 0.00000
train epoch 470 avg loss: 0.23387 (A-MSE: 0.20283) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.38532 (A-MSE: 0.33627) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.40427 (A-MSE: 0.36555) avg lploss: 0.00000
*** Best Val Loss: 0.38532 	 Best Test Loss: 0.40427 	 Best epoch 470
Validation loss decreased (0.390643 --> 0.385324).  Saving model ...
train epoch 471 avg loss: 0.18839 (A-MSE: 0.16453) avg lploss: 0.00000
train epoch 472 avg loss: 0.18997 (A-MSE: 0.16607) avg lploss: 0.00000
train epoch 473 avg loss: 0.20914 (A-MSE: 0.18286) avg lploss: 0.00000
train epoch 474 avg loss: 0.19930 (A-MSE: 0.17317) avg lploss: 0.00000
train epoch 475 avg loss: 0.20882 (A-MSE: 0.18175) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.44651 (A-MSE: 0.38970) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.46240 (A-MSE: 0.41440) avg lploss: 0.00000
*** Best Val Loss: 0.38532 	 Best Test Loss: 0.40427 	 Best epoch 470
EarlyStopping counter: 1 out of 50
train epoch 476 avg loss: 0.20488 (A-MSE: 0.17736) avg lploss: 0.00000
train epoch 477 avg loss: 0.23494 (A-MSE: 0.20349) avg lploss: 0.00000
train epoch 478 avg loss: 0.19707 (A-MSE: 0.17235) avg lploss: 0.00000
train epoch 479 avg loss: 0.18983 (A-MSE: 0.16558) avg lploss: 0.00000
train epoch 480 avg loss: 0.20329 (A-MSE: 0.17616) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.35445 (A-MSE: 0.30824) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.39153 (A-MSE: 0.35104) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
Validation loss decreased (0.385324 --> 0.354455).  Saving model ...
train epoch 481 avg loss: 0.18018 (A-MSE: 0.15696) avg lploss: 0.00000
train epoch 482 avg loss: 0.18539 (A-MSE: 0.16155) avg lploss: 0.00000
train epoch 483 avg loss: 0.20012 (A-MSE: 0.17464) avg lploss: 0.00000
train epoch 484 avg loss: 0.21106 (A-MSE: 0.18348) avg lploss: 0.00000
train epoch 485 avg loss: 0.18744 (A-MSE: 0.16256) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.42971 (A-MSE: 0.37087) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.45700 (A-MSE: 0.40414) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 1 out of 50
train epoch 486 avg loss: 0.19042 (A-MSE: 0.16602) avg lploss: 0.00000
train epoch 487 avg loss: 0.19010 (A-MSE: 0.16527) avg lploss: 0.00000
train epoch 488 avg loss: 0.18029 (A-MSE: 0.15645) avg lploss: 0.00000
train epoch 489 avg loss: 0.17496 (A-MSE: 0.15184) avg lploss: 0.00000
train epoch 490 avg loss: 0.17566 (A-MSE: 0.15227) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.36731 (A-MSE: 0.32630) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.43060 (A-MSE: 0.39265) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 2 out of 50
train epoch 491 avg loss: 0.17982 (A-MSE: 0.15833) avg lploss: 0.00000
train epoch 492 avg loss: 0.17712 (A-MSE: 0.15383) avg lploss: 0.00000
train epoch 493 avg loss: 0.18354 (A-MSE: 0.16031) avg lploss: 0.00000
train epoch 494 avg loss: 0.18380 (A-MSE: 0.16038) avg lploss: 0.00000
train epoch 495 avg loss: 0.19138 (A-MSE: 0.16773) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.40369 (A-MSE: 0.35662) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.42548 (A-MSE: 0.38530) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 3 out of 50
train epoch 496 avg loss: 0.16798 (A-MSE: 0.14604) avg lploss: 0.00000
train epoch 497 avg loss: 0.17144 (A-MSE: 0.15047) avg lploss: 0.00000
train epoch 498 avg loss: 0.19482 (A-MSE: 0.17042) avg lploss: 0.00000
train epoch 499 avg loss: 0.24174 (A-MSE: 0.21116) avg lploss: 0.00000
train epoch 500 avg loss: 0.24195 (A-MSE: 0.21086) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.38945 (A-MSE: 0.33949) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.41318 (A-MSE: 0.37311) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 4 out of 50
train epoch 501 avg loss: 0.21452 (A-MSE: 0.18681) avg lploss: 0.00000
train epoch 502 avg loss: 0.18904 (A-MSE: 0.16407) avg lploss: 0.00000
train epoch 503 avg loss: 0.19440 (A-MSE: 0.17051) avg lploss: 0.00000
train epoch 504 avg loss: 0.19310 (A-MSE: 0.16984) avg lploss: 0.00000
train epoch 505 avg loss: 0.19654 (A-MSE: 0.17304) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.37754 (A-MSE: 0.33296) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.44143 (A-MSE: 0.39556) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 5 out of 50
train epoch 506 avg loss: 0.21589 (A-MSE: 0.18727) avg lploss: 0.00000
train epoch 507 avg loss: 0.20020 (A-MSE: 0.17350) avg lploss: 0.00000
train epoch 508 avg loss: 0.21953 (A-MSE: 0.19152) avg lploss: 0.00000
train epoch 509 avg loss: 0.20875 (A-MSE: 0.18303) avg lploss: 0.00000
train epoch 510 avg loss: 0.18062 (A-MSE: 0.15605) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.43468 (A-MSE: 0.37501) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.45191 (A-MSE: 0.40152) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 6 out of 50
train epoch 511 avg loss: 0.18746 (A-MSE: 0.16278) avg lploss: 0.00000
train epoch 512 avg loss: 0.19359 (A-MSE: 0.16695) avg lploss: 0.00000
train epoch 513 avg loss: 0.17120 (A-MSE: 0.14957) avg lploss: 0.00000
train epoch 514 avg loss: 0.17473 (A-MSE: 0.15320) avg lploss: 0.00000
train epoch 515 avg loss: 0.18199 (A-MSE: 0.15790) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.44971 (A-MSE: 0.38806) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.44521 (A-MSE: 0.39411) avg lploss: 0.00000
*** Best Val Loss: 0.35445 	 Best Test Loss: 0.39153 	 Best epoch 480
EarlyStopping counter: 7 out of 50
train epoch 516 avg loss: 0.20764 (A-MSE: 0.18292) avg lploss: 0.00000
train epoch 517 avg loss: 0.21333 (A-MSE: 0.18478) avg lploss: 0.00000
train epoch 518 avg loss: 0.21902 (A-MSE: 0.18682) avg lploss: 0.00000
train epoch 519 avg loss: 0.18288 (A-MSE: 0.15951) avg lploss: 0.00000
train epoch 520 avg loss: 0.16444 (A-MSE: 0.14400) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.35233 (A-MSE: 0.30868) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.41273 (A-MSE: 0.37156) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
Validation loss decreased (0.354455 --> 0.352331).  Saving model ...
train epoch 521 avg loss: 0.17384 (A-MSE: 0.15190) avg lploss: 0.00000
train epoch 522 avg loss: 0.19249 (A-MSE: 0.16887) avg lploss: 0.00000
train epoch 523 avg loss: 0.17577 (A-MSE: 0.15289) avg lploss: 0.00000
train epoch 524 avg loss: 0.17736 (A-MSE: 0.15368) avg lploss: 0.00000
train epoch 525 avg loss: 0.17059 (A-MSE: 0.14953) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.41059 (A-MSE: 0.36446) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.44125 (A-MSE: 0.40249) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
EarlyStopping counter: 1 out of 50
train epoch 526 avg loss: 0.18613 (A-MSE: 0.16312) avg lploss: 0.00000
train epoch 527 avg loss: 0.21624 (A-MSE: 0.18933) avg lploss: 0.00000
train epoch 528 avg loss: 0.19704 (A-MSE: 0.17313) avg lploss: 0.00000
train epoch 529 avg loss: 0.15996 (A-MSE: 0.14013) avg lploss: 0.00000
train epoch 530 avg loss: 0.15603 (A-MSE: 0.13658) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.41082 (A-MSE: 0.36187) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.43507 (A-MSE: 0.38740) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
EarlyStopping counter: 2 out of 50
train epoch 531 avg loss: 0.16129 (A-MSE: 0.14139) avg lploss: 0.00000
train epoch 532 avg loss: 0.22121 (A-MSE: 0.19490) avg lploss: 0.00000
train epoch 533 avg loss: 0.18099 (A-MSE: 0.15873) avg lploss: 0.00000
train epoch 534 avg loss: 0.15995 (A-MSE: 0.13921) avg lploss: 0.00000
train epoch 535 avg loss: 0.16679 (A-MSE: 0.14428) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.35963 (A-MSE: 0.31812) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.40330 (A-MSE: 0.36427) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
EarlyStopping counter: 3 out of 50
train epoch 536 avg loss: 0.16430 (A-MSE: 0.14426) avg lploss: 0.00000
train epoch 537 avg loss: 0.15963 (A-MSE: 0.13974) avg lploss: 0.00000
train epoch 538 avg loss: 0.16689 (A-MSE: 0.14424) avg lploss: 0.00000
train epoch 539 avg loss: 0.17101 (A-MSE: 0.14850) avg lploss: 0.00000
train epoch 540 avg loss: 0.16612 (A-MSE: 0.14525) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.38568 (A-MSE: 0.34148) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.44887 (A-MSE: 0.40416) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
EarlyStopping counter: 4 out of 50
train epoch 541 avg loss: 0.18101 (A-MSE: 0.15789) avg lploss: 0.00000
train epoch 542 avg loss: 0.18126 (A-MSE: 0.15907) avg lploss: 0.00000
train epoch 543 avg loss: 0.19687 (A-MSE: 0.17104) avg lploss: 0.00000
train epoch 544 avg loss: 0.18505 (A-MSE: 0.16222) avg lploss: 0.00000
train epoch 545 avg loss: 0.18599 (A-MSE: 0.16201) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.40737 (A-MSE: 0.36150) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.44166 (A-MSE: 0.40059) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
EarlyStopping counter: 5 out of 50
train epoch 546 avg loss: 0.15906 (A-MSE: 0.13917) avg lploss: 0.00000
train epoch 547 avg loss: 0.14849 (A-MSE: 0.12930) avg lploss: 0.00000
train epoch 548 avg loss: 0.14909 (A-MSE: 0.13119) avg lploss: 0.00000
train epoch 549 avg loss: 0.17652 (A-MSE: 0.15504) avg lploss: 0.00000
train epoch 550 avg loss: 0.17101 (A-MSE: 0.14819) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.36956 (A-MSE: 0.33219) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.42728 (A-MSE: 0.38930) avg lploss: 0.00000
*** Best Val Loss: 0.35233 	 Best Test Loss: 0.41273 	 Best epoch 520
EarlyStopping counter: 6 out of 50
train epoch 551 avg loss: 0.15437 (A-MSE: 0.13542) avg lploss: 0.00000
train epoch 552 avg loss: 0.15728 (A-MSE: 0.13673) avg lploss: 0.00000
train epoch 553 avg loss: 0.16558 (A-MSE: 0.14441) avg lploss: 0.00000
train epoch 554 avg loss: 0.16097 (A-MSE: 0.13939) avg lploss: 0.00000
train epoch 555 avg loss: 0.18004 (A-MSE: 0.15741) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.34758 (A-MSE: 0.30898) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.40820 (A-MSE: 0.37314) avg lploss: 0.00000
*** Best Val Loss: 0.34758 	 Best Test Loss: 0.40820 	 Best epoch 555
Validation loss decreased (0.352331 --> 0.347578).  Saving model ...
train epoch 556 avg loss: 0.15776 (A-MSE: 0.13853) avg lploss: 0.00000
train epoch 557 avg loss: 0.15814 (A-MSE: 0.13815) avg lploss: 0.00000
train epoch 558 avg loss: 0.14645 (A-MSE: 0.12848) avg lploss: 0.00000
train epoch 559 avg loss: 0.22066 (A-MSE: 0.19095) avg lploss: 0.00000
train epoch 560 avg loss: 0.18791 (A-MSE: 0.16514) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.37017 (A-MSE: 0.33057) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.39793 (A-MSE: 0.36459) avg lploss: 0.00000
*** Best Val Loss: 0.34758 	 Best Test Loss: 0.40820 	 Best epoch 555
EarlyStopping counter: 1 out of 50
train epoch 561 avg loss: 0.17523 (A-MSE: 0.15530) avg lploss: 0.00000
train epoch 562 avg loss: 0.20357 (A-MSE: 0.17679) avg lploss: 0.00000
train epoch 563 avg loss: 0.19219 (A-MSE: 0.16765) avg lploss: 0.00000
train epoch 564 avg loss: 0.18407 (A-MSE: 0.16361) avg lploss: 0.00000
train epoch 565 avg loss: 0.18688 (A-MSE: 0.16407) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.44996 (A-MSE: 0.38970) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.46353 (A-MSE: 0.41190) avg lploss: 0.00000
*** Best Val Loss: 0.34758 	 Best Test Loss: 0.40820 	 Best epoch 555
EarlyStopping counter: 2 out of 50
train epoch 566 avg loss: 0.16219 (A-MSE: 0.14199) avg lploss: 0.00000
train epoch 567 avg loss: 0.14483 (A-MSE: 0.12704) avg lploss: 0.00000
train epoch 568 avg loss: 0.15574 (A-MSE: 0.13642) avg lploss: 0.00000
train epoch 569 avg loss: 0.15707 (A-MSE: 0.13766) avg lploss: 0.00000
train epoch 570 avg loss: 0.15713 (A-MSE: 0.13616) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.34595 (A-MSE: 0.31099) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.39163 (A-MSE: 0.35797) avg lploss: 0.00000
*** Best Val Loss: 0.34595 	 Best Test Loss: 0.39163 	 Best epoch 570
Validation loss decreased (0.347578 --> 0.345954).  Saving model ...
train epoch 571 avg loss: 0.14644 (A-MSE: 0.12934) avg lploss: 0.00000
train epoch 572 avg loss: 0.15839 (A-MSE: 0.13793) avg lploss: 0.00000
train epoch 573 avg loss: 0.15474 (A-MSE: 0.13516) avg lploss: 0.00000
train epoch 574 avg loss: 0.15329 (A-MSE: 0.13497) avg lploss: 0.00000
train epoch 575 avg loss: 0.14709 (A-MSE: 0.12761) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.39108 (A-MSE: 0.34463) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.42930 (A-MSE: 0.38890) avg lploss: 0.00000
*** Best Val Loss: 0.34595 	 Best Test Loss: 0.39163 	 Best epoch 570
EarlyStopping counter: 1 out of 50
train epoch 576 avg loss: 0.16018 (A-MSE: 0.13971) avg lploss: 0.00000
train epoch 577 avg loss: 0.16176 (A-MSE: 0.14076) avg lploss: 0.00000
train epoch 578 avg loss: 0.17670 (A-MSE: 0.15412) avg lploss: 0.00000
train epoch 579 avg loss: 0.17532 (A-MSE: 0.15388) avg lploss: 0.00000
train epoch 580 avg loss: 0.16283 (A-MSE: 0.14291) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.37279 (A-MSE: 0.33161) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.41519 (A-MSE: 0.37609) avg lploss: 0.00000
*** Best Val Loss: 0.34595 	 Best Test Loss: 0.39163 	 Best epoch 570
EarlyStopping counter: 2 out of 50
train epoch 581 avg loss: 0.16702 (A-MSE: 0.14558) avg lploss: 0.00000
train epoch 582 avg loss: 0.15553 (A-MSE: 0.13586) avg lploss: 0.00000
train epoch 583 avg loss: 0.14940 (A-MSE: 0.13126) avg lploss: 0.00000
train epoch 584 avg loss: 0.19320 (A-MSE: 0.17136) avg lploss: 0.00000
train epoch 585 avg loss: 0.24493 (A-MSE: 0.21322) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.41097 (A-MSE: 0.36371) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.45977 (A-MSE: 0.41203) avg lploss: 0.00000
*** Best Val Loss: 0.34595 	 Best Test Loss: 0.39163 	 Best epoch 570
EarlyStopping counter: 3 out of 50
train epoch 586 avg loss: 0.20144 (A-MSE: 0.17780) avg lploss: 0.00000
train epoch 587 avg loss: 0.18562 (A-MSE: 0.16367) avg lploss: 0.00000
train epoch 588 avg loss: 0.18045 (A-MSE: 0.15887) avg lploss: 0.00000
train epoch 589 avg loss: 0.17133 (A-MSE: 0.14791) avg lploss: 0.00000
train epoch 590 avg loss: 0.18477 (A-MSE: 0.16186) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.38558 (A-MSE: 0.34859) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.43834 (A-MSE: 0.40724) avg lploss: 0.00000
*** Best Val Loss: 0.34595 	 Best Test Loss: 0.39163 	 Best epoch 570
EarlyStopping counter: 4 out of 50
train epoch 591 avg loss: 0.16085 (A-MSE: 0.14165) avg lploss: 0.00000
train epoch 592 avg loss: 0.17695 (A-MSE: 0.15367) avg lploss: 0.00000
train epoch 593 avg loss: 0.16286 (A-MSE: 0.14209) avg lploss: 0.00000
train epoch 594 avg loss: 0.15394 (A-MSE: 0.13294) avg lploss: 0.00000
train epoch 595 avg loss: 0.14444 (A-MSE: 0.12747) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.32229 (A-MSE: 0.28463) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.36853 (A-MSE: 0.33339) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
Validation loss decreased (0.345954 --> 0.322288).  Saving model ...
train epoch 596 avg loss: 0.13978 (A-MSE: 0.12248) avg lploss: 0.00000
train epoch 597 avg loss: 0.13998 (A-MSE: 0.12321) avg lploss: 0.00000
train epoch 598 avg loss: 0.14182 (A-MSE: 0.12441) avg lploss: 0.00000
train epoch 599 avg loss: 0.15271 (A-MSE: 0.13406) avg lploss: 0.00000
train epoch 600 avg loss: 0.15549 (A-MSE: 0.13520) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.50542 (A-MSE: 0.43441) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.51531 (A-MSE: 0.45235) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 1 out of 50
train epoch 601 avg loss: 0.15941 (A-MSE: 0.13863) avg lploss: 0.00000
train epoch 602 avg loss: 0.16766 (A-MSE: 0.14770) avg lploss: 0.00000
train epoch 603 avg loss: 0.15792 (A-MSE: 0.13766) avg lploss: 0.00000
train epoch 604 avg loss: 0.14941 (A-MSE: 0.13135) avg lploss: 0.00000
train epoch 605 avg loss: 0.14313 (A-MSE: 0.12633) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.35056 (A-MSE: 0.31370) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.41132 (A-MSE: 0.37452) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 2 out of 50
train epoch 606 avg loss: 0.14492 (A-MSE: 0.12672) avg lploss: 0.00000
train epoch 607 avg loss: 0.15540 (A-MSE: 0.13481) avg lploss: 0.00000
train epoch 608 avg loss: 0.14804 (A-MSE: 0.12968) avg lploss: 0.00000
train epoch 609 avg loss: 0.14594 (A-MSE: 0.12845) avg lploss: 0.00000
train epoch 610 avg loss: 0.16212 (A-MSE: 0.14236) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.39377 (A-MSE: 0.34646) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.43381 (A-MSE: 0.38995) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 3 out of 50
train epoch 611 avg loss: 0.15712 (A-MSE: 0.13736) avg lploss: 0.00000
train epoch 612 avg loss: 0.15784 (A-MSE: 0.13798) avg lploss: 0.00000
train epoch 613 avg loss: 0.16498 (A-MSE: 0.14316) avg lploss: 0.00000
train epoch 614 avg loss: 0.14854 (A-MSE: 0.13026) avg lploss: 0.00000
train epoch 615 avg loss: 0.14428 (A-MSE: 0.12607) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.37236 (A-MSE: 0.32726) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.40203 (A-MSE: 0.36313) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 4 out of 50
train epoch 616 avg loss: 0.14450 (A-MSE: 0.12615) avg lploss: 0.00000
train epoch 617 avg loss: 0.12871 (A-MSE: 0.11328) avg lploss: 0.00000
train epoch 618 avg loss: 0.12468 (A-MSE: 0.10966) avg lploss: 0.00000
train epoch 619 avg loss: 0.16852 (A-MSE: 0.14810) avg lploss: 0.00000
train epoch 620 avg loss: 0.15511 (A-MSE: 0.13636) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.33122 (A-MSE: 0.29275) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.37061 (A-MSE: 0.33602) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 5 out of 50
train epoch 621 avg loss: 0.15552 (A-MSE: 0.13609) avg lploss: 0.00000
train epoch 622 avg loss: 0.14205 (A-MSE: 0.12489) avg lploss: 0.00000
train epoch 623 avg loss: 0.14658 (A-MSE: 0.12980) avg lploss: 0.00000
train epoch 624 avg loss: 0.16192 (A-MSE: 0.14130) avg lploss: 0.00000
train epoch 625 avg loss: 0.16204 (A-MSE: 0.14354) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.34152 (A-MSE: 0.30190) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.38618 (A-MSE: 0.35010) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 6 out of 50
train epoch 626 avg loss: 0.17270 (A-MSE: 0.15095) avg lploss: 0.00000
train epoch 627 avg loss: 0.15013 (A-MSE: 0.13190) avg lploss: 0.00000
train epoch 628 avg loss: 0.13767 (A-MSE: 0.12043) avg lploss: 0.00000
train epoch 629 avg loss: 0.13918 (A-MSE: 0.12159) avg lploss: 0.00000
train epoch 630 avg loss: 0.16137 (A-MSE: 0.14191) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.48048 (A-MSE: 0.41426) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.48399 (A-MSE: 0.42784) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 7 out of 50
train epoch 631 avg loss: 0.15791 (A-MSE: 0.13822) avg lploss: 0.00000
train epoch 632 avg loss: 0.15384 (A-MSE: 0.13521) avg lploss: 0.00000
train epoch 633 avg loss: 0.14360 (A-MSE: 0.12579) avg lploss: 0.00000
train epoch 634 avg loss: 0.12666 (A-MSE: 0.11131) avg lploss: 0.00000
train epoch 635 avg loss: 0.13461 (A-MSE: 0.11712) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.36898 (A-MSE: 0.32198) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.38928 (A-MSE: 0.35129) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 8 out of 50
train epoch 636 avg loss: 0.13700 (A-MSE: 0.12020) avg lploss: 0.00000
train epoch 637 avg loss: 0.14689 (A-MSE: 0.12795) avg lploss: 0.00000
train epoch 638 avg loss: 0.13117 (A-MSE: 0.11559) avg lploss: 0.00000
train epoch 639 avg loss: 0.12211 (A-MSE: 0.10712) avg lploss: 0.00000
train epoch 640 avg loss: 0.13233 (A-MSE: 0.11654) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.35159 (A-MSE: 0.31175) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.37645 (A-MSE: 0.34556) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 9 out of 50
train epoch 641 avg loss: 0.13584 (A-MSE: 0.11747) avg lploss: 0.00000
train epoch 642 avg loss: 0.13234 (A-MSE: 0.11577) avg lploss: 0.00000
train epoch 643 avg loss: 0.13286 (A-MSE: 0.11715) avg lploss: 0.00000
train epoch 644 avg loss: 0.12538 (A-MSE: 0.10932) avg lploss: 0.00000
train epoch 645 avg loss: 0.13607 (A-MSE: 0.11898) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.32593 (A-MSE: 0.28890) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.37242 (A-MSE: 0.33663) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 10 out of 50
train epoch 646 avg loss: 0.15681 (A-MSE: 0.13574) avg lploss: 0.00000
train epoch 647 avg loss: 0.14866 (A-MSE: 0.13129) avg lploss: 0.00000
train epoch 648 avg loss: 0.12208 (A-MSE: 0.10749) avg lploss: 0.00000
train epoch 649 avg loss: 0.14583 (A-MSE: 0.12849) avg lploss: 0.00000
train epoch 650 avg loss: 0.15097 (A-MSE: 0.13394) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.33110 (A-MSE: 0.29042) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.37416 (A-MSE: 0.34594) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 11 out of 50
train epoch 651 avg loss: 0.16996 (A-MSE: 0.14936) avg lploss: 0.00000
train epoch 652 avg loss: 0.16405 (A-MSE: 0.14291) avg lploss: 0.00000
train epoch 653 avg loss: 0.13544 (A-MSE: 0.11749) avg lploss: 0.00000
train epoch 654 avg loss: 0.16151 (A-MSE: 0.14256) avg lploss: 0.00000
train epoch 655 avg loss: 0.13757 (A-MSE: 0.12184) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.34178 (A-MSE: 0.30564) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.40256 (A-MSE: 0.36953) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 12 out of 50
train epoch 656 avg loss: 0.13836 (A-MSE: 0.11998) avg lploss: 0.00000
train epoch 657 avg loss: 0.11907 (A-MSE: 0.10533) avg lploss: 0.00000
train epoch 658 avg loss: 0.13300 (A-MSE: 0.11684) avg lploss: 0.00000
train epoch 659 avg loss: 0.13451 (A-MSE: 0.11992) avg lploss: 0.00000
train epoch 660 avg loss: 0.14249 (A-MSE: 0.12529) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.35316 (A-MSE: 0.31642) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.42087 (A-MSE: 0.38481) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 13 out of 50
train epoch 661 avg loss: 0.17595 (A-MSE: 0.15333) avg lploss: 0.00000
train epoch 662 avg loss: 0.17308 (A-MSE: 0.15198) avg lploss: 0.00000
train epoch 663 avg loss: 0.16776 (A-MSE: 0.14666) avg lploss: 0.00000
train epoch 664 avg loss: 0.16322 (A-MSE: 0.14203) avg lploss: 0.00000
train epoch 665 avg loss: 0.16681 (A-MSE: 0.14422) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.39030 (A-MSE: 0.34506) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.40402 (A-MSE: 0.36838) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 14 out of 50
train epoch 666 avg loss: 0.13013 (A-MSE: 0.11432) avg lploss: 0.00000
train epoch 667 avg loss: 0.12081 (A-MSE: 0.10585) avg lploss: 0.00000
train epoch 668 avg loss: 0.12132 (A-MSE: 0.10639) avg lploss: 0.00000
train epoch 669 avg loss: 0.11569 (A-MSE: 0.10159) avg lploss: 0.00000
train epoch 670 avg loss: 0.11954 (A-MSE: 0.10592) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.38081 (A-MSE: 0.33623) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.42092 (A-MSE: 0.38080) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 15 out of 50
train epoch 671 avg loss: 0.13013 (A-MSE: 0.11420) avg lploss: 0.00000
train epoch 672 avg loss: 0.13127 (A-MSE: 0.11472) avg lploss: 0.00000
train epoch 673 avg loss: 0.15327 (A-MSE: 0.13483) avg lploss: 0.00000
train epoch 674 avg loss: 0.15604 (A-MSE: 0.13617) avg lploss: 0.00000
train epoch 675 avg loss: 0.15659 (A-MSE: 0.13758) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.33392 (A-MSE: 0.29714) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.38063 (A-MSE: 0.34873) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 16 out of 50
train epoch 676 avg loss: 0.12198 (A-MSE: 0.10635) avg lploss: 0.00000
train epoch 677 avg loss: 0.11509 (A-MSE: 0.10114) avg lploss: 0.00000
train epoch 678 avg loss: 0.12991 (A-MSE: 0.11421) avg lploss: 0.00000
train epoch 679 avg loss: 0.14042 (A-MSE: 0.12389) avg lploss: 0.00000
train epoch 680 avg loss: 0.11591 (A-MSE: 0.10083) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.34893 (A-MSE: 0.30731) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.38734 (A-MSE: 0.35404) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 17 out of 50
train epoch 681 avg loss: 0.11875 (A-MSE: 0.10451) avg lploss: 0.00000
train epoch 682 avg loss: 0.12802 (A-MSE: 0.11224) avg lploss: 0.00000
train epoch 683 avg loss: 0.11928 (A-MSE: 0.10481) avg lploss: 0.00000
train epoch 684 avg loss: 0.12657 (A-MSE: 0.11219) avg lploss: 0.00000
train epoch 685 avg loss: 0.14034 (A-MSE: 0.12255) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.35171 (A-MSE: 0.30913) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.38091 (A-MSE: 0.34299) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 18 out of 50
train epoch 686 avg loss: 0.13287 (A-MSE: 0.11596) avg lploss: 0.00000
train epoch 687 avg loss: 0.12678 (A-MSE: 0.11091) avg lploss: 0.00000
train epoch 688 avg loss: 0.12479 (A-MSE: 0.10976) avg lploss: 0.00000
train epoch 689 avg loss: 0.13482 (A-MSE: 0.11875) avg lploss: 0.00000
train epoch 690 avg loss: 0.12761 (A-MSE: 0.11324) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.33928 (A-MSE: 0.30086) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.37810 (A-MSE: 0.34482) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 19 out of 50
train epoch 691 avg loss: 0.15514 (A-MSE: 0.13567) avg lploss: 0.00000
train epoch 692 avg loss: 0.14742 (A-MSE: 0.12962) avg lploss: 0.00000
train epoch 693 avg loss: 0.13946 (A-MSE: 0.12238) avg lploss: 0.00000
train epoch 694 avg loss: 0.13184 (A-MSE: 0.11568) avg lploss: 0.00000
train epoch 695 avg loss: 0.13853 (A-MSE: 0.12188) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.35328 (A-MSE: 0.31106) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.38130 (A-MSE: 0.34673) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 20 out of 50
train epoch 696 avg loss: 0.13836 (A-MSE: 0.12184) avg lploss: 0.00000
train epoch 697 avg loss: 0.12631 (A-MSE: 0.11096) avg lploss: 0.00000
train epoch 698 avg loss: 0.14236 (A-MSE: 0.12394) avg lploss: 0.00000
train epoch 699 avg loss: 0.15962 (A-MSE: 0.13861) avg lploss: 0.00000
train epoch 700 avg loss: 0.14246 (A-MSE: 0.12573) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.37544 (A-MSE: 0.33389) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.40735 (A-MSE: 0.37359) avg lploss: 0.00000
*** Best Val Loss: 0.32229 	 Best Test Loss: 0.36853 	 Best epoch 595
EarlyStopping counter: 21 out of 50
train epoch 701 avg loss: 0.12477 (A-MSE: 0.10941) avg lploss: 0.00000
train epoch 702 avg loss: 0.12041 (A-MSE: 0.10593) avg lploss: 0.00000
train epoch 703 avg loss: 0.11155 (A-MSE: 0.09794) avg lploss: 0.00000
train epoch 704 avg loss: 0.11104 (A-MSE: 0.09798) avg lploss: 0.00000
train epoch 705 avg loss: 0.11616 (A-MSE: 0.10133) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.30923 (A-MSE: 0.27377) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.35251 (A-MSE: 0.31999) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
Validation loss decreased (0.322288 --> 0.309228).  Saving model ...
train epoch 706 avg loss: 0.11902 (A-MSE: 0.10414) avg lploss: 0.00000
train epoch 707 avg loss: 0.13838 (A-MSE: 0.12178) avg lploss: 0.00000
train epoch 708 avg loss: 0.12673 (A-MSE: 0.11039) avg lploss: 0.00000
train epoch 709 avg loss: 0.11858 (A-MSE: 0.10462) avg lploss: 0.00000
train epoch 710 avg loss: 0.12694 (A-MSE: 0.11070) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.35716 (A-MSE: 0.31574) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.37856 (A-MSE: 0.34472) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 1 out of 50
train epoch 711 avg loss: 0.13109 (A-MSE: 0.11463) avg lploss: 0.00000
train epoch 712 avg loss: 0.15808 (A-MSE: 0.13841) avg lploss: 0.00000
train epoch 713 avg loss: 0.12116 (A-MSE: 0.10662) avg lploss: 0.00000
train epoch 714 avg loss: 0.15252 (A-MSE: 0.13271) avg lploss: 0.00000
train epoch 715 avg loss: 0.15537 (A-MSE: 0.13537) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.37909 (A-MSE: 0.33756) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.42970 (A-MSE: 0.39377) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 2 out of 50
train epoch 716 avg loss: 0.13914 (A-MSE: 0.12066) avg lploss: 0.00000
train epoch 717 avg loss: 0.13597 (A-MSE: 0.11903) avg lploss: 0.00000
train epoch 718 avg loss: 0.12803 (A-MSE: 0.11378) avg lploss: 0.00000
train epoch 719 avg loss: 0.13908 (A-MSE: 0.12180) avg lploss: 0.00000
train epoch 720 avg loss: 0.13432 (A-MSE: 0.11837) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.35058 (A-MSE: 0.31088) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.39699 (A-MSE: 0.36091) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 3 out of 50
train epoch 721 avg loss: 0.11944 (A-MSE: 0.10413) avg lploss: 0.00000
train epoch 722 avg loss: 0.11758 (A-MSE: 0.10399) avg lploss: 0.00000
train epoch 723 avg loss: 0.10861 (A-MSE: 0.09586) avg lploss: 0.00000
train epoch 724 avg loss: 0.10375 (A-MSE: 0.09035) avg lploss: 0.00000
train epoch 725 avg loss: 0.11314 (A-MSE: 0.09976) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.36851 (A-MSE: 0.32771) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.39302 (A-MSE: 0.35699) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 4 out of 50
train epoch 726 avg loss: 0.11305 (A-MSE: 0.09929) avg lploss: 0.00000
train epoch 727 avg loss: 0.11156 (A-MSE: 0.09698) avg lploss: 0.00000
train epoch 728 avg loss: 0.11900 (A-MSE: 0.10373) avg lploss: 0.00000
train epoch 729 avg loss: 0.12362 (A-MSE: 0.10934) avg lploss: 0.00000
train epoch 730 avg loss: 0.12051 (A-MSE: 0.10615) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.44705 (A-MSE: 0.39325) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.48369 (A-MSE: 0.43643) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 5 out of 50
train epoch 731 avg loss: 0.14050 (A-MSE: 0.12462) avg lploss: 0.00000
train epoch 732 avg loss: 0.12675 (A-MSE: 0.11070) avg lploss: 0.00000
train epoch 733 avg loss: 0.11789 (A-MSE: 0.10399) avg lploss: 0.00000
train epoch 734 avg loss: 0.11345 (A-MSE: 0.10025) avg lploss: 0.00000
train epoch 735 avg loss: 0.13021 (A-MSE: 0.11420) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.38944 (A-MSE: 0.33612) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.39913 (A-MSE: 0.35676) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 6 out of 50
train epoch 736 avg loss: 0.11848 (A-MSE: 0.10369) avg lploss: 0.00000
train epoch 737 avg loss: 0.11803 (A-MSE: 0.10223) avg lploss: 0.00000
train epoch 738 avg loss: 0.12493 (A-MSE: 0.10847) avg lploss: 0.00000
train epoch 739 avg loss: 0.11326 (A-MSE: 0.10028) avg lploss: 0.00000
train epoch 740 avg loss: 0.11246 (A-MSE: 0.09900) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.33909 (A-MSE: 0.30214) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.40067 (A-MSE: 0.36603) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 7 out of 50
train epoch 741 avg loss: 0.11207 (A-MSE: 0.09828) avg lploss: 0.00000
train epoch 742 avg loss: 0.11080 (A-MSE: 0.09729) avg lploss: 0.00000
train epoch 743 avg loss: 0.14822 (A-MSE: 0.13015) avg lploss: 0.00000
train epoch 744 avg loss: 0.12598 (A-MSE: 0.10963) avg lploss: 0.00000
train epoch 745 avg loss: 0.10466 (A-MSE: 0.09247) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.35831 (A-MSE: 0.31365) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.37350 (A-MSE: 0.33726) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 8 out of 50
train epoch 746 avg loss: 0.12532 (A-MSE: 0.10967) avg lploss: 0.00000
train epoch 747 avg loss: 0.12613 (A-MSE: 0.11072) avg lploss: 0.00000
train epoch 748 avg loss: 0.10970 (A-MSE: 0.09605) avg lploss: 0.00000
train epoch 749 avg loss: 0.11261 (A-MSE: 0.09814) avg lploss: 0.00000
train epoch 750 avg loss: 0.10635 (A-MSE: 0.09318) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.33326 (A-MSE: 0.29458) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.36108 (A-MSE: 0.33098) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 9 out of 50
train epoch 751 avg loss: 0.10067 (A-MSE: 0.08801) avg lploss: 0.00000
train epoch 752 avg loss: 0.10159 (A-MSE: 0.08923) avg lploss: 0.00000
train epoch 753 avg loss: 0.11452 (A-MSE: 0.10093) avg lploss: 0.00000
train epoch 754 avg loss: 0.11677 (A-MSE: 0.10164) avg lploss: 0.00000
train epoch 755 avg loss: 0.10486 (A-MSE: 0.09231) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.34439 (A-MSE: 0.30380) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.39941 (A-MSE: 0.35971) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 10 out of 50
train epoch 756 avg loss: 0.13823 (A-MSE: 0.12099) avg lploss: 0.00000
train epoch 757 avg loss: 0.16139 (A-MSE: 0.13991) avg lploss: 0.00000
train epoch 758 avg loss: 0.13310 (A-MSE: 0.11646) avg lploss: 0.00000
train epoch 759 avg loss: 0.12458 (A-MSE: 0.10856) avg lploss: 0.00000
train epoch 760 avg loss: 0.13422 (A-MSE: 0.11798) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.36638 (A-MSE: 0.31925) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.40797 (A-MSE: 0.36446) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 11 out of 50
train epoch 761 avg loss: 0.11460 (A-MSE: 0.10111) avg lploss: 0.00000
train epoch 762 avg loss: 0.11112 (A-MSE: 0.09742) avg lploss: 0.00000
train epoch 763 avg loss: 0.13060 (A-MSE: 0.11426) avg lploss: 0.00000
train epoch 764 avg loss: 0.11819 (A-MSE: 0.10356) avg lploss: 0.00000
train epoch 765 avg loss: 0.13607 (A-MSE: 0.12001) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.38026 (A-MSE: 0.32953) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.39250 (A-MSE: 0.35515) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 12 out of 50
train epoch 766 avg loss: 0.13644 (A-MSE: 0.11933) avg lploss: 0.00000
train epoch 767 avg loss: 0.11280 (A-MSE: 0.09886) avg lploss: 0.00000
train epoch 768 avg loss: 0.11590 (A-MSE: 0.10258) avg lploss: 0.00000
train epoch 769 avg loss: 0.11590 (A-MSE: 0.10175) avg lploss: 0.00000
train epoch 770 avg loss: 0.11147 (A-MSE: 0.09802) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.34621 (A-MSE: 0.30659) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.39676 (A-MSE: 0.36410) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 13 out of 50
train epoch 771 avg loss: 0.10446 (A-MSE: 0.09123) avg lploss: 0.00000
train epoch 772 avg loss: 0.11511 (A-MSE: 0.10097) avg lploss: 0.00000
train epoch 773 avg loss: 0.11079 (A-MSE: 0.09818) avg lploss: 0.00000
train epoch 774 avg loss: 0.11228 (A-MSE: 0.09832) avg lploss: 0.00000
train epoch 775 avg loss: 0.10626 (A-MSE: 0.09400) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.38203 (A-MSE: 0.33684) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.41385 (A-MSE: 0.37271) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 14 out of 50
train epoch 776 avg loss: 0.09777 (A-MSE: 0.08586) avg lploss: 0.00000
train epoch 777 avg loss: 0.12486 (A-MSE: 0.11027) avg lploss: 0.00000
train epoch 778 avg loss: 0.13512 (A-MSE: 0.11752) avg lploss: 0.00000
train epoch 779 avg loss: 0.11830 (A-MSE: 0.10359) avg lploss: 0.00000
train epoch 780 avg loss: 0.09687 (A-MSE: 0.08570) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.32403 (A-MSE: 0.28859) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.36829 (A-MSE: 0.33713) avg lploss: 0.00000
*** Best Val Loss: 0.30923 	 Best Test Loss: 0.35251 	 Best epoch 705
EarlyStopping counter: 15 out of 50
train epoch 781 avg loss: 0.09428 (A-MSE: 0.08277) avg lploss: 0.00000
train epoch 782 avg loss: 0.09110 (A-MSE: 0.08004) avg lploss: 0.00000
train epoch 783 avg loss: 0.09866 (A-MSE: 0.08703) avg lploss: 0.00000
train epoch 784 avg loss: 0.09698 (A-MSE: 0.08501) avg lploss: 0.00000
train epoch 785 avg loss: 0.10020 (A-MSE: 0.08863) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.30698 (A-MSE: 0.27099) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.34563 (A-MSE: 0.31679) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
Validation loss decreased (0.309228 --> 0.306977).  Saving model ...
train epoch 786 avg loss: 0.11275 (A-MSE: 0.09982) avg lploss: 0.00000
train epoch 787 avg loss: 0.12514 (A-MSE: 0.10937) avg lploss: 0.00000
train epoch 788 avg loss: 0.10547 (A-MSE: 0.09210) avg lploss: 0.00000
train epoch 789 avg loss: 0.10313 (A-MSE: 0.09118) avg lploss: 0.00000
train epoch 790 avg loss: 0.10638 (A-MSE: 0.09273) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.36647 (A-MSE: 0.32360) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.38092 (A-MSE: 0.34264) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 1 out of 50
train epoch 791 avg loss: 0.09837 (A-MSE: 0.08713) avg lploss: 0.00000
train epoch 792 avg loss: 0.09554 (A-MSE: 0.08365) avg lploss: 0.00000
train epoch 793 avg loss: 0.09271 (A-MSE: 0.08155) avg lploss: 0.00000
train epoch 794 avg loss: 0.10717 (A-MSE: 0.09426) avg lploss: 0.00000
train epoch 795 avg loss: 0.11973 (A-MSE: 0.10519) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.31332 (A-MSE: 0.27452) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.36300 (A-MSE: 0.32769) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 2 out of 50
train epoch 796 avg loss: 0.12803 (A-MSE: 0.11058) avg lploss: 0.00000
train epoch 797 avg loss: 0.11175 (A-MSE: 0.09759) avg lploss: 0.00000
train epoch 798 avg loss: 0.11333 (A-MSE: 0.09911) avg lploss: 0.00000
train epoch 799 avg loss: 0.10958 (A-MSE: 0.09590) avg lploss: 0.00000
train epoch 800 avg loss: 0.10091 (A-MSE: 0.08911) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.33055 (A-MSE: 0.29425) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.38500 (A-MSE: 0.34941) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 3 out of 50
train epoch 801 avg loss: 0.11570 (A-MSE: 0.10263) avg lploss: 0.00000
train epoch 802 avg loss: 0.10175 (A-MSE: 0.09043) avg lploss: 0.00000
train epoch 803 avg loss: 0.09325 (A-MSE: 0.08185) avg lploss: 0.00000
train epoch 804 avg loss: 0.10053 (A-MSE: 0.08810) avg lploss: 0.00000
train epoch 805 avg loss: 0.12130 (A-MSE: 0.10606) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.35350 (A-MSE: 0.31442) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.39549 (A-MSE: 0.35695) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 4 out of 50
train epoch 806 avg loss: 0.10900 (A-MSE: 0.09494) avg lploss: 0.00000
train epoch 807 avg loss: 0.10507 (A-MSE: 0.09235) avg lploss: 0.00000
train epoch 808 avg loss: 0.09899 (A-MSE: 0.08740) avg lploss: 0.00000
train epoch 809 avg loss: 0.10321 (A-MSE: 0.08909) avg lploss: 0.00000
train epoch 810 avg loss: 0.11234 (A-MSE: 0.09680) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.32846 (A-MSE: 0.29072) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.38366 (A-MSE: 0.35432) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 5 out of 50
train epoch 811 avg loss: 0.11030 (A-MSE: 0.09734) avg lploss: 0.00000
train epoch 812 avg loss: 0.11756 (A-MSE: 0.10369) avg lploss: 0.00000
train epoch 813 avg loss: 0.12705 (A-MSE: 0.11203) avg lploss: 0.00000
train epoch 814 avg loss: 0.11801 (A-MSE: 0.10436) avg lploss: 0.00000
train epoch 815 avg loss: 0.10749 (A-MSE: 0.09383) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.34406 (A-MSE: 0.30584) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.38100 (A-MSE: 0.34731) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 6 out of 50
train epoch 816 avg loss: 0.10044 (A-MSE: 0.08855) avg lploss: 0.00000
train epoch 817 avg loss: 0.09956 (A-MSE: 0.08849) avg lploss: 0.00000
train epoch 818 avg loss: 0.11443 (A-MSE: 0.09956) avg lploss: 0.00000
train epoch 819 avg loss: 0.11182 (A-MSE: 0.09811) avg lploss: 0.00000
train epoch 820 avg loss: 0.10513 (A-MSE: 0.09244) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.32174 (A-MSE: 0.28299) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.34601 (A-MSE: 0.31143) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 7 out of 50
train epoch 821 avg loss: 0.09740 (A-MSE: 0.08468) avg lploss: 0.00000
train epoch 822 avg loss: 0.12667 (A-MSE: 0.11143) avg lploss: 0.00000
train epoch 823 avg loss: 0.17664 (A-MSE: 0.15289) avg lploss: 0.00000
train epoch 824 avg loss: 0.17132 (A-MSE: 0.15182) avg lploss: 0.00000
train epoch 825 avg loss: 0.11565 (A-MSE: 0.10064) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.35421 (A-MSE: 0.30747) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.37180 (A-MSE: 0.33126) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 8 out of 50
train epoch 826 avg loss: 0.10412 (A-MSE: 0.09144) avg lploss: 0.00000
train epoch 827 avg loss: 0.10949 (A-MSE: 0.09628) avg lploss: 0.00000
train epoch 828 avg loss: 0.10009 (A-MSE: 0.08804) avg lploss: 0.00000
train epoch 829 avg loss: 0.10512 (A-MSE: 0.09207) avg lploss: 0.00000
train epoch 830 avg loss: 0.08829 (A-MSE: 0.07784) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.35948 (A-MSE: 0.31923) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.37510 (A-MSE: 0.34224) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 9 out of 50
train epoch 831 avg loss: 0.08654 (A-MSE: 0.07598) avg lploss: 0.00000
train epoch 832 avg loss: 0.09516 (A-MSE: 0.08282) avg lploss: 0.00000
train epoch 833 avg loss: 0.08659 (A-MSE: 0.07591) avg lploss: 0.00000
train epoch 834 avg loss: 0.08851 (A-MSE: 0.07927) avg lploss: 0.00000
train epoch 835 avg loss: 0.08834 (A-MSE: 0.07687) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.35055 (A-MSE: 0.30773) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.38168 (A-MSE: 0.34296) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 10 out of 50
train epoch 836 avg loss: 0.08822 (A-MSE: 0.07851) avg lploss: 0.00000
train epoch 837 avg loss: 0.09038 (A-MSE: 0.07923) avg lploss: 0.00000
train epoch 838 avg loss: 0.09122 (A-MSE: 0.07997) avg lploss: 0.00000
train epoch 839 avg loss: 0.08321 (A-MSE: 0.07295) avg lploss: 0.00000
train epoch 840 avg loss: 0.09244 (A-MSE: 0.08137) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.32354 (A-MSE: 0.28983) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.35833 (A-MSE: 0.32851) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 11 out of 50
train epoch 841 avg loss: 0.08686 (A-MSE: 0.07667) avg lploss: 0.00000
train epoch 842 avg loss: 0.09917 (A-MSE: 0.08682) avg lploss: 0.00000
train epoch 843 avg loss: 0.10225 (A-MSE: 0.09001) avg lploss: 0.00000
train epoch 844 avg loss: 0.10479 (A-MSE: 0.09202) avg lploss: 0.00000
train epoch 845 avg loss: 0.12330 (A-MSE: 0.10680) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.34981 (A-MSE: 0.30496) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.39643 (A-MSE: 0.35755) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 12 out of 50
train epoch 846 avg loss: 0.13913 (A-MSE: 0.12130) avg lploss: 0.00000
train epoch 847 avg loss: 0.13443 (A-MSE: 0.11830) avg lploss: 0.00000
train epoch 848 avg loss: 0.13281 (A-MSE: 0.11627) avg lploss: 0.00000
train epoch 849 avg loss: 0.10156 (A-MSE: 0.08840) avg lploss: 0.00000
train epoch 850 avg loss: 0.09696 (A-MSE: 0.08570) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.32895 (A-MSE: 0.28798) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.36055 (A-MSE: 0.32417) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 13 out of 50
train epoch 851 avg loss: 0.08816 (A-MSE: 0.07718) avg lploss: 0.00000
train epoch 852 avg loss: 0.08188 (A-MSE: 0.07189) avg lploss: 0.00000
train epoch 853 avg loss: 0.08388 (A-MSE: 0.07300) avg lploss: 0.00000
train epoch 854 avg loss: 0.08654 (A-MSE: 0.07614) avg lploss: 0.00000
train epoch 855 avg loss: 0.08077 (A-MSE: 0.07113) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.34202 (A-MSE: 0.30327) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.37940 (A-MSE: 0.34608) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 14 out of 50
train epoch 856 avg loss: 0.08427 (A-MSE: 0.07421) avg lploss: 0.00000
train epoch 857 avg loss: 0.10019 (A-MSE: 0.08713) avg lploss: 0.00000
train epoch 858 avg loss: 0.09667 (A-MSE: 0.08475) avg lploss: 0.00000
train epoch 859 avg loss: 0.10699 (A-MSE: 0.09353) avg lploss: 0.00000
train epoch 860 avg loss: 0.10460 (A-MSE: 0.09248) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.40863 (A-MSE: 0.35466) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.44589 (A-MSE: 0.39579) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 15 out of 50
train epoch 861 avg loss: 0.09894 (A-MSE: 0.08683) avg lploss: 0.00000
train epoch 862 avg loss: 0.09572 (A-MSE: 0.08492) avg lploss: 0.00000
train epoch 863 avg loss: 0.11052 (A-MSE: 0.09639) avg lploss: 0.00000
train epoch 864 avg loss: 0.10558 (A-MSE: 0.09287) avg lploss: 0.00000
train epoch 865 avg loss: 0.09572 (A-MSE: 0.08375) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.34501 (A-MSE: 0.30492) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.38243 (A-MSE: 0.34434) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 16 out of 50
train epoch 866 avg loss: 0.09535 (A-MSE: 0.08478) avg lploss: 0.00000
train epoch 867 avg loss: 0.08727 (A-MSE: 0.07639) avg lploss: 0.00000
train epoch 868 avg loss: 0.08717 (A-MSE: 0.07594) avg lploss: 0.00000
train epoch 869 avg loss: 0.08663 (A-MSE: 0.07586) avg lploss: 0.00000
train epoch 870 avg loss: 0.08451 (A-MSE: 0.07443) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.37539 (A-MSE: 0.32961) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.41502 (A-MSE: 0.37544) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 17 out of 50
train epoch 871 avg loss: 0.09405 (A-MSE: 0.08176) avg lploss: 0.00000
train epoch 872 avg loss: 0.07991 (A-MSE: 0.07010) avg lploss: 0.00000
train epoch 873 avg loss: 0.09017 (A-MSE: 0.07951) avg lploss: 0.00000
train epoch 874 avg loss: 0.09998 (A-MSE: 0.08747) avg lploss: 0.00000
train epoch 875 avg loss: 0.08664 (A-MSE: 0.07684) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.33912 (A-MSE: 0.30119) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.37704 (A-MSE: 0.34294) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 18 out of 50
train epoch 876 avg loss: 0.07884 (A-MSE: 0.06958) avg lploss: 0.00000
train epoch 877 avg loss: 0.11290 (A-MSE: 0.09788) avg lploss: 0.00000
train epoch 878 avg loss: 0.11242 (A-MSE: 0.09955) avg lploss: 0.00000
train epoch 879 avg loss: 0.10455 (A-MSE: 0.09205) avg lploss: 0.00000
train epoch 880 avg loss: 0.08676 (A-MSE: 0.07638) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.31707 (A-MSE: 0.28279) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.39132 (A-MSE: 0.35604) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 19 out of 50
train epoch 881 avg loss: 0.08831 (A-MSE: 0.07732) avg lploss: 0.00000
train epoch 882 avg loss: 0.09123 (A-MSE: 0.08015) avg lploss: 0.00000
train epoch 883 avg loss: 0.09809 (A-MSE: 0.08762) avg lploss: 0.00000
train epoch 884 avg loss: 0.09749 (A-MSE: 0.08605) avg lploss: 0.00000
train epoch 885 avg loss: 0.09210 (A-MSE: 0.08053) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.35710 (A-MSE: 0.31851) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.39804 (A-MSE: 0.36049) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 20 out of 50
train epoch 886 avg loss: 0.08525 (A-MSE: 0.07506) avg lploss: 0.00000
train epoch 887 avg loss: 0.08091 (A-MSE: 0.07131) avg lploss: 0.00000
train epoch 888 avg loss: 0.09046 (A-MSE: 0.07968) avg lploss: 0.00000
train epoch 889 avg loss: 0.10008 (A-MSE: 0.08726) avg lploss: 0.00000
train epoch 890 avg loss: 0.09165 (A-MSE: 0.08066) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.32641 (A-MSE: 0.28999) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.37130 (A-MSE: 0.33457) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 21 out of 50
train epoch 891 avg loss: 0.09572 (A-MSE: 0.08344) avg lploss: 0.00000
train epoch 892 avg loss: 0.09555 (A-MSE: 0.08360) avg lploss: 0.00000
train epoch 893 avg loss: 0.08997 (A-MSE: 0.07921) avg lploss: 0.00000
train epoch 894 avg loss: 0.07501 (A-MSE: 0.06625) avg lploss: 0.00000
train epoch 895 avg loss: 0.08111 (A-MSE: 0.07144) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.35891 (A-MSE: 0.31367) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.36761 (A-MSE: 0.32970) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 22 out of 50
train epoch 896 avg loss: 0.10727 (A-MSE: 0.09406) avg lploss: 0.00000
train epoch 897 avg loss: 0.09820 (A-MSE: 0.08634) avg lploss: 0.00000
train epoch 898 avg loss: 0.08889 (A-MSE: 0.07828) avg lploss: 0.00000
train epoch 899 avg loss: 0.09819 (A-MSE: 0.08670) avg lploss: 0.00000
train epoch 900 avg loss: 0.12061 (A-MSE: 0.10421) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.35903 (A-MSE: 0.31551) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.38676 (A-MSE: 0.34671) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 23 out of 50
train epoch 901 avg loss: 0.10608 (A-MSE: 0.09375) avg lploss: 0.00000
train epoch 902 avg loss: 0.08751 (A-MSE: 0.07726) avg lploss: 0.00000
train epoch 903 avg loss: 0.08339 (A-MSE: 0.07397) avg lploss: 0.00000
train epoch 904 avg loss: 0.10734 (A-MSE: 0.09523) avg lploss: 0.00000
train epoch 905 avg loss: 0.10126 (A-MSE: 0.09039) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.32238 (A-MSE: 0.27914) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.35402 (A-MSE: 0.31590) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 24 out of 50
train epoch 906 avg loss: 0.10944 (A-MSE: 0.09532) avg lploss: 0.00000
train epoch 907 avg loss: 0.11841 (A-MSE: 0.10313) avg lploss: 0.00000
train epoch 908 avg loss: 0.12081 (A-MSE: 0.10672) avg lploss: 0.00000
train epoch 909 avg loss: 0.10712 (A-MSE: 0.09398) avg lploss: 0.00000
train epoch 910 avg loss: 0.09333 (A-MSE: 0.08154) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.33924 (A-MSE: 0.29737) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.35790 (A-MSE: 0.32153) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 25 out of 50
train epoch 911 avg loss: 0.08452 (A-MSE: 0.07411) avg lploss: 0.00000
train epoch 912 avg loss: 0.08389 (A-MSE: 0.07369) avg lploss: 0.00000
train epoch 913 avg loss: 0.08554 (A-MSE: 0.07545) avg lploss: 0.00000
train epoch 914 avg loss: 0.09772 (A-MSE: 0.08529) avg lploss: 0.00000
train epoch 915 avg loss: 0.10534 (A-MSE: 0.09175) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.34016 (A-MSE: 0.30242) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.37230 (A-MSE: 0.33719) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 26 out of 50
train epoch 916 avg loss: 0.08064 (A-MSE: 0.07117) avg lploss: 0.00000
train epoch 917 avg loss: 0.08977 (A-MSE: 0.07924) avg lploss: 0.00000
train epoch 918 avg loss: 0.09381 (A-MSE: 0.08161) avg lploss: 0.00000
train epoch 919 avg loss: 0.09431 (A-MSE: 0.08293) avg lploss: 0.00000
train epoch 920 avg loss: 0.10122 (A-MSE: 0.08943) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.42439 (A-MSE: 0.37856) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.41028 (A-MSE: 0.36975) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 27 out of 50
train epoch 921 avg loss: 0.10091 (A-MSE: 0.08688) avg lploss: 0.00000
train epoch 922 avg loss: 0.08741 (A-MSE: 0.07719) avg lploss: 0.00000
train epoch 923 avg loss: 0.07740 (A-MSE: 0.06818) avg lploss: 0.00000
train epoch 924 avg loss: 0.09658 (A-MSE: 0.08635) avg lploss: 0.00000
train epoch 925 avg loss: 0.08793 (A-MSE: 0.07780) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.34337 (A-MSE: 0.29743) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.37529 (A-MSE: 0.33637) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 28 out of 50
train epoch 926 avg loss: 0.07663 (A-MSE: 0.06755) avg lploss: 0.00000
train epoch 927 avg loss: 0.06834 (A-MSE: 0.05951) avg lploss: 0.00000
train epoch 928 avg loss: 0.06471 (A-MSE: 0.05650) avg lploss: 0.00000
train epoch 929 avg loss: 0.07659 (A-MSE: 0.06716) avg lploss: 0.00000
train epoch 930 avg loss: 0.08673 (A-MSE: 0.07656) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.32981 (A-MSE: 0.29369) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.39482 (A-MSE: 0.35935) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 29 out of 50
train epoch 931 avg loss: 0.10907 (A-MSE: 0.09568) avg lploss: 0.00000
train epoch 932 avg loss: 0.10190 (A-MSE: 0.08950) avg lploss: 0.00000
train epoch 933 avg loss: 0.09276 (A-MSE: 0.08025) avg lploss: 0.00000
train epoch 934 avg loss: 0.08998 (A-MSE: 0.07891) avg lploss: 0.00000
train epoch 935 avg loss: 0.08330 (A-MSE: 0.07289) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.35622 (A-MSE: 0.31863) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.39122 (A-MSE: 0.35712) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 30 out of 50
train epoch 936 avg loss: 0.08880 (A-MSE: 0.07880) avg lploss: 0.00000
train epoch 937 avg loss: 0.08393 (A-MSE: 0.07434) avg lploss: 0.00000
train epoch 938 avg loss: 0.09340 (A-MSE: 0.08250) avg lploss: 0.00000
train epoch 939 avg loss: 0.08749 (A-MSE: 0.07752) avg lploss: 0.00000
train epoch 940 avg loss: 0.08732 (A-MSE: 0.07668) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.44041 (A-MSE: 0.38197) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.47894 (A-MSE: 0.42185) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 31 out of 50
train epoch 941 avg loss: 0.09239 (A-MSE: 0.08074) avg lploss: 0.00000
train epoch 942 avg loss: 0.08329 (A-MSE: 0.07427) avg lploss: 0.00000
train epoch 943 avg loss: 0.08887 (A-MSE: 0.07826) avg lploss: 0.00000
train epoch 944 avg loss: 0.08795 (A-MSE: 0.07726) avg lploss: 0.00000
train epoch 945 avg loss: 0.07399 (A-MSE: 0.06568) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.34642 (A-MSE: 0.30782) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.36413 (A-MSE: 0.32890) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 32 out of 50
train epoch 946 avg loss: 0.07864 (A-MSE: 0.06953) avg lploss: 0.00000
train epoch 947 avg loss: 0.07036 (A-MSE: 0.06182) avg lploss: 0.00000
train epoch 948 avg loss: 0.07174 (A-MSE: 0.06246) avg lploss: 0.00000
train epoch 949 avg loss: 0.07288 (A-MSE: 0.06407) avg lploss: 0.00000
train epoch 950 avg loss: 0.06905 (A-MSE: 0.06103) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.32197 (A-MSE: 0.28855) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.37300 (A-MSE: 0.33860) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 33 out of 50
train epoch 951 avg loss: 0.06931 (A-MSE: 0.06085) avg lploss: 0.00000
train epoch 952 avg loss: 0.06454 (A-MSE: 0.05717) avg lploss: 0.00000
train epoch 953 avg loss: 0.06374 (A-MSE: 0.05607) avg lploss: 0.00000
train epoch 954 avg loss: 0.06246 (A-MSE: 0.05471) avg lploss: 0.00000
train epoch 955 avg loss: 0.07780 (A-MSE: 0.06856) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.36485 (A-MSE: 0.31739) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.37191 (A-MSE: 0.33343) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 34 out of 50
train epoch 956 avg loss: 0.08130 (A-MSE: 0.07218) avg lploss: 0.00000
train epoch 957 avg loss: 0.08404 (A-MSE: 0.07304) avg lploss: 0.00000
train epoch 958 avg loss: 0.08968 (A-MSE: 0.07932) avg lploss: 0.00000
train epoch 959 avg loss: 0.09322 (A-MSE: 0.08118) avg lploss: 0.00000
train epoch 960 avg loss: 0.10548 (A-MSE: 0.09231) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.33012 (A-MSE: 0.29416) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.38428 (A-MSE: 0.34564) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 35 out of 50
train epoch 961 avg loss: 0.07986 (A-MSE: 0.07000) avg lploss: 0.00000
train epoch 962 avg loss: 0.07419 (A-MSE: 0.06609) avg lploss: 0.00000
train epoch 963 avg loss: 0.08366 (A-MSE: 0.07462) avg lploss: 0.00000
train epoch 964 avg loss: 0.09126 (A-MSE: 0.08043) avg lploss: 0.00000
train epoch 965 avg loss: 0.08192 (A-MSE: 0.07200) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.32968 (A-MSE: 0.29312) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.35761 (A-MSE: 0.32362) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 36 out of 50
train epoch 966 avg loss: 0.07167 (A-MSE: 0.06342) avg lploss: 0.00000
train epoch 967 avg loss: 0.07238 (A-MSE: 0.06419) avg lploss: 0.00000
train epoch 968 avg loss: 0.07858 (A-MSE: 0.06924) avg lploss: 0.00000
train epoch 969 avg loss: 0.07716 (A-MSE: 0.06822) avg lploss: 0.00000
train epoch 970 avg loss: 0.09857 (A-MSE: 0.08621) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.33779 (A-MSE: 0.29890) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.36052 (A-MSE: 0.32676) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 37 out of 50
train epoch 971 avg loss: 0.09607 (A-MSE: 0.08515) avg lploss: 0.00000
train epoch 972 avg loss: 0.08121 (A-MSE: 0.07148) avg lploss: 0.00000
train epoch 973 avg loss: 0.07273 (A-MSE: 0.06334) avg lploss: 0.00000
train epoch 974 avg loss: 0.07079 (A-MSE: 0.06191) avg lploss: 0.00000
train epoch 975 avg loss: 0.06923 (A-MSE: 0.06103) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.31305 (A-MSE: 0.27410) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.35441 (A-MSE: 0.31984) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 38 out of 50
train epoch 976 avg loss: 0.08017 (A-MSE: 0.07040) avg lploss: 0.00000
train epoch 977 avg loss: 0.07908 (A-MSE: 0.06923) avg lploss: 0.00000
train epoch 978 avg loss: 0.08076 (A-MSE: 0.07145) avg lploss: 0.00000
train epoch 979 avg loss: 0.10343 (A-MSE: 0.09090) avg lploss: 0.00000
train epoch 980 avg loss: 0.08862 (A-MSE: 0.07816) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.32618 (A-MSE: 0.28864) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.38521 (A-MSE: 0.34797) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 39 out of 50
train epoch 981 avg loss: 0.07575 (A-MSE: 0.06650) avg lploss: 0.00000
train epoch 982 avg loss: 0.07499 (A-MSE: 0.06611) avg lploss: 0.00000
train epoch 983 avg loss: 0.08045 (A-MSE: 0.07142) avg lploss: 0.00000
train epoch 984 avg loss: 0.08580 (A-MSE: 0.07511) avg lploss: 0.00000
train epoch 985 avg loss: 0.07938 (A-MSE: 0.07017) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.38597 (A-MSE: 0.34299) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.43880 (A-MSE: 0.39661) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 40 out of 50
train epoch 986 avg loss: 0.10341 (A-MSE: 0.09060) avg lploss: 0.00000
train epoch 987 avg loss: 0.10829 (A-MSE: 0.09489) avg lploss: 0.00000
train epoch 988 avg loss: 0.08333 (A-MSE: 0.07397) avg lploss: 0.00000
train epoch 989 avg loss: 0.08528 (A-MSE: 0.07489) avg lploss: 0.00000
train epoch 990 avg loss: 0.07322 (A-MSE: 0.06559) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.35560 (A-MSE: 0.31377) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.38669 (A-MSE: 0.34964) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 41 out of 50
train epoch 991 avg loss: 0.06378 (A-MSE: 0.05645) avg lploss: 0.00000
train epoch 992 avg loss: 0.06462 (A-MSE: 0.05698) avg lploss: 0.00000
train epoch 993 avg loss: 0.06195 (A-MSE: 0.05435) avg lploss: 0.00000
train epoch 994 avg loss: 0.06221 (A-MSE: 0.05495) avg lploss: 0.00000
train epoch 995 avg loss: 0.06942 (A-MSE: 0.06118) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.33157 (A-MSE: 0.29116) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.36350 (A-MSE: 0.32867) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 42 out of 50
train epoch 996 avg loss: 0.07037 (A-MSE: 0.06296) avg lploss: 0.00000
train epoch 997 avg loss: 0.06802 (A-MSE: 0.06010) avg lploss: 0.00000
train epoch 998 avg loss: 0.06386 (A-MSE: 0.05632) avg lploss: 0.00000
train epoch 999 avg loss: 0.06442 (A-MSE: 0.05748) avg lploss: 0.00000
train epoch 1000 avg loss: 0.07332 (A-MSE: 0.06496) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.42823 (A-MSE: 0.37922) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.45481 (A-MSE: 0.40882) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 43 out of 50
train epoch 1001 avg loss: 0.09167 (A-MSE: 0.08031) avg lploss: 0.00000
train epoch 1002 avg loss: 0.07732 (A-MSE: 0.06854) avg lploss: 0.00000
train epoch 1003 avg loss: 0.07333 (A-MSE: 0.06406) avg lploss: 0.00000
train epoch 1004 avg loss: 0.07697 (A-MSE: 0.06727) avg lploss: 0.00000
train epoch 1005 avg loss: 0.07887 (A-MSE: 0.06890) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.33356 (A-MSE: 0.29734) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.35927 (A-MSE: 0.32743) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 44 out of 50
train epoch 1006 avg loss: 0.06814 (A-MSE: 0.06072) avg lploss: 0.00000
train epoch 1007 avg loss: 0.07570 (A-MSE: 0.06747) avg lploss: 0.00000
train epoch 1008 avg loss: 0.07250 (A-MSE: 0.06315) avg lploss: 0.00000
train epoch 1009 avg loss: 0.07956 (A-MSE: 0.07045) avg lploss: 0.00000
train epoch 1010 avg loss: 0.09699 (A-MSE: 0.08473) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.36115 (A-MSE: 0.31178) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.37157 (A-MSE: 0.33080) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 45 out of 50
train epoch 1011 avg loss: 0.07260 (A-MSE: 0.06398) avg lploss: 0.00000
train epoch 1012 avg loss: 0.06510 (A-MSE: 0.05679) avg lploss: 0.00000
train epoch 1013 avg loss: 0.06847 (A-MSE: 0.06024) avg lploss: 0.00000
train epoch 1014 avg loss: 0.06828 (A-MSE: 0.06035) avg lploss: 0.00000
train epoch 1015 avg loss: 0.07214 (A-MSE: 0.06375) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.31305 (A-MSE: 0.27910) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.37844 (A-MSE: 0.34183) avg lploss: 0.00000
*** Best Val Loss: 0.30698 	 Best Test Loss: 0.34563 	 Best epoch 785
EarlyStopping counter: 46 out of 50
train epoch 1016 avg loss: 0.07233 (A-MSE: 0.06290) avg lploss: 0.00000
train epoch 1017 avg loss: 0.06513 (A-MSE: 0.05680) avg lploss: 0.00000
train epoch 1018 avg loss: 0.06013 (A-MSE: 0.05312) avg lploss: 0.00000
train epoch 1019 avg loss: 0.05710 (A-MSE: 0.05013) avg lploss: 0.00000
train epoch 1020 avg loss: 0.05781 (A-MSE: 0.05128) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.29488 (A-MSE: 0.26587) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.34380 (A-MSE: 0.31482) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
Validation loss decreased (0.306977 --> 0.294876).  Saving model ...
train epoch 1021 avg loss: 0.07296 (A-MSE: 0.06435) avg lploss: 0.00000
train epoch 1022 avg loss: 0.07701 (A-MSE: 0.06787) avg lploss: 0.00000
train epoch 1023 avg loss: 0.06572 (A-MSE: 0.05868) avg lploss: 0.00000
train epoch 1024 avg loss: 0.05931 (A-MSE: 0.05242) avg lploss: 0.00000
train epoch 1025 avg loss: 0.05768 (A-MSE: 0.05051) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.30877 (A-MSE: 0.27598) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.35215 (A-MSE: 0.32076) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 1 out of 50
train epoch 1026 avg loss: 0.05419 (A-MSE: 0.04794) avg lploss: 0.00000
train epoch 1027 avg loss: 0.06101 (A-MSE: 0.05427) avg lploss: 0.00000
train epoch 1028 avg loss: 0.06380 (A-MSE: 0.05557) avg lploss: 0.00000
train epoch 1029 avg loss: 0.09293 (A-MSE: 0.08155) avg lploss: 0.00000
train epoch 1030 avg loss: 0.08463 (A-MSE: 0.07457) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.34339 (A-MSE: 0.30490) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.38543 (A-MSE: 0.35083) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 2 out of 50
train epoch 1031 avg loss: 0.07937 (A-MSE: 0.06913) avg lploss: 0.00000
train epoch 1032 avg loss: 0.07154 (A-MSE: 0.06403) avg lploss: 0.00000
train epoch 1033 avg loss: 0.07061 (A-MSE: 0.06240) avg lploss: 0.00000
train epoch 1034 avg loss: 0.06916 (A-MSE: 0.06245) avg lploss: 0.00000
train epoch 1035 avg loss: 0.07173 (A-MSE: 0.06378) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.36715 (A-MSE: 0.32365) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.41802 (A-MSE: 0.37904) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 3 out of 50
train epoch 1036 avg loss: 0.06385 (A-MSE: 0.05598) avg lploss: 0.00000
train epoch 1037 avg loss: 0.06322 (A-MSE: 0.05555) avg lploss: 0.00000
train epoch 1038 avg loss: 0.08139 (A-MSE: 0.07108) avg lploss: 0.00000
train epoch 1039 avg loss: 0.08554 (A-MSE: 0.07515) avg lploss: 0.00000
train epoch 1040 avg loss: 0.08015 (A-MSE: 0.07043) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.40219 (A-MSE: 0.35516) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.41618 (A-MSE: 0.37697) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 4 out of 50
train epoch 1041 avg loss: 0.07997 (A-MSE: 0.07057) avg lploss: 0.00000
train epoch 1042 avg loss: 0.07006 (A-MSE: 0.06185) avg lploss: 0.00000
train epoch 1043 avg loss: 0.06878 (A-MSE: 0.06110) avg lploss: 0.00000
train epoch 1044 avg loss: 0.08486 (A-MSE: 0.07440) avg lploss: 0.00000
train epoch 1045 avg loss: 0.06983 (A-MSE: 0.06192) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.32619 (A-MSE: 0.28836) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.36244 (A-MSE: 0.32883) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 5 out of 50
train epoch 1046 avg loss: 0.06109 (A-MSE: 0.05384) avg lploss: 0.00000
train epoch 1047 avg loss: 0.06384 (A-MSE: 0.05617) avg lploss: 0.00000
train epoch 1048 avg loss: 0.06638 (A-MSE: 0.05833) avg lploss: 0.00000
train epoch 1049 avg loss: 0.07011 (A-MSE: 0.06207) avg lploss: 0.00000
train epoch 1050 avg loss: 0.06248 (A-MSE: 0.05463) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.33870 (A-MSE: 0.29596) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.37374 (A-MSE: 0.33468) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 6 out of 50
train epoch 1051 avg loss: 0.05232 (A-MSE: 0.04650) avg lploss: 0.00000
train epoch 1052 avg loss: 0.05171 (A-MSE: 0.04573) avg lploss: 0.00000
train epoch 1053 avg loss: 0.04946 (A-MSE: 0.04378) avg lploss: 0.00000
train epoch 1054 avg loss: 0.05171 (A-MSE: 0.04579) avg lploss: 0.00000
train epoch 1055 avg loss: 0.05764 (A-MSE: 0.05005) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.38551 (A-MSE: 0.34625) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.38170 (A-MSE: 0.34833) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 7 out of 50
train epoch 1056 avg loss: 0.05466 (A-MSE: 0.04864) avg lploss: 0.00000
train epoch 1057 avg loss: 0.05163 (A-MSE: 0.04581) avg lploss: 0.00000
train epoch 1058 avg loss: 0.05208 (A-MSE: 0.04582) avg lploss: 0.00000
train epoch 1059 avg loss: 0.05431 (A-MSE: 0.04839) avg lploss: 0.00000
train epoch 1060 avg loss: 0.05578 (A-MSE: 0.04886) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.33375 (A-MSE: 0.29667) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.36625 (A-MSE: 0.33074) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 8 out of 50
train epoch 1061 avg loss: 0.05996 (A-MSE: 0.05340) avg lploss: 0.00000
train epoch 1062 avg loss: 0.06840 (A-MSE: 0.06145) avg lploss: 0.00000
train epoch 1063 avg loss: 0.09129 (A-MSE: 0.08089) avg lploss: 0.00000
train epoch 1064 avg loss: 0.09052 (A-MSE: 0.07950) avg lploss: 0.00000
train epoch 1065 avg loss: 0.08123 (A-MSE: 0.07186) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.33937 (A-MSE: 0.30245) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.39697 (A-MSE: 0.36155) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 9 out of 50
train epoch 1066 avg loss: 0.07736 (A-MSE: 0.06765) avg lploss: 0.00000
train epoch 1067 avg loss: 0.07527 (A-MSE: 0.06722) avg lploss: 0.00000
train epoch 1068 avg loss: 0.08321 (A-MSE: 0.07300) avg lploss: 0.00000
train epoch 1069 avg loss: 0.08129 (A-MSE: 0.07237) avg lploss: 0.00000
train epoch 1070 avg loss: 0.08552 (A-MSE: 0.07380) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.32619 (A-MSE: 0.28309) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.39223 (A-MSE: 0.34914) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 10 out of 50
train epoch 1071 avg loss: 0.08175 (A-MSE: 0.07155) avg lploss: 0.00000
train epoch 1072 avg loss: 0.07372 (A-MSE: 0.06465) avg lploss: 0.00000
train epoch 1073 avg loss: 0.08126 (A-MSE: 0.07251) avg lploss: 0.00000
train epoch 1074 avg loss: 0.10554 (A-MSE: 0.09326) avg lploss: 0.00000
train epoch 1075 avg loss: 0.08286 (A-MSE: 0.07314) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.36605 (A-MSE: 0.32315) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.41514 (A-MSE: 0.37309) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 11 out of 50
train epoch 1076 avg loss: 0.09122 (A-MSE: 0.08137) avg lploss: 0.00000
train epoch 1077 avg loss: 0.08838 (A-MSE: 0.07845) avg lploss: 0.00000
train epoch 1078 avg loss: 0.08473 (A-MSE: 0.07379) avg lploss: 0.00000
train epoch 1079 avg loss: 0.08194 (A-MSE: 0.07308) avg lploss: 0.00000
train epoch 1080 avg loss: 0.07294 (A-MSE: 0.06482) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.32333 (A-MSE: 0.28666) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.33886 (A-MSE: 0.30767) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 12 out of 50
train epoch 1081 avg loss: 0.06190 (A-MSE: 0.05578) avg lploss: 0.00000
train epoch 1082 avg loss: 0.05552 (A-MSE: 0.04902) avg lploss: 0.00000
train epoch 1083 avg loss: 0.05728 (A-MSE: 0.05058) avg lploss: 0.00000
train epoch 1084 avg loss: 0.05362 (A-MSE: 0.04721) avg lploss: 0.00000
train epoch 1085 avg loss: 0.05390 (A-MSE: 0.04793) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.37678 (A-MSE: 0.33571) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.42075 (A-MSE: 0.38279) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 13 out of 50
train epoch 1086 avg loss: 0.06453 (A-MSE: 0.05782) avg lploss: 0.00000
train epoch 1087 avg loss: 0.06354 (A-MSE: 0.05627) avg lploss: 0.00000
train epoch 1088 avg loss: 0.06359 (A-MSE: 0.05585) avg lploss: 0.00000
train epoch 1089 avg loss: 0.05954 (A-MSE: 0.05203) avg lploss: 0.00000
train epoch 1090 avg loss: 0.05535 (A-MSE: 0.04867) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.32075 (A-MSE: 0.28909) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.36514 (A-MSE: 0.33154) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 14 out of 50
train epoch 1091 avg loss: 0.05601 (A-MSE: 0.04929) avg lploss: 0.00000
train epoch 1092 avg loss: 0.07054 (A-MSE: 0.06206) avg lploss: 0.00000
train epoch 1093 avg loss: 0.06669 (A-MSE: 0.05858) avg lploss: 0.00000
train epoch 1094 avg loss: 0.06335 (A-MSE: 0.05518) avg lploss: 0.00000
train epoch 1095 avg loss: 0.05443 (A-MSE: 0.04784) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.30337 (A-MSE: 0.27116) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.35009 (A-MSE: 0.31509) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 15 out of 50
train epoch 1096 avg loss: 0.05689 (A-MSE: 0.05059) avg lploss: 0.00000
train epoch 1097 avg loss: 0.06275 (A-MSE: 0.05540) avg lploss: 0.00000
train epoch 1098 avg loss: 0.07744 (A-MSE: 0.06873) avg lploss: 0.00000
train epoch 1099 avg loss: 0.07146 (A-MSE: 0.06295) avg lploss: 0.00000
train epoch 1100 avg loss: 0.06370 (A-MSE: 0.05607) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.33180 (A-MSE: 0.29424) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.36913 (A-MSE: 0.33690) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 16 out of 50
train epoch 1101 avg loss: 0.06768 (A-MSE: 0.05943) avg lploss: 0.00000
train epoch 1102 avg loss: 0.06098 (A-MSE: 0.05397) avg lploss: 0.00000
train epoch 1103 avg loss: 0.06108 (A-MSE: 0.05407) avg lploss: 0.00000
train epoch 1104 avg loss: 0.06331 (A-MSE: 0.05575) avg lploss: 0.00000
train epoch 1105 avg loss: 0.06933 (A-MSE: 0.06128) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.34853 (A-MSE: 0.30636) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.39631 (A-MSE: 0.36129) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 17 out of 50
train epoch 1106 avg loss: 0.05876 (A-MSE: 0.05117) avg lploss: 0.00000
train epoch 1107 avg loss: 0.05515 (A-MSE: 0.04897) avg lploss: 0.00000
train epoch 1108 avg loss: 0.06185 (A-MSE: 0.05461) avg lploss: 0.00000
train epoch 1109 avg loss: 0.06164 (A-MSE: 0.05408) avg lploss: 0.00000
train epoch 1110 avg loss: 0.05529 (A-MSE: 0.04846) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.39811 (A-MSE: 0.35137) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.40178 (A-MSE: 0.36243) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 18 out of 50
train epoch 1111 avg loss: 0.05581 (A-MSE: 0.04845) avg lploss: 0.00000
train epoch 1112 avg loss: 0.06303 (A-MSE: 0.05522) avg lploss: 0.00000
train epoch 1113 avg loss: 0.05440 (A-MSE: 0.04876) avg lploss: 0.00000
train epoch 1114 avg loss: 0.05675 (A-MSE: 0.04960) avg lploss: 0.00000
train epoch 1115 avg loss: 0.05434 (A-MSE: 0.04847) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.32194 (A-MSE: 0.28653) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.35722 (A-MSE: 0.32418) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 19 out of 50
train epoch 1116 avg loss: 0.04942 (A-MSE: 0.04391) avg lploss: 0.00000
train epoch 1117 avg loss: 0.05284 (A-MSE: 0.04642) avg lploss: 0.00000
train epoch 1118 avg loss: 0.04834 (A-MSE: 0.04291) avg lploss: 0.00000
train epoch 1119 avg loss: 0.05918 (A-MSE: 0.05128) avg lploss: 0.00000
train epoch 1120 avg loss: 0.06975 (A-MSE: 0.06136) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.32900 (A-MSE: 0.29576) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.38923 (A-MSE: 0.35367) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 20 out of 50
train epoch 1121 avg loss: 0.06814 (A-MSE: 0.06058) avg lploss: 0.00000
train epoch 1122 avg loss: 0.06612 (A-MSE: 0.05825) avg lploss: 0.00000
train epoch 1123 avg loss: 0.07028 (A-MSE: 0.06153) avg lploss: 0.00000
train epoch 1124 avg loss: 0.06072 (A-MSE: 0.05340) avg lploss: 0.00000
train epoch 1125 avg loss: 0.06882 (A-MSE: 0.06023) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.35908 (A-MSE: 0.31292) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.37238 (A-MSE: 0.33377) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 21 out of 50
train epoch 1126 avg loss: 0.07222 (A-MSE: 0.06362) avg lploss: 0.00000
train epoch 1127 avg loss: 0.06678 (A-MSE: 0.05930) avg lploss: 0.00000
train epoch 1128 avg loss: 0.06110 (A-MSE: 0.05395) avg lploss: 0.00000
train epoch 1129 avg loss: 0.06074 (A-MSE: 0.05365) avg lploss: 0.00000
train epoch 1130 avg loss: 0.05441 (A-MSE: 0.04761) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.31345 (A-MSE: 0.27871) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.35199 (A-MSE: 0.32068) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 22 out of 50
train epoch 1131 avg loss: 0.05053 (A-MSE: 0.04487) avg lploss: 0.00000
train epoch 1132 avg loss: 0.04870 (A-MSE: 0.04227) avg lploss: 0.00000
train epoch 1133 avg loss: 0.04519 (A-MSE: 0.03978) avg lploss: 0.00000
train epoch 1134 avg loss: 0.05050 (A-MSE: 0.04406) avg lploss: 0.00000
train epoch 1135 avg loss: 0.05083 (A-MSE: 0.04498) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.35614 (A-MSE: 0.31632) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.37170 (A-MSE: 0.33707) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 23 out of 50
train epoch 1136 avg loss: 0.06320 (A-MSE: 0.05521) avg lploss: 0.00000
train epoch 1137 avg loss: 0.06652 (A-MSE: 0.05893) avg lploss: 0.00000
train epoch 1138 avg loss: 0.06234 (A-MSE: 0.05478) avg lploss: 0.00000
train epoch 1139 avg loss: 0.05660 (A-MSE: 0.04995) avg lploss: 0.00000
train epoch 1140 avg loss: 0.04688 (A-MSE: 0.04162) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.31561 (A-MSE: 0.27993) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.35056 (A-MSE: 0.31665) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 24 out of 50
train epoch 1141 avg loss: 0.04821 (A-MSE: 0.04255) avg lploss: 0.00000
train epoch 1142 avg loss: 0.05239 (A-MSE: 0.04662) avg lploss: 0.00000
train epoch 1143 avg loss: 0.05407 (A-MSE: 0.04741) avg lploss: 0.00000
train epoch 1144 avg loss: 0.05036 (A-MSE: 0.04489) avg lploss: 0.00000
train epoch 1145 avg loss: 0.04916 (A-MSE: 0.04406) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.32777 (A-MSE: 0.28965) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.36292 (A-MSE: 0.32881) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 25 out of 50
train epoch 1146 avg loss: 0.05383 (A-MSE: 0.04682) avg lploss: 0.00000
train epoch 1147 avg loss: 0.07248 (A-MSE: 0.06338) avg lploss: 0.00000
train epoch 1148 avg loss: 0.05943 (A-MSE: 0.05233) avg lploss: 0.00000
train epoch 1149 avg loss: 0.07251 (A-MSE: 0.06338) avg lploss: 0.00000
train epoch 1150 avg loss: 0.07215 (A-MSE: 0.06409) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.39898 (A-MSE: 0.35007) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.41219 (A-MSE: 0.36928) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 26 out of 50
train epoch 1151 avg loss: 0.06853 (A-MSE: 0.06003) avg lploss: 0.00000
train epoch 1152 avg loss: 0.05728 (A-MSE: 0.05055) avg lploss: 0.00000
train epoch 1153 avg loss: 0.05694 (A-MSE: 0.05001) avg lploss: 0.00000
train epoch 1154 avg loss: 0.06607 (A-MSE: 0.05752) avg lploss: 0.00000
train epoch 1155 avg loss: 0.06970 (A-MSE: 0.06192) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.35338 (A-MSE: 0.31766) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.38383 (A-MSE: 0.34995) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 27 out of 50
train epoch 1156 avg loss: 0.06194 (A-MSE: 0.05445) avg lploss: 0.00000
train epoch 1157 avg loss: 0.07316 (A-MSE: 0.06407) avg lploss: 0.00000
train epoch 1158 avg loss: 0.06955 (A-MSE: 0.06139) avg lploss: 0.00000
train epoch 1159 avg loss: 0.06404 (A-MSE: 0.05583) avg lploss: 0.00000
train epoch 1160 avg loss: 0.06168 (A-MSE: 0.05456) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.34670 (A-MSE: 0.30768) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.39267 (A-MSE: 0.35407) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 28 out of 50
train epoch 1161 avg loss: 0.07474 (A-MSE: 0.06598) avg lploss: 0.00000
train epoch 1162 avg loss: 0.07871 (A-MSE: 0.06965) avg lploss: 0.00000
train epoch 1163 avg loss: 0.08670 (A-MSE: 0.07762) avg lploss: 0.00000
train epoch 1164 avg loss: 0.07064 (A-MSE: 0.06310) avg lploss: 0.00000
train epoch 1165 avg loss: 0.06215 (A-MSE: 0.05433) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.31386 (A-MSE: 0.28391) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.36211 (A-MSE: 0.32973) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 29 out of 50
train epoch 1166 avg loss: 0.04955 (A-MSE: 0.04363) avg lploss: 0.00000
train epoch 1167 avg loss: 0.05272 (A-MSE: 0.04651) avg lploss: 0.00000
train epoch 1168 avg loss: 0.05004 (A-MSE: 0.04462) avg lploss: 0.00000
train epoch 1169 avg loss: 0.05804 (A-MSE: 0.05115) avg lploss: 0.00000
train epoch 1170 avg loss: 0.05629 (A-MSE: 0.04848) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.31599 (A-MSE: 0.27955) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.34722 (A-MSE: 0.31084) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 30 out of 50
train epoch 1171 avg loss: 0.04968 (A-MSE: 0.04392) avg lploss: 0.00000
train epoch 1172 avg loss: 0.04951 (A-MSE: 0.04367) avg lploss: 0.00000
train epoch 1173 avg loss: 0.04837 (A-MSE: 0.04234) avg lploss: 0.00000
train epoch 1174 avg loss: 0.05360 (A-MSE: 0.04780) avg lploss: 0.00000
train epoch 1175 avg loss: 0.06137 (A-MSE: 0.05401) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.35668 (A-MSE: 0.31203) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.38153 (A-MSE: 0.34261) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 31 out of 50
train epoch 1176 avg loss: 0.05406 (A-MSE: 0.04762) avg lploss: 0.00000
train epoch 1177 avg loss: 0.06462 (A-MSE: 0.05655) avg lploss: 0.00000
train epoch 1178 avg loss: 0.05814 (A-MSE: 0.05108) avg lploss: 0.00000
train epoch 1179 avg loss: 0.04882 (A-MSE: 0.04368) avg lploss: 0.00000
train epoch 1180 avg loss: 0.05074 (A-MSE: 0.04523) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.37217 (A-MSE: 0.32947) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.39040 (A-MSE: 0.35137) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 32 out of 50
train epoch 1181 avg loss: 0.05343 (A-MSE: 0.04672) avg lploss: 0.00000
train epoch 1182 avg loss: 0.05066 (A-MSE: 0.04460) avg lploss: 0.00000
train epoch 1183 avg loss: 0.05674 (A-MSE: 0.05017) avg lploss: 0.00000
train epoch 1184 avg loss: 0.06504 (A-MSE: 0.05703) avg lploss: 0.00000
train epoch 1185 avg loss: 0.05743 (A-MSE: 0.05085) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.35100 (A-MSE: 0.30556) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.37018 (A-MSE: 0.33420) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 33 out of 50
train epoch 1186 avg loss: 0.06666 (A-MSE: 0.05893) avg lploss: 0.00000
train epoch 1187 avg loss: 0.06062 (A-MSE: 0.05335) avg lploss: 0.00000
train epoch 1188 avg loss: 0.05754 (A-MSE: 0.05076) avg lploss: 0.00000
train epoch 1189 avg loss: 0.06120 (A-MSE: 0.05354) avg lploss: 0.00000
train epoch 1190 avg loss: 0.05380 (A-MSE: 0.04717) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.31717 (A-MSE: 0.28141) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.35822 (A-MSE: 0.32447) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 34 out of 50
train epoch 1191 avg loss: 0.06037 (A-MSE: 0.05385) avg lploss: 0.00000
train epoch 1192 avg loss: 0.06071 (A-MSE: 0.05401) avg lploss: 0.00000
train epoch 1193 avg loss: 0.05781 (A-MSE: 0.05113) avg lploss: 0.00000
train epoch 1194 avg loss: 0.05030 (A-MSE: 0.04427) avg lploss: 0.00000
train epoch 1195 avg loss: 0.04889 (A-MSE: 0.04302) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.33533 (A-MSE: 0.29868) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.36182 (A-MSE: 0.33312) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 35 out of 50
train epoch 1196 avg loss: 0.04618 (A-MSE: 0.04068) avg lploss: 0.00000
train epoch 1197 avg loss: 0.05065 (A-MSE: 0.04464) avg lploss: 0.00000
train epoch 1198 avg loss: 0.05482 (A-MSE: 0.04830) avg lploss: 0.00000
train epoch 1199 avg loss: 0.05279 (A-MSE: 0.04736) avg lploss: 0.00000
train epoch 1200 avg loss: 0.04869 (A-MSE: 0.04275) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.35447 (A-MSE: 0.31242) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.37576 (A-MSE: 0.33875) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 36 out of 50
train epoch 1201 avg loss: 0.04539 (A-MSE: 0.04003) avg lploss: 0.00000
train epoch 1202 avg loss: 0.05633 (A-MSE: 0.04922) avg lploss: 0.00000
train epoch 1203 avg loss: 0.05862 (A-MSE: 0.05264) avg lploss: 0.00000
train epoch 1204 avg loss: 0.04831 (A-MSE: 0.04252) avg lploss: 0.00000
train epoch 1205 avg loss: 0.04187 (A-MSE: 0.03656) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.33484 (A-MSE: 0.29523) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.37886 (A-MSE: 0.34387) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 37 out of 50
train epoch 1206 avg loss: 0.03887 (A-MSE: 0.03413) avg lploss: 0.00000
train epoch 1207 avg loss: 0.05038 (A-MSE: 0.04455) avg lploss: 0.00000
train epoch 1208 avg loss: 0.06522 (A-MSE: 0.05770) avg lploss: 0.00000
train epoch 1209 avg loss: 0.07031 (A-MSE: 0.06115) avg lploss: 0.00000
train epoch 1210 avg loss: 0.07012 (A-MSE: 0.06165) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.31330 (A-MSE: 0.27837) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.38400 (A-MSE: 0.35158) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 38 out of 50
train epoch 1211 avg loss: 0.06802 (A-MSE: 0.06060) avg lploss: 0.00000
train epoch 1212 avg loss: 0.06302 (A-MSE: 0.05541) avg lploss: 0.00000
train epoch 1213 avg loss: 0.05822 (A-MSE: 0.05193) avg lploss: 0.00000
train epoch 1214 avg loss: 0.04968 (A-MSE: 0.04341) avg lploss: 0.00000
train epoch 1215 avg loss: 0.04390 (A-MSE: 0.03863) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.30977 (A-MSE: 0.27740) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.35487 (A-MSE: 0.32205) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 39 out of 50
train epoch 1216 avg loss: 0.04021 (A-MSE: 0.03568) avg lploss: 0.00000
train epoch 1217 avg loss: 0.04931 (A-MSE: 0.04378) avg lploss: 0.00000
train epoch 1218 avg loss: 0.04800 (A-MSE: 0.04180) avg lploss: 0.00000
train epoch 1219 avg loss: 0.04386 (A-MSE: 0.03850) avg lploss: 0.00000
train epoch 1220 avg loss: 0.05235 (A-MSE: 0.04642) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.34297 (A-MSE: 0.30545) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.38421 (A-MSE: 0.35103) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 40 out of 50
train epoch 1221 avg loss: 0.05577 (A-MSE: 0.04927) avg lploss: 0.00000
train epoch 1222 avg loss: 0.06246 (A-MSE: 0.05441) avg lploss: 0.00000
train epoch 1223 avg loss: 0.06637 (A-MSE: 0.05805) avg lploss: 0.00000
train epoch 1224 avg loss: 0.05894 (A-MSE: 0.05182) avg lploss: 0.00000
train epoch 1225 avg loss: 0.06033 (A-MSE: 0.05319) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.42999 (A-MSE: 0.37377) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.42611 (A-MSE: 0.37722) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 41 out of 50
train epoch 1226 avg loss: 0.07724 (A-MSE: 0.06804) avg lploss: 0.00000
train epoch 1227 avg loss: 0.06218 (A-MSE: 0.05418) avg lploss: 0.00000
train epoch 1228 avg loss: 0.07486 (A-MSE: 0.06630) avg lploss: 0.00000
train epoch 1229 avg loss: 0.13366 (A-MSE: 0.11821) avg lploss: 0.00000
train epoch 1230 avg loss: 0.14918 (A-MSE: 0.12916) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.39737 (A-MSE: 0.35585) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.44095 (A-MSE: 0.40504) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 42 out of 50
train epoch 1231 avg loss: 0.11524 (A-MSE: 0.10176) avg lploss: 0.00000
train epoch 1232 avg loss: 0.10492 (A-MSE: 0.09096) avg lploss: 0.00000
train epoch 1233 avg loss: 0.08018 (A-MSE: 0.07067) avg lploss: 0.00000
train epoch 1234 avg loss: 0.06161 (A-MSE: 0.05379) avg lploss: 0.00000
train epoch 1235 avg loss: 0.05872 (A-MSE: 0.05192) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.30239 (A-MSE: 0.26962) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.34302 (A-MSE: 0.31308) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 43 out of 50
train epoch 1236 avg loss: 0.05606 (A-MSE: 0.04986) avg lploss: 0.00000
train epoch 1237 avg loss: 0.05178 (A-MSE: 0.04603) avg lploss: 0.00000
train epoch 1238 avg loss: 0.04846 (A-MSE: 0.04279) avg lploss: 0.00000
train epoch 1239 avg loss: 0.05354 (A-MSE: 0.04711) avg lploss: 0.00000
train epoch 1240 avg loss: 0.05194 (A-MSE: 0.04635) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.35744 (A-MSE: 0.31164) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.37608 (A-MSE: 0.34023) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 44 out of 50
train epoch 1241 avg loss: 0.04814 (A-MSE: 0.04221) avg lploss: 0.00000
train epoch 1242 avg loss: 0.04054 (A-MSE: 0.03592) avg lploss: 0.00000
train epoch 1243 avg loss: 0.03666 (A-MSE: 0.03241) avg lploss: 0.00000
train epoch 1244 avg loss: 0.03699 (A-MSE: 0.03241) avg lploss: 0.00000
train epoch 1245 avg loss: 0.04129 (A-MSE: 0.03626) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.35169 (A-MSE: 0.31057) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.38837 (A-MSE: 0.35172) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 45 out of 50
train epoch 1246 avg loss: 0.03843 (A-MSE: 0.03389) avg lploss: 0.00000
train epoch 1247 avg loss: 0.03842 (A-MSE: 0.03431) avg lploss: 0.00000
train epoch 1248 avg loss: 0.03662 (A-MSE: 0.03225) avg lploss: 0.00000
train epoch 1249 avg loss: 0.05260 (A-MSE: 0.04604) avg lploss: 0.00000
train epoch 1250 avg loss: 0.05035 (A-MSE: 0.04417) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.35738 (A-MSE: 0.31596) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.38516 (A-MSE: 0.34504) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 46 out of 50
train epoch 1251 avg loss: 0.04568 (A-MSE: 0.04027) avg lploss: 0.00000
train epoch 1252 avg loss: 0.03820 (A-MSE: 0.03369) avg lploss: 0.00000
train epoch 1253 avg loss: 0.04032 (A-MSE: 0.03573) avg lploss: 0.00000
train epoch 1254 avg loss: 0.03737 (A-MSE: 0.03299) avg lploss: 0.00000
train epoch 1255 avg loss: 0.03891 (A-MSE: 0.03403) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.30715 (A-MSE: 0.27339) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.35936 (A-MSE: 0.32574) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 47 out of 50
train epoch 1256 avg loss: 0.03844 (A-MSE: 0.03411) avg lploss: 0.00000
train epoch 1257 avg loss: 0.04118 (A-MSE: 0.03611) avg lploss: 0.00000
train epoch 1258 avg loss: 0.03614 (A-MSE: 0.03193) avg lploss: 0.00000
train epoch 1259 avg loss: 0.03726 (A-MSE: 0.03233) avg lploss: 0.00000
train epoch 1260 avg loss: 0.04034 (A-MSE: 0.03554) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.32713 (A-MSE: 0.28989) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.36248 (A-MSE: 0.33146) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 48 out of 50
train epoch 1261 avg loss: 0.04680 (A-MSE: 0.04039) avg lploss: 0.00000
train epoch 1262 avg loss: 0.04495 (A-MSE: 0.03967) avg lploss: 0.00000
train epoch 1263 avg loss: 0.04358 (A-MSE: 0.03832) avg lploss: 0.00000
train epoch 1264 avg loss: 0.04367 (A-MSE: 0.03829) avg lploss: 0.00000
train epoch 1265 avg loss: 0.04250 (A-MSE: 0.03770) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.32953 (A-MSE: 0.28791) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.34996 (A-MSE: 0.31523) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 49 out of 50
train epoch 1266 avg loss: 0.03736 (A-MSE: 0.03305) avg lploss: 0.00000
train epoch 1267 avg loss: 0.03512 (A-MSE: 0.03082) avg lploss: 0.00000
train epoch 1268 avg loss: 0.03177 (A-MSE: 0.02788) avg lploss: 0.00000
train epoch 1269 avg loss: 0.03156 (A-MSE: 0.02787) avg lploss: 0.00000
train epoch 1270 avg loss: 0.03617 (A-MSE: 0.03185) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.32519 (A-MSE: 0.29076) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.36157 (A-MSE: 0.32714) avg lploss: 0.00000
*** Best Val Loss: 0.29488 	 Best Test Loss: 0.34380 	 Best epoch 1020
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.057814
best_lp = 0.000000
best_val = 0.294876
best_test = 0.343804
best_epoch = 1020
best_train = 0.057814, best_lp = 0.000000, best_val = 0.294876, best_test = 0.343804, best_epoch = 1020
Job completed at Mon Dec  8 22:58:55 CET 2025
