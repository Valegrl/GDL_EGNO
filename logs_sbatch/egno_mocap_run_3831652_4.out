Date              = Mon Dec  8 23:11:24 CET 2025
Hostname          = mel2076
Array Task ID     = 4
Running config: configs/mocap_run_seed5.json
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_seed5.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_seed5', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=5, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_seed5/saved_model.pth
train epoch 0 avg loss: 1665.63803 (A-MSE: 1758.88163) avg lploss: 0.00000
==> val epoch 0 avg loss: 1162.65449 (A-MSE: 1202.44466) avg lploss: 0.00000
==> test epoch 0 avg loss: 1166.47036 (A-MSE: 1206.62433) avg lploss: 0.00000
*** Best Val Loss: 1162.65449 	 Best Test Loss: 1166.47036 	 Best epoch 0
Validation loss decreased (inf --> 1162.654486).  Saving model ...
train epoch 1 avg loss: 191.98748 (A-MSE: 186.75579) avg lploss: 0.00000
train epoch 2 avg loss: 90.01510 (A-MSE: 79.57008) avg lploss: 0.00000
train epoch 3 avg loss: 88.71243 (A-MSE: 78.30438) avg lploss: 0.00000
train epoch 4 avg loss: 86.10878 (A-MSE: 75.96996) avg lploss: 0.00000
train epoch 5 avg loss: 82.31834 (A-MSE: 72.62154) avg lploss: 0.00000
==> val epoch 5 avg loss: 81.49858 (A-MSE: 71.82869) avg lploss: 0.00000
==> test epoch 5 avg loss: 77.26166 (A-MSE: 68.10491) avg lploss: 0.00000
*** Best Val Loss: 81.49858 	 Best Test Loss: 77.26166 	 Best epoch 5
Validation loss decreased (1162.654486 --> 81.498581).  Saving model ...
train epoch 6 avg loss: 77.62343 (A-MSE: 68.48689) avg lploss: 0.00000
train epoch 7 avg loss: 72.73880 (A-MSE: 64.03230) avg lploss: 0.00000
train epoch 8 avg loss: 62.83328 (A-MSE: 54.81464) avg lploss: 0.00000
train epoch 9 avg loss: 50.26872 (A-MSE: 43.54783) avg lploss: 0.00000
train epoch 10 avg loss: 43.93130 (A-MSE: 38.08994) avg lploss: 0.00000
==> val epoch 10 avg loss: 40.65622 (A-MSE: 34.92164) avg lploss: 0.00000
==> test epoch 10 avg loss: 38.21174 (A-MSE: 32.82471) avg lploss: 0.00000
*** Best Val Loss: 40.65622 	 Best Test Loss: 38.21174 	 Best epoch 10
Validation loss decreased (81.498581 --> 40.656219).  Saving model ...
train epoch 11 avg loss: 37.58709 (A-MSE: 32.36769) avg lploss: 0.00000
train epoch 12 avg loss: 33.08868 (A-MSE: 28.54128) avg lploss: 0.00000
train epoch 13 avg loss: 29.28024 (A-MSE: 25.19777) avg lploss: 0.00000
train epoch 14 avg loss: 26.49914 (A-MSE: 22.90591) avg lploss: 0.00000
train epoch 15 avg loss: 25.13604 (A-MSE: 21.74738) avg lploss: 0.00000
==> val epoch 15 avg loss: 23.43472 (A-MSE: 20.16074) avg lploss: 0.00000
==> test epoch 15 avg loss: 22.35952 (A-MSE: 19.21185) avg lploss: 0.00000
*** Best Val Loss: 23.43472 	 Best Test Loss: 22.35952 	 Best epoch 15
Validation loss decreased (40.656219 --> 23.434717).  Saving model ...
train epoch 16 avg loss: 23.65075 (A-MSE: 20.54634) avg lploss: 0.00000
train epoch 17 avg loss: 22.56320 (A-MSE: 19.67125) avg lploss: 0.00000
train epoch 18 avg loss: 20.54674 (A-MSE: 17.91023) avg lploss: 0.00000
train epoch 19 avg loss: 18.80498 (A-MSE: 16.45190) avg lploss: 0.00000
train epoch 20 avg loss: 17.58902 (A-MSE: 15.42011) avg lploss: 0.00000
==> val epoch 20 avg loss: 16.75698 (A-MSE: 14.58917) avg lploss: 0.00000
==> test epoch 20 avg loss: 15.66963 (A-MSE: 13.60369) avg lploss: 0.00000
*** Best Val Loss: 16.75698 	 Best Test Loss: 15.66963 	 Best epoch 20
Validation loss decreased (23.434717 --> 16.756980).  Saving model ...
train epoch 21 avg loss: 16.58199 (A-MSE: 14.59356) avg lploss: 0.00000
train epoch 22 avg loss: 15.59183 (A-MSE: 13.74252) avg lploss: 0.00000
train epoch 23 avg loss: 14.81987 (A-MSE: 13.06713) avg lploss: 0.00000
train epoch 24 avg loss: 13.84312 (A-MSE: 12.22018) avg lploss: 0.00000
train epoch 25 avg loss: 13.26385 (A-MSE: 11.69061) avg lploss: 0.00000
==> val epoch 25 avg loss: 12.03681 (A-MSE: 10.56092) avg lploss: 0.00000
==> test epoch 25 avg loss: 11.29902 (A-MSE: 9.88657) avg lploss: 0.00000
*** Best Val Loss: 12.03681 	 Best Test Loss: 11.29902 	 Best epoch 25
Validation loss decreased (16.756980 --> 12.036813).  Saving model ...
train epoch 26 avg loss: 12.84321 (A-MSE: 11.31763) avg lploss: 0.00000
train epoch 27 avg loss: 12.52854 (A-MSE: 11.05072) avg lploss: 0.00000
train epoch 28 avg loss: 11.77562 (A-MSE: 10.36565) avg lploss: 0.00000
train epoch 29 avg loss: 11.57194 (A-MSE: 10.17686) avg lploss: 0.00000
train epoch 30 avg loss: 11.34047 (A-MSE: 9.97888) avg lploss: 0.00000
==> val epoch 30 avg loss: 10.21997 (A-MSE: 8.90603) avg lploss: 0.00000
==> test epoch 30 avg loss: 9.77154 (A-MSE: 8.49806) avg lploss: 0.00000
*** Best Val Loss: 10.21997 	 Best Test Loss: 9.77154 	 Best epoch 30
Validation loss decreased (12.036813 --> 10.219966).  Saving model ...
train epoch 31 avg loss: 10.73227 (A-MSE: 9.38009) avg lploss: 0.00000
train epoch 32 avg loss: 10.57469 (A-MSE: 9.26925) avg lploss: 0.00000
train epoch 33 avg loss: 10.14898 (A-MSE: 8.88494) avg lploss: 0.00000
train epoch 34 avg loss: 9.91231 (A-MSE: 8.65162) avg lploss: 0.00000
train epoch 35 avg loss: 9.52652 (A-MSE: 8.32757) avg lploss: 0.00000
==> val epoch 35 avg loss: 9.12417 (A-MSE: 7.95280) avg lploss: 0.00000
==> test epoch 35 avg loss: 8.63660 (A-MSE: 7.49586) avg lploss: 0.00000
*** Best Val Loss: 9.12417 	 Best Test Loss: 8.63660 	 Best epoch 35
Validation loss decreased (10.219966 --> 9.124165).  Saving model ...
train epoch 36 avg loss: 9.32364 (A-MSE: 8.15524) avg lploss: 0.00000
train epoch 37 avg loss: 9.23977 (A-MSE: 8.10533) avg lploss: 0.00000
train epoch 38 avg loss: 8.97535 (A-MSE: 7.86728) avg lploss: 0.00000
train epoch 39 avg loss: 8.64336 (A-MSE: 7.57904) avg lploss: 0.00000
train epoch 40 avg loss: 8.17653 (A-MSE: 7.16304) avg lploss: 0.00000
==> val epoch 40 avg loss: 7.46569 (A-MSE: 6.62836) avg lploss: 0.00000
==> test epoch 40 avg loss: 7.18128 (A-MSE: 6.35558) avg lploss: 0.00000
*** Best Val Loss: 7.46569 	 Best Test Loss: 7.18128 	 Best epoch 40
Validation loss decreased (9.124165 --> 7.465690).  Saving model ...
train epoch 41 avg loss: 7.68344 (A-MSE: 6.76872) avg lploss: 0.00000
train epoch 42 avg loss: 7.02550 (A-MSE: 6.18268) avg lploss: 0.00000
train epoch 43 avg loss: 6.32992 (A-MSE: 5.56830) avg lploss: 0.00000
train epoch 44 avg loss: 6.01960 (A-MSE: 5.32017) avg lploss: 0.00000
train epoch 45 avg loss: 5.58343 (A-MSE: 4.94618) avg lploss: 0.00000
==> val epoch 45 avg loss: 5.13591 (A-MSE: 4.54169) avg lploss: 0.00000
==> test epoch 45 avg loss: 5.30400 (A-MSE: 4.69172) avg lploss: 0.00000
*** Best Val Loss: 5.13591 	 Best Test Loss: 5.30400 	 Best epoch 45
Validation loss decreased (7.465690 --> 5.135913).  Saving model ...
train epoch 46 avg loss: 5.24562 (A-MSE: 4.64022) avg lploss: 0.00000
train epoch 47 avg loss: 4.92497 (A-MSE: 4.35879) avg lploss: 0.00000
train epoch 48 avg loss: 4.74634 (A-MSE: 4.19727) avg lploss: 0.00000
train epoch 49 avg loss: 4.57935 (A-MSE: 4.05040) avg lploss: 0.00000
train epoch 50 avg loss: 4.30611 (A-MSE: 3.78294) avg lploss: 0.00000
==> val epoch 50 avg loss: 4.15356 (A-MSE: 3.75355) avg lploss: 0.00000
==> test epoch 50 avg loss: 4.32604 (A-MSE: 3.90674) avg lploss: 0.00000
*** Best Val Loss: 4.15356 	 Best Test Loss: 4.32604 	 Best epoch 50
Validation loss decreased (5.135913 --> 4.153558).  Saving model ...
train epoch 51 avg loss: 4.05987 (A-MSE: 3.60693) avg lploss: 0.00000
train epoch 52 avg loss: 3.87820 (A-MSE: 3.44034) avg lploss: 0.00000
train epoch 53 avg loss: 3.75260 (A-MSE: 3.34121) avg lploss: 0.00000
train epoch 54 avg loss: 3.95700 (A-MSE: 3.54829) avg lploss: 0.00000
train epoch 55 avg loss: 3.57310 (A-MSE: 3.19170) avg lploss: 0.00000
==> val epoch 55 avg loss: 3.60112 (A-MSE: 3.27998) avg lploss: 0.00000
==> test epoch 55 avg loss: 3.70871 (A-MSE: 3.36754) avg lploss: 0.00000
*** Best Val Loss: 3.60112 	 Best Test Loss: 3.70871 	 Best epoch 55
Validation loss decreased (4.153558 --> 3.601122).  Saving model ...
train epoch 56 avg loss: 3.30811 (A-MSE: 2.94811) avg lploss: 0.00000
train epoch 57 avg loss: 3.15398 (A-MSE: 2.81772) avg lploss: 0.00000
train epoch 58 avg loss: 3.03357 (A-MSE: 2.70466) avg lploss: 0.00000
train epoch 59 avg loss: 2.94095 (A-MSE: 2.60704) avg lploss: 0.00000
train epoch 60 avg loss: 2.91371 (A-MSE: 2.60118) avg lploss: 0.00000
==> val epoch 60 avg loss: 2.94479 (A-MSE: 2.71463) avg lploss: 0.00000
==> test epoch 60 avg loss: 3.18591 (A-MSE: 2.93090) avg lploss: 0.00000
*** Best Val Loss: 2.94479 	 Best Test Loss: 3.18591 	 Best epoch 60
Validation loss decreased (3.601122 --> 2.944785).  Saving model ...
train epoch 61 avg loss: 2.99623 (A-MSE: 2.66456) avg lploss: 0.00000
train epoch 62 avg loss: 2.84436 (A-MSE: 2.52033) avg lploss: 0.00000
train epoch 63 avg loss: 2.84638 (A-MSE: 2.53101) avg lploss: 0.00000
train epoch 64 avg loss: 2.69675 (A-MSE: 2.38578) avg lploss: 0.00000
train epoch 65 avg loss: 2.62204 (A-MSE: 2.31946) avg lploss: 0.00000
==> val epoch 65 avg loss: 3.06400 (A-MSE: 2.84148) avg lploss: 0.00000
==> test epoch 65 avg loss: 3.29365 (A-MSE: 3.05109) avg lploss: 0.00000
*** Best Val Loss: 2.94479 	 Best Test Loss: 3.18591 	 Best epoch 60
EarlyStopping counter: 1 out of 50
train epoch 66 avg loss: 2.44382 (A-MSE: 2.17548) avg lploss: 0.00000
train epoch 67 avg loss: 2.26664 (A-MSE: 1.99824) avg lploss: 0.00000
train epoch 68 avg loss: 2.27547 (A-MSE: 2.01499) avg lploss: 0.00000
train epoch 69 avg loss: 2.25944 (A-MSE: 1.99273) avg lploss: 0.00000
train epoch 70 avg loss: 2.24156 (A-MSE: 1.95647) avg lploss: 0.00000
==> val epoch 70 avg loss: 2.22837 (A-MSE: 1.96493) avg lploss: 0.00000
==> test epoch 70 avg loss: 2.52149 (A-MSE: 2.22964) avg lploss: 0.00000
*** Best Val Loss: 2.22837 	 Best Test Loss: 2.52149 	 Best epoch 70
Validation loss decreased (2.944785 --> 2.228374).  Saving model ...
train epoch 71 avg loss: 2.18243 (A-MSE: 1.92772) avg lploss: 0.00000
train epoch 72 avg loss: 2.05238 (A-MSE: 1.80603) avg lploss: 0.00000
train epoch 73 avg loss: 2.00435 (A-MSE: 1.75900) avg lploss: 0.00000
train epoch 74 avg loss: 2.02591 (A-MSE: 1.78308) avg lploss: 0.00000
train epoch 75 avg loss: 1.99926 (A-MSE: 1.76474) avg lploss: 0.00000
==> val epoch 75 avg loss: 2.08032 (A-MSE: 1.84049) avg lploss: 0.00000
==> test epoch 75 avg loss: 2.32502 (A-MSE: 2.05982) avg lploss: 0.00000
*** Best Val Loss: 2.08032 	 Best Test Loss: 2.32502 	 Best epoch 75
Validation loss decreased (2.228374 --> 2.080319).  Saving model ...
train epoch 76 avg loss: 1.91090 (A-MSE: 1.68001) avg lploss: 0.00000
train epoch 77 avg loss: 1.86874 (A-MSE: 1.63548) avg lploss: 0.00000
train epoch 78 avg loss: 1.87449 (A-MSE: 1.64469) avg lploss: 0.00000
train epoch 79 avg loss: 1.69121 (A-MSE: 1.48737) avg lploss: 0.00000
train epoch 80 avg loss: 1.74689 (A-MSE: 1.52781) avg lploss: 0.00000
==> val epoch 80 avg loss: 2.38917 (A-MSE: 2.15336) avg lploss: 0.00000
==> test epoch 80 avg loss: 2.66486 (A-MSE: 2.38979) avg lploss: 0.00000
*** Best Val Loss: 2.08032 	 Best Test Loss: 2.32502 	 Best epoch 75
EarlyStopping counter: 1 out of 50
train epoch 81 avg loss: 1.77805 (A-MSE: 1.55659) avg lploss: 0.00000
train epoch 82 avg loss: 1.69503 (A-MSE: 1.48653) avg lploss: 0.00000
train epoch 83 avg loss: 1.81562 (A-MSE: 1.60539) avg lploss: 0.00000
train epoch 84 avg loss: 1.84617 (A-MSE: 1.62479) avg lploss: 0.00000
train epoch 85 avg loss: 1.88336 (A-MSE: 1.65284) avg lploss: 0.00000
==> val epoch 85 avg loss: 1.74427 (A-MSE: 1.54001) avg lploss: 0.00000
==> test epoch 85 avg loss: 1.87462 (A-MSE: 1.65641) avg lploss: 0.00000
*** Best Val Loss: 1.74427 	 Best Test Loss: 1.87462 	 Best epoch 85
Validation loss decreased (2.080319 --> 1.744267).  Saving model ...
train epoch 86 avg loss: 1.67267 (A-MSE: 1.46603) avg lploss: 0.00000
train epoch 87 avg loss: 1.80928 (A-MSE: 1.59556) avg lploss: 0.00000
train epoch 88 avg loss: 1.74618 (A-MSE: 1.52256) avg lploss: 0.00000
train epoch 89 avg loss: 1.52034 (A-MSE: 1.33158) avg lploss: 0.00000
train epoch 90 avg loss: 1.52752 (A-MSE: 1.33917) avg lploss: 0.00000
==> val epoch 90 avg loss: 1.65116 (A-MSE: 1.44163) avg lploss: 0.00000
==> test epoch 90 avg loss: 1.76446 (A-MSE: 1.54326) avg lploss: 0.00000
*** Best Val Loss: 1.65116 	 Best Test Loss: 1.76446 	 Best epoch 90
Validation loss decreased (1.744267 --> 1.651156).  Saving model ...
train epoch 91 avg loss: 1.48647 (A-MSE: 1.30358) avg lploss: 0.00000
train epoch 92 avg loss: 1.44364 (A-MSE: 1.26325) avg lploss: 0.00000
train epoch 93 avg loss: 1.36432 (A-MSE: 1.18393) avg lploss: 0.00000
train epoch 94 avg loss: 1.33864 (A-MSE: 1.16150) avg lploss: 0.00000
train epoch 95 avg loss: 1.43946 (A-MSE: 1.26663) avg lploss: 0.00000
==> val epoch 95 avg loss: 1.48971 (A-MSE: 1.29053) avg lploss: 0.00000
==> test epoch 95 avg loss: 1.69468 (A-MSE: 1.47726) avg lploss: 0.00000
*** Best Val Loss: 1.48971 	 Best Test Loss: 1.69468 	 Best epoch 95
Validation loss decreased (1.651156 --> 1.489707).  Saving model ...
train epoch 96 avg loss: 1.30457 (A-MSE: 1.13849) avg lploss: 0.00000
train epoch 97 avg loss: 1.45832 (A-MSE: 1.28133) avg lploss: 0.00000
train epoch 98 avg loss: 1.54234 (A-MSE: 1.36061) avg lploss: 0.00000
train epoch 99 avg loss: 1.41083 (A-MSE: 1.22211) avg lploss: 0.00000
train epoch 100 avg loss: 1.35426 (A-MSE: 1.18069) avg lploss: 0.00000
==> val epoch 100 avg loss: 1.41374 (A-MSE: 1.22722) avg lploss: 0.00000
==> test epoch 100 avg loss: 1.55399 (A-MSE: 1.35812) avg lploss: 0.00000
*** Best Val Loss: 1.41374 	 Best Test Loss: 1.55399 	 Best epoch 100
Validation loss decreased (1.489707 --> 1.413743).  Saving model ...
train epoch 101 avg loss: 1.29687 (A-MSE: 1.13037) avg lploss: 0.00000
train epoch 102 avg loss: 1.28355 (A-MSE: 1.12404) avg lploss: 0.00000
train epoch 103 avg loss: 1.36461 (A-MSE: 1.19784) avg lploss: 0.00000
train epoch 104 avg loss: 1.28015 (A-MSE: 1.10994) avg lploss: 0.00000
train epoch 105 avg loss: 1.27203 (A-MSE: 1.11204) avg lploss: 0.00000
==> val epoch 105 avg loss: 1.32787 (A-MSE: 1.15486) avg lploss: 0.00000
==> test epoch 105 avg loss: 1.47864 (A-MSE: 1.29242) avg lploss: 0.00000
*** Best Val Loss: 1.32787 	 Best Test Loss: 1.47864 	 Best epoch 105
Validation loss decreased (1.413743 --> 1.327870).  Saving model ...
train epoch 106 avg loss: 1.19500 (A-MSE: 1.04173) avg lploss: 0.00000
train epoch 107 avg loss: 1.12446 (A-MSE: 0.97596) avg lploss: 0.00000
train epoch 108 avg loss: 1.19601 (A-MSE: 1.04188) avg lploss: 0.00000
train epoch 109 avg loss: 1.26538 (A-MSE: 1.10540) avg lploss: 0.00000
train epoch 110 avg loss: 1.22687 (A-MSE: 1.06760) avg lploss: 0.00000
==> val epoch 110 avg loss: 1.34094 (A-MSE: 1.17159) avg lploss: 0.00000
==> test epoch 110 avg loss: 1.41874 (A-MSE: 1.24392) avg lploss: 0.00000
*** Best Val Loss: 1.32787 	 Best Test Loss: 1.47864 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 1.17000 (A-MSE: 1.01801) avg lploss: 0.00000
train epoch 112 avg loss: 1.17300 (A-MSE: 1.02100) avg lploss: 0.00000
train epoch 113 avg loss: 1.14676 (A-MSE: 0.99618) avg lploss: 0.00000
train epoch 114 avg loss: 1.10105 (A-MSE: 0.96348) avg lploss: 0.00000
train epoch 115 avg loss: 1.17192 (A-MSE: 1.02424) avg lploss: 0.00000
==> val epoch 115 avg loss: 1.27133 (A-MSE: 1.11697) avg lploss: 0.00000
==> test epoch 115 avg loss: 1.44591 (A-MSE: 1.27314) avg lploss: 0.00000
*** Best Val Loss: 1.27133 	 Best Test Loss: 1.44591 	 Best epoch 115
Validation loss decreased (1.327870 --> 1.271332).  Saving model ...
train epoch 116 avg loss: 1.17326 (A-MSE: 1.02317) avg lploss: 0.00000
train epoch 117 avg loss: 1.15379 (A-MSE: 1.00774) avg lploss: 0.00000
train epoch 118 avg loss: 1.07455 (A-MSE: 0.93844) avg lploss: 0.00000
train epoch 119 avg loss: 1.11242 (A-MSE: 0.96682) avg lploss: 0.00000
train epoch 120 avg loss: 1.12880 (A-MSE: 0.98792) avg lploss: 0.00000
==> val epoch 120 avg loss: 1.18738 (A-MSE: 1.03657) avg lploss: 0.00000
==> test epoch 120 avg loss: 1.29009 (A-MSE: 1.13114) avg lploss: 0.00000
*** Best Val Loss: 1.18738 	 Best Test Loss: 1.29009 	 Best epoch 120
Validation loss decreased (1.271332 --> 1.187381).  Saving model ...
train epoch 121 avg loss: 1.04233 (A-MSE: 0.90944) avg lploss: 0.00000
train epoch 122 avg loss: 1.10523 (A-MSE: 0.96712) avg lploss: 0.00000
train epoch 123 avg loss: 1.03256 (A-MSE: 0.90260) avg lploss: 0.00000
train epoch 124 avg loss: 1.02215 (A-MSE: 0.88975) avg lploss: 0.00000
train epoch 125 avg loss: 0.97195 (A-MSE: 0.84991) avg lploss: 0.00000
==> val epoch 125 avg loss: 1.08595 (A-MSE: 0.94164) avg lploss: 0.00000
==> test epoch 125 avg loss: 1.18641 (A-MSE: 1.03506) avg lploss: 0.00000
*** Best Val Loss: 1.08595 	 Best Test Loss: 1.18641 	 Best epoch 125
Validation loss decreased (1.187381 --> 1.085949).  Saving model ...
train epoch 126 avg loss: 1.07630 (A-MSE: 0.94697) avg lploss: 0.00000
train epoch 127 avg loss: 1.12545 (A-MSE: 0.98822) avg lploss: 0.00000
train epoch 128 avg loss: 1.00997 (A-MSE: 0.88691) avg lploss: 0.00000
train epoch 129 avg loss: 0.96738 (A-MSE: 0.84283) avg lploss: 0.00000
train epoch 130 avg loss: 1.00764 (A-MSE: 0.88286) avg lploss: 0.00000
==> val epoch 130 avg loss: 1.13520 (A-MSE: 1.00021) avg lploss: 0.00000
==> test epoch 130 avg loss: 1.22589 (A-MSE: 1.08433) avg lploss: 0.00000
*** Best Val Loss: 1.08595 	 Best Test Loss: 1.18641 	 Best epoch 125
EarlyStopping counter: 1 out of 50
train epoch 131 avg loss: 0.96156 (A-MSE: 0.84273) avg lploss: 0.00000
train epoch 132 avg loss: 0.97828 (A-MSE: 0.85099) avg lploss: 0.00000
train epoch 133 avg loss: 0.93269 (A-MSE: 0.81654) avg lploss: 0.00000
train epoch 134 avg loss: 0.86788 (A-MSE: 0.76036) avg lploss: 0.00000
train epoch 135 avg loss: 0.90003 (A-MSE: 0.78916) avg lploss: 0.00000
==> val epoch 135 avg loss: 1.16688 (A-MSE: 1.00254) avg lploss: 0.00000
==> test epoch 135 avg loss: 1.31889 (A-MSE: 1.14279) avg lploss: 0.00000
*** Best Val Loss: 1.08595 	 Best Test Loss: 1.18641 	 Best epoch 125
EarlyStopping counter: 2 out of 50
train epoch 136 avg loss: 0.91960 (A-MSE: 0.79901) avg lploss: 0.00000
train epoch 137 avg loss: 0.93441 (A-MSE: 0.82374) avg lploss: 0.00000
train epoch 138 avg loss: 0.90339 (A-MSE: 0.79196) avg lploss: 0.00000
train epoch 139 avg loss: 0.92605 (A-MSE: 0.80978) avg lploss: 0.00000
train epoch 140 avg loss: 1.03420 (A-MSE: 0.91998) avg lploss: 0.00000
==> val epoch 140 avg loss: 1.36161 (A-MSE: 1.16808) avg lploss: 0.00000
==> test epoch 140 avg loss: 1.49038 (A-MSE: 1.28846) avg lploss: 0.00000
*** Best Val Loss: 1.08595 	 Best Test Loss: 1.18641 	 Best epoch 125
EarlyStopping counter: 3 out of 50
train epoch 141 avg loss: 0.96791 (A-MSE: 0.85193) avg lploss: 0.00000
train epoch 142 avg loss: 1.04117 (A-MSE: 0.91898) avg lploss: 0.00000
train epoch 143 avg loss: 0.90034 (A-MSE: 0.78282) avg lploss: 0.00000
train epoch 144 avg loss: 0.87324 (A-MSE: 0.76531) avg lploss: 0.00000
train epoch 145 avg loss: 0.82647 (A-MSE: 0.72114) avg lploss: 0.00000
==> val epoch 145 avg loss: 0.92304 (A-MSE: 0.80093) avg lploss: 0.00000
==> test epoch 145 avg loss: 1.06425 (A-MSE: 0.93212) avg lploss: 0.00000
*** Best Val Loss: 0.92304 	 Best Test Loss: 1.06425 	 Best epoch 145
Validation loss decreased (1.085949 --> 0.923039).  Saving model ...
train epoch 146 avg loss: 0.85163 (A-MSE: 0.74454) avg lploss: 0.00000
train epoch 147 avg loss: 0.81105 (A-MSE: 0.70983) avg lploss: 0.00000
train epoch 148 avg loss: 0.85824 (A-MSE: 0.75213) avg lploss: 0.00000
train epoch 149 avg loss: 0.82699 (A-MSE: 0.72001) avg lploss: 0.00000
train epoch 150 avg loss: 0.86580 (A-MSE: 0.76904) avg lploss: 0.00000
==> val epoch 150 avg loss: 1.11635 (A-MSE: 0.94834) avg lploss: 0.00000
==> test epoch 150 avg loss: 1.23462 (A-MSE: 1.06055) avg lploss: 0.00000
*** Best Val Loss: 0.92304 	 Best Test Loss: 1.06425 	 Best epoch 145
EarlyStopping counter: 1 out of 50
train epoch 151 avg loss: 0.79782 (A-MSE: 0.69150) avg lploss: 0.00000
train epoch 152 avg loss: 0.93329 (A-MSE: 0.82047) avg lploss: 0.00000
train epoch 153 avg loss: 0.84374 (A-MSE: 0.74074) avg lploss: 0.00000
train epoch 154 avg loss: 0.86219 (A-MSE: 0.75770) avg lploss: 0.00000
train epoch 155 avg loss: 0.82328 (A-MSE: 0.72478) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.90627 (A-MSE: 0.79262) avg lploss: 0.00000
==> test epoch 155 avg loss: 1.03116 (A-MSE: 0.91174) avg lploss: 0.00000
*** Best Val Loss: 0.90627 	 Best Test Loss: 1.03116 	 Best epoch 155
Validation loss decreased (0.923039 --> 0.906266).  Saving model ...
train epoch 156 avg loss: 0.79170 (A-MSE: 0.68879) avg lploss: 0.00000
train epoch 157 avg loss: 0.75890 (A-MSE: 0.66524) avg lploss: 0.00000
train epoch 158 avg loss: 0.80495 (A-MSE: 0.70484) avg lploss: 0.00000
train epoch 159 avg loss: 0.76653 (A-MSE: 0.67135) avg lploss: 0.00000
train epoch 160 avg loss: 0.74145 (A-MSE: 0.64661) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.91094 (A-MSE: 0.78480) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.04180 (A-MSE: 0.90803) avg lploss: 0.00000
*** Best Val Loss: 0.90627 	 Best Test Loss: 1.03116 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 0.81800 (A-MSE: 0.71807) avg lploss: 0.00000
train epoch 162 avg loss: 0.79052 (A-MSE: 0.69852) avg lploss: 0.00000
train epoch 163 avg loss: 0.73332 (A-MSE: 0.63883) avg lploss: 0.00000
train epoch 164 avg loss: 0.83022 (A-MSE: 0.72789) avg lploss: 0.00000
train epoch 165 avg loss: 0.80694 (A-MSE: 0.71442) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.95490 (A-MSE: 0.82582) avg lploss: 0.00000
==> test epoch 165 avg loss: 1.05433 (A-MSE: 0.92121) avg lploss: 0.00000
*** Best Val Loss: 0.90627 	 Best Test Loss: 1.03116 	 Best epoch 155
EarlyStopping counter: 2 out of 50
train epoch 166 avg loss: 0.79202 (A-MSE: 0.69528) avg lploss: 0.00000
train epoch 167 avg loss: 0.75317 (A-MSE: 0.65836) avg lploss: 0.00000
train epoch 168 avg loss: 0.90608 (A-MSE: 0.80286) avg lploss: 0.00000
train epoch 169 avg loss: 0.79742 (A-MSE: 0.69768) avg lploss: 0.00000
train epoch 170 avg loss: 0.77021 (A-MSE: 0.67862) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.96554 (A-MSE: 0.83720) avg lploss: 0.00000
==> test epoch 170 avg loss: 1.09454 (A-MSE: 0.95777) avg lploss: 0.00000
*** Best Val Loss: 0.90627 	 Best Test Loss: 1.03116 	 Best epoch 155
EarlyStopping counter: 3 out of 50
train epoch 171 avg loss: 0.74798 (A-MSE: 0.65068) avg lploss: 0.00000
train epoch 172 avg loss: 0.74213 (A-MSE: 0.65138) avg lploss: 0.00000
train epoch 173 avg loss: 0.75075 (A-MSE: 0.66544) avg lploss: 0.00000
train epoch 174 avg loss: 0.80101 (A-MSE: 0.71021) avg lploss: 0.00000
train epoch 175 avg loss: 0.73574 (A-MSE: 0.64123) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.82644 (A-MSE: 0.73102) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.94411 (A-MSE: 0.84090) avg lploss: 0.00000
*** Best Val Loss: 0.82644 	 Best Test Loss: 0.94411 	 Best epoch 175
Validation loss decreased (0.906266 --> 0.826438).  Saving model ...
train epoch 176 avg loss: 0.75491 (A-MSE: 0.66432) avg lploss: 0.00000
train epoch 177 avg loss: 0.69061 (A-MSE: 0.60237) avg lploss: 0.00000
train epoch 178 avg loss: 0.65891 (A-MSE: 0.57270) avg lploss: 0.00000
train epoch 179 avg loss: 0.66894 (A-MSE: 0.59000) avg lploss: 0.00000
train epoch 180 avg loss: 0.67976 (A-MSE: 0.59493) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.81661 (A-MSE: 0.71250) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.93742 (A-MSE: 0.82453) avg lploss: 0.00000
*** Best Val Loss: 0.81661 	 Best Test Loss: 0.93742 	 Best epoch 180
Validation loss decreased (0.826438 --> 0.816611).  Saving model ...
train epoch 181 avg loss: 0.70984 (A-MSE: 0.62188) avg lploss: 0.00000
train epoch 182 avg loss: 0.69361 (A-MSE: 0.60900) avg lploss: 0.00000
train epoch 183 avg loss: 0.64503 (A-MSE: 0.56091) avg lploss: 0.00000
train epoch 184 avg loss: 0.64863 (A-MSE: 0.56675) avg lploss: 0.00000
train epoch 185 avg loss: 0.62990 (A-MSE: 0.55258) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.86404 (A-MSE: 0.77151) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.93458 (A-MSE: 0.84020) avg lploss: 0.00000
*** Best Val Loss: 0.81661 	 Best Test Loss: 0.93742 	 Best epoch 180
EarlyStopping counter: 1 out of 50
train epoch 186 avg loss: 0.65761 (A-MSE: 0.57799) avg lploss: 0.00000
train epoch 187 avg loss: 0.67860 (A-MSE: 0.60024) avg lploss: 0.00000
train epoch 188 avg loss: 0.68064 (A-MSE: 0.59281) avg lploss: 0.00000
train epoch 189 avg loss: 0.65413 (A-MSE: 0.57808) avg lploss: 0.00000
train epoch 190 avg loss: 0.67597 (A-MSE: 0.59384) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.89908 (A-MSE: 0.76654) avg lploss: 0.00000
==> test epoch 190 avg loss: 1.01048 (A-MSE: 0.87230) avg lploss: 0.00000
*** Best Val Loss: 0.81661 	 Best Test Loss: 0.93742 	 Best epoch 180
EarlyStopping counter: 2 out of 50
train epoch 191 avg loss: 0.65881 (A-MSE: 0.57658) avg lploss: 0.00000
train epoch 192 avg loss: 0.62673 (A-MSE: 0.55295) avg lploss: 0.00000
train epoch 193 avg loss: 0.64562 (A-MSE: 0.56540) avg lploss: 0.00000
train epoch 194 avg loss: 0.65579 (A-MSE: 0.57689) avg lploss: 0.00000
train epoch 195 avg loss: 0.63869 (A-MSE: 0.56234) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.80750 (A-MSE: 0.71052) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.93303 (A-MSE: 0.82726) avg lploss: 0.00000
*** Best Val Loss: 0.80750 	 Best Test Loss: 0.93303 	 Best epoch 195
Validation loss decreased (0.816611 --> 0.807505).  Saving model ...
train epoch 196 avg loss: 0.61310 (A-MSE: 0.54194) avg lploss: 0.00000
train epoch 197 avg loss: 0.61365 (A-MSE: 0.53790) avg lploss: 0.00000
train epoch 198 avg loss: 0.59066 (A-MSE: 0.51527) avg lploss: 0.00000
train epoch 199 avg loss: 0.59143 (A-MSE: 0.51715) avg lploss: 0.00000
train epoch 200 avg loss: 0.63326 (A-MSE: 0.55439) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.80992 (A-MSE: 0.71528) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.91725 (A-MSE: 0.81849) avg lploss: 0.00000
*** Best Val Loss: 0.80750 	 Best Test Loss: 0.93303 	 Best epoch 195
EarlyStopping counter: 1 out of 50
train epoch 201 avg loss: 0.58481 (A-MSE: 0.51530) avg lploss: 0.00000
train epoch 202 avg loss: 0.60666 (A-MSE: 0.53438) avg lploss: 0.00000
train epoch 203 avg loss: 0.66700 (A-MSE: 0.58438) avg lploss: 0.00000
train epoch 204 avg loss: 0.64539 (A-MSE: 0.56785) avg lploss: 0.00000
train epoch 205 avg loss: 0.62119 (A-MSE: 0.54518) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.99557 (A-MSE: 0.85537) avg lploss: 0.00000
==> test epoch 205 avg loss: 1.10059 (A-MSE: 0.95699) avg lploss: 0.00000
*** Best Val Loss: 0.80750 	 Best Test Loss: 0.93303 	 Best epoch 195
EarlyStopping counter: 2 out of 50
train epoch 206 avg loss: 0.61814 (A-MSE: 0.53637) avg lploss: 0.00000
train epoch 207 avg loss: 0.59964 (A-MSE: 0.52869) avg lploss: 0.00000
train epoch 208 avg loss: 0.59707 (A-MSE: 0.52307) avg lploss: 0.00000
train epoch 209 avg loss: 0.58947 (A-MSE: 0.51957) avg lploss: 0.00000
train epoch 210 avg loss: 0.66865 (A-MSE: 0.59119) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.86057 (A-MSE: 0.74783) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.96899 (A-MSE: 0.84715) avg lploss: 0.00000
*** Best Val Loss: 0.80750 	 Best Test Loss: 0.93303 	 Best epoch 195
EarlyStopping counter: 3 out of 50
train epoch 211 avg loss: 0.59194 (A-MSE: 0.51970) avg lploss: 0.00000
train epoch 212 avg loss: 0.61294 (A-MSE: 0.54093) avg lploss: 0.00000
train epoch 213 avg loss: 0.63734 (A-MSE: 0.56027) avg lploss: 0.00000
train epoch 214 avg loss: 0.62096 (A-MSE: 0.54213) avg lploss: 0.00000
train epoch 215 avg loss: 0.65391 (A-MSE: 0.57474) avg lploss: 0.00000
==> val epoch 215 avg loss: 1.07042 (A-MSE: 0.95204) avg lploss: 0.00000
==> test epoch 215 avg loss: 1.14551 (A-MSE: 1.03159) avg lploss: 0.00000
*** Best Val Loss: 0.80750 	 Best Test Loss: 0.93303 	 Best epoch 195
EarlyStopping counter: 4 out of 50
train epoch 216 avg loss: 0.72856 (A-MSE: 0.64710) avg lploss: 0.00000
train epoch 217 avg loss: 0.59571 (A-MSE: 0.52296) avg lploss: 0.00000
train epoch 218 avg loss: 0.60972 (A-MSE: 0.53781) avg lploss: 0.00000
train epoch 219 avg loss: 0.57229 (A-MSE: 0.50370) avg lploss: 0.00000
train epoch 220 avg loss: 0.55299 (A-MSE: 0.48231) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.75527 (A-MSE: 0.65523) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.84317 (A-MSE: 0.74266) avg lploss: 0.00000
*** Best Val Loss: 0.75527 	 Best Test Loss: 0.84317 	 Best epoch 220
Validation loss decreased (0.807505 --> 0.755265).  Saving model ...
train epoch 221 avg loss: 0.56163 (A-MSE: 0.49218) avg lploss: 0.00000
train epoch 222 avg loss: 0.55753 (A-MSE: 0.48897) avg lploss: 0.00000
train epoch 223 avg loss: 0.62322 (A-MSE: 0.54922) avg lploss: 0.00000
train epoch 224 avg loss: 0.62145 (A-MSE: 0.54586) avg lploss: 0.00000
train epoch 225 avg loss: 0.58309 (A-MSE: 0.51371) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.83045 (A-MSE: 0.72759) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.90391 (A-MSE: 0.79492) avg lploss: 0.00000
*** Best Val Loss: 0.75527 	 Best Test Loss: 0.84317 	 Best epoch 220
EarlyStopping counter: 1 out of 50
train epoch 226 avg loss: 0.58401 (A-MSE: 0.51476) avg lploss: 0.00000
train epoch 227 avg loss: 0.56890 (A-MSE: 0.50104) avg lploss: 0.00000
train epoch 228 avg loss: 0.60342 (A-MSE: 0.53045) avg lploss: 0.00000
train epoch 229 avg loss: 0.55408 (A-MSE: 0.48807) avg lploss: 0.00000
train epoch 230 avg loss: 0.57703 (A-MSE: 0.50683) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.79874 (A-MSE: 0.69005) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.89189 (A-MSE: 0.77954) avg lploss: 0.00000
*** Best Val Loss: 0.75527 	 Best Test Loss: 0.84317 	 Best epoch 220
EarlyStopping counter: 2 out of 50
train epoch 231 avg loss: 0.57768 (A-MSE: 0.50583) avg lploss: 0.00000
train epoch 232 avg loss: 0.55224 (A-MSE: 0.48512) avg lploss: 0.00000
train epoch 233 avg loss: 0.52527 (A-MSE: 0.46037) avg lploss: 0.00000
train epoch 234 avg loss: 0.54492 (A-MSE: 0.47739) avg lploss: 0.00000
train epoch 235 avg loss: 0.55171 (A-MSE: 0.48854) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.70409 (A-MSE: 0.62521) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.81078 (A-MSE: 0.72589) avg lploss: 0.00000
*** Best Val Loss: 0.70409 	 Best Test Loss: 0.81078 	 Best epoch 235
Validation loss decreased (0.755265 --> 0.704089).  Saving model ...
train epoch 236 avg loss: 0.54606 (A-MSE: 0.47800) avg lploss: 0.00000
train epoch 237 avg loss: 0.54705 (A-MSE: 0.48448) avg lploss: 0.00000
train epoch 238 avg loss: 0.57609 (A-MSE: 0.50486) avg lploss: 0.00000
train epoch 239 avg loss: 0.55267 (A-MSE: 0.48636) avg lploss: 0.00000
train epoch 240 avg loss: 0.52591 (A-MSE: 0.45907) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.70867 (A-MSE: 0.61903) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.76964 (A-MSE: 0.68130) avg lploss: 0.00000
*** Best Val Loss: 0.70409 	 Best Test Loss: 0.81078 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.48346 (A-MSE: 0.42364) avg lploss: 0.00000
train epoch 242 avg loss: 0.47540 (A-MSE: 0.41456) avg lploss: 0.00000
train epoch 243 avg loss: 0.50223 (A-MSE: 0.44050) avg lploss: 0.00000
train epoch 244 avg loss: 0.55193 (A-MSE: 0.48428) avg lploss: 0.00000
train epoch 245 avg loss: 0.64666 (A-MSE: 0.57269) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.72333 (A-MSE: 0.64728) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.82379 (A-MSE: 0.74347) avg lploss: 0.00000
*** Best Val Loss: 0.70409 	 Best Test Loss: 0.81078 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.56102 (A-MSE: 0.49641) avg lploss: 0.00000
train epoch 247 avg loss: 0.55576 (A-MSE: 0.48642) avg lploss: 0.00000
train epoch 248 avg loss: 0.61138 (A-MSE: 0.54066) avg lploss: 0.00000
train epoch 249 avg loss: 0.62189 (A-MSE: 0.55092) avg lploss: 0.00000
train epoch 250 avg loss: 0.53124 (A-MSE: 0.46588) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.69827 (A-MSE: 0.60922) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.78316 (A-MSE: 0.68804) avg lploss: 0.00000
*** Best Val Loss: 0.69827 	 Best Test Loss: 0.78316 	 Best epoch 250
Validation loss decreased (0.704089 --> 0.698275).  Saving model ...
train epoch 251 avg loss: 0.54665 (A-MSE: 0.47961) avg lploss: 0.00000
train epoch 252 avg loss: 0.54195 (A-MSE: 0.47729) avg lploss: 0.00000
train epoch 253 avg loss: 0.51153 (A-MSE: 0.45039) avg lploss: 0.00000
train epoch 254 avg loss: 0.51411 (A-MSE: 0.45258) avg lploss: 0.00000
train epoch 255 avg loss: 0.50209 (A-MSE: 0.44174) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.87453 (A-MSE: 0.76769) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.93451 (A-MSE: 0.82601) avg lploss: 0.00000
*** Best Val Loss: 0.69827 	 Best Test Loss: 0.78316 	 Best epoch 250
EarlyStopping counter: 1 out of 50
train epoch 256 avg loss: 0.57720 (A-MSE: 0.50599) avg lploss: 0.00000
train epoch 257 avg loss: 0.54436 (A-MSE: 0.47897) avg lploss: 0.00000
train epoch 258 avg loss: 0.55279 (A-MSE: 0.48769) avg lploss: 0.00000
train epoch 259 avg loss: 0.58676 (A-MSE: 0.52174) avg lploss: 0.00000
train epoch 260 avg loss: 0.57644 (A-MSE: 0.50925) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.63002 (A-MSE: 0.56418) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.73084 (A-MSE: 0.65830) avg lploss: 0.00000
*** Best Val Loss: 0.63002 	 Best Test Loss: 0.73084 	 Best epoch 260
Validation loss decreased (0.698275 --> 0.630021).  Saving model ...
train epoch 261 avg loss: 0.52265 (A-MSE: 0.46326) avg lploss: 0.00000
train epoch 262 avg loss: 0.52244 (A-MSE: 0.45846) avg lploss: 0.00000
train epoch 263 avg loss: 0.48737 (A-MSE: 0.42775) avg lploss: 0.00000
train epoch 264 avg loss: 0.46874 (A-MSE: 0.41147) avg lploss: 0.00000
train epoch 265 avg loss: 0.46701 (A-MSE: 0.40740) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.63015 (A-MSE: 0.55965) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.69649 (A-MSE: 0.62655) avg lploss: 0.00000
*** Best Val Loss: 0.63002 	 Best Test Loss: 0.73084 	 Best epoch 260
EarlyStopping counter: 1 out of 50
train epoch 266 avg loss: 0.45692 (A-MSE: 0.40214) avg lploss: 0.00000
train epoch 267 avg loss: 0.56202 (A-MSE: 0.49557) avg lploss: 0.00000
train epoch 268 avg loss: 0.48057 (A-MSE: 0.42491) avg lploss: 0.00000
train epoch 269 avg loss: 0.47764 (A-MSE: 0.41898) avg lploss: 0.00000
train epoch 270 avg loss: 0.46885 (A-MSE: 0.40983) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.62752 (A-MSE: 0.54763) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.68967 (A-MSE: 0.61041) avg lploss: 0.00000
*** Best Val Loss: 0.62752 	 Best Test Loss: 0.68967 	 Best epoch 270
Validation loss decreased (0.630021 --> 0.627516).  Saving model ...
train epoch 271 avg loss: 0.45542 (A-MSE: 0.40088) avg lploss: 0.00000
train epoch 272 avg loss: 0.47271 (A-MSE: 0.41847) avg lploss: 0.00000
train epoch 273 avg loss: 0.46072 (A-MSE: 0.40543) avg lploss: 0.00000
train epoch 274 avg loss: 0.46205 (A-MSE: 0.40616) avg lploss: 0.00000
train epoch 275 avg loss: 0.45339 (A-MSE: 0.39858) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.61191 (A-MSE: 0.53619) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.68865 (A-MSE: 0.60835) avg lploss: 0.00000
*** Best Val Loss: 0.61191 	 Best Test Loss: 0.68865 	 Best epoch 275
Validation loss decreased (0.627516 --> 0.611909).  Saving model ...
train epoch 276 avg loss: 0.48017 (A-MSE: 0.42267) avg lploss: 0.00000
train epoch 277 avg loss: 0.43846 (A-MSE: 0.38501) avg lploss: 0.00000
train epoch 278 avg loss: 0.43031 (A-MSE: 0.37940) avg lploss: 0.00000
train epoch 279 avg loss: 0.44340 (A-MSE: 0.39202) avg lploss: 0.00000
train epoch 280 avg loss: 0.46159 (A-MSE: 0.40584) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.87266 (A-MSE: 0.75173) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.89464 (A-MSE: 0.78065) avg lploss: 0.00000
*** Best Val Loss: 0.61191 	 Best Test Loss: 0.68865 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 0.45205 (A-MSE: 0.39855) avg lploss: 0.00000
train epoch 282 avg loss: 0.46417 (A-MSE: 0.40874) avg lploss: 0.00000
train epoch 283 avg loss: 0.45475 (A-MSE: 0.40029) avg lploss: 0.00000
train epoch 284 avg loss: 0.45030 (A-MSE: 0.39679) avg lploss: 0.00000
train epoch 285 avg loss: 0.45105 (A-MSE: 0.39841) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.72333 (A-MSE: 0.63224) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.72833 (A-MSE: 0.64575) avg lploss: 0.00000
*** Best Val Loss: 0.61191 	 Best Test Loss: 0.68865 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 0.50563 (A-MSE: 0.44671) avg lploss: 0.00000
train epoch 287 avg loss: 0.49948 (A-MSE: 0.44145) avg lploss: 0.00000
train epoch 288 avg loss: 0.44568 (A-MSE: 0.39070) avg lploss: 0.00000
train epoch 289 avg loss: 0.44437 (A-MSE: 0.38871) avg lploss: 0.00000
train epoch 290 avg loss: 0.42226 (A-MSE: 0.37286) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.74906 (A-MSE: 0.66587) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.79308 (A-MSE: 0.71391) avg lploss: 0.00000
*** Best Val Loss: 0.61191 	 Best Test Loss: 0.68865 	 Best epoch 275
EarlyStopping counter: 3 out of 50
train epoch 291 avg loss: 0.46778 (A-MSE: 0.41407) avg lploss: 0.00000
train epoch 292 avg loss: 0.49396 (A-MSE: 0.43914) avg lploss: 0.00000
train epoch 293 avg loss: 0.44786 (A-MSE: 0.39381) avg lploss: 0.00000
train epoch 294 avg loss: 0.42847 (A-MSE: 0.37784) avg lploss: 0.00000
train epoch 295 avg loss: 0.42843 (A-MSE: 0.38038) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.73407 (A-MSE: 0.63442) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.76699 (A-MSE: 0.67103) avg lploss: 0.00000
*** Best Val Loss: 0.61191 	 Best Test Loss: 0.68865 	 Best epoch 275
EarlyStopping counter: 4 out of 50
train epoch 296 avg loss: 0.47309 (A-MSE: 0.41733) avg lploss: 0.00000
train epoch 297 avg loss: 0.43247 (A-MSE: 0.37864) avg lploss: 0.00000
train epoch 298 avg loss: 0.43887 (A-MSE: 0.38675) avg lploss: 0.00000
train epoch 299 avg loss: 0.43914 (A-MSE: 0.38867) avg lploss: 0.00000
train epoch 300 avg loss: 0.42231 (A-MSE: 0.37636) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.69559 (A-MSE: 0.61188) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.72454 (A-MSE: 0.64385) avg lploss: 0.00000
*** Best Val Loss: 0.61191 	 Best Test Loss: 0.68865 	 Best epoch 275
EarlyStopping counter: 5 out of 50
train epoch 301 avg loss: 0.42672 (A-MSE: 0.37644) avg lploss: 0.00000
train epoch 302 avg loss: 0.41926 (A-MSE: 0.36784) avg lploss: 0.00000
train epoch 303 avg loss: 0.45197 (A-MSE: 0.40216) avg lploss: 0.00000
train epoch 304 avg loss: 0.42497 (A-MSE: 0.37421) avg lploss: 0.00000
train epoch 305 avg loss: 0.39850 (A-MSE: 0.35045) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.57745 (A-MSE: 0.50702) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.62480 (A-MSE: 0.55583) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
Validation loss decreased (0.611909 --> 0.577447).  Saving model ...
train epoch 306 avg loss: 0.41003 (A-MSE: 0.36287) avg lploss: 0.00000
train epoch 307 avg loss: 0.42631 (A-MSE: 0.37532) avg lploss: 0.00000
train epoch 308 avg loss: 0.46008 (A-MSE: 0.40907) avg lploss: 0.00000
train epoch 309 avg loss: 0.42291 (A-MSE: 0.37221) avg lploss: 0.00000
train epoch 310 avg loss: 0.38173 (A-MSE: 0.33673) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.62504 (A-MSE: 0.54870) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.66126 (A-MSE: 0.58759) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 1 out of 50
train epoch 311 avg loss: 0.40258 (A-MSE: 0.35385) avg lploss: 0.00000
train epoch 312 avg loss: 0.41219 (A-MSE: 0.36695) avg lploss: 0.00000
train epoch 313 avg loss: 0.43603 (A-MSE: 0.38448) avg lploss: 0.00000
train epoch 314 avg loss: 0.40549 (A-MSE: 0.35809) avg lploss: 0.00000
train epoch 315 avg loss: 0.42926 (A-MSE: 0.37825) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.70973 (A-MSE: 0.62611) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.74334 (A-MSE: 0.66424) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 2 out of 50
train epoch 316 avg loss: 0.48244 (A-MSE: 0.42957) avg lploss: 0.00000
train epoch 317 avg loss: 0.55229 (A-MSE: 0.48801) avg lploss: 0.00000
train epoch 318 avg loss: 0.46869 (A-MSE: 0.41410) avg lploss: 0.00000
train epoch 319 avg loss: 0.44622 (A-MSE: 0.39399) avg lploss: 0.00000
train epoch 320 avg loss: 0.47037 (A-MSE: 0.41542) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.72521 (A-MSE: 0.63932) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.75524 (A-MSE: 0.67538) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 3 out of 50
train epoch 321 avg loss: 0.43332 (A-MSE: 0.38414) avg lploss: 0.00000
train epoch 322 avg loss: 0.40018 (A-MSE: 0.35193) avg lploss: 0.00000
train epoch 323 avg loss: 0.38369 (A-MSE: 0.33775) avg lploss: 0.00000
train epoch 324 avg loss: 0.40286 (A-MSE: 0.35732) avg lploss: 0.00000
train epoch 325 avg loss: 0.41587 (A-MSE: 0.36840) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.65853 (A-MSE: 0.57155) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.68347 (A-MSE: 0.60434) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 4 out of 50
train epoch 326 avg loss: 0.36831 (A-MSE: 0.32383) avg lploss: 0.00000
train epoch 327 avg loss: 0.36780 (A-MSE: 0.32644) avg lploss: 0.00000
train epoch 328 avg loss: 0.42202 (A-MSE: 0.37542) avg lploss: 0.00000
train epoch 329 avg loss: 0.47343 (A-MSE: 0.42248) avg lploss: 0.00000
train epoch 330 avg loss: 0.46211 (A-MSE: 0.41163) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.67841 (A-MSE: 0.58491) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.70610 (A-MSE: 0.61365) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 5 out of 50
train epoch 331 avg loss: 0.42276 (A-MSE: 0.36917) avg lploss: 0.00000
train epoch 332 avg loss: 0.38576 (A-MSE: 0.33985) avg lploss: 0.00000
train epoch 333 avg loss: 0.43098 (A-MSE: 0.38528) avg lploss: 0.00000
train epoch 334 avg loss: 0.40814 (A-MSE: 0.36066) avg lploss: 0.00000
train epoch 335 avg loss: 0.37824 (A-MSE: 0.33454) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.62082 (A-MSE: 0.54041) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.65662 (A-MSE: 0.58098) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 6 out of 50
train epoch 336 avg loss: 0.36707 (A-MSE: 0.32613) avg lploss: 0.00000
train epoch 337 avg loss: 0.36997 (A-MSE: 0.32376) avg lploss: 0.00000
train epoch 338 avg loss: 0.41094 (A-MSE: 0.36700) avg lploss: 0.00000
train epoch 339 avg loss: 0.41937 (A-MSE: 0.37329) avg lploss: 0.00000
train epoch 340 avg loss: 0.38027 (A-MSE: 0.33294) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.67048 (A-MSE: 0.58600) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.69249 (A-MSE: 0.61769) avg lploss: 0.00000
*** Best Val Loss: 0.57745 	 Best Test Loss: 0.62480 	 Best epoch 305
EarlyStopping counter: 7 out of 50
train epoch 341 avg loss: 0.43411 (A-MSE: 0.38675) avg lploss: 0.00000
train epoch 342 avg loss: 0.40255 (A-MSE: 0.35878) avg lploss: 0.00000
train epoch 343 avg loss: 0.38690 (A-MSE: 0.34003) avg lploss: 0.00000
train epoch 344 avg loss: 0.37263 (A-MSE: 0.32928) avg lploss: 0.00000
train epoch 345 avg loss: 0.36913 (A-MSE: 0.32746) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.54952 (A-MSE: 0.48119) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.60297 (A-MSE: 0.53635) avg lploss: 0.00000
*** Best Val Loss: 0.54952 	 Best Test Loss: 0.60297 	 Best epoch 345
Validation loss decreased (0.577447 --> 0.549520).  Saving model ...
train epoch 346 avg loss: 0.37724 (A-MSE: 0.33452) avg lploss: 0.00000
train epoch 347 avg loss: 0.38942 (A-MSE: 0.34546) avg lploss: 0.00000
train epoch 348 avg loss: 0.48742 (A-MSE: 0.43264) avg lploss: 0.00000
train epoch 349 avg loss: 0.41888 (A-MSE: 0.37252) avg lploss: 0.00000
train epoch 350 avg loss: 0.38809 (A-MSE: 0.34215) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.61934 (A-MSE: 0.54114) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.67587 (A-MSE: 0.59452) avg lploss: 0.00000
*** Best Val Loss: 0.54952 	 Best Test Loss: 0.60297 	 Best epoch 345
EarlyStopping counter: 1 out of 50
train epoch 351 avg loss: 0.35443 (A-MSE: 0.31309) avg lploss: 0.00000
train epoch 352 avg loss: 0.37947 (A-MSE: 0.34030) avg lploss: 0.00000
train epoch 353 avg loss: 0.37574 (A-MSE: 0.33081) avg lploss: 0.00000
train epoch 354 avg loss: 0.35667 (A-MSE: 0.31388) avg lploss: 0.00000
train epoch 355 avg loss: 0.34705 (A-MSE: 0.30875) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.53503 (A-MSE: 0.46543) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.60026 (A-MSE: 0.52702) avg lploss: 0.00000
*** Best Val Loss: 0.53503 	 Best Test Loss: 0.60026 	 Best epoch 355
Validation loss decreased (0.549520 --> 0.535035).  Saving model ...
train epoch 356 avg loss: 0.39376 (A-MSE: 0.35049) avg lploss: 0.00000
train epoch 357 avg loss: 0.36173 (A-MSE: 0.31945) avg lploss: 0.00000
train epoch 358 avg loss: 0.34463 (A-MSE: 0.30507) avg lploss: 0.00000
train epoch 359 avg loss: 0.36748 (A-MSE: 0.32410) avg lploss: 0.00000
train epoch 360 avg loss: 0.37382 (A-MSE: 0.33066) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.53888 (A-MSE: 0.47245) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.61299 (A-MSE: 0.54581) avg lploss: 0.00000
*** Best Val Loss: 0.53503 	 Best Test Loss: 0.60026 	 Best epoch 355
EarlyStopping counter: 1 out of 50
train epoch 361 avg loss: 0.36199 (A-MSE: 0.32032) avg lploss: 0.00000
train epoch 362 avg loss: 0.37224 (A-MSE: 0.32732) avg lploss: 0.00000
train epoch 363 avg loss: 0.32680 (A-MSE: 0.28973) avg lploss: 0.00000
train epoch 364 avg loss: 0.34722 (A-MSE: 0.30862) avg lploss: 0.00000
train epoch 365 avg loss: 0.41029 (A-MSE: 0.36689) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.53856 (A-MSE: 0.48448) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.60394 (A-MSE: 0.54707) avg lploss: 0.00000
*** Best Val Loss: 0.53503 	 Best Test Loss: 0.60026 	 Best epoch 355
EarlyStopping counter: 2 out of 50
train epoch 366 avg loss: 0.40470 (A-MSE: 0.35943) avg lploss: 0.00000
train epoch 367 avg loss: 0.38349 (A-MSE: 0.34068) avg lploss: 0.00000
train epoch 368 avg loss: 0.37242 (A-MSE: 0.32951) avg lploss: 0.00000
train epoch 369 avg loss: 0.39192 (A-MSE: 0.34565) avg lploss: 0.00000
train epoch 370 avg loss: 0.41209 (A-MSE: 0.36852) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.58643 (A-MSE: 0.51160) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.62294 (A-MSE: 0.55393) avg lploss: 0.00000
*** Best Val Loss: 0.53503 	 Best Test Loss: 0.60026 	 Best epoch 355
EarlyStopping counter: 3 out of 50
train epoch 371 avg loss: 0.35898 (A-MSE: 0.31748) avg lploss: 0.00000
train epoch 372 avg loss: 0.34652 (A-MSE: 0.30684) avg lploss: 0.00000
train epoch 373 avg loss: 0.36594 (A-MSE: 0.32634) avg lploss: 0.00000
train epoch 374 avg loss: 0.32640 (A-MSE: 0.28847) avg lploss: 0.00000
train epoch 375 avg loss: 0.34929 (A-MSE: 0.30958) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.53784 (A-MSE: 0.47033) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.57112 (A-MSE: 0.50555) avg lploss: 0.00000
*** Best Val Loss: 0.53503 	 Best Test Loss: 0.60026 	 Best epoch 355
EarlyStopping counter: 4 out of 50
train epoch 376 avg loss: 0.34553 (A-MSE: 0.30509) avg lploss: 0.00000
train epoch 377 avg loss: 0.37441 (A-MSE: 0.33390) avg lploss: 0.00000
train epoch 378 avg loss: 0.35320 (A-MSE: 0.31111) avg lploss: 0.00000
train epoch 379 avg loss: 0.36297 (A-MSE: 0.32129) avg lploss: 0.00000
train epoch 380 avg loss: 0.33565 (A-MSE: 0.29740) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.51447 (A-MSE: 0.45035) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.55386 (A-MSE: 0.48850) avg lploss: 0.00000
*** Best Val Loss: 0.51447 	 Best Test Loss: 0.55386 	 Best epoch 380
Validation loss decreased (0.535035 --> 0.514474).  Saving model ...
train epoch 381 avg loss: 0.34178 (A-MSE: 0.30177) avg lploss: 0.00000
train epoch 382 avg loss: 0.35618 (A-MSE: 0.31731) avg lploss: 0.00000
train epoch 383 avg loss: 0.34776 (A-MSE: 0.30847) avg lploss: 0.00000
train epoch 384 avg loss: 0.37255 (A-MSE: 0.32958) avg lploss: 0.00000
train epoch 385 avg loss: 0.36470 (A-MSE: 0.32186) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.56635 (A-MSE: 0.49783) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.60232 (A-MSE: 0.53691) avg lploss: 0.00000
*** Best Val Loss: 0.51447 	 Best Test Loss: 0.55386 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.38786 (A-MSE: 0.34586) avg lploss: 0.00000
train epoch 387 avg loss: 0.34977 (A-MSE: 0.30904) avg lploss: 0.00000
train epoch 388 avg loss: 0.34505 (A-MSE: 0.30765) avg lploss: 0.00000
train epoch 389 avg loss: 0.38885 (A-MSE: 0.34399) avg lploss: 0.00000
train epoch 390 avg loss: 0.35074 (A-MSE: 0.31031) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.55819 (A-MSE: 0.49325) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.59153 (A-MSE: 0.52427) avg lploss: 0.00000
*** Best Val Loss: 0.51447 	 Best Test Loss: 0.55386 	 Best epoch 380
EarlyStopping counter: 2 out of 50
train epoch 391 avg loss: 0.35312 (A-MSE: 0.31200) avg lploss: 0.00000
train epoch 392 avg loss: 0.38022 (A-MSE: 0.33578) avg lploss: 0.00000
train epoch 393 avg loss: 0.34970 (A-MSE: 0.30953) avg lploss: 0.00000
train epoch 394 avg loss: 0.33085 (A-MSE: 0.29275) avg lploss: 0.00000
train epoch 395 avg loss: 0.31369 (A-MSE: 0.27771) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.66163 (A-MSE: 0.60189) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.66491 (A-MSE: 0.60784) avg lploss: 0.00000
*** Best Val Loss: 0.51447 	 Best Test Loss: 0.55386 	 Best epoch 380
EarlyStopping counter: 3 out of 50
train epoch 396 avg loss: 0.36748 (A-MSE: 0.32839) avg lploss: 0.00000
train epoch 397 avg loss: 0.32369 (A-MSE: 0.28702) avg lploss: 0.00000
train epoch 398 avg loss: 0.36790 (A-MSE: 0.32637) avg lploss: 0.00000
train epoch 399 avg loss: 0.31147 (A-MSE: 0.27632) avg lploss: 0.00000
train epoch 400 avg loss: 0.31521 (A-MSE: 0.27957) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.51561 (A-MSE: 0.45122) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.58329 (A-MSE: 0.51326) avg lploss: 0.00000
*** Best Val Loss: 0.51447 	 Best Test Loss: 0.55386 	 Best epoch 380
EarlyStopping counter: 4 out of 50
train epoch 401 avg loss: 0.32818 (A-MSE: 0.28943) avg lploss: 0.00000
train epoch 402 avg loss: 0.32881 (A-MSE: 0.29065) avg lploss: 0.00000
train epoch 403 avg loss: 0.32128 (A-MSE: 0.28483) avg lploss: 0.00000
train epoch 404 avg loss: 0.36571 (A-MSE: 0.32645) avg lploss: 0.00000
train epoch 405 avg loss: 0.33513 (A-MSE: 0.29689) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.49812 (A-MSE: 0.44394) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.55344 (A-MSE: 0.49389) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
Validation loss decreased (0.514474 --> 0.498116).  Saving model ...
train epoch 406 avg loss: 0.32911 (A-MSE: 0.29082) avg lploss: 0.00000
train epoch 407 avg loss: 0.31378 (A-MSE: 0.27780) avg lploss: 0.00000
train epoch 408 avg loss: 0.32180 (A-MSE: 0.28523) avg lploss: 0.00000
train epoch 409 avg loss: 0.29049 (A-MSE: 0.25677) avg lploss: 0.00000
train epoch 410 avg loss: 0.28315 (A-MSE: 0.24972) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.50444 (A-MSE: 0.43851) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.54316 (A-MSE: 0.47851) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 1 out of 50
train epoch 411 avg loss: 0.29994 (A-MSE: 0.26485) avg lploss: 0.00000
train epoch 412 avg loss: 0.36754 (A-MSE: 0.32607) avg lploss: 0.00000
train epoch 413 avg loss: 0.32304 (A-MSE: 0.28598) avg lploss: 0.00000
train epoch 414 avg loss: 0.37980 (A-MSE: 0.33674) avg lploss: 0.00000
train epoch 415 avg loss: 0.34737 (A-MSE: 0.30800) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.55648 (A-MSE: 0.49055) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.59924 (A-MSE: 0.54010) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 2 out of 50
train epoch 416 avg loss: 0.31939 (A-MSE: 0.28469) avg lploss: 0.00000
train epoch 417 avg loss: 0.32373 (A-MSE: 0.28643) avg lploss: 0.00000
train epoch 418 avg loss: 0.29334 (A-MSE: 0.26050) avg lploss: 0.00000
train epoch 419 avg loss: 0.28582 (A-MSE: 0.25483) avg lploss: 0.00000
train epoch 420 avg loss: 0.32488 (A-MSE: 0.28694) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.67864 (A-MSE: 0.59866) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.72389 (A-MSE: 0.63114) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 3 out of 50
train epoch 421 avg loss: 0.39547 (A-MSE: 0.35189) avg lploss: 0.00000
train epoch 422 avg loss: 0.36745 (A-MSE: 0.32447) avg lploss: 0.00000
train epoch 423 avg loss: 0.33410 (A-MSE: 0.29453) avg lploss: 0.00000
train epoch 424 avg loss: 0.39150 (A-MSE: 0.34893) avg lploss: 0.00000
train epoch 425 avg loss: 0.39030 (A-MSE: 0.34744) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.60078 (A-MSE: 0.52605) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.61724 (A-MSE: 0.54245) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 4 out of 50
train epoch 426 avg loss: 0.31431 (A-MSE: 0.27713) avg lploss: 0.00000
train epoch 427 avg loss: 0.28762 (A-MSE: 0.25380) avg lploss: 0.00000
train epoch 428 avg loss: 0.28933 (A-MSE: 0.25629) avg lploss: 0.00000
train epoch 429 avg loss: 0.29193 (A-MSE: 0.25731) avg lploss: 0.00000
train epoch 430 avg loss: 0.29124 (A-MSE: 0.25888) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.52525 (A-MSE: 0.46909) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.54988 (A-MSE: 0.48737) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 5 out of 50
train epoch 431 avg loss: 0.31554 (A-MSE: 0.28037) avg lploss: 0.00000
train epoch 432 avg loss: 0.30423 (A-MSE: 0.26946) avg lploss: 0.00000
train epoch 433 avg loss: 0.33526 (A-MSE: 0.29840) avg lploss: 0.00000
train epoch 434 avg loss: 0.37596 (A-MSE: 0.33631) avg lploss: 0.00000
train epoch 435 avg loss: 0.33335 (A-MSE: 0.29469) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.60134 (A-MSE: 0.53112) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.61709 (A-MSE: 0.54397) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 6 out of 50
train epoch 436 avg loss: 0.28954 (A-MSE: 0.25834) avg lploss: 0.00000
train epoch 437 avg loss: 0.29805 (A-MSE: 0.26424) avg lploss: 0.00000
train epoch 438 avg loss: 0.28485 (A-MSE: 0.25210) avg lploss: 0.00000
train epoch 439 avg loss: 0.28214 (A-MSE: 0.25177) avg lploss: 0.00000
train epoch 440 avg loss: 0.29556 (A-MSE: 0.26141) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.49903 (A-MSE: 0.43722) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.53170 (A-MSE: 0.46465) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 7 out of 50
train epoch 441 avg loss: 0.31828 (A-MSE: 0.28281) avg lploss: 0.00000
train epoch 442 avg loss: 0.32897 (A-MSE: 0.29160) avg lploss: 0.00000
train epoch 443 avg loss: 0.30063 (A-MSE: 0.26809) avg lploss: 0.00000
train epoch 444 avg loss: 0.28792 (A-MSE: 0.25422) avg lploss: 0.00000
train epoch 445 avg loss: 0.28915 (A-MSE: 0.25565) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.59393 (A-MSE: 0.51207) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.59911 (A-MSE: 0.52073) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 8 out of 50
train epoch 446 avg loss: 0.28751 (A-MSE: 0.25477) avg lploss: 0.00000
train epoch 447 avg loss: 0.29582 (A-MSE: 0.26044) avg lploss: 0.00000
train epoch 448 avg loss: 0.31839 (A-MSE: 0.28495) avg lploss: 0.00000
train epoch 449 avg loss: 0.29827 (A-MSE: 0.26775) avg lploss: 0.00000
train epoch 450 avg loss: 0.30745 (A-MSE: 0.27253) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.50891 (A-MSE: 0.45094) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.55997 (A-MSE: 0.49396) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 9 out of 50
train epoch 451 avg loss: 0.29740 (A-MSE: 0.26402) avg lploss: 0.00000
train epoch 452 avg loss: 0.30074 (A-MSE: 0.26499) avg lploss: 0.00000
train epoch 453 avg loss: 0.29362 (A-MSE: 0.26312) avg lploss: 0.00000
train epoch 454 avg loss: 0.28574 (A-MSE: 0.25262) avg lploss: 0.00000
train epoch 455 avg loss: 0.31647 (A-MSE: 0.28158) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.58041 (A-MSE: 0.51096) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.59896 (A-MSE: 0.53106) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 10 out of 50
train epoch 456 avg loss: 0.31492 (A-MSE: 0.27919) avg lploss: 0.00000
train epoch 457 avg loss: 0.30867 (A-MSE: 0.27440) avg lploss: 0.00000
train epoch 458 avg loss: 0.27029 (A-MSE: 0.23977) avg lploss: 0.00000
train epoch 459 avg loss: 0.28096 (A-MSE: 0.24863) avg lploss: 0.00000
train epoch 460 avg loss: 0.38288 (A-MSE: 0.34177) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.68186 (A-MSE: 0.58442) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.71660 (A-MSE: 0.62555) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 11 out of 50
train epoch 461 avg loss: 0.37151 (A-MSE: 0.32961) avg lploss: 0.00000
train epoch 462 avg loss: 0.30491 (A-MSE: 0.27166) avg lploss: 0.00000
train epoch 463 avg loss: 0.28194 (A-MSE: 0.24948) avg lploss: 0.00000
train epoch 464 avg loss: 0.29121 (A-MSE: 0.25987) avg lploss: 0.00000
train epoch 465 avg loss: 0.27893 (A-MSE: 0.24720) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.55947 (A-MSE: 0.49367) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.59683 (A-MSE: 0.52088) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 12 out of 50
train epoch 466 avg loss: 0.28330 (A-MSE: 0.25152) avg lploss: 0.00000
train epoch 467 avg loss: 0.30037 (A-MSE: 0.26674) avg lploss: 0.00000
train epoch 468 avg loss: 0.27456 (A-MSE: 0.24274) avg lploss: 0.00000
train epoch 469 avg loss: 0.28515 (A-MSE: 0.25342) avg lploss: 0.00000
train epoch 470 avg loss: 0.28202 (A-MSE: 0.25167) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.50443 (A-MSE: 0.44943) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.56525 (A-MSE: 0.50578) avg lploss: 0.00000
*** Best Val Loss: 0.49812 	 Best Test Loss: 0.55344 	 Best epoch 405
EarlyStopping counter: 13 out of 50
train epoch 471 avg loss: 0.30079 (A-MSE: 0.26707) avg lploss: 0.00000
train epoch 472 avg loss: 0.29804 (A-MSE: 0.26511) avg lploss: 0.00000
train epoch 473 avg loss: 0.27482 (A-MSE: 0.24357) avg lploss: 0.00000
train epoch 474 avg loss: 0.26042 (A-MSE: 0.23085) avg lploss: 0.00000
train epoch 475 avg loss: 0.29694 (A-MSE: 0.26369) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.48446 (A-MSE: 0.43345) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.54533 (A-MSE: 0.48445) avg lploss: 0.00000
*** Best Val Loss: 0.48446 	 Best Test Loss: 0.54533 	 Best epoch 475
Validation loss decreased (0.498116 --> 0.484458).  Saving model ...
train epoch 476 avg loss: 0.29293 (A-MSE: 0.25740) avg lploss: 0.00000
train epoch 477 avg loss: 0.29667 (A-MSE: 0.26538) avg lploss: 0.00000
train epoch 478 avg loss: 0.26884 (A-MSE: 0.23831) avg lploss: 0.00000
train epoch 479 avg loss: 0.27786 (A-MSE: 0.24708) avg lploss: 0.00000
train epoch 480 avg loss: 0.28956 (A-MSE: 0.25844) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.51344 (A-MSE: 0.44983) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.53979 (A-MSE: 0.47478) avg lploss: 0.00000
*** Best Val Loss: 0.48446 	 Best Test Loss: 0.54533 	 Best epoch 475
EarlyStopping counter: 1 out of 50
train epoch 481 avg loss: 0.25122 (A-MSE: 0.22031) avg lploss: 0.00000
train epoch 482 avg loss: 0.26613 (A-MSE: 0.23675) avg lploss: 0.00000
train epoch 483 avg loss: 0.25805 (A-MSE: 0.22806) avg lploss: 0.00000
train epoch 484 avg loss: 0.26972 (A-MSE: 0.24073) avg lploss: 0.00000
train epoch 485 avg loss: 0.24859 (A-MSE: 0.22015) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.45993 (A-MSE: 0.40415) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.50723 (A-MSE: 0.44342) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
Validation loss decreased (0.484458 --> 0.459933).  Saving model ...
train epoch 486 avg loss: 0.25324 (A-MSE: 0.22521) avg lploss: 0.00000
train epoch 487 avg loss: 0.24902 (A-MSE: 0.22123) avg lploss: 0.00000
train epoch 488 avg loss: 0.26493 (A-MSE: 0.23590) avg lploss: 0.00000
train epoch 489 avg loss: 0.24952 (A-MSE: 0.21971) avg lploss: 0.00000
train epoch 490 avg loss: 0.24594 (A-MSE: 0.21837) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.51096 (A-MSE: 0.45580) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.53500 (A-MSE: 0.47435) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 1 out of 50
train epoch 491 avg loss: 0.25134 (A-MSE: 0.22183) avg lploss: 0.00000
train epoch 492 avg loss: 0.26567 (A-MSE: 0.23535) avg lploss: 0.00000
train epoch 493 avg loss: 0.29456 (A-MSE: 0.26383) avg lploss: 0.00000
train epoch 494 avg loss: 0.29569 (A-MSE: 0.26261) avg lploss: 0.00000
train epoch 495 avg loss: 0.28535 (A-MSE: 0.25157) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.51745 (A-MSE: 0.46118) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.59892 (A-MSE: 0.53028) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 2 out of 50
train epoch 496 avg loss: 0.27940 (A-MSE: 0.24863) avg lploss: 0.00000
train epoch 497 avg loss: 0.24604 (A-MSE: 0.21820) avg lploss: 0.00000
train epoch 498 avg loss: 0.25523 (A-MSE: 0.22740) avg lploss: 0.00000
train epoch 499 avg loss: 0.24803 (A-MSE: 0.21925) avg lploss: 0.00000
train epoch 500 avg loss: 0.28423 (A-MSE: 0.25203) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.56787 (A-MSE: 0.49727) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.58962 (A-MSE: 0.52035) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 3 out of 50
train epoch 501 avg loss: 0.26091 (A-MSE: 0.23085) avg lploss: 0.00000
train epoch 502 avg loss: 0.22533 (A-MSE: 0.19864) avg lploss: 0.00000
train epoch 503 avg loss: 0.23753 (A-MSE: 0.21204) avg lploss: 0.00000
train epoch 504 avg loss: 0.23692 (A-MSE: 0.20936) avg lploss: 0.00000
train epoch 505 avg loss: 0.25020 (A-MSE: 0.22219) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.53216 (A-MSE: 0.46996) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.53832 (A-MSE: 0.47636) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 4 out of 50
train epoch 506 avg loss: 0.24388 (A-MSE: 0.21692) avg lploss: 0.00000
train epoch 507 avg loss: 0.27234 (A-MSE: 0.24245) avg lploss: 0.00000
train epoch 508 avg loss: 0.24685 (A-MSE: 0.21907) avg lploss: 0.00000
train epoch 509 avg loss: 0.23787 (A-MSE: 0.21169) avg lploss: 0.00000
train epoch 510 avg loss: 0.22135 (A-MSE: 0.19668) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.46187 (A-MSE: 0.41036) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.51985 (A-MSE: 0.46006) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 5 out of 50
train epoch 511 avg loss: 0.25366 (A-MSE: 0.22700) avg lploss: 0.00000
train epoch 512 avg loss: 0.30903 (A-MSE: 0.27381) avg lploss: 0.00000
train epoch 513 avg loss: 0.28995 (A-MSE: 0.25923) avg lploss: 0.00000
train epoch 514 avg loss: 0.26795 (A-MSE: 0.24021) avg lploss: 0.00000
train epoch 515 avg loss: 0.25854 (A-MSE: 0.23015) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.51988 (A-MSE: 0.45534) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.54755 (A-MSE: 0.48080) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 6 out of 50
train epoch 516 avg loss: 0.29696 (A-MSE: 0.26327) avg lploss: 0.00000
train epoch 517 avg loss: 0.28643 (A-MSE: 0.25438) avg lploss: 0.00000
train epoch 518 avg loss: 0.26024 (A-MSE: 0.22859) avg lploss: 0.00000
train epoch 519 avg loss: 0.26864 (A-MSE: 0.23971) avg lploss: 0.00000
train epoch 520 avg loss: 0.34888 (A-MSE: 0.31122) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.68125 (A-MSE: 0.61132) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.66713 (A-MSE: 0.60004) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 7 out of 50
train epoch 521 avg loss: 0.31756 (A-MSE: 0.28014) avg lploss: 0.00000
train epoch 522 avg loss: 0.27397 (A-MSE: 0.24339) avg lploss: 0.00000
train epoch 523 avg loss: 0.24201 (A-MSE: 0.21506) avg lploss: 0.00000
train epoch 524 avg loss: 0.24098 (A-MSE: 0.21512) avg lploss: 0.00000
train epoch 525 avg loss: 0.24902 (A-MSE: 0.22186) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.52943 (A-MSE: 0.46816) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.53967 (A-MSE: 0.47485) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 8 out of 50
train epoch 526 avg loss: 0.24393 (A-MSE: 0.21638) avg lploss: 0.00000
train epoch 527 avg loss: 0.27053 (A-MSE: 0.24095) avg lploss: 0.00000
train epoch 528 avg loss: 0.24652 (A-MSE: 0.21995) avg lploss: 0.00000
train epoch 529 avg loss: 0.22417 (A-MSE: 0.19840) avg lploss: 0.00000
train epoch 530 avg loss: 0.21961 (A-MSE: 0.19417) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.48576 (A-MSE: 0.43316) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.50607 (A-MSE: 0.45127) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 9 out of 50
train epoch 531 avg loss: 0.23717 (A-MSE: 0.21154) avg lploss: 0.00000
train epoch 532 avg loss: 0.23633 (A-MSE: 0.21061) avg lploss: 0.00000
train epoch 533 avg loss: 0.24607 (A-MSE: 0.21978) avg lploss: 0.00000
train epoch 534 avg loss: 0.21406 (A-MSE: 0.19273) avg lploss: 0.00000
train epoch 535 avg loss: 0.22924 (A-MSE: 0.20294) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.55209 (A-MSE: 0.48533) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.55545 (A-MSE: 0.48702) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 10 out of 50
train epoch 536 avg loss: 0.25168 (A-MSE: 0.22300) avg lploss: 0.00000
train epoch 537 avg loss: 0.26935 (A-MSE: 0.24059) avg lploss: 0.00000
train epoch 538 avg loss: 0.26636 (A-MSE: 0.23621) avg lploss: 0.00000
train epoch 539 avg loss: 0.23655 (A-MSE: 0.21104) avg lploss: 0.00000
train epoch 540 avg loss: 0.26057 (A-MSE: 0.23070) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.54329 (A-MSE: 0.48067) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.56748 (A-MSE: 0.50651) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 11 out of 50
train epoch 541 avg loss: 0.26911 (A-MSE: 0.23916) avg lploss: 0.00000
train epoch 542 avg loss: 0.23833 (A-MSE: 0.21275) avg lploss: 0.00000
train epoch 543 avg loss: 0.20608 (A-MSE: 0.18218) avg lploss: 0.00000
train epoch 544 avg loss: 0.21923 (A-MSE: 0.19491) avg lploss: 0.00000
train epoch 545 avg loss: 0.22083 (A-MSE: 0.19890) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.49036 (A-MSE: 0.43626) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.49173 (A-MSE: 0.43695) avg lploss: 0.00000
*** Best Val Loss: 0.45993 	 Best Test Loss: 0.50723 	 Best epoch 485
EarlyStopping counter: 12 out of 50
train epoch 546 avg loss: 0.25606 (A-MSE: 0.23008) avg lploss: 0.00000
train epoch 547 avg loss: 0.31073 (A-MSE: 0.27561) avg lploss: 0.00000
train epoch 548 avg loss: 0.25485 (A-MSE: 0.22574) avg lploss: 0.00000
train epoch 549 avg loss: 0.22555 (A-MSE: 0.20143) avg lploss: 0.00000
train epoch 550 avg loss: 0.21244 (A-MSE: 0.18970) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.44554 (A-MSE: 0.40528) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.50172 (A-MSE: 0.44825) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
Validation loss decreased (0.459933 --> 0.445538).  Saving model ...
train epoch 551 avg loss: 0.23868 (A-MSE: 0.21404) avg lploss: 0.00000
train epoch 552 avg loss: 0.25521 (A-MSE: 0.22780) avg lploss: 0.00000
train epoch 553 avg loss: 0.26484 (A-MSE: 0.23359) avg lploss: 0.00000
train epoch 554 avg loss: 0.25296 (A-MSE: 0.22782) avg lploss: 0.00000
train epoch 555 avg loss: 0.25291 (A-MSE: 0.21921) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.47789 (A-MSE: 0.41643) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.53701 (A-MSE: 0.46739) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 1 out of 50
train epoch 556 avg loss: 0.28029 (A-MSE: 0.24570) avg lploss: 0.00000
train epoch 557 avg loss: 0.27175 (A-MSE: 0.24131) avg lploss: 0.00000
train epoch 558 avg loss: 0.25743 (A-MSE: 0.22961) avg lploss: 0.00000
train epoch 559 avg loss: 0.25263 (A-MSE: 0.22390) avg lploss: 0.00000
train epoch 560 avg loss: 0.21243 (A-MSE: 0.18760) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.51986 (A-MSE: 0.46589) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.52814 (A-MSE: 0.46814) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 2 out of 50
train epoch 561 avg loss: 0.20842 (A-MSE: 0.18576) avg lploss: 0.00000
train epoch 562 avg loss: 0.21359 (A-MSE: 0.18928) avg lploss: 0.00000
train epoch 563 avg loss: 0.22827 (A-MSE: 0.20461) avg lploss: 0.00000
train epoch 564 avg loss: 0.23579 (A-MSE: 0.20871) avg lploss: 0.00000
train epoch 565 avg loss: 0.23484 (A-MSE: 0.20925) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.45129 (A-MSE: 0.39651) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.49638 (A-MSE: 0.43499) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 3 out of 50
train epoch 566 avg loss: 0.20812 (A-MSE: 0.18429) avg lploss: 0.00000
train epoch 567 avg loss: 0.23108 (A-MSE: 0.20527) avg lploss: 0.00000
train epoch 568 avg loss: 0.24642 (A-MSE: 0.21949) avg lploss: 0.00000
train epoch 569 avg loss: 0.23469 (A-MSE: 0.20848) avg lploss: 0.00000
train epoch 570 avg loss: 0.24762 (A-MSE: 0.22096) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.51894 (A-MSE: 0.46346) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.55019 (A-MSE: 0.49197) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 4 out of 50
train epoch 571 avg loss: 0.23555 (A-MSE: 0.20926) avg lploss: 0.00000
train epoch 572 avg loss: 0.22657 (A-MSE: 0.20052) avg lploss: 0.00000
train epoch 573 avg loss: 0.24958 (A-MSE: 0.22317) avg lploss: 0.00000
train epoch 574 avg loss: 0.23011 (A-MSE: 0.20500) avg lploss: 0.00000
train epoch 575 avg loss: 0.21064 (A-MSE: 0.18714) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.48855 (A-MSE: 0.42901) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.50773 (A-MSE: 0.44892) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 5 out of 50
train epoch 576 avg loss: 0.22713 (A-MSE: 0.20320) avg lploss: 0.00000
train epoch 577 avg loss: 0.22739 (A-MSE: 0.20101) avg lploss: 0.00000
train epoch 578 avg loss: 0.21512 (A-MSE: 0.19083) avg lploss: 0.00000
train epoch 579 avg loss: 0.20476 (A-MSE: 0.18372) avg lploss: 0.00000
train epoch 580 avg loss: 0.21542 (A-MSE: 0.19114) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.48568 (A-MSE: 0.42982) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.49053 (A-MSE: 0.43310) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 6 out of 50
train epoch 581 avg loss: 0.20911 (A-MSE: 0.18634) avg lploss: 0.00000
train epoch 582 avg loss: 0.20925 (A-MSE: 0.18568) avg lploss: 0.00000
train epoch 583 avg loss: 0.19808 (A-MSE: 0.17657) avg lploss: 0.00000
train epoch 584 avg loss: 0.21616 (A-MSE: 0.19247) avg lploss: 0.00000
train epoch 585 avg loss: 0.22133 (A-MSE: 0.19688) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.59482 (A-MSE: 0.52331) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.56495 (A-MSE: 0.49364) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 7 out of 50
train epoch 586 avg loss: 0.20886 (A-MSE: 0.18600) avg lploss: 0.00000
train epoch 587 avg loss: 0.21424 (A-MSE: 0.19020) avg lploss: 0.00000
train epoch 588 avg loss: 0.23078 (A-MSE: 0.20604) avg lploss: 0.00000
train epoch 589 avg loss: 0.24209 (A-MSE: 0.21398) avg lploss: 0.00000
train epoch 590 avg loss: 0.25042 (A-MSE: 0.22332) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.50126 (A-MSE: 0.44140) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.55059 (A-MSE: 0.48792) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 8 out of 50
train epoch 591 avg loss: 0.21845 (A-MSE: 0.19351) avg lploss: 0.00000
train epoch 592 avg loss: 0.21654 (A-MSE: 0.19347) avg lploss: 0.00000
train epoch 593 avg loss: 0.20602 (A-MSE: 0.18339) avg lploss: 0.00000
train epoch 594 avg loss: 0.19295 (A-MSE: 0.17275) avg lploss: 0.00000
train epoch 595 avg loss: 0.24797 (A-MSE: 0.22223) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.61922 (A-MSE: 0.55020) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.63798 (A-MSE: 0.55875) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 9 out of 50
train epoch 596 avg loss: 0.21941 (A-MSE: 0.19521) avg lploss: 0.00000
train epoch 597 avg loss: 0.22343 (A-MSE: 0.19870) avg lploss: 0.00000
train epoch 598 avg loss: 0.21609 (A-MSE: 0.19228) avg lploss: 0.00000
train epoch 599 avg loss: 0.23359 (A-MSE: 0.20829) avg lploss: 0.00000
train epoch 600 avg loss: 0.18586 (A-MSE: 0.16542) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.47736 (A-MSE: 0.42367) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.46823 (A-MSE: 0.41482) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 10 out of 50
train epoch 601 avg loss: 0.18953 (A-MSE: 0.16857) avg lploss: 0.00000
train epoch 602 avg loss: 0.21658 (A-MSE: 0.19200) avg lploss: 0.00000
train epoch 603 avg loss: 0.19200 (A-MSE: 0.17058) avg lploss: 0.00000
train epoch 604 avg loss: 0.21338 (A-MSE: 0.19029) avg lploss: 0.00000
train epoch 605 avg loss: 0.19288 (A-MSE: 0.17110) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.59515 (A-MSE: 0.52967) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.56704 (A-MSE: 0.50289) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 11 out of 50
train epoch 606 avg loss: 0.20914 (A-MSE: 0.18682) avg lploss: 0.00000
train epoch 607 avg loss: 0.22478 (A-MSE: 0.20065) avg lploss: 0.00000
train epoch 608 avg loss: 0.20005 (A-MSE: 0.17749) avg lploss: 0.00000
train epoch 609 avg loss: 0.21129 (A-MSE: 0.18662) avg lploss: 0.00000
train epoch 610 avg loss: 0.21417 (A-MSE: 0.19204) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.49403 (A-MSE: 0.42820) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.49820 (A-MSE: 0.43832) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 12 out of 50
train epoch 611 avg loss: 0.21551 (A-MSE: 0.19074) avg lploss: 0.00000
train epoch 612 avg loss: 0.22373 (A-MSE: 0.19814) avg lploss: 0.00000
train epoch 613 avg loss: 0.20875 (A-MSE: 0.18638) avg lploss: 0.00000
train epoch 614 avg loss: 0.19221 (A-MSE: 0.16980) avg lploss: 0.00000
train epoch 615 avg loss: 0.19620 (A-MSE: 0.17463) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.50631 (A-MSE: 0.44706) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.52334 (A-MSE: 0.46075) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 13 out of 50
train epoch 616 avg loss: 0.19023 (A-MSE: 0.16963) avg lploss: 0.00000
train epoch 617 avg loss: 0.18250 (A-MSE: 0.16144) avg lploss: 0.00000
train epoch 618 avg loss: 0.18927 (A-MSE: 0.16860) avg lploss: 0.00000
train epoch 619 avg loss: 0.18823 (A-MSE: 0.16668) avg lploss: 0.00000
train epoch 620 avg loss: 0.22005 (A-MSE: 0.19728) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.51175 (A-MSE: 0.44630) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.54723 (A-MSE: 0.48354) avg lploss: 0.00000
*** Best Val Loss: 0.44554 	 Best Test Loss: 0.50172 	 Best epoch 550
EarlyStopping counter: 14 out of 50
train epoch 621 avg loss: 0.26564 (A-MSE: 0.23780) avg lploss: 0.00000
train epoch 622 avg loss: 0.24408 (A-MSE: 0.21615) avg lploss: 0.00000
train epoch 623 avg loss: 0.24483 (A-MSE: 0.21755) avg lploss: 0.00000
train epoch 624 avg loss: 0.23373 (A-MSE: 0.20743) avg lploss: 0.00000
train epoch 625 avg loss: 0.22401 (A-MSE: 0.20032) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.44444 (A-MSE: 0.39587) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.47686 (A-MSE: 0.42609) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
Validation loss decreased (0.445538 --> 0.444436).  Saving model ...
train epoch 626 avg loss: 0.19723 (A-MSE: 0.17440) avg lploss: 0.00000
train epoch 627 avg loss: 0.19603 (A-MSE: 0.17537) avg lploss: 0.00000
train epoch 628 avg loss: 0.20784 (A-MSE: 0.18444) avg lploss: 0.00000
train epoch 629 avg loss: 0.19419 (A-MSE: 0.17290) avg lploss: 0.00000
train epoch 630 avg loss: 0.18100 (A-MSE: 0.16048) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.46778 (A-MSE: 0.41767) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.49597 (A-MSE: 0.44264) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 1 out of 50
train epoch 631 avg loss: 0.18543 (A-MSE: 0.16469) avg lploss: 0.00000
train epoch 632 avg loss: 0.21609 (A-MSE: 0.19123) avg lploss: 0.00000
train epoch 633 avg loss: 0.22481 (A-MSE: 0.19996) avg lploss: 0.00000
train epoch 634 avg loss: 0.24397 (A-MSE: 0.21776) avg lploss: 0.00000
train epoch 635 avg loss: 0.22594 (A-MSE: 0.20047) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.47699 (A-MSE: 0.41936) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.48641 (A-MSE: 0.42712) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 2 out of 50
train epoch 636 avg loss: 0.19949 (A-MSE: 0.17704) avg lploss: 0.00000
train epoch 637 avg loss: 0.21116 (A-MSE: 0.18702) avg lploss: 0.00000
train epoch 638 avg loss: 0.20059 (A-MSE: 0.17723) avg lploss: 0.00000
train epoch 639 avg loss: 0.20798 (A-MSE: 0.18651) avg lploss: 0.00000
train epoch 640 avg loss: 0.19265 (A-MSE: 0.17229) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.44499 (A-MSE: 0.39688) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.47026 (A-MSE: 0.41674) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 3 out of 50
train epoch 641 avg loss: 0.20243 (A-MSE: 0.17991) avg lploss: 0.00000
train epoch 642 avg loss: 0.19167 (A-MSE: 0.17075) avg lploss: 0.00000
train epoch 643 avg loss: 0.18481 (A-MSE: 0.16396) avg lploss: 0.00000
train epoch 644 avg loss: 0.18557 (A-MSE: 0.16470) avg lploss: 0.00000
train epoch 645 avg loss: 0.19396 (A-MSE: 0.17307) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.50493 (A-MSE: 0.44774) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.51971 (A-MSE: 0.45786) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 4 out of 50
train epoch 646 avg loss: 0.20893 (A-MSE: 0.18531) avg lploss: 0.00000
train epoch 647 avg loss: 0.20363 (A-MSE: 0.18025) avg lploss: 0.00000
train epoch 648 avg loss: 0.19925 (A-MSE: 0.17593) avg lploss: 0.00000
train epoch 649 avg loss: 0.19990 (A-MSE: 0.17818) avg lploss: 0.00000
train epoch 650 avg loss: 0.17651 (A-MSE: 0.15684) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.49923 (A-MSE: 0.45256) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.52762 (A-MSE: 0.47559) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 5 out of 50
train epoch 651 avg loss: 0.19940 (A-MSE: 0.17914) avg lploss: 0.00000
train epoch 652 avg loss: 0.22182 (A-MSE: 0.19858) avg lploss: 0.00000
train epoch 653 avg loss: 0.21835 (A-MSE: 0.19401) avg lploss: 0.00000
train epoch 654 avg loss: 0.28065 (A-MSE: 0.23940) avg lploss: 0.00000
train epoch 655 avg loss: 57.59457 (A-MSE: 46.83427) avg lploss: 0.00000
==> val epoch 655 avg loss: 884194536.00000 (A-MSE: 886294126.40000) avg lploss: 0.00000
==> test epoch 655 avg loss: 742635569.60000 (A-MSE: 743300737.60000) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 6 out of 50
train epoch 656 avg loss: 56709435.09054 (A-MSE: 58608691.04480) avg lploss: 0.00000
train epoch 657 avg loss: 688890.85192 (A-MSE: 647946.01683) avg lploss: 0.00000
train epoch 658 avg loss: 3684.14713 (A-MSE: 3788.03589) avg lploss: 0.00000
train epoch 659 avg loss: 1788.97767 (A-MSE: 1847.82995) avg lploss: 0.00000
train epoch 660 avg loss: 1265.79312 (A-MSE: 1287.28732) avg lploss: 0.00000
==> val epoch 660 avg loss: 1082.88637 (A-MSE: 1106.74468) avg lploss: 0.00000
==> test epoch 660 avg loss: 1110.96620 (A-MSE: 1127.82144) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 7 out of 50
train epoch 661 avg loss: 1933.86867 (A-MSE: 1933.49711) avg lploss: 0.00000
train epoch 662 avg loss: 2581.51369 (A-MSE: 2505.50786) avg lploss: 0.00000
train epoch 663 avg loss: 1372.70838 (A-MSE: 1360.73558) avg lploss: 0.00000
train epoch 664 avg loss: 1142.24010 (A-MSE: 1133.02386) avg lploss: 0.00000
train epoch 665 avg loss: 1103.04995 (A-MSE: 1096.18685) avg lploss: 0.00000
==> val epoch 665 avg loss: 1021.23210 (A-MSE: 1008.47060) avg lploss: 0.00000
==> test epoch 665 avg loss: 1050.66172 (A-MSE: 1039.13040) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 8 out of 50
train epoch 666 avg loss: 1049.66230 (A-MSE: 1041.04159) avg lploss: 0.00000
train epoch 667 avg loss: 1275.77384 (A-MSE: 1278.08945) avg lploss: 0.00000
train epoch 668 avg loss: 1763.44909 (A-MSE: 1738.48072) avg lploss: 0.00000
train epoch 669 avg loss: 971.11927 (A-MSE: 967.02177) avg lploss: 0.00000
train epoch 670 avg loss: 580.37212 (A-MSE: 588.09358) avg lploss: 0.00000
==> val epoch 670 avg loss: 533.93246 (A-MSE: 545.47427) avg lploss: 0.00000
==> test epoch 670 avg loss: 524.86329 (A-MSE: 525.96160) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 9 out of 50
train epoch 671 avg loss: 493.45677 (A-MSE: 481.62272) avg lploss: 0.00000
train epoch 672 avg loss: 336.33936 (A-MSE: 325.85623) avg lploss: 0.00000
train epoch 673 avg loss: 386.93792 (A-MSE: 388.92213) avg lploss: 0.00000
train epoch 674 avg loss: 325.61749 (A-MSE: 311.12105) avg lploss: 0.00000
train epoch 675 avg loss: 2279.59942 (A-MSE: 2341.99615) avg lploss: 0.00000
==> val epoch 675 avg loss: 803.54821 (A-MSE: 795.31857) avg lploss: 0.00000
==> test epoch 675 avg loss: 813.29117 (A-MSE: 805.89198) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 10 out of 50
train epoch 676 avg loss: 928.34277 (A-MSE: 925.44538) avg lploss: 0.00000
train epoch 677 avg loss: 534.28553 (A-MSE: 529.89753) avg lploss: 0.00000
train epoch 678 avg loss: 546.39976 (A-MSE: 537.44918) avg lploss: 0.00000
train epoch 679 avg loss: 402.29208 (A-MSE: 393.80224) avg lploss: 0.00000
train epoch 680 avg loss: 372.54529 (A-MSE: 366.57635) avg lploss: 0.00000
==> val epoch 680 avg loss: 422.59268 (A-MSE: 414.38462) avg lploss: 0.00000
==> test epoch 680 avg loss: 432.59492 (A-MSE: 425.97710) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 11 out of 50
train epoch 681 avg loss: 405.79247 (A-MSE: 396.23169) avg lploss: 0.00000
train epoch 682 avg loss: 545.53747 (A-MSE: 539.19572) avg lploss: 0.00000
train epoch 683 avg loss: 408.13352 (A-MSE: 406.00689) avg lploss: 0.00000
train epoch 684 avg loss: 367.50966 (A-MSE: 354.22157) avg lploss: 0.00000
train epoch 685 avg loss: 329.10944 (A-MSE: 329.79558) avg lploss: 0.00000
==> val epoch 685 avg loss: 332.62242 (A-MSE: 332.06554) avg lploss: 0.00000
==> test epoch 685 avg loss: 368.89468 (A-MSE: 359.18243) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 12 out of 50
train epoch 686 avg loss: 301.12332 (A-MSE: 296.01070) avg lploss: 0.00000
train epoch 687 avg loss: 265.20019 (A-MSE: 258.68701) avg lploss: 0.00000
train epoch 688 avg loss: 257.99463 (A-MSE: 249.51371) avg lploss: 0.00000
train epoch 689 avg loss: 243.57966 (A-MSE: 239.88774) avg lploss: 0.00000
train epoch 690 avg loss: 226.90229 (A-MSE: 219.62646) avg lploss: 0.00000
==> val epoch 690 avg loss: 255.04264 (A-MSE: 248.81951) avg lploss: 0.00000
==> test epoch 690 avg loss: 245.58651 (A-MSE: 238.04655) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 13 out of 50
train epoch 691 avg loss: 240.26060 (A-MSE: 230.62589) avg lploss: 0.00000
train epoch 692 avg loss: 269.66224 (A-MSE: 258.95306) avg lploss: 0.00000
train epoch 693 avg loss: 222.11266 (A-MSE: 216.90850) avg lploss: 0.00000
train epoch 694 avg loss: 211.07619 (A-MSE: 205.25607) avg lploss: 0.00000
train epoch 695 avg loss: 204.73020 (A-MSE: 198.08792) avg lploss: 0.00000
==> val epoch 695 avg loss: 230.16362 (A-MSE: 223.82956) avg lploss: 0.00000
==> test epoch 695 avg loss: 238.09933 (A-MSE: 232.86177) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 14 out of 50
train epoch 696 avg loss: 201.05671 (A-MSE: 198.45981) avg lploss: 0.00000
train epoch 697 avg loss: 181.06472 (A-MSE: 178.33117) avg lploss: 0.00000
train epoch 698 avg loss: 181.57899 (A-MSE: 180.18925) avg lploss: 0.00000
train epoch 699 avg loss: 183.07741 (A-MSE: 182.52169) avg lploss: 0.00000
train epoch 700 avg loss: 189.22330 (A-MSE: 188.56103) avg lploss: 0.00000
==> val epoch 700 avg loss: 216.86374 (A-MSE: 216.21716) avg lploss: 0.00000
==> test epoch 700 avg loss: 207.77889 (A-MSE: 203.52945) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 15 out of 50
train epoch 701 avg loss: 175.66725 (A-MSE: 171.52476) avg lploss: 0.00000
train epoch 702 avg loss: 191.16863 (A-MSE: 189.10982) avg lploss: 0.00000
train epoch 703 avg loss: 195.17576 (A-MSE: 190.30696) avg lploss: 0.00000
train epoch 704 avg loss: 202.67748 (A-MSE: 199.30600) avg lploss: 0.00000
train epoch 705 avg loss: 178.28030 (A-MSE: 174.30956) avg lploss: 0.00000
==> val epoch 705 avg loss: 186.26514 (A-MSE: 180.08558) avg lploss: 0.00000
==> test epoch 705 avg loss: 189.32440 (A-MSE: 185.03372) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 16 out of 50
train epoch 706 avg loss: 173.16475 (A-MSE: 163.99462) avg lploss: 0.00000
train epoch 707 avg loss: 170.35703 (A-MSE: 169.12956) avg lploss: 0.00000
train epoch 708 avg loss: 172.08179 (A-MSE: 172.68593) avg lploss: 0.00000
train epoch 709 avg loss: 182.87860 (A-MSE: 183.52544) avg lploss: 0.00000
train epoch 710 avg loss: 157.27014 (A-MSE: 157.82677) avg lploss: 0.00000
==> val epoch 710 avg loss: 180.21410 (A-MSE: 177.47566) avg lploss: 0.00000
==> test epoch 710 avg loss: 168.09396 (A-MSE: 170.92631) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 17 out of 50
train epoch 711 avg loss: 146.71007 (A-MSE: 152.30279) avg lploss: 0.00000
train epoch 712 avg loss: 139.43253 (A-MSE: 143.66953) avg lploss: 0.00000
train epoch 713 avg loss: 158.25800 (A-MSE: 160.31368) avg lploss: 0.00000
train epoch 714 avg loss: 144.72715 (A-MSE: 151.03810) avg lploss: 0.00000
train epoch 715 avg loss: 202.30166 (A-MSE: 200.58297) avg lploss: 0.00000
==> val epoch 715 avg loss: 355.61101 (A-MSE: 364.35435) avg lploss: 0.00000
==> test epoch 715 avg loss: 355.75351 (A-MSE: 363.22681) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 18 out of 50
train epoch 716 avg loss: 323.29507 (A-MSE: 319.22972) avg lploss: 0.00000
train epoch 717 avg loss: 227.82451 (A-MSE: 222.38280) avg lploss: 0.00000
train epoch 718 avg loss: 181.20239 (A-MSE: 182.91818) avg lploss: 0.00000
train epoch 719 avg loss: 260.04218 (A-MSE: 261.90902) avg lploss: 0.00000
train epoch 720 avg loss: 272.33435 (A-MSE: 264.06239) avg lploss: 0.00000
==> val epoch 720 avg loss: 253.46555 (A-MSE: 249.70852) avg lploss: 0.00000
==> test epoch 720 avg loss: 249.63040 (A-MSE: 251.39882) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 19 out of 50
train epoch 721 avg loss: 253.10885 (A-MSE: 253.72062) avg lploss: 0.00000
train epoch 722 avg loss: 227.58676 (A-MSE: 228.10920) avg lploss: 0.00000
train epoch 723 avg loss: 207.01856 (A-MSE: 208.36265) avg lploss: 0.00000
train epoch 724 avg loss: 189.23121 (A-MSE: 188.80171) avg lploss: 0.00000
train epoch 725 avg loss: 179.72351 (A-MSE: 179.49767) avg lploss: 0.00000
==> val epoch 725 avg loss: 183.40542 (A-MSE: 184.57872) avg lploss: 0.00000
==> test epoch 725 avg loss: 175.07173 (A-MSE: 171.37795) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 20 out of 50
train epoch 726 avg loss: 155.05233 (A-MSE: 150.90461) avg lploss: 0.00000
train epoch 727 avg loss: 156.20662 (A-MSE: 158.75214) avg lploss: 0.00000
train epoch 728 avg loss: 155.31239 (A-MSE: 159.13711) avg lploss: 0.00000
train epoch 729 avg loss: 164.85626 (A-MSE: 169.90894) avg lploss: 0.00000
train epoch 730 avg loss: 308.51785 (A-MSE: 305.28954) avg lploss: 0.00000
==> val epoch 730 avg loss: 351.46177 (A-MSE: 347.97522) avg lploss: 0.00000
==> test epoch 730 avg loss: 369.85470 (A-MSE: 373.89570) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 21 out of 50
train epoch 731 avg loss: 334.05507 (A-MSE: 337.02493) avg lploss: 0.00000
train epoch 732 avg loss: 328.30609 (A-MSE: 336.58245) avg lploss: 0.00000
train epoch 733 avg loss: 233.53228 (A-MSE: 233.70469) avg lploss: 0.00000
train epoch 734 avg loss: 170.51960 (A-MSE: 169.81028) avg lploss: 0.00000
train epoch 735 avg loss: 149.88389 (A-MSE: 152.40140) avg lploss: 0.00000
==> val epoch 735 avg loss: 152.94552 (A-MSE: 153.87352) avg lploss: 0.00000
==> test epoch 735 avg loss: 151.71300 (A-MSE: 150.47356) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 22 out of 50
train epoch 736 avg loss: 137.03804 (A-MSE: 139.94522) avg lploss: 0.00000
train epoch 737 avg loss: 132.65155 (A-MSE: 134.91183) avg lploss: 0.00000
train epoch 738 avg loss: 124.01283 (A-MSE: 125.15513) avg lploss: 0.00000
train epoch 739 avg loss: 121.70615 (A-MSE: 124.85398) avg lploss: 0.00000
train epoch 740 avg loss: 124.55396 (A-MSE: 126.19008) avg lploss: 0.00000
==> val epoch 740 avg loss: 125.20099 (A-MSE: 126.83281) avg lploss: 0.00000
==> test epoch 740 avg loss: 127.28052 (A-MSE: 126.50688) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 23 out of 50
train epoch 741 avg loss: 114.62430 (A-MSE: 115.37735) avg lploss: 0.00000
train epoch 742 avg loss: 111.63259 (A-MSE: 112.74226) avg lploss: 0.00000
train epoch 743 avg loss: 112.27858 (A-MSE: 111.72805) avg lploss: 0.00000
train epoch 744 avg loss: 108.99521 (A-MSE: 107.07475) avg lploss: 0.00000
train epoch 745 avg loss: 109.04520 (A-MSE: 110.22973) avg lploss: 0.00000
==> val epoch 745 avg loss: 111.30835 (A-MSE: 112.22233) avg lploss: 0.00000
==> test epoch 745 avg loss: 113.16695 (A-MSE: 114.57959) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 24 out of 50
train epoch 746 avg loss: 104.94417 (A-MSE: 106.58025) avg lploss: 0.00000
train epoch 747 avg loss: 117.66465 (A-MSE: 115.01252) avg lploss: 0.00000
train epoch 748 avg loss: 100.60226 (A-MSE: 102.48583) avg lploss: 0.00000
train epoch 749 avg loss: 104.15897 (A-MSE: 103.95166) avg lploss: 0.00000
train epoch 750 avg loss: 103.17040 (A-MSE: 101.81532) avg lploss: 0.00000
==> val epoch 750 avg loss: 101.35219 (A-MSE: 102.06997) avg lploss: 0.00000
==> test epoch 750 avg loss: 103.76526 (A-MSE: 101.88157) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 25 out of 50
train epoch 751 avg loss: 96.79204 (A-MSE: 98.90870) avg lploss: 0.00000
train epoch 752 avg loss: 94.28124 (A-MSE: 94.78332) avg lploss: 0.00000
train epoch 753 avg loss: 92.43545 (A-MSE: 92.52401) avg lploss: 0.00000
train epoch 754 avg loss: 94.16117 (A-MSE: 93.05697) avg lploss: 0.00000
train epoch 755 avg loss: 93.94871 (A-MSE: 94.05502) avg lploss: 0.00000
==> val epoch 755 avg loss: 102.16995 (A-MSE: 101.18254) avg lploss: 0.00000
==> test epoch 755 avg loss: 106.18830 (A-MSE: 103.13581) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 26 out of 50
train epoch 756 avg loss: 93.41060 (A-MSE: 92.55200) avg lploss: 0.00000
train epoch 757 avg loss: 93.53483 (A-MSE: 94.47445) avg lploss: 0.00000
train epoch 758 avg loss: 97.02168 (A-MSE: 96.26265) avg lploss: 0.00000
train epoch 759 avg loss: 94.79094 (A-MSE: 92.86243) avg lploss: 0.00000
train epoch 760 avg loss: 96.34025 (A-MSE: 93.51528) avg lploss: 0.00000
==> val epoch 760 avg loss: 98.80599 (A-MSE: 94.17020) avg lploss: 0.00000
==> test epoch 760 avg loss: 94.01435 (A-MSE: 91.48233) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 27 out of 50
train epoch 761 avg loss: 87.60591 (A-MSE: 89.19922) avg lploss: 0.00000
train epoch 762 avg loss: 94.07300 (A-MSE: 92.63618) avg lploss: 0.00000
train epoch 763 avg loss: 99.00768 (A-MSE: 95.39970) avg lploss: 0.00000
train epoch 764 avg loss: 93.65820 (A-MSE: 90.70698) avg lploss: 0.00000
train epoch 765 avg loss: 88.08522 (A-MSE: 87.06329) avg lploss: 0.00000
==> val epoch 765 avg loss: 116.04699 (A-MSE: 113.90688) avg lploss: 0.00000
==> test epoch 765 avg loss: 120.43057 (A-MSE: 114.93070) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 28 out of 50
train epoch 766 avg loss: 107.65802 (A-MSE: 105.39862) avg lploss: 0.00000
train epoch 767 avg loss: 94.50964 (A-MSE: 91.05308) avg lploss: 0.00000
train epoch 768 avg loss: 85.56087 (A-MSE: 85.41545) avg lploss: 0.00000
train epoch 769 avg loss: 81.14872 (A-MSE: 81.61267) avg lploss: 0.00000
train epoch 770 avg loss: 79.05063 (A-MSE: 76.98894) avg lploss: 0.00000
==> val epoch 770 avg loss: 88.12835 (A-MSE: 87.36418) avg lploss: 0.00000
==> test epoch 770 avg loss: 83.31447 (A-MSE: 81.13366) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 29 out of 50
train epoch 771 avg loss: 102.61862 (A-MSE: 100.83976) avg lploss: 0.00000
train epoch 772 avg loss: 125.64191 (A-MSE: 123.03636) avg lploss: 0.00000
train epoch 773 avg loss: 99.45279 (A-MSE: 97.53437) avg lploss: 0.00000
train epoch 774 avg loss: 89.41433 (A-MSE: 88.13645) avg lploss: 0.00000
train epoch 775 avg loss: 85.87707 (A-MSE: 84.19539) avg lploss: 0.00000
==> val epoch 775 avg loss: 92.88975 (A-MSE: 92.07955) avg lploss: 0.00000
==> test epoch 775 avg loss: 82.81850 (A-MSE: 81.56518) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 30 out of 50
train epoch 776 avg loss: 82.81180 (A-MSE: 81.52232) avg lploss: 0.00000
train epoch 777 avg loss: 73.17533 (A-MSE: 71.84014) avg lploss: 0.00000
train epoch 778 avg loss: 75.84949 (A-MSE: 74.01010) avg lploss: 0.00000
train epoch 779 avg loss: 69.28778 (A-MSE: 68.32743) avg lploss: 0.00000
train epoch 780 avg loss: 68.47523 (A-MSE: 66.90560) avg lploss: 0.00000
==> val epoch 780 avg loss: 72.76559 (A-MSE: 70.99232) avg lploss: 0.00000
==> test epoch 780 avg loss: 67.67799 (A-MSE: 65.30965) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 31 out of 50
train epoch 781 avg loss: 68.01225 (A-MSE: 65.50216) avg lploss: 0.00000
train epoch 782 avg loss: 69.22508 (A-MSE: 67.81788) avg lploss: 0.00000
train epoch 783 avg loss: 65.95519 (A-MSE: 63.62802) avg lploss: 0.00000
train epoch 784 avg loss: 67.27833 (A-MSE: 65.80239) avg lploss: 0.00000
train epoch 785 avg loss: 61.61580 (A-MSE: 60.87931) avg lploss: 0.00000
==> val epoch 785 avg loss: 64.60384 (A-MSE: 63.57229) avg lploss: 0.00000
==> test epoch 785 avg loss: 58.78640 (A-MSE: 56.50973) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 32 out of 50
train epoch 786 avg loss: 61.99859 (A-MSE: 60.17414) avg lploss: 0.00000
train epoch 787 avg loss: 60.75228 (A-MSE: 59.13311) avg lploss: 0.00000
train epoch 788 avg loss: 70.99866 (A-MSE: 68.61058) avg lploss: 0.00000
train epoch 789 avg loss: 85.63654 (A-MSE: 80.23974) avg lploss: 0.00000
train epoch 790 avg loss: 60.93258 (A-MSE: 59.47124) avg lploss: 0.00000
==> val epoch 790 avg loss: 72.56579 (A-MSE: 70.72974) avg lploss: 0.00000
==> test epoch 790 avg loss: 63.81596 (A-MSE: 62.83588) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 33 out of 50
train epoch 791 avg loss: 89.33416 (A-MSE: 93.41036) avg lploss: 0.00000
train epoch 792 avg loss: 133.67421 (A-MSE: 139.69684) avg lploss: 0.00000
train epoch 793 avg loss: 78.51780 (A-MSE: 78.39467) avg lploss: 0.00000
train epoch 794 avg loss: 82.86241 (A-MSE: 80.95827) avg lploss: 0.00000
train epoch 795 avg loss: 89.51751 (A-MSE: 87.61398) avg lploss: 0.00000
==> val epoch 795 avg loss: 104.05207 (A-MSE: 101.28346) avg lploss: 0.00000
==> test epoch 795 avg loss: 93.48317 (A-MSE: 89.64987) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 34 out of 50
train epoch 796 avg loss: 97.15148 (A-MSE: 94.47002) avg lploss: 0.00000
train epoch 797 avg loss: 79.21803 (A-MSE: 76.97889) avg lploss: 0.00000
train epoch 798 avg loss: 79.83326 (A-MSE: 79.29301) avg lploss: 0.00000
train epoch 799 avg loss: 80.28929 (A-MSE: 76.94505) avg lploss: 0.00000
train epoch 800 avg loss: 68.27137 (A-MSE: 66.26078) avg lploss: 0.00000
==> val epoch 800 avg loss: 71.07134 (A-MSE: 67.25378) avg lploss: 0.00000
==> test epoch 800 avg loss: 60.98079 (A-MSE: 59.31901) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 35 out of 50
train epoch 801 avg loss: 58.99690 (A-MSE: 55.71679) avg lploss: 0.00000
train epoch 802 avg loss: 47.30886 (A-MSE: 46.80027) avg lploss: 0.00000
train epoch 803 avg loss: 54.11782 (A-MSE: 52.99966) avg lploss: 0.00000
train epoch 804 avg loss: 50.71566 (A-MSE: 50.17954) avg lploss: 0.00000
train epoch 805 avg loss: 57.51660 (A-MSE: 60.22364) avg lploss: 0.00000
==> val epoch 805 avg loss: 77.51888 (A-MSE: 77.07939) avg lploss: 0.00000
==> test epoch 805 avg loss: 71.49574 (A-MSE: 72.15891) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 36 out of 50
train epoch 806 avg loss: 139.53809 (A-MSE: 139.09025) avg lploss: 0.00000
train epoch 807 avg loss: 273.09996 (A-MSE: 268.00291) avg lploss: 0.00000
train epoch 808 avg loss: 304.72827 (A-MSE: 311.21377) avg lploss: 0.00000
train epoch 809 avg loss: 225.65839 (A-MSE: 215.01624) avg lploss: 0.00000
train epoch 810 avg loss: 179.40117 (A-MSE: 182.21928) avg lploss: 0.00000
==> val epoch 810 avg loss: 146.09596 (A-MSE: 139.42892) avg lploss: 0.00000
==> test epoch 810 avg loss: 143.11649 (A-MSE: 135.12220) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 37 out of 50
train epoch 811 avg loss: 126.87019 (A-MSE: 120.72367) avg lploss: 0.00000
train epoch 812 avg loss: 102.62360 (A-MSE: 96.50135) avg lploss: 0.00000
train epoch 813 avg loss: 89.50291 (A-MSE: 84.72178) avg lploss: 0.00000
train epoch 814 avg loss: 78.28414 (A-MSE: 76.19553) avg lploss: 0.00000
train epoch 815 avg loss: 86.86761 (A-MSE: 81.45660) avg lploss: 0.00000
==> val epoch 815 avg loss: 91.99904 (A-MSE: 87.43338) avg lploss: 0.00000
==> test epoch 815 avg loss: 83.13823 (A-MSE: 77.61694) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 38 out of 50
train epoch 816 avg loss: 81.07087 (A-MSE: 75.34887) avg lploss: 0.00000
train epoch 817 avg loss: 86.37299 (A-MSE: 82.20477) avg lploss: 0.00000
train epoch 818 avg loss: 70.58147 (A-MSE: 69.55393) avg lploss: 0.00000
train epoch 819 avg loss: 72.25941 (A-MSE: 70.61067) avg lploss: 0.00000
train epoch 820 avg loss: 70.79168 (A-MSE: 68.35791) avg lploss: 0.00000
==> val epoch 820 avg loss: 75.96880 (A-MSE: 72.08362) avg lploss: 0.00000
==> test epoch 820 avg loss: 74.26644 (A-MSE: 69.39086) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 39 out of 50
train epoch 821 avg loss: 65.55902 (A-MSE: 64.64077) avg lploss: 0.00000
train epoch 822 avg loss: 77.26387 (A-MSE: 75.65602) avg lploss: 0.00000
train epoch 823 avg loss: 70.25941 (A-MSE: 68.93064) avg lploss: 0.00000
train epoch 824 avg loss: 78.21168 (A-MSE: 73.16235) avg lploss: 0.00000
train epoch 825 avg loss: 60.18981 (A-MSE: 58.76161) avg lploss: 0.00000
==> val epoch 825 avg loss: 68.50445 (A-MSE: 65.58855) avg lploss: 0.00000
==> test epoch 825 avg loss: 61.28470 (A-MSE: 59.91909) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 40 out of 50
train epoch 826 avg loss: 62.06199 (A-MSE: 60.12769) avg lploss: 0.00000
train epoch 827 avg loss: 57.20971 (A-MSE: 55.19073) avg lploss: 0.00000
train epoch 828 avg loss: 53.87758 (A-MSE: 53.81288) avg lploss: 0.00000
train epoch 829 avg loss: 51.31451 (A-MSE: 50.31450) avg lploss: 0.00000
train epoch 830 avg loss: 50.53072 (A-MSE: 50.75691) avg lploss: 0.00000
==> val epoch 830 avg loss: 58.21725 (A-MSE: 56.75593) avg lploss: 0.00000
==> test epoch 830 avg loss: 59.00726 (A-MSE: 56.56580) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 41 out of 50
train epoch 831 avg loss: 54.39721 (A-MSE: 53.40364) avg lploss: 0.00000
train epoch 832 avg loss: 55.38135 (A-MSE: 53.04086) avg lploss: 0.00000
train epoch 833 avg loss: 48.70793 (A-MSE: 47.38793) avg lploss: 0.00000
train epoch 834 avg loss: 50.95638 (A-MSE: 48.60151) avg lploss: 0.00000
train epoch 835 avg loss: 56.58051 (A-MSE: 53.02176) avg lploss: 0.00000
==> val epoch 835 avg loss: 54.60186 (A-MSE: 52.85117) avg lploss: 0.00000
==> test epoch 835 avg loss: 57.29553 (A-MSE: 53.82971) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 42 out of 50
train epoch 836 avg loss: 52.44992 (A-MSE: 49.71675) avg lploss: 0.00000
train epoch 837 avg loss: 50.00738 (A-MSE: 46.92260) avg lploss: 0.00000
train epoch 838 avg loss: 49.50984 (A-MSE: 46.68680) avg lploss: 0.00000
train epoch 839 avg loss: 45.38333 (A-MSE: 44.03734) avg lploss: 0.00000
train epoch 840 avg loss: 46.05637 (A-MSE: 44.82242) avg lploss: 0.00000
==> val epoch 840 avg loss: 53.48709 (A-MSE: 51.33448) avg lploss: 0.00000
==> test epoch 840 avg loss: 55.35719 (A-MSE: 51.90918) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 43 out of 50
train epoch 841 avg loss: 45.68698 (A-MSE: 44.88372) avg lploss: 0.00000
train epoch 842 avg loss: 43.52285 (A-MSE: 42.32752) avg lploss: 0.00000
train epoch 843 avg loss: 42.06830 (A-MSE: 40.44005) avg lploss: 0.00000
train epoch 844 avg loss: 43.07223 (A-MSE: 42.14849) avg lploss: 0.00000
train epoch 845 avg loss: 44.97230 (A-MSE: 43.35557) avg lploss: 0.00000
==> val epoch 845 avg loss: 46.19064 (A-MSE: 46.21454) avg lploss: 0.00000
==> test epoch 845 avg loss: 44.29034 (A-MSE: 42.71693) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 44 out of 50
train epoch 846 avg loss: 43.79935 (A-MSE: 43.68113) avg lploss: 0.00000
train epoch 847 avg loss: 49.46759 (A-MSE: 45.81089) avg lploss: 0.00000
train epoch 848 avg loss: 48.10045 (A-MSE: 44.07376) avg lploss: 0.00000
train epoch 849 avg loss: 42.95749 (A-MSE: 40.00378) avg lploss: 0.00000
train epoch 850 avg loss: 41.23697 (A-MSE: 41.07767) avg lploss: 0.00000
==> val epoch 850 avg loss: 43.46316 (A-MSE: 42.24392) avg lploss: 0.00000
==> test epoch 850 avg loss: 44.94638 (A-MSE: 42.61685) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 45 out of 50
train epoch 851 avg loss: 44.31252 (A-MSE: 41.81379) avg lploss: 0.00000
train epoch 852 avg loss: 42.94198 (A-MSE: 41.55570) avg lploss: 0.00000
train epoch 853 avg loss: 42.16435 (A-MSE: 42.11493) avg lploss: 0.00000
train epoch 854 avg loss: 43.09047 (A-MSE: 41.38591) avg lploss: 0.00000
train epoch 855 avg loss: 40.17250 (A-MSE: 40.92174) avg lploss: 0.00000
==> val epoch 855 avg loss: 52.07243 (A-MSE: 50.81221) avg lploss: 0.00000
==> test epoch 855 avg loss: 53.19198 (A-MSE: 50.92485) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 46 out of 50
train epoch 856 avg loss: 39.07785 (A-MSE: 37.22192) avg lploss: 0.00000
train epoch 857 avg loss: 36.42241 (A-MSE: 36.26597) avg lploss: 0.00000
train epoch 858 avg loss: 38.53261 (A-MSE: 36.72336) avg lploss: 0.00000
train epoch 859 avg loss: 40.81514 (A-MSE: 40.22875) avg lploss: 0.00000
train epoch 860 avg loss: 37.05750 (A-MSE: 35.12843) avg lploss: 0.00000
==> val epoch 860 avg loss: 47.71221 (A-MSE: 45.04197) avg lploss: 0.00000
==> test epoch 860 avg loss: 45.78341 (A-MSE: 42.87363) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 47 out of 50
train epoch 861 avg loss: 38.66868 (A-MSE: 36.11803) avg lploss: 0.00000
train epoch 862 avg loss: 37.81193 (A-MSE: 36.73302) avg lploss: 0.00000
train epoch 863 avg loss: 36.40057 (A-MSE: 34.21703) avg lploss: 0.00000
train epoch 864 avg loss: 35.21316 (A-MSE: 32.53632) avg lploss: 0.00000
train epoch 865 avg loss: 36.47669 (A-MSE: 34.97006) avg lploss: 0.00000
==> val epoch 865 avg loss: 38.74270 (A-MSE: 36.84709) avg lploss: 0.00000
==> test epoch 865 avg loss: 37.76752 (A-MSE: 36.03523) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 48 out of 50
train epoch 866 avg loss: 35.00956 (A-MSE: 34.82876) avg lploss: 0.00000
train epoch 867 avg loss: 35.07768 (A-MSE: 33.51767) avg lploss: 0.00000
train epoch 868 avg loss: 33.81989 (A-MSE: 32.76577) avg lploss: 0.00000
train epoch 869 avg loss: 37.42986 (A-MSE: 35.28932) avg lploss: 0.00000
train epoch 870 avg loss: 56.84520 (A-MSE: 53.39350) avg lploss: 0.00000
==> val epoch 870 avg loss: 74.12860 (A-MSE: 70.29031) avg lploss: 0.00000
==> test epoch 870 avg loss: 71.70609 (A-MSE: 67.00391) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 49 out of 50
train epoch 871 avg loss: 75.15432 (A-MSE: 72.66300) avg lploss: 0.00000
train epoch 872 avg loss: 58.54086 (A-MSE: 55.95877) avg lploss: 0.00000
train epoch 873 avg loss: 44.74926 (A-MSE: 44.13087) avg lploss: 0.00000
train epoch 874 avg loss: 41.45330 (A-MSE: 39.41312) avg lploss: 0.00000
train epoch 875 avg loss: 37.24017 (A-MSE: 35.29294) avg lploss: 0.00000
==> val epoch 875 avg loss: 37.52818 (A-MSE: 35.56850) avg lploss: 0.00000
==> test epoch 875 avg loss: 41.68306 (A-MSE: 38.56521) avg lploss: 0.00000
*** Best Val Loss: 0.44444 	 Best Test Loss: 0.47686 	 Best epoch 625
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train_f_mse = 0.224014
best_lp = 0.000000
best_val_f_mse = 0.444436
best_test_f_mse = 0.476865
best_test_a_mse = 0.426091
best_epoch = 625
best_train_f_mse = 0.224014, best_lp = 0.000000, best_val_f_mse = 0.444436, best_test_f_mse = 0.476865, best_test_a_mse = 0.426091, best_epoch = 625
Job completed at Mon Dec  8 23:20:21 CET 2025
