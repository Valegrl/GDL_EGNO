Date              = Mon Dec  8 23:11:23 CET 2025
Hostname          = mel2053
Array Task ID     = 3
Running config: configs/mocap_walk_seed4.json
Namespace(batch_size=12, case='walk', config_by_file='configs/mocap_walk_seed4.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_walk_seed4', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 198 samples!
Got Split!
Got 600 samples!
Got Split!
Got 600 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_walk_seed4/saved_model.pth
train epoch 0 avg loss: 15.55044 (A-MSE: 14.10534) avg lploss: 0.00000
==> val epoch 0 avg loss: 14.35887 (A-MSE: 12.79785) avg lploss: 0.00000
==> test epoch 0 avg loss: 14.39291 (A-MSE: 12.83826) avg lploss: 0.00000
*** Best Val Loss: 14.35887 	 Best Test Loss: 14.39291 	 Best epoch 0
Validation loss decreased (inf --> 14.358873).  Saving model ...
train epoch 1 avg loss: 12.86532 (A-MSE: 11.43548) avg lploss: 0.00000
train epoch 2 avg loss: 11.54989 (A-MSE: 10.22191) avg lploss: 0.00000
train epoch 3 avg loss: 10.07876 (A-MSE: 8.84290) avg lploss: 0.00000
train epoch 4 avg loss: 8.60625 (A-MSE: 7.52470) avg lploss: 0.00000
train epoch 5 avg loss: 5.87237 (A-MSE: 5.02210) avg lploss: 0.00000
==> val epoch 5 avg loss: 6696.51063 (A-MSE: 6595.19561) avg lploss: 0.00000
==> test epoch 5 avg loss: 4.42454 (A-MSE: 4.30468) avg lploss: 0.00000
*** Best Val Loss: 14.35887 	 Best Test Loss: 14.39291 	 Best epoch 0
EarlyStopping counter: 1 out of 50
train epoch 6 avg loss: 289602.13215 (A-MSE: 287201.67570) avg lploss: 0.00000
train epoch 7 avg loss: 2380.58837 (A-MSE: 2348.20921) avg lploss: 0.00000
train epoch 8 avg loss: 13.23376 (A-MSE: 11.98633) avg lploss: 0.00000
train epoch 9 avg loss: 10.28873 (A-MSE: 9.04326) avg lploss: 0.00000
train epoch 10 avg loss: 9.82056 (A-MSE: 8.57716) avg lploss: 0.00000
==> val epoch 10 avg loss: 10.14019 (A-MSE: 8.82167) avg lploss: 0.00000
==> test epoch 10 avg loss: 10.17164 (A-MSE: 8.85816) avg lploss: 0.00000
*** Best Val Loss: 10.14019 	 Best Test Loss: 10.17164 	 Best epoch 10
Validation loss decreased (14.358873 --> 10.140186).  Saving model ...
train epoch 11 avg loss: 9.57021 (A-MSE: 8.33680) avg lploss: 0.00000
train epoch 12 avg loss: 9.34605 (A-MSE: 8.13012) avg lploss: 0.00000
train epoch 13 avg loss: 9.23372 (A-MSE: 8.01701) avg lploss: 0.00000
train epoch 14 avg loss: 9.03864 (A-MSE: 7.83700) avg lploss: 0.00000
train epoch 15 avg loss: 8.81003 (A-MSE: 7.62237) avg lploss: 0.00000
==> val epoch 15 avg loss: 9.12983 (A-MSE: 7.86852) avg lploss: 0.00000
==> test epoch 15 avg loss: 9.14275 (A-MSE: 7.88825) avg lploss: 0.00000
*** Best Val Loss: 9.12983 	 Best Test Loss: 9.14275 	 Best epoch 15
Validation loss decreased (10.140186 --> 9.129825).  Saving model ...
train epoch 16 avg loss: 8.49109 (A-MSE: 7.32840) avg lploss: 0.00000
train epoch 17 avg loss: 7.98632 (A-MSE: 6.87109) avg lploss: 0.00000
train epoch 18 avg loss: 7.43574 (A-MSE: 6.38273) avg lploss: 0.00000
train epoch 19 avg loss: 6.83809 (A-MSE: 5.86409) avg lploss: 0.00000
train epoch 20 avg loss: 6.15938 (A-MSE: 5.27665) avg lploss: 0.00000
==> val epoch 20 avg loss: 6.21534 (A-MSE: 5.30845) avg lploss: 0.00000
==> test epoch 20 avg loss: 6.17963 (A-MSE: 5.27903) avg lploss: 0.00000
*** Best Val Loss: 6.21534 	 Best Test Loss: 6.17963 	 Best epoch 20
Validation loss decreased (9.129825 --> 6.215342).  Saving model ...
train epoch 21 avg loss: 5.58695 (A-MSE: 4.80081) avg lploss: 0.00000
train epoch 22 avg loss: 5.24730 (A-MSE: 4.52924) avg lploss: 0.00000
train epoch 23 avg loss: 5.07018 (A-MSE: 4.37839) avg lploss: 0.00000
train epoch 24 avg loss: 4.82416 (A-MSE: 4.16160) avg lploss: 0.00000
train epoch 25 avg loss: 4.66252 (A-MSE: 4.02779) avg lploss: 0.00000
==> val epoch 25 avg loss: 5.00719 (A-MSE: 4.32343) avg lploss: 0.00000
==> test epoch 25 avg loss: 4.90612 (A-MSE: 4.22617) avg lploss: 0.00000
*** Best Val Loss: 5.00719 	 Best Test Loss: 4.90612 	 Best epoch 25
Validation loss decreased (6.215342 --> 5.007194).  Saving model ...
train epoch 26 avg loss: 4.56509 (A-MSE: 3.94986) avg lploss: 0.00000
train epoch 27 avg loss: 4.45497 (A-MSE: 3.85334) avg lploss: 0.00000
train epoch 28 avg loss: 4.38657 (A-MSE: 3.79709) avg lploss: 0.00000
train epoch 29 avg loss: 4.31244 (A-MSE: 3.73640) avg lploss: 0.00000
train epoch 30 avg loss: 4.23008 (A-MSE: 3.66542) avg lploss: 0.00000
==> val epoch 30 avg loss: 4.62583 (A-MSE: 3.99973) avg lploss: 0.00000
==> test epoch 30 avg loss: 4.51365 (A-MSE: 3.89122) avg lploss: 0.00000
*** Best Val Loss: 4.62583 	 Best Test Loss: 4.51365 	 Best epoch 30
Validation loss decreased (5.007194 --> 4.625834).  Saving model ...
train epoch 31 avg loss: 4.22869 (A-MSE: 3.66489) avg lploss: 0.00000
train epoch 32 avg loss: 4.16922 (A-MSE: 3.61206) avg lploss: 0.00000
train epoch 33 avg loss: 4.13270 (A-MSE: 3.57493) avg lploss: 0.00000
train epoch 34 avg loss: 4.07298 (A-MSE: 3.52770) avg lploss: 0.00000
train epoch 35 avg loss: 4.04519 (A-MSE: 3.50298) avg lploss: 0.00000
==> val epoch 35 avg loss: 4.46685 (A-MSE: 3.85332) avg lploss: 0.00000
==> test epoch 35 avg loss: 4.35279 (A-MSE: 3.74323) avg lploss: 0.00000
*** Best Val Loss: 4.46685 	 Best Test Loss: 4.35279 	 Best epoch 35
Validation loss decreased (4.625834 --> 4.466848).  Saving model ...
train epoch 36 avg loss: 4.03129 (A-MSE: 3.49071) avg lploss: 0.00000
train epoch 37 avg loss: 4.01082 (A-MSE: 3.47569) avg lploss: 0.00000
train epoch 38 avg loss: 3.99547 (A-MSE: 3.46318) avg lploss: 0.00000
train epoch 39 avg loss: 3.94039 (A-MSE: 3.41206) avg lploss: 0.00000
train epoch 40 avg loss: 3.90452 (A-MSE: 3.38129) avg lploss: 0.00000
==> val epoch 40 avg loss: 4.40098 (A-MSE: 3.80051) avg lploss: 0.00000
==> test epoch 40 avg loss: 4.26875 (A-MSE: 3.67419) avg lploss: 0.00000
*** Best Val Loss: 4.40098 	 Best Test Loss: 4.26875 	 Best epoch 40
Validation loss decreased (4.466848 --> 4.400979).  Saving model ...
train epoch 41 avg loss: 3.90150 (A-MSE: 3.37575) avg lploss: 0.00000
train epoch 42 avg loss: 3.82132 (A-MSE: 3.30637) avg lploss: 0.00000
train epoch 43 avg loss: 3.80830 (A-MSE: 3.29248) avg lploss: 0.00000
train epoch 44 avg loss: 3.77827 (A-MSE: 3.27172) avg lploss: 0.00000
train epoch 45 avg loss: 3.78019 (A-MSE: 3.26950) avg lploss: 0.00000
==> val epoch 45 avg loss: 4.17616 (A-MSE: 3.60882) avg lploss: 0.00000
==> test epoch 45 avg loss: 4.06257 (A-MSE: 3.50022) avg lploss: 0.00000
*** Best Val Loss: 4.17616 	 Best Test Loss: 4.06257 	 Best epoch 45
Validation loss decreased (4.400979 --> 4.176164).  Saving model ...
train epoch 46 avg loss: 3.73165 (A-MSE: 3.23163) avg lploss: 0.00000
train epoch 47 avg loss: 3.72423 (A-MSE: 3.22652) avg lploss: 0.00000
train epoch 48 avg loss: 3.70725 (A-MSE: 3.21108) avg lploss: 0.00000
train epoch 49 avg loss: 3.69181 (A-MSE: 3.19351) avg lploss: 0.00000
train epoch 50 avg loss: 3.61421 (A-MSE: 3.12768) avg lploss: 0.00000
==> val epoch 50 avg loss: 3.96315 (A-MSE: 3.41000) avg lploss: 0.00000
==> test epoch 50 avg loss: 3.84208 (A-MSE: 3.29524) avg lploss: 0.00000
*** Best Val Loss: 3.96315 	 Best Test Loss: 3.84208 	 Best epoch 50
Validation loss decreased (4.176164 --> 3.963153).  Saving model ...
train epoch 51 avg loss: 3.60198 (A-MSE: 3.11830) avg lploss: 0.00000
train epoch 52 avg loss: 3.56142 (A-MSE: 3.08022) avg lploss: 0.00000
train epoch 53 avg loss: 3.53816 (A-MSE: 3.06257) avg lploss: 0.00000
train epoch 54 avg loss: 3.49537 (A-MSE: 3.02079) avg lploss: 0.00000
train epoch 55 avg loss: 3.47159 (A-MSE: 3.00901) avg lploss: 0.00000
==> val epoch 55 avg loss: 3.85307 (A-MSE: 3.29793) avg lploss: 0.00000
==> test epoch 55 avg loss: 3.73270 (A-MSE: 3.18543) avg lploss: 0.00000
*** Best Val Loss: 3.85307 	 Best Test Loss: 3.73270 	 Best epoch 55
Validation loss decreased (3.963153 --> 3.853073).  Saving model ...
train epoch 56 avg loss: 3.47104 (A-MSE: 2.99809) avg lploss: 0.00000
train epoch 57 avg loss: 3.39148 (A-MSE: 2.93263) avg lploss: 0.00000
train epoch 58 avg loss: 3.32852 (A-MSE: 2.87496) avg lploss: 0.00000
train epoch 59 avg loss: 3.33372 (A-MSE: 2.88290) avg lploss: 0.00000
train epoch 60 avg loss: 3.25544 (A-MSE: 2.81478) avg lploss: 0.00000
==> val epoch 60 avg loss: 3.65340 (A-MSE: 3.14625) avg lploss: 0.00000
==> test epoch 60 avg loss: 3.52039 (A-MSE: 3.02349) avg lploss: 0.00000
*** Best Val Loss: 3.65340 	 Best Test Loss: 3.52039 	 Best epoch 60
Validation loss decreased (3.853073 --> 3.653405).  Saving model ...
train epoch 61 avg loss: 3.28744 (A-MSE: 2.84352) avg lploss: 0.00000
train epoch 62 avg loss: 3.19050 (A-MSE: 2.75672) avg lploss: 0.00000
train epoch 63 avg loss: 3.19802 (A-MSE: 2.76085) avg lploss: 0.00000
train epoch 64 avg loss: 3.14372 (A-MSE: 2.71795) avg lploss: 0.00000
train epoch 65 avg loss: 3.06278 (A-MSE: 2.64245) avg lploss: 0.00000
==> val epoch 65 avg loss: 3.38786 (A-MSE: 2.90009) avg lploss: 0.00000
==> test epoch 65 avg loss: 3.24958 (A-MSE: 2.77377) avg lploss: 0.00000
*** Best Val Loss: 3.38786 	 Best Test Loss: 3.24958 	 Best epoch 65
Validation loss decreased (3.653405 --> 3.387859).  Saving model ...
train epoch 66 avg loss: 3.05867 (A-MSE: 2.64042) avg lploss: 0.00000
train epoch 67 avg loss: 3.06225 (A-MSE: 2.65002) avg lploss: 0.00000
train epoch 68 avg loss: 2.98407 (A-MSE: 2.57508) avg lploss: 0.00000
train epoch 69 avg loss: 2.96730 (A-MSE: 2.56968) avg lploss: 0.00000
train epoch 70 avg loss: 2.93409 (A-MSE: 2.53048) avg lploss: 0.00000
==> val epoch 70 avg loss: 3.26535 (A-MSE: 2.80593) avg lploss: 0.00000
==> test epoch 70 avg loss: 3.12311 (A-MSE: 2.67638) avg lploss: 0.00000
*** Best Val Loss: 3.26535 	 Best Test Loss: 3.12311 	 Best epoch 70
Validation loss decreased (3.387859 --> 3.265347).  Saving model ...
train epoch 71 avg loss: 2.89143 (A-MSE: 2.49342) avg lploss: 0.00000
train epoch 72 avg loss: 2.90949 (A-MSE: 2.51348) avg lploss: 0.00000
train epoch 73 avg loss: 2.91716 (A-MSE: 2.52281) avg lploss: 0.00000
train epoch 74 avg loss: 2.89695 (A-MSE: 2.50153) avg lploss: 0.00000
train epoch 75 avg loss: 2.83748 (A-MSE: 2.45016) avg lploss: 0.00000
==> val epoch 75 avg loss: 3.15616 (A-MSE: 2.69949) avg lploss: 0.00000
==> test epoch 75 avg loss: 3.00954 (A-MSE: 2.56546) avg lploss: 0.00000
*** Best Val Loss: 3.15616 	 Best Test Loss: 3.00954 	 Best epoch 75
Validation loss decreased (3.265347 --> 3.156158).  Saving model ...
train epoch 76 avg loss: 2.81412 (A-MSE: 2.42853) avg lploss: 0.00000
train epoch 77 avg loss: 2.77640 (A-MSE: 2.39220) avg lploss: 0.00000
train epoch 78 avg loss: 2.77258 (A-MSE: 2.39405) avg lploss: 0.00000
train epoch 79 avg loss: 2.75364 (A-MSE: 2.37671) avg lploss: 0.00000
train epoch 80 avg loss: 2.75026 (A-MSE: 2.36927) avg lploss: 0.00000
==> val epoch 80 avg loss: 3.07768 (A-MSE: 2.64361) avg lploss: 0.00000
==> test epoch 80 avg loss: 2.93331 (A-MSE: 2.51117) avg lploss: 0.00000
*** Best Val Loss: 3.07768 	 Best Test Loss: 2.93331 	 Best epoch 80
Validation loss decreased (3.156158 --> 3.077681).  Saving model ...
train epoch 81 avg loss: 2.72582 (A-MSE: 2.35508) avg lploss: 0.00000
train epoch 82 avg loss: 2.73370 (A-MSE: 2.35796) avg lploss: 0.00000
train epoch 83 avg loss: 2.70561 (A-MSE: 2.33100) avg lploss: 0.00000
train epoch 84 avg loss: 2.69553 (A-MSE: 2.32803) avg lploss: 0.00000
train epoch 85 avg loss: 2.65016 (A-MSE: 2.28513) avg lploss: 0.00000
==> val epoch 85 avg loss: 2.99617 (A-MSE: 2.54995) avg lploss: 0.00000
==> test epoch 85 avg loss: 2.85244 (A-MSE: 2.41786) avg lploss: 0.00000
*** Best Val Loss: 2.99617 	 Best Test Loss: 2.85244 	 Best epoch 85
Validation loss decreased (3.077681 --> 2.996169).  Saving model ...
train epoch 86 avg loss: 2.65872 (A-MSE: 2.28637) avg lploss: 0.00000
train epoch 87 avg loss: 2.62606 (A-MSE: 2.26649) avg lploss: 0.00000
train epoch 88 avg loss: 2.62835 (A-MSE: 2.26306) avg lploss: 0.00000
train epoch 89 avg loss: 2.60486 (A-MSE: 2.24328) avg lploss: 0.00000
train epoch 90 avg loss: 2.61582 (A-MSE: 2.26013) avg lploss: 0.00000
==> val epoch 90 avg loss: 2.91058 (A-MSE: 2.48123) avg lploss: 0.00000
==> test epoch 90 avg loss: 2.77073 (A-MSE: 2.35326) avg lploss: 0.00000
*** Best Val Loss: 2.91058 	 Best Test Loss: 2.77073 	 Best epoch 90
Validation loss decreased (2.996169 --> 2.910580).  Saving model ...
train epoch 91 avg loss: 2.56067 (A-MSE: 2.20477) avg lploss: 0.00000
train epoch 92 avg loss: 2.53269 (A-MSE: 2.18345) avg lploss: 0.00000
train epoch 93 avg loss: 2.54349 (A-MSE: 2.18718) avg lploss: 0.00000
train epoch 94 avg loss: 2.53543 (A-MSE: 2.18303) avg lploss: 0.00000
train epoch 95 avg loss: 2.49568 (A-MSE: 2.14596) avg lploss: 0.00000
==> val epoch 95 avg loss: 2.80984 (A-MSE: 2.42707) avg lploss: 0.00000
==> test epoch 95 avg loss: 2.67792 (A-MSE: 2.30737) avg lploss: 0.00000
*** Best Val Loss: 2.80984 	 Best Test Loss: 2.67792 	 Best epoch 95
Validation loss decreased (2.910580 --> 2.809843).  Saving model ...
train epoch 96 avg loss: 2.55197 (A-MSE: 2.20746) avg lploss: 0.00000
train epoch 97 avg loss: 2.48886 (A-MSE: 2.14542) avg lploss: 0.00000
train epoch 98 avg loss: 2.49799 (A-MSE: 2.14862) avg lploss: 0.00000
train epoch 99 avg loss: 2.46233 (A-MSE: 2.12226) avg lploss: 0.00000
train epoch 100 avg loss: 2.41445 (A-MSE: 2.07676) avg lploss: 0.00000
==> val epoch 100 avg loss: 2.72342 (A-MSE: 2.32261) avg lploss: 0.00000
==> test epoch 100 avg loss: 2.59562 (A-MSE: 2.20657) avg lploss: 0.00000
*** Best Val Loss: 2.72342 	 Best Test Loss: 2.59562 	 Best epoch 100
Validation loss decreased (2.809843 --> 2.723422).  Saving model ...
train epoch 101 avg loss: 2.40035 (A-MSE: 2.06743) avg lploss: 0.00000
train epoch 102 avg loss: 2.39339 (A-MSE: 2.06126) avg lploss: 0.00000
train epoch 103 avg loss: 2.39868 (A-MSE: 2.06875) avg lploss: 0.00000
train epoch 104 avg loss: 2.38800 (A-MSE: 2.05968) avg lploss: 0.00000
train epoch 105 avg loss: 2.34830 (A-MSE: 2.01672) avg lploss: 0.00000
==> val epoch 105 avg loss: 2.67894 (A-MSE: 2.29211) avg lploss: 0.00000
==> test epoch 105 avg loss: 2.55194 (A-MSE: 2.17713) avg lploss: 0.00000
*** Best Val Loss: 2.67894 	 Best Test Loss: 2.55194 	 Best epoch 105
Validation loss decreased (2.723422 --> 2.678940).  Saving model ...
train epoch 106 avg loss: 2.36772 (A-MSE: 2.03948) avg lploss: 0.00000
train epoch 107 avg loss: 2.36049 (A-MSE: 2.03661) avg lploss: 0.00000
train epoch 108 avg loss: 2.36381 (A-MSE: 2.03706) avg lploss: 0.00000
train epoch 109 avg loss: 2.30507 (A-MSE: 1.98091) avg lploss: 0.00000
train epoch 110 avg loss: 2.30214 (A-MSE: 1.98100) avg lploss: 0.00000
==> val epoch 110 avg loss: 2.61334 (A-MSE: 2.22004) avg lploss: 0.00000
==> test epoch 110 avg loss: 2.49080 (A-MSE: 2.10861) avg lploss: 0.00000
*** Best Val Loss: 2.61334 	 Best Test Loss: 2.49080 	 Best epoch 110
Validation loss decreased (2.678940 --> 2.613341).  Saving model ...
train epoch 111 avg loss: 2.29866 (A-MSE: 1.97917) avg lploss: 0.00000
train epoch 112 avg loss: 2.35763 (A-MSE: 2.03045) avg lploss: 0.00000
train epoch 113 avg loss: 2.27637 (A-MSE: 1.95809) avg lploss: 0.00000
train epoch 114 avg loss: 2.27146 (A-MSE: 1.95095) avg lploss: 0.00000
train epoch 115 avg loss: 2.26703 (A-MSE: 1.95702) avg lploss: 0.00000
==> val epoch 115 avg loss: 2.59268 (A-MSE: 2.20186) avg lploss: 0.00000
==> test epoch 115 avg loss: 2.47334 (A-MSE: 2.09528) avg lploss: 0.00000
*** Best Val Loss: 2.59268 	 Best Test Loss: 2.47334 	 Best epoch 115
Validation loss decreased (2.613341 --> 2.592680).  Saving model ...
train epoch 116 avg loss: 2.27330 (A-MSE: 1.95302) avg lploss: 0.00000
train epoch 117 avg loss: 2.21802 (A-MSE: 1.90400) avg lploss: 0.00000
train epoch 118 avg loss: 2.22362 (A-MSE: 1.92101) avg lploss: 0.00000
train epoch 119 avg loss: 2.24299 (A-MSE: 1.92891) avg lploss: 0.00000
train epoch 120 avg loss: 2.18354 (A-MSE: 1.87525) avg lploss: 0.00000
==> val epoch 120 avg loss: 2.54926 (A-MSE: 2.19044) avg lploss: 0.00000
==> test epoch 120 avg loss: 2.43522 (A-MSE: 2.08884) avg lploss: 0.00000
*** Best Val Loss: 2.54926 	 Best Test Loss: 2.43522 	 Best epoch 120
Validation loss decreased (2.592680 --> 2.549259).  Saving model ...
train epoch 121 avg loss: 2.18540 (A-MSE: 1.88312) avg lploss: 0.00000
train epoch 122 avg loss: 2.16323 (A-MSE: 1.85495) avg lploss: 0.00000
train epoch 123 avg loss: 2.14646 (A-MSE: 1.84384) avg lploss: 0.00000
train epoch 124 avg loss: 2.11800 (A-MSE: 1.82123) avg lploss: 0.00000
train epoch 125 avg loss: 2.14403 (A-MSE: 1.84191) avg lploss: 0.00000
==> val epoch 125 avg loss: 2.37439 (A-MSE: 2.01633) avg lploss: 0.00000
==> test epoch 125 avg loss: 2.26074 (A-MSE: 1.91554) avg lploss: 0.00000
*** Best Val Loss: 2.37439 	 Best Test Loss: 2.26074 	 Best epoch 125
Validation loss decreased (2.549259 --> 2.374391).  Saving model ...
train epoch 126 avg loss: 2.09019 (A-MSE: 1.79583) avg lploss: 0.00000
train epoch 127 avg loss: 2.11376 (A-MSE: 1.81207) avg lploss: 0.00000
train epoch 128 avg loss: 2.09673 (A-MSE: 1.79886) avg lploss: 0.00000
train epoch 129 avg loss: 2.08575 (A-MSE: 1.79860) avg lploss: 0.00000
train epoch 130 avg loss: 2.08170 (A-MSE: 1.78582) avg lploss: 0.00000
==> val epoch 130 avg loss: 2.36467 (A-MSE: 2.00202) avg lploss: 0.00000
==> test epoch 130 avg loss: 2.24619 (A-MSE: 1.89844) avg lploss: 0.00000
*** Best Val Loss: 2.36467 	 Best Test Loss: 2.24619 	 Best epoch 130
Validation loss decreased (2.374391 --> 2.364674).  Saving model ...
train epoch 131 avg loss: 2.07383 (A-MSE: 1.78331) avg lploss: 0.00000
train epoch 132 avg loss: 2.07311 (A-MSE: 1.77986) avg lploss: 0.00000
train epoch 133 avg loss: 2.02285 (A-MSE: 1.73116) avg lploss: 0.00000
train epoch 134 avg loss: 2.03600 (A-MSE: 1.74494) avg lploss: 0.00000
train epoch 135 avg loss: 2.03632 (A-MSE: 1.74847) avg lploss: 0.00000
==> val epoch 135 avg loss: 2.27343 (A-MSE: 1.92245) avg lploss: 0.00000
==> test epoch 135 avg loss: 2.15743 (A-MSE: 1.82027) avg lploss: 0.00000
*** Best Val Loss: 2.27343 	 Best Test Loss: 2.15743 	 Best epoch 135
Validation loss decreased (2.364674 --> 2.273430).  Saving model ...
train epoch 136 avg loss: 2.02857 (A-MSE: 1.74287) avg lploss: 0.00000
train epoch 137 avg loss: 2.02724 (A-MSE: 1.74072) avg lploss: 0.00000
train epoch 138 avg loss: 2.00585 (A-MSE: 1.72258) avg lploss: 0.00000
train epoch 139 avg loss: 1.98348 (A-MSE: 1.69994) avg lploss: 0.00000
train epoch 140 avg loss: 1.97691 (A-MSE: 1.69659) avg lploss: 0.00000
==> val epoch 140 avg loss: 2.26661 (A-MSE: 1.90639) avg lploss: 0.00000
==> test epoch 140 avg loss: 2.14320 (A-MSE: 1.79675) avg lploss: 0.00000
*** Best Val Loss: 2.26661 	 Best Test Loss: 2.14320 	 Best epoch 140
Validation loss decreased (2.273430 --> 2.266614).  Saving model ...
train epoch 141 avg loss: 2.00301 (A-MSE: 1.72346) avg lploss: 0.00000
train epoch 142 avg loss: 2.00844 (A-MSE: 1.71743) avg lploss: 0.00000
train epoch 143 avg loss: 1.96774 (A-MSE: 1.69033) avg lploss: 0.00000
train epoch 144 avg loss: 1.95031 (A-MSE: 1.67117) avg lploss: 0.00000
train epoch 145 avg loss: 1.92081 (A-MSE: 1.64502) avg lploss: 0.00000
==> val epoch 145 avg loss: 2.21043 (A-MSE: 1.86822) avg lploss: 0.00000
==> test epoch 145 avg loss: 2.09552 (A-MSE: 1.76823) avg lploss: 0.00000
*** Best Val Loss: 2.21043 	 Best Test Loss: 2.09552 	 Best epoch 145
Validation loss decreased (2.266614 --> 2.210433).  Saving model ...
train epoch 146 avg loss: 1.97864 (A-MSE: 1.70165) avg lploss: 0.00000
train epoch 147 avg loss: 2.03088 (A-MSE: 1.75214) avg lploss: 0.00000
train epoch 148 avg loss: 1.91497 (A-MSE: 1.64228) avg lploss: 0.00000
train epoch 149 avg loss: 1.87850 (A-MSE: 1.60567) avg lploss: 0.00000
train epoch 150 avg loss: 1.87603 (A-MSE: 1.60655) avg lploss: 0.00000
==> val epoch 150 avg loss: 2.13930 (A-MSE: 1.80367) avg lploss: 0.00000
==> test epoch 150 avg loss: 2.01462 (A-MSE: 1.69487) avg lploss: 0.00000
*** Best Val Loss: 2.13930 	 Best Test Loss: 2.01462 	 Best epoch 150
Validation loss decreased (2.210433 --> 2.139298).  Saving model ...
train epoch 151 avg loss: 1.89242 (A-MSE: 1.62531) avg lploss: 0.00000
train epoch 152 avg loss: 1.84805 (A-MSE: 1.58208) avg lploss: 0.00000
train epoch 153 avg loss: 1.84932 (A-MSE: 1.58441) avg lploss: 0.00000
train epoch 154 avg loss: 1.87636 (A-MSE: 1.60751) avg lploss: 0.00000
train epoch 155 avg loss: 1.86203 (A-MSE: 1.59565) avg lploss: 0.00000
==> val epoch 155 avg loss: 2.10347 (A-MSE: 1.77469) avg lploss: 0.00000
==> test epoch 155 avg loss: 1.96741 (A-MSE: 1.65442) avg lploss: 0.00000
*** Best Val Loss: 2.10347 	 Best Test Loss: 1.96741 	 Best epoch 155
Validation loss decreased (2.139298 --> 2.103471).  Saving model ...
train epoch 156 avg loss: 1.83108 (A-MSE: 1.57012) avg lploss: 0.00000
train epoch 157 avg loss: 1.84711 (A-MSE: 1.58410) avg lploss: 0.00000
train epoch 158 avg loss: 1.83508 (A-MSE: 1.56928) avg lploss: 0.00000
train epoch 159 avg loss: 1.83197 (A-MSE: 1.57019) avg lploss: 0.00000
train epoch 160 avg loss: 1.83962 (A-MSE: 1.57636) avg lploss: 0.00000
==> val epoch 160 avg loss: 2.06031 (A-MSE: 1.76150) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.91669 (A-MSE: 1.63340) avg lploss: 0.00000
*** Best Val Loss: 2.06031 	 Best Test Loss: 1.91669 	 Best epoch 160
Validation loss decreased (2.103471 --> 2.060312).  Saving model ...
train epoch 161 avg loss: 1.84042 (A-MSE: 1.58306) avg lploss: 0.00000
train epoch 162 avg loss: 1.89474 (A-MSE: 1.62891) avg lploss: 0.00000
train epoch 163 avg loss: 1.81301 (A-MSE: 1.54865) avg lploss: 0.00000
train epoch 164 avg loss: 1.78384 (A-MSE: 1.52863) avg lploss: 0.00000
train epoch 165 avg loss: 1.80886 (A-MSE: 1.55287) avg lploss: 0.00000
==> val epoch 165 avg loss: 2.04594 (A-MSE: 1.72156) avg lploss: 0.00000
==> test epoch 165 avg loss: 1.91985 (A-MSE: 1.61188) avg lploss: 0.00000
*** Best Val Loss: 2.04594 	 Best Test Loss: 1.91985 	 Best epoch 165
Validation loss decreased (2.060312 --> 2.045940).  Saving model ...
train epoch 166 avg loss: 1.81804 (A-MSE: 1.56526) avg lploss: 0.00000
train epoch 167 avg loss: 1.78146 (A-MSE: 1.52217) avg lploss: 0.00000
train epoch 168 avg loss: 1.74228 (A-MSE: 1.49199) avg lploss: 0.00000
train epoch 169 avg loss: 1.76793 (A-MSE: 1.51979) avg lploss: 0.00000
train epoch 170 avg loss: 1.86445 (A-MSE: 1.60133) avg lploss: 0.00000
==> val epoch 170 avg loss: 2.19342 (A-MSE: 1.88129) avg lploss: 0.00000
==> test epoch 170 avg loss: 2.07124 (A-MSE: 1.77460) avg lploss: 0.00000
*** Best Val Loss: 2.04594 	 Best Test Loss: 1.91985 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 1.79926 (A-MSE: 1.54517) avg lploss: 0.00000
train epoch 172 avg loss: 1.75228 (A-MSE: 1.50086) avg lploss: 0.00000
train epoch 173 avg loss: 1.73878 (A-MSE: 1.48518) avg lploss: 0.00000
train epoch 174 avg loss: 1.73940 (A-MSE: 1.49149) avg lploss: 0.00000
train epoch 175 avg loss: 1.72249 (A-MSE: 1.47033) avg lploss: 0.00000
==> val epoch 175 avg loss: 1.93372 (A-MSE: 1.63056) avg lploss: 0.00000
==> test epoch 175 avg loss: 1.79592 (A-MSE: 1.50912) avg lploss: 0.00000
*** Best Val Loss: 1.93372 	 Best Test Loss: 1.79592 	 Best epoch 175
Validation loss decreased (2.045940 --> 1.933720).  Saving model ...
train epoch 176 avg loss: 1.72692 (A-MSE: 1.47947) avg lploss: 0.00000
train epoch 177 avg loss: 1.73214 (A-MSE: 1.48607) avg lploss: 0.00000
train epoch 178 avg loss: 1.76016 (A-MSE: 1.51095) avg lploss: 0.00000
train epoch 179 avg loss: 1.71548 (A-MSE: 1.46869) avg lploss: 0.00000
train epoch 180 avg loss: 1.68121 (A-MSE: 1.43356) avg lploss: 0.00000
==> val epoch 180 avg loss: 1.89532 (A-MSE: 1.58964) avg lploss: 0.00000
==> test epoch 180 avg loss: 1.76931 (A-MSE: 1.47927) avg lploss: 0.00000
*** Best Val Loss: 1.89532 	 Best Test Loss: 1.76931 	 Best epoch 180
Validation loss decreased (1.933720 --> 1.895316).  Saving model ...
train epoch 181 avg loss: 1.65241 (A-MSE: 1.41419) avg lploss: 0.00000
train epoch 182 avg loss: 1.66501 (A-MSE: 1.42961) avg lploss: 0.00000
train epoch 183 avg loss: 1.70116 (A-MSE: 1.44953) avg lploss: 0.00000
train epoch 184 avg loss: 1.64708 (A-MSE: 1.41084) avg lploss: 0.00000
train epoch 185 avg loss: 1.66704 (A-MSE: 1.42911) avg lploss: 0.00000
==> val epoch 185 avg loss: 1.89166 (A-MSE: 1.59348) avg lploss: 0.00000
==> test epoch 185 avg loss: 1.76016 (A-MSE: 1.47821) avg lploss: 0.00000
*** Best Val Loss: 1.89166 	 Best Test Loss: 1.76016 	 Best epoch 185
Validation loss decreased (1.895316 --> 1.891665).  Saving model ...
train epoch 186 avg loss: 1.66212 (A-MSE: 1.42102) avg lploss: 0.00000
train epoch 187 avg loss: 1.70442 (A-MSE: 1.46658) avg lploss: 0.00000
train epoch 188 avg loss: 1.74215 (A-MSE: 1.49820) avg lploss: 0.00000
train epoch 189 avg loss: 1.67270 (A-MSE: 1.43131) avg lploss: 0.00000
train epoch 190 avg loss: 1.62639 (A-MSE: 1.38705) avg lploss: 0.00000
==> val epoch 190 avg loss: 1.88018 (A-MSE: 1.57591) avg lploss: 0.00000
==> test epoch 190 avg loss: 1.74468 (A-MSE: 1.45625) avg lploss: 0.00000
*** Best Val Loss: 1.88018 	 Best Test Loss: 1.74468 	 Best epoch 190
Validation loss decreased (1.891665 --> 1.880181).  Saving model ...
train epoch 191 avg loss: 1.65875 (A-MSE: 1.41996) avg lploss: 0.00000
train epoch 192 avg loss: 1.63317 (A-MSE: 1.39836) avg lploss: 0.00000
train epoch 193 avg loss: 1.62113 (A-MSE: 1.38494) avg lploss: 0.00000
train epoch 194 avg loss: 1.65332 (A-MSE: 1.42181) avg lploss: 0.00000
train epoch 195 avg loss: 1.64604 (A-MSE: 1.40704) avg lploss: 0.00000
==> val epoch 195 avg loss: 1.95044 (A-MSE: 1.64211) avg lploss: 0.00000
==> test epoch 195 avg loss: 1.82433 (A-MSE: 1.53341) avg lploss: 0.00000
*** Best Val Loss: 1.88018 	 Best Test Loss: 1.74468 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 1.63383 (A-MSE: 1.39214) avg lploss: 0.00000
train epoch 197 avg loss: 1.59650 (A-MSE: 1.37218) avg lploss: 0.00000
train epoch 198 avg loss: 1.60247 (A-MSE: 1.36837) avg lploss: 0.00000
train epoch 199 avg loss: 1.59573 (A-MSE: 1.36560) avg lploss: 0.00000
train epoch 200 avg loss: 1.58004 (A-MSE: 1.35341) avg lploss: 0.00000
==> val epoch 200 avg loss: 1.79890 (A-MSE: 1.50341) avg lploss: 0.00000
==> test epoch 200 avg loss: 1.67373 (A-MSE: 1.39386) avg lploss: 0.00000
*** Best Val Loss: 1.79890 	 Best Test Loss: 1.67373 	 Best epoch 200
Validation loss decreased (1.880181 --> 1.798905).  Saving model ...
train epoch 201 avg loss: 1.60132 (A-MSE: 1.36827) avg lploss: 0.00000
train epoch 202 avg loss: 1.61358 (A-MSE: 1.38297) avg lploss: 0.00000
train epoch 203 avg loss: 1.57561 (A-MSE: 1.34810) avg lploss: 0.00000
train epoch 204 avg loss: 1.57580 (A-MSE: 1.34961) avg lploss: 0.00000
train epoch 205 avg loss: 1.57750 (A-MSE: 1.34468) avg lploss: 0.00000
==> val epoch 205 avg loss: 1.77972 (A-MSE: 1.49923) avg lploss: 0.00000
==> test epoch 205 avg loss: 1.64494 (A-MSE: 1.37936) avg lploss: 0.00000
*** Best Val Loss: 1.77972 	 Best Test Loss: 1.64494 	 Best epoch 205
Validation loss decreased (1.798905 --> 1.779720).  Saving model ...
train epoch 206 avg loss: 1.54988 (A-MSE: 1.32710) avg lploss: 0.00000
train epoch 207 avg loss: 1.56955 (A-MSE: 1.34515) avg lploss: 0.00000
train epoch 208 avg loss: 1.59752 (A-MSE: 1.37087) avg lploss: 0.00000
train epoch 209 avg loss: 1.57316 (A-MSE: 1.34585) avg lploss: 0.00000
train epoch 210 avg loss: 1.58640 (A-MSE: 1.36167) avg lploss: 0.00000
==> val epoch 210 avg loss: 1.82556 (A-MSE: 1.53703) avg lploss: 0.00000
==> test epoch 210 avg loss: 1.70414 (A-MSE: 1.43090) avg lploss: 0.00000
*** Best Val Loss: 1.77972 	 Best Test Loss: 1.64494 	 Best epoch 205
EarlyStopping counter: 1 out of 50
train epoch 211 avg loss: 1.55811 (A-MSE: 1.32754) avg lploss: 0.00000
train epoch 212 avg loss: 1.58830 (A-MSE: 1.36404) avg lploss: 0.00000
train epoch 213 avg loss: 1.55902 (A-MSE: 1.33036) avg lploss: 0.00000
train epoch 214 avg loss: 1.59098 (A-MSE: 1.36813) avg lploss: 0.00000
train epoch 215 avg loss: 1.64923 (A-MSE: 1.41323) avg lploss: 0.00000
==> val epoch 215 avg loss: 1.84025 (A-MSE: 1.54681) avg lploss: 0.00000
==> test epoch 215 avg loss: 1.71657 (A-MSE: 1.43768) avg lploss: 0.00000
*** Best Val Loss: 1.77972 	 Best Test Loss: 1.64494 	 Best epoch 205
EarlyStopping counter: 2 out of 50
train epoch 216 avg loss: 1.54471 (A-MSE: 1.32021) avg lploss: 0.00000
train epoch 217 avg loss: 1.54780 (A-MSE: 1.32140) avg lploss: 0.00000
train epoch 218 avg loss: 1.53789 (A-MSE: 1.31824) avg lploss: 0.00000
train epoch 219 avg loss: 1.51282 (A-MSE: 1.29137) avg lploss: 0.00000
train epoch 220 avg loss: 1.52192 (A-MSE: 1.30131) avg lploss: 0.00000
==> val epoch 220 avg loss: 1.73736 (A-MSE: 1.45834) avg lploss: 0.00000
==> test epoch 220 avg loss: 1.60466 (A-MSE: 1.33986) avg lploss: 0.00000
*** Best Val Loss: 1.73736 	 Best Test Loss: 1.60466 	 Best epoch 220
Validation loss decreased (1.779720 --> 1.737361).  Saving model ...
train epoch 221 avg loss: 1.52278 (A-MSE: 1.30494) avg lploss: 0.00000
train epoch 222 avg loss: 1.52909 (A-MSE: 1.30671) avg lploss: 0.00000
train epoch 223 avg loss: 1.54418 (A-MSE: 1.32246) avg lploss: 0.00000
train epoch 224 avg loss: 1.51765 (A-MSE: 1.30096) avg lploss: 0.00000
train epoch 225 avg loss: 1.50262 (A-MSE: 1.27910) avg lploss: 0.00000
==> val epoch 225 avg loss: 1.72352 (A-MSE: 1.45156) avg lploss: 0.00000
==> test epoch 225 avg loss: 1.58200 (A-MSE: 1.32532) avg lploss: 0.00000
*** Best Val Loss: 1.72352 	 Best Test Loss: 1.58200 	 Best epoch 225
Validation loss decreased (1.737361 --> 1.723523).  Saving model ...
train epoch 226 avg loss: 1.50407 (A-MSE: 1.29085) avg lploss: 0.00000
train epoch 227 avg loss: 1.49365 (A-MSE: 1.27145) avg lploss: 0.00000
train epoch 228 avg loss: 1.45967 (A-MSE: 1.25000) avg lploss: 0.00000
train epoch 229 avg loss: 1.48794 (A-MSE: 1.26895) avg lploss: 0.00000
train epoch 230 avg loss: 1.46608 (A-MSE: 1.25706) avg lploss: 0.00000
==> val epoch 230 avg loss: 1.68402 (A-MSE: 1.42064) avg lploss: 0.00000
==> test epoch 230 avg loss: 1.54523 (A-MSE: 1.29540) avg lploss: 0.00000
*** Best Val Loss: 1.68402 	 Best Test Loss: 1.54523 	 Best epoch 230
Validation loss decreased (1.723523 --> 1.684024).  Saving model ...
train epoch 231 avg loss: 1.50071 (A-MSE: 1.28555) avg lploss: 0.00000
train epoch 232 avg loss: 1.48306 (A-MSE: 1.27122) avg lploss: 0.00000
train epoch 233 avg loss: 1.50903 (A-MSE: 1.29166) avg lploss: 0.00000
train epoch 234 avg loss: 1.46014 (A-MSE: 1.24595) avg lploss: 0.00000
train epoch 235 avg loss: 1.49701 (A-MSE: 1.28505) avg lploss: 0.00000
==> val epoch 235 avg loss: 1.71176 (A-MSE: 1.44399) avg lploss: 0.00000
==> test epoch 235 avg loss: 1.57548 (A-MSE: 1.32149) avg lploss: 0.00000
*** Best Val Loss: 1.68402 	 Best Test Loss: 1.54523 	 Best epoch 230
EarlyStopping counter: 1 out of 50
train epoch 236 avg loss: 1.54934 (A-MSE: 1.33074) avg lploss: 0.00000
train epoch 237 avg loss: 1.49909 (A-MSE: 1.27988) avg lploss: 0.00000
train epoch 238 avg loss: 1.44475 (A-MSE: 1.23055) avg lploss: 0.00000
train epoch 239 avg loss: 1.43309 (A-MSE: 1.22499) avg lploss: 0.00000
train epoch 240 avg loss: 1.41536 (A-MSE: 1.21003) avg lploss: 0.00000
==> val epoch 240 avg loss: 1.67499 (A-MSE: 1.40178) avg lploss: 0.00000
==> test epoch 240 avg loss: 1.53194 (A-MSE: 1.27233) avg lploss: 0.00000
*** Best Val Loss: 1.67499 	 Best Test Loss: 1.53194 	 Best epoch 240
Validation loss decreased (1.684024 --> 1.674986).  Saving model ...
train epoch 241 avg loss: 1.42797 (A-MSE: 1.22192) avg lploss: 0.00000
train epoch 242 avg loss: 1.40705 (A-MSE: 1.19910) avg lploss: 0.00000
train epoch 243 avg loss: 1.42910 (A-MSE: 1.22660) avg lploss: 0.00000
train epoch 244 avg loss: 1.41093 (A-MSE: 1.20285) avg lploss: 0.00000
train epoch 245 avg loss: 1.45232 (A-MSE: 1.24878) avg lploss: 0.00000
==> val epoch 245 avg loss: 1.70037 (A-MSE: 1.42909) avg lploss: 0.00000
==> test epoch 245 avg loss: 1.55596 (A-MSE: 1.29830) avg lploss: 0.00000
*** Best Val Loss: 1.67499 	 Best Test Loss: 1.53194 	 Best epoch 240
EarlyStopping counter: 1 out of 50
train epoch 246 avg loss: 1.47257 (A-MSE: 1.26432) avg lploss: 0.00000
train epoch 247 avg loss: 1.40581 (A-MSE: 1.19979) avg lploss: 0.00000
train epoch 248 avg loss: 1.42497 (A-MSE: 1.21764) avg lploss: 0.00000
train epoch 249 avg loss: 1.43082 (A-MSE: 1.22706) avg lploss: 0.00000
train epoch 250 avg loss: 1.46111 (A-MSE: 1.25258) avg lploss: 0.00000
==> val epoch 250 avg loss: 1.67709 (A-MSE: 1.42015) avg lploss: 0.00000
==> test epoch 250 avg loss: 1.54063 (A-MSE: 1.29637) avg lploss: 0.00000
*** Best Val Loss: 1.67499 	 Best Test Loss: 1.53194 	 Best epoch 240
EarlyStopping counter: 2 out of 50
train epoch 251 avg loss: 1.39642 (A-MSE: 1.19304) avg lploss: 0.00000
train epoch 252 avg loss: 1.38713 (A-MSE: 1.18501) avg lploss: 0.00000
train epoch 253 avg loss: 1.48225 (A-MSE: 1.27391) avg lploss: 0.00000
train epoch 254 avg loss: 1.43508 (A-MSE: 1.22779) avg lploss: 0.00000
train epoch 255 avg loss: 1.40324 (A-MSE: 1.19685) avg lploss: 0.00000
==> val epoch 255 avg loss: 1.71570 (A-MSE: 1.46521) avg lploss: 0.00000
==> test epoch 255 avg loss: 1.55493 (A-MSE: 1.31784) avg lploss: 0.00000
*** Best Val Loss: 1.67499 	 Best Test Loss: 1.53194 	 Best epoch 240
EarlyStopping counter: 3 out of 50
train epoch 256 avg loss: 1.40223 (A-MSE: 1.19905) avg lploss: 0.00000
train epoch 257 avg loss: 1.37850 (A-MSE: 1.17561) avg lploss: 0.00000
train epoch 258 avg loss: 1.41801 (A-MSE: 1.22032) avg lploss: 0.00000
train epoch 259 avg loss: 1.44896 (A-MSE: 1.24105) avg lploss: 0.00000
train epoch 260 avg loss: 1.39169 (A-MSE: 1.19276) avg lploss: 0.00000
==> val epoch 260 avg loss: 1.66550 (A-MSE: 1.40614) avg lploss: 0.00000
==> test epoch 260 avg loss: 1.52114 (A-MSE: 1.27596) avg lploss: 0.00000
*** Best Val Loss: 1.66550 	 Best Test Loss: 1.52114 	 Best epoch 260
Validation loss decreased (1.674986 --> 1.665504).  Saving model ...
train epoch 261 avg loss: 1.36290 (A-MSE: 1.16085) avg lploss: 0.00000
train epoch 262 avg loss: 1.33674 (A-MSE: 1.14058) avg lploss: 0.00000
train epoch 263 avg loss: 1.38881 (A-MSE: 1.19130) avg lploss: 0.00000
train epoch 264 avg loss: 1.39235 (A-MSE: 1.19233) avg lploss: 0.00000
train epoch 265 avg loss: 1.37933 (A-MSE: 1.17674) avg lploss: 0.00000
==> val epoch 265 avg loss: 1.60155 (A-MSE: 1.35080) avg lploss: 0.00000
==> test epoch 265 avg loss: 1.45418 (A-MSE: 1.21627) avg lploss: 0.00000
*** Best Val Loss: 1.60155 	 Best Test Loss: 1.45418 	 Best epoch 265
Validation loss decreased (1.665504 --> 1.601552).  Saving model ...
train epoch 266 avg loss: 1.32549 (A-MSE: 1.13074) avg lploss: 0.00000
train epoch 267 avg loss: 1.35351 (A-MSE: 1.15499) avg lploss: 0.00000
train epoch 268 avg loss: 1.36205 (A-MSE: 1.16676) avg lploss: 0.00000
train epoch 269 avg loss: 1.35423 (A-MSE: 1.15641) avg lploss: 0.00000
train epoch 270 avg loss: 1.40001 (A-MSE: 1.20550) avg lploss: 0.00000
==> val epoch 270 avg loss: 1.73190 (A-MSE: 1.48068) avg lploss: 0.00000
==> test epoch 270 avg loss: 1.57497 (A-MSE: 1.33482) avg lploss: 0.00000
*** Best Val Loss: 1.60155 	 Best Test Loss: 1.45418 	 Best epoch 265
EarlyStopping counter: 1 out of 50
train epoch 271 avg loss: 1.37680 (A-MSE: 1.17746) avg lploss: 0.00000
train epoch 272 avg loss: 1.32346 (A-MSE: 1.12927) avg lploss: 0.00000
train epoch 273 avg loss: 1.36224 (A-MSE: 1.16632) avg lploss: 0.00000
train epoch 274 avg loss: 1.32695 (A-MSE: 1.13535) avg lploss: 0.00000
train epoch 275 avg loss: 1.32748 (A-MSE: 1.13373) avg lploss: 0.00000
==> val epoch 275 avg loss: 1.55362 (A-MSE: 1.31267) avg lploss: 0.00000
==> test epoch 275 avg loss: 1.41541 (A-MSE: 1.18573) avg lploss: 0.00000
*** Best Val Loss: 1.55362 	 Best Test Loss: 1.41541 	 Best epoch 275
Validation loss decreased (1.601552 --> 1.553624).  Saving model ...
train epoch 276 avg loss: 1.32186 (A-MSE: 1.13006) avg lploss: 0.00000
train epoch 277 avg loss: 1.30923 (A-MSE: 1.12107) avg lploss: 0.00000
train epoch 278 avg loss: 1.28792 (A-MSE: 1.09793) avg lploss: 0.00000
train epoch 279 avg loss: 1.28636 (A-MSE: 1.09758) avg lploss: 0.00000
train epoch 280 avg loss: 1.31000 (A-MSE: 1.12485) avg lploss: 0.00000
==> val epoch 280 avg loss: 1.57593 (A-MSE: 1.33574) avg lploss: 0.00000
==> test epoch 280 avg loss: 1.41381 (A-MSE: 1.18476) avg lploss: 0.00000
*** Best Val Loss: 1.55362 	 Best Test Loss: 1.41541 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 1.33408 (A-MSE: 1.14108) avg lploss: 0.00000
train epoch 282 avg loss: 1.37429 (A-MSE: 1.18455) avg lploss: 0.00000
train epoch 283 avg loss: 1.33352 (A-MSE: 1.13725) avg lploss: 0.00000
train epoch 284 avg loss: 1.32111 (A-MSE: 1.12698) avg lploss: 0.00000
train epoch 285 avg loss: 1.29569 (A-MSE: 1.10950) avg lploss: 0.00000
==> val epoch 285 avg loss: 1.51784 (A-MSE: 1.29657) avg lploss: 0.00000
==> test epoch 285 avg loss: 1.36335 (A-MSE: 1.15367) avg lploss: 0.00000
*** Best Val Loss: 1.51784 	 Best Test Loss: 1.36335 	 Best epoch 285
Validation loss decreased (1.553624 --> 1.517844).  Saving model ...
train epoch 286 avg loss: 1.31756 (A-MSE: 1.12589) avg lploss: 0.00000
train epoch 287 avg loss: 1.30582 (A-MSE: 1.11491) avg lploss: 0.00000
train epoch 288 avg loss: 1.23868 (A-MSE: 1.05688) avg lploss: 0.00000
train epoch 289 avg loss: 1.28530 (A-MSE: 1.09986) avg lploss: 0.00000
train epoch 290 avg loss: 1.36411 (A-MSE: 1.17979) avg lploss: 0.00000
==> val epoch 290 avg loss: 1.62640 (A-MSE: 1.38936) avg lploss: 0.00000
==> test epoch 290 avg loss: 1.49279 (A-MSE: 1.26489) avg lploss: 0.00000
*** Best Val Loss: 1.51784 	 Best Test Loss: 1.36335 	 Best epoch 285
EarlyStopping counter: 1 out of 50
train epoch 291 avg loss: 1.32512 (A-MSE: 1.13330) avg lploss: 0.00000
train epoch 292 avg loss: 1.29373 (A-MSE: 1.10514) avg lploss: 0.00000
train epoch 293 avg loss: 1.28871 (A-MSE: 1.10111) avg lploss: 0.00000
train epoch 294 avg loss: 1.27493 (A-MSE: 1.08965) avg lploss: 0.00000
train epoch 295 avg loss: 1.23885 (A-MSE: 1.05791) avg lploss: 0.00000
==> val epoch 295 avg loss: 1.46670 (A-MSE: 1.24107) avg lploss: 0.00000
==> test epoch 295 avg loss: 1.31989 (A-MSE: 1.10709) avg lploss: 0.00000
*** Best Val Loss: 1.46670 	 Best Test Loss: 1.31989 	 Best epoch 295
Validation loss decreased (1.517844 --> 1.466703).  Saving model ...
train epoch 296 avg loss: 1.23767 (A-MSE: 1.05325) avg lploss: 0.00000
train epoch 297 avg loss: 1.19357 (A-MSE: 1.01849) avg lploss: 0.00000
train epoch 298 avg loss: 1.23032 (A-MSE: 1.05129) avg lploss: 0.00000
train epoch 299 avg loss: 1.24431 (A-MSE: 1.06605) avg lploss: 0.00000
train epoch 300 avg loss: 1.43147 (A-MSE: 1.24209) avg lploss: 0.00000
==> val epoch 300 avg loss: 1.67213 (A-MSE: 1.40456) avg lploss: 0.00000
==> test epoch 300 avg loss: 1.54781 (A-MSE: 1.29170) avg lploss: 0.00000
*** Best Val Loss: 1.46670 	 Best Test Loss: 1.31989 	 Best epoch 295
EarlyStopping counter: 1 out of 50
train epoch 301 avg loss: 1.30045 (A-MSE: 1.11088) avg lploss: 0.00000
train epoch 302 avg loss: 1.25168 (A-MSE: 1.07325) avg lploss: 0.00000
train epoch 303 avg loss: 1.27863 (A-MSE: 1.08916) avg lploss: 0.00000
train epoch 304 avg loss: 1.19954 (A-MSE: 1.02331) avg lploss: 0.00000
train epoch 305 avg loss: 1.28300 (A-MSE: 1.10136) avg lploss: 0.00000
==> val epoch 305 avg loss: 1.52138 (A-MSE: 1.31067) avg lploss: 0.00000
==> test epoch 305 avg loss: 1.37488 (A-MSE: 1.17385) avg lploss: 0.00000
*** Best Val Loss: 1.46670 	 Best Test Loss: 1.31989 	 Best epoch 295
EarlyStopping counter: 2 out of 50
train epoch 306 avg loss: 1.24228 (A-MSE: 1.06390) avg lploss: 0.00000
train epoch 307 avg loss: 1.25362 (A-MSE: 1.07447) avg lploss: 0.00000
train epoch 308 avg loss: 1.21535 (A-MSE: 1.03526) avg lploss: 0.00000
train epoch 309 avg loss: 1.22098 (A-MSE: 1.04173) avg lploss: 0.00000
train epoch 310 avg loss: 1.17852 (A-MSE: 1.00264) avg lploss: 0.00000
==> val epoch 310 avg loss: 1.40539 (A-MSE: 1.19209) avg lploss: 0.00000
==> test epoch 310 avg loss: 1.25576 (A-MSE: 1.05366) avg lploss: 0.00000
*** Best Val Loss: 1.40539 	 Best Test Loss: 1.25576 	 Best epoch 310
Validation loss decreased (1.466703 --> 1.405394).  Saving model ...
train epoch 311 avg loss: 1.15981 (A-MSE: 0.99039) avg lploss: 0.00000
train epoch 312 avg loss: 1.35967 (A-MSE: 1.19300) avg lploss: 0.00000
train epoch 313 avg loss: 1.34355 (A-MSE: 1.15269) avg lploss: 0.00000
train epoch 314 avg loss: 1.21080 (A-MSE: 1.02768) avg lploss: 0.00000
train epoch 315 avg loss: 1.15887 (A-MSE: 0.98475) avg lploss: 0.00000
==> val epoch 315 avg loss: 1.38284 (A-MSE: 1.16918) avg lploss: 0.00000
==> test epoch 315 avg loss: 1.23777 (A-MSE: 1.03382) avg lploss: 0.00000
*** Best Val Loss: 1.38284 	 Best Test Loss: 1.23777 	 Best epoch 315
Validation loss decreased (1.405394 --> 1.382842).  Saving model ...
train epoch 316 avg loss: 1.18620 (A-MSE: 1.01837) avg lploss: 0.00000
train epoch 317 avg loss: 1.18909 (A-MSE: 1.01229) avg lploss: 0.00000
train epoch 318 avg loss: 1.15104 (A-MSE: 0.98364) avg lploss: 0.00000
train epoch 319 avg loss: 1.15706 (A-MSE: 0.98644) avg lploss: 0.00000
train epoch 320 avg loss: 1.17378 (A-MSE: 1.00667) avg lploss: 0.00000
==> val epoch 320 avg loss: 1.40954 (A-MSE: 1.19911) avg lploss: 0.00000
==> test epoch 320 avg loss: 1.26010 (A-MSE: 1.05943) avg lploss: 0.00000
*** Best Val Loss: 1.38284 	 Best Test Loss: 1.23777 	 Best epoch 315
EarlyStopping counter: 1 out of 50
train epoch 321 avg loss: 1.13137 (A-MSE: 0.96361) avg lploss: 0.00000
train epoch 322 avg loss: 1.14036 (A-MSE: 0.97677) avg lploss: 0.00000
train epoch 323 avg loss: 1.16305 (A-MSE: 0.99338) avg lploss: 0.00000
train epoch 324 avg loss: 1.19762 (A-MSE: 1.02876) avg lploss: 0.00000
train epoch 325 avg loss: 1.17328 (A-MSE: 1.00020) avg lploss: 0.00000
==> val epoch 325 avg loss: 1.37038 (A-MSE: 1.17948) avg lploss: 0.00000
==> test epoch 325 avg loss: 1.22465 (A-MSE: 1.04218) avg lploss: 0.00000
*** Best Val Loss: 1.37038 	 Best Test Loss: 1.22465 	 Best epoch 325
Validation loss decreased (1.382842 --> 1.370379).  Saving model ...
train epoch 326 avg loss: 1.15074 (A-MSE: 0.98495) avg lploss: 0.00000
train epoch 327 avg loss: 1.11928 (A-MSE: 0.95647) avg lploss: 0.00000
train epoch 328 avg loss: 1.15336 (A-MSE: 0.99176) avg lploss: 0.00000
train epoch 329 avg loss: 1.31094 (A-MSE: 1.13118) avg lploss: 0.00000
train epoch 330 avg loss: 1.15112 (A-MSE: 0.98700) avg lploss: 0.00000
==> val epoch 330 avg loss: 1.31463 (A-MSE: 1.10369) avg lploss: 0.00000
==> test epoch 330 avg loss: 1.16834 (A-MSE: 0.96742) avg lploss: 0.00000
*** Best Val Loss: 1.31463 	 Best Test Loss: 1.16834 	 Best epoch 330
Validation loss decreased (1.370379 --> 1.314628).  Saving model ...
train epoch 331 avg loss: 1.12375 (A-MSE: 0.95787) avg lploss: 0.00000
train epoch 332 avg loss: 1.11645 (A-MSE: 0.95391) avg lploss: 0.00000
train epoch 333 avg loss: 1.12631 (A-MSE: 0.96468) avg lploss: 0.00000
train epoch 334 avg loss: 1.13789 (A-MSE: 0.97537) avg lploss: 0.00000
train epoch 335 avg loss: 1.17336 (A-MSE: 1.00918) avg lploss: 0.00000
==> val epoch 335 avg loss: 1.36648 (A-MSE: 1.14272) avg lploss: 0.00000
==> test epoch 335 avg loss: 1.22481 (A-MSE: 1.01108) avg lploss: 0.00000
*** Best Val Loss: 1.31463 	 Best Test Loss: 1.16834 	 Best epoch 330
EarlyStopping counter: 1 out of 50
train epoch 336 avg loss: 1.09491 (A-MSE: 0.93212) avg lploss: 0.00000
train epoch 337 avg loss: 1.08680 (A-MSE: 0.92623) avg lploss: 0.00000
train epoch 338 avg loss: 1.09263 (A-MSE: 0.94091) avg lploss: 0.00000
train epoch 339 avg loss: 1.10005 (A-MSE: 0.93859) avg lploss: 0.00000
train epoch 340 avg loss: 1.11728 (A-MSE: 0.95829) avg lploss: 0.00000
==> val epoch 340 avg loss: 1.36893 (A-MSE: 1.16745) avg lploss: 0.00000
==> test epoch 340 avg loss: 1.22453 (A-MSE: 1.03210) avg lploss: 0.00000
*** Best Val Loss: 1.31463 	 Best Test Loss: 1.16834 	 Best epoch 330
EarlyStopping counter: 2 out of 50
train epoch 341 avg loss: 1.11264 (A-MSE: 0.95486) avg lploss: 0.00000
train epoch 342 avg loss: 1.12012 (A-MSE: 0.96175) avg lploss: 0.00000
train epoch 343 avg loss: 1.15618 (A-MSE: 0.99681) avg lploss: 0.00000
train epoch 344 avg loss: 1.11906 (A-MSE: 0.95975) avg lploss: 0.00000
train epoch 345 avg loss: 1.15332 (A-MSE: 0.99398) avg lploss: 0.00000
==> val epoch 345 avg loss: 1.42625 (A-MSE: 1.20436) avg lploss: 0.00000
==> test epoch 345 avg loss: 1.28235 (A-MSE: 1.06799) avg lploss: 0.00000
*** Best Val Loss: 1.31463 	 Best Test Loss: 1.16834 	 Best epoch 330
EarlyStopping counter: 3 out of 50
train epoch 346 avg loss: 1.15114 (A-MSE: 0.99082) avg lploss: 0.00000
train epoch 347 avg loss: 1.08579 (A-MSE: 0.92674) avg lploss: 0.00000
train epoch 348 avg loss: 1.07184 (A-MSE: 0.91871) avg lploss: 0.00000
train epoch 349 avg loss: 1.06982 (A-MSE: 0.91433) avg lploss: 0.00000
train epoch 350 avg loss: 1.04679 (A-MSE: 0.89630) avg lploss: 0.00000
==> val epoch 350 avg loss: 1.22738 (A-MSE: 1.04369) avg lploss: 0.00000
==> test epoch 350 avg loss: 1.09042 (A-MSE: 0.91386) avg lploss: 0.00000
*** Best Val Loss: 1.22738 	 Best Test Loss: 1.09042 	 Best epoch 350
Validation loss decreased (1.314628 --> 1.227379).  Saving model ...
train epoch 351 avg loss: 1.04507 (A-MSE: 0.89640) avg lploss: 0.00000
train epoch 352 avg loss: 1.02609 (A-MSE: 0.87652) avg lploss: 0.00000
train epoch 353 avg loss: 1.00559 (A-MSE: 0.86282) avg lploss: 0.00000
train epoch 354 avg loss: 1.03523 (A-MSE: 0.88639) avg lploss: 0.00000
train epoch 355 avg loss: 1.04531 (A-MSE: 0.89885) avg lploss: 0.00000
==> val epoch 355 avg loss: 1.23332 (A-MSE: 1.04388) avg lploss: 0.00000
==> test epoch 355 avg loss: 1.11281 (A-MSE: 0.93143) avg lploss: 0.00000
*** Best Val Loss: 1.22738 	 Best Test Loss: 1.09042 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 1.04035 (A-MSE: 0.88880) avg lploss: 0.00000
train epoch 357 avg loss: 1.06619 (A-MSE: 0.91636) avg lploss: 0.00000
train epoch 358 avg loss: 1.08377 (A-MSE: 0.93231) avg lploss: 0.00000
train epoch 359 avg loss: 1.04926 (A-MSE: 0.90251) avg lploss: 0.00000
train epoch 360 avg loss: 1.09709 (A-MSE: 0.94573) avg lploss: 0.00000
==> val epoch 360 avg loss: 1.33675 (A-MSE: 1.13067) avg lploss: 0.00000
==> test epoch 360 avg loss: 1.20073 (A-MSE: 1.00137) avg lploss: 0.00000
*** Best Val Loss: 1.22738 	 Best Test Loss: 1.09042 	 Best epoch 350
EarlyStopping counter: 2 out of 50
train epoch 361 avg loss: 1.10439 (A-MSE: 0.95225) avg lploss: 0.00000
train epoch 362 avg loss: 1.03339 (A-MSE: 0.88325) avg lploss: 0.00000
train epoch 363 avg loss: 0.99272 (A-MSE: 0.85172) avg lploss: 0.00000
train epoch 364 avg loss: 1.06588 (A-MSE: 0.91815) avg lploss: 0.00000
train epoch 365 avg loss: 1.02030 (A-MSE: 0.87574) avg lploss: 0.00000
==> val epoch 365 avg loss: 1.15884 (A-MSE: 0.99005) avg lploss: 0.00000
==> test epoch 365 avg loss: 1.01702 (A-MSE: 0.85555) avg lploss: 0.00000
*** Best Val Loss: 1.15884 	 Best Test Loss: 1.01702 	 Best epoch 365
Validation loss decreased (1.227379 --> 1.158836).  Saving model ...
train epoch 366 avg loss: 0.98384 (A-MSE: 0.84311) avg lploss: 0.00000
train epoch 367 avg loss: 0.98979 (A-MSE: 0.84594) avg lploss: 0.00000
train epoch 368 avg loss: 0.99737 (A-MSE: 0.85853) avg lploss: 0.00000
train epoch 369 avg loss: 1.01451 (A-MSE: 0.87140) avg lploss: 0.00000
train epoch 370 avg loss: 0.98126 (A-MSE: 0.84216) avg lploss: 0.00000
==> val epoch 370 avg loss: 1.23014 (A-MSE: 1.04827) avg lploss: 0.00000
==> test epoch 370 avg loss: 1.07769 (A-MSE: 0.90299) avg lploss: 0.00000
*** Best Val Loss: 1.15884 	 Best Test Loss: 1.01702 	 Best epoch 365
EarlyStopping counter: 1 out of 50
train epoch 371 avg loss: 1.00024 (A-MSE: 0.85952) avg lploss: 0.00000
train epoch 372 avg loss: 1.03697 (A-MSE: 0.89478) avg lploss: 0.00000
train epoch 373 avg loss: 0.97061 (A-MSE: 0.83415) avg lploss: 0.00000
train epoch 374 avg loss: 0.94375 (A-MSE: 0.80885) avg lploss: 0.00000
train epoch 375 avg loss: 0.97489 (A-MSE: 0.83842) avg lploss: 0.00000
==> val epoch 375 avg loss: 1.18283 (A-MSE: 1.00477) avg lploss: 0.00000
==> test epoch 375 avg loss: 1.03156 (A-MSE: 0.86148) avg lploss: 0.00000
*** Best Val Loss: 1.15884 	 Best Test Loss: 1.01702 	 Best epoch 365
EarlyStopping counter: 2 out of 50
train epoch 376 avg loss: 0.96209 (A-MSE: 0.82854) avg lploss: 0.00000
train epoch 377 avg loss: 0.96549 (A-MSE: 0.83016) avg lploss: 0.00000
train epoch 378 avg loss: 0.96385 (A-MSE: 0.82874) avg lploss: 0.00000
train epoch 379 avg loss: 0.96219 (A-MSE: 0.82685) avg lploss: 0.00000
train epoch 380 avg loss: 0.93299 (A-MSE: 0.80194) avg lploss: 0.00000
==> val epoch 380 avg loss: 1.10974 (A-MSE: 0.94557) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.96828 (A-MSE: 0.81148) avg lploss: 0.00000
*** Best Val Loss: 1.10974 	 Best Test Loss: 0.96828 	 Best epoch 380
Validation loss decreased (1.158836 --> 1.109735).  Saving model ...
train epoch 381 avg loss: 0.91189 (A-MSE: 0.78562) avg lploss: 0.00000
train epoch 382 avg loss: 1.07226 (A-MSE: 0.93114) avg lploss: 0.00000
train epoch 383 avg loss: 1.01221 (A-MSE: 0.87390) avg lploss: 0.00000
train epoch 384 avg loss: 0.91462 (A-MSE: 0.78260) avg lploss: 0.00000
train epoch 385 avg loss: 0.92484 (A-MSE: 0.79301) avg lploss: 0.00000
==> val epoch 385 avg loss: 1.12428 (A-MSE: 0.96810) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.99667 (A-MSE: 0.84818) avg lploss: 0.00000
*** Best Val Loss: 1.10974 	 Best Test Loss: 0.96828 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.96448 (A-MSE: 0.83040) avg lploss: 0.00000
train epoch 387 avg loss: 0.92758 (A-MSE: 0.79789) avg lploss: 0.00000
train epoch 388 avg loss: 0.91401 (A-MSE: 0.78359) avg lploss: 0.00000
train epoch 389 avg loss: 0.90746 (A-MSE: 0.77960) avg lploss: 0.00000
train epoch 390 avg loss: 0.89481 (A-MSE: 0.77101) avg lploss: 0.00000
==> val epoch 390 avg loss: 1.04645 (A-MSE: 0.88782) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.92999 (A-MSE: 0.77758) avg lploss: 0.00000
*** Best Val Loss: 1.04645 	 Best Test Loss: 0.92999 	 Best epoch 390
Validation loss decreased (1.109735 --> 1.046447).  Saving model ...
train epoch 391 avg loss: 0.86843 (A-MSE: 0.74645) avg lploss: 0.00000
train epoch 392 avg loss: 0.95077 (A-MSE: 0.82045) avg lploss: 0.00000
train epoch 393 avg loss: 0.89266 (A-MSE: 0.76840) avg lploss: 0.00000
train epoch 394 avg loss: 0.88118 (A-MSE: 0.75680) avg lploss: 0.00000
train epoch 395 avg loss: 0.86758 (A-MSE: 0.74665) avg lploss: 0.00000
==> val epoch 395 avg loss: 1.08791 (A-MSE: 0.92358) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.96265 (A-MSE: 0.80402) avg lploss: 0.00000
*** Best Val Loss: 1.04645 	 Best Test Loss: 0.92999 	 Best epoch 390
EarlyStopping counter: 1 out of 50
train epoch 396 avg loss: 0.86754 (A-MSE: 0.74573) avg lploss: 0.00000
train epoch 397 avg loss: 0.87324 (A-MSE: 0.74980) avg lploss: 0.00000
train epoch 398 avg loss: 0.84943 (A-MSE: 0.73003) avg lploss: 0.00000
train epoch 399 avg loss: 0.88019 (A-MSE: 0.76039) avg lploss: 0.00000
train epoch 400 avg loss: 0.84785 (A-MSE: 0.72953) avg lploss: 0.00000
==> val epoch 400 avg loss: 1.03805 (A-MSE: 0.89074) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.90552 (A-MSE: 0.76660) avg lploss: 0.00000
*** Best Val Loss: 1.03805 	 Best Test Loss: 0.90552 	 Best epoch 400
Validation loss decreased (1.046447 --> 1.038051).  Saving model ...
train epoch 401 avg loss: 0.83643 (A-MSE: 0.71913) avg lploss: 0.00000
train epoch 402 avg loss: 0.85057 (A-MSE: 0.73456) avg lploss: 0.00000
train epoch 403 avg loss: 0.88258 (A-MSE: 0.76420) avg lploss: 0.00000
train epoch 404 avg loss: 0.87314 (A-MSE: 0.75118) avg lploss: 0.00000
train epoch 405 avg loss: 0.89748 (A-MSE: 0.77323) avg lploss: 0.00000
==> val epoch 405 avg loss: 1.17515 (A-MSE: 1.03133) avg lploss: 0.00000
==> test epoch 405 avg loss: 1.03324 (A-MSE: 0.89945) avg lploss: 0.00000
*** Best Val Loss: 1.03805 	 Best Test Loss: 0.90552 	 Best epoch 400
EarlyStopping counter: 1 out of 50
train epoch 406 avg loss: 1.10352 (A-MSE: 0.96336) avg lploss: 0.00000
train epoch 407 avg loss: 0.87628 (A-MSE: 0.75710) avg lploss: 0.00000
train epoch 408 avg loss: 0.83130 (A-MSE: 0.71354) avg lploss: 0.00000
train epoch 409 avg loss: 0.85431 (A-MSE: 0.74061) avg lploss: 0.00000
train epoch 410 avg loss: 0.79055 (A-MSE: 0.67669) avg lploss: 0.00000
==> val epoch 410 avg loss: 1.02413 (A-MSE: 0.88746) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.89120 (A-MSE: 0.76302) avg lploss: 0.00000
*** Best Val Loss: 1.02413 	 Best Test Loss: 0.89120 	 Best epoch 410
Validation loss decreased (1.038051 --> 1.024126).  Saving model ...
train epoch 411 avg loss: 0.82477 (A-MSE: 0.70933) avg lploss: 0.00000
train epoch 412 avg loss: 0.81697 (A-MSE: 0.70426) avg lploss: 0.00000
train epoch 413 avg loss: 0.82057 (A-MSE: 0.70779) avg lploss: 0.00000
train epoch 414 avg loss: 0.78401 (A-MSE: 0.67521) avg lploss: 0.00000
train epoch 415 avg loss: 0.78599 (A-MSE: 0.67638) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.93497 (A-MSE: 0.81228) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.80300 (A-MSE: 0.68904) avg lploss: 0.00000
*** Best Val Loss: 0.93497 	 Best Test Loss: 0.80300 	 Best epoch 415
Validation loss decreased (1.024126 --> 0.934966).  Saving model ...
train epoch 416 avg loss: 0.78644 (A-MSE: 0.67742) avg lploss: 0.00000
train epoch 417 avg loss: 0.78009 (A-MSE: 0.67209) avg lploss: 0.00000
train epoch 418 avg loss: 0.84492 (A-MSE: 0.73095) avg lploss: 0.00000
train epoch 419 avg loss: 0.85065 (A-MSE: 0.73534) avg lploss: 0.00000
train epoch 420 avg loss: 0.80517 (A-MSE: 0.69425) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.97996 (A-MSE: 0.84195) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.84563 (A-MSE: 0.71922) avg lploss: 0.00000
*** Best Val Loss: 0.93497 	 Best Test Loss: 0.80300 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 0.77597 (A-MSE: 0.66582) avg lploss: 0.00000
train epoch 422 avg loss: 0.76129 (A-MSE: 0.65606) avg lploss: 0.00000
train epoch 423 avg loss: 0.90114 (A-MSE: 0.78559) avg lploss: 0.00000
train epoch 424 avg loss: 0.79104 (A-MSE: 0.67997) avg lploss: 0.00000
train epoch 425 avg loss: 0.78589 (A-MSE: 0.67970) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.95315 (A-MSE: 0.80506) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.85873 (A-MSE: 0.71982) avg lploss: 0.00000
*** Best Val Loss: 0.93497 	 Best Test Loss: 0.80300 	 Best epoch 415
EarlyStopping counter: 2 out of 50
train epoch 426 avg loss: 0.73275 (A-MSE: 0.63090) avg lploss: 0.00000
train epoch 427 avg loss: 0.70752 (A-MSE: 0.60843) avg lploss: 0.00000
train epoch 428 avg loss: 0.73729 (A-MSE: 0.63595) avg lploss: 0.00000
train epoch 429 avg loss: 0.74825 (A-MSE: 0.64691) avg lploss: 0.00000
train epoch 430 avg loss: 0.75002 (A-MSE: 0.64717) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.99337 (A-MSE: 0.84002) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.85534 (A-MSE: 0.71509) avg lploss: 0.00000
*** Best Val Loss: 0.93497 	 Best Test Loss: 0.80300 	 Best epoch 415
EarlyStopping counter: 3 out of 50
train epoch 431 avg loss: 0.74380 (A-MSE: 0.64145) avg lploss: 0.00000
train epoch 432 avg loss: 0.72364 (A-MSE: 0.62847) avg lploss: 0.00000
train epoch 433 avg loss: 0.76564 (A-MSE: 0.65943) avg lploss: 0.00000
train epoch 434 avg loss: 0.83837 (A-MSE: 0.73076) avg lploss: 0.00000
train epoch 435 avg loss: 0.82621 (A-MSE: 0.71310) avg lploss: 0.00000
==> val epoch 435 avg loss: 1.08359 (A-MSE: 0.95269) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.93847 (A-MSE: 0.81955) avg lploss: 0.00000
*** Best Val Loss: 0.93497 	 Best Test Loss: 0.80300 	 Best epoch 415
EarlyStopping counter: 4 out of 50
train epoch 436 avg loss: 0.80456 (A-MSE: 0.69472) avg lploss: 0.00000
train epoch 437 avg loss: 0.73431 (A-MSE: 0.63298) avg lploss: 0.00000
train epoch 438 avg loss: 0.75451 (A-MSE: 0.65253) avg lploss: 0.00000
train epoch 439 avg loss: 0.72624 (A-MSE: 0.62910) avg lploss: 0.00000
train epoch 440 avg loss: 0.67655 (A-MSE: 0.58018) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.96304 (A-MSE: 0.80279) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.87451 (A-MSE: 0.72472) avg lploss: 0.00000
*** Best Val Loss: 0.93497 	 Best Test Loss: 0.80300 	 Best epoch 415
EarlyStopping counter: 5 out of 50
train epoch 441 avg loss: 0.70790 (A-MSE: 0.61138) avg lploss: 0.00000
train epoch 442 avg loss: 0.71211 (A-MSE: 0.61460) avg lploss: 0.00000
train epoch 443 avg loss: 0.69024 (A-MSE: 0.59539) avg lploss: 0.00000
train epoch 444 avg loss: 0.64807 (A-MSE: 0.55863) avg lploss: 0.00000
train epoch 445 avg loss: 0.70561 (A-MSE: 0.61319) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.86964 (A-MSE: 0.74879) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.77964 (A-MSE: 0.67015) avg lploss: 0.00000
*** Best Val Loss: 0.86964 	 Best Test Loss: 0.77964 	 Best epoch 445
Validation loss decreased (0.934966 --> 0.869639).  Saving model ...
train epoch 446 avg loss: 0.65585 (A-MSE: 0.56392) avg lploss: 0.00000
train epoch 447 avg loss: 0.63187 (A-MSE: 0.54450) avg lploss: 0.00000
train epoch 448 avg loss: 0.91086 (A-MSE: 0.80155) avg lploss: 0.00000
train epoch 449 avg loss: 0.77740 (A-MSE: 0.67407) avg lploss: 0.00000
train epoch 450 avg loss: 0.68882 (A-MSE: 0.59242) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.91140 (A-MSE: 0.78417) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.79303 (A-MSE: 0.67755) avg lploss: 0.00000
*** Best Val Loss: 0.86964 	 Best Test Loss: 0.77964 	 Best epoch 445
EarlyStopping counter: 1 out of 50
train epoch 451 avg loss: 0.63337 (A-MSE: 0.54217) avg lploss: 0.00000
train epoch 452 avg loss: 0.62737 (A-MSE: 0.53888) avg lploss: 0.00000
train epoch 453 avg loss: 0.61258 (A-MSE: 0.52850) avg lploss: 0.00000
train epoch 454 avg loss: 0.64745 (A-MSE: 0.56168) avg lploss: 0.00000
train epoch 455 avg loss: 0.63921 (A-MSE: 0.55081) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.89643 (A-MSE: 0.77400) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.78608 (A-MSE: 0.67539) avg lploss: 0.00000
*** Best Val Loss: 0.86964 	 Best Test Loss: 0.77964 	 Best epoch 445
EarlyStopping counter: 2 out of 50
train epoch 456 avg loss: 0.66230 (A-MSE: 0.57580) avg lploss: 0.00000
train epoch 457 avg loss: 0.64135 (A-MSE: 0.55422) avg lploss: 0.00000
train epoch 458 avg loss: 0.65203 (A-MSE: 0.56460) avg lploss: 0.00000
train epoch 459 avg loss: 0.64842 (A-MSE: 0.56064) avg lploss: 0.00000
train epoch 460 avg loss: 0.67976 (A-MSE: 0.58797) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.76332 (A-MSE: 0.65476) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.64967 (A-MSE: 0.55288) avg lploss: 0.00000
*** Best Val Loss: 0.76332 	 Best Test Loss: 0.64967 	 Best epoch 460
Validation loss decreased (0.869639 --> 0.763316).  Saving model ...
train epoch 461 avg loss: 0.57802 (A-MSE: 0.49652) avg lploss: 0.00000
train epoch 462 avg loss: 0.57912 (A-MSE: 0.49861) avg lploss: 0.00000
train epoch 463 avg loss: 0.57630 (A-MSE: 0.49715) avg lploss: 0.00000
train epoch 464 avg loss: 0.65892 (A-MSE: 0.57374) avg lploss: 0.00000
train epoch 465 avg loss: 0.64726 (A-MSE: 0.55930) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.69929 (A-MSE: 0.59438) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.60987 (A-MSE: 0.51715) avg lploss: 0.00000
*** Best Val Loss: 0.69929 	 Best Test Loss: 0.60987 	 Best epoch 465
Validation loss decreased (0.763316 --> 0.699285).  Saving model ...
train epoch 466 avg loss: 0.57587 (A-MSE: 0.49643) avg lploss: 0.00000
train epoch 467 avg loss: 0.56233 (A-MSE: 0.48515) avg lploss: 0.00000
train epoch 468 avg loss: 0.62091 (A-MSE: 0.53827) avg lploss: 0.00000
train epoch 469 avg loss: 0.57709 (A-MSE: 0.49974) avg lploss: 0.00000
train epoch 470 avg loss: 0.59233 (A-MSE: 0.51330) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.68661 (A-MSE: 0.59704) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.59032 (A-MSE: 0.51247) avg lploss: 0.00000
*** Best Val Loss: 0.68661 	 Best Test Loss: 0.59032 	 Best epoch 470
Validation loss decreased (0.699285 --> 0.686607).  Saving model ...
train epoch 471 avg loss: 0.57532 (A-MSE: 0.49791) avg lploss: 0.00000
train epoch 472 avg loss: 0.53836 (A-MSE: 0.46381) avg lploss: 0.00000
train epoch 473 avg loss: 0.51302 (A-MSE: 0.44289) avg lploss: 0.00000
train epoch 474 avg loss: 0.58546 (A-MSE: 0.51021) avg lploss: 0.00000
train epoch 475 avg loss: 0.58259 (A-MSE: 0.50112) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.81640 (A-MSE: 0.69765) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.69466 (A-MSE: 0.59010) avg lploss: 0.00000
*** Best Val Loss: 0.68661 	 Best Test Loss: 0.59032 	 Best epoch 470
EarlyStopping counter: 1 out of 50
train epoch 476 avg loss: 0.67534 (A-MSE: 0.58948) avg lploss: 0.00000
train epoch 477 avg loss: 0.54967 (A-MSE: 0.47515) avg lploss: 0.00000
train epoch 478 avg loss: 0.61944 (A-MSE: 0.53576) avg lploss: 0.00000
train epoch 479 avg loss: 0.55875 (A-MSE: 0.48096) avg lploss: 0.00000
train epoch 480 avg loss: 0.52273 (A-MSE: 0.45080) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.87844 (A-MSE: 0.74257) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.77809 (A-MSE: 0.65465) avg lploss: 0.00000
*** Best Val Loss: 0.68661 	 Best Test Loss: 0.59032 	 Best epoch 470
EarlyStopping counter: 2 out of 50
train epoch 481 avg loss: 0.56102 (A-MSE: 0.48649) avg lploss: 0.00000
train epoch 482 avg loss: 0.55401 (A-MSE: 0.47864) avg lploss: 0.00000
train epoch 483 avg loss: 0.51905 (A-MSE: 0.44824) avg lploss: 0.00000
train epoch 484 avg loss: 0.50342 (A-MSE: 0.43331) avg lploss: 0.00000
train epoch 485 avg loss: 0.50279 (A-MSE: 0.43543) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.78021 (A-MSE: 0.65188) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.68916 (A-MSE: 0.57294) avg lploss: 0.00000
*** Best Val Loss: 0.68661 	 Best Test Loss: 0.59032 	 Best epoch 470
EarlyStopping counter: 3 out of 50
train epoch 486 avg loss: 0.54910 (A-MSE: 0.47513) avg lploss: 0.00000
train epoch 487 avg loss: 0.51529 (A-MSE: 0.44492) avg lploss: 0.00000
train epoch 488 avg loss: 0.55377 (A-MSE: 0.48172) avg lploss: 0.00000
train epoch 489 avg loss: 0.48143 (A-MSE: 0.41309) avg lploss: 0.00000
train epoch 490 avg loss: 0.44402 (A-MSE: 0.38225) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.59387 (A-MSE: 0.50581) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.51324 (A-MSE: 0.43502) avg lploss: 0.00000
*** Best Val Loss: 0.59387 	 Best Test Loss: 0.51324 	 Best epoch 490
Validation loss decreased (0.686607 --> 0.593865).  Saving model ...
train epoch 491 avg loss: 0.50865 (A-MSE: 0.44366) avg lploss: 0.00000
train epoch 492 avg loss: 0.59597 (A-MSE: 0.51679) avg lploss: 0.00000
train epoch 493 avg loss: 0.61160 (A-MSE: 0.53317) avg lploss: 0.00000
train epoch 494 avg loss: 0.49264 (A-MSE: 0.42776) avg lploss: 0.00000
train epoch 495 avg loss: 0.48771 (A-MSE: 0.42132) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.56215 (A-MSE: 0.48165) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.49023 (A-MSE: 0.41930) avg lploss: 0.00000
*** Best Val Loss: 0.56215 	 Best Test Loss: 0.49023 	 Best epoch 495
Validation loss decreased (0.593865 --> 0.562149).  Saving model ...
train epoch 496 avg loss: 0.48597 (A-MSE: 0.41863) avg lploss: 0.00000
train epoch 497 avg loss: 0.50316 (A-MSE: 0.43693) avg lploss: 0.00000
train epoch 498 avg loss: 0.45857 (A-MSE: 0.39751) avg lploss: 0.00000
train epoch 499 avg loss: 0.50750 (A-MSE: 0.43995) avg lploss: 0.00000
train epoch 500 avg loss: 0.53911 (A-MSE: 0.46794) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.69201 (A-MSE: 0.58113) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.61636 (A-MSE: 0.51624) avg lploss: 0.00000
*** Best Val Loss: 0.56215 	 Best Test Loss: 0.49023 	 Best epoch 495
EarlyStopping counter: 1 out of 50
train epoch 501 avg loss: 0.47429 (A-MSE: 0.40595) avg lploss: 0.00000
train epoch 502 avg loss: 0.47386 (A-MSE: 0.41373) avg lploss: 0.00000
train epoch 503 avg loss: 0.46170 (A-MSE: 0.39877) avg lploss: 0.00000
train epoch 504 avg loss: 0.45909 (A-MSE: 0.39755) avg lploss: 0.00000
train epoch 505 avg loss: 0.47387 (A-MSE: 0.41055) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.58352 (A-MSE: 0.49907) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.50138 (A-MSE: 0.42737) avg lploss: 0.00000
*** Best Val Loss: 0.56215 	 Best Test Loss: 0.49023 	 Best epoch 495
EarlyStopping counter: 2 out of 50
train epoch 506 avg loss: 0.45703 (A-MSE: 0.39794) avg lploss: 0.00000
train epoch 507 avg loss: 0.48720 (A-MSE: 0.42414) avg lploss: 0.00000
train epoch 508 avg loss: 0.55339 (A-MSE: 0.48123) avg lploss: 0.00000
train epoch 509 avg loss: 0.46835 (A-MSE: 0.40323) avg lploss: 0.00000
train epoch 510 avg loss: 0.46719 (A-MSE: 0.40830) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.62650 (A-MSE: 0.52851) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.57955 (A-MSE: 0.48823) avg lploss: 0.00000
*** Best Val Loss: 0.56215 	 Best Test Loss: 0.49023 	 Best epoch 495
EarlyStopping counter: 3 out of 50
train epoch 511 avg loss: 0.47258 (A-MSE: 0.40615) avg lploss: 0.00000
train epoch 512 avg loss: 0.49591 (A-MSE: 0.43169) avg lploss: 0.00000
train epoch 513 avg loss: 0.41997 (A-MSE: 0.36519) avg lploss: 0.00000
train epoch 514 avg loss: 0.43513 (A-MSE: 0.38015) avg lploss: 0.00000
train epoch 515 avg loss: 0.49095 (A-MSE: 0.42309) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.55648 (A-MSE: 0.48265) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.47928 (A-MSE: 0.41564) avg lploss: 0.00000
*** Best Val Loss: 0.55648 	 Best Test Loss: 0.47928 	 Best epoch 515
Validation loss decreased (0.562149 --> 0.556477).  Saving model ...
train epoch 516 avg loss: 0.42434 (A-MSE: 0.37113) avg lploss: 0.00000
train epoch 517 avg loss: 0.43175 (A-MSE: 0.37439) avg lploss: 0.00000
train epoch 518 avg loss: 0.43519 (A-MSE: 0.37752) avg lploss: 0.00000
train epoch 519 avg loss: 0.41388 (A-MSE: 0.35951) avg lploss: 0.00000
train epoch 520 avg loss: 0.42816 (A-MSE: 0.37111) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.56353 (A-MSE: 0.48803) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.47107 (A-MSE: 0.40659) avg lploss: 0.00000
*** Best Val Loss: 0.55648 	 Best Test Loss: 0.47928 	 Best epoch 515
EarlyStopping counter: 1 out of 50
train epoch 521 avg loss: 0.44944 (A-MSE: 0.39223) avg lploss: 0.00000
train epoch 522 avg loss: 0.43603 (A-MSE: 0.37909) avg lploss: 0.00000
train epoch 523 avg loss: 0.46960 (A-MSE: 0.40790) avg lploss: 0.00000
train epoch 524 avg loss: 0.38952 (A-MSE: 0.33920) avg lploss: 0.00000
train epoch 525 avg loss: 0.41046 (A-MSE: 0.35745) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.52684 (A-MSE: 0.44871) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.45524 (A-MSE: 0.38660) avg lploss: 0.00000
*** Best Val Loss: 0.52684 	 Best Test Loss: 0.45524 	 Best epoch 525
Validation loss decreased (0.556477 --> 0.526843).  Saving model ...
train epoch 526 avg loss: 0.37384 (A-MSE: 0.32303) avg lploss: 0.00000
train epoch 527 avg loss: 0.39380 (A-MSE: 0.34196) avg lploss: 0.00000
train epoch 528 avg loss: 0.39834 (A-MSE: 0.34469) avg lploss: 0.00000
train epoch 529 avg loss: 0.41241 (A-MSE: 0.35912) avg lploss: 0.00000
train epoch 530 avg loss: 0.38496 (A-MSE: 0.33399) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.52068 (A-MSE: 0.44686) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.44616 (A-MSE: 0.38196) avg lploss: 0.00000
*** Best Val Loss: 0.52068 	 Best Test Loss: 0.44616 	 Best epoch 530
Validation loss decreased (0.526843 --> 0.520680).  Saving model ...
train epoch 531 avg loss: 0.38553 (A-MSE: 0.33486) avg lploss: 0.00000
train epoch 532 avg loss: 0.38098 (A-MSE: 0.33040) avg lploss: 0.00000
train epoch 533 avg loss: 0.42496 (A-MSE: 0.36926) avg lploss: 0.00000
train epoch 534 avg loss: 0.39428 (A-MSE: 0.34178) avg lploss: 0.00000
train epoch 535 avg loss: 0.39003 (A-MSE: 0.33938) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.48828 (A-MSE: 0.41547) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.43298 (A-MSE: 0.36888) avg lploss: 0.00000
*** Best Val Loss: 0.48828 	 Best Test Loss: 0.43298 	 Best epoch 535
Validation loss decreased (0.520680 --> 0.488278).  Saving model ...
train epoch 536 avg loss: 0.38419 (A-MSE: 0.33646) avg lploss: 0.00000
train epoch 537 avg loss: 0.37163 (A-MSE: 0.32455) avg lploss: 0.00000
train epoch 538 avg loss: 0.40904 (A-MSE: 0.35577) avg lploss: 0.00000
train epoch 539 avg loss: 0.39167 (A-MSE: 0.34082) avg lploss: 0.00000
train epoch 540 avg loss: 0.40924 (A-MSE: 0.35525) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.57994 (A-MSE: 0.50710) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.49144 (A-MSE: 0.42935) avg lploss: 0.00000
*** Best Val Loss: 0.48828 	 Best Test Loss: 0.43298 	 Best epoch 535
EarlyStopping counter: 1 out of 50
train epoch 541 avg loss: 0.39627 (A-MSE: 0.34480) avg lploss: 0.00000
train epoch 542 avg loss: 0.41693 (A-MSE: 0.36324) avg lploss: 0.00000
train epoch 543 avg loss: 0.40943 (A-MSE: 0.35735) avg lploss: 0.00000
train epoch 544 avg loss: 0.43559 (A-MSE: 0.37950) avg lploss: 0.00000
train epoch 545 avg loss: 0.40390 (A-MSE: 0.35011) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.51423 (A-MSE: 0.44539) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.45075 (A-MSE: 0.39075) avg lploss: 0.00000
*** Best Val Loss: 0.48828 	 Best Test Loss: 0.43298 	 Best epoch 535
EarlyStopping counter: 2 out of 50
train epoch 546 avg loss: 0.39442 (A-MSE: 0.34502) avg lploss: 0.00000
train epoch 547 avg loss: 0.36380 (A-MSE: 0.31643) avg lploss: 0.00000
train epoch 548 avg loss: 0.34956 (A-MSE: 0.30399) avg lploss: 0.00000
train epoch 549 avg loss: 0.40008 (A-MSE: 0.34916) avg lploss: 0.00000
train epoch 550 avg loss: 0.42315 (A-MSE: 0.36710) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.51455 (A-MSE: 0.43662) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.46843 (A-MSE: 0.39904) avg lploss: 0.00000
*** Best Val Loss: 0.48828 	 Best Test Loss: 0.43298 	 Best epoch 535
EarlyStopping counter: 3 out of 50
train epoch 551 avg loss: 0.36196 (A-MSE: 0.31525) avg lploss: 0.00000
train epoch 552 avg loss: 0.34644 (A-MSE: 0.30073) avg lploss: 0.00000
train epoch 553 avg loss: 0.42587 (A-MSE: 0.37365) avg lploss: 0.00000
train epoch 554 avg loss: 0.38808 (A-MSE: 0.33811) avg lploss: 0.00000
train epoch 555 avg loss: 0.38215 (A-MSE: 0.33318) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.47277 (A-MSE: 0.40056) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.41818 (A-MSE: 0.35422) avg lploss: 0.00000
*** Best Val Loss: 0.47277 	 Best Test Loss: 0.41818 	 Best epoch 555
Validation loss decreased (0.488278 --> 0.472774).  Saving model ...
train epoch 556 avg loss: 0.37242 (A-MSE: 0.32250) avg lploss: 0.00000
train epoch 557 avg loss: 0.40243 (A-MSE: 0.35149) avg lploss: 0.00000
train epoch 558 avg loss: 0.36104 (A-MSE: 0.31568) avg lploss: 0.00000
train epoch 559 avg loss: 0.37229 (A-MSE: 0.32314) avg lploss: 0.00000
train epoch 560 avg loss: 0.40395 (A-MSE: 0.35171) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.50328 (A-MSE: 0.42718) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.45058 (A-MSE: 0.38284) avg lploss: 0.00000
*** Best Val Loss: 0.47277 	 Best Test Loss: 0.41818 	 Best epoch 555
EarlyStopping counter: 1 out of 50
train epoch 561 avg loss: 0.39188 (A-MSE: 0.34156) avg lploss: 0.00000
train epoch 562 avg loss: 0.38551 (A-MSE: 0.33706) avg lploss: 0.00000
train epoch 563 avg loss: 0.39999 (A-MSE: 0.34967) avg lploss: 0.00000
train epoch 564 avg loss: 0.38340 (A-MSE: 0.33201) avg lploss: 0.00000
train epoch 565 avg loss: 0.37636 (A-MSE: 0.32833) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.53947 (A-MSE: 0.46975) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.50860 (A-MSE: 0.44418) avg lploss: 0.00000
*** Best Val Loss: 0.47277 	 Best Test Loss: 0.41818 	 Best epoch 555
EarlyStopping counter: 2 out of 50
train epoch 566 avg loss: 0.37932 (A-MSE: 0.33129) avg lploss: 0.00000
train epoch 567 avg loss: 0.37261 (A-MSE: 0.32535) avg lploss: 0.00000
train epoch 568 avg loss: 0.34922 (A-MSE: 0.30480) avg lploss: 0.00000
train epoch 569 avg loss: 0.34556 (A-MSE: 0.30039) avg lploss: 0.00000
train epoch 570 avg loss: 0.38047 (A-MSE: 0.33149) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.49209 (A-MSE: 0.42035) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.41977 (A-MSE: 0.35752) avg lploss: 0.00000
*** Best Val Loss: 0.47277 	 Best Test Loss: 0.41818 	 Best epoch 555
EarlyStopping counter: 3 out of 50
train epoch 571 avg loss: 0.36698 (A-MSE: 0.31936) avg lploss: 0.00000
train epoch 572 avg loss: 0.32926 (A-MSE: 0.28653) avg lploss: 0.00000
train epoch 573 avg loss: 0.33066 (A-MSE: 0.28790) avg lploss: 0.00000
train epoch 574 avg loss: 0.37086 (A-MSE: 0.32427) avg lploss: 0.00000
train epoch 575 avg loss: 0.32755 (A-MSE: 0.28469) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.40076 (A-MSE: 0.34552) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.35263 (A-MSE: 0.30436) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
Validation loss decreased (0.472774 --> 0.400756).  Saving model ...
train epoch 576 avg loss: 0.33452 (A-MSE: 0.29345) avg lploss: 0.00000
train epoch 577 avg loss: 0.33520 (A-MSE: 0.29153) avg lploss: 0.00000
train epoch 578 avg loss: 0.34817 (A-MSE: 0.30349) avg lploss: 0.00000
train epoch 579 avg loss: 0.33679 (A-MSE: 0.29349) avg lploss: 0.00000
train epoch 580 avg loss: 0.32402 (A-MSE: 0.28196) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.44029 (A-MSE: 0.37823) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.37471 (A-MSE: 0.32136) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 1 out of 50
train epoch 581 avg loss: 0.32012 (A-MSE: 0.28096) avg lploss: 0.00000
train epoch 582 avg loss: 0.36432 (A-MSE: 0.31889) avg lploss: 0.00000
train epoch 583 avg loss: 0.33589 (A-MSE: 0.29403) avg lploss: 0.00000
train epoch 584 avg loss: 0.32918 (A-MSE: 0.28792) avg lploss: 0.00000
train epoch 585 avg loss: 0.34549 (A-MSE: 0.30124) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.43507 (A-MSE: 0.37460) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.37264 (A-MSE: 0.32094) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 2 out of 50
train epoch 586 avg loss: 0.31278 (A-MSE: 0.27219) avg lploss: 0.00000
train epoch 587 avg loss: 0.31555 (A-MSE: 0.27474) avg lploss: 0.00000
train epoch 588 avg loss: 0.31088 (A-MSE: 0.27223) avg lploss: 0.00000
train epoch 589 avg loss: 0.33804 (A-MSE: 0.29496) avg lploss: 0.00000
train epoch 590 avg loss: 0.38094 (A-MSE: 0.33202) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.45270 (A-MSE: 0.39326) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.39579 (A-MSE: 0.34386) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 3 out of 50
train epoch 591 avg loss: 0.40648 (A-MSE: 0.35438) avg lploss: 0.00000
train epoch 592 avg loss: 0.35267 (A-MSE: 0.30953) avg lploss: 0.00000
train epoch 593 avg loss: 0.30319 (A-MSE: 0.26373) avg lploss: 0.00000
train epoch 594 avg loss: 0.29738 (A-MSE: 0.25968) avg lploss: 0.00000
train epoch 595 avg loss: 0.30454 (A-MSE: 0.26533) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.41859 (A-MSE: 0.36104) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.36228 (A-MSE: 0.31342) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 4 out of 50
train epoch 596 avg loss: 0.29529 (A-MSE: 0.25770) avg lploss: 0.00000
train epoch 597 avg loss: 0.30750 (A-MSE: 0.26996) avg lploss: 0.00000
train epoch 598 avg loss: 0.31730 (A-MSE: 0.27609) avg lploss: 0.00000
train epoch 599 avg loss: 0.30417 (A-MSE: 0.26588) avg lploss: 0.00000
train epoch 600 avg loss: 0.31727 (A-MSE: 0.27676) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.43959 (A-MSE: 0.38499) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.38360 (A-MSE: 0.33558) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 5 out of 50
train epoch 601 avg loss: 0.30796 (A-MSE: 0.26899) avg lploss: 0.00000
train epoch 602 avg loss: 0.29239 (A-MSE: 0.25643) avg lploss: 0.00000
train epoch 603 avg loss: 0.31988 (A-MSE: 0.28017) avg lploss: 0.00000
train epoch 604 avg loss: 0.35370 (A-MSE: 0.30936) avg lploss: 0.00000
train epoch 605 avg loss: 0.31065 (A-MSE: 0.27095) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.41947 (A-MSE: 0.35891) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.36891 (A-MSE: 0.31580) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 6 out of 50
train epoch 606 avg loss: 0.30725 (A-MSE: 0.26848) avg lploss: 0.00000
train epoch 607 avg loss: 0.31976 (A-MSE: 0.27953) avg lploss: 0.00000
train epoch 608 avg loss: 0.38440 (A-MSE: 0.33639) avg lploss: 0.00000
train epoch 609 avg loss: 0.36650 (A-MSE: 0.32034) avg lploss: 0.00000
train epoch 610 avg loss: 0.30952 (A-MSE: 0.26950) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.43184 (A-MSE: 0.37315) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.36314 (A-MSE: 0.31314) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 7 out of 50
train epoch 611 avg loss: 0.29475 (A-MSE: 0.25672) avg lploss: 0.00000
train epoch 612 avg loss: 0.29765 (A-MSE: 0.25954) avg lploss: 0.00000
train epoch 613 avg loss: 0.28837 (A-MSE: 0.25155) avg lploss: 0.00000
train epoch 614 avg loss: 0.33794 (A-MSE: 0.29773) avg lploss: 0.00000
train epoch 615 avg loss: 0.31796 (A-MSE: 0.27650) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.41182 (A-MSE: 0.35797) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.35095 (A-MSE: 0.30459) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 8 out of 50
train epoch 616 avg loss: 0.31145 (A-MSE: 0.27377) avg lploss: 0.00000
train epoch 617 avg loss: 0.32154 (A-MSE: 0.28009) avg lploss: 0.00000
train epoch 618 avg loss: 0.29365 (A-MSE: 0.25788) avg lploss: 0.00000
train epoch 619 avg loss: 0.32572 (A-MSE: 0.28449) avg lploss: 0.00000
train epoch 620 avg loss: 0.34070 (A-MSE: 0.29908) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.50242 (A-MSE: 0.42666) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.44058 (A-MSE: 0.37375) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 9 out of 50
train epoch 621 avg loss: 0.32698 (A-MSE: 0.28510) avg lploss: 0.00000
train epoch 622 avg loss: 0.27594 (A-MSE: 0.23996) avg lploss: 0.00000
train epoch 623 avg loss: 0.27855 (A-MSE: 0.24425) avg lploss: 0.00000
train epoch 624 avg loss: 0.27995 (A-MSE: 0.24485) avg lploss: 0.00000
train epoch 625 avg loss: 0.32454 (A-MSE: 0.28500) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.41427 (A-MSE: 0.35231) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.36193 (A-MSE: 0.30789) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 10 out of 50
train epoch 626 avg loss: 0.33242 (A-MSE: 0.29146) avg lploss: 0.00000
train epoch 627 avg loss: 0.31060 (A-MSE: 0.27252) avg lploss: 0.00000
train epoch 628 avg loss: 0.30955 (A-MSE: 0.27046) avg lploss: 0.00000
train epoch 629 avg loss: 0.30851 (A-MSE: 0.27002) avg lploss: 0.00000
train epoch 630 avg loss: 0.36984 (A-MSE: 0.32233) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.52079 (A-MSE: 0.45368) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.45304 (A-MSE: 0.39336) avg lploss: 0.00000
*** Best Val Loss: 0.40076 	 Best Test Loss: 0.35263 	 Best epoch 575
EarlyStopping counter: 11 out of 50
train epoch 631 avg loss: 0.32483 (A-MSE: 0.28371) avg lploss: 0.00000
train epoch 632 avg loss: 0.30823 (A-MSE: 0.27049) avg lploss: 0.00000
train epoch 633 avg loss: 0.29907 (A-MSE: 0.26111) avg lploss: 0.00000
train epoch 634 avg loss: 0.29201 (A-MSE: 0.25654) avg lploss: 0.00000
train epoch 635 avg loss: 0.29303 (A-MSE: 0.25634) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.38178 (A-MSE: 0.33082) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.31783 (A-MSE: 0.27501) avg lploss: 0.00000
*** Best Val Loss: 0.38178 	 Best Test Loss: 0.31783 	 Best epoch 635
Validation loss decreased (0.400756 --> 0.381777).  Saving model ...
train epoch 636 avg loss: 0.27792 (A-MSE: 0.24316) avg lploss: 0.00000
train epoch 637 avg loss: 0.35611 (A-MSE: 0.31386) avg lploss: 0.00000
train epoch 638 avg loss: 0.30453 (A-MSE: 0.26437) avg lploss: 0.00000
train epoch 639 avg loss: 0.28920 (A-MSE: 0.25371) avg lploss: 0.00000
train epoch 640 avg loss: 0.27954 (A-MSE: 0.24553) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.38805 (A-MSE: 0.33631) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.33240 (A-MSE: 0.28807) avg lploss: 0.00000
*** Best Val Loss: 0.38178 	 Best Test Loss: 0.31783 	 Best epoch 635
EarlyStopping counter: 1 out of 50
train epoch 641 avg loss: 0.27392 (A-MSE: 0.23881) avg lploss: 0.00000
train epoch 642 avg loss: 0.27507 (A-MSE: 0.24025) avg lploss: 0.00000
train epoch 643 avg loss: 0.28597 (A-MSE: 0.25038) avg lploss: 0.00000
train epoch 644 avg loss: 0.32691 (A-MSE: 0.28670) avg lploss: 0.00000
train epoch 645 avg loss: 0.29543 (A-MSE: 0.25812) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.36738 (A-MSE: 0.31851) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.30705 (A-MSE: 0.26532) avg lploss: 0.00000
*** Best Val Loss: 0.36738 	 Best Test Loss: 0.30705 	 Best epoch 645
Validation loss decreased (0.381777 --> 0.367381).  Saving model ...
train epoch 646 avg loss: 0.25860 (A-MSE: 0.22586) avg lploss: 0.00000
train epoch 647 avg loss: 0.25499 (A-MSE: 0.22325) avg lploss: 0.00000
train epoch 648 avg loss: 0.26651 (A-MSE: 0.23169) avg lploss: 0.00000
train epoch 649 avg loss: 0.25708 (A-MSE: 0.22578) avg lploss: 0.00000
train epoch 650 avg loss: 0.27607 (A-MSE: 0.24196) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.44694 (A-MSE: 0.38243) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.39237 (A-MSE: 0.33580) avg lploss: 0.00000
*** Best Val Loss: 0.36738 	 Best Test Loss: 0.30705 	 Best epoch 645
EarlyStopping counter: 1 out of 50
train epoch 651 avg loss: 0.28689 (A-MSE: 0.25121) avg lploss: 0.00000
train epoch 652 avg loss: 0.27751 (A-MSE: 0.24391) avg lploss: 0.00000
train epoch 653 avg loss: 0.24951 (A-MSE: 0.21869) avg lploss: 0.00000
train epoch 654 avg loss: 0.29563 (A-MSE: 0.25808) avg lploss: 0.00000
train epoch 655 avg loss: 0.27528 (A-MSE: 0.24095) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.37656 (A-MSE: 0.32315) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.31950 (A-MSE: 0.27433) avg lploss: 0.00000
*** Best Val Loss: 0.36738 	 Best Test Loss: 0.30705 	 Best epoch 645
EarlyStopping counter: 2 out of 50
train epoch 656 avg loss: 0.27673 (A-MSE: 0.24300) avg lploss: 0.00000
train epoch 657 avg loss: 0.27054 (A-MSE: 0.23619) avg lploss: 0.00000
train epoch 658 avg loss: 0.27128 (A-MSE: 0.23661) avg lploss: 0.00000
train epoch 659 avg loss: 0.26975 (A-MSE: 0.23733) avg lploss: 0.00000
train epoch 660 avg loss: 0.29484 (A-MSE: 0.25759) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.49976 (A-MSE: 0.42384) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.44656 (A-MSE: 0.37878) avg lploss: 0.00000
*** Best Val Loss: 0.36738 	 Best Test Loss: 0.30705 	 Best epoch 645
EarlyStopping counter: 3 out of 50
train epoch 661 avg loss: 0.29759 (A-MSE: 0.26101) avg lploss: 0.00000
train epoch 662 avg loss: 0.25543 (A-MSE: 0.22287) avg lploss: 0.00000
train epoch 663 avg loss: 0.25412 (A-MSE: 0.22197) avg lploss: 0.00000
train epoch 664 avg loss: 0.26883 (A-MSE: 0.23448) avg lploss: 0.00000
train epoch 665 avg loss: 0.25239 (A-MSE: 0.22022) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.34728 (A-MSE: 0.30010) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.30635 (A-MSE: 0.26508) avg lploss: 0.00000
*** Best Val Loss: 0.34728 	 Best Test Loss: 0.30635 	 Best epoch 665
Validation loss decreased (0.367381 --> 0.347277).  Saving model ...
train epoch 666 avg loss: 0.27295 (A-MSE: 0.23891) avg lploss: 0.00000
train epoch 667 avg loss: 0.24501 (A-MSE: 0.21458) avg lploss: 0.00000
train epoch 668 avg loss: 0.26696 (A-MSE: 0.23421) avg lploss: 0.00000
train epoch 669 avg loss: 0.30601 (A-MSE: 0.26844) avg lploss: 0.00000
train epoch 670 avg loss: 0.29535 (A-MSE: 0.25933) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.39582 (A-MSE: 0.34473) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.33480 (A-MSE: 0.29221) avg lploss: 0.00000
*** Best Val Loss: 0.34728 	 Best Test Loss: 0.30635 	 Best epoch 665
EarlyStopping counter: 1 out of 50
train epoch 671 avg loss: 0.28411 (A-MSE: 0.24843) avg lploss: 0.00000
train epoch 672 avg loss: 0.28672 (A-MSE: 0.25101) avg lploss: 0.00000
train epoch 673 avg loss: 0.29846 (A-MSE: 0.26176) avg lploss: 0.00000
train epoch 674 avg loss: 0.26796 (A-MSE: 0.23459) avg lploss: 0.00000
train epoch 675 avg loss: 0.27193 (A-MSE: 0.23906) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.49118 (A-MSE: 0.42589) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.43231 (A-MSE: 0.37466) avg lploss: 0.00000
*** Best Val Loss: 0.34728 	 Best Test Loss: 0.30635 	 Best epoch 665
EarlyStopping counter: 2 out of 50
train epoch 676 avg loss: 0.30158 (A-MSE: 0.26495) avg lploss: 0.00000
train epoch 677 avg loss: 0.27002 (A-MSE: 0.23721) avg lploss: 0.00000
train epoch 678 avg loss: 0.26705 (A-MSE: 0.23373) avg lploss: 0.00000
train epoch 679 avg loss: 0.26788 (A-MSE: 0.23380) avg lploss: 0.00000
train epoch 680 avg loss: 0.25201 (A-MSE: 0.22090) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.35553 (A-MSE: 0.30720) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.30252 (A-MSE: 0.26133) avg lploss: 0.00000
*** Best Val Loss: 0.34728 	 Best Test Loss: 0.30635 	 Best epoch 665
EarlyStopping counter: 3 out of 50
train epoch 681 avg loss: 0.24935 (A-MSE: 0.21853) avg lploss: 0.00000
train epoch 682 avg loss: 0.27463 (A-MSE: 0.24070) avg lploss: 0.00000
train epoch 683 avg loss: 0.27333 (A-MSE: 0.23958) avg lploss: 0.00000
train epoch 684 avg loss: 0.27721 (A-MSE: 0.24171) avg lploss: 0.00000
train epoch 685 avg loss: 0.28676 (A-MSE: 0.25135) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.38737 (A-MSE: 0.33393) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.34803 (A-MSE: 0.30022) avg lploss: 0.00000
*** Best Val Loss: 0.34728 	 Best Test Loss: 0.30635 	 Best epoch 665
EarlyStopping counter: 4 out of 50
train epoch 686 avg loss: 0.26654 (A-MSE: 0.23353) avg lploss: 0.00000
train epoch 687 avg loss: 0.26355 (A-MSE: 0.23185) avg lploss: 0.00000
train epoch 688 avg loss: 0.23637 (A-MSE: 0.20699) avg lploss: 0.00000
train epoch 689 avg loss: 0.26497 (A-MSE: 0.23355) avg lploss: 0.00000
train epoch 690 avg loss: 0.28418 (A-MSE: 0.24782) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.41769 (A-MSE: 0.36474) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.35131 (A-MSE: 0.30649) avg lploss: 0.00000
*** Best Val Loss: 0.34728 	 Best Test Loss: 0.30635 	 Best epoch 665
EarlyStopping counter: 5 out of 50
train epoch 691 avg loss: 0.24246 (A-MSE: 0.21256) avg lploss: 0.00000
train epoch 692 avg loss: 0.27578 (A-MSE: 0.24243) avg lploss: 0.00000
train epoch 693 avg loss: 0.29838 (A-MSE: 0.26191) avg lploss: 0.00000
train epoch 694 avg loss: 0.27053 (A-MSE: 0.23709) avg lploss: 0.00000
train epoch 695 avg loss: 0.26287 (A-MSE: 0.23026) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.33703 (A-MSE: 0.29464) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.29183 (A-MSE: 0.25519) avg lploss: 0.00000
*** Best Val Loss: 0.33703 	 Best Test Loss: 0.29183 	 Best epoch 695
Validation loss decreased (0.347277 --> 0.337031).  Saving model ...
train epoch 696 avg loss: 0.24200 (A-MSE: 0.21166) avg lploss: 0.00000
train epoch 697 avg loss: 0.24572 (A-MSE: 0.21683) avg lploss: 0.00000
train epoch 698 avg loss: 0.25344 (A-MSE: 0.22275) avg lploss: 0.00000
train epoch 699 avg loss: 0.27040 (A-MSE: 0.23641) avg lploss: 0.00000
train epoch 700 avg loss: 0.24869 (A-MSE: 0.21856) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.37211 (A-MSE: 0.32794) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.30756 (A-MSE: 0.27099) avg lploss: 0.00000
*** Best Val Loss: 0.33703 	 Best Test Loss: 0.29183 	 Best epoch 695
EarlyStopping counter: 1 out of 50
train epoch 701 avg loss: 0.27287 (A-MSE: 0.23929) avg lploss: 0.00000
train epoch 702 avg loss: 0.25258 (A-MSE: 0.22125) avg lploss: 0.00000
train epoch 703 avg loss: 0.27192 (A-MSE: 0.23816) avg lploss: 0.00000
train epoch 704 avg loss: 0.23258 (A-MSE: 0.20488) avg lploss: 0.00000
train epoch 705 avg loss: 0.24066 (A-MSE: 0.21134) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.36277 (A-MSE: 0.31310) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.30910 (A-MSE: 0.26669) avg lploss: 0.00000
*** Best Val Loss: 0.33703 	 Best Test Loss: 0.29183 	 Best epoch 695
EarlyStopping counter: 2 out of 50
train epoch 706 avg loss: 0.26054 (A-MSE: 0.22774) avg lploss: 0.00000
train epoch 707 avg loss: 0.25077 (A-MSE: 0.22093) avg lploss: 0.00000
train epoch 708 avg loss: 0.23290 (A-MSE: 0.20363) avg lploss: 0.00000
train epoch 709 avg loss: 0.23238 (A-MSE: 0.20449) avg lploss: 0.00000
train epoch 710 avg loss: 0.25452 (A-MSE: 0.22347) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.45234 (A-MSE: 0.39257) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.39893 (A-MSE: 0.34608) avg lploss: 0.00000
*** Best Val Loss: 0.33703 	 Best Test Loss: 0.29183 	 Best epoch 695
EarlyStopping counter: 3 out of 50
train epoch 711 avg loss: 0.25322 (A-MSE: 0.22200) avg lploss: 0.00000
train epoch 712 avg loss: 0.26541 (A-MSE: 0.23370) avg lploss: 0.00000
train epoch 713 avg loss: 0.27220 (A-MSE: 0.23808) avg lploss: 0.00000
train epoch 714 avg loss: 0.24307 (A-MSE: 0.21353) avg lploss: 0.00000
train epoch 715 avg loss: 0.24468 (A-MSE: 0.21544) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.36379 (A-MSE: 0.31956) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.30976 (A-MSE: 0.27138) avg lploss: 0.00000
*** Best Val Loss: 0.33703 	 Best Test Loss: 0.29183 	 Best epoch 695
EarlyStopping counter: 4 out of 50
train epoch 716 avg loss: 0.23117 (A-MSE: 0.20253) avg lploss: 0.00000
train epoch 717 avg loss: 0.25676 (A-MSE: 0.22561) avg lploss: 0.00000
train epoch 718 avg loss: 0.25731 (A-MSE: 0.22503) avg lploss: 0.00000
train epoch 719 avg loss: 0.27001 (A-MSE: 0.23777) avg lploss: 0.00000
train epoch 720 avg loss: 0.25803 (A-MSE: 0.22698) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.32972 (A-MSE: 0.28764) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.28074 (A-MSE: 0.24440) avg lploss: 0.00000
*** Best Val Loss: 0.32972 	 Best Test Loss: 0.28074 	 Best epoch 720
Validation loss decreased (0.337031 --> 0.329716).  Saving model ...
train epoch 721 avg loss: 0.24439 (A-MSE: 0.21422) avg lploss: 0.00000
train epoch 722 avg loss: 0.23316 (A-MSE: 0.20362) avg lploss: 0.00000
train epoch 723 avg loss: 0.22989 (A-MSE: 0.20170) avg lploss: 0.00000
train epoch 724 avg loss: 0.22248 (A-MSE: 0.19433) avg lploss: 0.00000
train epoch 725 avg loss: 0.26704 (A-MSE: 0.23573) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.35681 (A-MSE: 0.30614) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.31836 (A-MSE: 0.27344) avg lploss: 0.00000
*** Best Val Loss: 0.32972 	 Best Test Loss: 0.28074 	 Best epoch 720
EarlyStopping counter: 1 out of 50
train epoch 726 avg loss: 0.25002 (A-MSE: 0.21875) avg lploss: 0.00000
train epoch 727 avg loss: 0.23303 (A-MSE: 0.20417) avg lploss: 0.00000
train epoch 728 avg loss: 0.23878 (A-MSE: 0.20951) avg lploss: 0.00000
train epoch 729 avg loss: 0.23132 (A-MSE: 0.20264) avg lploss: 0.00000
train epoch 730 avg loss: 0.23977 (A-MSE: 0.21156) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.37214 (A-MSE: 0.32277) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.32427 (A-MSE: 0.28094) avg lploss: 0.00000
*** Best Val Loss: 0.32972 	 Best Test Loss: 0.28074 	 Best epoch 720
EarlyStopping counter: 2 out of 50
train epoch 731 avg loss: 0.23171 (A-MSE: 0.20292) avg lploss: 0.00000
train epoch 732 avg loss: 0.23167 (A-MSE: 0.20418) avg lploss: 0.00000
train epoch 733 avg loss: 0.23318 (A-MSE: 0.20485) avg lploss: 0.00000
train epoch 734 avg loss: 0.22133 (A-MSE: 0.19370) avg lploss: 0.00000
train epoch 735 avg loss: 0.22451 (A-MSE: 0.19668) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.35279 (A-MSE: 0.30939) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.29418 (A-MSE: 0.25784) avg lploss: 0.00000
*** Best Val Loss: 0.32972 	 Best Test Loss: 0.28074 	 Best epoch 720
EarlyStopping counter: 3 out of 50
train epoch 736 avg loss: 0.23337 (A-MSE: 0.20556) avg lploss: 0.00000
train epoch 737 avg loss: 0.24848 (A-MSE: 0.21861) avg lploss: 0.00000
train epoch 738 avg loss: 0.23889 (A-MSE: 0.21015) avg lploss: 0.00000
train epoch 739 avg loss: 0.24810 (A-MSE: 0.21715) avg lploss: 0.00000
train epoch 740 avg loss: 0.25463 (A-MSE: 0.22378) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.32023 (A-MSE: 0.27673) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.27813 (A-MSE: 0.23999) avg lploss: 0.00000
*** Best Val Loss: 0.32023 	 Best Test Loss: 0.27813 	 Best epoch 740
Validation loss decreased (0.329716 --> 0.320226).  Saving model ...
train epoch 741 avg loss: 0.21314 (A-MSE: 0.18818) avg lploss: 0.00000
train epoch 742 avg loss: 0.21855 (A-MSE: 0.19112) avg lploss: 0.00000
train epoch 743 avg loss: 0.21290 (A-MSE: 0.18691) avg lploss: 0.00000
train epoch 744 avg loss: 0.24604 (A-MSE: 0.21703) avg lploss: 0.00000
train epoch 745 avg loss: 0.24624 (A-MSE: 0.21534) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.34701 (A-MSE: 0.30410) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.29605 (A-MSE: 0.25945) avg lploss: 0.00000
*** Best Val Loss: 0.32023 	 Best Test Loss: 0.27813 	 Best epoch 740
EarlyStopping counter: 1 out of 50
train epoch 746 avg loss: 0.22300 (A-MSE: 0.19598) avg lploss: 0.00000
train epoch 747 avg loss: 0.21897 (A-MSE: 0.19227) avg lploss: 0.00000
train epoch 748 avg loss: 0.22568 (A-MSE: 0.19801) avg lploss: 0.00000
train epoch 749 avg loss: 0.25198 (A-MSE: 0.22233) avg lploss: 0.00000
train epoch 750 avg loss: 0.26061 (A-MSE: 0.22911) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.41094 (A-MSE: 0.36336) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.34512 (A-MSE: 0.30459) avg lploss: 0.00000
*** Best Val Loss: 0.32023 	 Best Test Loss: 0.27813 	 Best epoch 740
EarlyStopping counter: 2 out of 50
train epoch 751 avg loss: 0.23534 (A-MSE: 0.20757) avg lploss: 0.00000
train epoch 752 avg loss: 0.30632 (A-MSE: 0.26890) avg lploss: 0.00000
train epoch 753 avg loss: 0.28458 (A-MSE: 0.25040) avg lploss: 0.00000
train epoch 754 avg loss: 0.24814 (A-MSE: 0.21772) avg lploss: 0.00000
train epoch 755 avg loss: 0.24320 (A-MSE: 0.21314) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.30809 (A-MSE: 0.26849) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.26721 (A-MSE: 0.23244) avg lploss: 0.00000
*** Best Val Loss: 0.30809 	 Best Test Loss: 0.26721 	 Best epoch 755
Validation loss decreased (0.320226 --> 0.308086).  Saving model ...
train epoch 756 avg loss: 0.23225 (A-MSE: 0.20371) avg lploss: 0.00000
train epoch 757 avg loss: 0.24411 (A-MSE: 0.21417) avg lploss: 0.00000
train epoch 758 avg loss: 0.22455 (A-MSE: 0.19797) avg lploss: 0.00000
train epoch 759 avg loss: 0.20537 (A-MSE: 0.18036) avg lploss: 0.00000
train epoch 760 avg loss: 0.21973 (A-MSE: 0.19271) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.32514 (A-MSE: 0.28354) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.27697 (A-MSE: 0.24119) avg lploss: 0.00000
*** Best Val Loss: 0.30809 	 Best Test Loss: 0.26721 	 Best epoch 755
EarlyStopping counter: 1 out of 50
train epoch 761 avg loss: 0.22159 (A-MSE: 0.19492) avg lploss: 0.00000
train epoch 762 avg loss: 0.21747 (A-MSE: 0.19178) avg lploss: 0.00000
train epoch 763 avg loss: 0.24570 (A-MSE: 0.21500) avg lploss: 0.00000
train epoch 764 avg loss: 0.25099 (A-MSE: 0.22058) avg lploss: 0.00000
train epoch 765 avg loss: 0.24477 (A-MSE: 0.21570) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.36296 (A-MSE: 0.31911) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.33001 (A-MSE: 0.29133) avg lploss: 0.00000
*** Best Val Loss: 0.30809 	 Best Test Loss: 0.26721 	 Best epoch 755
EarlyStopping counter: 2 out of 50
train epoch 766 avg loss: 0.23604 (A-MSE: 0.20744) avg lploss: 0.00000
train epoch 767 avg loss: 0.22203 (A-MSE: 0.19471) avg lploss: 0.00000
train epoch 768 avg loss: 0.20981 (A-MSE: 0.18380) avg lploss: 0.00000
train epoch 769 avg loss: 0.22247 (A-MSE: 0.19534) avg lploss: 0.00000
train epoch 770 avg loss: 0.22277 (A-MSE: 0.19531) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.31830 (A-MSE: 0.28346) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.27433 (A-MSE: 0.24428) avg lploss: 0.00000
*** Best Val Loss: 0.30809 	 Best Test Loss: 0.26721 	 Best epoch 755
EarlyStopping counter: 3 out of 50
train epoch 771 avg loss: 0.22680 (A-MSE: 0.19911) avg lploss: 0.00000
train epoch 772 avg loss: 0.20075 (A-MSE: 0.17642) avg lploss: 0.00000
train epoch 773 avg loss: 0.20883 (A-MSE: 0.18302) avg lploss: 0.00000
train epoch 774 avg loss: 0.21278 (A-MSE: 0.18721) avg lploss: 0.00000
train epoch 775 avg loss: 0.19529 (A-MSE: 0.17242) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.29870 (A-MSE: 0.26182) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.25916 (A-MSE: 0.22736) avg lploss: 0.00000
*** Best Val Loss: 0.29870 	 Best Test Loss: 0.25916 	 Best epoch 775
Validation loss decreased (0.308086 --> 0.298701).  Saving model ...
train epoch 776 avg loss: 0.19667 (A-MSE: 0.17280) avg lploss: 0.00000
train epoch 777 avg loss: 0.19734 (A-MSE: 0.17359) avg lploss: 0.00000
train epoch 778 avg loss: 0.21379 (A-MSE: 0.18728) avg lploss: 0.00000
train epoch 779 avg loss: 0.22099 (A-MSE: 0.19503) avg lploss: 0.00000
train epoch 780 avg loss: 0.24512 (A-MSE: 0.21615) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.33639 (A-MSE: 0.28963) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.29689 (A-MSE: 0.25532) avg lploss: 0.00000
*** Best Val Loss: 0.29870 	 Best Test Loss: 0.25916 	 Best epoch 775
EarlyStopping counter: 1 out of 50
train epoch 781 avg loss: 0.22070 (A-MSE: 0.19367) avg lploss: 0.00000
train epoch 782 avg loss: 0.23600 (A-MSE: 0.20649) avg lploss: 0.00000
train epoch 783 avg loss: 0.24639 (A-MSE: 0.21659) avg lploss: 0.00000
train epoch 784 avg loss: 0.22272 (A-MSE: 0.19625) avg lploss: 0.00000
train epoch 785 avg loss: 0.20803 (A-MSE: 0.18248) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.29047 (A-MSE: 0.25045) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.24891 (A-MSE: 0.21462) avg lploss: 0.00000
*** Best Val Loss: 0.29047 	 Best Test Loss: 0.24891 	 Best epoch 785
Validation loss decreased (0.298701 --> 0.290471).  Saving model ...
train epoch 786 avg loss: 0.19902 (A-MSE: 0.17462) avg lploss: 0.00000
train epoch 787 avg loss: 0.18549 (A-MSE: 0.16311) avg lploss: 0.00000
train epoch 788 avg loss: 0.20749 (A-MSE: 0.18246) avg lploss: 0.00000
train epoch 789 avg loss: 0.24810 (A-MSE: 0.21689) avg lploss: 0.00000
train epoch 790 avg loss: 0.22235 (A-MSE: 0.19600) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.30234 (A-MSE: 0.26750) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.26072 (A-MSE: 0.23115) avg lploss: 0.00000
*** Best Val Loss: 0.29047 	 Best Test Loss: 0.24891 	 Best epoch 785
EarlyStopping counter: 1 out of 50
train epoch 791 avg loss: 0.21201 (A-MSE: 0.18714) avg lploss: 0.00000
train epoch 792 avg loss: 0.21876 (A-MSE: 0.19261) avg lploss: 0.00000
train epoch 793 avg loss: 0.19896 (A-MSE: 0.17564) avg lploss: 0.00000
train epoch 794 avg loss: 0.18579 (A-MSE: 0.16353) avg lploss: 0.00000
train epoch 795 avg loss: 0.22275 (A-MSE: 0.19643) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.31277 (A-MSE: 0.27353) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.27878 (A-MSE: 0.24439) avg lploss: 0.00000
*** Best Val Loss: 0.29047 	 Best Test Loss: 0.24891 	 Best epoch 785
EarlyStopping counter: 2 out of 50
train epoch 796 avg loss: 0.20408 (A-MSE: 0.18009) avg lploss: 0.00000
train epoch 797 avg loss: 0.20130 (A-MSE: 0.17657) avg lploss: 0.00000
train epoch 798 avg loss: 0.24718 (A-MSE: 0.21598) avg lploss: 0.00000
train epoch 799 avg loss: 0.25306 (A-MSE: 0.22379) avg lploss: 0.00000
train epoch 800 avg loss: 0.21345 (A-MSE: 0.18795) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.31097 (A-MSE: 0.27030) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.26710 (A-MSE: 0.23243) avg lploss: 0.00000
*** Best Val Loss: 0.29047 	 Best Test Loss: 0.24891 	 Best epoch 785
EarlyStopping counter: 3 out of 50
train epoch 801 avg loss: 0.20436 (A-MSE: 0.17984) avg lploss: 0.00000
train epoch 802 avg loss: 0.20478 (A-MSE: 0.17926) avg lploss: 0.00000
train epoch 803 avg loss: 0.20353 (A-MSE: 0.17938) avg lploss: 0.00000
train epoch 804 avg loss: 0.19766 (A-MSE: 0.17426) avg lploss: 0.00000
train epoch 805 avg loss: 0.20765 (A-MSE: 0.18281) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.26857 (A-MSE: 0.23596) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.23661 (A-MSE: 0.20841) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
Validation loss decreased (0.290471 --> 0.268567).  Saving model ...
train epoch 806 avg loss: 0.18268 (A-MSE: 0.16051) avg lploss: 0.00000
train epoch 807 avg loss: 0.21596 (A-MSE: 0.19050) avg lploss: 0.00000
train epoch 808 avg loss: 0.21621 (A-MSE: 0.18985) avg lploss: 0.00000
train epoch 809 avg loss: 0.21884 (A-MSE: 0.19201) avg lploss: 0.00000
train epoch 810 avg loss: 0.19597 (A-MSE: 0.17231) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.27656 (A-MSE: 0.24176) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.23861 (A-MSE: 0.20888) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 1 out of 50
train epoch 811 avg loss: 0.19725 (A-MSE: 0.17370) avg lploss: 0.00000
train epoch 812 avg loss: 0.21246 (A-MSE: 0.18690) avg lploss: 0.00000
train epoch 813 avg loss: 0.20542 (A-MSE: 0.18025) avg lploss: 0.00000
train epoch 814 avg loss: 0.20418 (A-MSE: 0.17969) avg lploss: 0.00000
train epoch 815 avg loss: 0.20097 (A-MSE: 0.17763) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.28616 (A-MSE: 0.24998) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.24118 (A-MSE: 0.21106) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 2 out of 50
train epoch 816 avg loss: 0.19879 (A-MSE: 0.17540) avg lploss: 0.00000
train epoch 817 avg loss: 0.19419 (A-MSE: 0.17042) avg lploss: 0.00000
train epoch 818 avg loss: 0.18887 (A-MSE: 0.16581) avg lploss: 0.00000
train epoch 819 avg loss: 0.19534 (A-MSE: 0.17158) avg lploss: 0.00000
train epoch 820 avg loss: 0.21295 (A-MSE: 0.18845) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.31532 (A-MSE: 0.27487) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.28898 (A-MSE: 0.25341) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 3 out of 50
train epoch 821 avg loss: 0.21995 (A-MSE: 0.19372) avg lploss: 0.00000
train epoch 822 avg loss: 0.21745 (A-MSE: 0.19148) avg lploss: 0.00000
train epoch 823 avg loss: 0.18791 (A-MSE: 0.16511) avg lploss: 0.00000
train epoch 824 avg loss: 0.18623 (A-MSE: 0.16451) avg lploss: 0.00000
train epoch 825 avg loss: 0.20035 (A-MSE: 0.17621) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.28547 (A-MSE: 0.24998) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.23792 (A-MSE: 0.20879) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 4 out of 50
train epoch 826 avg loss: 0.19935 (A-MSE: 0.17620) avg lploss: 0.00000
train epoch 827 avg loss: 0.20844 (A-MSE: 0.18395) avg lploss: 0.00000
train epoch 828 avg loss: 0.18959 (A-MSE: 0.16688) avg lploss: 0.00000
train epoch 829 avg loss: 0.20509 (A-MSE: 0.18032) avg lploss: 0.00000
train epoch 830 avg loss: 0.19379 (A-MSE: 0.17070) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.31099 (A-MSE: 0.27242) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.26820 (A-MSE: 0.23500) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 5 out of 50
train epoch 831 avg loss: 0.20203 (A-MSE: 0.17862) avg lploss: 0.00000
train epoch 832 avg loss: 0.20220 (A-MSE: 0.17717) avg lploss: 0.00000
train epoch 833 avg loss: 0.22209 (A-MSE: 0.19471) avg lploss: 0.00000
train epoch 834 avg loss: 0.20149 (A-MSE: 0.17866) avg lploss: 0.00000
train epoch 835 avg loss: 0.21619 (A-MSE: 0.19115) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.30997 (A-MSE: 0.27041) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.26926 (A-MSE: 0.23491) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 6 out of 50
train epoch 836 avg loss: 0.20164 (A-MSE: 0.17745) avg lploss: 0.00000
train epoch 837 avg loss: 0.18619 (A-MSE: 0.16419) avg lploss: 0.00000
train epoch 838 avg loss: 0.18971 (A-MSE: 0.16648) avg lploss: 0.00000
train epoch 839 avg loss: 0.20492 (A-MSE: 0.18035) avg lploss: 0.00000
train epoch 840 avg loss: 0.19609 (A-MSE: 0.17277) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.34398 (A-MSE: 0.30487) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.29003 (A-MSE: 0.25713) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 7 out of 50
train epoch 841 avg loss: 0.18909 (A-MSE: 0.16714) avg lploss: 0.00000
train epoch 842 avg loss: 0.19072 (A-MSE: 0.16798) avg lploss: 0.00000
train epoch 843 avg loss: 0.18506 (A-MSE: 0.16309) avg lploss: 0.00000
train epoch 844 avg loss: 0.21521 (A-MSE: 0.18965) avg lploss: 0.00000
train epoch 845 avg loss: 0.20201 (A-MSE: 0.17795) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.27840 (A-MSE: 0.24551) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.23754 (A-MSE: 0.21071) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 8 out of 50
train epoch 846 avg loss: 0.17214 (A-MSE: 0.15150) avg lploss: 0.00000
train epoch 847 avg loss: 0.21258 (A-MSE: 0.18764) avg lploss: 0.00000
train epoch 848 avg loss: 0.21650 (A-MSE: 0.19162) avg lploss: 0.00000
train epoch 849 avg loss: 0.21645 (A-MSE: 0.19069) avg lploss: 0.00000
train epoch 850 avg loss: 0.20637 (A-MSE: 0.18182) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.34443 (A-MSE: 0.29967) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.29477 (A-MSE: 0.25705) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 9 out of 50
train epoch 851 avg loss: 0.21369 (A-MSE: 0.18827) avg lploss: 0.00000
train epoch 852 avg loss: 0.20088 (A-MSE: 0.17767) avg lploss: 0.00000
train epoch 853 avg loss: 0.22172 (A-MSE: 0.19543) avg lploss: 0.00000
train epoch 854 avg loss: 0.20332 (A-MSE: 0.17903) avg lploss: 0.00000
train epoch 855 avg loss: 0.20354 (A-MSE: 0.17842) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.32719 (A-MSE: 0.28414) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.28179 (A-MSE: 0.24419) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 10 out of 50
train epoch 856 avg loss: 0.19260 (A-MSE: 0.16917) avg lploss: 0.00000
train epoch 857 avg loss: 0.20101 (A-MSE: 0.17686) avg lploss: 0.00000
train epoch 858 avg loss: 0.17151 (A-MSE: 0.15088) avg lploss: 0.00000
train epoch 859 avg loss: 0.19945 (A-MSE: 0.17577) avg lploss: 0.00000
train epoch 860 avg loss: 0.19630 (A-MSE: 0.17333) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.36811 (A-MSE: 0.32270) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.31558 (A-MSE: 0.27707) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 11 out of 50
train epoch 861 avg loss: 0.18271 (A-MSE: 0.16121) avg lploss: 0.00000
train epoch 862 avg loss: 0.18352 (A-MSE: 0.16190) avg lploss: 0.00000
train epoch 863 avg loss: 0.20578 (A-MSE: 0.18234) avg lploss: 0.00000
train epoch 864 avg loss: 0.19177 (A-MSE: 0.16948) avg lploss: 0.00000
train epoch 865 avg loss: 0.19552 (A-MSE: 0.17301) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.29764 (A-MSE: 0.26267) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.26446 (A-MSE: 0.23438) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 12 out of 50
train epoch 866 avg loss: 0.20528 (A-MSE: 0.18092) avg lploss: 0.00000
train epoch 867 avg loss: 0.17640 (A-MSE: 0.15559) avg lploss: 0.00000
train epoch 868 avg loss: 0.18489 (A-MSE: 0.16291) avg lploss: 0.00000
train epoch 869 avg loss: 0.18163 (A-MSE: 0.15989) avg lploss: 0.00000
train epoch 870 avg loss: 0.18282 (A-MSE: 0.16182) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.28357 (A-MSE: 0.24610) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.23906 (A-MSE: 0.20790) avg lploss: 0.00000
*** Best Val Loss: 0.26857 	 Best Test Loss: 0.23661 	 Best epoch 805
EarlyStopping counter: 13 out of 50
train epoch 871 avg loss: 0.19343 (A-MSE: 0.17008) avg lploss: 0.00000
train epoch 872 avg loss: 0.19081 (A-MSE: 0.16838) avg lploss: 0.00000
train epoch 873 avg loss: 0.19121 (A-MSE: 0.16843) avg lploss: 0.00000
train epoch 874 avg loss: 0.18616 (A-MSE: 0.16397) avg lploss: 0.00000
train epoch 875 avg loss: 0.17857 (A-MSE: 0.15840) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.25161 (A-MSE: 0.21918) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.21882 (A-MSE: 0.19093) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
Validation loss decreased (0.268567 --> 0.251613).  Saving model ...
train epoch 876 avg loss: 0.17668 (A-MSE: 0.15500) avg lploss: 0.00000
train epoch 877 avg loss: 0.18510 (A-MSE: 0.16395) avg lploss: 0.00000
train epoch 878 avg loss: 0.17077 (A-MSE: 0.15037) avg lploss: 0.00000
train epoch 879 avg loss: 0.17588 (A-MSE: 0.15487) avg lploss: 0.00000
train epoch 880 avg loss: 0.17477 (A-MSE: 0.15424) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.29400 (A-MSE: 0.25769) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.25525 (A-MSE: 0.22432) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
EarlyStopping counter: 1 out of 50
train epoch 881 avg loss: 0.18270 (A-MSE: 0.16128) avg lploss: 0.00000
train epoch 882 avg loss: 0.19549 (A-MSE: 0.17245) avg lploss: 0.00000
train epoch 883 avg loss: 0.20295 (A-MSE: 0.17899) avg lploss: 0.00000
train epoch 884 avg loss: 0.19314 (A-MSE: 0.17085) avg lploss: 0.00000
train epoch 885 avg loss: 0.16813 (A-MSE: 0.14912) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.25772 (A-MSE: 0.22727) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.21667 (A-MSE: 0.19142) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
EarlyStopping counter: 2 out of 50
train epoch 886 avg loss: 0.20949 (A-MSE: 0.18561) avg lploss: 0.00000
train epoch 887 avg loss: 0.20048 (A-MSE: 0.17632) avg lploss: 0.00000
train epoch 888 avg loss: 0.17839 (A-MSE: 0.15756) avg lploss: 0.00000
train epoch 889 avg loss: 0.18062 (A-MSE: 0.15920) avg lploss: 0.00000
train epoch 890 avg loss: 0.18575 (A-MSE: 0.16415) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.32442 (A-MSE: 0.28050) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.29860 (A-MSE: 0.25843) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
EarlyStopping counter: 3 out of 50
train epoch 891 avg loss: 0.21025 (A-MSE: 0.18548) avg lploss: 0.00000
train epoch 892 avg loss: 0.19214 (A-MSE: 0.17024) avg lploss: 0.00000
train epoch 893 avg loss: 0.17649 (A-MSE: 0.15551) avg lploss: 0.00000
train epoch 894 avg loss: 0.16888 (A-MSE: 0.14998) avg lploss: 0.00000
train epoch 895 avg loss: 0.18279 (A-MSE: 0.16114) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.39954 (A-MSE: 0.34982) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.35061 (A-MSE: 0.30770) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
EarlyStopping counter: 4 out of 50
train epoch 896 avg loss: 0.19539 (A-MSE: 0.17268) avg lploss: 0.00000
train epoch 897 avg loss: 0.18939 (A-MSE: 0.16722) avg lploss: 0.00000
train epoch 898 avg loss: 0.22205 (A-MSE: 0.19677) avg lploss: 0.00000
train epoch 899 avg loss: 0.21231 (A-MSE: 0.18808) avg lploss: 0.00000
train epoch 900 avg loss: 0.19290 (A-MSE: 0.17099) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.28782 (A-MSE: 0.24747) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.25224 (A-MSE: 0.21729) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
EarlyStopping counter: 5 out of 50
train epoch 901 avg loss: 0.18549 (A-MSE: 0.16255) avg lploss: 0.00000
train epoch 902 avg loss: 0.17380 (A-MSE: 0.15352) avg lploss: 0.00000
train epoch 903 avg loss: 0.17902 (A-MSE: 0.15837) avg lploss: 0.00000
train epoch 904 avg loss: 0.17099 (A-MSE: 0.15059) avg lploss: 0.00000
train epoch 905 avg loss: 0.15853 (A-MSE: 0.14013) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.30673 (A-MSE: 0.26768) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.26811 (A-MSE: 0.23416) avg lploss: 0.00000
*** Best Val Loss: 0.25161 	 Best Test Loss: 0.21882 	 Best epoch 875
EarlyStopping counter: 6 out of 50
train epoch 906 avg loss: 0.17767 (A-MSE: 0.15645) avg lploss: 0.00000
train epoch 907 avg loss: 0.17068 (A-MSE: 0.15043) avg lploss: 0.00000
train epoch 908 avg loss: 0.16454 (A-MSE: 0.14555) avg lploss: 0.00000
train epoch 909 avg loss: 0.15886 (A-MSE: 0.14017) avg lploss: 0.00000
train epoch 910 avg loss: 0.16366 (A-MSE: 0.14431) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.24395 (A-MSE: 0.21200) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.20828 (A-MSE: 0.18183) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
Validation loss decreased (0.251613 --> 0.243949).  Saving model ...
train epoch 911 avg loss: 0.14980 (A-MSE: 0.13194) avg lploss: 0.00000
train epoch 912 avg loss: 0.15594 (A-MSE: 0.13821) avg lploss: 0.00000
train epoch 913 avg loss: 0.15465 (A-MSE: 0.13681) avg lploss: 0.00000
train epoch 914 avg loss: 0.19147 (A-MSE: 0.16885) avg lploss: 0.00000
train epoch 915 avg loss: 0.19037 (A-MSE: 0.16785) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.26902 (A-MSE: 0.23332) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.22973 (A-MSE: 0.20028) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 1 out of 50
train epoch 916 avg loss: 0.20355 (A-MSE: 0.17953) avg lploss: 0.00000
train epoch 917 avg loss: 0.17277 (A-MSE: 0.15336) avg lploss: 0.00000
train epoch 918 avg loss: 0.16030 (A-MSE: 0.14192) avg lploss: 0.00000
train epoch 919 avg loss: 0.16428 (A-MSE: 0.14562) avg lploss: 0.00000
train epoch 920 avg loss: 0.16856 (A-MSE: 0.14926) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.25412 (A-MSE: 0.22116) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.21841 (A-MSE: 0.19082) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 2 out of 50
train epoch 921 avg loss: 0.15860 (A-MSE: 0.14020) avg lploss: 0.00000
train epoch 922 avg loss: 0.17254 (A-MSE: 0.15257) avg lploss: 0.00000
train epoch 923 avg loss: 0.16573 (A-MSE: 0.14706) avg lploss: 0.00000
train epoch 924 avg loss: 0.15603 (A-MSE: 0.13831) avg lploss: 0.00000
train epoch 925 avg loss: 0.15357 (A-MSE: 0.13573) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.29740 (A-MSE: 0.26067) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.25513 (A-MSE: 0.22431) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 3 out of 50
train epoch 926 avg loss: 0.19504 (A-MSE: 0.17164) avg lploss: 0.00000
train epoch 927 avg loss: 0.23378 (A-MSE: 0.20661) avg lploss: 0.00000
train epoch 928 avg loss: 0.19468 (A-MSE: 0.17174) avg lploss: 0.00000
train epoch 929 avg loss: 0.18462 (A-MSE: 0.16471) avg lploss: 0.00000
train epoch 930 avg loss: 0.17505 (A-MSE: 0.15333) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.28079 (A-MSE: 0.25165) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.23617 (A-MSE: 0.21248) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 4 out of 50
train epoch 931 avg loss: 0.16293 (A-MSE: 0.14523) avg lploss: 0.00000
train epoch 932 avg loss: 0.16284 (A-MSE: 0.14443) avg lploss: 0.00000
train epoch 933 avg loss: 0.14757 (A-MSE: 0.13065) avg lploss: 0.00000
train epoch 934 avg loss: 0.15194 (A-MSE: 0.13481) avg lploss: 0.00000
train epoch 935 avg loss: 0.14893 (A-MSE: 0.13162) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.33409 (A-MSE: 0.29765) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.28582 (A-MSE: 0.25620) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 5 out of 50
train epoch 936 avg loss: 0.18217 (A-MSE: 0.16056) avg lploss: 0.00000
train epoch 937 avg loss: 0.19591 (A-MSE: 0.17307) avg lploss: 0.00000
train epoch 938 avg loss: 0.20460 (A-MSE: 0.18025) avg lploss: 0.00000
train epoch 939 avg loss: 0.17704 (A-MSE: 0.15695) avg lploss: 0.00000
train epoch 940 avg loss: 0.16228 (A-MSE: 0.14325) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.25191 (A-MSE: 0.22424) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.21364 (A-MSE: 0.19091) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 6 out of 50
train epoch 941 avg loss: 0.18514 (A-MSE: 0.16463) avg lploss: 0.00000
train epoch 942 avg loss: 0.16295 (A-MSE: 0.14453) avg lploss: 0.00000
train epoch 943 avg loss: 0.17707 (A-MSE: 0.15755) avg lploss: 0.00000
train epoch 944 avg loss: 0.17146 (A-MSE: 0.15114) avg lploss: 0.00000
train epoch 945 avg loss: 0.16826 (A-MSE: 0.14894) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.26351 (A-MSE: 0.22914) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.23495 (A-MSE: 0.20451) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 7 out of 50
train epoch 946 avg loss: 0.17049 (A-MSE: 0.15128) avg lploss: 0.00000
train epoch 947 avg loss: 0.14694 (A-MSE: 0.12996) avg lploss: 0.00000
train epoch 948 avg loss: 0.15228 (A-MSE: 0.13463) avg lploss: 0.00000
train epoch 949 avg loss: 0.17471 (A-MSE: 0.15501) avg lploss: 0.00000
train epoch 950 avg loss: 0.17280 (A-MSE: 0.15231) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.29153 (A-MSE: 0.25652) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.25501 (A-MSE: 0.22517) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 8 out of 50
train epoch 951 avg loss: 0.17134 (A-MSE: 0.15153) avg lploss: 0.00000
train epoch 952 avg loss: 0.16915 (A-MSE: 0.14961) avg lploss: 0.00000
train epoch 953 avg loss: 0.15546 (A-MSE: 0.13742) avg lploss: 0.00000
train epoch 954 avg loss: 0.14616 (A-MSE: 0.12930) avg lploss: 0.00000
train epoch 955 avg loss: 0.15211 (A-MSE: 0.13488) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.25438 (A-MSE: 0.22046) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.22214 (A-MSE: 0.19311) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 9 out of 50
train epoch 956 avg loss: 0.16747 (A-MSE: 0.14834) avg lploss: 0.00000
train epoch 957 avg loss: 0.19783 (A-MSE: 0.17451) avg lploss: 0.00000
train epoch 958 avg loss: 0.20002 (A-MSE: 0.17611) avg lploss: 0.00000
train epoch 959 avg loss: 0.17938 (A-MSE: 0.15894) avg lploss: 0.00000
train epoch 960 avg loss: 0.17919 (A-MSE: 0.15885) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.27656 (A-MSE: 0.24133) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.23733 (A-MSE: 0.20787) avg lploss: 0.00000
*** Best Val Loss: 0.24395 	 Best Test Loss: 0.20828 	 Best epoch 910
EarlyStopping counter: 10 out of 50
train epoch 961 avg loss: 0.17426 (A-MSE: 0.15368) avg lploss: 0.00000
train epoch 962 avg loss: 0.16252 (A-MSE: 0.14500) avg lploss: 0.00000
train epoch 963 avg loss: 0.15719 (A-MSE: 0.13854) avg lploss: 0.00000
train epoch 964 avg loss: 0.13696 (A-MSE: 0.12135) avg lploss: 0.00000
train epoch 965 avg loss: 0.16787 (A-MSE: 0.14813) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.23385 (A-MSE: 0.20570) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.20036 (A-MSE: 0.17716) avg lploss: 0.00000
*** Best Val Loss: 0.23385 	 Best Test Loss: 0.20036 	 Best epoch 965
Validation loss decreased (0.243949 --> 0.233854).  Saving model ...
train epoch 966 avg loss: 0.16645 (A-MSE: 0.14770) avg lploss: 0.00000
train epoch 967 avg loss: 0.16901 (A-MSE: 0.14893) avg lploss: 0.00000
train epoch 968 avg loss: 0.15672 (A-MSE: 0.13886) avg lploss: 0.00000
train epoch 969 avg loss: 0.14998 (A-MSE: 0.13339) avg lploss: 0.00000
train epoch 970 avg loss: 0.16738 (A-MSE: 0.14808) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.22496 (A-MSE: 0.19710) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.19285 (A-MSE: 0.16995) avg lploss: 0.00000
*** Best Val Loss: 0.22496 	 Best Test Loss: 0.19285 	 Best epoch 970
Validation loss decreased (0.233854 --> 0.224957).  Saving model ...
train epoch 971 avg loss: 0.14733 (A-MSE: 0.13007) avg lploss: 0.00000
train epoch 972 avg loss: 0.15489 (A-MSE: 0.13680) avg lploss: 0.00000
train epoch 973 avg loss: 0.14967 (A-MSE: 0.13257) avg lploss: 0.00000
train epoch 974 avg loss: 0.16540 (A-MSE: 0.14666) avg lploss: 0.00000
train epoch 975 avg loss: 0.18940 (A-MSE: 0.16758) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.32452 (A-MSE: 0.28082) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.29039 (A-MSE: 0.25208) avg lploss: 0.00000
*** Best Val Loss: 0.22496 	 Best Test Loss: 0.19285 	 Best epoch 970
EarlyStopping counter: 1 out of 50
train epoch 976 avg loss: 0.15634 (A-MSE: 0.13858) avg lploss: 0.00000
train epoch 977 avg loss: 0.15287 (A-MSE: 0.13650) avg lploss: 0.00000
train epoch 978 avg loss: 0.15365 (A-MSE: 0.13575) avg lploss: 0.00000
train epoch 979 avg loss: 0.17239 (A-MSE: 0.15217) avg lploss: 0.00000
train epoch 980 avg loss: 0.14666 (A-MSE: 0.12991) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.22037 (A-MSE: 0.19340) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.18714 (A-MSE: 0.16485) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
Validation loss decreased (0.224957 --> 0.220371).  Saving model ...
train epoch 981 avg loss: 0.14467 (A-MSE: 0.12800) avg lploss: 0.00000
train epoch 982 avg loss: 0.14487 (A-MSE: 0.12873) avg lploss: 0.00000
train epoch 983 avg loss: 0.14895 (A-MSE: 0.13169) avg lploss: 0.00000
train epoch 984 avg loss: 0.16202 (A-MSE: 0.14281) avg lploss: 0.00000
train epoch 985 avg loss: 0.14457 (A-MSE: 0.12737) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.26426 (A-MSE: 0.23106) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.23040 (A-MSE: 0.20167) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 1 out of 50
train epoch 986 avg loss: 0.14766 (A-MSE: 0.13067) avg lploss: 0.00000
train epoch 987 avg loss: 0.15058 (A-MSE: 0.13296) avg lploss: 0.00000
train epoch 988 avg loss: 0.16547 (A-MSE: 0.14699) avg lploss: 0.00000
train epoch 989 avg loss: 0.15888 (A-MSE: 0.14085) avg lploss: 0.00000
train epoch 990 avg loss: 0.15741 (A-MSE: 0.13974) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.23716 (A-MSE: 0.20839) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.20589 (A-MSE: 0.18232) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 2 out of 50
train epoch 991 avg loss: 0.15080 (A-MSE: 0.13364) avg lploss: 0.00000
train epoch 992 avg loss: 0.13299 (A-MSE: 0.11804) avg lploss: 0.00000
train epoch 993 avg loss: 0.12639 (A-MSE: 0.11222) avg lploss: 0.00000
train epoch 994 avg loss: 0.13952 (A-MSE: 0.12304) avg lploss: 0.00000
train epoch 995 avg loss: 0.13671 (A-MSE: 0.12117) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.24043 (A-MSE: 0.20839) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.21691 (A-MSE: 0.18938) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 3 out of 50
train epoch 996 avg loss: 0.14218 (A-MSE: 0.12589) avg lploss: 0.00000
train epoch 997 avg loss: 0.17217 (A-MSE: 0.15212) avg lploss: 0.00000
train epoch 998 avg loss: 0.21969 (A-MSE: 0.19434) avg lploss: 0.00000
train epoch 999 avg loss: 0.18155 (A-MSE: 0.16107) avg lploss: 0.00000
train epoch 1000 avg loss: 0.16470 (A-MSE: 0.14606) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.24747 (A-MSE: 0.21637) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.21262 (A-MSE: 0.18614) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 4 out of 50
train epoch 1001 avg loss: 0.14840 (A-MSE: 0.13159) avg lploss: 0.00000
train epoch 1002 avg loss: 0.14792 (A-MSE: 0.13136) avg lploss: 0.00000
train epoch 1003 avg loss: 0.15236 (A-MSE: 0.13481) avg lploss: 0.00000
train epoch 1004 avg loss: 0.13995 (A-MSE: 0.12479) avg lploss: 0.00000
train epoch 1005 avg loss: 0.17170 (A-MSE: 0.15186) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.26390 (A-MSE: 0.23463) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.22544 (A-MSE: 0.20137) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 5 out of 50
train epoch 1006 avg loss: 0.15867 (A-MSE: 0.14089) avg lploss: 0.00000
train epoch 1007 avg loss: 0.14548 (A-MSE: 0.12852) avg lploss: 0.00000
train epoch 1008 avg loss: 0.13614 (A-MSE: 0.12082) avg lploss: 0.00000
train epoch 1009 avg loss: 0.15603 (A-MSE: 0.13836) avg lploss: 0.00000
train epoch 1010 avg loss: 0.17878 (A-MSE: 0.15779) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.26237 (A-MSE: 0.22741) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.23868 (A-MSE: 0.20724) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 6 out of 50
train epoch 1011 avg loss: 0.14223 (A-MSE: 0.12646) avg lploss: 0.00000
train epoch 1012 avg loss: 0.13802 (A-MSE: 0.12178) avg lploss: 0.00000
train epoch 1013 avg loss: 0.14233 (A-MSE: 0.12593) avg lploss: 0.00000
train epoch 1014 avg loss: 0.15120 (A-MSE: 0.13350) avg lploss: 0.00000
train epoch 1015 avg loss: 0.14951 (A-MSE: 0.13239) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.22433 (A-MSE: 0.20057) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.19750 (A-MSE: 0.17726) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 7 out of 50
train epoch 1016 avg loss: 0.14450 (A-MSE: 0.12824) avg lploss: 0.00000
train epoch 1017 avg loss: 0.15073 (A-MSE: 0.13424) avg lploss: 0.00000
train epoch 1018 avg loss: 0.14978 (A-MSE: 0.13230) avg lploss: 0.00000
train epoch 1019 avg loss: 0.15427 (A-MSE: 0.13673) avg lploss: 0.00000
train epoch 1020 avg loss: 0.13707 (A-MSE: 0.12141) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.24415 (A-MSE: 0.21359) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.21338 (A-MSE: 0.18744) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 8 out of 50
train epoch 1021 avg loss: 0.13056 (A-MSE: 0.11603) avg lploss: 0.00000
train epoch 1022 avg loss: 0.13470 (A-MSE: 0.11919) avg lploss: 0.00000
train epoch 1023 avg loss: 0.14591 (A-MSE: 0.12927) avg lploss: 0.00000
train epoch 1024 avg loss: 0.15804 (A-MSE: 0.13969) avg lploss: 0.00000
train epoch 1025 avg loss: 0.15246 (A-MSE: 0.13490) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.26559 (A-MSE: 0.22709) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.23764 (A-MSE: 0.20414) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 9 out of 50
train epoch 1026 avg loss: 0.16654 (A-MSE: 0.14711) avg lploss: 0.00000
train epoch 1027 avg loss: 0.14587 (A-MSE: 0.12903) avg lploss: 0.00000
train epoch 1028 avg loss: 0.15136 (A-MSE: 0.13503) avg lploss: 0.00000
train epoch 1029 avg loss: 0.13864 (A-MSE: 0.12373) avg lploss: 0.00000
train epoch 1030 avg loss: 0.14817 (A-MSE: 0.13154) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.27100 (A-MSE: 0.23365) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.23886 (A-MSE: 0.20679) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 10 out of 50
train epoch 1031 avg loss: 0.15716 (A-MSE: 0.13834) avg lploss: 0.00000
train epoch 1032 avg loss: 0.14625 (A-MSE: 0.12934) avg lploss: 0.00000
train epoch 1033 avg loss: 0.13917 (A-MSE: 0.12335) avg lploss: 0.00000
train epoch 1034 avg loss: 0.13636 (A-MSE: 0.12050) avg lploss: 0.00000
train epoch 1035 avg loss: 0.13692 (A-MSE: 0.12150) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.22206 (A-MSE: 0.19264) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.18612 (A-MSE: 0.16152) avg lploss: 0.00000
*** Best Val Loss: 0.22037 	 Best Test Loss: 0.18714 	 Best epoch 980
EarlyStopping counter: 11 out of 50
train epoch 1036 avg loss: 0.13826 (A-MSE: 0.12182) avg lploss: 0.00000
train epoch 1037 avg loss: 0.15771 (A-MSE: 0.13926) avg lploss: 0.00000
train epoch 1038 avg loss: 0.14628 (A-MSE: 0.12959) avg lploss: 0.00000
train epoch 1039 avg loss: 0.17015 (A-MSE: 0.15041) avg lploss: 0.00000
train epoch 1040 avg loss: 0.14998 (A-MSE: 0.13326) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.21497 (A-MSE: 0.18824) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.18485 (A-MSE: 0.16240) avg lploss: 0.00000
*** Best Val Loss: 0.21497 	 Best Test Loss: 0.18485 	 Best epoch 1040
Validation loss decreased (0.220371 --> 0.214969).  Saving model ...
train epoch 1041 avg loss: 0.13123 (A-MSE: 0.11637) avg lploss: 0.00000
train epoch 1042 avg loss: 0.14231 (A-MSE: 0.12591) avg lploss: 0.00000
train epoch 1043 avg loss: 0.14835 (A-MSE: 0.13165) avg lploss: 0.00000
train epoch 1044 avg loss: 0.13850 (A-MSE: 0.12239) avg lploss: 0.00000
train epoch 1045 avg loss: 0.13706 (A-MSE: 0.12152) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.21654 (A-MSE: 0.19080) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.18744 (A-MSE: 0.16617) avg lploss: 0.00000
*** Best Val Loss: 0.21497 	 Best Test Loss: 0.18485 	 Best epoch 1040
EarlyStopping counter: 1 out of 50
train epoch 1046 avg loss: 0.13445 (A-MSE: 0.11920) avg lploss: 0.00000
train epoch 1047 avg loss: 0.14767 (A-MSE: 0.12982) avg lploss: 0.00000
train epoch 1048 avg loss: 0.16925 (A-MSE: 0.14998) avg lploss: 0.00000
train epoch 1049 avg loss: 0.14726 (A-MSE: 0.13005) avg lploss: 0.00000
train epoch 1050 avg loss: 0.13348 (A-MSE: 0.11824) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.20231 (A-MSE: 0.17946) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.17128 (A-MSE: 0.15205) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
Validation loss decreased (0.214969 --> 0.202314).  Saving model ...
train epoch 1051 avg loss: 0.14272 (A-MSE: 0.12681) avg lploss: 0.00000
train epoch 1052 avg loss: 0.13739 (A-MSE: 0.12170) avg lploss: 0.00000
train epoch 1053 avg loss: 0.12775 (A-MSE: 0.11369) avg lploss: 0.00000
train epoch 1054 avg loss: 0.14363 (A-MSE: 0.12734) avg lploss: 0.00000
train epoch 1055 avg loss: 0.14298 (A-MSE: 0.12688) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.24195 (A-MSE: 0.21175) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.21327 (A-MSE: 0.18742) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 1 out of 50
train epoch 1056 avg loss: 0.15128 (A-MSE: 0.13408) avg lploss: 0.00000
train epoch 1057 avg loss: 0.13810 (A-MSE: 0.12280) avg lploss: 0.00000
train epoch 1058 avg loss: 0.14688 (A-MSE: 0.13084) avg lploss: 0.00000
train epoch 1059 avg loss: 0.14123 (A-MSE: 0.12539) avg lploss: 0.00000
train epoch 1060 avg loss: 0.16920 (A-MSE: 0.15087) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.21601 (A-MSE: 0.18941) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.19297 (A-MSE: 0.16953) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 2 out of 50
train epoch 1061 avg loss: 0.15200 (A-MSE: 0.13539) avg lploss: 0.00000
train epoch 1062 avg loss: 0.15055 (A-MSE: 0.13287) avg lploss: 0.00000
train epoch 1063 avg loss: 0.13791 (A-MSE: 0.12280) avg lploss: 0.00000
train epoch 1064 avg loss: 0.14884 (A-MSE: 0.13118) avg lploss: 0.00000
train epoch 1065 avg loss: 0.14476 (A-MSE: 0.12879) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.21812 (A-MSE: 0.19045) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.18760 (A-MSE: 0.16404) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 3 out of 50
train epoch 1066 avg loss: 0.13394 (A-MSE: 0.11844) avg lploss: 0.00000
train epoch 1067 avg loss: 0.13171 (A-MSE: 0.11707) avg lploss: 0.00000
train epoch 1068 avg loss: 0.13507 (A-MSE: 0.11945) avg lploss: 0.00000
train epoch 1069 avg loss: 0.14593 (A-MSE: 0.12954) avg lploss: 0.00000
train epoch 1070 avg loss: 0.15019 (A-MSE: 0.13307) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.22318 (A-MSE: 0.19398) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.19127 (A-MSE: 0.16627) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 4 out of 50
train epoch 1071 avg loss: 0.14027 (A-MSE: 0.12350) avg lploss: 0.00000
train epoch 1072 avg loss: 0.12917 (A-MSE: 0.11439) avg lploss: 0.00000
train epoch 1073 avg loss: 0.15210 (A-MSE: 0.13534) avg lploss: 0.00000
train epoch 1074 avg loss: 0.14440 (A-MSE: 0.12786) avg lploss: 0.00000
train epoch 1075 avg loss: 0.14426 (A-MSE: 0.12635) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.30586 (A-MSE: 0.26926) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.27378 (A-MSE: 0.24199) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 5 out of 50
train epoch 1076 avg loss: 0.16209 (A-MSE: 0.14406) avg lploss: 0.00000
train epoch 1077 avg loss: 0.13731 (A-MSE: 0.12192) avg lploss: 0.00000
train epoch 1078 avg loss: 0.13788 (A-MSE: 0.12272) avg lploss: 0.00000
train epoch 1079 avg loss: 0.14711 (A-MSE: 0.12943) avg lploss: 0.00000
train epoch 1080 avg loss: 0.15422 (A-MSE: 0.13687) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.25055 (A-MSE: 0.21890) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.22392 (A-MSE: 0.19576) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 6 out of 50
train epoch 1081 avg loss: 0.15528 (A-MSE: 0.13766) avg lploss: 0.00000
train epoch 1082 avg loss: 0.14056 (A-MSE: 0.12459) avg lploss: 0.00000
train epoch 1083 avg loss: 0.15699 (A-MSE: 0.13906) avg lploss: 0.00000
train epoch 1084 avg loss: 0.16079 (A-MSE: 0.14240) avg lploss: 0.00000
train epoch 1085 avg loss: 0.14992 (A-MSE: 0.13307) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.21951 (A-MSE: 0.19683) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.19304 (A-MSE: 0.17442) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 7 out of 50
train epoch 1086 avg loss: 0.14237 (A-MSE: 0.12618) avg lploss: 0.00000
train epoch 1087 avg loss: 0.12994 (A-MSE: 0.11509) avg lploss: 0.00000
train epoch 1088 avg loss: 0.12365 (A-MSE: 0.10994) avg lploss: 0.00000
train epoch 1089 avg loss: 0.13138 (A-MSE: 0.11621) avg lploss: 0.00000
train epoch 1090 avg loss: 0.15165 (A-MSE: 0.13431) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.21990 (A-MSE: 0.19687) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.19415 (A-MSE: 0.17463) avg lploss: 0.00000
*** Best Val Loss: 0.20231 	 Best Test Loss: 0.17128 	 Best epoch 1050
EarlyStopping counter: 8 out of 50
train epoch 1091 avg loss: 0.15714 (A-MSE: 0.13964) avg lploss: 0.00000
train epoch 1092 avg loss: 0.14397 (A-MSE: 0.12815) avg lploss: 0.00000
train epoch 1093 avg loss: 0.14584 (A-MSE: 0.12871) avg lploss: 0.00000
train epoch 1094 avg loss: 0.15260 (A-MSE: 0.13558) avg lploss: 0.00000
train epoch 1095 avg loss: 0.13574 (A-MSE: 0.12029) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.20085 (A-MSE: 0.17762) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.17098 (A-MSE: 0.15191) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
Validation loss decreased (0.202314 --> 0.200847).  Saving model ...
train epoch 1096 avg loss: 0.13051 (A-MSE: 0.11540) avg lploss: 0.00000
train epoch 1097 avg loss: 0.13879 (A-MSE: 0.12330) avg lploss: 0.00000
train epoch 1098 avg loss: 0.12491 (A-MSE: 0.11085) avg lploss: 0.00000
train epoch 1099 avg loss: 0.12388 (A-MSE: 0.10940) avg lploss: 0.00000
train epoch 1100 avg loss: 0.12532 (A-MSE: 0.11089) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.23601 (A-MSE: 0.20748) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.20142 (A-MSE: 0.17786) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 1 out of 50
train epoch 1101 avg loss: 0.12784 (A-MSE: 0.11275) avg lploss: 0.00000
train epoch 1102 avg loss: 0.12420 (A-MSE: 0.11031) avg lploss: 0.00000
train epoch 1103 avg loss: 0.11812 (A-MSE: 0.10448) avg lploss: 0.00000
train epoch 1104 avg loss: 0.13622 (A-MSE: 0.12060) avg lploss: 0.00000
train epoch 1105 avg loss: 0.15278 (A-MSE: 0.13496) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.20596 (A-MSE: 0.18155) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.18584 (A-MSE: 0.16417) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 2 out of 50
train epoch 1106 avg loss: 0.15193 (A-MSE: 0.13520) avg lploss: 0.00000
train epoch 1107 avg loss: 0.13523 (A-MSE: 0.11949) avg lploss: 0.00000
train epoch 1108 avg loss: 0.15299 (A-MSE: 0.13491) avg lploss: 0.00000
train epoch 1109 avg loss: 0.15061 (A-MSE: 0.13404) avg lploss: 0.00000
train epoch 1110 avg loss: 0.14088 (A-MSE: 0.12427) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.23645 (A-MSE: 0.20485) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.20776 (A-MSE: 0.18000) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 3 out of 50
train epoch 1111 avg loss: 0.12709 (A-MSE: 0.11281) avg lploss: 0.00000
train epoch 1112 avg loss: 0.13217 (A-MSE: 0.11773) avg lploss: 0.00000
train epoch 1113 avg loss: 0.12203 (A-MSE: 0.10794) avg lploss: 0.00000
train epoch 1114 avg loss: 0.12157 (A-MSE: 0.10810) avg lploss: 0.00000
train epoch 1115 avg loss: 0.14128 (A-MSE: 0.12536) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.24905 (A-MSE: 0.21704) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.22200 (A-MSE: 0.19429) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 4 out of 50
train epoch 1116 avg loss: 0.14357 (A-MSE: 0.12669) avg lploss: 0.00000
train epoch 1117 avg loss: 0.12445 (A-MSE: 0.11108) avg lploss: 0.00000
train epoch 1118 avg loss: 0.12367 (A-MSE: 0.10906) avg lploss: 0.00000
train epoch 1119 avg loss: 0.13927 (A-MSE: 0.12314) avg lploss: 0.00000
train epoch 1120 avg loss: 0.15970 (A-MSE: 0.14153) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.20740 (A-MSE: 0.18389) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.18231 (A-MSE: 0.16240) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 5 out of 50
train epoch 1121 avg loss: 0.12882 (A-MSE: 0.11440) avg lploss: 0.00000
train epoch 1122 avg loss: 0.13129 (A-MSE: 0.11559) avg lploss: 0.00000
train epoch 1123 avg loss: 0.12467 (A-MSE: 0.11053) avg lploss: 0.00000
train epoch 1124 avg loss: 0.11851 (A-MSE: 0.10539) avg lploss: 0.00000
train epoch 1125 avg loss: 0.13168 (A-MSE: 0.11727) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.20667 (A-MSE: 0.17898) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.18056 (A-MSE: 0.15697) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 6 out of 50
train epoch 1126 avg loss: 0.13124 (A-MSE: 0.11626) avg lploss: 0.00000
train epoch 1127 avg loss: 0.11645 (A-MSE: 0.10307) avg lploss: 0.00000
train epoch 1128 avg loss: 0.12836 (A-MSE: 0.11409) avg lploss: 0.00000
train epoch 1129 avg loss: 0.11975 (A-MSE: 0.10641) avg lploss: 0.00000
train epoch 1130 avg loss: 0.13713 (A-MSE: 0.12149) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.20939 (A-MSE: 0.18390) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.18784 (A-MSE: 0.16570) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 7 out of 50
train epoch 1131 avg loss: 0.14212 (A-MSE: 0.12773) avg lploss: 0.00000
train epoch 1132 avg loss: 0.14087 (A-MSE: 0.12455) avg lploss: 0.00000
train epoch 1133 avg loss: 0.13038 (A-MSE: 0.11441) avg lploss: 0.00000
train epoch 1134 avg loss: 0.13023 (A-MSE: 0.11539) avg lploss: 0.00000
train epoch 1135 avg loss: 0.14550 (A-MSE: 0.12954) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.26742 (A-MSE: 0.23238) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.22244 (A-MSE: 0.19392) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 8 out of 50
train epoch 1136 avg loss: 0.15509 (A-MSE: 0.13841) avg lploss: 0.00000
train epoch 1137 avg loss: 0.16202 (A-MSE: 0.14293) avg lploss: 0.00000
train epoch 1138 avg loss: 0.14556 (A-MSE: 0.12852) avg lploss: 0.00000
train epoch 1139 avg loss: 0.13437 (A-MSE: 0.11897) avg lploss: 0.00000
train epoch 1140 avg loss: 0.13489 (A-MSE: 0.11985) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.29550 (A-MSE: 0.25910) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.26942 (A-MSE: 0.23613) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 9 out of 50
train epoch 1141 avg loss: 0.13665 (A-MSE: 0.12140) avg lploss: 0.00000
train epoch 1142 avg loss: 0.11716 (A-MSE: 0.10316) avg lploss: 0.00000
train epoch 1143 avg loss: 0.11133 (A-MSE: 0.09897) avg lploss: 0.00000
train epoch 1144 avg loss: 0.10673 (A-MSE: 0.09425) avg lploss: 0.00000
train epoch 1145 avg loss: 0.10750 (A-MSE: 0.09513) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.25935 (A-MSE: 0.22370) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.23432 (A-MSE: 0.20196) avg lploss: 0.00000
*** Best Val Loss: 0.20085 	 Best Test Loss: 0.17098 	 Best epoch 1095
EarlyStopping counter: 10 out of 50
train epoch 1146 avg loss: 0.13192 (A-MSE: 0.11752) avg lploss: 0.00000
train epoch 1147 avg loss: 0.12708 (A-MSE: 0.11276) avg lploss: 0.00000
train epoch 1148 avg loss: 0.11916 (A-MSE: 0.10516) avg lploss: 0.00000
train epoch 1149 avg loss: 0.11251 (A-MSE: 0.09922) avg lploss: 0.00000
train epoch 1150 avg loss: 0.11530 (A-MSE: 0.10206) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.18360 (A-MSE: 0.16139) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.15472 (A-MSE: 0.13628) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
Validation loss decreased (0.200847 --> 0.183603).  Saving model ...
train epoch 1151 avg loss: 0.13183 (A-MSE: 0.11646) avg lploss: 0.00000
train epoch 1152 avg loss: 0.15848 (A-MSE: 0.14111) avg lploss: 0.00000
train epoch 1153 avg loss: 0.14304 (A-MSE: 0.12699) avg lploss: 0.00000
train epoch 1154 avg loss: 0.12595 (A-MSE: 0.11093) avg lploss: 0.00000
train epoch 1155 avg loss: 0.12842 (A-MSE: 0.11376) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.21264 (A-MSE: 0.18698) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.17972 (A-MSE: 0.15773) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 1 out of 50
train epoch 1156 avg loss: 0.11724 (A-MSE: 0.10406) avg lploss: 0.00000
train epoch 1157 avg loss: 0.11648 (A-MSE: 0.10328) avg lploss: 0.00000
train epoch 1158 avg loss: 0.10881 (A-MSE: 0.09685) avg lploss: 0.00000
train epoch 1159 avg loss: 0.11856 (A-MSE: 0.10472) avg lploss: 0.00000
train epoch 1160 avg loss: 0.11716 (A-MSE: 0.10339) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.21820 (A-MSE: 0.19295) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.18408 (A-MSE: 0.16314) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 2 out of 50
train epoch 1161 avg loss: 0.11459 (A-MSE: 0.10188) avg lploss: 0.00000
train epoch 1162 avg loss: 0.12928 (A-MSE: 0.11483) avg lploss: 0.00000
train epoch 1163 avg loss: 0.13398 (A-MSE: 0.11892) avg lploss: 0.00000
train epoch 1164 avg loss: 0.13522 (A-MSE: 0.11927) avg lploss: 0.00000
train epoch 1165 avg loss: 0.12258 (A-MSE: 0.11001) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.19401 (A-MSE: 0.16902) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.16604 (A-MSE: 0.14514) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 3 out of 50
train epoch 1166 avg loss: 0.11254 (A-MSE: 0.09937) avg lploss: 0.00000
train epoch 1167 avg loss: 0.10310 (A-MSE: 0.09200) avg lploss: 0.00000
train epoch 1168 avg loss: 0.11559 (A-MSE: 0.10244) avg lploss: 0.00000
train epoch 1169 avg loss: 0.13318 (A-MSE: 0.11781) avg lploss: 0.00000
train epoch 1170 avg loss: 0.12264 (A-MSE: 0.10868) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.21083 (A-MSE: 0.18495) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.17899 (A-MSE: 0.15715) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 4 out of 50
train epoch 1171 avg loss: 0.11702 (A-MSE: 0.10384) avg lploss: 0.00000
train epoch 1172 avg loss: 0.12690 (A-MSE: 0.11264) avg lploss: 0.00000
train epoch 1173 avg loss: 0.11807 (A-MSE: 0.10428) avg lploss: 0.00000
train epoch 1174 avg loss: 0.13893 (A-MSE: 0.12269) avg lploss: 0.00000
train epoch 1175 avg loss: 0.12661 (A-MSE: 0.11243) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.19984 (A-MSE: 0.17519) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.17506 (A-MSE: 0.15388) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 5 out of 50
train epoch 1176 avg loss: 0.11327 (A-MSE: 0.09977) avg lploss: 0.00000
train epoch 1177 avg loss: 0.12288 (A-MSE: 0.10931) avg lploss: 0.00000
train epoch 1178 avg loss: 0.13148 (A-MSE: 0.11636) avg lploss: 0.00000
train epoch 1179 avg loss: 0.12959 (A-MSE: 0.11460) avg lploss: 0.00000
train epoch 1180 avg loss: 0.15529 (A-MSE: 0.13671) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.20653 (A-MSE: 0.18295) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.17961 (A-MSE: 0.16046) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 6 out of 50
train epoch 1181 avg loss: 0.14534 (A-MSE: 0.12901) avg lploss: 0.00000
train epoch 1182 avg loss: 0.12927 (A-MSE: 0.11524) avg lploss: 0.00000
train epoch 1183 avg loss: 0.11829 (A-MSE: 0.10472) avg lploss: 0.00000
train epoch 1184 avg loss: 0.12461 (A-MSE: 0.11002) avg lploss: 0.00000
train epoch 1185 avg loss: 0.15532 (A-MSE: 0.13743) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.23586 (A-MSE: 0.20739) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.21238 (A-MSE: 0.18759) avg lploss: 0.00000
*** Best Val Loss: 0.18360 	 Best Test Loss: 0.15472 	 Best epoch 1150
EarlyStopping counter: 7 out of 50
train epoch 1186 avg loss: 0.13268 (A-MSE: 0.11823) avg lploss: 0.00000
train epoch 1187 avg loss: 0.10911 (A-MSE: 0.09682) avg lploss: 0.00000
train epoch 1188 avg loss: 0.11448 (A-MSE: 0.10150) avg lploss: 0.00000
train epoch 1189 avg loss: 0.11398 (A-MSE: 0.10112) avg lploss: 0.00000
train epoch 1190 avg loss: 0.11709 (A-MSE: 0.10402) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.17183 (A-MSE: 0.15329) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.14195 (A-MSE: 0.12625) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
Validation loss decreased (0.183603 --> 0.171832).  Saving model ...
train epoch 1191 avg loss: 0.10600 (A-MSE: 0.09443) avg lploss: 0.00000
train epoch 1192 avg loss: 0.10869 (A-MSE: 0.09606) avg lploss: 0.00000
train epoch 1193 avg loss: 0.10904 (A-MSE: 0.09650) avg lploss: 0.00000
train epoch 1194 avg loss: 0.10569 (A-MSE: 0.09314) avg lploss: 0.00000
train epoch 1195 avg loss: 0.11825 (A-MSE: 0.10474) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.20054 (A-MSE: 0.17669) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.16404 (A-MSE: 0.14498) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 1 out of 50
train epoch 1196 avg loss: 0.13858 (A-MSE: 0.12279) avg lploss: 0.00000
train epoch 1197 avg loss: 0.11886 (A-MSE: 0.10519) avg lploss: 0.00000
train epoch 1198 avg loss: 0.10805 (A-MSE: 0.09607) avg lploss: 0.00000
train epoch 1199 avg loss: 0.11238 (A-MSE: 0.09923) avg lploss: 0.00000
train epoch 1200 avg loss: 0.10586 (A-MSE: 0.09363) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.19021 (A-MSE: 0.16586) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.16535 (A-MSE: 0.14445) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 2 out of 50
train epoch 1201 avg loss: 0.10313 (A-MSE: 0.09179) avg lploss: 0.00000
train epoch 1202 avg loss: 0.10338 (A-MSE: 0.09167) avg lploss: 0.00000
train epoch 1203 avg loss: 0.11907 (A-MSE: 0.10497) avg lploss: 0.00000
train epoch 1204 avg loss: 0.10335 (A-MSE: 0.09115) avg lploss: 0.00000
train epoch 1205 avg loss: 0.12718 (A-MSE: 0.11235) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.20439 (A-MSE: 0.18062) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.17360 (A-MSE: 0.15400) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 3 out of 50
train epoch 1206 avg loss: 0.10653 (A-MSE: 0.09488) avg lploss: 0.00000
train epoch 1207 avg loss: 0.12279 (A-MSE: 0.10833) avg lploss: 0.00000
train epoch 1208 avg loss: 0.11354 (A-MSE: 0.10048) avg lploss: 0.00000
train epoch 1209 avg loss: 0.10950 (A-MSE: 0.09754) avg lploss: 0.00000
train epoch 1210 avg loss: 0.11532 (A-MSE: 0.10166) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.21797 (A-MSE: 0.18896) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.19384 (A-MSE: 0.16838) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 4 out of 50
train epoch 1211 avg loss: 0.14229 (A-MSE: 0.12612) avg lploss: 0.00000
train epoch 1212 avg loss: 0.13672 (A-MSE: 0.12164) avg lploss: 0.00000
train epoch 1213 avg loss: 0.11750 (A-MSE: 0.10441) avg lploss: 0.00000
train epoch 1214 avg loss: 0.10924 (A-MSE: 0.09634) avg lploss: 0.00000
train epoch 1215 avg loss: 0.11119 (A-MSE: 0.09897) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.23144 (A-MSE: 0.20378) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.19286 (A-MSE: 0.17010) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 5 out of 50
train epoch 1216 avg loss: 0.11560 (A-MSE: 0.10256) avg lploss: 0.00000
train epoch 1217 avg loss: 0.13253 (A-MSE: 0.11578) avg lploss: 0.00000
train epoch 1218 avg loss: 0.11365 (A-MSE: 0.10115) avg lploss: 0.00000
train epoch 1219 avg loss: 0.10151 (A-MSE: 0.09001) avg lploss: 0.00000
train epoch 1220 avg loss: 0.10914 (A-MSE: 0.09628) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.25603 (A-MSE: 0.22287) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.21700 (A-MSE: 0.18960) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 6 out of 50
train epoch 1221 avg loss: 0.11663 (A-MSE: 0.10338) avg lploss: 0.00000
train epoch 1222 avg loss: 0.10552 (A-MSE: 0.09290) avg lploss: 0.00000
train epoch 1223 avg loss: 0.11280 (A-MSE: 0.09985) avg lploss: 0.00000
train epoch 1224 avg loss: 0.11746 (A-MSE: 0.10332) avg lploss: 0.00000
train epoch 1225 avg loss: 0.10916 (A-MSE: 0.09727) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.19267 (A-MSE: 0.16774) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.16278 (A-MSE: 0.14218) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 7 out of 50
train epoch 1226 avg loss: 0.10731 (A-MSE: 0.09508) avg lploss: 0.00000
train epoch 1227 avg loss: 0.10926 (A-MSE: 0.09736) avg lploss: 0.00000
train epoch 1228 avg loss: 0.11013 (A-MSE: 0.09766) avg lploss: 0.00000
train epoch 1229 avg loss: 0.11012 (A-MSE: 0.09747) avg lploss: 0.00000
train epoch 1230 avg loss: 0.11691 (A-MSE: 0.10431) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.26213 (A-MSE: 0.22748) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.23460 (A-MSE: 0.20370) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 8 out of 50
train epoch 1231 avg loss: 0.12853 (A-MSE: 0.11467) avg lploss: 0.00000
train epoch 1232 avg loss: 0.13406 (A-MSE: 0.11908) avg lploss: 0.00000
train epoch 1233 avg loss: 0.11183 (A-MSE: 0.09928) avg lploss: 0.00000
train epoch 1234 avg loss: 0.10295 (A-MSE: 0.09068) avg lploss: 0.00000
train epoch 1235 avg loss: 0.10358 (A-MSE: 0.09261) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.18707 (A-MSE: 0.16627) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.15408 (A-MSE: 0.13754) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 9 out of 50
train epoch 1236 avg loss: 0.12096 (A-MSE: 0.10691) avg lploss: 0.00000
train epoch 1237 avg loss: 0.10448 (A-MSE: 0.09228) avg lploss: 0.00000
train epoch 1238 avg loss: 0.10513 (A-MSE: 0.09266) avg lploss: 0.00000
train epoch 1239 avg loss: 0.11385 (A-MSE: 0.10063) avg lploss: 0.00000
train epoch 1240 avg loss: 0.11266 (A-MSE: 0.09991) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.21040 (A-MSE: 0.18361) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.18034 (A-MSE: 0.15824) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 10 out of 50
train epoch 1241 avg loss: 0.10367 (A-MSE: 0.09113) avg lploss: 0.00000
train epoch 1242 avg loss: 0.11337 (A-MSE: 0.10070) avg lploss: 0.00000
train epoch 1243 avg loss: 0.13090 (A-MSE: 0.11712) avg lploss: 0.00000
train epoch 1244 avg loss: 0.10344 (A-MSE: 0.09175) avg lploss: 0.00000
train epoch 1245 avg loss: 0.11534 (A-MSE: 0.10203) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.23080 (A-MSE: 0.20410) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.20740 (A-MSE: 0.18327) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 11 out of 50
train epoch 1246 avg loss: 0.12590 (A-MSE: 0.11028) avg lploss: 0.00000
train epoch 1247 avg loss: 0.10854 (A-MSE: 0.09650) avg lploss: 0.00000
train epoch 1248 avg loss: 0.09554 (A-MSE: 0.08514) avg lploss: 0.00000
train epoch 1249 avg loss: 0.10318 (A-MSE: 0.09113) avg lploss: 0.00000
train epoch 1250 avg loss: 0.09540 (A-MSE: 0.08489) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.25274 (A-MSE: 0.21763) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.22226 (A-MSE: 0.19097) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 12 out of 50
train epoch 1251 avg loss: 0.11107 (A-MSE: 0.09814) avg lploss: 0.00000
train epoch 1252 avg loss: 0.09966 (A-MSE: 0.08850) avg lploss: 0.00000
train epoch 1253 avg loss: 0.11723 (A-MSE: 0.10359) avg lploss: 0.00000
train epoch 1254 avg loss: 0.12008 (A-MSE: 0.10585) avg lploss: 0.00000
train epoch 1255 avg loss: 0.12051 (A-MSE: 0.10656) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.17300 (A-MSE: 0.15243) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.13736 (A-MSE: 0.12191) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 13 out of 50
train epoch 1256 avg loss: 0.11594 (A-MSE: 0.10254) avg lploss: 0.00000
train epoch 1257 avg loss: 0.10937 (A-MSE: 0.09710) avg lploss: 0.00000
train epoch 1258 avg loss: 0.12114 (A-MSE: 0.10693) avg lploss: 0.00000
train epoch 1259 avg loss: 0.12029 (A-MSE: 0.10705) avg lploss: 0.00000
train epoch 1260 avg loss: 0.10522 (A-MSE: 0.09314) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.22660 (A-MSE: 0.20165) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.19289 (A-MSE: 0.17167) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 14 out of 50
train epoch 1261 avg loss: 0.10710 (A-MSE: 0.09523) avg lploss: 0.00000
train epoch 1262 avg loss: 0.11623 (A-MSE: 0.10337) avg lploss: 0.00000
train epoch 1263 avg loss: 0.11473 (A-MSE: 0.10103) avg lploss: 0.00000
train epoch 1264 avg loss: 0.11752 (A-MSE: 0.10415) avg lploss: 0.00000
train epoch 1265 avg loss: 0.11445 (A-MSE: 0.10140) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.20892 (A-MSE: 0.18262) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.17788 (A-MSE: 0.15550) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 15 out of 50
train epoch 1266 avg loss: 0.10294 (A-MSE: 0.09086) avg lploss: 0.00000
train epoch 1267 avg loss: 0.10596 (A-MSE: 0.09369) avg lploss: 0.00000
train epoch 1268 avg loss: 0.10870 (A-MSE: 0.09658) avg lploss: 0.00000
train epoch 1269 avg loss: 0.11110 (A-MSE: 0.09804) avg lploss: 0.00000
train epoch 1270 avg loss: 0.11277 (A-MSE: 0.09990) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.19214 (A-MSE: 0.17207) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.16083 (A-MSE: 0.14441) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 16 out of 50
train epoch 1271 avg loss: 0.10844 (A-MSE: 0.09614) avg lploss: 0.00000
train epoch 1272 avg loss: 0.11286 (A-MSE: 0.10018) avg lploss: 0.00000
train epoch 1273 avg loss: 0.10611 (A-MSE: 0.09360) avg lploss: 0.00000
train epoch 1274 avg loss: 0.12033 (A-MSE: 0.10688) avg lploss: 0.00000
train epoch 1275 avg loss: 0.11300 (A-MSE: 0.10100) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.18902 (A-MSE: 0.16523) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.16065 (A-MSE: 0.14077) avg lploss: 0.00000
*** Best Val Loss: 0.17183 	 Best Test Loss: 0.14195 	 Best epoch 1190
EarlyStopping counter: 17 out of 50
train epoch 1276 avg loss: 0.10690 (A-MSE: 0.09521) avg lploss: 0.00000
train epoch 1277 avg loss: 0.11050 (A-MSE: 0.09788) avg lploss: 0.00000
train epoch 1278 avg loss: 0.10770 (A-MSE: 0.09535) avg lploss: 0.00000
train epoch 1279 avg loss: 0.10005 (A-MSE: 0.08842) avg lploss: 0.00000
train epoch 1280 avg loss: 0.10210 (A-MSE: 0.09004) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.16278 (A-MSE: 0.14139) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.13761 (A-MSE: 0.11943) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
Validation loss decreased (0.171832 --> 0.162781).  Saving model ...
train epoch 1281 avg loss: 0.09853 (A-MSE: 0.08694) avg lploss: 0.00000
train epoch 1282 avg loss: 0.11042 (A-MSE: 0.09784) avg lploss: 0.00000
train epoch 1283 avg loss: 0.13397 (A-MSE: 0.11856) avg lploss: 0.00000
train epoch 1284 avg loss: 0.11885 (A-MSE: 0.10480) avg lploss: 0.00000
train epoch 1285 avg loss: 0.11183 (A-MSE: 0.09891) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.20681 (A-MSE: 0.18218) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.18007 (A-MSE: 0.15921) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 1 out of 50
train epoch 1286 avg loss: 0.10302 (A-MSE: 0.09184) avg lploss: 0.00000
train epoch 1287 avg loss: 0.10825 (A-MSE: 0.09587) avg lploss: 0.00000
train epoch 1288 avg loss: 0.11042 (A-MSE: 0.09740) avg lploss: 0.00000
train epoch 1289 avg loss: 0.11400 (A-MSE: 0.10064) avg lploss: 0.00000
train epoch 1290 avg loss: 0.11301 (A-MSE: 0.09993) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.18985 (A-MSE: 0.16488) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.15851 (A-MSE: 0.13725) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 2 out of 50
train epoch 1291 avg loss: 0.10007 (A-MSE: 0.08869) avg lploss: 0.00000
train epoch 1292 avg loss: 0.09767 (A-MSE: 0.08618) avg lploss: 0.00000
train epoch 1293 avg loss: 0.11174 (A-MSE: 0.09901) avg lploss: 0.00000
train epoch 1294 avg loss: 0.10648 (A-MSE: 0.09363) avg lploss: 0.00000
train epoch 1295 avg loss: 0.10515 (A-MSE: 0.09370) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.24811 (A-MSE: 0.21372) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.22090 (A-MSE: 0.18983) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 3 out of 50
train epoch 1296 avg loss: 0.10119 (A-MSE: 0.08966) avg lploss: 0.00000
train epoch 1297 avg loss: 0.10256 (A-MSE: 0.09056) avg lploss: 0.00000
train epoch 1298 avg loss: 0.09530 (A-MSE: 0.08438) avg lploss: 0.00000
train epoch 1299 avg loss: 0.10209 (A-MSE: 0.09013) avg lploss: 0.00000
train epoch 1300 avg loss: 0.10936 (A-MSE: 0.09681) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.18190 (A-MSE: 0.16039) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.15670 (A-MSE: 0.13868) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 4 out of 50
train epoch 1301 avg loss: 0.12497 (A-MSE: 0.11147) avg lploss: 0.00000
train epoch 1302 avg loss: 0.11826 (A-MSE: 0.10505) avg lploss: 0.00000
train epoch 1303 avg loss: 0.11636 (A-MSE: 0.10268) avg lploss: 0.00000
train epoch 1304 avg loss: 0.11746 (A-MSE: 0.10466) avg lploss: 0.00000
train epoch 1305 avg loss: 0.12011 (A-MSE: 0.10670) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.19614 (A-MSE: 0.17256) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.16857 (A-MSE: 0.14850) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 5 out of 50
train epoch 1306 avg loss: 0.09834 (A-MSE: 0.08687) avg lploss: 0.00000
train epoch 1307 avg loss: 0.09215 (A-MSE: 0.08120) avg lploss: 0.00000
train epoch 1308 avg loss: 0.09557 (A-MSE: 0.08441) avg lploss: 0.00000
train epoch 1309 avg loss: 0.09822 (A-MSE: 0.08720) avg lploss: 0.00000
train epoch 1310 avg loss: 0.09282 (A-MSE: 0.08251) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.17564 (A-MSE: 0.15382) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.14119 (A-MSE: 0.12358) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 6 out of 50
train epoch 1311 avg loss: 0.08649 (A-MSE: 0.07641) avg lploss: 0.00000
train epoch 1312 avg loss: 0.08760 (A-MSE: 0.07784) avg lploss: 0.00000
train epoch 1313 avg loss: 0.08798 (A-MSE: 0.07792) avg lploss: 0.00000
train epoch 1314 avg loss: 0.09598 (A-MSE: 0.08551) avg lploss: 0.00000
train epoch 1315 avg loss: 0.10120 (A-MSE: 0.08993) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.19449 (A-MSE: 0.17133) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.16819 (A-MSE: 0.14881) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 7 out of 50
train epoch 1316 avg loss: 0.08948 (A-MSE: 0.07966) avg lploss: 0.00000
train epoch 1317 avg loss: 0.08682 (A-MSE: 0.07692) avg lploss: 0.00000
train epoch 1318 avg loss: 0.08973 (A-MSE: 0.07992) avg lploss: 0.00000
train epoch 1319 avg loss: 0.09868 (A-MSE: 0.08727) avg lploss: 0.00000
train epoch 1320 avg loss: 0.09805 (A-MSE: 0.08665) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.16960 (A-MSE: 0.14880) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.13535 (A-MSE: 0.11863) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 8 out of 50
train epoch 1321 avg loss: 0.09592 (A-MSE: 0.08551) avg lploss: 0.00000
train epoch 1322 avg loss: 0.12291 (A-MSE: 0.10854) avg lploss: 0.00000
train epoch 1323 avg loss: 0.09223 (A-MSE: 0.08178) avg lploss: 0.00000
train epoch 1324 avg loss: 0.09805 (A-MSE: 0.08691) avg lploss: 0.00000
train epoch 1325 avg loss: 0.10195 (A-MSE: 0.09056) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.19898 (A-MSE: 0.17265) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.16884 (A-MSE: 0.14667) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 9 out of 50
train epoch 1326 avg loss: 0.09526 (A-MSE: 0.08448) avg lploss: 0.00000
train epoch 1327 avg loss: 0.10089 (A-MSE: 0.08964) avg lploss: 0.00000
train epoch 1328 avg loss: 0.12264 (A-MSE: 0.10854) avg lploss: 0.00000
train epoch 1329 avg loss: 0.11102 (A-MSE: 0.09885) avg lploss: 0.00000
train epoch 1330 avg loss: 0.10576 (A-MSE: 0.09424) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.21438 (A-MSE: 0.18703) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.17861 (A-MSE: 0.15603) avg lploss: 0.00000
*** Best Val Loss: 0.16278 	 Best Test Loss: 0.13761 	 Best epoch 1280
EarlyStopping counter: 10 out of 50
train epoch 1331 avg loss: 0.10654 (A-MSE: 0.09370) avg lploss: 0.00000
train epoch 1332 avg loss: 0.09253 (A-MSE: 0.08239) avg lploss: 0.00000
train epoch 1333 avg loss: 0.09657 (A-MSE: 0.08577) avg lploss: 0.00000
train epoch 1334 avg loss: 0.09372 (A-MSE: 0.08309) avg lploss: 0.00000
train epoch 1335 avg loss: 0.09396 (A-MSE: 0.08395) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.16191 (A-MSE: 0.14279) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.12785 (A-MSE: 0.11286) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
Validation loss decreased (0.162781 --> 0.161913).  Saving model ...
train epoch 1336 avg loss: 0.09175 (A-MSE: 0.08130) avg lploss: 0.00000
train epoch 1337 avg loss: 0.08914 (A-MSE: 0.07849) avg lploss: 0.00000
train epoch 1338 avg loss: 0.10447 (A-MSE: 0.09311) avg lploss: 0.00000
train epoch 1339 avg loss: 0.10201 (A-MSE: 0.09110) avg lploss: 0.00000
train epoch 1340 avg loss: 0.09547 (A-MSE: 0.08448) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.17449 (A-MSE: 0.15276) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.14514 (A-MSE: 0.12686) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 1 out of 50
train epoch 1341 avg loss: 0.09255 (A-MSE: 0.08161) avg lploss: 0.00000
train epoch 1342 avg loss: 0.08917 (A-MSE: 0.07900) avg lploss: 0.00000
train epoch 1343 avg loss: 0.09036 (A-MSE: 0.07968) avg lploss: 0.00000
train epoch 1344 avg loss: 0.09031 (A-MSE: 0.07965) avg lploss: 0.00000
train epoch 1345 avg loss: 0.08989 (A-MSE: 0.07966) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.18796 (A-MSE: 0.16525) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.15793 (A-MSE: 0.13859) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 2 out of 50
train epoch 1346 avg loss: 0.08083 (A-MSE: 0.07185) avg lploss: 0.00000
train epoch 1347 avg loss: 0.08421 (A-MSE: 0.07484) avg lploss: 0.00000
train epoch 1348 avg loss: 0.10390 (A-MSE: 0.09132) avg lploss: 0.00000
train epoch 1349 avg loss: 0.11131 (A-MSE: 0.09931) avg lploss: 0.00000
train epoch 1350 avg loss: 0.08861 (A-MSE: 0.07838) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.16889 (A-MSE: 0.14876) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.13416 (A-MSE: 0.11841) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 3 out of 50
train epoch 1351 avg loss: 0.08163 (A-MSE: 0.07269) avg lploss: 0.00000
train epoch 1352 avg loss: 0.08949 (A-MSE: 0.07913) avg lploss: 0.00000
train epoch 1353 avg loss: 0.08290 (A-MSE: 0.07341) avg lploss: 0.00000
train epoch 1354 avg loss: 0.09670 (A-MSE: 0.08565) avg lploss: 0.00000
train epoch 1355 avg loss: 0.10085 (A-MSE: 0.08942) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.16375 (A-MSE: 0.14491) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.13393 (A-MSE: 0.11881) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 4 out of 50
train epoch 1356 avg loss: 0.08603 (A-MSE: 0.07614) avg lploss: 0.00000
train epoch 1357 avg loss: 0.08880 (A-MSE: 0.07885) avg lploss: 0.00000
train epoch 1358 avg loss: 0.08643 (A-MSE: 0.07705) avg lploss: 0.00000
train epoch 1359 avg loss: 0.09214 (A-MSE: 0.08179) avg lploss: 0.00000
train epoch 1360 avg loss: 0.10177 (A-MSE: 0.09035) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.17443 (A-MSE: 0.15175) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.14266 (A-MSE: 0.12353) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 5 out of 50
train epoch 1361 avg loss: 0.09641 (A-MSE: 0.08498) avg lploss: 0.00000
train epoch 1362 avg loss: 0.10110 (A-MSE: 0.08956) avg lploss: 0.00000
train epoch 1363 avg loss: 0.09620 (A-MSE: 0.08516) avg lploss: 0.00000
train epoch 1364 avg loss: 0.09131 (A-MSE: 0.08076) avg lploss: 0.00000
train epoch 1365 avg loss: 0.08960 (A-MSE: 0.07975) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.17454 (A-MSE: 0.15127) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.13720 (A-MSE: 0.11869) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 6 out of 50
train epoch 1366 avg loss: 0.08045 (A-MSE: 0.07153) avg lploss: 0.00000
train epoch 1367 avg loss: 0.07667 (A-MSE: 0.06807) avg lploss: 0.00000
train epoch 1368 avg loss: 0.08542 (A-MSE: 0.07571) avg lploss: 0.00000
train epoch 1369 avg loss: 0.09566 (A-MSE: 0.08426) avg lploss: 0.00000
train epoch 1370 avg loss: 0.10341 (A-MSE: 0.09154) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.18232 (A-MSE: 0.16047) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.14579 (A-MSE: 0.12826) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 7 out of 50
train epoch 1371 avg loss: 0.09749 (A-MSE: 0.08670) avg lploss: 0.00000
train epoch 1372 avg loss: 0.08989 (A-MSE: 0.07960) avg lploss: 0.00000
train epoch 1373 avg loss: 0.08343 (A-MSE: 0.07432) avg lploss: 0.00000
train epoch 1374 avg loss: 0.07970 (A-MSE: 0.07071) avg lploss: 0.00000
train epoch 1375 avg loss: 0.07741 (A-MSE: 0.06887) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.16436 (A-MSE: 0.14486) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.13074 (A-MSE: 0.11506) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 8 out of 50
train epoch 1376 avg loss: 0.08202 (A-MSE: 0.07270) avg lploss: 0.00000
train epoch 1377 avg loss: 0.08477 (A-MSE: 0.07491) avg lploss: 0.00000
train epoch 1378 avg loss: 0.10197 (A-MSE: 0.08930) avg lploss: 0.00000
train epoch 1379 avg loss: 0.09012 (A-MSE: 0.07984) avg lploss: 0.00000
train epoch 1380 avg loss: 0.09064 (A-MSE: 0.08045) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.18833 (A-MSE: 0.16384) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.14217 (A-MSE: 0.12331) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 9 out of 50
train epoch 1381 avg loss: 0.08022 (A-MSE: 0.07066) avg lploss: 0.00000
train epoch 1382 avg loss: 0.08048 (A-MSE: 0.07090) avg lploss: 0.00000
train epoch 1383 avg loss: 0.08677 (A-MSE: 0.07688) avg lploss: 0.00000
train epoch 1384 avg loss: 0.07796 (A-MSE: 0.06880) avg lploss: 0.00000
train epoch 1385 avg loss: 0.07257 (A-MSE: 0.06428) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.17311 (A-MSE: 0.15318) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.13296 (A-MSE: 0.11827) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 10 out of 50
train epoch 1386 avg loss: 0.07595 (A-MSE: 0.06722) avg lploss: 0.00000
train epoch 1387 avg loss: 0.07390 (A-MSE: 0.06549) avg lploss: 0.00000
train epoch 1388 avg loss: 0.07815 (A-MSE: 0.06930) avg lploss: 0.00000
train epoch 1389 avg loss: 0.08446 (A-MSE: 0.07524) avg lploss: 0.00000
train epoch 1390 avg loss: 0.08440 (A-MSE: 0.07441) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.16778 (A-MSE: 0.14959) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.13326 (A-MSE: 0.11937) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 11 out of 50
train epoch 1391 avg loss: 0.07528 (A-MSE: 0.06674) avg lploss: 0.00000
train epoch 1392 avg loss: 0.07393 (A-MSE: 0.06556) avg lploss: 0.00000
train epoch 1393 avg loss: 0.07310 (A-MSE: 0.06497) avg lploss: 0.00000
train epoch 1394 avg loss: 0.07937 (A-MSE: 0.06999) avg lploss: 0.00000
train epoch 1395 avg loss: 0.10427 (A-MSE: 0.09251) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.27367 (A-MSE: 0.24274) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.24117 (A-MSE: 0.21471) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 12 out of 50
train epoch 1396 avg loss: 0.10166 (A-MSE: 0.08961) avg lploss: 0.00000
train epoch 1397 avg loss: 0.07831 (A-MSE: 0.06869) avg lploss: 0.00000
train epoch 1398 avg loss: 0.08288 (A-MSE: 0.07345) avg lploss: 0.00000
train epoch 1399 avg loss: 0.07817 (A-MSE: 0.06927) avg lploss: 0.00000
train epoch 1400 avg loss: 0.08787 (A-MSE: 0.07720) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.17846 (A-MSE: 0.15695) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.13838 (A-MSE: 0.12206) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 13 out of 50
train epoch 1401 avg loss: 0.08440 (A-MSE: 0.07469) avg lploss: 0.00000
train epoch 1402 avg loss: 0.09387 (A-MSE: 0.08343) avg lploss: 0.00000
train epoch 1403 avg loss: 0.08944 (A-MSE: 0.07980) avg lploss: 0.00000
train epoch 1404 avg loss: 0.07509 (A-MSE: 0.06680) avg lploss: 0.00000
train epoch 1405 avg loss: 0.08514 (A-MSE: 0.07489) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.16343 (A-MSE: 0.14298) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.12397 (A-MSE: 0.10889) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 14 out of 50
train epoch 1406 avg loss: 0.08432 (A-MSE: 0.07462) avg lploss: 0.00000
train epoch 1407 avg loss: 0.08713 (A-MSE: 0.07698) avg lploss: 0.00000
train epoch 1408 avg loss: 0.08481 (A-MSE: 0.07512) avg lploss: 0.00000
train epoch 1409 avg loss: 0.07985 (A-MSE: 0.07065) avg lploss: 0.00000
train epoch 1410 avg loss: 0.08597 (A-MSE: 0.07685) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.17038 (A-MSE: 0.14774) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.13304 (A-MSE: 0.11546) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 15 out of 50
train epoch 1411 avg loss: 0.07688 (A-MSE: 0.06845) avg lploss: 0.00000
train epoch 1412 avg loss: 0.06981 (A-MSE: 0.06214) avg lploss: 0.00000
train epoch 1413 avg loss: 0.07899 (A-MSE: 0.07005) avg lploss: 0.00000
train epoch 1414 avg loss: 0.07039 (A-MSE: 0.06235) avg lploss: 0.00000
train epoch 1415 avg loss: 0.07299 (A-MSE: 0.06457) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.16803 (A-MSE: 0.14499) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.13533 (A-MSE: 0.11612) avg lploss: 0.00000
*** Best Val Loss: 0.16191 	 Best Test Loss: 0.12785 	 Best epoch 1335
EarlyStopping counter: 16 out of 50
train epoch 1416 avg loss: 0.08374 (A-MSE: 0.07376) avg lploss: 0.00000
train epoch 1417 avg loss: 0.08193 (A-MSE: 0.07253) avg lploss: 0.00000
train epoch 1418 avg loss: 0.07642 (A-MSE: 0.06763) avg lploss: 0.00000
train epoch 1419 avg loss: 0.07689 (A-MSE: 0.06796) avg lploss: 0.00000
train epoch 1420 avg loss: 0.07200 (A-MSE: 0.06409) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.14535 (A-MSE: 0.12726) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.11289 (A-MSE: 0.09880) avg lploss: 0.00000
*** Best Val Loss: 0.14535 	 Best Test Loss: 0.11289 	 Best epoch 1420
Validation loss decreased (0.161913 --> 0.145353).  Saving model ...
train epoch 1421 avg loss: 0.07439 (A-MSE: 0.06600) avg lploss: 0.00000
train epoch 1422 avg loss: 0.07540 (A-MSE: 0.06737) avg lploss: 0.00000
train epoch 1423 avg loss: 0.08601 (A-MSE: 0.07565) avg lploss: 0.00000
train epoch 1424 avg loss: 0.08205 (A-MSE: 0.07292) avg lploss: 0.00000
train epoch 1425 avg loss: 0.07771 (A-MSE: 0.06917) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.14196 (A-MSE: 0.12561) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.10969 (A-MSE: 0.09710) avg lploss: 0.00000
*** Best Val Loss: 0.14196 	 Best Test Loss: 0.10969 	 Best epoch 1425
Validation loss decreased (0.145353 --> 0.141959).  Saving model ...
train epoch 1426 avg loss: 0.09060 (A-MSE: 0.07967) avg lploss: 0.00000
train epoch 1427 avg loss: 0.08209 (A-MSE: 0.07352) avg lploss: 0.00000
train epoch 1428 avg loss: 0.07220 (A-MSE: 0.06438) avg lploss: 0.00000
train epoch 1429 avg loss: 0.06760 (A-MSE: 0.05991) avg lploss: 0.00000
train epoch 1430 avg loss: 0.06670 (A-MSE: 0.05898) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.14442 (A-MSE: 0.12668) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.11105 (A-MSE: 0.09744) avg lploss: 0.00000
*** Best Val Loss: 0.14196 	 Best Test Loss: 0.10969 	 Best epoch 1425
EarlyStopping counter: 1 out of 50
train epoch 1431 avg loss: 0.07731 (A-MSE: 0.06825) avg lploss: 0.00000
train epoch 1432 avg loss: 0.08477 (A-MSE: 0.07529) avg lploss: 0.00000
train epoch 1433 avg loss: 0.08682 (A-MSE: 0.07603) avg lploss: 0.00000
train epoch 1434 avg loss: 0.07735 (A-MSE: 0.06885) avg lploss: 0.00000
train epoch 1435 avg loss: 0.06888 (A-MSE: 0.06099) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.14363 (A-MSE: 0.12585) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.11087 (A-MSE: 0.09641) avg lploss: 0.00000
*** Best Val Loss: 0.14196 	 Best Test Loss: 0.10969 	 Best epoch 1425
EarlyStopping counter: 2 out of 50
train epoch 1436 avg loss: 0.06964 (A-MSE: 0.06194) avg lploss: 0.00000
train epoch 1437 avg loss: 0.07094 (A-MSE: 0.06249) avg lploss: 0.00000
train epoch 1438 avg loss: 0.07272 (A-MSE: 0.06436) avg lploss: 0.00000
train epoch 1439 avg loss: 0.06778 (A-MSE: 0.06003) avg lploss: 0.00000
train epoch 1440 avg loss: 0.07669 (A-MSE: 0.06808) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.17853 (A-MSE: 0.15749) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.13991 (A-MSE: 0.12315) avg lploss: 0.00000
*** Best Val Loss: 0.14196 	 Best Test Loss: 0.10969 	 Best epoch 1425
EarlyStopping counter: 3 out of 50
train epoch 1441 avg loss: 0.08135 (A-MSE: 0.07168) avg lploss: 0.00000
train epoch 1442 avg loss: 0.07811 (A-MSE: 0.06925) avg lploss: 0.00000
train epoch 1443 avg loss: 0.08061 (A-MSE: 0.07068) avg lploss: 0.00000
train epoch 1444 avg loss: 0.07762 (A-MSE: 0.06894) avg lploss: 0.00000
train epoch 1445 avg loss: 0.07420 (A-MSE: 0.06601) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.16467 (A-MSE: 0.14255) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.13205 (A-MSE: 0.11409) avg lploss: 0.00000
*** Best Val Loss: 0.14196 	 Best Test Loss: 0.10969 	 Best epoch 1425
EarlyStopping counter: 4 out of 50
train epoch 1446 avg loss: 0.07973 (A-MSE: 0.07067) avg lploss: 0.00000
train epoch 1447 avg loss: 0.06862 (A-MSE: 0.06122) avg lploss: 0.00000
train epoch 1448 avg loss: 0.06612 (A-MSE: 0.05858) avg lploss: 0.00000
train epoch 1449 avg loss: 0.06302 (A-MSE: 0.05573) avg lploss: 0.00000
train epoch 1450 avg loss: 0.07476 (A-MSE: 0.06612) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.14334 (A-MSE: 0.12659) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.11434 (A-MSE: 0.10099) avg lploss: 0.00000
*** Best Val Loss: 0.14196 	 Best Test Loss: 0.10969 	 Best epoch 1425
EarlyStopping counter: 5 out of 50
train epoch 1451 avg loss: 0.06670 (A-MSE: 0.05936) avg lploss: 0.00000
train epoch 1452 avg loss: 0.06086 (A-MSE: 0.05416) avg lploss: 0.00000
train epoch 1453 avg loss: 0.07914 (A-MSE: 0.06945) avg lploss: 0.00000
train epoch 1454 avg loss: 0.07323 (A-MSE: 0.06522) avg lploss: 0.00000
train epoch 1455 avg loss: 0.06560 (A-MSE: 0.05830) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.14022 (A-MSE: 0.12351) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.10544 (A-MSE: 0.09309) avg lploss: 0.00000
*** Best Val Loss: 0.14022 	 Best Test Loss: 0.10544 	 Best epoch 1455
Validation loss decreased (0.141959 --> 0.140224).  Saving model ...
train epoch 1456 avg loss: 0.07008 (A-MSE: 0.06216) avg lploss: 0.00000
train epoch 1457 avg loss: 0.07307 (A-MSE: 0.06483) avg lploss: 0.00000
train epoch 1458 avg loss: 0.07055 (A-MSE: 0.06328) avg lploss: 0.00000
train epoch 1459 avg loss: 0.07257 (A-MSE: 0.06450) avg lploss: 0.00000
train epoch 1460 avg loss: 0.06195 (A-MSE: 0.05503) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.14422 (A-MSE: 0.12554) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.11017 (A-MSE: 0.09516) avg lploss: 0.00000
*** Best Val Loss: 0.14022 	 Best Test Loss: 0.10544 	 Best epoch 1455
EarlyStopping counter: 1 out of 50
train epoch 1461 avg loss: 0.06112 (A-MSE: 0.05429) avg lploss: 0.00000
train epoch 1462 avg loss: 0.06584 (A-MSE: 0.05842) avg lploss: 0.00000
train epoch 1463 avg loss: 0.06532 (A-MSE: 0.05812) avg lploss: 0.00000
train epoch 1464 avg loss: 0.06475 (A-MSE: 0.05739) avg lploss: 0.00000
train epoch 1465 avg loss: 0.06520 (A-MSE: 0.05753) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.15635 (A-MSE: 0.13795) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.12314 (A-MSE: 0.10777) avg lploss: 0.00000
*** Best Val Loss: 0.14022 	 Best Test Loss: 0.10544 	 Best epoch 1455
EarlyStopping counter: 2 out of 50
train epoch 1466 avg loss: 0.06073 (A-MSE: 0.05378) avg lploss: 0.00000
train epoch 1467 avg loss: 0.06279 (A-MSE: 0.05563) avg lploss: 0.00000
train epoch 1468 avg loss: 0.06871 (A-MSE: 0.06061) avg lploss: 0.00000
train epoch 1469 avg loss: 0.06782 (A-MSE: 0.06016) avg lploss: 0.00000
train epoch 1470 avg loss: 0.06011 (A-MSE: 0.05327) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.15422 (A-MSE: 0.13581) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.12147 (A-MSE: 0.10645) avg lploss: 0.00000
*** Best Val Loss: 0.14022 	 Best Test Loss: 0.10544 	 Best epoch 1455
EarlyStopping counter: 3 out of 50
train epoch 1471 avg loss: 0.06495 (A-MSE: 0.05715) avg lploss: 0.00000
train epoch 1472 avg loss: 0.06385 (A-MSE: 0.05678) avg lploss: 0.00000
train epoch 1473 avg loss: 0.07466 (A-MSE: 0.06570) avg lploss: 0.00000
train epoch 1474 avg loss: 0.06815 (A-MSE: 0.06062) avg lploss: 0.00000
train epoch 1475 avg loss: 0.07450 (A-MSE: 0.06558) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.13605 (A-MSE: 0.12027) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.10417 (A-MSE: 0.09199) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
Validation loss decreased (0.140224 --> 0.136054).  Saving model ...
train epoch 1476 avg loss: 0.06660 (A-MSE: 0.05921) avg lploss: 0.00000
train epoch 1477 avg loss: 0.06211 (A-MSE: 0.05522) avg lploss: 0.00000
train epoch 1478 avg loss: 0.06324 (A-MSE: 0.05628) avg lploss: 0.00000
train epoch 1479 avg loss: 0.06272 (A-MSE: 0.05581) avg lploss: 0.00000
train epoch 1480 avg loss: 0.06296 (A-MSE: 0.05624) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.15247 (A-MSE: 0.13282) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.12118 (A-MSE: 0.10513) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 1 out of 50
train epoch 1481 avg loss: 0.07140 (A-MSE: 0.06355) avg lploss: 0.00000
train epoch 1482 avg loss: 0.07319 (A-MSE: 0.06449) avg lploss: 0.00000
train epoch 1483 avg loss: 0.06525 (A-MSE: 0.05791) avg lploss: 0.00000
train epoch 1484 avg loss: 0.06291 (A-MSE: 0.05536) avg lploss: 0.00000
train epoch 1485 avg loss: 0.05817 (A-MSE: 0.05142) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.14746 (A-MSE: 0.13088) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.10984 (A-MSE: 0.09702) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 2 out of 50
train epoch 1486 avg loss: 0.06474 (A-MSE: 0.05677) avg lploss: 0.00000
train epoch 1487 avg loss: 0.07706 (A-MSE: 0.06875) avg lploss: 0.00000
train epoch 1488 avg loss: 0.06363 (A-MSE: 0.05646) avg lploss: 0.00000
train epoch 1489 avg loss: 0.06817 (A-MSE: 0.06063) avg lploss: 0.00000
train epoch 1490 avg loss: 0.06555 (A-MSE: 0.05840) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.15074 (A-MSE: 0.13279) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.11526 (A-MSE: 0.10067) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 3 out of 50
train epoch 1491 avg loss: 0.07097 (A-MSE: 0.06272) avg lploss: 0.00000
train epoch 1492 avg loss: 0.06850 (A-MSE: 0.06060) avg lploss: 0.00000
train epoch 1493 avg loss: 0.06596 (A-MSE: 0.05823) avg lploss: 0.00000
train epoch 1494 avg loss: 0.07330 (A-MSE: 0.06455) avg lploss: 0.00000
train epoch 1495 avg loss: 0.08382 (A-MSE: 0.07336) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.17213 (A-MSE: 0.14984) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.14293 (A-MSE: 0.12306) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 4 out of 50
train epoch 1496 avg loss: 0.14000 (A-MSE: 0.12169) avg lploss: 0.00000
train epoch 1497 avg loss: 23.73586 (A-MSE: 19.32315) avg lploss: 0.00000
train epoch 1498 avg loss: 5.21643 (A-MSE: 4.52324) avg lploss: 0.00000
train epoch 1499 avg loss: 1.60544 (A-MSE: 1.34343) avg lploss: 0.00000
train epoch 1500 avg loss: 0.95088 (A-MSE: 0.80122) avg lploss: 0.00000
==> val epoch 1500 avg loss: 1.02714 (A-MSE: 0.83446) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.94918 (A-MSE: 0.77024) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 5 out of 50
train epoch 1501 avg loss: 0.75911 (A-MSE: 0.63968) avg lploss: 0.00000
train epoch 1502 avg loss: 0.66934 (A-MSE: 0.56537) avg lploss: 0.00000
train epoch 1503 avg loss: 0.62919 (A-MSE: 0.53232) avg lploss: 0.00000
train epoch 1504 avg loss: 0.54723 (A-MSE: 0.46277) avg lploss: 0.00000
train epoch 1505 avg loss: 0.49233 (A-MSE: 0.41614) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.63198 (A-MSE: 0.52451) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.58254 (A-MSE: 0.48574) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 6 out of 50
train epoch 1506 avg loss: 0.45139 (A-MSE: 0.38648) avg lploss: 0.00000
train epoch 1507 avg loss: 0.42311 (A-MSE: 0.36248) avg lploss: 0.00000
train epoch 1508 avg loss: 0.38759 (A-MSE: 0.32997) avg lploss: 0.00000
train epoch 1509 avg loss: 0.36830 (A-MSE: 0.31674) avg lploss: 0.00000
train epoch 1510 avg loss: 0.35606 (A-MSE: 0.30344) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.47264 (A-MSE: 0.39595) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.42337 (A-MSE: 0.35502) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 7 out of 50
train epoch 1511 avg loss: 0.33643 (A-MSE: 0.29042) avg lploss: 0.00000
train epoch 1512 avg loss: 0.31648 (A-MSE: 0.26953) avg lploss: 0.00000
train epoch 1513 avg loss: 0.35711 (A-MSE: 0.30903) avg lploss: 0.00000
train epoch 1514 avg loss: 0.31257 (A-MSE: 0.26786) avg lploss: 0.00000
train epoch 1515 avg loss: 0.28459 (A-MSE: 0.24388) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.41121 (A-MSE: 0.34514) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.37170 (A-MSE: 0.31310) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 8 out of 50
train epoch 1516 avg loss: 0.28635 (A-MSE: 0.24678) avg lploss: 0.00000
train epoch 1517 avg loss: 0.27183 (A-MSE: 0.23521) avg lploss: 0.00000
train epoch 1518 avg loss: 0.27421 (A-MSE: 0.23626) avg lploss: 0.00000
train epoch 1519 avg loss: 0.27256 (A-MSE: 0.23540) avg lploss: 0.00000
train epoch 1520 avg loss: 0.27155 (A-MSE: 0.23475) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.39806 (A-MSE: 0.33752) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.35756 (A-MSE: 0.30333) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 9 out of 50
train epoch 1521 avg loss: 0.24804 (A-MSE: 0.21462) avg lploss: 0.00000
train epoch 1522 avg loss: 0.24613 (A-MSE: 0.21285) avg lploss: 0.00000
train epoch 1523 avg loss: 0.24291 (A-MSE: 0.21130) avg lploss: 0.00000
train epoch 1524 avg loss: 0.24719 (A-MSE: 0.21412) avg lploss: 0.00000
train epoch 1525 avg loss: 0.24924 (A-MSE: 0.21669) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.37906 (A-MSE: 0.33113) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.33924 (A-MSE: 0.29742) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 10 out of 50
train epoch 1526 avg loss: 0.26726 (A-MSE: 0.23131) avg lploss: 0.00000
train epoch 1527 avg loss: 0.25756 (A-MSE: 0.22440) avg lploss: 0.00000
train epoch 1528 avg loss: 0.25320 (A-MSE: 0.22087) avg lploss: 0.00000
train epoch 1529 avg loss: 0.23892 (A-MSE: 0.20728) avg lploss: 0.00000
train epoch 1530 avg loss: 0.22105 (A-MSE: 0.19223) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.38487 (A-MSE: 0.33290) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.33862 (A-MSE: 0.29396) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 11 out of 50
train epoch 1531 avg loss: 0.22559 (A-MSE: 0.19744) avg lploss: 0.00000
train epoch 1532 avg loss: 0.23898 (A-MSE: 0.20872) avg lploss: 0.00000
train epoch 1533 avg loss: 0.23143 (A-MSE: 0.20149) avg lploss: 0.00000
train epoch 1534 avg loss: 0.21641 (A-MSE: 0.18827) avg lploss: 0.00000
train epoch 1535 avg loss: 0.20393 (A-MSE: 0.17815) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.32989 (A-MSE: 0.28857) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.31244 (A-MSE: 0.27477) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 12 out of 50
train epoch 1536 avg loss: 0.21881 (A-MSE: 0.19088) avg lploss: 0.00000
train epoch 1537 avg loss: 0.20621 (A-MSE: 0.18035) avg lploss: 0.00000
train epoch 1538 avg loss: 0.19769 (A-MSE: 0.17300) avg lploss: 0.00000
train epoch 1539 avg loss: 0.20757 (A-MSE: 0.18117) avg lploss: 0.00000
train epoch 1540 avg loss: 0.20027 (A-MSE: 0.17491) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.33659 (A-MSE: 0.28569) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.30400 (A-MSE: 0.25960) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 13 out of 50
train epoch 1541 avg loss: 0.19198 (A-MSE: 0.16628) avg lploss: 0.00000
train epoch 1542 avg loss: 0.19151 (A-MSE: 0.16675) avg lploss: 0.00000
train epoch 1543 avg loss: 0.19901 (A-MSE: 0.17414) avg lploss: 0.00000
train epoch 1544 avg loss: 0.20112 (A-MSE: 0.17593) avg lploss: 0.00000
train epoch 1545 avg loss: 0.20741 (A-MSE: 0.18150) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.33368 (A-MSE: 0.28385) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.29594 (A-MSE: 0.25331) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 14 out of 50
train epoch 1546 avg loss: 0.19772 (A-MSE: 0.17234) avg lploss: 0.00000
train epoch 1547 avg loss: 0.20185 (A-MSE: 0.17697) avg lploss: 0.00000
train epoch 1548 avg loss: 0.19609 (A-MSE: 0.17172) avg lploss: 0.00000
train epoch 1549 avg loss: 0.18109 (A-MSE: 0.15910) avg lploss: 0.00000
train epoch 1550 avg loss: 0.17445 (A-MSE: 0.15243) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.27638 (A-MSE: 0.23850) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.24839 (A-MSE: 0.21574) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 15 out of 50
train epoch 1551 avg loss: 0.17637 (A-MSE: 0.15490) avg lploss: 0.00000
train epoch 1552 avg loss: 0.18619 (A-MSE: 0.16257) avg lploss: 0.00000
train epoch 1553 avg loss: 0.19515 (A-MSE: 0.17151) avg lploss: 0.00000
train epoch 1554 avg loss: 0.20781 (A-MSE: 0.18324) avg lploss: 0.00000
train epoch 1555 avg loss: 0.20643 (A-MSE: 0.18071) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.31190 (A-MSE: 0.26562) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.27634 (A-MSE: 0.23631) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 16 out of 50
train epoch 1556 avg loss: 0.18390 (A-MSE: 0.16123) avg lploss: 0.00000
train epoch 1557 avg loss: 0.17514 (A-MSE: 0.15286) avg lploss: 0.00000
train epoch 1558 avg loss: 0.15641 (A-MSE: 0.13732) avg lploss: 0.00000
train epoch 1559 avg loss: 0.16477 (A-MSE: 0.14425) avg lploss: 0.00000
train epoch 1560 avg loss: 0.15944 (A-MSE: 0.14052) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.26864 (A-MSE: 0.23182) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.24219 (A-MSE: 0.20999) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 17 out of 50
train epoch 1561 avg loss: 0.15770 (A-MSE: 0.13872) avg lploss: 0.00000
train epoch 1562 avg loss: 0.16319 (A-MSE: 0.14386) avg lploss: 0.00000
train epoch 1563 avg loss: 0.16454 (A-MSE: 0.14421) avg lploss: 0.00000
train epoch 1564 avg loss: 0.15738 (A-MSE: 0.13851) avg lploss: 0.00000
train epoch 1565 avg loss: 0.17345 (A-MSE: 0.15211) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.33560 (A-MSE: 0.29162) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.29896 (A-MSE: 0.26106) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 18 out of 50
train epoch 1566 avg loss: 0.17503 (A-MSE: 0.15346) avg lploss: 0.00000
train epoch 1567 avg loss: 0.16973 (A-MSE: 0.14777) avg lploss: 0.00000
train epoch 1568 avg loss: 0.15669 (A-MSE: 0.13736) avg lploss: 0.00000
train epoch 1569 avg loss: 0.15343 (A-MSE: 0.13564) avg lploss: 0.00000
train epoch 1570 avg loss: 0.15391 (A-MSE: 0.13525) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.28170 (A-MSE: 0.24222) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.25004 (A-MSE: 0.21592) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 19 out of 50
train epoch 1571 avg loss: 0.14779 (A-MSE: 0.12956) avg lploss: 0.00000
train epoch 1572 avg loss: 0.14883 (A-MSE: 0.13096) avg lploss: 0.00000
train epoch 1573 avg loss: 0.15032 (A-MSE: 0.13234) avg lploss: 0.00000
train epoch 1574 avg loss: 0.16355 (A-MSE: 0.14387) avg lploss: 0.00000
train epoch 1575 avg loss: 0.16937 (A-MSE: 0.14869) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.30651 (A-MSE: 0.26313) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.27047 (A-MSE: 0.23303) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 20 out of 50
train epoch 1576 avg loss: 0.15540 (A-MSE: 0.13605) avg lploss: 0.00000
train epoch 1577 avg loss: 0.15429 (A-MSE: 0.13478) avg lploss: 0.00000
train epoch 1578 avg loss: 0.15083 (A-MSE: 0.13191) avg lploss: 0.00000
train epoch 1579 avg loss: 0.16548 (A-MSE: 0.14591) avg lploss: 0.00000
train epoch 1580 avg loss: 0.14490 (A-MSE: 0.12711) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.24995 (A-MSE: 0.21669) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.22648 (A-MSE: 0.19759) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 21 out of 50
train epoch 1581 avg loss: 0.14549 (A-MSE: 0.12767) avg lploss: 0.00000
train epoch 1582 avg loss: 0.14180 (A-MSE: 0.12516) avg lploss: 0.00000
train epoch 1583 avg loss: 0.13706 (A-MSE: 0.12027) avg lploss: 0.00000
train epoch 1584 avg loss: 0.15320 (A-MSE: 0.13489) avg lploss: 0.00000
train epoch 1585 avg loss: 0.15561 (A-MSE: 0.13768) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.25610 (A-MSE: 0.22012) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.23131 (A-MSE: 0.20088) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 22 out of 50
train epoch 1586 avg loss: 0.17974 (A-MSE: 0.15684) avg lploss: 0.00000
train epoch 1587 avg loss: 0.15902 (A-MSE: 0.14083) avg lploss: 0.00000
train epoch 1588 avg loss: 0.15121 (A-MSE: 0.13185) avg lploss: 0.00000
train epoch 1589 avg loss: 0.14273 (A-MSE: 0.12452) avg lploss: 0.00000
train epoch 1590 avg loss: 0.14537 (A-MSE: 0.12828) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.30453 (A-MSE: 0.26185) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.26932 (A-MSE: 0.23195) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 23 out of 50
train epoch 1591 avg loss: 0.14405 (A-MSE: 0.12633) avg lploss: 0.00000
train epoch 1592 avg loss: 0.13491 (A-MSE: 0.11831) avg lploss: 0.00000
train epoch 1593 avg loss: 0.13304 (A-MSE: 0.11666) avg lploss: 0.00000
train epoch 1594 avg loss: 0.13591 (A-MSE: 0.11896) avg lploss: 0.00000
train epoch 1595 avg loss: 0.14211 (A-MSE: 0.12491) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.26323 (A-MSE: 0.22870) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.22968 (A-MSE: 0.20058) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 24 out of 50
train epoch 1596 avg loss: 0.14328 (A-MSE: 0.12557) avg lploss: 0.00000
train epoch 1597 avg loss: 0.13395 (A-MSE: 0.11776) avg lploss: 0.00000
train epoch 1598 avg loss: 0.13374 (A-MSE: 0.11754) avg lploss: 0.00000
train epoch 1599 avg loss: 0.13231 (A-MSE: 0.11693) avg lploss: 0.00000
train epoch 1600 avg loss: 0.13505 (A-MSE: 0.11799) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.24870 (A-MSE: 0.21806) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.23071 (A-MSE: 0.20428) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 25 out of 50
train epoch 1601 avg loss: 0.13108 (A-MSE: 0.11551) avg lploss: 0.00000
train epoch 1602 avg loss: 0.12684 (A-MSE: 0.11094) avg lploss: 0.00000
train epoch 1603 avg loss: 0.12765 (A-MSE: 0.11288) avg lploss: 0.00000
train epoch 1604 avg loss: 0.12530 (A-MSE: 0.10997) avg lploss: 0.00000
train epoch 1605 avg loss: 0.13266 (A-MSE: 0.11628) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.23508 (A-MSE: 0.20446) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.20611 (A-MSE: 0.17930) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 26 out of 50
train epoch 1606 avg loss: 0.13518 (A-MSE: 0.11960) avg lploss: 0.00000
train epoch 1607 avg loss: 0.13371 (A-MSE: 0.11804) avg lploss: 0.00000
train epoch 1608 avg loss: 0.12447 (A-MSE: 0.10890) avg lploss: 0.00000
train epoch 1609 avg loss: 0.12157 (A-MSE: 0.10707) avg lploss: 0.00000
train epoch 1610 avg loss: 0.12922 (A-MSE: 0.11325) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.23437 (A-MSE: 0.20205) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.20558 (A-MSE: 0.17834) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 27 out of 50
train epoch 1611 avg loss: 0.12615 (A-MSE: 0.11032) avg lploss: 0.00000
train epoch 1612 avg loss: 0.13015 (A-MSE: 0.11464) avg lploss: 0.00000
train epoch 1613 avg loss: 0.13857 (A-MSE: 0.12254) avg lploss: 0.00000
train epoch 1614 avg loss: 0.12065 (A-MSE: 0.10594) avg lploss: 0.00000
train epoch 1615 avg loss: 0.11462 (A-MSE: 0.10056) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.24417 (A-MSE: 0.21066) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.21256 (A-MSE: 0.18384) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 28 out of 50
train epoch 1616 avg loss: 0.11800 (A-MSE: 0.10310) avg lploss: 0.00000
train epoch 1617 avg loss: 0.11089 (A-MSE: 0.09711) avg lploss: 0.00000
train epoch 1618 avg loss: 0.11642 (A-MSE: 0.10277) avg lploss: 0.00000
train epoch 1619 avg loss: 0.12100 (A-MSE: 0.10619) avg lploss: 0.00000
train epoch 1620 avg loss: 0.12143 (A-MSE: 0.10648) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.23809 (A-MSE: 0.20765) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.21489 (A-MSE: 0.18865) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 29 out of 50
train epoch 1621 avg loss: 0.13416 (A-MSE: 0.11800) avg lploss: 0.00000
train epoch 1622 avg loss: 0.11967 (A-MSE: 0.10490) avg lploss: 0.00000
train epoch 1623 avg loss: 0.11678 (A-MSE: 0.10275) avg lploss: 0.00000
train epoch 1624 avg loss: 0.12902 (A-MSE: 0.11372) avg lploss: 0.00000
train epoch 1625 avg loss: 0.11596 (A-MSE: 0.10177) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.23189 (A-MSE: 0.19957) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.20904 (A-MSE: 0.18162) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 30 out of 50
train epoch 1626 avg loss: 0.12108 (A-MSE: 0.10618) avg lploss: 0.00000
train epoch 1627 avg loss: 0.12273 (A-MSE: 0.10815) avg lploss: 0.00000
train epoch 1628 avg loss: 0.11968 (A-MSE: 0.10504) avg lploss: 0.00000
train epoch 1629 avg loss: 0.12377 (A-MSE: 0.10892) avg lploss: 0.00000
train epoch 1630 avg loss: 0.11844 (A-MSE: 0.10374) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.24512 (A-MSE: 0.20860) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.21339 (A-MSE: 0.18179) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 31 out of 50
train epoch 1631 avg loss: 0.11532 (A-MSE: 0.10118) avg lploss: 0.00000
train epoch 1632 avg loss: 0.11485 (A-MSE: 0.10082) avg lploss: 0.00000
train epoch 1633 avg loss: 0.13099 (A-MSE: 0.11430) avg lploss: 0.00000
train epoch 1634 avg loss: 0.13754 (A-MSE: 0.12218) avg lploss: 0.00000
train epoch 1635 avg loss: 0.11977 (A-MSE: 0.10572) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.23079 (A-MSE: 0.19870) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.20087 (A-MSE: 0.17398) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 32 out of 50
train epoch 1636 avg loss: 0.11353 (A-MSE: 0.09996) avg lploss: 0.00000
train epoch 1637 avg loss: 0.11100 (A-MSE: 0.09776) avg lploss: 0.00000
train epoch 1638 avg loss: 0.11563 (A-MSE: 0.10182) avg lploss: 0.00000
train epoch 1639 avg loss: 0.11681 (A-MSE: 0.10241) avg lploss: 0.00000
train epoch 1640 avg loss: 0.11139 (A-MSE: 0.09713) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.24629 (A-MSE: 0.21453) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.21624 (A-MSE: 0.18958) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 33 out of 50
train epoch 1641 avg loss: 0.10938 (A-MSE: 0.09682) avg lploss: 0.00000
train epoch 1642 avg loss: 0.11053 (A-MSE: 0.09658) avg lploss: 0.00000
train epoch 1643 avg loss: 0.12386 (A-MSE: 0.10967) avg lploss: 0.00000
train epoch 1644 avg loss: 0.12306 (A-MSE: 0.10829) avg lploss: 0.00000
train epoch 1645 avg loss: 0.11586 (A-MSE: 0.10161) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.21613 (A-MSE: 0.18724) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.18864 (A-MSE: 0.16434) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 34 out of 50
train epoch 1646 avg loss: 0.11352 (A-MSE: 0.09946) avg lploss: 0.00000
train epoch 1647 avg loss: 0.11224 (A-MSE: 0.09815) avg lploss: 0.00000
train epoch 1648 avg loss: 0.11345 (A-MSE: 0.09938) avg lploss: 0.00000
train epoch 1649 avg loss: 0.10913 (A-MSE: 0.09578) avg lploss: 0.00000
train epoch 1650 avg loss: 0.11385 (A-MSE: 0.09983) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.20751 (A-MSE: 0.18178) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.18540 (A-MSE: 0.16269) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 35 out of 50
train epoch 1651 avg loss: 0.11339 (A-MSE: 0.09928) avg lploss: 0.00000
train epoch 1652 avg loss: 0.10227 (A-MSE: 0.08966) avg lploss: 0.00000
train epoch 1653 avg loss: 0.10750 (A-MSE: 0.09391) avg lploss: 0.00000
train epoch 1654 avg loss: 0.11245 (A-MSE: 0.09898) avg lploss: 0.00000
train epoch 1655 avg loss: 0.10544 (A-MSE: 0.09205) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.21288 (A-MSE: 0.18487) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.18515 (A-MSE: 0.16118) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 36 out of 50
train epoch 1656 avg loss: 0.10296 (A-MSE: 0.09051) avg lploss: 0.00000
train epoch 1657 avg loss: 0.11155 (A-MSE: 0.09783) avg lploss: 0.00000
train epoch 1658 avg loss: 0.11622 (A-MSE: 0.10156) avg lploss: 0.00000
train epoch 1659 avg loss: 0.12074 (A-MSE: 0.10613) avg lploss: 0.00000
train epoch 1660 avg loss: 0.11020 (A-MSE: 0.09698) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.23743 (A-MSE: 0.20632) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.20925 (A-MSE: 0.18289) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 37 out of 50
train epoch 1661 avg loss: 0.10666 (A-MSE: 0.09413) avg lploss: 0.00000
train epoch 1662 avg loss: 0.10723 (A-MSE: 0.09399) avg lploss: 0.00000
train epoch 1663 avg loss: 0.11129 (A-MSE: 0.09741) avg lploss: 0.00000
train epoch 1664 avg loss: 0.12469 (A-MSE: 0.11035) avg lploss: 0.00000
train epoch 1665 avg loss: 0.12643 (A-MSE: 0.11084) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.25186 (A-MSE: 0.21779) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.22245 (A-MSE: 0.19324) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 38 out of 50
train epoch 1666 avg loss: 0.12174 (A-MSE: 0.10720) avg lploss: 0.00000
train epoch 1667 avg loss: 0.10834 (A-MSE: 0.09491) avg lploss: 0.00000
train epoch 1668 avg loss: 0.10776 (A-MSE: 0.09462) avg lploss: 0.00000
train epoch 1669 avg loss: 0.10954 (A-MSE: 0.09609) avg lploss: 0.00000
train epoch 1670 avg loss: 0.10298 (A-MSE: 0.09066) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.20721 (A-MSE: 0.18039) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.17887 (A-MSE: 0.15589) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 39 out of 50
train epoch 1671 avg loss: 0.10392 (A-MSE: 0.09137) avg lploss: 0.00000
train epoch 1672 avg loss: 0.10681 (A-MSE: 0.09329) avg lploss: 0.00000
train epoch 1673 avg loss: 0.11045 (A-MSE: 0.09724) avg lploss: 0.00000
train epoch 1674 avg loss: 0.10610 (A-MSE: 0.09328) avg lploss: 0.00000
train epoch 1675 avg loss: 0.09765 (A-MSE: 0.08556) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.19839 (A-MSE: 0.17267) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.16942 (A-MSE: 0.14743) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 40 out of 50
train epoch 1676 avg loss: 0.09582 (A-MSE: 0.08429) avg lploss: 0.00000
train epoch 1677 avg loss: 0.10377 (A-MSE: 0.09089) avg lploss: 0.00000
train epoch 1678 avg loss: 0.10150 (A-MSE: 0.08909) avg lploss: 0.00000
train epoch 1679 avg loss: 0.11042 (A-MSE: 0.09795) avg lploss: 0.00000
train epoch 1680 avg loss: 0.13111 (A-MSE: 0.11497) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.20267 (A-MSE: 0.17583) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.17569 (A-MSE: 0.15357) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 41 out of 50
train epoch 1681 avg loss: 0.11128 (A-MSE: 0.09808) avg lploss: 0.00000
train epoch 1682 avg loss: 0.10990 (A-MSE: 0.09660) avg lploss: 0.00000
train epoch 1683 avg loss: 0.09975 (A-MSE: 0.08805) avg lploss: 0.00000
train epoch 1684 avg loss: 0.10159 (A-MSE: 0.08868) avg lploss: 0.00000
train epoch 1685 avg loss: 0.09666 (A-MSE: 0.08504) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.21449 (A-MSE: 0.18575) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.18928 (A-MSE: 0.16468) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 42 out of 50
train epoch 1686 avg loss: 0.10609 (A-MSE: 0.09305) avg lploss: 0.00000
train epoch 1687 avg loss: 0.09905 (A-MSE: 0.08644) avg lploss: 0.00000
train epoch 1688 avg loss: 0.10006 (A-MSE: 0.08746) avg lploss: 0.00000
train epoch 1689 avg loss: 0.10123 (A-MSE: 0.08887) avg lploss: 0.00000
train epoch 1690 avg loss: 0.10459 (A-MSE: 0.09145) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.21584 (A-MSE: 0.18870) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.18733 (A-MSE: 0.16350) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 43 out of 50
train epoch 1691 avg loss: 0.09885 (A-MSE: 0.08658) avg lploss: 0.00000
train epoch 1692 avg loss: 0.09558 (A-MSE: 0.08427) avg lploss: 0.00000
train epoch 1693 avg loss: 0.09696 (A-MSE: 0.08548) avg lploss: 0.00000
train epoch 1694 avg loss: 0.09924 (A-MSE: 0.08742) avg lploss: 0.00000
train epoch 1695 avg loss: 0.11430 (A-MSE: 0.10101) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.20908 (A-MSE: 0.18181) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.18234 (A-MSE: 0.15936) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 44 out of 50
train epoch 1696 avg loss: 0.11038 (A-MSE: 0.09690) avg lploss: 0.00000
train epoch 1697 avg loss: 0.09984 (A-MSE: 0.08740) avg lploss: 0.00000
train epoch 1698 avg loss: 0.09389 (A-MSE: 0.08280) avg lploss: 0.00000
train epoch 1699 avg loss: 0.09308 (A-MSE: 0.08177) avg lploss: 0.00000
train epoch 1700 avg loss: 0.10338 (A-MSE: 0.09091) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.19650 (A-MSE: 0.17110) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.16838 (A-MSE: 0.14735) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 45 out of 50
train epoch 1701 avg loss: 0.09102 (A-MSE: 0.07964) avg lploss: 0.00000
train epoch 1702 avg loss: 0.09660 (A-MSE: 0.08467) avg lploss: 0.00000
train epoch 1703 avg loss: 0.09079 (A-MSE: 0.07994) avg lploss: 0.00000
train epoch 1704 avg loss: 0.08900 (A-MSE: 0.07813) avg lploss: 0.00000
train epoch 1705 avg loss: 0.09812 (A-MSE: 0.08583) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.18127 (A-MSE: 0.15809) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.15434 (A-MSE: 0.13513) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 46 out of 50
train epoch 1706 avg loss: 0.09410 (A-MSE: 0.08316) avg lploss: 0.00000
train epoch 1707 avg loss: 0.09035 (A-MSE: 0.07975) avg lploss: 0.00000
train epoch 1708 avg loss: 0.08829 (A-MSE: 0.07779) avg lploss: 0.00000
train epoch 1709 avg loss: 0.09346 (A-MSE: 0.08246) avg lploss: 0.00000
train epoch 1710 avg loss: 0.08798 (A-MSE: 0.07726) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.19846 (A-MSE: 0.17230) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.17382 (A-MSE: 0.15222) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 47 out of 50
train epoch 1711 avg loss: 0.09283 (A-MSE: 0.08192) avg lploss: 0.00000
train epoch 1712 avg loss: 0.09059 (A-MSE: 0.07948) avg lploss: 0.00000
train epoch 1713 avg loss: 0.09533 (A-MSE: 0.08377) avg lploss: 0.00000
train epoch 1714 avg loss: 0.09326 (A-MSE: 0.08202) avg lploss: 0.00000
train epoch 1715 avg loss: 0.09349 (A-MSE: 0.08204) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.19060 (A-MSE: 0.16507) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.16355 (A-MSE: 0.14138) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 48 out of 50
train epoch 1716 avg loss: 0.09557 (A-MSE: 0.08409) avg lploss: 0.00000
train epoch 1717 avg loss: 0.09212 (A-MSE: 0.08082) avg lploss: 0.00000
train epoch 1718 avg loss: 0.10085 (A-MSE: 0.08875) avg lploss: 0.00000
train epoch 1719 avg loss: 0.09822 (A-MSE: 0.08654) avg lploss: 0.00000
train epoch 1720 avg loss: 0.08735 (A-MSE: 0.07675) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.19863 (A-MSE: 0.17143) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.17103 (A-MSE: 0.14885) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 49 out of 50
train epoch 1721 avg loss: 0.09983 (A-MSE: 0.08780) avg lploss: 0.00000
train epoch 1722 avg loss: 0.10436 (A-MSE: 0.09303) avg lploss: 0.00000
train epoch 1723 avg loss: 0.09293 (A-MSE: 0.08220) avg lploss: 0.00000
train epoch 1724 avg loss: 0.10289 (A-MSE: 0.08985) avg lploss: 0.00000
train epoch 1725 avg loss: 0.09013 (A-MSE: 0.07986) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.19776 (A-MSE: 0.17350) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.17278 (A-MSE: 0.15240) avg lploss: 0.00000
*** Best Val Loss: 0.13605 	 Best Test Loss: 0.10417 	 Best epoch 1475
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train_f_mse = 0.074505
best_lp = 0.000000
best_val_f_mse = 0.136054
best_test_f_mse = 0.104174
best_test_a_mse = 0.091985
best_epoch = 1475
best_train_f_mse = 0.074505, best_lp = 0.000000, best_val_f_mse = 0.136054, best_test_f_mse = 0.104174, best_test_a_mse = 0.091985, best_epoch = 1475
Job completed at Mon Dec  8 23:32:49 CET 2025
