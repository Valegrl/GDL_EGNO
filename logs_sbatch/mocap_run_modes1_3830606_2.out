Running Mocap-Run with num_modes=1 for seed 2
Job ID: 3831010, Array Task ID: 2
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes1_seed2.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes1_seed2', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=1, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=2, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes1_seed2/saved_model.pth
train epoch 0 avg loss: 134.40990 (A-MSE: 138.75535) avg lploss: 0.00000
==> val epoch 0 avg loss: 89.34206 (A-MSE: 78.24119) avg lploss: 0.00000
==> test epoch 0 avg loss: 85.21580 (A-MSE: 74.65169) avg lploss: 0.00000
*** Best Val Loss: 89.34206 	 Best Test Loss: 85.21580 	 Best epoch 0
Validation loss decreased (inf --> 89.342057).  Saving model ...
train epoch 1 avg loss: 92.48828 (A-MSE: 82.18989) avg lploss: 0.00000
train epoch 2 avg loss: 87.40726 (A-MSE: 76.79600) avg lploss: 0.00000
train epoch 3 avg loss: 84.88776 (A-MSE: 74.65286) avg lploss: 0.00000
train epoch 4 avg loss: 79.16420 (A-MSE: 69.63513) avg lploss: 0.00000
train epoch 5 avg loss: 73.01337 (A-MSE: 64.08977) avg lploss: 0.00000
==> val epoch 5 avg loss: 70.71760 (A-MSE: 62.05784) avg lploss: 0.00000
==> test epoch 5 avg loss: 66.78877 (A-MSE: 58.63296) avg lploss: 0.00000
*** Best Val Loss: 70.71760 	 Best Test Loss: 66.78877 	 Best epoch 5
Validation loss decreased (89.342057 --> 70.717600).  Saving model ...
train epoch 6 avg loss: 65.75460 (A-MSE: 57.67878) avg lploss: 0.00000
train epoch 7 avg loss: 54.58479 (A-MSE: 47.61503) avg lploss: 0.00000
train epoch 8 avg loss: 42.78696 (A-MSE: 37.24096) avg lploss: 0.00000
train epoch 9 avg loss: 33.76864 (A-MSE: 29.46536) avg lploss: 0.00000
train epoch 10 avg loss: 26.25602 (A-MSE: 22.80130) avg lploss: 0.00000
==> val epoch 10 avg loss: 21.77903 (A-MSE: 18.88475) avg lploss: 0.00000
==> test epoch 10 avg loss: 20.44548 (A-MSE: 17.68076) avg lploss: 0.00000
*** Best Val Loss: 21.77903 	 Best Test Loss: 20.44548 	 Best epoch 10
Validation loss decreased (70.717600 --> 21.779026).  Saving model ...
train epoch 11 avg loss: 20.80999 (A-MSE: 18.17635) avg lploss: 0.00000
train epoch 12 avg loss: 18.21702 (A-MSE: 15.91209) avg lploss: 0.00000
train epoch 13 avg loss: 16.68405 (A-MSE: 14.56936) avg lploss: 0.00000
train epoch 14 avg loss: 15.60537 (A-MSE: 13.66997) avg lploss: 0.00000
train epoch 15 avg loss: 14.46284 (A-MSE: 12.69275) avg lploss: 0.00000
==> val epoch 15 avg loss: 13.07404 (A-MSE: 11.33950) avg lploss: 0.00000
==> test epoch 15 avg loss: 12.13590 (A-MSE: 10.46888) avg lploss: 0.00000
*** Best Val Loss: 13.07404 	 Best Test Loss: 12.13590 	 Best epoch 15
Validation loss decreased (21.779026 --> 13.074043).  Saving model ...
train epoch 16 avg loss: 12.94821 (A-MSE: 11.26018) avg lploss: 0.00000
train epoch 17 avg loss: 11.99628 (A-MSE: 10.48572) avg lploss: 0.00000
train epoch 18 avg loss: 11.16930 (A-MSE: 9.73507) avg lploss: 0.00000
train epoch 19 avg loss: 10.38708 (A-MSE: 9.08186) avg lploss: 0.00000
train epoch 20 avg loss: 9.70663 (A-MSE: 8.48342) avg lploss: 0.00000
==> val epoch 20 avg loss: 9.42024 (A-MSE: 8.08238) avg lploss: 0.00000
==> test epoch 20 avg loss: 9.05392 (A-MSE: 7.72733) avg lploss: 0.00000
*** Best Val Loss: 9.42024 	 Best Test Loss: 9.05392 	 Best epoch 20
Validation loss decreased (13.074043 --> 9.420238).  Saving model ...
train epoch 21 avg loss: 9.24028 (A-MSE: 8.07659) avg lploss: 0.00000
train epoch 22 avg loss: 8.51294 (A-MSE: 7.42096) avg lploss: 0.00000
train epoch 23 avg loss: 8.32736 (A-MSE: 7.27942) avg lploss: 0.00000
train epoch 24 avg loss: 8.10244 (A-MSE: 7.11448) avg lploss: 0.00000
train epoch 25 avg loss: 8.07454 (A-MSE: 7.04814) avg lploss: 0.00000
==> val epoch 25 avg loss: 7.67796 (A-MSE: 6.74188) avg lploss: 0.00000
==> test epoch 25 avg loss: 7.41203 (A-MSE: 6.45125) avg lploss: 0.00000
*** Best Val Loss: 7.67796 	 Best Test Loss: 7.41203 	 Best epoch 25
Validation loss decreased (9.420238 --> 7.677959).  Saving model ...
train epoch 26 avg loss: 7.33248 (A-MSE: 6.40845) avg lploss: 0.00000
train epoch 27 avg loss: 6.86420 (A-MSE: 6.02190) avg lploss: 0.00000
train epoch 28 avg loss: 6.37252 (A-MSE: 5.59243) avg lploss: 0.00000
train epoch 29 avg loss: 5.65307 (A-MSE: 4.95216) avg lploss: 0.00000
train epoch 30 avg loss: 5.44195 (A-MSE: 4.75062) avg lploss: 0.00000
==> val epoch 30 avg loss: 4.96613 (A-MSE: 4.39187) avg lploss: 0.00000
==> test epoch 30 avg loss: 4.97358 (A-MSE: 4.33720) avg lploss: 0.00000
*** Best Val Loss: 4.96613 	 Best Test Loss: 4.97358 	 Best epoch 30
Validation loss decreased (7.677959 --> 4.966131).  Saving model ...
train epoch 31 avg loss: 5.20517 (A-MSE: 4.52409) avg lploss: 0.00000
train epoch 32 avg loss: 4.77640 (A-MSE: 4.18231) avg lploss: 0.00000
train epoch 33 avg loss: 4.94716 (A-MSE: 4.34450) avg lploss: 0.00000
train epoch 34 avg loss: 4.39634 (A-MSE: 3.81603) avg lploss: 0.00000
train epoch 35 avg loss: 3.99177 (A-MSE: 3.44728) avg lploss: 0.00000
==> val epoch 35 avg loss: 3.73800 (A-MSE: 3.24359) avg lploss: 0.00000
==> test epoch 35 avg loss: 3.86474 (A-MSE: 3.28471) avg lploss: 0.00000
*** Best Val Loss: 3.73800 	 Best Test Loss: 3.86474 	 Best epoch 35
Validation loss decreased (4.966131 --> 3.738000).  Saving model ...
train epoch 36 avg loss: 3.85559 (A-MSE: 3.33132) avg lploss: 0.00000
train epoch 37 avg loss: 3.53235 (A-MSE: 3.06725) avg lploss: 0.00000
train epoch 38 avg loss: 3.59629 (A-MSE: 3.10710) avg lploss: 0.00000
train epoch 39 avg loss: 3.42037 (A-MSE: 2.97043) avg lploss: 0.00000
train epoch 40 avg loss: 3.35880 (A-MSE: 2.88243) avg lploss: 0.00000
==> val epoch 40 avg loss: 3.21180 (A-MSE: 2.82722) avg lploss: 0.00000
==> test epoch 40 avg loss: 3.32150 (A-MSE: 2.87079) avg lploss: 0.00000
*** Best Val Loss: 3.21180 	 Best Test Loss: 3.32150 	 Best epoch 40
Validation loss decreased (3.738000 --> 3.211796).  Saving model ...
train epoch 41 avg loss: 3.10109 (A-MSE: 2.66405) avg lploss: 0.00000
train epoch 42 avg loss: 3.07280 (A-MSE: 2.66645) avg lploss: 0.00000
train epoch 43 avg loss: 3.05685 (A-MSE: 2.62747) avg lploss: 0.00000
train epoch 44 avg loss: 2.97298 (A-MSE: 2.57280) avg lploss: 0.00000
train epoch 45 avg loss: 2.82687 (A-MSE: 2.42481) avg lploss: 0.00000
==> val epoch 45 avg loss: 2.63001 (A-MSE: 2.32451) avg lploss: 0.00000
==> test epoch 45 avg loss: 2.75646 (A-MSE: 2.37752) avg lploss: 0.00000
*** Best Val Loss: 2.63001 	 Best Test Loss: 2.75646 	 Best epoch 45
Validation loss decreased (3.211796 --> 2.630008).  Saving model ...
train epoch 46 avg loss: 2.70208 (A-MSE: 2.31864) avg lploss: 0.00000
train epoch 47 avg loss: 2.71293 (A-MSE: 2.34108) avg lploss: 0.00000
train epoch 48 avg loss: 2.70172 (A-MSE: 2.31279) avg lploss: 0.00000
train epoch 49 avg loss: 2.43486 (A-MSE: 2.08664) avg lploss: 0.00000
train epoch 50 avg loss: 2.45459 (A-MSE: 2.10120) avg lploss: 0.00000
==> val epoch 50 avg loss: 2.26464 (A-MSE: 2.02244) avg lploss: 0.00000
==> test epoch 50 avg loss: 2.46136 (A-MSE: 2.14417) avg lploss: 0.00000
*** Best Val Loss: 2.26464 	 Best Test Loss: 2.46136 	 Best epoch 50
Validation loss decreased (2.630008 --> 2.264641).  Saving model ...
train epoch 51 avg loss: 2.23442 (A-MSE: 1.92086) avg lploss: 0.00000
train epoch 52 avg loss: 2.21850 (A-MSE: 1.88757) avg lploss: 0.00000
train epoch 53 avg loss: 2.24736 (A-MSE: 1.95743) avg lploss: 0.00000
train epoch 54 avg loss: 2.18556 (A-MSE: 1.87133) avg lploss: 0.00000
train epoch 55 avg loss: 2.14499 (A-MSE: 1.83250) avg lploss: 0.00000
==> val epoch 55 avg loss: 2.13830 (A-MSE: 2.01912) avg lploss: 0.00000
==> test epoch 55 avg loss: 2.20220 (A-MSE: 2.02264) avg lploss: 0.00000
*** Best Val Loss: 2.13830 	 Best Test Loss: 2.20220 	 Best epoch 55
Validation loss decreased (2.264641 --> 2.138302).  Saving model ...
train epoch 56 avg loss: 1.97722 (A-MSE: 1.70322) avg lploss: 0.00000
train epoch 57 avg loss: 1.97209 (A-MSE: 1.69337) avg lploss: 0.00000
train epoch 58 avg loss: 2.14194 (A-MSE: 1.84730) avg lploss: 0.00000
train epoch 59 avg loss: 1.99871 (A-MSE: 1.70985) avg lploss: 0.00000
train epoch 60 avg loss: 1.95830 (A-MSE: 1.69815) avg lploss: 0.00000
==> val epoch 60 avg loss: 2.08037 (A-MSE: 1.74791) avg lploss: 0.00000
==> test epoch 60 avg loss: 2.27934 (A-MSE: 1.90723) avg lploss: 0.00000
*** Best Val Loss: 2.08037 	 Best Test Loss: 2.27934 	 Best epoch 60
Validation loss decreased (2.138302 --> 2.080366).  Saving model ...
train epoch 61 avg loss: 1.94047 (A-MSE: 1.65388) avg lploss: 0.00000
train epoch 62 avg loss: 1.81762 (A-MSE: 1.57368) avg lploss: 0.00000
train epoch 63 avg loss: 1.99913 (A-MSE: 1.72470) avg lploss: 0.00000
train epoch 64 avg loss: 1.97404 (A-MSE: 1.71217) avg lploss: 0.00000
train epoch 65 avg loss: 1.91604 (A-MSE: 1.65498) avg lploss: 0.00000
==> val epoch 65 avg loss: 2.22482 (A-MSE: 1.82942) avg lploss: 0.00000
==> test epoch 65 avg loss: 2.49185 (A-MSE: 2.05984) avg lploss: 0.00000
*** Best Val Loss: 2.08037 	 Best Test Loss: 2.27934 	 Best epoch 60
EarlyStopping counter: 1 out of 50
train epoch 66 avg loss: 1.74265 (A-MSE: 1.49841) avg lploss: 0.00000
train epoch 67 avg loss: 1.69438 (A-MSE: 1.45690) avg lploss: 0.00000
train epoch 68 avg loss: 1.61264 (A-MSE: 1.38770) avg lploss: 0.00000
train epoch 69 avg loss: 1.56336 (A-MSE: 1.34295) avg lploss: 0.00000
train epoch 70 avg loss: 1.42926 (A-MSE: 1.23317) avg lploss: 0.00000
==> val epoch 70 avg loss: 1.66786 (A-MSE: 1.45845) avg lploss: 0.00000
==> test epoch 70 avg loss: 1.83324 (A-MSE: 1.59002) avg lploss: 0.00000
*** Best Val Loss: 1.66786 	 Best Test Loss: 1.83324 	 Best epoch 70
Validation loss decreased (2.080366 --> 1.667857).  Saving model ...
train epoch 71 avg loss: 1.43841 (A-MSE: 1.23766) avg lploss: 0.00000
train epoch 72 avg loss: 1.34877 (A-MSE: 1.16806) avg lploss: 0.00000
train epoch 73 avg loss: 1.41023 (A-MSE: 1.21053) avg lploss: 0.00000
train epoch 74 avg loss: 1.51470 (A-MSE: 1.31238) avg lploss: 0.00000
train epoch 75 avg loss: 1.32057 (A-MSE: 1.13690) avg lploss: 0.00000
==> val epoch 75 avg loss: 1.46454 (A-MSE: 1.32882) avg lploss: 0.00000
==> test epoch 75 avg loss: 1.54963 (A-MSE: 1.39622) avg lploss: 0.00000
*** Best Val Loss: 1.46454 	 Best Test Loss: 1.54963 	 Best epoch 75
Validation loss decreased (1.667857 --> 1.464545).  Saving model ...
train epoch 76 avg loss: 1.33604 (A-MSE: 1.15604) avg lploss: 0.00000
train epoch 77 avg loss: 1.41714 (A-MSE: 1.22805) avg lploss: 0.00000
train epoch 78 avg loss: 1.49532 (A-MSE: 1.29419) avg lploss: 0.00000
train epoch 79 avg loss: 1.27382 (A-MSE: 1.10009) avg lploss: 0.00000
train epoch 80 avg loss: 1.32167 (A-MSE: 1.14417) avg lploss: 0.00000
==> val epoch 80 avg loss: 1.43264 (A-MSE: 1.27932) avg lploss: 0.00000
==> test epoch 80 avg loss: 1.52329 (A-MSE: 1.35233) avg lploss: 0.00000
*** Best Val Loss: 1.43264 	 Best Test Loss: 1.52329 	 Best epoch 80
Validation loss decreased (1.464545 --> 1.432638).  Saving model ...
train epoch 81 avg loss: 1.20866 (A-MSE: 1.03539) avg lploss: 0.00000
train epoch 82 avg loss: 1.31154 (A-MSE: 1.13147) avg lploss: 0.00000
train epoch 83 avg loss: 1.43503 (A-MSE: 1.25373) avg lploss: 0.00000
train epoch 84 avg loss: 1.48035 (A-MSE: 1.28035) avg lploss: 0.00000
train epoch 85 avg loss: 1.41723 (A-MSE: 1.22024) avg lploss: 0.00000
==> val epoch 85 avg loss: 1.43873 (A-MSE: 1.26635) avg lploss: 0.00000
==> test epoch 85 avg loss: 1.64758 (A-MSE: 1.45587) avg lploss: 0.00000
*** Best Val Loss: 1.43264 	 Best Test Loss: 1.52329 	 Best epoch 80
EarlyStopping counter: 1 out of 50
train epoch 86 avg loss: 1.19561 (A-MSE: 1.03317) avg lploss: 0.00000
train epoch 87 avg loss: 1.15237 (A-MSE: 0.99707) avg lploss: 0.00000
train epoch 88 avg loss: 1.14418 (A-MSE: 0.98138) avg lploss: 0.00000
train epoch 89 avg loss: 1.14982 (A-MSE: 0.99092) avg lploss: 0.00000
train epoch 90 avg loss: 1.11999 (A-MSE: 0.97295) avg lploss: 0.00000
==> val epoch 90 avg loss: 1.41662 (A-MSE: 1.23414) avg lploss: 0.00000
==> test epoch 90 avg loss: 1.49414 (A-MSE: 1.31593) avg lploss: 0.00000
*** Best Val Loss: 1.41662 	 Best Test Loss: 1.49414 	 Best epoch 90
Validation loss decreased (1.432638 --> 1.416623).  Saving model ...
train epoch 91 avg loss: 1.14664 (A-MSE: 0.98791) avg lploss: 0.00000
train epoch 92 avg loss: 1.14412 (A-MSE: 0.99857) avg lploss: 0.00000
train epoch 93 avg loss: 1.12511 (A-MSE: 0.97531) avg lploss: 0.00000
train epoch 94 avg loss: 1.08964 (A-MSE: 0.94324) avg lploss: 0.00000
train epoch 95 avg loss: 1.20254 (A-MSE: 1.04153) avg lploss: 0.00000
==> val epoch 95 avg loss: 1.34560 (A-MSE: 1.19171) avg lploss: 0.00000
==> test epoch 95 avg loss: 1.47233 (A-MSE: 1.31298) avg lploss: 0.00000
*** Best Val Loss: 1.34560 	 Best Test Loss: 1.47233 	 Best epoch 95
Validation loss decreased (1.416623 --> 1.345604).  Saving model ...
train epoch 96 avg loss: 1.07833 (A-MSE: 0.93251) avg lploss: 0.00000
train epoch 97 avg loss: 1.11911 (A-MSE: 0.97082) avg lploss: 0.00000
train epoch 98 avg loss: 1.03225 (A-MSE: 0.89540) avg lploss: 0.00000
train epoch 99 avg loss: 1.05297 (A-MSE: 0.91612) avg lploss: 0.00000
train epoch 100 avg loss: 0.97555 (A-MSE: 0.84765) avg lploss: 0.00000
==> val epoch 100 avg loss: 1.16357 (A-MSE: 1.08480) avg lploss: 0.00000
==> test epoch 100 avg loss: 1.27147 (A-MSE: 1.18768) avg lploss: 0.00000
*** Best Val Loss: 1.16357 	 Best Test Loss: 1.27147 	 Best epoch 100
Validation loss decreased (1.345604 --> 1.163572).  Saving model ...
train epoch 101 avg loss: 1.06623 (A-MSE: 0.93089) avg lploss: 0.00000
train epoch 102 avg loss: 1.03530 (A-MSE: 0.89706) avg lploss: 0.00000
train epoch 103 avg loss: 0.96894 (A-MSE: 0.83583) avg lploss: 0.00000
train epoch 104 avg loss: 0.94974 (A-MSE: 0.82554) avg lploss: 0.00000
train epoch 105 avg loss: 0.97384 (A-MSE: 0.84701) avg lploss: 0.00000
==> val epoch 105 avg loss: 1.08342 (A-MSE: 0.95346) avg lploss: 0.00000
==> test epoch 105 avg loss: 1.15876 (A-MSE: 1.03660) avg lploss: 0.00000
*** Best Val Loss: 1.08342 	 Best Test Loss: 1.15876 	 Best epoch 105
Validation loss decreased (1.163572 --> 1.083421).  Saving model ...
train epoch 106 avg loss: 1.17395 (A-MSE: 1.03004) avg lploss: 0.00000
train epoch 107 avg loss: 1.08492 (A-MSE: 0.94383) avg lploss: 0.00000
train epoch 108 avg loss: 1.05761 (A-MSE: 0.91800) avg lploss: 0.00000
train epoch 109 avg loss: 0.94930 (A-MSE: 0.81680) avg lploss: 0.00000
train epoch 110 avg loss: 0.87737 (A-MSE: 0.76062) avg lploss: 0.00000
==> val epoch 110 avg loss: 1.07365 (A-MSE: 0.92036) avg lploss: 0.00000
==> test epoch 110 avg loss: 1.19185 (A-MSE: 1.04675) avg lploss: 0.00000
*** Best Val Loss: 1.07365 	 Best Test Loss: 1.19185 	 Best epoch 110
Validation loss decreased (1.083421 --> 1.073654).  Saving model ...
train epoch 111 avg loss: 0.85623 (A-MSE: 0.73581) avg lploss: 0.00000
train epoch 112 avg loss: 0.88521 (A-MSE: 0.77086) avg lploss: 0.00000
train epoch 113 avg loss: 0.86548 (A-MSE: 0.74832) avg lploss: 0.00000
train epoch 114 avg loss: 0.91020 (A-MSE: 0.78814) avg lploss: 0.00000
train epoch 115 avg loss: 0.82909 (A-MSE: 0.71869) avg lploss: 0.00000
==> val epoch 115 avg loss: 1.14413 (A-MSE: 0.98336) avg lploss: 0.00000
==> test epoch 115 avg loss: 1.36075 (A-MSE: 1.19943) avg lploss: 0.00000
*** Best Val Loss: 1.07365 	 Best Test Loss: 1.19185 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 0.85247 (A-MSE: 0.73377) avg lploss: 0.00000
train epoch 117 avg loss: 0.81411 (A-MSE: 0.70609) avg lploss: 0.00000
train epoch 118 avg loss: 0.84422 (A-MSE: 0.73194) avg lploss: 0.00000
train epoch 119 avg loss: 0.84453 (A-MSE: 0.73134) avg lploss: 0.00000
train epoch 120 avg loss: 0.81427 (A-MSE: 0.70595) avg lploss: 0.00000
==> val epoch 120 avg loss: 1.23482 (A-MSE: 1.12110) avg lploss: 0.00000
==> test epoch 120 avg loss: 1.24524 (A-MSE: 1.14478) avg lploss: 0.00000
*** Best Val Loss: 1.07365 	 Best Test Loss: 1.19185 	 Best epoch 110
EarlyStopping counter: 2 out of 50
train epoch 121 avg loss: 0.82968 (A-MSE: 0.72415) avg lploss: 0.00000
train epoch 122 avg loss: 0.83055 (A-MSE: 0.71406) avg lploss: 0.00000
train epoch 123 avg loss: 0.76825 (A-MSE: 0.66696) avg lploss: 0.00000
train epoch 124 avg loss: 0.77661 (A-MSE: 0.66770) avg lploss: 0.00000
train epoch 125 avg loss: 0.73215 (A-MSE: 0.63905) avg lploss: 0.00000
==> val epoch 125 avg loss: 1.09686 (A-MSE: 0.91972) avg lploss: 0.00000
==> test epoch 125 avg loss: 1.24604 (A-MSE: 1.07933) avg lploss: 0.00000
*** Best Val Loss: 1.07365 	 Best Test Loss: 1.19185 	 Best epoch 110
EarlyStopping counter: 3 out of 50
train epoch 126 avg loss: 0.77444 (A-MSE: 0.66543) avg lploss: 0.00000
train epoch 127 avg loss: 0.73946 (A-MSE: 0.63486) avg lploss: 0.00000
train epoch 128 avg loss: 0.74995 (A-MSE: 0.65807) avg lploss: 0.00000
train epoch 129 avg loss: 0.79132 (A-MSE: 0.68644) avg lploss: 0.00000
train epoch 130 avg loss: 0.73480 (A-MSE: 0.63871) avg lploss: 0.00000
==> val epoch 130 avg loss: 1.31573 (A-MSE: 1.14280) avg lploss: 0.00000
==> test epoch 130 avg loss: 1.33568 (A-MSE: 1.17728) avg lploss: 0.00000
*** Best Val Loss: 1.07365 	 Best Test Loss: 1.19185 	 Best epoch 110
EarlyStopping counter: 4 out of 50
train epoch 131 avg loss: 0.82955 (A-MSE: 0.71401) avg lploss: 0.00000
train epoch 132 avg loss: 0.77303 (A-MSE: 0.67117) avg lploss: 0.00000
train epoch 133 avg loss: 0.77615 (A-MSE: 0.67224) avg lploss: 0.00000
train epoch 134 avg loss: 0.80352 (A-MSE: 0.70646) avg lploss: 0.00000
train epoch 135 avg loss: 0.76874 (A-MSE: 0.66291) avg lploss: 0.00000
==> val epoch 135 avg loss: 0.89351 (A-MSE: 0.78271) avg lploss: 0.00000
==> test epoch 135 avg loss: 1.03172 (A-MSE: 0.92618) avg lploss: 0.00000
*** Best Val Loss: 0.89351 	 Best Test Loss: 1.03172 	 Best epoch 135
Validation loss decreased (1.073654 --> 0.893513).  Saving model ...
train epoch 136 avg loss: 0.71921 (A-MSE: 0.62550) avg lploss: 0.00000
train epoch 137 avg loss: 0.84892 (A-MSE: 0.74061) avg lploss: 0.00000
train epoch 138 avg loss: 0.83591 (A-MSE: 0.72106) avg lploss: 0.00000
train epoch 139 avg loss: 0.78772 (A-MSE: 0.69083) avg lploss: 0.00000
train epoch 140 avg loss: 0.70669 (A-MSE: 0.60521) avg lploss: 0.00000
==> val epoch 140 avg loss: 0.92289 (A-MSE: 0.79340) avg lploss: 0.00000
==> test epoch 140 avg loss: 1.01581 (A-MSE: 0.89640) avg lploss: 0.00000
*** Best Val Loss: 0.89351 	 Best Test Loss: 1.03172 	 Best epoch 135
EarlyStopping counter: 1 out of 50
train epoch 141 avg loss: 0.66520 (A-MSE: 0.57597) avg lploss: 0.00000
train epoch 142 avg loss: 0.69832 (A-MSE: 0.60637) avg lploss: 0.00000
train epoch 143 avg loss: 0.79096 (A-MSE: 0.69252) avg lploss: 0.00000
train epoch 144 avg loss: 0.84185 (A-MSE: 0.73349) avg lploss: 0.00000
train epoch 145 avg loss: 0.81795 (A-MSE: 0.70530) avg lploss: 0.00000
==> val epoch 145 avg loss: 1.04798 (A-MSE: 0.87721) avg lploss: 0.00000
==> test epoch 145 avg loss: 1.20964 (A-MSE: 1.04941) avg lploss: 0.00000
*** Best Val Loss: 0.89351 	 Best Test Loss: 1.03172 	 Best epoch 135
EarlyStopping counter: 2 out of 50
train epoch 146 avg loss: 0.82868 (A-MSE: 0.72874) avg lploss: 0.00000
train epoch 147 avg loss: 0.80522 (A-MSE: 0.69639) avg lploss: 0.00000
train epoch 148 avg loss: 0.70632 (A-MSE: 0.61372) avg lploss: 0.00000
train epoch 149 avg loss: 0.64110 (A-MSE: 0.55222) avg lploss: 0.00000
train epoch 150 avg loss: 0.73958 (A-MSE: 0.64728) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.94844 (A-MSE: 0.82323) avg lploss: 0.00000
==> test epoch 150 avg loss: 0.97042 (A-MSE: 0.86542) avg lploss: 0.00000
*** Best Val Loss: 0.89351 	 Best Test Loss: 1.03172 	 Best epoch 135
EarlyStopping counter: 3 out of 50
train epoch 151 avg loss: 0.74129 (A-MSE: 0.64525) avg lploss: 0.00000
train epoch 152 avg loss: 0.72733 (A-MSE: 0.63230) avg lploss: 0.00000
train epoch 153 avg loss: 0.64565 (A-MSE: 0.56278) avg lploss: 0.00000
train epoch 154 avg loss: 0.63758 (A-MSE: 0.55246) avg lploss: 0.00000
train epoch 155 avg loss: 0.63811 (A-MSE: 0.55249) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.77932 (A-MSE: 0.68067) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.93277 (A-MSE: 0.84691) avg lploss: 0.00000
*** Best Val Loss: 0.77932 	 Best Test Loss: 0.93277 	 Best epoch 155
Validation loss decreased (0.893513 --> 0.779318).  Saving model ...
train epoch 156 avg loss: 0.72610 (A-MSE: 0.63334) avg lploss: 0.00000
train epoch 157 avg loss: 0.63577 (A-MSE: 0.54837) avg lploss: 0.00000
train epoch 158 avg loss: 0.59455 (A-MSE: 0.52182) avg lploss: 0.00000
train epoch 159 avg loss: 0.67115 (A-MSE: 0.58427) avg lploss: 0.00000
train epoch 160 avg loss: 0.65230 (A-MSE: 0.56785) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.78327 (A-MSE: 0.68414) avg lploss: 0.00000
==> test epoch 160 avg loss: 0.88497 (A-MSE: 0.79621) avg lploss: 0.00000
*** Best Val Loss: 0.77932 	 Best Test Loss: 0.93277 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 0.61496 (A-MSE: 0.53896) avg lploss: 0.00000
train epoch 162 avg loss: 0.65087 (A-MSE: 0.56745) avg lploss: 0.00000
train epoch 163 avg loss: 0.68775 (A-MSE: 0.58965) avg lploss: 0.00000
train epoch 164 avg loss: 0.66257 (A-MSE: 0.57652) avg lploss: 0.00000
train epoch 165 avg loss: 0.62227 (A-MSE: 0.53475) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.83592 (A-MSE: 0.73446) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.94328 (A-MSE: 0.85025) avg lploss: 0.00000
*** Best Val Loss: 0.77932 	 Best Test Loss: 0.93277 	 Best epoch 155
EarlyStopping counter: 2 out of 50
train epoch 166 avg loss: 0.59508 (A-MSE: 0.52318) avg lploss: 0.00000
train epoch 167 avg loss: 0.62794 (A-MSE: 0.54932) avg lploss: 0.00000
train epoch 168 avg loss: 0.57952 (A-MSE: 0.50257) avg lploss: 0.00000
train epoch 169 avg loss: 0.58224 (A-MSE: 0.50203) avg lploss: 0.00000
train epoch 170 avg loss: 0.52645 (A-MSE: 0.45781) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.81007 (A-MSE: 0.69905) avg lploss: 0.00000
==> test epoch 170 avg loss: 0.85680 (A-MSE: 0.76574) avg lploss: 0.00000
*** Best Val Loss: 0.77932 	 Best Test Loss: 0.93277 	 Best epoch 155
EarlyStopping counter: 3 out of 50
train epoch 171 avg loss: 0.56414 (A-MSE: 0.48852) avg lploss: 0.00000
train epoch 172 avg loss: 0.56846 (A-MSE: 0.49244) avg lploss: 0.00000
train epoch 173 avg loss: 0.55470 (A-MSE: 0.48302) avg lploss: 0.00000
train epoch 174 avg loss: 0.55724 (A-MSE: 0.48471) avg lploss: 0.00000
train epoch 175 avg loss: 0.55739 (A-MSE: 0.48667) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.73876 (A-MSE: 0.64615) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.86491 (A-MSE: 0.78783) avg lploss: 0.00000
*** Best Val Loss: 0.73876 	 Best Test Loss: 0.86491 	 Best epoch 175
Validation loss decreased (0.779318 --> 0.738759).  Saving model ...
train epoch 176 avg loss: 0.70557 (A-MSE: 0.61797) avg lploss: 0.00000
train epoch 177 avg loss: 0.67412 (A-MSE: 0.58505) avg lploss: 0.00000
train epoch 178 avg loss: 0.57518 (A-MSE: 0.49887) avg lploss: 0.00000
train epoch 179 avg loss: 0.59367 (A-MSE: 0.52232) avg lploss: 0.00000
train epoch 180 avg loss: 0.55296 (A-MSE: 0.48042) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.67519 (A-MSE: 0.58928) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.76460 (A-MSE: 0.69149) avg lploss: 0.00000
*** Best Val Loss: 0.67519 	 Best Test Loss: 0.76460 	 Best epoch 180
Validation loss decreased (0.738759 --> 0.675194).  Saving model ...
train epoch 181 avg loss: 0.58954 (A-MSE: 0.51036) avg lploss: 0.00000
train epoch 182 avg loss: 0.58515 (A-MSE: 0.51371) avg lploss: 0.00000
train epoch 183 avg loss: 0.55526 (A-MSE: 0.48052) avg lploss: 0.00000
train epoch 184 avg loss: 0.56813 (A-MSE: 0.49330) avg lploss: 0.00000
train epoch 185 avg loss: 0.57059 (A-MSE: 0.50229) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.85921 (A-MSE: 0.72980) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.92472 (A-MSE: 0.80878) avg lploss: 0.00000
*** Best Val Loss: 0.67519 	 Best Test Loss: 0.76460 	 Best epoch 180
EarlyStopping counter: 1 out of 50
train epoch 186 avg loss: 0.58492 (A-MSE: 0.50670) avg lploss: 0.00000
train epoch 187 avg loss: 0.59087 (A-MSE: 0.51199) avg lploss: 0.00000
train epoch 188 avg loss: 0.53981 (A-MSE: 0.47146) avg lploss: 0.00000
train epoch 189 avg loss: 0.56646 (A-MSE: 0.49276) avg lploss: 0.00000
train epoch 190 avg loss: 0.54868 (A-MSE: 0.47770) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.67065 (A-MSE: 0.58392) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.81027 (A-MSE: 0.73276) avg lploss: 0.00000
*** Best Val Loss: 0.67065 	 Best Test Loss: 0.81027 	 Best epoch 190
Validation loss decreased (0.675194 --> 0.670653).  Saving model ...
train epoch 191 avg loss: 0.49690 (A-MSE: 0.43291) avg lploss: 0.00000
train epoch 192 avg loss: 0.50658 (A-MSE: 0.44248) avg lploss: 0.00000
train epoch 193 avg loss: 0.53859 (A-MSE: 0.46973) avg lploss: 0.00000
train epoch 194 avg loss: 0.51871 (A-MSE: 0.44938) avg lploss: 0.00000
train epoch 195 avg loss: 0.52178 (A-MSE: 0.45782) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.64853 (A-MSE: 0.55161) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.75214 (A-MSE: 0.67098) avg lploss: 0.00000
*** Best Val Loss: 0.64853 	 Best Test Loss: 0.75214 	 Best epoch 195
Validation loss decreased (0.670653 --> 0.648528).  Saving model ...
train epoch 196 avg loss: 0.54479 (A-MSE: 0.47352) avg lploss: 0.00000
train epoch 197 avg loss: 0.56739 (A-MSE: 0.49331) avg lploss: 0.00000
train epoch 198 avg loss: 0.54844 (A-MSE: 0.47719) avg lploss: 0.00000
train epoch 199 avg loss: 0.53937 (A-MSE: 0.47182) avg lploss: 0.00000
train epoch 200 avg loss: 0.53867 (A-MSE: 0.47094) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.62760 (A-MSE: 0.54286) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.76892 (A-MSE: 0.69138) avg lploss: 0.00000
*** Best Val Loss: 0.62760 	 Best Test Loss: 0.76892 	 Best epoch 200
Validation loss decreased (0.648528 --> 0.627597).  Saving model ...
train epoch 201 avg loss: 0.51082 (A-MSE: 0.44437) avg lploss: 0.00000
train epoch 202 avg loss: 0.54786 (A-MSE: 0.47634) avg lploss: 0.00000
train epoch 203 avg loss: 0.53083 (A-MSE: 0.46510) avg lploss: 0.00000
train epoch 204 avg loss: 0.51598 (A-MSE: 0.45102) avg lploss: 0.00000
train epoch 205 avg loss: 0.48224 (A-MSE: 0.42324) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.65514 (A-MSE: 0.56345) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.74199 (A-MSE: 0.66788) avg lploss: 0.00000
*** Best Val Loss: 0.62760 	 Best Test Loss: 0.76892 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 0.48933 (A-MSE: 0.42252) avg lploss: 0.00000
train epoch 207 avg loss: 0.49172 (A-MSE: 0.42879) avg lploss: 0.00000
train epoch 208 avg loss: 0.51022 (A-MSE: 0.44301) avg lploss: 0.00000
train epoch 209 avg loss: 0.47704 (A-MSE: 0.41727) avg lploss: 0.00000
train epoch 210 avg loss: 0.51926 (A-MSE: 0.45114) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.75266 (A-MSE: 0.64023) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.91874 (A-MSE: 0.82056) avg lploss: 0.00000
*** Best Val Loss: 0.62760 	 Best Test Loss: 0.76892 	 Best epoch 200
EarlyStopping counter: 2 out of 50
train epoch 211 avg loss: 0.50132 (A-MSE: 0.43989) avg lploss: 0.00000
train epoch 212 avg loss: 0.45849 (A-MSE: 0.39796) avg lploss: 0.00000
train epoch 213 avg loss: 0.49693 (A-MSE: 0.43173) avg lploss: 0.00000
train epoch 214 avg loss: 0.58695 (A-MSE: 0.50586) avg lploss: 0.00000
train epoch 215 avg loss: 0.54293 (A-MSE: 0.47481) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.79774 (A-MSE: 0.69913) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.79031 (A-MSE: 0.71317) avg lploss: 0.00000
*** Best Val Loss: 0.62760 	 Best Test Loss: 0.76892 	 Best epoch 200
EarlyStopping counter: 3 out of 50
train epoch 216 avg loss: 0.51136 (A-MSE: 0.45046) avg lploss: 0.00000
train epoch 217 avg loss: 0.45171 (A-MSE: 0.39443) avg lploss: 0.00000
train epoch 218 avg loss: 0.49458 (A-MSE: 0.43074) avg lploss: 0.00000
train epoch 219 avg loss: 0.51060 (A-MSE: 0.44363) avg lploss: 0.00000
train epoch 220 avg loss: 0.43774 (A-MSE: 0.38397) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.65881 (A-MSE: 0.55693) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.70945 (A-MSE: 0.63006) avg lploss: 0.00000
*** Best Val Loss: 0.62760 	 Best Test Loss: 0.76892 	 Best epoch 200
EarlyStopping counter: 4 out of 50
train epoch 221 avg loss: 0.51399 (A-MSE: 0.44731) avg lploss: 0.00000
train epoch 222 avg loss: 0.59511 (A-MSE: 0.52092) avg lploss: 0.00000
train epoch 223 avg loss: 0.44151 (A-MSE: 0.38725) avg lploss: 0.00000
train epoch 224 avg loss: 0.42378 (A-MSE: 0.37134) avg lploss: 0.00000
train epoch 225 avg loss: 0.45368 (A-MSE: 0.39641) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.61658 (A-MSE: 0.52391) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.76587 (A-MSE: 0.68124) avg lploss: 0.00000
*** Best Val Loss: 0.61658 	 Best Test Loss: 0.76587 	 Best epoch 225
Validation loss decreased (0.627597 --> 0.616580).  Saving model ...
train epoch 226 avg loss: 0.47967 (A-MSE: 0.41705) avg lploss: 0.00000
train epoch 227 avg loss: 0.48926 (A-MSE: 0.42758) avg lploss: 0.00000
train epoch 228 avg loss: 0.47679 (A-MSE: 0.41508) avg lploss: 0.00000
train epoch 229 avg loss: 0.50750 (A-MSE: 0.44714) avg lploss: 0.00000
train epoch 230 avg loss: 0.45665 (A-MSE: 0.39680) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.69584 (A-MSE: 0.62040) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.84755 (A-MSE: 0.78708) avg lploss: 0.00000
*** Best Val Loss: 0.61658 	 Best Test Loss: 0.76587 	 Best epoch 225
EarlyStopping counter: 1 out of 50
train epoch 231 avg loss: 0.52373 (A-MSE: 0.45836) avg lploss: 0.00000
train epoch 232 avg loss: 0.48646 (A-MSE: 0.42767) avg lploss: 0.00000
train epoch 233 avg loss: 0.41444 (A-MSE: 0.35925) avg lploss: 0.00000
train epoch 234 avg loss: 0.43141 (A-MSE: 0.37874) avg lploss: 0.00000
train epoch 235 avg loss: 0.42350 (A-MSE: 0.37257) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.56722 (A-MSE: 0.48292) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.66700 (A-MSE: 0.59901) avg lploss: 0.00000
*** Best Val Loss: 0.56722 	 Best Test Loss: 0.66700 	 Best epoch 235
Validation loss decreased (0.616580 --> 0.567215).  Saving model ...
train epoch 236 avg loss: 0.38753 (A-MSE: 0.33536) avg lploss: 0.00000
train epoch 237 avg loss: 0.38638 (A-MSE: 0.33378) avg lploss: 0.00000
train epoch 238 avg loss: 0.40639 (A-MSE: 0.35488) avg lploss: 0.00000
train epoch 239 avg loss: 0.41345 (A-MSE: 0.36060) avg lploss: 0.00000
train epoch 240 avg loss: 0.40364 (A-MSE: 0.35079) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.65454 (A-MSE: 0.58327) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.78661 (A-MSE: 0.72956) avg lploss: 0.00000
*** Best Val Loss: 0.56722 	 Best Test Loss: 0.66700 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.47752 (A-MSE: 0.41855) avg lploss: 0.00000
train epoch 242 avg loss: 0.50905 (A-MSE: 0.44896) avg lploss: 0.00000
train epoch 243 avg loss: 0.44368 (A-MSE: 0.38597) avg lploss: 0.00000
train epoch 244 avg loss: 0.45070 (A-MSE: 0.39243) avg lploss: 0.00000
train epoch 245 avg loss: 0.41105 (A-MSE: 0.35988) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.60108 (A-MSE: 0.51698) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.67938 (A-MSE: 0.61399) avg lploss: 0.00000
*** Best Val Loss: 0.56722 	 Best Test Loss: 0.66700 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.40794 (A-MSE: 0.35910) avg lploss: 0.00000
train epoch 247 avg loss: 0.41883 (A-MSE: 0.36392) avg lploss: 0.00000
train epoch 248 avg loss: 0.42309 (A-MSE: 0.37224) avg lploss: 0.00000
train epoch 249 avg loss: 0.38982 (A-MSE: 0.33987) avg lploss: 0.00000
train epoch 250 avg loss: 0.41690 (A-MSE: 0.36524) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.60408 (A-MSE: 0.52210) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.71144 (A-MSE: 0.64169) avg lploss: 0.00000
*** Best Val Loss: 0.56722 	 Best Test Loss: 0.66700 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 0.39213 (A-MSE: 0.33983) avg lploss: 0.00000
train epoch 252 avg loss: 0.38771 (A-MSE: 0.33927) avg lploss: 0.00000
train epoch 253 avg loss: 0.37521 (A-MSE: 0.32774) avg lploss: 0.00000
train epoch 254 avg loss: 0.40993 (A-MSE: 0.35594) avg lploss: 0.00000
train epoch 255 avg loss: 0.41602 (A-MSE: 0.36668) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.59358 (A-MSE: 0.50949) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.63045 (A-MSE: 0.56565) avg lploss: 0.00000
*** Best Val Loss: 0.56722 	 Best Test Loss: 0.66700 	 Best epoch 235
EarlyStopping counter: 4 out of 50
train epoch 256 avg loss: 0.48125 (A-MSE: 0.41799) avg lploss: 0.00000
train epoch 257 avg loss: 0.46148 (A-MSE: 0.41077) avg lploss: 0.00000
train epoch 258 avg loss: 0.44229 (A-MSE: 0.38790) avg lploss: 0.00000
train epoch 259 avg loss: 0.43388 (A-MSE: 0.37643) avg lploss: 0.00000
train epoch 260 avg loss: 0.38360 (A-MSE: 0.33531) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.56619 (A-MSE: 0.48257) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.62614 (A-MSE: 0.55755) avg lploss: 0.00000
*** Best Val Loss: 0.56619 	 Best Test Loss: 0.62614 	 Best epoch 260
Validation loss decreased (0.567215 --> 0.566185).  Saving model ...
train epoch 261 avg loss: 0.38338 (A-MSE: 0.33624) avg lploss: 0.00000
train epoch 262 avg loss: 0.40835 (A-MSE: 0.35853) avg lploss: 0.00000
train epoch 263 avg loss: 0.39975 (A-MSE: 0.34843) avg lploss: 0.00000
train epoch 264 avg loss: 0.37808 (A-MSE: 0.33180) avg lploss: 0.00000
train epoch 265 avg loss: 0.38905 (A-MSE: 0.34215) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.61019 (A-MSE: 0.51971) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.67043 (A-MSE: 0.59816) avg lploss: 0.00000
*** Best Val Loss: 0.56619 	 Best Test Loss: 0.62614 	 Best epoch 260
EarlyStopping counter: 1 out of 50
train epoch 266 avg loss: 0.35035 (A-MSE: 0.30458) avg lploss: 0.00000
train epoch 267 avg loss: 0.36425 (A-MSE: 0.31899) avg lploss: 0.00000
train epoch 268 avg loss: 0.40111 (A-MSE: 0.35089) avg lploss: 0.00000
train epoch 269 avg loss: 0.39145 (A-MSE: 0.34503) avg lploss: 0.00000
train epoch 270 avg loss: 0.43290 (A-MSE: 0.38036) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.61592 (A-MSE: 0.52907) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.64680 (A-MSE: 0.58269) avg lploss: 0.00000
*** Best Val Loss: 0.56619 	 Best Test Loss: 0.62614 	 Best epoch 260
EarlyStopping counter: 2 out of 50
train epoch 271 avg loss: 0.40660 (A-MSE: 0.35676) avg lploss: 0.00000
train epoch 272 avg loss: 0.42186 (A-MSE: 0.37146) avg lploss: 0.00000
train epoch 273 avg loss: 0.39660 (A-MSE: 0.34468) avg lploss: 0.00000
train epoch 274 avg loss: 0.36965 (A-MSE: 0.32131) avg lploss: 0.00000
train epoch 275 avg loss: 0.37547 (A-MSE: 0.32926) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.57703 (A-MSE: 0.49721) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.66405 (A-MSE: 0.59912) avg lploss: 0.00000
*** Best Val Loss: 0.56619 	 Best Test Loss: 0.62614 	 Best epoch 260
EarlyStopping counter: 3 out of 50
train epoch 276 avg loss: 0.36840 (A-MSE: 0.32171) avg lploss: 0.00000
train epoch 277 avg loss: 0.39155 (A-MSE: 0.34109) avg lploss: 0.00000
train epoch 278 avg loss: 0.33056 (A-MSE: 0.28941) avg lploss: 0.00000
train epoch 279 avg loss: 0.34167 (A-MSE: 0.29818) avg lploss: 0.00000
train epoch 280 avg loss: 0.32349 (A-MSE: 0.28030) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.58885 (A-MSE: 0.51007) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.62018 (A-MSE: 0.55919) avg lploss: 0.00000
*** Best Val Loss: 0.56619 	 Best Test Loss: 0.62614 	 Best epoch 260
EarlyStopping counter: 4 out of 50
train epoch 281 avg loss: 0.34288 (A-MSE: 0.29911) avg lploss: 0.00000
train epoch 282 avg loss: 0.30763 (A-MSE: 0.26917) avg lploss: 0.00000
train epoch 283 avg loss: 0.35331 (A-MSE: 0.31024) avg lploss: 0.00000
train epoch 284 avg loss: 0.39354 (A-MSE: 0.34766) avg lploss: 0.00000
train epoch 285 avg loss: 0.38346 (A-MSE: 0.33568) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.62164 (A-MSE: 0.53924) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.60620 (A-MSE: 0.54557) avg lploss: 0.00000
*** Best Val Loss: 0.56619 	 Best Test Loss: 0.62614 	 Best epoch 260
EarlyStopping counter: 5 out of 50
train epoch 286 avg loss: 0.35549 (A-MSE: 0.31284) avg lploss: 0.00000
train epoch 287 avg loss: 0.36500 (A-MSE: 0.31789) avg lploss: 0.00000
train epoch 288 avg loss: 0.33801 (A-MSE: 0.29487) avg lploss: 0.00000
train epoch 289 avg loss: 0.37241 (A-MSE: 0.32745) avg lploss: 0.00000
train epoch 290 avg loss: 0.34654 (A-MSE: 0.30551) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.50419 (A-MSE: 0.43291) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.62477 (A-MSE: 0.56191) avg lploss: 0.00000
*** Best Val Loss: 0.50419 	 Best Test Loss: 0.62477 	 Best epoch 290
Validation loss decreased (0.566185 --> 0.504192).  Saving model ...
train epoch 291 avg loss: 0.34980 (A-MSE: 0.30603) avg lploss: 0.00000
train epoch 292 avg loss: 0.31521 (A-MSE: 0.27601) avg lploss: 0.00000
train epoch 293 avg loss: 0.32515 (A-MSE: 0.28489) avg lploss: 0.00000
train epoch 294 avg loss: 0.32751 (A-MSE: 0.28657) avg lploss: 0.00000
train epoch 295 avg loss: 0.33076 (A-MSE: 0.29174) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.62696 (A-MSE: 0.52993) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.60395 (A-MSE: 0.53251) avg lploss: 0.00000
*** Best Val Loss: 0.50419 	 Best Test Loss: 0.62477 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 0.37912 (A-MSE: 0.33187) avg lploss: 0.00000
train epoch 297 avg loss: 0.37132 (A-MSE: 0.32379) avg lploss: 0.00000
train epoch 298 avg loss: 0.35465 (A-MSE: 0.31214) avg lploss: 0.00000
train epoch 299 avg loss: 0.33905 (A-MSE: 0.29735) avg lploss: 0.00000
train epoch 300 avg loss: 0.33265 (A-MSE: 0.29120) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.49987 (A-MSE: 0.42772) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.57744 (A-MSE: 0.52074) avg lploss: 0.00000
*** Best Val Loss: 0.49987 	 Best Test Loss: 0.57744 	 Best epoch 300
Validation loss decreased (0.504192 --> 0.499872).  Saving model ...
train epoch 301 avg loss: 0.31299 (A-MSE: 0.27555) avg lploss: 0.00000
train epoch 302 avg loss: 0.32678 (A-MSE: 0.28584) avg lploss: 0.00000
train epoch 303 avg loss: 0.35908 (A-MSE: 0.31592) avg lploss: 0.00000
train epoch 304 avg loss: 0.31547 (A-MSE: 0.27596) avg lploss: 0.00000
train epoch 305 avg loss: 0.30848 (A-MSE: 0.27288) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.47329 (A-MSE: 0.40272) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.52214 (A-MSE: 0.47097) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
Validation loss decreased (0.499872 --> 0.473288).  Saving model ...
train epoch 306 avg loss: 0.34028 (A-MSE: 0.30131) avg lploss: 0.00000
train epoch 307 avg loss: 0.37269 (A-MSE: 0.32610) avg lploss: 0.00000
train epoch 308 avg loss: 0.32885 (A-MSE: 0.28628) avg lploss: 0.00000
train epoch 309 avg loss: 0.32290 (A-MSE: 0.28349) avg lploss: 0.00000
train epoch 310 avg loss: 0.34100 (A-MSE: 0.30290) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.68581 (A-MSE: 0.60567) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.72859 (A-MSE: 0.66732) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
EarlyStopping counter: 1 out of 50
train epoch 311 avg loss: 0.33926 (A-MSE: 0.29580) avg lploss: 0.00000
train epoch 312 avg loss: 0.31889 (A-MSE: 0.27917) avg lploss: 0.00000
train epoch 313 avg loss: 0.31928 (A-MSE: 0.28159) avg lploss: 0.00000
train epoch 314 avg loss: 0.30932 (A-MSE: 0.27031) avg lploss: 0.00000
train epoch 315 avg loss: 0.32902 (A-MSE: 0.28995) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.74662 (A-MSE: 0.63496) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.72383 (A-MSE: 0.63294) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
EarlyStopping counter: 2 out of 50
train epoch 316 avg loss: 0.40742 (A-MSE: 0.35681) avg lploss: 0.00000
train epoch 317 avg loss: 0.31237 (A-MSE: 0.27540) avg lploss: 0.00000
train epoch 318 avg loss: 0.29158 (A-MSE: 0.25629) avg lploss: 0.00000
train epoch 319 avg loss: 0.32121 (A-MSE: 0.27863) avg lploss: 0.00000
train epoch 320 avg loss: 0.32235 (A-MSE: 0.28350) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.48045 (A-MSE: 0.40407) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.51424 (A-MSE: 0.45838) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
EarlyStopping counter: 3 out of 50
train epoch 321 avg loss: 0.30962 (A-MSE: 0.27411) avg lploss: 0.00000
train epoch 322 avg loss: 0.34126 (A-MSE: 0.29940) avg lploss: 0.00000
train epoch 323 avg loss: 0.32431 (A-MSE: 0.28472) avg lploss: 0.00000
train epoch 324 avg loss: 0.32201 (A-MSE: 0.28462) avg lploss: 0.00000
train epoch 325 avg loss: 0.38305 (A-MSE: 0.33239) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.56686 (A-MSE: 0.48578) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.60355 (A-MSE: 0.53845) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
EarlyStopping counter: 4 out of 50
train epoch 326 avg loss: 0.34017 (A-MSE: 0.30184) avg lploss: 0.00000
train epoch 327 avg loss: 0.31173 (A-MSE: 0.27474) avg lploss: 0.00000
train epoch 328 avg loss: 0.28723 (A-MSE: 0.25050) avg lploss: 0.00000
train epoch 329 avg loss: 0.34763 (A-MSE: 0.30479) avg lploss: 0.00000
train epoch 330 avg loss: 0.27826 (A-MSE: 0.24590) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.56892 (A-MSE: 0.48029) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.58715 (A-MSE: 0.51694) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
EarlyStopping counter: 5 out of 50
train epoch 331 avg loss: 0.32455 (A-MSE: 0.28614) avg lploss: 0.00000
train epoch 332 avg loss: 0.29516 (A-MSE: 0.26178) avg lploss: 0.00000
train epoch 333 avg loss: 0.35597 (A-MSE: 0.31313) avg lploss: 0.00000
train epoch 334 avg loss: 0.36580 (A-MSE: 0.32210) avg lploss: 0.00000
train epoch 335 avg loss: 0.36894 (A-MSE: 0.32497) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.48751 (A-MSE: 0.41873) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.54194 (A-MSE: 0.49077) avg lploss: 0.00000
*** Best Val Loss: 0.47329 	 Best Test Loss: 0.52214 	 Best epoch 305
EarlyStopping counter: 6 out of 50
train epoch 336 avg loss: 0.36836 (A-MSE: 0.33082) avg lploss: 0.00000
train epoch 337 avg loss: 0.39428 (A-MSE: 0.34465) avg lploss: 0.00000
train epoch 338 avg loss: 0.29728 (A-MSE: 0.26358) avg lploss: 0.00000
train epoch 339 avg loss: 0.29190 (A-MSE: 0.25549) avg lploss: 0.00000
train epoch 340 avg loss: 0.27241 (A-MSE: 0.23865) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.45195 (A-MSE: 0.38769) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.55664 (A-MSE: 0.50290) avg lploss: 0.00000
*** Best Val Loss: 0.45195 	 Best Test Loss: 0.55664 	 Best epoch 340
Validation loss decreased (0.473288 --> 0.451949).  Saving model ...
train epoch 341 avg loss: 0.29796 (A-MSE: 0.26316) avg lploss: 0.00000
train epoch 342 avg loss: 0.34289 (A-MSE: 0.30287) avg lploss: 0.00000
train epoch 343 avg loss: 0.30418 (A-MSE: 0.26692) avg lploss: 0.00000
train epoch 344 avg loss: 0.28518 (A-MSE: 0.25314) avg lploss: 0.00000
train epoch 345 avg loss: 0.28704 (A-MSE: 0.25515) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.46565 (A-MSE: 0.38864) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.53308 (A-MSE: 0.47010) avg lploss: 0.00000
*** Best Val Loss: 0.45195 	 Best Test Loss: 0.55664 	 Best epoch 340
EarlyStopping counter: 1 out of 50
train epoch 346 avg loss: 0.28421 (A-MSE: 0.25008) avg lploss: 0.00000
train epoch 347 avg loss: 0.30248 (A-MSE: 0.26389) avg lploss: 0.00000
train epoch 348 avg loss: 0.29836 (A-MSE: 0.26152) avg lploss: 0.00000
train epoch 349 avg loss: 0.29368 (A-MSE: 0.25807) avg lploss: 0.00000
train epoch 350 avg loss: 0.27451 (A-MSE: 0.23930) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.42147 (A-MSE: 0.36430) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.48376 (A-MSE: 0.44127) avg lploss: 0.00000
*** Best Val Loss: 0.42147 	 Best Test Loss: 0.48376 	 Best epoch 350
Validation loss decreased (0.451949 --> 0.421472).  Saving model ...
train epoch 351 avg loss: 0.27496 (A-MSE: 0.24515) avg lploss: 0.00000
train epoch 352 avg loss: 0.26569 (A-MSE: 0.23097) avg lploss: 0.00000
train epoch 353 avg loss: 0.26636 (A-MSE: 0.23558) avg lploss: 0.00000
train epoch 354 avg loss: 0.31800 (A-MSE: 0.27895) avg lploss: 0.00000
train epoch 355 avg loss: 0.26372 (A-MSE: 0.23184) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.54055 (A-MSE: 0.44895) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.55616 (A-MSE: 0.48229) avg lploss: 0.00000
*** Best Val Loss: 0.42147 	 Best Test Loss: 0.48376 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.26610 (A-MSE: 0.23335) avg lploss: 0.00000
train epoch 357 avg loss: 0.29144 (A-MSE: 0.25766) avg lploss: 0.00000
train epoch 358 avg loss: 0.32023 (A-MSE: 0.28287) avg lploss: 0.00000
train epoch 359 avg loss: 0.28260 (A-MSE: 0.24783) avg lploss: 0.00000
train epoch 360 avg loss: 0.29270 (A-MSE: 0.25727) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.48809 (A-MSE: 0.41941) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.56326 (A-MSE: 0.50937) avg lploss: 0.00000
*** Best Val Loss: 0.42147 	 Best Test Loss: 0.48376 	 Best epoch 350
EarlyStopping counter: 2 out of 50
train epoch 361 avg loss: 0.26708 (A-MSE: 0.23489) avg lploss: 0.00000
train epoch 362 avg loss: 0.26769 (A-MSE: 0.23625) avg lploss: 0.00000
train epoch 363 avg loss: 0.33314 (A-MSE: 0.29305) avg lploss: 0.00000
train epoch 364 avg loss: 0.31137 (A-MSE: 0.27448) avg lploss: 0.00000
train epoch 365 avg loss: 0.30196 (A-MSE: 0.26601) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.49143 (A-MSE: 0.41874) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.52835 (A-MSE: 0.47532) avg lploss: 0.00000
*** Best Val Loss: 0.42147 	 Best Test Loss: 0.48376 	 Best epoch 350
EarlyStopping counter: 3 out of 50
train epoch 366 avg loss: 0.27193 (A-MSE: 0.24012) avg lploss: 0.00000
train epoch 367 avg loss: 0.25323 (A-MSE: 0.22318) avg lploss: 0.00000
train epoch 368 avg loss: 0.26115 (A-MSE: 0.23079) avg lploss: 0.00000
train epoch 369 avg loss: 0.24450 (A-MSE: 0.21391) avg lploss: 0.00000
train epoch 370 avg loss: 0.29204 (A-MSE: 0.25841) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.49428 (A-MSE: 0.41852) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.56714 (A-MSE: 0.50255) avg lploss: 0.00000
*** Best Val Loss: 0.42147 	 Best Test Loss: 0.48376 	 Best epoch 350
EarlyStopping counter: 4 out of 50
train epoch 371 avg loss: 0.25637 (A-MSE: 0.22485) avg lploss: 0.00000
train epoch 372 avg loss: 0.23341 (A-MSE: 0.20471) avg lploss: 0.00000
train epoch 373 avg loss: 0.24287 (A-MSE: 0.21405) avg lploss: 0.00000
train epoch 374 avg loss: 0.26435 (A-MSE: 0.23320) avg lploss: 0.00000
train epoch 375 avg loss: 0.26293 (A-MSE: 0.23127) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.50500 (A-MSE: 0.42998) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.54669 (A-MSE: 0.48310) avg lploss: 0.00000
*** Best Val Loss: 0.42147 	 Best Test Loss: 0.48376 	 Best epoch 350
EarlyStopping counter: 5 out of 50
train epoch 376 avg loss: 0.22552 (A-MSE: 0.19898) avg lploss: 0.00000
train epoch 377 avg loss: 0.26189 (A-MSE: 0.22889) avg lploss: 0.00000
train epoch 378 avg loss: 0.26538 (A-MSE: 0.23670) avg lploss: 0.00000
train epoch 379 avg loss: 0.25571 (A-MSE: 0.22552) avg lploss: 0.00000
train epoch 380 avg loss: 0.24073 (A-MSE: 0.21234) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.40456 (A-MSE: 0.34315) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.49066 (A-MSE: 0.43558) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
Validation loss decreased (0.421472 --> 0.404555).  Saving model ...
train epoch 381 avg loss: 0.27120 (A-MSE: 0.23927) avg lploss: 0.00000
train epoch 382 avg loss: 0.42272 (A-MSE: 0.37568) avg lploss: 0.00000
train epoch 383 avg loss: 0.29168 (A-MSE: 0.25921) avg lploss: 0.00000
train epoch 384 avg loss: 0.25660 (A-MSE: 0.22563) avg lploss: 0.00000
train epoch 385 avg loss: 0.24579 (A-MSE: 0.21402) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.45802 (A-MSE: 0.39445) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.50472 (A-MSE: 0.45512) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.24523 (A-MSE: 0.21674) avg lploss: 0.00000
train epoch 387 avg loss: 0.24899 (A-MSE: 0.21789) avg lploss: 0.00000
train epoch 388 avg loss: 0.26092 (A-MSE: 0.22986) avg lploss: 0.00000
train epoch 389 avg loss: 0.23461 (A-MSE: 0.20770) avg lploss: 0.00000
train epoch 390 avg loss: 0.24456 (A-MSE: 0.21312) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.45975 (A-MSE: 0.38564) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.50754 (A-MSE: 0.44524) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 2 out of 50
train epoch 391 avg loss: 0.26443 (A-MSE: 0.23556) avg lploss: 0.00000
train epoch 392 avg loss: 0.26987 (A-MSE: 0.23666) avg lploss: 0.00000
train epoch 393 avg loss: 0.29567 (A-MSE: 0.26100) avg lploss: 0.00000
train epoch 394 avg loss: 0.24979 (A-MSE: 0.22036) avg lploss: 0.00000
train epoch 395 avg loss: 0.23884 (A-MSE: 0.21057) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.43398 (A-MSE: 0.36288) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.47194 (A-MSE: 0.41595) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 3 out of 50
train epoch 396 avg loss: 0.24173 (A-MSE: 0.21298) avg lploss: 0.00000
train epoch 397 avg loss: 0.26659 (A-MSE: 0.23788) avg lploss: 0.00000
train epoch 398 avg loss: 0.24365 (A-MSE: 0.21423) avg lploss: 0.00000
train epoch 399 avg loss: 0.21627 (A-MSE: 0.18940) avg lploss: 0.00000
train epoch 400 avg loss: 0.23942 (A-MSE: 0.21155) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.48668 (A-MSE: 0.41113) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.51468 (A-MSE: 0.45224) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 4 out of 50
train epoch 401 avg loss: 0.24710 (A-MSE: 0.21958) avg lploss: 0.00000
train epoch 402 avg loss: 0.34371 (A-MSE: 0.30387) avg lploss: 0.00000
train epoch 403 avg loss: 0.29421 (A-MSE: 0.25865) avg lploss: 0.00000
train epoch 404 avg loss: 0.33189 (A-MSE: 0.29642) avg lploss: 0.00000
train epoch 405 avg loss: 0.34296 (A-MSE: 0.30660) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.59959 (A-MSE: 0.51156) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.60150 (A-MSE: 0.53010) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 5 out of 50
train epoch 406 avg loss: 0.29661 (A-MSE: 0.26080) avg lploss: 0.00000
train epoch 407 avg loss: 0.25534 (A-MSE: 0.22503) avg lploss: 0.00000
train epoch 408 avg loss: 0.25317 (A-MSE: 0.22228) avg lploss: 0.00000
train epoch 409 avg loss: 0.28778 (A-MSE: 0.25545) avg lploss: 0.00000
train epoch 410 avg loss: 0.23417 (A-MSE: 0.20509) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.46661 (A-MSE: 0.39804) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.48251 (A-MSE: 0.42809) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 6 out of 50
train epoch 411 avg loss: 0.21182 (A-MSE: 0.18633) avg lploss: 0.00000
train epoch 412 avg loss: 0.22887 (A-MSE: 0.20336) avg lploss: 0.00000
train epoch 413 avg loss: 0.23271 (A-MSE: 0.20209) avg lploss: 0.00000
train epoch 414 avg loss: 0.22412 (A-MSE: 0.19808) avg lploss: 0.00000
train epoch 415 avg loss: 0.23825 (A-MSE: 0.20921) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.55640 (A-MSE: 0.47685) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.55555 (A-MSE: 0.49271) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 7 out of 50
train epoch 416 avg loss: 0.26294 (A-MSE: 0.23506) avg lploss: 0.00000
train epoch 417 avg loss: 0.23190 (A-MSE: 0.20366) avg lploss: 0.00000
train epoch 418 avg loss: 0.24761 (A-MSE: 0.21722) avg lploss: 0.00000
train epoch 419 avg loss: 0.32355 (A-MSE: 0.28512) avg lploss: 0.00000
train epoch 420 avg loss: 0.24770 (A-MSE: 0.21998) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.47549 (A-MSE: 0.40516) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.49245 (A-MSE: 0.43598) avg lploss: 0.00000
*** Best Val Loss: 0.40456 	 Best Test Loss: 0.49066 	 Best epoch 380
EarlyStopping counter: 8 out of 50
train epoch 421 avg loss: 0.24778 (A-MSE: 0.22062) avg lploss: 0.00000
train epoch 422 avg loss: 0.22200 (A-MSE: 0.19453) avg lploss: 0.00000
train epoch 423 avg loss: 0.23090 (A-MSE: 0.20345) avg lploss: 0.00000
train epoch 424 avg loss: 0.21842 (A-MSE: 0.19309) avg lploss: 0.00000
train epoch 425 avg loss: 0.22109 (A-MSE: 0.19484) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.40380 (A-MSE: 0.34045) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.47631 (A-MSE: 0.42274) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
Validation loss decreased (0.404555 --> 0.403797).  Saving model ...
train epoch 426 avg loss: 0.22391 (A-MSE: 0.19900) avg lploss: 0.00000
train epoch 427 avg loss: 0.22356 (A-MSE: 0.19529) avg lploss: 0.00000
train epoch 428 avg loss: 0.25098 (A-MSE: 0.22064) avg lploss: 0.00000
train epoch 429 avg loss: 0.24758 (A-MSE: 0.21639) avg lploss: 0.00000
train epoch 430 avg loss: 0.25007 (A-MSE: 0.22150) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.50467 (A-MSE: 0.42129) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.55331 (A-MSE: 0.48176) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
EarlyStopping counter: 1 out of 50
train epoch 431 avg loss: 0.20269 (A-MSE: 0.17802) avg lploss: 0.00000
train epoch 432 avg loss: 0.19145 (A-MSE: 0.16840) avg lploss: 0.00000
train epoch 433 avg loss: 0.22876 (A-MSE: 0.20357) avg lploss: 0.00000
train epoch 434 avg loss: 0.22260 (A-MSE: 0.19543) avg lploss: 0.00000
train epoch 435 avg loss: 0.20201 (A-MSE: 0.17709) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.49485 (A-MSE: 0.42186) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.52256 (A-MSE: 0.46278) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
EarlyStopping counter: 2 out of 50
train epoch 436 avg loss: 0.20159 (A-MSE: 0.17748) avg lploss: 0.00000
train epoch 437 avg loss: 0.20215 (A-MSE: 0.17792) avg lploss: 0.00000
train epoch 438 avg loss: 0.20978 (A-MSE: 0.18525) avg lploss: 0.00000
train epoch 439 avg loss: 0.22083 (A-MSE: 0.19486) avg lploss: 0.00000
train epoch 440 avg loss: 0.19512 (A-MSE: 0.17048) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.41465 (A-MSE: 0.35369) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.49651 (A-MSE: 0.44265) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
EarlyStopping counter: 3 out of 50
train epoch 441 avg loss: 0.21385 (A-MSE: 0.18871) avg lploss: 0.00000
train epoch 442 avg loss: 0.22997 (A-MSE: 0.20189) avg lploss: 0.00000
train epoch 443 avg loss: 0.31824 (A-MSE: 0.28918) avg lploss: 0.00000
train epoch 444 avg loss: 0.28839 (A-MSE: 0.25143) avg lploss: 0.00000
train epoch 445 avg loss: 0.26161 (A-MSE: 0.23160) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.48476 (A-MSE: 0.40392) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.53842 (A-MSE: 0.46866) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
EarlyStopping counter: 4 out of 50
train epoch 446 avg loss: 0.20620 (A-MSE: 0.18199) avg lploss: 0.00000
train epoch 447 avg loss: 0.20959 (A-MSE: 0.18373) avg lploss: 0.00000
train epoch 448 avg loss: 0.23057 (A-MSE: 0.20447) avg lploss: 0.00000
train epoch 449 avg loss: 0.21879 (A-MSE: 0.19407) avg lploss: 0.00000
train epoch 450 avg loss: 0.21393 (A-MSE: 0.18772) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.42967 (A-MSE: 0.36545) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.49882 (A-MSE: 0.44323) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
EarlyStopping counter: 5 out of 50
train epoch 451 avg loss: 0.22069 (A-MSE: 0.19597) avg lploss: 0.00000
train epoch 452 avg loss: 0.19362 (A-MSE: 0.17004) avg lploss: 0.00000
train epoch 453 avg loss: 0.18680 (A-MSE: 0.16328) avg lploss: 0.00000
train epoch 454 avg loss: 0.19821 (A-MSE: 0.17386) avg lploss: 0.00000
train epoch 455 avg loss: 0.19655 (A-MSE: 0.17316) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.44152 (A-MSE: 0.37083) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.48999 (A-MSE: 0.42626) avg lploss: 0.00000
*** Best Val Loss: 0.40380 	 Best Test Loss: 0.47631 	 Best epoch 425
EarlyStopping counter: 6 out of 50
train epoch 456 avg loss: 0.18821 (A-MSE: 0.16538) avg lploss: 0.00000
train epoch 457 avg loss: 0.18537 (A-MSE: 0.16417) avg lploss: 0.00000
train epoch 458 avg loss: 0.22690 (A-MSE: 0.20016) avg lploss: 0.00000
train epoch 459 avg loss: 0.19452 (A-MSE: 0.17080) avg lploss: 0.00000
train epoch 460 avg loss: 0.17506 (A-MSE: 0.15449) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.39831 (A-MSE: 0.34284) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.44762 (A-MSE: 0.39918) avg lploss: 0.00000
*** Best Val Loss: 0.39831 	 Best Test Loss: 0.44762 	 Best epoch 460
Validation loss decreased (0.403797 --> 0.398312).  Saving model ...
train epoch 461 avg loss: 0.17148 (A-MSE: 0.15050) avg lploss: 0.00000
train epoch 462 avg loss: 0.21528 (A-MSE: 0.19117) avg lploss: 0.00000
train epoch 463 avg loss: 0.22565 (A-MSE: 0.19956) avg lploss: 0.00000
train epoch 464 avg loss: 0.22320 (A-MSE: 0.19725) avg lploss: 0.00000
train epoch 465 avg loss: 0.20776 (A-MSE: 0.18384) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.56734 (A-MSE: 0.49746) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.60033 (A-MSE: 0.54090) avg lploss: 0.00000
*** Best Val Loss: 0.39831 	 Best Test Loss: 0.44762 	 Best epoch 460
EarlyStopping counter: 1 out of 50
train epoch 466 avg loss: 0.20805 (A-MSE: 0.18416) avg lploss: 0.00000
train epoch 467 avg loss: 0.19811 (A-MSE: 0.17385) avg lploss: 0.00000
train epoch 468 avg loss: 0.19581 (A-MSE: 0.17328) avg lploss: 0.00000
train epoch 469 avg loss: 0.18224 (A-MSE: 0.15967) avg lploss: 0.00000
train epoch 470 avg loss: 0.18885 (A-MSE: 0.16668) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.45176 (A-MSE: 0.37786) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.48561 (A-MSE: 0.42279) avg lploss: 0.00000
*** Best Val Loss: 0.39831 	 Best Test Loss: 0.44762 	 Best epoch 460
EarlyStopping counter: 2 out of 50
train epoch 471 avg loss: 0.18501 (A-MSE: 0.16199) avg lploss: 0.00000
train epoch 472 avg loss: 0.17817 (A-MSE: 0.15657) avg lploss: 0.00000
train epoch 473 avg loss: 0.19029 (A-MSE: 0.16790) avg lploss: 0.00000
train epoch 474 avg loss: 0.19710 (A-MSE: 0.17518) avg lploss: 0.00000
train epoch 475 avg loss: 0.17628 (A-MSE: 0.15541) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.44124 (A-MSE: 0.36901) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.45061 (A-MSE: 0.39446) avg lploss: 0.00000
*** Best Val Loss: 0.39831 	 Best Test Loss: 0.44762 	 Best epoch 460
EarlyStopping counter: 3 out of 50
train epoch 476 avg loss: 0.19138 (A-MSE: 0.16806) avg lploss: 0.00000
train epoch 477 avg loss: 0.19717 (A-MSE: 0.17391) avg lploss: 0.00000
train epoch 478 avg loss: 0.17447 (A-MSE: 0.15326) avg lploss: 0.00000
train epoch 479 avg loss: 0.19328 (A-MSE: 0.17119) avg lploss: 0.00000
train epoch 480 avg loss: 0.20909 (A-MSE: 0.18491) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.39395 (A-MSE: 0.34035) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.43911 (A-MSE: 0.39241) avg lploss: 0.00000
*** Best Val Loss: 0.39395 	 Best Test Loss: 0.43911 	 Best epoch 480
Validation loss decreased (0.398312 --> 0.393954).  Saving model ...
train epoch 481 avg loss: 0.20660 (A-MSE: 0.18172) avg lploss: 0.00000
train epoch 482 avg loss: 0.20984 (A-MSE: 0.18444) avg lploss: 0.00000
train epoch 483 avg loss: 0.22177 (A-MSE: 0.19553) avg lploss: 0.00000
train epoch 484 avg loss: 0.18870 (A-MSE: 0.16527) avg lploss: 0.00000
train epoch 485 avg loss: 0.19151 (A-MSE: 0.17066) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.38610 (A-MSE: 0.32861) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.42293 (A-MSE: 0.37497) avg lploss: 0.00000
*** Best Val Loss: 0.38610 	 Best Test Loss: 0.42293 	 Best epoch 485
Validation loss decreased (0.393954 --> 0.386097).  Saving model ...
train epoch 486 avg loss: 0.19868 (A-MSE: 0.17305) avg lploss: 0.00000
train epoch 487 avg loss: 0.22046 (A-MSE: 0.19519) avg lploss: 0.00000
train epoch 488 avg loss: 0.19040 (A-MSE: 0.16920) avg lploss: 0.00000
train epoch 489 avg loss: 0.20782 (A-MSE: 0.18322) avg lploss: 0.00000
train epoch 490 avg loss: 0.20397 (A-MSE: 0.18106) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.48237 (A-MSE: 0.40890) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.52790 (A-MSE: 0.46200) avg lploss: 0.00000
*** Best Val Loss: 0.38610 	 Best Test Loss: 0.42293 	 Best epoch 485
EarlyStopping counter: 1 out of 50
train epoch 491 avg loss: 0.18614 (A-MSE: 0.16404) avg lploss: 0.00000
train epoch 492 avg loss: 0.18599 (A-MSE: 0.16356) avg lploss: 0.00000
train epoch 493 avg loss: 0.24782 (A-MSE: 0.22184) avg lploss: 0.00000
train epoch 494 avg loss: 0.26080 (A-MSE: 0.23181) avg lploss: 0.00000
train epoch 495 avg loss: 0.32244 (A-MSE: 0.28804) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.48713 (A-MSE: 0.42544) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.50999 (A-MSE: 0.45880) avg lploss: 0.00000
*** Best Val Loss: 0.38610 	 Best Test Loss: 0.42293 	 Best epoch 485
EarlyStopping counter: 2 out of 50
train epoch 496 avg loss: 0.27464 (A-MSE: 0.24187) avg lploss: 0.00000
train epoch 497 avg loss: 0.21571 (A-MSE: 0.19133) avg lploss: 0.00000
train epoch 498 avg loss: 0.19717 (A-MSE: 0.17381) avg lploss: 0.00000
train epoch 499 avg loss: 0.21632 (A-MSE: 0.19132) avg lploss: 0.00000
train epoch 500 avg loss: 0.24287 (A-MSE: 0.21436) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.43631 (A-MSE: 0.36897) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.48553 (A-MSE: 0.42457) avg lploss: 0.00000
*** Best Val Loss: 0.38610 	 Best Test Loss: 0.42293 	 Best epoch 485
EarlyStopping counter: 3 out of 50
train epoch 501 avg loss: 0.20342 (A-MSE: 0.17964) avg lploss: 0.00000
train epoch 502 avg loss: 0.19338 (A-MSE: 0.16901) avg lploss: 0.00000
train epoch 503 avg loss: 0.21116 (A-MSE: 0.18692) avg lploss: 0.00000
train epoch 504 avg loss: 0.18248 (A-MSE: 0.16011) avg lploss: 0.00000
train epoch 505 avg loss: 0.18630 (A-MSE: 0.16429) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.42813 (A-MSE: 0.36168) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.44968 (A-MSE: 0.39634) avg lploss: 0.00000
*** Best Val Loss: 0.38610 	 Best Test Loss: 0.42293 	 Best epoch 485
EarlyStopping counter: 4 out of 50
train epoch 506 avg loss: 0.18165 (A-MSE: 0.16000) avg lploss: 0.00000
train epoch 507 avg loss: 0.20061 (A-MSE: 0.17679) avg lploss: 0.00000
train epoch 508 avg loss: 0.19347 (A-MSE: 0.17038) avg lploss: 0.00000
train epoch 509 avg loss: 0.17327 (A-MSE: 0.15219) avg lploss: 0.00000
train epoch 510 avg loss: 0.21359 (A-MSE: 0.19171) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.40179 (A-MSE: 0.34617) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.47139 (A-MSE: 0.42182) avg lploss: 0.00000
*** Best Val Loss: 0.38610 	 Best Test Loss: 0.42293 	 Best epoch 485
EarlyStopping counter: 5 out of 50
train epoch 511 avg loss: 0.22200 (A-MSE: 0.19650) avg lploss: 0.00000
train epoch 512 avg loss: 0.20689 (A-MSE: 0.18228) avg lploss: 0.00000
train epoch 513 avg loss: 0.19538 (A-MSE: 0.17259) avg lploss: 0.00000
train epoch 514 avg loss: 0.18806 (A-MSE: 0.16629) avg lploss: 0.00000
train epoch 515 avg loss: 0.19448 (A-MSE: 0.17223) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.37928 (A-MSE: 0.32310) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.43909 (A-MSE: 0.38679) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
Validation loss decreased (0.386097 --> 0.379281).  Saving model ...
train epoch 516 avg loss: 0.20122 (A-MSE: 0.17562) avg lploss: 0.00000
train epoch 517 avg loss: 0.18669 (A-MSE: 0.16396) avg lploss: 0.00000
train epoch 518 avg loss: 0.20854 (A-MSE: 0.18467) avg lploss: 0.00000
train epoch 519 avg loss: 0.17225 (A-MSE: 0.15025) avg lploss: 0.00000
train epoch 520 avg loss: 0.16905 (A-MSE: 0.15109) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.46315 (A-MSE: 0.38498) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.47836 (A-MSE: 0.41306) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 1 out of 50
train epoch 521 avg loss: 0.17012 (A-MSE: 0.14963) avg lploss: 0.00000
train epoch 522 avg loss: 0.17342 (A-MSE: 0.15276) avg lploss: 0.00000
train epoch 523 avg loss: 0.14551 (A-MSE: 0.12810) avg lploss: 0.00000
train epoch 524 avg loss: 0.16329 (A-MSE: 0.14382) avg lploss: 0.00000
train epoch 525 avg loss: 0.17722 (A-MSE: 0.15661) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.52647 (A-MSE: 0.45812) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.52358 (A-MSE: 0.46453) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 2 out of 50
train epoch 526 avg loss: 0.25798 (A-MSE: 0.23206) avg lploss: 0.00000
train epoch 527 avg loss: 0.24943 (A-MSE: 0.22228) avg lploss: 0.00000
train epoch 528 avg loss: 0.20229 (A-MSE: 0.17957) avg lploss: 0.00000
train epoch 529 avg loss: 0.19300 (A-MSE: 0.16953) avg lploss: 0.00000
train epoch 530 avg loss: 0.18746 (A-MSE: 0.16680) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.63010 (A-MSE: 0.53632) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.57431 (A-MSE: 0.50186) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 3 out of 50
train epoch 531 avg loss: 0.19593 (A-MSE: 0.17326) avg lploss: 0.00000
train epoch 532 avg loss: 0.19278 (A-MSE: 0.17030) avg lploss: 0.00000
train epoch 533 avg loss: 0.17003 (A-MSE: 0.14915) avg lploss: 0.00000
train epoch 534 avg loss: 0.16001 (A-MSE: 0.14079) avg lploss: 0.00000
train epoch 535 avg loss: 0.17377 (A-MSE: 0.15308) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.40780 (A-MSE: 0.34074) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.46420 (A-MSE: 0.39970) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 4 out of 50
train epoch 536 avg loss: 0.15734 (A-MSE: 0.13886) avg lploss: 0.00000
train epoch 537 avg loss: 0.14159 (A-MSE: 0.12442) avg lploss: 0.00000
train epoch 538 avg loss: 0.14994 (A-MSE: 0.13140) avg lploss: 0.00000
train epoch 539 avg loss: 0.15762 (A-MSE: 0.13885) avg lploss: 0.00000
train epoch 540 avg loss: 0.16447 (A-MSE: 0.14544) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.38363 (A-MSE: 0.31793) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.43601 (A-MSE: 0.37648) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 5 out of 50
train epoch 541 avg loss: 0.17523 (A-MSE: 0.15261) avg lploss: 0.00000
train epoch 542 avg loss: 0.19697 (A-MSE: 0.17394) avg lploss: 0.00000
train epoch 543 avg loss: 0.16324 (A-MSE: 0.14496) avg lploss: 0.00000
train epoch 544 avg loss: 0.20310 (A-MSE: 0.17761) avg lploss: 0.00000
train epoch 545 avg loss: 0.22808 (A-MSE: 0.20388) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.44900 (A-MSE: 0.38567) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.50122 (A-MSE: 0.44184) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 6 out of 50
train epoch 546 avg loss: 0.20625 (A-MSE: 0.18147) avg lploss: 0.00000
train epoch 547 avg loss: 0.21403 (A-MSE: 0.19025) avg lploss: 0.00000
train epoch 548 avg loss: 0.19141 (A-MSE: 0.16940) avg lploss: 0.00000
train epoch 549 avg loss: 0.19320 (A-MSE: 0.17004) avg lploss: 0.00000
train epoch 550 avg loss: 0.16193 (A-MSE: 0.14280) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.44463 (A-MSE: 0.37468) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.46564 (A-MSE: 0.40581) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 7 out of 50
train epoch 551 avg loss: 0.13992 (A-MSE: 0.12367) avg lploss: 0.00000
train epoch 552 avg loss: 0.17100 (A-MSE: 0.15246) avg lploss: 0.00000
train epoch 553 avg loss: 0.19381 (A-MSE: 0.17084) avg lploss: 0.00000
train epoch 554 avg loss: 0.16016 (A-MSE: 0.14114) avg lploss: 0.00000
train epoch 555 avg loss: 0.15603 (A-MSE: 0.13725) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.38743 (A-MSE: 0.33350) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.43470 (A-MSE: 0.38586) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 8 out of 50
train epoch 556 avg loss: 0.16022 (A-MSE: 0.14063) avg lploss: 0.00000
train epoch 557 avg loss: 0.18504 (A-MSE: 0.16329) avg lploss: 0.00000
train epoch 558 avg loss: 0.16776 (A-MSE: 0.14830) avg lploss: 0.00000
train epoch 559 avg loss: 0.20533 (A-MSE: 0.18263) avg lploss: 0.00000
train epoch 560 avg loss: 0.15354 (A-MSE: 0.13518) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.46320 (A-MSE: 0.39185) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.49197 (A-MSE: 0.42869) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 9 out of 50
train epoch 561 avg loss: 0.14742 (A-MSE: 0.12976) avg lploss: 0.00000
train epoch 562 avg loss: 0.14201 (A-MSE: 0.12590) avg lploss: 0.00000
train epoch 563 avg loss: 0.16498 (A-MSE: 0.14655) avg lploss: 0.00000
train epoch 564 avg loss: 0.16474 (A-MSE: 0.14470) avg lploss: 0.00000
train epoch 565 avg loss: 0.18828 (A-MSE: 0.16751) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.40917 (A-MSE: 0.34655) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.43416 (A-MSE: 0.38539) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 10 out of 50
train epoch 566 avg loss: 0.16458 (A-MSE: 0.14507) avg lploss: 0.00000
train epoch 567 avg loss: 0.15868 (A-MSE: 0.14016) avg lploss: 0.00000
train epoch 568 avg loss: 0.15412 (A-MSE: 0.13597) avg lploss: 0.00000
train epoch 569 avg loss: 0.16683 (A-MSE: 0.14721) avg lploss: 0.00000
train epoch 570 avg loss: 0.17498 (A-MSE: 0.15389) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.40584 (A-MSE: 0.34307) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.44881 (A-MSE: 0.38944) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 11 out of 50
train epoch 571 avg loss: 0.14907 (A-MSE: 0.13142) avg lploss: 0.00000
train epoch 572 avg loss: 0.14201 (A-MSE: 0.12557) avg lploss: 0.00000
train epoch 573 avg loss: 0.14553 (A-MSE: 0.12834) avg lploss: 0.00000
train epoch 574 avg loss: 0.19969 (A-MSE: 0.17772) avg lploss: 0.00000
train epoch 575 avg loss: 0.17449 (A-MSE: 0.15401) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.44952 (A-MSE: 0.38335) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.46825 (A-MSE: 0.41245) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 12 out of 50
train epoch 576 avg loss: 0.15022 (A-MSE: 0.13391) avg lploss: 0.00000
train epoch 577 avg loss: 0.16372 (A-MSE: 0.14472) avg lploss: 0.00000
train epoch 578 avg loss: 0.19140 (A-MSE: 0.17000) avg lploss: 0.00000
train epoch 579 avg loss: 0.16446 (A-MSE: 0.14497) avg lploss: 0.00000
train epoch 580 avg loss: 0.16612 (A-MSE: 0.14637) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.40923 (A-MSE: 0.34615) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.44573 (A-MSE: 0.39166) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 13 out of 50
train epoch 581 avg loss: 0.18582 (A-MSE: 0.16466) avg lploss: 0.00000
train epoch 582 avg loss: 0.22975 (A-MSE: 0.20611) avg lploss: 0.00000
train epoch 583 avg loss: 0.20867 (A-MSE: 0.18385) avg lploss: 0.00000
train epoch 584 avg loss: 0.17939 (A-MSE: 0.15820) avg lploss: 0.00000
train epoch 585 avg loss: 0.15371 (A-MSE: 0.13422) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.40029 (A-MSE: 0.33509) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.43288 (A-MSE: 0.37575) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 14 out of 50
train epoch 586 avg loss: 0.13952 (A-MSE: 0.12267) avg lploss: 0.00000
train epoch 587 avg loss: 0.14513 (A-MSE: 0.12697) avg lploss: 0.00000
train epoch 588 avg loss: 0.14706 (A-MSE: 0.12983) avg lploss: 0.00000
train epoch 589 avg loss: 0.17209 (A-MSE: 0.15138) avg lploss: 0.00000
train epoch 590 avg loss: 0.14839 (A-MSE: 0.13072) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.41539 (A-MSE: 0.35017) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.46508 (A-MSE: 0.40368) avg lploss: 0.00000
*** Best Val Loss: 0.37928 	 Best Test Loss: 0.43909 	 Best epoch 515
EarlyStopping counter: 15 out of 50
train epoch 591 avg loss: 0.13914 (A-MSE: 0.12187) avg lploss: 0.00000
train epoch 592 avg loss: 0.14072 (A-MSE: 0.12431) avg lploss: 0.00000
train epoch 593 avg loss: 0.14963 (A-MSE: 0.13274) avg lploss: 0.00000
train epoch 594 avg loss: 0.13201 (A-MSE: 0.11670) avg lploss: 0.00000
train epoch 595 avg loss: 0.13555 (A-MSE: 0.11993) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.37127 (A-MSE: 0.30960) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.41759 (A-MSE: 0.36437) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
Validation loss decreased (0.379281 --> 0.371267).  Saving model ...
train epoch 596 avg loss: 0.15997 (A-MSE: 0.14073) avg lploss: 0.00000
train epoch 597 avg loss: 0.16817 (A-MSE: 0.14845) avg lploss: 0.00000
train epoch 598 avg loss: 0.17352 (A-MSE: 0.15437) avg lploss: 0.00000
train epoch 599 avg loss: 0.18743 (A-MSE: 0.16680) avg lploss: 0.00000
train epoch 600 avg loss: 0.18601 (A-MSE: 0.16354) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.41150 (A-MSE: 0.34747) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.44583 (A-MSE: 0.39112) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 1 out of 50
train epoch 601 avg loss: 0.17561 (A-MSE: 0.15518) avg lploss: 0.00000
train epoch 602 avg loss: 0.16984 (A-MSE: 0.14888) avg lploss: 0.00000
train epoch 603 avg loss: 0.18049 (A-MSE: 0.16036) avg lploss: 0.00000
train epoch 604 avg loss: 0.16720 (A-MSE: 0.14917) avg lploss: 0.00000
train epoch 605 avg loss: 0.14697 (A-MSE: 0.12974) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.37922 (A-MSE: 0.32037) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.41807 (A-MSE: 0.36502) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 2 out of 50
train epoch 606 avg loss: 0.15426 (A-MSE: 0.13607) avg lploss: 0.00000
train epoch 607 avg loss: 0.14975 (A-MSE: 0.13247) avg lploss: 0.00000
train epoch 608 avg loss: 0.15344 (A-MSE: 0.13561) avg lploss: 0.00000
train epoch 609 avg loss: 0.14302 (A-MSE: 0.12662) avg lploss: 0.00000
train epoch 610 avg loss: 0.14569 (A-MSE: 0.12854) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.42204 (A-MSE: 0.35976) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.41829 (A-MSE: 0.36764) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 3 out of 50
train epoch 611 avg loss: 0.15094 (A-MSE: 0.13336) avg lploss: 0.00000
train epoch 612 avg loss: 0.18479 (A-MSE: 0.16330) avg lploss: 0.00000
train epoch 613 avg loss: 0.16480 (A-MSE: 0.14599) avg lploss: 0.00000
train epoch 614 avg loss: 0.17811 (A-MSE: 0.15752) avg lploss: 0.00000
train epoch 615 avg loss: 0.17236 (A-MSE: 0.15321) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.41512 (A-MSE: 0.35195) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.43752 (A-MSE: 0.38166) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 4 out of 50
train epoch 616 avg loss: 0.14046 (A-MSE: 0.12359) avg lploss: 0.00000
train epoch 617 avg loss: 0.13900 (A-MSE: 0.12316) avg lploss: 0.00000
train epoch 618 avg loss: 0.15964 (A-MSE: 0.14029) avg lploss: 0.00000
train epoch 619 avg loss: 0.15279 (A-MSE: 0.13570) avg lploss: 0.00000
train epoch 620 avg loss: 0.13747 (A-MSE: 0.12154) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.37200 (A-MSE: 0.31348) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.42267 (A-MSE: 0.36958) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 5 out of 50
train epoch 621 avg loss: 0.14180 (A-MSE: 0.12357) avg lploss: 0.00000
train epoch 622 avg loss: 0.12386 (A-MSE: 0.10933) avg lploss: 0.00000
train epoch 623 avg loss: 0.13354 (A-MSE: 0.11872) avg lploss: 0.00000
train epoch 624 avg loss: 0.15162 (A-MSE: 0.13499) avg lploss: 0.00000
train epoch 625 avg loss: 0.16416 (A-MSE: 0.14495) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.42638 (A-MSE: 0.35634) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.45846 (A-MSE: 0.39659) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 6 out of 50
train epoch 626 avg loss: 0.14969 (A-MSE: 0.13211) avg lploss: 0.00000
train epoch 627 avg loss: 0.15576 (A-MSE: 0.13869) avg lploss: 0.00000
train epoch 628 avg loss: 0.16855 (A-MSE: 0.14995) avg lploss: 0.00000
train epoch 629 avg loss: 0.17506 (A-MSE: 0.15446) avg lploss: 0.00000
train epoch 630 avg loss: 0.14883 (A-MSE: 0.12994) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.46464 (A-MSE: 0.38916) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.49070 (A-MSE: 0.42302) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 7 out of 50
train epoch 631 avg loss: 0.16403 (A-MSE: 0.14474) avg lploss: 0.00000
train epoch 632 avg loss: 0.17658 (A-MSE: 0.15668) avg lploss: 0.00000
train epoch 633 avg loss: 0.14683 (A-MSE: 0.13009) avg lploss: 0.00000
train epoch 634 avg loss: 0.14064 (A-MSE: 0.12498) avg lploss: 0.00000
train epoch 635 avg loss: 0.15616 (A-MSE: 0.13737) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.38668 (A-MSE: 0.32604) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.44561 (A-MSE: 0.38742) avg lploss: 0.00000
*** Best Val Loss: 0.37127 	 Best Test Loss: 0.41759 	 Best epoch 595
EarlyStopping counter: 8 out of 50
train epoch 636 avg loss: 0.16329 (A-MSE: 0.14546) avg lploss: 0.00000
train epoch 637 avg loss: 0.14446 (A-MSE: 0.12789) avg lploss: 0.00000
train epoch 638 avg loss: 0.16869 (A-MSE: 0.14992) avg lploss: 0.00000
train epoch 639 avg loss: 0.14411 (A-MSE: 0.12861) avg lploss: 0.00000
train epoch 640 avg loss: 0.12218 (A-MSE: 0.10749) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.35961 (A-MSE: 0.30242) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.41253 (A-MSE: 0.35771) avg lploss: 0.00000
*** Best Val Loss: 0.35961 	 Best Test Loss: 0.41253 	 Best epoch 640
Validation loss decreased (0.371267 --> 0.359611).  Saving model ...
train epoch 641 avg loss: 0.11697 (A-MSE: 0.10325) avg lploss: 0.00000
train epoch 642 avg loss: 0.12235 (A-MSE: 0.10974) avg lploss: 0.00000
train epoch 643 avg loss: 0.12925 (A-MSE: 0.11402) avg lploss: 0.00000
train epoch 644 avg loss: 0.13943 (A-MSE: 0.12331) avg lploss: 0.00000
train epoch 645 avg loss: 0.16949 (A-MSE: 0.15224) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.45077 (A-MSE: 0.38686) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.45305 (A-MSE: 0.39826) avg lploss: 0.00000
*** Best Val Loss: 0.35961 	 Best Test Loss: 0.41253 	 Best epoch 640
EarlyStopping counter: 1 out of 50
train epoch 646 avg loss: 0.18084 (A-MSE: 0.15954) avg lploss: 0.00000
train epoch 647 avg loss: 0.18361 (A-MSE: 0.15981) avg lploss: 0.00000
train epoch 648 avg loss: 0.15820 (A-MSE: 0.14094) avg lploss: 0.00000
train epoch 649 avg loss: 0.12834 (A-MSE: 0.11263) avg lploss: 0.00000
train epoch 650 avg loss: 0.11222 (A-MSE: 0.09917) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.38419 (A-MSE: 0.32297) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.42195 (A-MSE: 0.36722) avg lploss: 0.00000
*** Best Val Loss: 0.35961 	 Best Test Loss: 0.41253 	 Best epoch 640
EarlyStopping counter: 2 out of 50
train epoch 651 avg loss: 0.11833 (A-MSE: 0.10509) avg lploss: 0.00000
train epoch 652 avg loss: 0.12128 (A-MSE: 0.10599) avg lploss: 0.00000
train epoch 653 avg loss: 0.12464 (A-MSE: 0.11057) avg lploss: 0.00000
train epoch 654 avg loss: 0.13745 (A-MSE: 0.12131) avg lploss: 0.00000
train epoch 655 avg loss: 0.11502 (A-MSE: 0.10042) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.35423 (A-MSE: 0.29997) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.38819 (A-MSE: 0.33924) avg lploss: 0.00000
*** Best Val Loss: 0.35423 	 Best Test Loss: 0.38819 	 Best epoch 655
Validation loss decreased (0.359611 --> 0.354230).  Saving model ...
train epoch 656 avg loss: 0.11593 (A-MSE: 0.10285) avg lploss: 0.00000
train epoch 657 avg loss: 0.12382 (A-MSE: 0.10965) avg lploss: 0.00000
train epoch 658 avg loss: 0.13482 (A-MSE: 0.11909) avg lploss: 0.00000
train epoch 659 avg loss: 0.15361 (A-MSE: 0.13575) avg lploss: 0.00000
train epoch 660 avg loss: 0.12178 (A-MSE: 0.10681) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.38949 (A-MSE: 0.32960) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.45560 (A-MSE: 0.39631) avg lploss: 0.00000
*** Best Val Loss: 0.35423 	 Best Test Loss: 0.38819 	 Best epoch 655
EarlyStopping counter: 1 out of 50
train epoch 661 avg loss: 0.15444 (A-MSE: 0.13907) avg lploss: 0.00000
train epoch 662 avg loss: 0.13939 (A-MSE: 0.12302) avg lploss: 0.00000
train epoch 663 avg loss: 0.12465 (A-MSE: 0.10980) avg lploss: 0.00000
train epoch 664 avg loss: 0.13110 (A-MSE: 0.11700) avg lploss: 0.00000
train epoch 665 avg loss: 0.12874 (A-MSE: 0.11518) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.40642 (A-MSE: 0.34093) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.45903 (A-MSE: 0.39551) avg lploss: 0.00000
*** Best Val Loss: 0.35423 	 Best Test Loss: 0.38819 	 Best epoch 655
EarlyStopping counter: 2 out of 50
train epoch 666 avg loss: 0.12368 (A-MSE: 0.10974) avg lploss: 0.00000
train epoch 667 avg loss: 0.12575 (A-MSE: 0.11181) avg lploss: 0.00000
train epoch 668 avg loss: 0.12058 (A-MSE: 0.10573) avg lploss: 0.00000
train epoch 669 avg loss: 0.12351 (A-MSE: 0.10844) avg lploss: 0.00000
train epoch 670 avg loss: 0.13300 (A-MSE: 0.11841) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.35066 (A-MSE: 0.29910) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.41303 (A-MSE: 0.36269) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
Validation loss decreased (0.354230 --> 0.350664).  Saving model ...
train epoch 671 avg loss: 0.12513 (A-MSE: 0.10986) avg lploss: 0.00000
train epoch 672 avg loss: 0.11999 (A-MSE: 0.10525) avg lploss: 0.00000
train epoch 673 avg loss: 0.12837 (A-MSE: 0.11376) avg lploss: 0.00000
train epoch 674 avg loss: 0.12271 (A-MSE: 0.10869) avg lploss: 0.00000
train epoch 675 avg loss: 0.12222 (A-MSE: 0.10711) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.38275 (A-MSE: 0.32439) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.43662 (A-MSE: 0.37954) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 1 out of 50
train epoch 676 avg loss: 0.12703 (A-MSE: 0.11206) avg lploss: 0.00000
train epoch 677 avg loss: 0.14030 (A-MSE: 0.12288) avg lploss: 0.00000
train epoch 678 avg loss: 0.14742 (A-MSE: 0.12925) avg lploss: 0.00000
train epoch 679 avg loss: 0.12268 (A-MSE: 0.10829) avg lploss: 0.00000
train epoch 680 avg loss: 0.12465 (A-MSE: 0.10968) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.47745 (A-MSE: 0.40396) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.45696 (A-MSE: 0.39829) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 2 out of 50
train epoch 681 avg loss: 0.12507 (A-MSE: 0.11059) avg lploss: 0.00000
train epoch 682 avg loss: 0.12800 (A-MSE: 0.11248) avg lploss: 0.00000
train epoch 683 avg loss: 0.12207 (A-MSE: 0.10896) avg lploss: 0.00000
train epoch 684 avg loss: 0.12196 (A-MSE: 0.10820) avg lploss: 0.00000
train epoch 685 avg loss: 0.11447 (A-MSE: 0.10102) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.41415 (A-MSE: 0.35303) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.42267 (A-MSE: 0.37003) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 3 out of 50
train epoch 686 avg loss: 0.10864 (A-MSE: 0.09686) avg lploss: 0.00000
train epoch 687 avg loss: 0.11660 (A-MSE: 0.10421) avg lploss: 0.00000
train epoch 688 avg loss: 0.12166 (A-MSE: 0.10720) avg lploss: 0.00000
train epoch 689 avg loss: 0.11108 (A-MSE: 0.09874) avg lploss: 0.00000
train epoch 690 avg loss: 0.12612 (A-MSE: 0.11157) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.38141 (A-MSE: 0.32598) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.42677 (A-MSE: 0.37159) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 4 out of 50
train epoch 691 avg loss: 0.11159 (A-MSE: 0.09939) avg lploss: 0.00000
train epoch 692 avg loss: 0.12341 (A-MSE: 0.10947) avg lploss: 0.00000
train epoch 693 avg loss: 0.12116 (A-MSE: 0.10634) avg lploss: 0.00000
train epoch 694 avg loss: 0.12845 (A-MSE: 0.11366) avg lploss: 0.00000
train epoch 695 avg loss: 0.13157 (A-MSE: 0.11659) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.37174 (A-MSE: 0.31338) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.43444 (A-MSE: 0.37827) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 5 out of 50
train epoch 696 avg loss: 0.13373 (A-MSE: 0.11997) avg lploss: 0.00000
train epoch 697 avg loss: 0.12056 (A-MSE: 0.10626) avg lploss: 0.00000
train epoch 698 avg loss: 0.11187 (A-MSE: 0.10045) avg lploss: 0.00000
train epoch 699 avg loss: 0.11318 (A-MSE: 0.09999) avg lploss: 0.00000
train epoch 700 avg loss: 0.11190 (A-MSE: 0.09898) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.36354 (A-MSE: 0.30381) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.40221 (A-MSE: 0.35051) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 6 out of 50
train epoch 701 avg loss: 0.11919 (A-MSE: 0.10595) avg lploss: 0.00000
train epoch 702 avg loss: 0.15300 (A-MSE: 0.13601) avg lploss: 0.00000
train epoch 703 avg loss: 0.13129 (A-MSE: 0.11565) avg lploss: 0.00000
train epoch 704 avg loss: 0.16342 (A-MSE: 0.14478) avg lploss: 0.00000
train epoch 705 avg loss: 0.17371 (A-MSE: 0.15366) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.45479 (A-MSE: 0.38197) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.50636 (A-MSE: 0.43956) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 7 out of 50
train epoch 706 avg loss: 0.15283 (A-MSE: 0.13572) avg lploss: 0.00000
train epoch 707 avg loss: 0.12632 (A-MSE: 0.11320) avg lploss: 0.00000
train epoch 708 avg loss: 0.10496 (A-MSE: 0.09271) avg lploss: 0.00000
train epoch 709 avg loss: 0.10587 (A-MSE: 0.09339) avg lploss: 0.00000
train epoch 710 avg loss: 0.10462 (A-MSE: 0.09271) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.39474 (A-MSE: 0.33399) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.41846 (A-MSE: 0.36435) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 8 out of 50
train epoch 711 avg loss: 0.10298 (A-MSE: 0.09037) avg lploss: 0.00000
train epoch 712 avg loss: 0.11651 (A-MSE: 0.10321) avg lploss: 0.00000
train epoch 713 avg loss: 0.11969 (A-MSE: 0.10652) avg lploss: 0.00000
train epoch 714 avg loss: 0.13397 (A-MSE: 0.11740) avg lploss: 0.00000
train epoch 715 avg loss: 0.12830 (A-MSE: 0.11441) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.46216 (A-MSE: 0.39078) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.46429 (A-MSE: 0.40505) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 9 out of 50
train epoch 716 avg loss: 0.11165 (A-MSE: 0.09866) avg lploss: 0.00000
train epoch 717 avg loss: 0.11159 (A-MSE: 0.09863) avg lploss: 0.00000
train epoch 718 avg loss: 0.11494 (A-MSE: 0.10266) avg lploss: 0.00000
train epoch 719 avg loss: 0.10258 (A-MSE: 0.08972) avg lploss: 0.00000
train epoch 720 avg loss: 0.10928 (A-MSE: 0.09632) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.37940 (A-MSE: 0.31907) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.42194 (A-MSE: 0.36453) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 10 out of 50
train epoch 721 avg loss: 0.10488 (A-MSE: 0.09225) avg lploss: 0.00000
train epoch 722 avg loss: 0.12356 (A-MSE: 0.10990) avg lploss: 0.00000
train epoch 723 avg loss: 0.12581 (A-MSE: 0.11130) avg lploss: 0.00000
train epoch 724 avg loss: 0.11832 (A-MSE: 0.10448) avg lploss: 0.00000
train epoch 725 avg loss: 0.12993 (A-MSE: 0.11608) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.46426 (A-MSE: 0.39355) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.48493 (A-MSE: 0.42068) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 11 out of 50
train epoch 726 avg loss: 0.13452 (A-MSE: 0.12073) avg lploss: 0.00000
train epoch 727 avg loss: 0.13260 (A-MSE: 0.11780) avg lploss: 0.00000
train epoch 728 avg loss: 0.13672 (A-MSE: 0.12092) avg lploss: 0.00000
train epoch 729 avg loss: 0.13341 (A-MSE: 0.11772) avg lploss: 0.00000
train epoch 730 avg loss: 0.13422 (A-MSE: 0.11916) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.40587 (A-MSE: 0.33445) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.45445 (A-MSE: 0.38979) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 12 out of 50
train epoch 731 avg loss: 0.14016 (A-MSE: 0.12474) avg lploss: 0.00000
train epoch 732 avg loss: 0.17198 (A-MSE: 0.15257) avg lploss: 0.00000
train epoch 733 avg loss: 0.14362 (A-MSE: 0.12550) avg lploss: 0.00000
train epoch 734 avg loss: 0.13375 (A-MSE: 0.11840) avg lploss: 0.00000
train epoch 735 avg loss: 0.11943 (A-MSE: 0.10572) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.38988 (A-MSE: 0.33056) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.42198 (A-MSE: 0.36577) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 13 out of 50
train epoch 736 avg loss: 0.10920 (A-MSE: 0.09550) avg lploss: 0.00000
train epoch 737 avg loss: 0.10136 (A-MSE: 0.08930) avg lploss: 0.00000
train epoch 738 avg loss: 0.09588 (A-MSE: 0.08507) avg lploss: 0.00000
train epoch 739 avg loss: 0.10331 (A-MSE: 0.09161) avg lploss: 0.00000
train epoch 740 avg loss: 0.10062 (A-MSE: 0.08820) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.35260 (A-MSE: 0.30012) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.40504 (A-MSE: 0.35469) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 14 out of 50
train epoch 741 avg loss: 0.13090 (A-MSE: 0.11599) avg lploss: 0.00000
train epoch 742 avg loss: 0.11182 (A-MSE: 0.09727) avg lploss: 0.00000
train epoch 743 avg loss: 0.10652 (A-MSE: 0.09423) avg lploss: 0.00000
train epoch 744 avg loss: 0.10557 (A-MSE: 0.09246) avg lploss: 0.00000
train epoch 745 avg loss: 0.09747 (A-MSE: 0.08605) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.45569 (A-MSE: 0.38499) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.46896 (A-MSE: 0.40597) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 15 out of 50
train epoch 746 avg loss: 0.11919 (A-MSE: 0.10612) avg lploss: 0.00000
train epoch 747 avg loss: 0.09575 (A-MSE: 0.08393) avg lploss: 0.00000
train epoch 748 avg loss: 0.11473 (A-MSE: 0.10120) avg lploss: 0.00000
train epoch 749 avg loss: 0.14048 (A-MSE: 0.12320) avg lploss: 0.00000
train epoch 750 avg loss: 0.13238 (A-MSE: 0.11778) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.38668 (A-MSE: 0.32692) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.45610 (A-MSE: 0.39543) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 16 out of 50
train epoch 751 avg loss: 0.13269 (A-MSE: 0.11794) avg lploss: 0.00000
train epoch 752 avg loss: 0.11692 (A-MSE: 0.10441) avg lploss: 0.00000
train epoch 753 avg loss: 0.11446 (A-MSE: 0.10024) avg lploss: 0.00000
train epoch 754 avg loss: 0.11558 (A-MSE: 0.10110) avg lploss: 0.00000
train epoch 755 avg loss: 0.09880 (A-MSE: 0.08701) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.37666 (A-MSE: 0.31897) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.42591 (A-MSE: 0.36757) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 17 out of 50
train epoch 756 avg loss: 0.10408 (A-MSE: 0.09295) avg lploss: 0.00000
train epoch 757 avg loss: 0.11206 (A-MSE: 0.09924) avg lploss: 0.00000
train epoch 758 avg loss: 0.10830 (A-MSE: 0.09649) avg lploss: 0.00000
train epoch 759 avg loss: 0.09981 (A-MSE: 0.08776) avg lploss: 0.00000
train epoch 760 avg loss: 0.09039 (A-MSE: 0.07951) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.37520 (A-MSE: 0.31631) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.40964 (A-MSE: 0.35732) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 18 out of 50
train epoch 761 avg loss: 0.11333 (A-MSE: 0.10016) avg lploss: 0.00000
train epoch 762 avg loss: 0.14206 (A-MSE: 0.12607) avg lploss: 0.00000
train epoch 763 avg loss: 0.14997 (A-MSE: 0.13362) avg lploss: 0.00000
train epoch 764 avg loss: 0.15024 (A-MSE: 0.13392) avg lploss: 0.00000
train epoch 765 avg loss: 0.15249 (A-MSE: 0.13326) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.43194 (A-MSE: 0.37087) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.49773 (A-MSE: 0.43275) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 19 out of 50
train epoch 766 avg loss: 0.13986 (A-MSE: 0.12289) avg lploss: 0.00000
train epoch 767 avg loss: 0.12552 (A-MSE: 0.11170) avg lploss: 0.00000
train epoch 768 avg loss: 0.13612 (A-MSE: 0.12004) avg lploss: 0.00000
train epoch 769 avg loss: 0.12233 (A-MSE: 0.10762) avg lploss: 0.00000
train epoch 770 avg loss: 0.10245 (A-MSE: 0.09014) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.38220 (A-MSE: 0.32206) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.42045 (A-MSE: 0.36556) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 20 out of 50
train epoch 771 avg loss: 0.12043 (A-MSE: 0.10658) avg lploss: 0.00000
train epoch 772 avg loss: 0.12734 (A-MSE: 0.11252) avg lploss: 0.00000
train epoch 773 avg loss: 0.17683 (A-MSE: 0.15590) avg lploss: 0.00000
train epoch 774 avg loss: 0.19537 (A-MSE: 0.17381) avg lploss: 0.00000
train epoch 775 avg loss: 0.15822 (A-MSE: 0.14047) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.38242 (A-MSE: 0.32507) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.41571 (A-MSE: 0.36478) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 21 out of 50
train epoch 776 avg loss: 0.11087 (A-MSE: 0.09829) avg lploss: 0.00000
train epoch 777 avg loss: 0.09527 (A-MSE: 0.08426) avg lploss: 0.00000
train epoch 778 avg loss: 0.09415 (A-MSE: 0.08258) avg lploss: 0.00000
train epoch 779 avg loss: 0.10000 (A-MSE: 0.08876) avg lploss: 0.00000
train epoch 780 avg loss: 0.09648 (A-MSE: 0.08464) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.35471 (A-MSE: 0.30359) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.41170 (A-MSE: 0.35811) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 22 out of 50
train epoch 781 avg loss: 0.08903 (A-MSE: 0.07922) avg lploss: 0.00000
train epoch 782 avg loss: 0.09296 (A-MSE: 0.08222) avg lploss: 0.00000
train epoch 783 avg loss: 0.09359 (A-MSE: 0.08268) avg lploss: 0.00000
train epoch 784 avg loss: 0.12469 (A-MSE: 0.11263) avg lploss: 0.00000
train epoch 785 avg loss: 0.13060 (A-MSE: 0.11341) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.40955 (A-MSE: 0.35002) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.46711 (A-MSE: 0.40824) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 23 out of 50
train epoch 786 avg loss: 0.11221 (A-MSE: 0.09952) avg lploss: 0.00000
train epoch 787 avg loss: 0.10806 (A-MSE: 0.09498) avg lploss: 0.00000
train epoch 788 avg loss: 0.10142 (A-MSE: 0.09010) avg lploss: 0.00000
train epoch 789 avg loss: 0.09523 (A-MSE: 0.08417) avg lploss: 0.00000
train epoch 790 avg loss: 0.10804 (A-MSE: 0.09573) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.40941 (A-MSE: 0.34613) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.44426 (A-MSE: 0.38577) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 24 out of 50
train epoch 791 avg loss: 0.10603 (A-MSE: 0.09400) avg lploss: 0.00000
train epoch 792 avg loss: 0.11781 (A-MSE: 0.10487) avg lploss: 0.00000
train epoch 793 avg loss: 0.12512 (A-MSE: 0.11075) avg lploss: 0.00000
train epoch 794 avg loss: 0.10708 (A-MSE: 0.09414) avg lploss: 0.00000
train epoch 795 avg loss: 0.10588 (A-MSE: 0.09426) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.43981 (A-MSE: 0.37328) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.46234 (A-MSE: 0.40013) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 25 out of 50
train epoch 796 avg loss: 0.10413 (A-MSE: 0.09212) avg lploss: 0.00000
train epoch 797 avg loss: 0.10427 (A-MSE: 0.09221) avg lploss: 0.00000
train epoch 798 avg loss: 0.09263 (A-MSE: 0.08244) avg lploss: 0.00000
train epoch 799 avg loss: 0.08618 (A-MSE: 0.07649) avg lploss: 0.00000
train epoch 800 avg loss: 0.08383 (A-MSE: 0.07400) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.37656 (A-MSE: 0.31988) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.41220 (A-MSE: 0.35826) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 26 out of 50
train epoch 801 avg loss: 0.08412 (A-MSE: 0.07354) avg lploss: 0.00000
train epoch 802 avg loss: 0.09568 (A-MSE: 0.08494) avg lploss: 0.00000
train epoch 803 avg loss: 0.09248 (A-MSE: 0.08246) avg lploss: 0.00000
train epoch 804 avg loss: 0.11071 (A-MSE: 0.09769) avg lploss: 0.00000
train epoch 805 avg loss: 0.11943 (A-MSE: 0.10707) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.35653 (A-MSE: 0.30562) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.40963 (A-MSE: 0.35556) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 27 out of 50
train epoch 806 avg loss: 0.11058 (A-MSE: 0.09832) avg lploss: 0.00000
train epoch 807 avg loss: 0.09855 (A-MSE: 0.08731) avg lploss: 0.00000
train epoch 808 avg loss: 0.08499 (A-MSE: 0.07520) avg lploss: 0.00000
train epoch 809 avg loss: 0.08535 (A-MSE: 0.07431) avg lploss: 0.00000
train epoch 810 avg loss: 0.09363 (A-MSE: 0.08216) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.39647 (A-MSE: 0.33356) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.48755 (A-MSE: 0.42041) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 28 out of 50
train epoch 811 avg loss: 0.11275 (A-MSE: 0.09993) avg lploss: 0.00000
train epoch 812 avg loss: 0.10480 (A-MSE: 0.09300) avg lploss: 0.00000
train epoch 813 avg loss: 0.08986 (A-MSE: 0.07920) avg lploss: 0.00000
train epoch 814 avg loss: 0.08414 (A-MSE: 0.07391) avg lploss: 0.00000
train epoch 815 avg loss: 0.08669 (A-MSE: 0.07654) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.40573 (A-MSE: 0.34431) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.43482 (A-MSE: 0.37667) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 29 out of 50
train epoch 816 avg loss: 0.07368 (A-MSE: 0.06452) avg lploss: 0.00000
train epoch 817 avg loss: 0.07577 (A-MSE: 0.06664) avg lploss: 0.00000
train epoch 818 avg loss: 0.07961 (A-MSE: 0.07009) avg lploss: 0.00000
train epoch 819 avg loss: 0.09309 (A-MSE: 0.08172) avg lploss: 0.00000
train epoch 820 avg loss: 0.10416 (A-MSE: 0.09275) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.44829 (A-MSE: 0.38802) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.51526 (A-MSE: 0.45016) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 30 out of 50
train epoch 821 avg loss: 0.11819 (A-MSE: 0.10535) avg lploss: 0.00000
train epoch 822 avg loss: 0.11795 (A-MSE: 0.10467) avg lploss: 0.00000
train epoch 823 avg loss: 0.10195 (A-MSE: 0.09030) avg lploss: 0.00000
train epoch 824 avg loss: 0.08950 (A-MSE: 0.07861) avg lploss: 0.00000
train epoch 825 avg loss: 0.08723 (A-MSE: 0.07751) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.37291 (A-MSE: 0.32058) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.42799 (A-MSE: 0.37389) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 31 out of 50
train epoch 826 avg loss: 0.09696 (A-MSE: 0.08589) avg lploss: 0.00000
train epoch 827 avg loss: 0.08149 (A-MSE: 0.07159) avg lploss: 0.00000
train epoch 828 avg loss: 0.08922 (A-MSE: 0.07826) avg lploss: 0.00000
train epoch 829 avg loss: 0.10041 (A-MSE: 0.08901) avg lploss: 0.00000
train epoch 830 avg loss: 0.10023 (A-MSE: 0.08913) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.42346 (A-MSE: 0.36502) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.46989 (A-MSE: 0.41113) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 32 out of 50
train epoch 831 avg loss: 0.08825 (A-MSE: 0.07737) avg lploss: 0.00000
train epoch 832 avg loss: 0.08105 (A-MSE: 0.07099) avg lploss: 0.00000
train epoch 833 avg loss: 0.08422 (A-MSE: 0.07433) avg lploss: 0.00000
train epoch 834 avg loss: 0.09153 (A-MSE: 0.08033) avg lploss: 0.00000
train epoch 835 avg loss: 0.10465 (A-MSE: 0.09249) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.45095 (A-MSE: 0.38670) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.49415 (A-MSE: 0.43055) avg lploss: 0.00000
*** Best Val Loss: 0.35066 	 Best Test Loss: 0.41303 	 Best epoch 670
EarlyStopping counter: 33 out of 50
train epoch 836 avg loss: 0.08975 (A-MSE: 0.07886) avg lploss: 0.00000
train epoch 837 avg loss: 0.07523 (A-MSE: 0.06661) avg lploss: 0.00000
train epoch 838 avg loss: 0.09354 (A-MSE: 0.08185) avg lploss: 0.00000
train epoch 839 avg loss: 0.12376 (A-MSE: 0.10913) avg lploss: 0.00000
train epoch 840 avg loss: 0.12280 (A-MSE: 0.10966) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.34800 (A-MSE: 0.29489) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.40494 (A-MSE: 0.35413) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
Validation loss decreased (0.350664 --> 0.348004).  Saving model ...
train epoch 841 avg loss: 0.11701 (A-MSE: 0.10343) avg lploss: 0.00000
train epoch 842 avg loss: 0.11091 (A-MSE: 0.09765) avg lploss: 0.00000
train epoch 843 avg loss: 0.10914 (A-MSE: 0.09594) avg lploss: 0.00000
train epoch 844 avg loss: 0.11086 (A-MSE: 0.09814) avg lploss: 0.00000
train epoch 845 avg loss: 0.09777 (A-MSE: 0.08591) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.44181 (A-MSE: 0.37569) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.45936 (A-MSE: 0.39902) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 1 out of 50
train epoch 846 avg loss: 0.08585 (A-MSE: 0.07638) avg lploss: 0.00000
train epoch 847 avg loss: 0.08323 (A-MSE: 0.07379) avg lploss: 0.00000
train epoch 848 avg loss: 0.08274 (A-MSE: 0.07356) avg lploss: 0.00000
train epoch 849 avg loss: 0.08441 (A-MSE: 0.07402) avg lploss: 0.00000
train epoch 850 avg loss: 0.08586 (A-MSE: 0.07644) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.36487 (A-MSE: 0.31616) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.43365 (A-MSE: 0.38462) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 2 out of 50
train epoch 851 avg loss: 0.08861 (A-MSE: 0.07916) avg lploss: 0.00000
train epoch 852 avg loss: 0.08230 (A-MSE: 0.07205) avg lploss: 0.00000
train epoch 853 avg loss: 0.07880 (A-MSE: 0.06969) avg lploss: 0.00000
train epoch 854 avg loss: 0.07670 (A-MSE: 0.06772) avg lploss: 0.00000
train epoch 855 avg loss: 0.10713 (A-MSE: 0.09416) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.43889 (A-MSE: 0.37511) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.46085 (A-MSE: 0.40064) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 3 out of 50
train epoch 856 avg loss: 0.09160 (A-MSE: 0.08046) avg lploss: 0.00000
train epoch 857 avg loss: 0.09535 (A-MSE: 0.08437) avg lploss: 0.00000
train epoch 858 avg loss: 0.12483 (A-MSE: 0.11171) avg lploss: 0.00000
train epoch 859 avg loss: 0.16078 (A-MSE: 0.14364) avg lploss: 0.00000
train epoch 860 avg loss: 0.15440 (A-MSE: 0.13681) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.39994 (A-MSE: 0.34628) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.46917 (A-MSE: 0.41104) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 4 out of 50
train epoch 861 avg loss: 0.14951 (A-MSE: 0.13133) avg lploss: 0.00000
train epoch 862 avg loss: 0.13995 (A-MSE: 0.12486) avg lploss: 0.00000
train epoch 863 avg loss: 0.11222 (A-MSE: 0.09909) avg lploss: 0.00000
train epoch 864 avg loss: 0.11213 (A-MSE: 0.09917) avg lploss: 0.00000
train epoch 865 avg loss: 0.09471 (A-MSE: 0.08297) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.38477 (A-MSE: 0.33238) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.40613 (A-MSE: 0.35596) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 5 out of 50
train epoch 866 avg loss: 0.08782 (A-MSE: 0.07752) avg lploss: 0.00000
train epoch 867 avg loss: 0.10273 (A-MSE: 0.08980) avg lploss: 0.00000
train epoch 868 avg loss: 0.09584 (A-MSE: 0.08462) avg lploss: 0.00000
train epoch 869 avg loss: 0.09317 (A-MSE: 0.08301) avg lploss: 0.00000
train epoch 870 avg loss: 0.08465 (A-MSE: 0.07507) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.40731 (A-MSE: 0.34368) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.42074 (A-MSE: 0.36436) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 6 out of 50
train epoch 871 avg loss: 0.09036 (A-MSE: 0.07969) avg lploss: 0.00000
train epoch 872 avg loss: 0.10044 (A-MSE: 0.08859) avg lploss: 0.00000
train epoch 873 avg loss: 0.10969 (A-MSE: 0.09740) avg lploss: 0.00000
train epoch 874 avg loss: 0.10623 (A-MSE: 0.09395) avg lploss: 0.00000
train epoch 875 avg loss: 0.11155 (A-MSE: 0.09883) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.38346 (A-MSE: 0.32546) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.46161 (A-MSE: 0.39632) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 7 out of 50
train epoch 876 avg loss: 0.10711 (A-MSE: 0.09541) avg lploss: 0.00000
train epoch 877 avg loss: 0.08397 (A-MSE: 0.07419) avg lploss: 0.00000
train epoch 878 avg loss: 0.08624 (A-MSE: 0.07605) avg lploss: 0.00000
train epoch 879 avg loss: 0.08507 (A-MSE: 0.07538) avg lploss: 0.00000
train epoch 880 avg loss: 0.09906 (A-MSE: 0.08795) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.42753 (A-MSE: 0.36560) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.45140 (A-MSE: 0.39275) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 8 out of 50
train epoch 881 avg loss: 0.09581 (A-MSE: 0.08574) avg lploss: 0.00000
train epoch 882 avg loss: 0.09128 (A-MSE: 0.08085) avg lploss: 0.00000
train epoch 883 avg loss: 0.11078 (A-MSE: 0.09767) avg lploss: 0.00000
train epoch 884 avg loss: 0.11037 (A-MSE: 0.09622) avg lploss: 0.00000
train epoch 885 avg loss: 0.09558 (A-MSE: 0.08456) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.41071 (A-MSE: 0.34273) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.44340 (A-MSE: 0.37911) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 9 out of 50
train epoch 886 avg loss: 0.07766 (A-MSE: 0.06882) avg lploss: 0.00000
train epoch 887 avg loss: 0.09464 (A-MSE: 0.08414) avg lploss: 0.00000
train epoch 888 avg loss: 0.09832 (A-MSE: 0.08632) avg lploss: 0.00000
train epoch 889 avg loss: 0.10452 (A-MSE: 0.09359) avg lploss: 0.00000
train epoch 890 avg loss: 0.07956 (A-MSE: 0.06999) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.41863 (A-MSE: 0.35410) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.43878 (A-MSE: 0.37719) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 10 out of 50
train epoch 891 avg loss: 0.07311 (A-MSE: 0.06368) avg lploss: 0.00000
train epoch 892 avg loss: 0.06921 (A-MSE: 0.06069) avg lploss: 0.00000
train epoch 893 avg loss: 0.07832 (A-MSE: 0.06929) avg lploss: 0.00000
train epoch 894 avg loss: 0.08703 (A-MSE: 0.07643) avg lploss: 0.00000
train epoch 895 avg loss: 0.06665 (A-MSE: 0.05810) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.37492 (A-MSE: 0.31966) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.44512 (A-MSE: 0.38958) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 11 out of 50
train epoch 896 avg loss: 0.06816 (A-MSE: 0.06056) avg lploss: 0.00000
train epoch 897 avg loss: 0.06507 (A-MSE: 0.05728) avg lploss: 0.00000
train epoch 898 avg loss: 0.06276 (A-MSE: 0.05569) avg lploss: 0.00000
train epoch 899 avg loss: 0.06984 (A-MSE: 0.06150) avg lploss: 0.00000
train epoch 900 avg loss: 0.07367 (A-MSE: 0.06646) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.39380 (A-MSE: 0.33346) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.43139 (A-MSE: 0.37394) avg lploss: 0.00000
*** Best Val Loss: 0.34800 	 Best Test Loss: 0.40494 	 Best epoch 840
EarlyStopping counter: 12 out of 50
train epoch 901 avg loss: 0.07599 (A-MSE: 0.06657) avg lploss: 0.00000
train epoch 902 avg loss: 0.07983 (A-MSE: 0.07075) avg lploss: 0.00000
train epoch 903 avg loss: 0.09130 (A-MSE: 0.08068) avg lploss: 0.00000
train epoch 904 avg loss: 0.10527 (A-MSE: 0.09163) avg lploss: 0.00000
train epoch 905 avg loss: 0.10870 (A-MSE: 0.09595) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.34342 (A-MSE: 0.29274) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.39307 (A-MSE: 0.34571) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
Validation loss decreased (0.348004 --> 0.343420).  Saving model ...
train epoch 906 avg loss: 0.10921 (A-MSE: 0.09807) avg lploss: 0.00000
train epoch 907 avg loss: 0.10379 (A-MSE: 0.09283) avg lploss: 0.00000
train epoch 908 avg loss: 0.12220 (A-MSE: 0.10760) avg lploss: 0.00000
train epoch 909 avg loss: 0.09747 (A-MSE: 0.08551) avg lploss: 0.00000
train epoch 910 avg loss: 0.07914 (A-MSE: 0.06971) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.40108 (A-MSE: 0.34972) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.43001 (A-MSE: 0.37955) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 1 out of 50
train epoch 911 avg loss: 0.07998 (A-MSE: 0.07069) avg lploss: 0.00000
train epoch 912 avg loss: 0.08657 (A-MSE: 0.07639) avg lploss: 0.00000
train epoch 913 avg loss: 0.07917 (A-MSE: 0.07004) avg lploss: 0.00000
train epoch 914 avg loss: 0.10614 (A-MSE: 0.09396) avg lploss: 0.00000
train epoch 915 avg loss: 0.12620 (A-MSE: 0.11281) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.38473 (A-MSE: 0.32026) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.41885 (A-MSE: 0.35926) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 2 out of 50
train epoch 916 avg loss: 0.10283 (A-MSE: 0.08943) avg lploss: 0.00000
train epoch 917 avg loss: 0.10444 (A-MSE: 0.09315) avg lploss: 0.00000
train epoch 918 avg loss: 0.10815 (A-MSE: 0.09650) avg lploss: 0.00000
train epoch 919 avg loss: 0.10346 (A-MSE: 0.09215) avg lploss: 0.00000
train epoch 920 avg loss: 0.09887 (A-MSE: 0.08693) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.37032 (A-MSE: 0.31617) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.40353 (A-MSE: 0.35362) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 3 out of 50
train epoch 921 avg loss: 0.09299 (A-MSE: 0.08224) avg lploss: 0.00000
train epoch 922 avg loss: 0.09303 (A-MSE: 0.08167) avg lploss: 0.00000
train epoch 923 avg loss: 0.08303 (A-MSE: 0.07379) avg lploss: 0.00000
train epoch 924 avg loss: 0.07358 (A-MSE: 0.06472) avg lploss: 0.00000
train epoch 925 avg loss: 0.07940 (A-MSE: 0.06919) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.37658 (A-MSE: 0.31960) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.42803 (A-MSE: 0.36947) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 4 out of 50
train epoch 926 avg loss: 0.06798 (A-MSE: 0.05989) avg lploss: 0.00000
train epoch 927 avg loss: 0.06755 (A-MSE: 0.06031) avg lploss: 0.00000
train epoch 928 avg loss: 0.06543 (A-MSE: 0.05758) avg lploss: 0.00000
train epoch 929 avg loss: 0.06218 (A-MSE: 0.05485) avg lploss: 0.00000
train epoch 930 avg loss: 0.06994 (A-MSE: 0.06118) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.39203 (A-MSE: 0.33580) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.42393 (A-MSE: 0.36807) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 5 out of 50
train epoch 931 avg loss: 0.08092 (A-MSE: 0.07193) avg lploss: 0.00000
train epoch 932 avg loss: 0.07249 (A-MSE: 0.06423) avg lploss: 0.00000
train epoch 933 avg loss: 0.09424 (A-MSE: 0.08262) avg lploss: 0.00000
train epoch 934 avg loss: 0.09495 (A-MSE: 0.08400) avg lploss: 0.00000
train epoch 935 avg loss: 0.08099 (A-MSE: 0.07280) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.36438 (A-MSE: 0.30959) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.39047 (A-MSE: 0.33767) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 6 out of 50
train epoch 936 avg loss: 0.07172 (A-MSE: 0.06313) avg lploss: 0.00000
train epoch 937 avg loss: 0.06457 (A-MSE: 0.05657) avg lploss: 0.00000
train epoch 938 avg loss: 0.06322 (A-MSE: 0.05522) avg lploss: 0.00000
train epoch 939 avg loss: 0.07175 (A-MSE: 0.06326) avg lploss: 0.00000
train epoch 940 avg loss: 0.07316 (A-MSE: 0.06442) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.38147 (A-MSE: 0.32743) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.42937 (A-MSE: 0.37318) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 7 out of 50
train epoch 941 avg loss: 0.07591 (A-MSE: 0.06707) avg lploss: 0.00000
train epoch 942 avg loss: 0.08827 (A-MSE: 0.07825) avg lploss: 0.00000
train epoch 943 avg loss: 0.12325 (A-MSE: 0.10851) avg lploss: 0.00000
train epoch 944 avg loss: 0.12764 (A-MSE: 0.11316) avg lploss: 0.00000
train epoch 945 avg loss: 0.11334 (A-MSE: 0.09941) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.36003 (A-MSE: 0.31193) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.39760 (A-MSE: 0.34872) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 8 out of 50
train epoch 946 avg loss: 0.09681 (A-MSE: 0.08561) avg lploss: 0.00000
train epoch 947 avg loss: 0.06961 (A-MSE: 0.06118) avg lploss: 0.00000
train epoch 948 avg loss: 0.06928 (A-MSE: 0.06099) avg lploss: 0.00000
train epoch 949 avg loss: 0.06314 (A-MSE: 0.05571) avg lploss: 0.00000
train epoch 950 avg loss: 0.06760 (A-MSE: 0.06004) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.39617 (A-MSE: 0.33800) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.42862 (A-MSE: 0.37246) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 9 out of 50
train epoch 951 avg loss: 0.06634 (A-MSE: 0.05802) avg lploss: 0.00000
train epoch 952 avg loss: 0.05918 (A-MSE: 0.05232) avg lploss: 0.00000
train epoch 953 avg loss: 0.05912 (A-MSE: 0.05208) avg lploss: 0.00000
train epoch 954 avg loss: 0.08185 (A-MSE: 0.07212) avg lploss: 0.00000
train epoch 955 avg loss: 0.06697 (A-MSE: 0.05963) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.38016 (A-MSE: 0.32454) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.43383 (A-MSE: 0.37638) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 10 out of 50
train epoch 956 avg loss: 0.06432 (A-MSE: 0.05697) avg lploss: 0.00000
train epoch 957 avg loss: 0.06568 (A-MSE: 0.05832) avg lploss: 0.00000
train epoch 958 avg loss: 0.06489 (A-MSE: 0.05732) avg lploss: 0.00000
train epoch 959 avg loss: 0.08803 (A-MSE: 0.07820) avg lploss: 0.00000
train epoch 960 avg loss: 0.08174 (A-MSE: 0.07216) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.35201 (A-MSE: 0.30022) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.39143 (A-MSE: 0.33903) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 11 out of 50
train epoch 961 avg loss: 0.08718 (A-MSE: 0.07807) avg lploss: 0.00000
train epoch 962 avg loss: 0.07375 (A-MSE: 0.06493) avg lploss: 0.00000
train epoch 963 avg loss: 0.06654 (A-MSE: 0.05832) avg lploss: 0.00000
train epoch 964 avg loss: 0.06394 (A-MSE: 0.05598) avg lploss: 0.00000
train epoch 965 avg loss: 0.06752 (A-MSE: 0.05994) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.40572 (A-MSE: 0.34873) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.42603 (A-MSE: 0.37171) avg lploss: 0.00000
*** Best Val Loss: 0.34342 	 Best Test Loss: 0.39307 	 Best epoch 905
EarlyStopping counter: 12 out of 50
train epoch 966 avg loss: 0.09253 (A-MSE: 0.08228) avg lploss: 0.00000
train epoch 967 avg loss: 0.09080 (A-MSE: 0.08045) avg lploss: 0.00000
train epoch 968 avg loss: 0.07482 (A-MSE: 0.06584) avg lploss: 0.00000
train epoch 969 avg loss: 0.07281 (A-MSE: 0.06448) avg lploss: 0.00000
train epoch 970 avg loss: 0.07735 (A-MSE: 0.06891) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.33920 (A-MSE: 0.29088) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.40229 (A-MSE: 0.35100) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
Validation loss decreased (0.343420 --> 0.339204).  Saving model ...
train epoch 971 avg loss: 0.08039 (A-MSE: 0.07173) avg lploss: 0.00000
train epoch 972 avg loss: 0.07398 (A-MSE: 0.06615) avg lploss: 0.00000
train epoch 973 avg loss: 0.07602 (A-MSE: 0.06712) avg lploss: 0.00000
train epoch 974 avg loss: 0.07174 (A-MSE: 0.06345) avg lploss: 0.00000
train epoch 975 avg loss: 0.07688 (A-MSE: 0.06835) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.37552 (A-MSE: 0.32756) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.42397 (A-MSE: 0.37269) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 1 out of 50
train epoch 976 avg loss: 0.07221 (A-MSE: 0.06362) avg lploss: 0.00000
train epoch 977 avg loss: 0.07915 (A-MSE: 0.06996) avg lploss: 0.00000
train epoch 978 avg loss: 0.06742 (A-MSE: 0.06009) avg lploss: 0.00000
train epoch 979 avg loss: 0.06139 (A-MSE: 0.05434) avg lploss: 0.00000
train epoch 980 avg loss: 0.05952 (A-MSE: 0.05238) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.36582 (A-MSE: 0.30973) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.41161 (A-MSE: 0.35412) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 2 out of 50
train epoch 981 avg loss: 0.06707 (A-MSE: 0.05884) avg lploss: 0.00000
train epoch 982 avg loss: 0.07458 (A-MSE: 0.06568) avg lploss: 0.00000
train epoch 983 avg loss: 0.07199 (A-MSE: 0.06392) avg lploss: 0.00000
train epoch 984 avg loss: 0.07279 (A-MSE: 0.06497) avg lploss: 0.00000
train epoch 985 avg loss: 0.06159 (A-MSE: 0.05429) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.38023 (A-MSE: 0.32110) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.43013 (A-MSE: 0.37308) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 3 out of 50
train epoch 986 avg loss: 0.06026 (A-MSE: 0.05334) avg lploss: 0.00000
train epoch 987 avg loss: 0.07628 (A-MSE: 0.06737) avg lploss: 0.00000
train epoch 988 avg loss: 0.07601 (A-MSE: 0.06702) avg lploss: 0.00000
train epoch 989 avg loss: 0.08270 (A-MSE: 0.07234) avg lploss: 0.00000
train epoch 990 avg loss: 0.07662 (A-MSE: 0.06756) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.38273 (A-MSE: 0.32433) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.43261 (A-MSE: 0.37318) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 4 out of 50
train epoch 991 avg loss: 0.07143 (A-MSE: 0.06274) avg lploss: 0.00000
train epoch 992 avg loss: 0.09340 (A-MSE: 0.08294) avg lploss: 0.00000
train epoch 993 avg loss: 0.07046 (A-MSE: 0.06262) avg lploss: 0.00000
train epoch 994 avg loss: 0.07746 (A-MSE: 0.06834) avg lploss: 0.00000
train epoch 995 avg loss: 0.07991 (A-MSE: 0.07042) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.34560 (A-MSE: 0.30156) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.39027 (A-MSE: 0.34239) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 5 out of 50
train epoch 996 avg loss: 0.06484 (A-MSE: 0.05693) avg lploss: 0.00000
train epoch 997 avg loss: 0.06700 (A-MSE: 0.05909) avg lploss: 0.00000
train epoch 998 avg loss: 0.06142 (A-MSE: 0.05485) avg lploss: 0.00000
train epoch 999 avg loss: 0.07385 (A-MSE: 0.06598) avg lploss: 0.00000
train epoch 1000 avg loss: 0.07184 (A-MSE: 0.06380) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.40457 (A-MSE: 0.34269) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.44103 (A-MSE: 0.38254) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 6 out of 50
train epoch 1001 avg loss: 0.07068 (A-MSE: 0.06342) avg lploss: 0.00000
train epoch 1002 avg loss: 0.06909 (A-MSE: 0.06074) avg lploss: 0.00000
train epoch 1003 avg loss: 0.07338 (A-MSE: 0.06416) avg lploss: 0.00000
train epoch 1004 avg loss: 0.08024 (A-MSE: 0.07059) avg lploss: 0.00000
train epoch 1005 avg loss: 0.09186 (A-MSE: 0.08151) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.43479 (A-MSE: 0.37100) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.48182 (A-MSE: 0.41586) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 7 out of 50
train epoch 1006 avg loss: 0.10377 (A-MSE: 0.09230) avg lploss: 0.00000
train epoch 1007 avg loss: 0.08573 (A-MSE: 0.07688) avg lploss: 0.00000
train epoch 1008 avg loss: 0.07642 (A-MSE: 0.06720) avg lploss: 0.00000
train epoch 1009 avg loss: 0.07796 (A-MSE: 0.06854) avg lploss: 0.00000
train epoch 1010 avg loss: 0.07857 (A-MSE: 0.07005) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.39964 (A-MSE: 0.34069) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.42933 (A-MSE: 0.37397) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 8 out of 50
train epoch 1011 avg loss: 0.06947 (A-MSE: 0.06159) avg lploss: 0.00000
train epoch 1012 avg loss: 0.06149 (A-MSE: 0.05419) avg lploss: 0.00000
train epoch 1013 avg loss: 0.05381 (A-MSE: 0.04734) avg lploss: 0.00000
train epoch 1014 avg loss: 0.06114 (A-MSE: 0.05367) avg lploss: 0.00000
train epoch 1015 avg loss: 0.06173 (A-MSE: 0.05423) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.35286 (A-MSE: 0.30288) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.39475 (A-MSE: 0.34653) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 9 out of 50
train epoch 1016 avg loss: 0.05727 (A-MSE: 0.05007) avg lploss: 0.00000
train epoch 1017 avg loss: 0.05675 (A-MSE: 0.05038) avg lploss: 0.00000
train epoch 1018 avg loss: 0.05550 (A-MSE: 0.04870) avg lploss: 0.00000
train epoch 1019 avg loss: 0.05964 (A-MSE: 0.05287) avg lploss: 0.00000
train epoch 1020 avg loss: 0.07659 (A-MSE: 0.06820) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.35035 (A-MSE: 0.30260) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.40117 (A-MSE: 0.35086) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 10 out of 50
train epoch 1021 avg loss: 0.08570 (A-MSE: 0.07625) avg lploss: 0.00000
train epoch 1022 avg loss: 0.08456 (A-MSE: 0.07471) avg lploss: 0.00000
train epoch 1023 avg loss: 0.07863 (A-MSE: 0.06995) avg lploss: 0.00000
train epoch 1024 avg loss: 0.06810 (A-MSE: 0.06034) avg lploss: 0.00000
train epoch 1025 avg loss: 0.06234 (A-MSE: 0.05519) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.42104 (A-MSE: 0.35915) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.47847 (A-MSE: 0.41580) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 11 out of 50
train epoch 1026 avg loss: 0.05760 (A-MSE: 0.05068) avg lploss: 0.00000
train epoch 1027 avg loss: 0.05271 (A-MSE: 0.04659) avg lploss: 0.00000
train epoch 1028 avg loss: 0.05367 (A-MSE: 0.04700) avg lploss: 0.00000
train epoch 1029 avg loss: 0.05838 (A-MSE: 0.05115) avg lploss: 0.00000
train epoch 1030 avg loss: 0.05753 (A-MSE: 0.05059) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.34776 (A-MSE: 0.29813) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.39256 (A-MSE: 0.34167) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 12 out of 50
train epoch 1031 avg loss: 0.05636 (A-MSE: 0.04953) avg lploss: 0.00000
train epoch 1032 avg loss: 0.07053 (A-MSE: 0.06288) avg lploss: 0.00000
train epoch 1033 avg loss: 0.08930 (A-MSE: 0.07965) avg lploss: 0.00000
train epoch 1034 avg loss: 0.08874 (A-MSE: 0.07838) avg lploss: 0.00000
train epoch 1035 avg loss: 0.08944 (A-MSE: 0.07748) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.38848 (A-MSE: 0.33050) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.44055 (A-MSE: 0.38439) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 13 out of 50
train epoch 1036 avg loss: 0.06809 (A-MSE: 0.06034) avg lploss: 0.00000
train epoch 1037 avg loss: 0.05439 (A-MSE: 0.04774) avg lploss: 0.00000
train epoch 1038 avg loss: 0.06406 (A-MSE: 0.05670) avg lploss: 0.00000
train epoch 1039 avg loss: 0.06348 (A-MSE: 0.05629) avg lploss: 0.00000
train epoch 1040 avg loss: 0.06147 (A-MSE: 0.05432) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.38849 (A-MSE: 0.33383) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.42099 (A-MSE: 0.36888) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 14 out of 50
train epoch 1041 avg loss: 0.06103 (A-MSE: 0.05315) avg lploss: 0.00000
train epoch 1042 avg loss: 0.06102 (A-MSE: 0.05436) avg lploss: 0.00000
train epoch 1043 avg loss: 0.06001 (A-MSE: 0.05288) avg lploss: 0.00000
train epoch 1044 avg loss: 0.06433 (A-MSE: 0.05657) avg lploss: 0.00000
train epoch 1045 avg loss: 0.05965 (A-MSE: 0.05291) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.35672 (A-MSE: 0.30433) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.40751 (A-MSE: 0.35465) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 15 out of 50
train epoch 1046 avg loss: 0.06744 (A-MSE: 0.05986) avg lploss: 0.00000
train epoch 1047 avg loss: 0.06508 (A-MSE: 0.05754) avg lploss: 0.00000
train epoch 1048 avg loss: 0.06027 (A-MSE: 0.05331) avg lploss: 0.00000
train epoch 1049 avg loss: 0.06440 (A-MSE: 0.05648) avg lploss: 0.00000
train epoch 1050 avg loss: 0.06381 (A-MSE: 0.05639) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.39172 (A-MSE: 0.33999) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.41933 (A-MSE: 0.37019) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 16 out of 50
train epoch 1051 avg loss: 0.05911 (A-MSE: 0.05239) avg lploss: 0.00000
train epoch 1052 avg loss: 0.06082 (A-MSE: 0.05315) avg lploss: 0.00000
train epoch 1053 avg loss: 0.06243 (A-MSE: 0.05478) avg lploss: 0.00000
train epoch 1054 avg loss: 0.06074 (A-MSE: 0.05344) avg lploss: 0.00000
train epoch 1055 avg loss: 0.06598 (A-MSE: 0.05796) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.39816 (A-MSE: 0.33854) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.43823 (A-MSE: 0.37911) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 17 out of 50
train epoch 1056 avg loss: 0.05864 (A-MSE: 0.05215) avg lploss: 0.00000
train epoch 1057 avg loss: 0.06035 (A-MSE: 0.05327) avg lploss: 0.00000
train epoch 1058 avg loss: 0.06637 (A-MSE: 0.05832) avg lploss: 0.00000
train epoch 1059 avg loss: 0.06325 (A-MSE: 0.05721) avg lploss: 0.00000
train epoch 1060 avg loss: 0.06933 (A-MSE: 0.05988) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.38680 (A-MSE: 0.33394) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.42438 (A-MSE: 0.37139) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 18 out of 50
train epoch 1061 avg loss: 0.06107 (A-MSE: 0.05373) avg lploss: 0.00000
train epoch 1062 avg loss: 0.05484 (A-MSE: 0.04853) avg lploss: 0.00000
train epoch 1063 avg loss: 0.06227 (A-MSE: 0.05486) avg lploss: 0.00000
train epoch 1064 avg loss: 0.06738 (A-MSE: 0.05929) avg lploss: 0.00000
train epoch 1065 avg loss: 0.06495 (A-MSE: 0.05735) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.39437 (A-MSE: 0.34245) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.42950 (A-MSE: 0.37675) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 19 out of 50
train epoch 1066 avg loss: 0.07776 (A-MSE: 0.06883) avg lploss: 0.00000
train epoch 1067 avg loss: 0.07360 (A-MSE: 0.06578) avg lploss: 0.00000
train epoch 1068 avg loss: 0.07313 (A-MSE: 0.06479) avg lploss: 0.00000
train epoch 1069 avg loss: 0.08429 (A-MSE: 0.07469) avg lploss: 0.00000
train epoch 1070 avg loss: 0.07107 (A-MSE: 0.06268) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.39105 (A-MSE: 0.32963) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.44604 (A-MSE: 0.38487) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 20 out of 50
train epoch 1071 avg loss: 0.06087 (A-MSE: 0.05369) avg lploss: 0.00000
train epoch 1072 avg loss: 0.05886 (A-MSE: 0.05200) avg lploss: 0.00000
train epoch 1073 avg loss: 0.08821 (A-MSE: 0.07743) avg lploss: 0.00000
train epoch 1074 avg loss: 0.14136 (A-MSE: 0.12562) avg lploss: 0.00000
train epoch 1075 avg loss: 0.13902 (A-MSE: 0.12369) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.48690 (A-MSE: 0.41877) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.51281 (A-MSE: 0.44835) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 21 out of 50
train epoch 1076 avg loss: 0.11755 (A-MSE: 0.10443) avg lploss: 0.00000
train epoch 1077 avg loss: 0.08000 (A-MSE: 0.07053) avg lploss: 0.00000
train epoch 1078 avg loss: 0.06223 (A-MSE: 0.05547) avg lploss: 0.00000
train epoch 1079 avg loss: 0.06200 (A-MSE: 0.05460) avg lploss: 0.00000
train epoch 1080 avg loss: 0.05371 (A-MSE: 0.04753) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.41021 (A-MSE: 0.35253) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.47438 (A-MSE: 0.41281) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 22 out of 50
train epoch 1081 avg loss: 0.06387 (A-MSE: 0.05613) avg lploss: 0.00000
train epoch 1082 avg loss: 0.05588 (A-MSE: 0.04919) avg lploss: 0.00000
train epoch 1083 avg loss: 0.05645 (A-MSE: 0.04968) avg lploss: 0.00000
train epoch 1084 avg loss: 0.08500 (A-MSE: 0.07581) avg lploss: 0.00000
train epoch 1085 avg loss: 0.11039 (A-MSE: 0.09875) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.44440 (A-MSE: 0.38319) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.47397 (A-MSE: 0.41451) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 23 out of 50
train epoch 1086 avg loss: 0.11821 (A-MSE: 0.10574) avg lploss: 0.00000
train epoch 1087 avg loss: 0.09414 (A-MSE: 0.08242) avg lploss: 0.00000
train epoch 1088 avg loss: 0.07234 (A-MSE: 0.06461) avg lploss: 0.00000
train epoch 1089 avg loss: 0.06480 (A-MSE: 0.05738) avg lploss: 0.00000
train epoch 1090 avg loss: 0.05682 (A-MSE: 0.04938) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.36448 (A-MSE: 0.31133) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.41069 (A-MSE: 0.35707) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 24 out of 50
train epoch 1091 avg loss: 0.05040 (A-MSE: 0.04385) avg lploss: 0.00000
train epoch 1092 avg loss: 0.05819 (A-MSE: 0.05141) avg lploss: 0.00000
train epoch 1093 avg loss: 0.05512 (A-MSE: 0.04866) avg lploss: 0.00000
train epoch 1094 avg loss: 0.04993 (A-MSE: 0.04430) avg lploss: 0.00000
train epoch 1095 avg loss: 0.06165 (A-MSE: 0.05441) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.40540 (A-MSE: 0.34735) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.45178 (A-MSE: 0.39035) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 25 out of 50
train epoch 1096 avg loss: 0.05169 (A-MSE: 0.04567) avg lploss: 0.00000
train epoch 1097 avg loss: 0.06073 (A-MSE: 0.05333) avg lploss: 0.00000
train epoch 1098 avg loss: 0.07174 (A-MSE: 0.06429) avg lploss: 0.00000
train epoch 1099 avg loss: 0.06778 (A-MSE: 0.06137) avg lploss: 0.00000
train epoch 1100 avg loss: 0.07090 (A-MSE: 0.06287) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.36245 (A-MSE: 0.31023) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.43172 (A-MSE: 0.37021) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 26 out of 50
train epoch 1101 avg loss: 0.07165 (A-MSE: 0.06357) avg lploss: 0.00000
train epoch 1102 avg loss: 0.06214 (A-MSE: 0.05495) avg lploss: 0.00000
train epoch 1103 avg loss: 0.05208 (A-MSE: 0.04613) avg lploss: 0.00000
train epoch 1104 avg loss: 0.06070 (A-MSE: 0.05391) avg lploss: 0.00000
train epoch 1105 avg loss: 0.05598 (A-MSE: 0.04877) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.36749 (A-MSE: 0.31472) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.41101 (A-MSE: 0.35803) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 27 out of 50
train epoch 1106 avg loss: 0.04790 (A-MSE: 0.04203) avg lploss: 0.00000
train epoch 1107 avg loss: 0.04362 (A-MSE: 0.03848) avg lploss: 0.00000
train epoch 1108 avg loss: 0.04908 (A-MSE: 0.04330) avg lploss: 0.00000
train epoch 1109 avg loss: 0.04769 (A-MSE: 0.04172) avg lploss: 0.00000
train epoch 1110 avg loss: 0.05062 (A-MSE: 0.04471) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.39070 (A-MSE: 0.33481) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.43610 (A-MSE: 0.38013) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 28 out of 50
train epoch 1111 avg loss: 0.05218 (A-MSE: 0.04606) avg lploss: 0.00000
train epoch 1112 avg loss: 0.04715 (A-MSE: 0.04169) avg lploss: 0.00000
train epoch 1113 avg loss: 0.05089 (A-MSE: 0.04470) avg lploss: 0.00000
train epoch 1114 avg loss: 0.05134 (A-MSE: 0.04478) avg lploss: 0.00000
train epoch 1115 avg loss: 0.05406 (A-MSE: 0.04719) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.40191 (A-MSE: 0.34937) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.44944 (A-MSE: 0.39359) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 29 out of 50
train epoch 1116 avg loss: 0.05462 (A-MSE: 0.04784) avg lploss: 0.00000
train epoch 1117 avg loss: 0.04746 (A-MSE: 0.04197) avg lploss: 0.00000
train epoch 1118 avg loss: 0.06568 (A-MSE: 0.05798) avg lploss: 0.00000
train epoch 1119 avg loss: 0.06850 (A-MSE: 0.06028) avg lploss: 0.00000
train epoch 1120 avg loss: 0.06256 (A-MSE: 0.05540) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.37550 (A-MSE: 0.31899) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.41959 (A-MSE: 0.36537) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 30 out of 50
train epoch 1121 avg loss: 0.06523 (A-MSE: 0.05760) avg lploss: 0.00000
train epoch 1122 avg loss: 0.05663 (A-MSE: 0.05013) avg lploss: 0.00000
train epoch 1123 avg loss: 0.05295 (A-MSE: 0.04658) avg lploss: 0.00000
train epoch 1124 avg loss: 0.04917 (A-MSE: 0.04272) avg lploss: 0.00000
train epoch 1125 avg loss: 0.05142 (A-MSE: 0.04518) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.38358 (A-MSE: 0.32689) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.41367 (A-MSE: 0.35787) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 31 out of 50
train epoch 1126 avg loss: 0.06141 (A-MSE: 0.05509) avg lploss: 0.00000
train epoch 1127 avg loss: 0.06656 (A-MSE: 0.05918) avg lploss: 0.00000
train epoch 1128 avg loss: 0.04895 (A-MSE: 0.04360) avg lploss: 0.00000
train epoch 1129 avg loss: 0.03974 (A-MSE: 0.03458) avg lploss: 0.00000
train epoch 1130 avg loss: 0.03731 (A-MSE: 0.03271) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.36444 (A-MSE: 0.31071) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.41061 (A-MSE: 0.35740) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 32 out of 50
train epoch 1131 avg loss: 0.04784 (A-MSE: 0.04204) avg lploss: 0.00000
train epoch 1132 avg loss: 0.05374 (A-MSE: 0.04806) avg lploss: 0.00000
train epoch 1133 avg loss: 0.05241 (A-MSE: 0.04663) avg lploss: 0.00000
train epoch 1134 avg loss: 0.05078 (A-MSE: 0.04544) avg lploss: 0.00000
train epoch 1135 avg loss: 0.05022 (A-MSE: 0.04400) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.38572 (A-MSE: 0.33138) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.44658 (A-MSE: 0.38900) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 33 out of 50
train epoch 1136 avg loss: 0.05295 (A-MSE: 0.04651) avg lploss: 0.00000
train epoch 1137 avg loss: 0.04615 (A-MSE: 0.04063) avg lploss: 0.00000
train epoch 1138 avg loss: 0.04414 (A-MSE: 0.03901) avg lploss: 0.00000
train epoch 1139 avg loss: 0.04855 (A-MSE: 0.04278) avg lploss: 0.00000
train epoch 1140 avg loss: 0.05883 (A-MSE: 0.05166) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.39257 (A-MSE: 0.33876) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.43820 (A-MSE: 0.38296) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 34 out of 50
train epoch 1141 avg loss: 0.05809 (A-MSE: 0.05146) avg lploss: 0.00000
train epoch 1142 avg loss: 0.05965 (A-MSE: 0.05284) avg lploss: 0.00000
train epoch 1143 avg loss: 0.06426 (A-MSE: 0.05708) avg lploss: 0.00000
train epoch 1144 avg loss: 0.07821 (A-MSE: 0.07067) avg lploss: 0.00000
train epoch 1145 avg loss: 0.12167 (A-MSE: 0.10951) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.44890 (A-MSE: 0.38780) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.49373 (A-MSE: 0.43653) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 35 out of 50
train epoch 1146 avg loss: 0.13757 (A-MSE: 0.12208) avg lploss: 0.00000
train epoch 1147 avg loss: 0.10900 (A-MSE: 0.09718) avg lploss: 0.00000
train epoch 1148 avg loss: 0.09010 (A-MSE: 0.07924) avg lploss: 0.00000
train epoch 1149 avg loss: 0.07377 (A-MSE: 0.06469) avg lploss: 0.00000
train epoch 1150 avg loss: 0.06930 (A-MSE: 0.06069) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.38423 (A-MSE: 0.33567) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.44306 (A-MSE: 0.38939) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 36 out of 50
train epoch 1151 avg loss: 0.04947 (A-MSE: 0.04435) avg lploss: 0.00000
train epoch 1152 avg loss: 0.04456 (A-MSE: 0.03895) avg lploss: 0.00000
train epoch 1153 avg loss: 0.05376 (A-MSE: 0.04674) avg lploss: 0.00000
train epoch 1154 avg loss: 0.05908 (A-MSE: 0.05202) avg lploss: 0.00000
train epoch 1155 avg loss: 0.05942 (A-MSE: 0.05232) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.38158 (A-MSE: 0.32526) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.42467 (A-MSE: 0.36960) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 37 out of 50
train epoch 1156 avg loss: 0.05415 (A-MSE: 0.04792) avg lploss: 0.00000
train epoch 1157 avg loss: 0.06214 (A-MSE: 0.05593) avg lploss: 0.00000
train epoch 1158 avg loss: 0.08061 (A-MSE: 0.07155) avg lploss: 0.00000
train epoch 1159 avg loss: 0.07939 (A-MSE: 0.07072) avg lploss: 0.00000
train epoch 1160 avg loss: 0.06730 (A-MSE: 0.05964) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.36815 (A-MSE: 0.31680) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.43161 (A-MSE: 0.37720) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 38 out of 50
train epoch 1161 avg loss: 0.05957 (A-MSE: 0.05189) avg lploss: 0.00000
train epoch 1162 avg loss: 0.04916 (A-MSE: 0.04341) avg lploss: 0.00000
train epoch 1163 avg loss: 0.04868 (A-MSE: 0.04359) avg lploss: 0.00000
train epoch 1164 avg loss: 0.04157 (A-MSE: 0.03670) avg lploss: 0.00000
train epoch 1165 avg loss: 0.04323 (A-MSE: 0.03833) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.39900 (A-MSE: 0.33852) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.43453 (A-MSE: 0.37784) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 39 out of 50
train epoch 1166 avg loss: 0.04959 (A-MSE: 0.04351) avg lploss: 0.00000
train epoch 1167 avg loss: 0.06303 (A-MSE: 0.05604) avg lploss: 0.00000
train epoch 1168 avg loss: 0.07177 (A-MSE: 0.06319) avg lploss: 0.00000
train epoch 1169 avg loss: 0.05634 (A-MSE: 0.04948) avg lploss: 0.00000
train epoch 1170 avg loss: 0.05217 (A-MSE: 0.04584) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.38824 (A-MSE: 0.33344) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.42359 (A-MSE: 0.36952) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 40 out of 50
train epoch 1171 avg loss: 0.05185 (A-MSE: 0.04587) avg lploss: 0.00000
train epoch 1172 avg loss: 0.05483 (A-MSE: 0.04846) avg lploss: 0.00000
train epoch 1173 avg loss: 0.06710 (A-MSE: 0.05945) avg lploss: 0.00000
train epoch 1174 avg loss: 0.05763 (A-MSE: 0.05105) avg lploss: 0.00000
train epoch 1175 avg loss: 0.05081 (A-MSE: 0.04430) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.39843 (A-MSE: 0.34276) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.45221 (A-MSE: 0.39518) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 41 out of 50
train epoch 1176 avg loss: 0.05118 (A-MSE: 0.04453) avg lploss: 0.00000
train epoch 1177 avg loss: 0.05415 (A-MSE: 0.04747) avg lploss: 0.00000
train epoch 1178 avg loss: 0.05779 (A-MSE: 0.05117) avg lploss: 0.00000
train epoch 1179 avg loss: 0.07669 (A-MSE: 0.06800) avg lploss: 0.00000
train epoch 1180 avg loss: 0.06208 (A-MSE: 0.05496) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.38239 (A-MSE: 0.32652) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.45412 (A-MSE: 0.39498) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 42 out of 50
train epoch 1181 avg loss: 0.06357 (A-MSE: 0.05606) avg lploss: 0.00000
train epoch 1182 avg loss: 0.05591 (A-MSE: 0.04979) avg lploss: 0.00000
train epoch 1183 avg loss: 0.05767 (A-MSE: 0.05108) avg lploss: 0.00000
train epoch 1184 avg loss: 0.06347 (A-MSE: 0.05639) avg lploss: 0.00000
train epoch 1185 avg loss: 0.06045 (A-MSE: 0.05389) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.38118 (A-MSE: 0.33047) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.43734 (A-MSE: 0.38562) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 43 out of 50
train epoch 1186 avg loss: 0.06633 (A-MSE: 0.05879) avg lploss: 0.00000
train epoch 1187 avg loss: 0.05825 (A-MSE: 0.05214) avg lploss: 0.00000
train epoch 1188 avg loss: 0.06275 (A-MSE: 0.05560) avg lploss: 0.00000
train epoch 1189 avg loss: 0.06065 (A-MSE: 0.05338) avg lploss: 0.00000
train epoch 1190 avg loss: 0.04774 (A-MSE: 0.04208) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.35684 (A-MSE: 0.30731) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.40807 (A-MSE: 0.35472) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 44 out of 50
train epoch 1191 avg loss: 0.04634 (A-MSE: 0.04087) avg lploss: 0.00000
train epoch 1192 avg loss: 0.04190 (A-MSE: 0.03660) avg lploss: 0.00000
train epoch 1193 avg loss: 0.03507 (A-MSE: 0.03095) avg lploss: 0.00000
train epoch 1194 avg loss: 0.04019 (A-MSE: 0.03550) avg lploss: 0.00000
train epoch 1195 avg loss: 0.04844 (A-MSE: 0.04296) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.40853 (A-MSE: 0.35041) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.46021 (A-MSE: 0.40261) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 45 out of 50
train epoch 1196 avg loss: 0.04730 (A-MSE: 0.04125) avg lploss: 0.00000
train epoch 1197 avg loss: 0.04700 (A-MSE: 0.04104) avg lploss: 0.00000
train epoch 1198 avg loss: 0.03915 (A-MSE: 0.03428) avg lploss: 0.00000
train epoch 1199 avg loss: 0.03623 (A-MSE: 0.03188) avg lploss: 0.00000
train epoch 1200 avg loss: 0.04376 (A-MSE: 0.03863) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.39756 (A-MSE: 0.33759) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.44423 (A-MSE: 0.38747) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 46 out of 50
train epoch 1201 avg loss: 0.04393 (A-MSE: 0.03905) avg lploss: 0.00000
train epoch 1202 avg loss: 0.06264 (A-MSE: 0.05635) avg lploss: 0.00000
train epoch 1203 avg loss: 0.07871 (A-MSE: 0.06932) avg lploss: 0.00000
train epoch 1204 avg loss: 0.07415 (A-MSE: 0.06595) avg lploss: 0.00000
train epoch 1205 avg loss: 0.06671 (A-MSE: 0.06011) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.43120 (A-MSE: 0.36994) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.44702 (A-MSE: 0.39128) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 47 out of 50
train epoch 1206 avg loss: 0.06388 (A-MSE: 0.05699) avg lploss: 0.00000
train epoch 1207 avg loss: 0.06454 (A-MSE: 0.05675) avg lploss: 0.00000
train epoch 1208 avg loss: 0.05236 (A-MSE: 0.04553) avg lploss: 0.00000
train epoch 1209 avg loss: 0.04824 (A-MSE: 0.04260) avg lploss: 0.00000
train epoch 1210 avg loss: 0.04422 (A-MSE: 0.03934) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.39685 (A-MSE: 0.34038) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.43520 (A-MSE: 0.38033) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 48 out of 50
train epoch 1211 avg loss: 0.04492 (A-MSE: 0.03919) avg lploss: 0.00000
train epoch 1212 avg loss: 0.05150 (A-MSE: 0.04521) avg lploss: 0.00000
train epoch 1213 avg loss: 0.04591 (A-MSE: 0.03979) avg lploss: 0.00000
train epoch 1214 avg loss: 0.03833 (A-MSE: 0.03339) avg lploss: 0.00000
train epoch 1215 avg loss: 0.04468 (A-MSE: 0.03908) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.38913 (A-MSE: 0.33152) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.43279 (A-MSE: 0.37984) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 49 out of 50
train epoch 1216 avg loss: 0.05147 (A-MSE: 0.04533) avg lploss: 0.00000
train epoch 1217 avg loss: 0.04853 (A-MSE: 0.04242) avg lploss: 0.00000
train epoch 1218 avg loss: 0.05412 (A-MSE: 0.04841) avg lploss: 0.00000
train epoch 1219 avg loss: 0.04642 (A-MSE: 0.04058) avg lploss: 0.00000
train epoch 1220 avg loss: 0.04206 (A-MSE: 0.03687) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.41831 (A-MSE: 0.35918) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.46111 (A-MSE: 0.40194) avg lploss: 0.00000
*** Best Val Loss: 0.33920 	 Best Test Loss: 0.40229 	 Best epoch 970
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.077346
best_lp = 0.000000
best_val = 0.339204
best_test = 0.402288
best_epoch = 970
best_train = 0.077346, best_lp = 0.000000, best_val = 0.339204, best_test = 0.402288, best_epoch = 970
Training completed for seed 2 with num_modes=1
