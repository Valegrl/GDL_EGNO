Running Mocap-Run with num_modes=1 for seed 3
Job ID: 3831011, Array Task ID: 3
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes1_seed3.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes1_seed3', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=1, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=3, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes1_seed3/saved_model.pth
train epoch 0 avg loss: 105653.78320 (A-MSE: 105658.15257) avg lploss: 0.00000
==> val epoch 0 avg loss: 99.20512 (A-MSE: 87.56582) avg lploss: 0.00000
==> test epoch 0 avg loss: 94.40234 (A-MSE: 83.33523) avg lploss: 0.00000
*** Best Val Loss: 99.20512 	 Best Test Loss: 94.40234 	 Best epoch 0
Validation loss decreased (inf --> 99.205119).  Saving model ...
train epoch 1 avg loss: 95.82386 (A-MSE: 84.63299) avg lploss: 0.00000
train epoch 2 avg loss: 94.51728 (A-MSE: 83.39379) avg lploss: 0.00000
train epoch 3 avg loss: 92.55986 (A-MSE: 81.58567) avg lploss: 0.00000
train epoch 4 avg loss: 87.97271 (A-MSE: 77.62967) avg lploss: 0.00000
train epoch 5 avg loss: 79.94126 (A-MSE: 70.34783) avg lploss: 0.00000
==> val epoch 5 avg loss: 74.51586 (A-MSE: 65.45562) avg lploss: 0.00000
==> test epoch 5 avg loss: 70.49327 (A-MSE: 61.96930) avg lploss: 0.00000
*** Best Val Loss: 74.51586 	 Best Test Loss: 70.49327 	 Best epoch 5
Validation loss decreased (99.205119 --> 74.515859).  Saving model ...
train epoch 6 avg loss: 66.81625 (A-MSE: 58.59265) avg lploss: 0.00000
train epoch 7 avg loss: 54.55987 (A-MSE: 47.84833) avg lploss: 0.00000
train epoch 8 avg loss: 46.09104 (A-MSE: 40.30674) avg lploss: 0.00000
train epoch 9 avg loss: 40.14278 (A-MSE: 35.05783) avg lploss: 0.00000
train epoch 10 avg loss: 37.36133 (A-MSE: 32.62805) avg lploss: 0.00000
==> val epoch 10 avg loss: 35.02527 (A-MSE: 30.37315) avg lploss: 0.00000
==> test epoch 10 avg loss: 33.63099 (A-MSE: 29.17497) avg lploss: 0.00000
*** Best Val Loss: 35.02527 	 Best Test Loss: 33.63099 	 Best epoch 10
Validation loss decreased (74.515859 --> 35.025266).  Saving model ...
train epoch 11 avg loss: 34.25305 (A-MSE: 29.88069) avg lploss: 0.00000
train epoch 12 avg loss: 31.83050 (A-MSE: 27.81424) avg lploss: 0.00000
train epoch 13 avg loss: 30.01060 (A-MSE: 26.20471) avg lploss: 0.00000
train epoch 14 avg loss: 27.82975 (A-MSE: 24.31125) avg lploss: 0.00000
train epoch 15 avg loss: 26.72186 (A-MSE: 23.36990) avg lploss: 0.00000
==> val epoch 15 avg loss: 26.19686 (A-MSE: 22.46346) avg lploss: 0.00000
==> test epoch 15 avg loss: 25.15837 (A-MSE: 21.49976) avg lploss: 0.00000
*** Best Val Loss: 26.19686 	 Best Test Loss: 25.15837 	 Best epoch 15
Validation loss decreased (35.025266 --> 26.196864).  Saving model ...
train epoch 16 avg loss: 24.84847 (A-MSE: 21.69110) avg lploss: 0.00000
train epoch 17 avg loss: 23.84057 (A-MSE: 20.85300) avg lploss: 0.00000
train epoch 18 avg loss: 22.06644 (A-MSE: 19.26140) avg lploss: 0.00000
train epoch 19 avg loss: 20.44440 (A-MSE: 17.84932) avg lploss: 0.00000
train epoch 20 avg loss: 20.36990 (A-MSE: 17.83379) avg lploss: 0.00000
==> val epoch 20 avg loss: 18.73953 (A-MSE: 16.35039) avg lploss: 0.00000
==> test epoch 20 avg loss: 17.55704 (A-MSE: 15.21126) avg lploss: 0.00000
*** Best Val Loss: 18.73953 	 Best Test Loss: 17.55704 	 Best epoch 20
Validation loss decreased (26.196864 --> 18.739530).  Saving model ...
train epoch 21 avg loss: 18.89753 (A-MSE: 16.49860) avg lploss: 0.00000
train epoch 22 avg loss: 18.01158 (A-MSE: 15.70288) avg lploss: 0.00000
train epoch 23 avg loss: 16.40069 (A-MSE: 14.33435) avg lploss: 0.00000
train epoch 24 avg loss: 15.13273 (A-MSE: 13.22574) avg lploss: 0.00000
train epoch 25 avg loss: 13.82199 (A-MSE: 12.01122) avg lploss: 0.00000
==> val epoch 25 avg loss: 13.07167 (A-MSE: 11.11579) avg lploss: 0.00000
==> test epoch 25 avg loss: 12.89902 (A-MSE: 10.94700) avg lploss: 0.00000
*** Best Val Loss: 13.07167 	 Best Test Loss: 12.89902 	 Best epoch 25
Validation loss decreased (18.739530 --> 13.071674).  Saving model ...
train epoch 26 avg loss: 12.77936 (A-MSE: 11.15686) avg lploss: 0.00000
train epoch 27 avg loss: 12.04144 (A-MSE: 10.53627) avg lploss: 0.00000
train epoch 28 avg loss: 11.60468 (A-MSE: 10.15017) avg lploss: 0.00000
train epoch 29 avg loss: 10.34747 (A-MSE: 9.01839) avg lploss: 0.00000
train epoch 30 avg loss: 10.21480 (A-MSE: 8.92236) avg lploss: 0.00000
==> val epoch 30 avg loss: 10.02377 (A-MSE: 8.68936) avg lploss: 0.00000
==> test epoch 30 avg loss: 10.13148 (A-MSE: 8.77455) avg lploss: 0.00000
*** Best Val Loss: 10.02377 	 Best Test Loss: 10.13148 	 Best epoch 30
Validation loss decreased (13.071674 --> 10.023768).  Saving model ...
train epoch 31 avg loss: 9.36231 (A-MSE: 8.19259) avg lploss: 0.00000
train epoch 32 avg loss: 9.53689 (A-MSE: 8.33562) avg lploss: 0.00000
train epoch 33 avg loss: 8.56975 (A-MSE: 7.51283) avg lploss: 0.00000
train epoch 34 avg loss: 8.08885 (A-MSE: 7.05803) avg lploss: 0.00000
train epoch 35 avg loss: 7.77434 (A-MSE: 6.81278) avg lploss: 0.00000
==> val epoch 35 avg loss: 8.74578 (A-MSE: 7.46746) avg lploss: 0.00000
==> test epoch 35 avg loss: 9.21821 (A-MSE: 7.90157) avg lploss: 0.00000
*** Best Val Loss: 8.74578 	 Best Test Loss: 9.21821 	 Best epoch 35
Validation loss decreased (10.023768 --> 8.745783).  Saving model ...
train epoch 36 avg loss: 7.74513 (A-MSE: 6.74937) avg lploss: 0.00000
train epoch 37 avg loss: 7.31593 (A-MSE: 6.44631) avg lploss: 0.00000
train epoch 38 avg loss: 6.85342 (A-MSE: 5.96030) avg lploss: 0.00000
train epoch 39 avg loss: 6.57567 (A-MSE: 5.75105) avg lploss: 0.00000
train epoch 40 avg loss: 6.28712 (A-MSE: 5.48380) avg lploss: 0.00000
==> val epoch 40 avg loss: 7.20817 (A-MSE: 6.08571) avg lploss: 0.00000
==> test epoch 40 avg loss: 7.53238 (A-MSE: 6.37316) avg lploss: 0.00000
*** Best Val Loss: 7.20817 	 Best Test Loss: 7.53238 	 Best epoch 40
Validation loss decreased (8.745783 --> 7.208171).  Saving model ...
train epoch 41 avg loss: 6.32554 (A-MSE: 5.50102) avg lploss: 0.00000
train epoch 42 avg loss: 6.37760 (A-MSE: 5.59605) avg lploss: 0.00000
train epoch 43 avg loss: 6.17118 (A-MSE: 5.36292) avg lploss: 0.00000
train epoch 44 avg loss: 5.79359 (A-MSE: 5.04201) avg lploss: 0.00000
train epoch 45 avg loss: 5.57868 (A-MSE: 4.88231) avg lploss: 0.00000
==> val epoch 45 avg loss: 6.78527 (A-MSE: 5.66500) avg lploss: 0.00000
==> test epoch 45 avg loss: 7.30373 (A-MSE: 6.14212) avg lploss: 0.00000
*** Best Val Loss: 6.78527 	 Best Test Loss: 7.30373 	 Best epoch 45
Validation loss decreased (7.208171 --> 6.785275).  Saving model ...
train epoch 46 avg loss: 5.34117 (A-MSE: 4.62490) avg lploss: 0.00000
train epoch 47 avg loss: 5.36401 (A-MSE: 4.68275) avg lploss: 0.00000
train epoch 48 avg loss: 5.53980 (A-MSE: 4.83181) avg lploss: 0.00000
train epoch 49 avg loss: 5.23495 (A-MSE: 4.53825) avg lploss: 0.00000
train epoch 50 avg loss: 5.11441 (A-MSE: 4.45419) avg lploss: 0.00000
==> val epoch 50 avg loss: 5.94128 (A-MSE: 5.04705) avg lploss: 0.00000
==> test epoch 50 avg loss: 6.37626 (A-MSE: 5.44452) avg lploss: 0.00000
*** Best Val Loss: 5.94128 	 Best Test Loss: 6.37626 	 Best epoch 50
Validation loss decreased (6.785275 --> 5.941284).  Saving model ...
train epoch 51 avg loss: 5.17389 (A-MSE: 4.48835) avg lploss: 0.00000
train epoch 52 avg loss: 4.90120 (A-MSE: 4.28358) avg lploss: 0.00000
train epoch 53 avg loss: 4.72385 (A-MSE: 4.10910) avg lploss: 0.00000
train epoch 54 avg loss: 4.55767 (A-MSE: 3.95963) avg lploss: 0.00000
train epoch 55 avg loss: 4.66884 (A-MSE: 4.06366) avg lploss: 0.00000
==> val epoch 55 avg loss: 5.38022 (A-MSE: 4.42819) avg lploss: 0.00000
==> test epoch 55 avg loss: 5.97477 (A-MSE: 4.96342) avg lploss: 0.00000
*** Best Val Loss: 5.38022 	 Best Test Loss: 5.97477 	 Best epoch 55
Validation loss decreased (5.941284 --> 5.380219).  Saving model ...
train epoch 56 avg loss: 4.58541 (A-MSE: 3.96558) avg lploss: 0.00000
train epoch 57 avg loss: 4.73852 (A-MSE: 4.10952) avg lploss: 0.00000
train epoch 58 avg loss: 4.41585 (A-MSE: 3.83184) avg lploss: 0.00000
train epoch 59 avg loss: 4.31076 (A-MSE: 3.73216) avg lploss: 0.00000
train epoch 60 avg loss: 4.20403 (A-MSE: 3.64049) avg lploss: 0.00000
==> val epoch 60 avg loss: 5.36104 (A-MSE: 4.36627) avg lploss: 0.00000
==> test epoch 60 avg loss: 5.97700 (A-MSE: 4.92917) avg lploss: 0.00000
*** Best Val Loss: 5.36104 	 Best Test Loss: 5.97700 	 Best epoch 60
Validation loss decreased (5.380219 --> 5.361041).  Saving model ...
train epoch 61 avg loss: 4.28607 (A-MSE: 3.71458) avg lploss: 0.00000
train epoch 62 avg loss: 4.25255 (A-MSE: 3.68389) avg lploss: 0.00000
train epoch 63 avg loss: 4.31454 (A-MSE: 3.72150) avg lploss: 0.00000
train epoch 64 avg loss: 4.31651 (A-MSE: 3.74432) avg lploss: 0.00000
train epoch 65 avg loss: 3.97938 (A-MSE: 3.41138) avg lploss: 0.00000
==> val epoch 65 avg loss: 4.70378 (A-MSE: 4.04640) avg lploss: 0.00000
==> test epoch 65 avg loss: 5.30763 (A-MSE: 4.56665) avg lploss: 0.00000
*** Best Val Loss: 4.70378 	 Best Test Loss: 5.30763 	 Best epoch 65
Validation loss decreased (5.361041 --> 4.703778).  Saving model ...
train epoch 66 avg loss: 3.88501 (A-MSE: 3.38862) avg lploss: 0.00000
train epoch 67 avg loss: 3.91434 (A-MSE: 3.34626) avg lploss: 0.00000
train epoch 68 avg loss: 4.16447 (A-MSE: 3.61650) avg lploss: 0.00000
train epoch 69 avg loss: 3.87776 (A-MSE: 3.34332) avg lploss: 0.00000
train epoch 70 avg loss: 3.78139 (A-MSE: 3.25229) avg lploss: 0.00000
==> val epoch 70 avg loss: 5.11255 (A-MSE: 4.30974) avg lploss: 0.00000
==> test epoch 70 avg loss: 5.80847 (A-MSE: 4.93201) avg lploss: 0.00000
*** Best Val Loss: 4.70378 	 Best Test Loss: 5.30763 	 Best epoch 65
EarlyStopping counter: 1 out of 50
train epoch 71 avg loss: 3.82931 (A-MSE: 3.33174) avg lploss: 0.00000
train epoch 72 avg loss: 4.01538 (A-MSE: 3.45366) avg lploss: 0.00000
train epoch 73 avg loss: 3.70038 (A-MSE: 3.17329) avg lploss: 0.00000
train epoch 74 avg loss: 3.71890 (A-MSE: 3.20545) avg lploss: 0.00000
train epoch 75 avg loss: 3.71013 (A-MSE: 3.21234) avg lploss: 0.00000
==> val epoch 75 avg loss: 4.25317 (A-MSE: 3.46688) avg lploss: 0.00000
==> test epoch 75 avg loss: 4.79796 (A-MSE: 3.94657) avg lploss: 0.00000
*** Best Val Loss: 4.25317 	 Best Test Loss: 4.79796 	 Best epoch 75
Validation loss decreased (4.703778 --> 4.253173).  Saving model ...
train epoch 76 avg loss: 3.51289 (A-MSE: 3.01795) avg lploss: 0.00000
train epoch 77 avg loss: 3.62859 (A-MSE: 3.10865) avg lploss: 0.00000
train epoch 78 avg loss: 3.26223 (A-MSE: 2.79369) avg lploss: 0.00000
train epoch 79 avg loss: 3.30824 (A-MSE: 2.84815) avg lploss: 0.00000
train epoch 80 avg loss: 3.82814 (A-MSE: 3.27760) avg lploss: 0.00000
==> val epoch 80 avg loss: 5.06374 (A-MSE: 4.22139) avg lploss: 0.00000
==> test epoch 80 avg loss: 5.70261 (A-MSE: 4.80076) avg lploss: 0.00000
*** Best Val Loss: 4.25317 	 Best Test Loss: 4.79796 	 Best epoch 75
EarlyStopping counter: 1 out of 50
train epoch 81 avg loss: 3.66197 (A-MSE: 3.14848) avg lploss: 0.00000
train epoch 82 avg loss: 3.21298 (A-MSE: 2.73280) avg lploss: 0.00000
train epoch 83 avg loss: 3.41873 (A-MSE: 2.94139) avg lploss: 0.00000
train epoch 84 avg loss: 3.28575 (A-MSE: 2.83054) avg lploss: 0.00000
train epoch 85 avg loss: 3.40232 (A-MSE: 2.90200) avg lploss: 0.00000
==> val epoch 85 avg loss: 4.03925 (A-MSE: 3.33277) avg lploss: 0.00000
==> test epoch 85 avg loss: 4.62431 (A-MSE: 3.85296) avg lploss: 0.00000
*** Best Val Loss: 4.03925 	 Best Test Loss: 4.62431 	 Best epoch 85
Validation loss decreased (4.253173 --> 4.039251).  Saving model ...
train epoch 86 avg loss: 3.15550 (A-MSE: 2.69172) avg lploss: 0.00000
train epoch 87 avg loss: 3.17378 (A-MSE: 2.71989) avg lploss: 0.00000
train epoch 88 avg loss: 3.25433 (A-MSE: 2.77789) avg lploss: 0.00000
train epoch 89 avg loss: 3.04649 (A-MSE: 2.59765) avg lploss: 0.00000
train epoch 90 avg loss: 3.05650 (A-MSE: 2.62052) avg lploss: 0.00000
==> val epoch 90 avg loss: 4.39639 (A-MSE: 3.63064) avg lploss: 0.00000
==> test epoch 90 avg loss: 4.92208 (A-MSE: 4.11257) avg lploss: 0.00000
*** Best Val Loss: 4.03925 	 Best Test Loss: 4.62431 	 Best epoch 85
EarlyStopping counter: 1 out of 50
train epoch 91 avg loss: 2.92512 (A-MSE: 2.48790) avg lploss: 0.00000
train epoch 92 avg loss: 2.95434 (A-MSE: 2.50666) avg lploss: 0.00000
train epoch 93 avg loss: 2.91896 (A-MSE: 2.47548) avg lploss: 0.00000
train epoch 94 avg loss: 2.91987 (A-MSE: 2.47934) avg lploss: 0.00000
train epoch 95 avg loss: 3.02427 (A-MSE: 2.56661) avg lploss: 0.00000
==> val epoch 95 avg loss: 3.65753 (A-MSE: 3.25773) avg lploss: 0.00000
==> test epoch 95 avg loss: 4.17244 (A-MSE: 3.71266) avg lploss: 0.00000
*** Best Val Loss: 3.65753 	 Best Test Loss: 4.17244 	 Best epoch 95
Validation loss decreased (4.039251 --> 3.657533).  Saving model ...
train epoch 96 avg loss: 2.95044 (A-MSE: 2.52093) avg lploss: 0.00000
train epoch 97 avg loss: 2.90266 (A-MSE: 2.46635) avg lploss: 0.00000
train epoch 98 avg loss: 3.11295 (A-MSE: 2.64767) avg lploss: 0.00000
train epoch 99 avg loss: 2.79540 (A-MSE: 2.38985) avg lploss: 0.00000
train epoch 100 avg loss: 2.65930 (A-MSE: 2.23869) avg lploss: 0.00000
==> val epoch 100 avg loss: 4.17974 (A-MSE: 3.39230) avg lploss: 0.00000
==> test epoch 100 avg loss: 4.76987 (A-MSE: 3.92915) avg lploss: 0.00000
*** Best Val Loss: 3.65753 	 Best Test Loss: 4.17244 	 Best epoch 95
EarlyStopping counter: 1 out of 50
train epoch 101 avg loss: 2.91257 (A-MSE: 2.47521) avg lploss: 0.00000
train epoch 102 avg loss: 2.67054 (A-MSE: 2.27332) avg lploss: 0.00000
train epoch 103 avg loss: 2.62320 (A-MSE: 2.20790) avg lploss: 0.00000
train epoch 104 avg loss: 2.59317 (A-MSE: 2.16305) avg lploss: 0.00000
train epoch 105 avg loss: 2.54805 (A-MSE: 2.15464) avg lploss: 0.00000
==> val epoch 105 avg loss: 3.25185 (A-MSE: 2.73099) avg lploss: 0.00000
==> test epoch 105 avg loss: 3.63872 (A-MSE: 3.07230) avg lploss: 0.00000
*** Best Val Loss: 3.25185 	 Best Test Loss: 3.63872 	 Best epoch 105
Validation loss decreased (3.657533 --> 3.251853).  Saving model ...
train epoch 106 avg loss: 2.68133 (A-MSE: 2.25687) avg lploss: 0.00000
train epoch 107 avg loss: 2.68967 (A-MSE: 2.27756) avg lploss: 0.00000
train epoch 108 avg loss: 2.57095 (A-MSE: 2.16859) avg lploss: 0.00000
train epoch 109 avg loss: 2.64550 (A-MSE: 2.22271) avg lploss: 0.00000
train epoch 110 avg loss: 2.51043 (A-MSE: 2.10877) avg lploss: 0.00000
==> val epoch 110 avg loss: 3.74150 (A-MSE: 3.10565) avg lploss: 0.00000
==> test epoch 110 avg loss: 4.34930 (A-MSE: 3.65842) avg lploss: 0.00000
*** Best Val Loss: 3.25185 	 Best Test Loss: 3.63872 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 2.58006 (A-MSE: 2.16943) avg lploss: 0.00000
train epoch 112 avg loss: 2.65621 (A-MSE: 2.23570) avg lploss: 0.00000
train epoch 113 avg loss: 2.58890 (A-MSE: 2.20149) avg lploss: 0.00000
train epoch 114 avg loss: 2.52902 (A-MSE: 2.11697) avg lploss: 0.00000
train epoch 115 avg loss: 2.41898 (A-MSE: 2.02649) avg lploss: 0.00000
==> val epoch 115 avg loss: 3.23307 (A-MSE: 2.72186) avg lploss: 0.00000
==> test epoch 115 avg loss: 3.70517 (A-MSE: 3.15602) avg lploss: 0.00000
*** Best Val Loss: 3.23307 	 Best Test Loss: 3.70517 	 Best epoch 115
Validation loss decreased (3.251853 --> 3.233069).  Saving model ...
train epoch 116 avg loss: 2.41322 (A-MSE: 2.01714) avg lploss: 0.00000
train epoch 117 avg loss: 2.31078 (A-MSE: 1.94068) avg lploss: 0.00000
train epoch 118 avg loss: 2.31924 (A-MSE: 1.95156) avg lploss: 0.00000
train epoch 119 avg loss: 2.32425 (A-MSE: 1.92189) avg lploss: 0.00000
train epoch 120 avg loss: 2.39082 (A-MSE: 2.00392) avg lploss: 0.00000
==> val epoch 120 avg loss: 2.86288 (A-MSE: 2.41837) avg lploss: 0.00000
==> test epoch 120 avg loss: 3.27426 (A-MSE: 2.79376) avg lploss: 0.00000
*** Best Val Loss: 2.86288 	 Best Test Loss: 3.27426 	 Best epoch 120
Validation loss decreased (3.233069 --> 2.862883).  Saving model ...
train epoch 121 avg loss: 2.44830 (A-MSE: 2.05892) avg lploss: 0.00000
train epoch 122 avg loss: 2.40442 (A-MSE: 2.00891) avg lploss: 0.00000
train epoch 123 avg loss: 2.41154 (A-MSE: 2.03405) avg lploss: 0.00000
train epoch 124 avg loss: 2.43097 (A-MSE: 2.04103) avg lploss: 0.00000
train epoch 125 avg loss: 2.42343 (A-MSE: 2.03832) avg lploss: 0.00000
==> val epoch 125 avg loss: 2.98035 (A-MSE: 2.52621) avg lploss: 0.00000
==> test epoch 125 avg loss: 3.21853 (A-MSE: 2.73994) avg lploss: 0.00000
*** Best Val Loss: 2.86288 	 Best Test Loss: 3.27426 	 Best epoch 120
EarlyStopping counter: 1 out of 50
train epoch 126 avg loss: 2.32394 (A-MSE: 1.94842) avg lploss: 0.00000
train epoch 127 avg loss: 2.22344 (A-MSE: 1.84081) avg lploss: 0.00000
train epoch 128 avg loss: 2.24724 (A-MSE: 1.89576) avg lploss: 0.00000
train epoch 129 avg loss: 2.26795 (A-MSE: 1.88401) avg lploss: 0.00000
train epoch 130 avg loss: 2.29347 (A-MSE: 1.92686) avg lploss: 0.00000
==> val epoch 130 avg loss: 2.75822 (A-MSE: 2.30974) avg lploss: 0.00000
==> test epoch 130 avg loss: 3.10198 (A-MSE: 2.63021) avg lploss: 0.00000
*** Best Val Loss: 2.75822 	 Best Test Loss: 3.10198 	 Best epoch 130
Validation loss decreased (2.862883 --> 2.758217).  Saving model ...
train epoch 131 avg loss: 2.25128 (A-MSE: 1.86931) avg lploss: 0.00000
train epoch 132 avg loss: 2.11286 (A-MSE: 1.76554) avg lploss: 0.00000
train epoch 133 avg loss: 2.13151 (A-MSE: 1.76824) avg lploss: 0.00000
train epoch 134 avg loss: 2.02558 (A-MSE: 1.68595) avg lploss: 0.00000
train epoch 135 avg loss: 2.23966 (A-MSE: 1.84841) avg lploss: 0.00000
==> val epoch 135 avg loss: 2.49339 (A-MSE: 2.09451) avg lploss: 0.00000
==> test epoch 135 avg loss: 2.82328 (A-MSE: 2.40948) avg lploss: 0.00000
*** Best Val Loss: 2.49339 	 Best Test Loss: 2.82328 	 Best epoch 135
Validation loss decreased (2.758217 --> 2.493390).  Saving model ...
train epoch 136 avg loss: 2.18499 (A-MSE: 1.83729) avg lploss: 0.00000
train epoch 137 avg loss: 2.13995 (A-MSE: 1.76767) avg lploss: 0.00000
train epoch 138 avg loss: 2.18033 (A-MSE: 1.82898) avg lploss: 0.00000
train epoch 139 avg loss: 2.24039 (A-MSE: 1.85590) avg lploss: 0.00000
train epoch 140 avg loss: 2.18086 (A-MSE: 1.82850) avg lploss: 0.00000
==> val epoch 140 avg loss: 3.41528 (A-MSE: 2.86155) avg lploss: 0.00000
==> test epoch 140 avg loss: 3.96267 (A-MSE: 3.39892) avg lploss: 0.00000
*** Best Val Loss: 2.49339 	 Best Test Loss: 2.82328 	 Best epoch 135
EarlyStopping counter: 1 out of 50
train epoch 141 avg loss: 2.04136 (A-MSE: 1.69146) avg lploss: 0.00000
train epoch 142 avg loss: 2.04045 (A-MSE: 1.68839) avg lploss: 0.00000
train epoch 143 avg loss: 2.02139 (A-MSE: 1.68243) avg lploss: 0.00000
train epoch 144 avg loss: 1.99733 (A-MSE: 1.65959) avg lploss: 0.00000
train epoch 145 avg loss: 1.96765 (A-MSE: 1.62941) avg lploss: 0.00000
==> val epoch 145 avg loss: 2.63826 (A-MSE: 2.22283) avg lploss: 0.00000
==> test epoch 145 avg loss: 2.97981 (A-MSE: 2.55715) avg lploss: 0.00000
*** Best Val Loss: 2.49339 	 Best Test Loss: 2.82328 	 Best epoch 135
EarlyStopping counter: 2 out of 50
train epoch 146 avg loss: 1.93456 (A-MSE: 1.60630) avg lploss: 0.00000
train epoch 147 avg loss: 2.00221 (A-MSE: 1.66354) avg lploss: 0.00000
train epoch 148 avg loss: 1.95675 (A-MSE: 1.62385) avg lploss: 0.00000
train epoch 149 avg loss: 1.93506 (A-MSE: 1.58957) avg lploss: 0.00000
train epoch 150 avg loss: 1.86765 (A-MSE: 1.55860) avg lploss: 0.00000
==> val epoch 150 avg loss: 2.74572 (A-MSE: 2.25505) avg lploss: 0.00000
==> test epoch 150 avg loss: 3.06924 (A-MSE: 2.57838) avg lploss: 0.00000
*** Best Val Loss: 2.49339 	 Best Test Loss: 2.82328 	 Best epoch 135
EarlyStopping counter: 3 out of 50
train epoch 151 avg loss: 1.85598 (A-MSE: 1.52437) avg lploss: 0.00000
train epoch 152 avg loss: 1.91242 (A-MSE: 1.58045) avg lploss: 0.00000
train epoch 153 avg loss: 1.83493 (A-MSE: 1.51332) avg lploss: 0.00000
train epoch 154 avg loss: 1.96741 (A-MSE: 1.63514) avg lploss: 0.00000
train epoch 155 avg loss: 1.88795 (A-MSE: 1.55988) avg lploss: 0.00000
==> val epoch 155 avg loss: 2.33989 (A-MSE: 2.07522) avg lploss: 0.00000
==> test epoch 155 avg loss: 2.69617 (A-MSE: 2.42741) avg lploss: 0.00000
*** Best Val Loss: 2.33989 	 Best Test Loss: 2.69617 	 Best epoch 155
Validation loss decreased (2.493390 --> 2.339890).  Saving model ...
train epoch 156 avg loss: 1.88881 (A-MSE: 1.56150) avg lploss: 0.00000
train epoch 157 avg loss: 1.92538 (A-MSE: 1.59667) avg lploss: 0.00000
train epoch 158 avg loss: 1.77121 (A-MSE: 1.46654) avg lploss: 0.00000
train epoch 159 avg loss: 1.79225 (A-MSE: 1.47827) avg lploss: 0.00000
train epoch 160 avg loss: 1.86325 (A-MSE: 1.54202) avg lploss: 0.00000
==> val epoch 160 avg loss: 2.48922 (A-MSE: 2.09633) avg lploss: 0.00000
==> test epoch 160 avg loss: 2.79682 (A-MSE: 2.40391) avg lploss: 0.00000
*** Best Val Loss: 2.33989 	 Best Test Loss: 2.69617 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 1.86302 (A-MSE: 1.53530) avg lploss: 0.00000
train epoch 162 avg loss: 1.69406 (A-MSE: 1.40651) avg lploss: 0.00000
train epoch 163 avg loss: 1.76413 (A-MSE: 1.45086) avg lploss: 0.00000
train epoch 164 avg loss: 1.79020 (A-MSE: 1.48035) avg lploss: 0.00000
train epoch 165 avg loss: 1.74917 (A-MSE: 1.45082) avg lploss: 0.00000
==> val epoch 165 avg loss: 2.18208 (A-MSE: 1.81494) avg lploss: 0.00000
==> test epoch 165 avg loss: 2.43548 (A-MSE: 2.07470) avg lploss: 0.00000
*** Best Val Loss: 2.18208 	 Best Test Loss: 2.43548 	 Best epoch 165
Validation loss decreased (2.339890 --> 2.182075).  Saving model ...
train epoch 166 avg loss: 1.72697 (A-MSE: 1.42508) avg lploss: 0.00000
train epoch 167 avg loss: 1.79592 (A-MSE: 1.49087) avg lploss: 0.00000
train epoch 168 avg loss: 1.96435 (A-MSE: 1.64590) avg lploss: 0.00000
train epoch 169 avg loss: 1.90912 (A-MSE: 1.57927) avg lploss: 0.00000
train epoch 170 avg loss: 1.90108 (A-MSE: 1.59063) avg lploss: 0.00000
==> val epoch 170 avg loss: 3.16880 (A-MSE: 2.71245) avg lploss: 0.00000
==> test epoch 170 avg loss: 3.65686 (A-MSE: 3.21973) avg lploss: 0.00000
*** Best Val Loss: 2.18208 	 Best Test Loss: 2.43548 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 1.86982 (A-MSE: 1.56283) avg lploss: 0.00000
train epoch 172 avg loss: 1.82174 (A-MSE: 1.49221) avg lploss: 0.00000
train epoch 173 avg loss: 1.75683 (A-MSE: 1.47525) avg lploss: 0.00000
train epoch 174 avg loss: 1.70428 (A-MSE: 1.40514) avg lploss: 0.00000
train epoch 175 avg loss: 1.69393 (A-MSE: 1.41082) avg lploss: 0.00000
==> val epoch 175 avg loss: 2.66006 (A-MSE: 2.31463) avg lploss: 0.00000
==> test epoch 175 avg loss: 3.05910 (A-MSE: 2.73533) avg lploss: 0.00000
*** Best Val Loss: 2.18208 	 Best Test Loss: 2.43548 	 Best epoch 165
EarlyStopping counter: 2 out of 50
train epoch 176 avg loss: 1.78877 (A-MSE: 1.48928) avg lploss: 0.00000
train epoch 177 avg loss: 1.66986 (A-MSE: 1.38914) avg lploss: 0.00000
train epoch 178 avg loss: 1.79011 (A-MSE: 1.48698) avg lploss: 0.00000
train epoch 179 avg loss: 1.72345 (A-MSE: 1.43598) avg lploss: 0.00000
train epoch 180 avg loss: 1.67060 (A-MSE: 1.37255) avg lploss: 0.00000
==> val epoch 180 avg loss: 2.06681 (A-MSE: 1.77515) avg lploss: 0.00000
==> test epoch 180 avg loss: 2.28989 (A-MSE: 2.01250) avg lploss: 0.00000
*** Best Val Loss: 2.06681 	 Best Test Loss: 2.28989 	 Best epoch 180
Validation loss decreased (2.182075 --> 2.066815).  Saving model ...
train epoch 181 avg loss: 1.61665 (A-MSE: 1.34782) avg lploss: 0.00000
train epoch 182 avg loss: 1.62223 (A-MSE: 1.31981) avg lploss: 0.00000
train epoch 183 avg loss: 1.80736 (A-MSE: 1.51576) avg lploss: 0.00000
train epoch 184 avg loss: 1.73630 (A-MSE: 1.45268) avg lploss: 0.00000
train epoch 185 avg loss: 1.65244 (A-MSE: 1.38258) avg lploss: 0.00000
==> val epoch 185 avg loss: 2.03558 (A-MSE: 1.77253) avg lploss: 0.00000
==> test epoch 185 avg loss: 2.25251 (A-MSE: 2.00533) avg lploss: 0.00000
*** Best Val Loss: 2.03558 	 Best Test Loss: 2.25251 	 Best epoch 185
Validation loss decreased (2.066815 --> 2.035583).  Saving model ...
train epoch 186 avg loss: 1.59963 (A-MSE: 1.31482) avg lploss: 0.00000
train epoch 187 avg loss: 1.49880 (A-MSE: 1.24421) avg lploss: 0.00000
train epoch 188 avg loss: 1.52451 (A-MSE: 1.26321) avg lploss: 0.00000
train epoch 189 avg loss: 1.49102 (A-MSE: 1.24892) avg lploss: 0.00000
train epoch 190 avg loss: 1.50389 (A-MSE: 1.24817) avg lploss: 0.00000
==> val epoch 190 avg loss: 2.43649 (A-MSE: 1.98726) avg lploss: 0.00000
==> test epoch 190 avg loss: 2.77168 (A-MSE: 2.33783) avg lploss: 0.00000
*** Best Val Loss: 2.03558 	 Best Test Loss: 2.25251 	 Best epoch 185
EarlyStopping counter: 1 out of 50
train epoch 191 avg loss: 1.54279 (A-MSE: 1.27870) avg lploss: 0.00000
train epoch 192 avg loss: 1.53505 (A-MSE: 1.27846) avg lploss: 0.00000
train epoch 193 avg loss: 1.52277 (A-MSE: 1.26802) avg lploss: 0.00000
train epoch 194 avg loss: 1.49136 (A-MSE: 1.25175) avg lploss: 0.00000
train epoch 195 avg loss: 1.52363 (A-MSE: 1.25692) avg lploss: 0.00000
==> val epoch 195 avg loss: 1.89850 (A-MSE: 1.75239) avg lploss: 0.00000
==> test epoch 195 avg loss: 2.20650 (A-MSE: 2.07176) avg lploss: 0.00000
*** Best Val Loss: 1.89850 	 Best Test Loss: 2.20650 	 Best epoch 195
Validation loss decreased (2.035583 --> 1.898497).  Saving model ...
train epoch 196 avg loss: 1.48045 (A-MSE: 1.24323) avg lploss: 0.00000
train epoch 197 avg loss: 1.62960 (A-MSE: 1.36141) avg lploss: 0.00000
train epoch 198 avg loss: 1.55795 (A-MSE: 1.31306) avg lploss: 0.00000
train epoch 199 avg loss: 1.51592 (A-MSE: 1.26784) avg lploss: 0.00000
train epoch 200 avg loss: 1.42604 (A-MSE: 1.18993) avg lploss: 0.00000
==> val epoch 200 avg loss: 1.99676 (A-MSE: 1.73498) avg lploss: 0.00000
==> test epoch 200 avg loss: 2.24600 (A-MSE: 2.00227) avg lploss: 0.00000
*** Best Val Loss: 1.89850 	 Best Test Loss: 2.20650 	 Best epoch 195
EarlyStopping counter: 1 out of 50
train epoch 201 avg loss: 1.40259 (A-MSE: 1.15516) avg lploss: 0.00000
train epoch 202 avg loss: 1.42739 (A-MSE: 1.20132) avg lploss: 0.00000
train epoch 203 avg loss: 1.43551 (A-MSE: 1.19892) avg lploss: 0.00000
train epoch 204 avg loss: 1.56439 (A-MSE: 1.31768) avg lploss: 0.00000
train epoch 205 avg loss: 1.60913 (A-MSE: 1.34616) avg lploss: 0.00000
==> val epoch 205 avg loss: 2.27966 (A-MSE: 1.87892) avg lploss: 0.00000
==> test epoch 205 avg loss: 2.57182 (A-MSE: 2.18115) avg lploss: 0.00000
*** Best Val Loss: 1.89850 	 Best Test Loss: 2.20650 	 Best epoch 195
EarlyStopping counter: 2 out of 50
train epoch 206 avg loss: 1.40717 (A-MSE: 1.18298) avg lploss: 0.00000
train epoch 207 avg loss: 1.44878 (A-MSE: 1.21137) avg lploss: 0.00000
train epoch 208 avg loss: 1.48865 (A-MSE: 1.25161) avg lploss: 0.00000
train epoch 209 avg loss: 1.47214 (A-MSE: 1.23993) avg lploss: 0.00000
train epoch 210 avg loss: 1.42527 (A-MSE: 1.19372) avg lploss: 0.00000
==> val epoch 210 avg loss: 2.01544 (A-MSE: 1.70432) avg lploss: 0.00000
==> test epoch 210 avg loss: 2.28621 (A-MSE: 1.99623) avg lploss: 0.00000
*** Best Val Loss: 1.89850 	 Best Test Loss: 2.20650 	 Best epoch 195
EarlyStopping counter: 3 out of 50
train epoch 211 avg loss: 1.36287 (A-MSE: 1.14686) avg lploss: 0.00000
train epoch 212 avg loss: 1.48388 (A-MSE: 1.26293) avg lploss: 0.00000
train epoch 213 avg loss: 1.43207 (A-MSE: 1.19768) avg lploss: 0.00000
train epoch 214 avg loss: 1.55742 (A-MSE: 1.32410) avg lploss: 0.00000
train epoch 215 avg loss: 1.33307 (A-MSE: 1.12592) avg lploss: 0.00000
==> val epoch 215 avg loss: 1.87946 (A-MSE: 1.67507) avg lploss: 0.00000
==> test epoch 215 avg loss: 2.18599 (A-MSE: 1.99241) avg lploss: 0.00000
*** Best Val Loss: 1.87946 	 Best Test Loss: 2.18599 	 Best epoch 215
Validation loss decreased (1.898497 --> 1.879456).  Saving model ...
train epoch 216 avg loss: 1.38196 (A-MSE: 1.16648) avg lploss: 0.00000
train epoch 217 avg loss: 1.44271 (A-MSE: 1.22318) avg lploss: 0.00000
train epoch 218 avg loss: 1.40493 (A-MSE: 1.18469) avg lploss: 0.00000
train epoch 219 avg loss: 1.41664 (A-MSE: 1.20352) avg lploss: 0.00000
train epoch 220 avg loss: 1.40950 (A-MSE: 1.19306) avg lploss: 0.00000
==> val epoch 220 avg loss: 2.64134 (A-MSE: 2.28442) avg lploss: 0.00000
==> test epoch 220 avg loss: 3.02551 (A-MSE: 2.68502) avg lploss: 0.00000
*** Best Val Loss: 1.87946 	 Best Test Loss: 2.18599 	 Best epoch 215
EarlyStopping counter: 1 out of 50
train epoch 221 avg loss: 1.53021 (A-MSE: 1.30138) avg lploss: 0.00000
train epoch 222 avg loss: 1.39610 (A-MSE: 1.17534) avg lploss: 0.00000
train epoch 223 avg loss: 1.33015 (A-MSE: 1.13519) avg lploss: 0.00000
train epoch 224 avg loss: 1.28812 (A-MSE: 1.08208) avg lploss: 0.00000
train epoch 225 avg loss: 1.31497 (A-MSE: 1.12315) avg lploss: 0.00000
==> val epoch 225 avg loss: 2.01592 (A-MSE: 1.71374) avg lploss: 0.00000
==> test epoch 225 avg loss: 2.27030 (A-MSE: 1.98527) avg lploss: 0.00000
*** Best Val Loss: 1.87946 	 Best Test Loss: 2.18599 	 Best epoch 215
EarlyStopping counter: 2 out of 50
train epoch 226 avg loss: 1.39246 (A-MSE: 1.17271) avg lploss: 0.00000
train epoch 227 avg loss: 1.47958 (A-MSE: 1.26417) avg lploss: 0.00000
train epoch 228 avg loss: 1.36539 (A-MSE: 1.16834) avg lploss: 0.00000
train epoch 229 avg loss: 1.35404 (A-MSE: 1.14091) avg lploss: 0.00000
train epoch 230 avg loss: 1.29085 (A-MSE: 1.09720) avg lploss: 0.00000
==> val epoch 230 avg loss: 1.92607 (A-MSE: 1.75275) avg lploss: 0.00000
==> test epoch 230 avg loss: 2.11793 (A-MSE: 1.94388) avg lploss: 0.00000
*** Best Val Loss: 1.87946 	 Best Test Loss: 2.18599 	 Best epoch 215
EarlyStopping counter: 3 out of 50
train epoch 231 avg loss: 1.31705 (A-MSE: 1.12313) avg lploss: 0.00000
train epoch 232 avg loss: 1.31574 (A-MSE: 1.11990) avg lploss: 0.00000
train epoch 233 avg loss: 1.32797 (A-MSE: 1.13721) avg lploss: 0.00000
train epoch 234 avg loss: 1.34029 (A-MSE: 1.14993) avg lploss: 0.00000
train epoch 235 avg loss: 1.31315 (A-MSE: 1.11951) avg lploss: 0.00000
==> val epoch 235 avg loss: 1.85987 (A-MSE: 1.57394) avg lploss: 0.00000
==> test epoch 235 avg loss: 2.14788 (A-MSE: 1.87698) avg lploss: 0.00000
*** Best Val Loss: 1.85987 	 Best Test Loss: 2.14788 	 Best epoch 235
Validation loss decreased (1.879456 --> 1.859865).  Saving model ...
train epoch 236 avg loss: 1.28613 (A-MSE: 1.08780) avg lploss: 0.00000
train epoch 237 avg loss: 1.33895 (A-MSE: 1.14474) avg lploss: 0.00000
train epoch 238 avg loss: 1.27885 (A-MSE: 1.08929) avg lploss: 0.00000
train epoch 239 avg loss: 1.33094 (A-MSE: 1.13524) avg lploss: 0.00000
train epoch 240 avg loss: 1.24280 (A-MSE: 1.05243) avg lploss: 0.00000
==> val epoch 240 avg loss: 1.84290 (A-MSE: 1.64804) avg lploss: 0.00000
==> test epoch 240 avg loss: 2.11660 (A-MSE: 1.92388) avg lploss: 0.00000
*** Best Val Loss: 1.84290 	 Best Test Loss: 2.11660 	 Best epoch 240
Validation loss decreased (1.859865 --> 1.842897).  Saving model ...
train epoch 241 avg loss: 1.24306 (A-MSE: 1.06218) avg lploss: 0.00000
train epoch 242 avg loss: 1.20749 (A-MSE: 1.03236) avg lploss: 0.00000
train epoch 243 avg loss: 1.13448 (A-MSE: 0.96748) avg lploss: 0.00000
train epoch 244 avg loss: 1.24180 (A-MSE: 1.05601) avg lploss: 0.00000
train epoch 245 avg loss: 1.25858 (A-MSE: 1.08060) avg lploss: 0.00000
==> val epoch 245 avg loss: 1.71241 (A-MSE: 1.50151) avg lploss: 0.00000
==> test epoch 245 avg loss: 1.89074 (A-MSE: 1.70780) avg lploss: 0.00000
*** Best Val Loss: 1.71241 	 Best Test Loss: 1.89074 	 Best epoch 245
Validation loss decreased (1.842897 --> 1.712415).  Saving model ...
train epoch 246 avg loss: 1.18747 (A-MSE: 1.01824) avg lploss: 0.00000
train epoch 247 avg loss: 1.12891 (A-MSE: 0.95366) avg lploss: 0.00000
train epoch 248 avg loss: 1.37990 (A-MSE: 1.18071) avg lploss: 0.00000
train epoch 249 avg loss: 1.34448 (A-MSE: 1.15744) avg lploss: 0.00000
train epoch 250 avg loss: 1.30775 (A-MSE: 1.12135) avg lploss: 0.00000
==> val epoch 250 avg loss: 1.65960 (A-MSE: 1.43436) avg lploss: 0.00000
==> test epoch 250 avg loss: 1.86421 (A-MSE: 1.65154) avg lploss: 0.00000
*** Best Val Loss: 1.65960 	 Best Test Loss: 1.86421 	 Best epoch 250
Validation loss decreased (1.712415 --> 1.659598).  Saving model ...
train epoch 251 avg loss: 1.18064 (A-MSE: 0.99651) avg lploss: 0.00000
train epoch 252 avg loss: 1.31283 (A-MSE: 1.12639) avg lploss: 0.00000
train epoch 253 avg loss: 1.19205 (A-MSE: 1.02810) avg lploss: 0.00000
train epoch 254 avg loss: 1.16704 (A-MSE: 0.99460) avg lploss: 0.00000
train epoch 255 avg loss: 1.15184 (A-MSE: 0.99027) avg lploss: 0.00000
==> val epoch 255 avg loss: 1.50926 (A-MSE: 1.33381) avg lploss: 0.00000
==> test epoch 255 avg loss: 1.69796 (A-MSE: 1.53479) avg lploss: 0.00000
*** Best Val Loss: 1.50926 	 Best Test Loss: 1.69796 	 Best epoch 255
Validation loss decreased (1.659598 --> 1.509256).  Saving model ...
train epoch 256 avg loss: 1.10550 (A-MSE: 0.93389) avg lploss: 0.00000
train epoch 257 avg loss: 1.14539 (A-MSE: 0.99401) avg lploss: 0.00000
train epoch 258 avg loss: 1.19163 (A-MSE: 1.01527) avg lploss: 0.00000
train epoch 259 avg loss: 1.06295 (A-MSE: 0.91343) avg lploss: 0.00000
train epoch 260 avg loss: 1.17759 (A-MSE: 0.99639) avg lploss: 0.00000
==> val epoch 260 avg loss: 1.67733 (A-MSE: 1.49985) avg lploss: 0.00000
==> test epoch 260 avg loss: 1.97882 (A-MSE: 1.79761) avg lploss: 0.00000
*** Best Val Loss: 1.50926 	 Best Test Loss: 1.69796 	 Best epoch 255
EarlyStopping counter: 1 out of 50
train epoch 261 avg loss: 1.07447 (A-MSE: 0.93131) avg lploss: 0.00000
train epoch 262 avg loss: 1.10166 (A-MSE: 0.95080) avg lploss: 0.00000
train epoch 263 avg loss: 1.15398 (A-MSE: 0.98548) avg lploss: 0.00000
train epoch 264 avg loss: 1.13593 (A-MSE: 0.98004) avg lploss: 0.00000
train epoch 265 avg loss: 1.18916 (A-MSE: 1.02468) avg lploss: 0.00000
==> val epoch 265 avg loss: 1.71822 (A-MSE: 1.53637) avg lploss: 0.00000
==> test epoch 265 avg loss: 1.98508 (A-MSE: 1.81336) avg lploss: 0.00000
*** Best Val Loss: 1.50926 	 Best Test Loss: 1.69796 	 Best epoch 255
EarlyStopping counter: 2 out of 50
train epoch 266 avg loss: 1.12338 (A-MSE: 0.96621) avg lploss: 0.00000
train epoch 267 avg loss: 1.09368 (A-MSE: 0.94122) avg lploss: 0.00000
train epoch 268 avg loss: 1.12382 (A-MSE: 0.96347) avg lploss: 0.00000
train epoch 269 avg loss: 1.03400 (A-MSE: 0.89229) avg lploss: 0.00000
train epoch 270 avg loss: 0.99135 (A-MSE: 0.85186) avg lploss: 0.00000
==> val epoch 270 avg loss: 1.42314 (A-MSE: 1.23930) avg lploss: 0.00000
==> test epoch 270 avg loss: 1.65697 (A-MSE: 1.49054) avg lploss: 0.00000
*** Best Val Loss: 1.42314 	 Best Test Loss: 1.65697 	 Best epoch 270
Validation loss decreased (1.509256 --> 1.423136).  Saving model ...
train epoch 271 avg loss: 1.11886 (A-MSE: 0.96556) avg lploss: 0.00000
train epoch 272 avg loss: 1.13102 (A-MSE: 0.97949) avg lploss: 0.00000
train epoch 273 avg loss: 1.13824 (A-MSE: 0.98463) avg lploss: 0.00000
train epoch 274 avg loss: 1.02271 (A-MSE: 0.87525) avg lploss: 0.00000
train epoch 275 avg loss: 1.15929 (A-MSE: 1.00957) avg lploss: 0.00000
==> val epoch 275 avg loss: 2.18625 (A-MSE: 1.81715) avg lploss: 0.00000
==> test epoch 275 avg loss: 2.38176 (A-MSE: 2.03213) avg lploss: 0.00000
*** Best Val Loss: 1.42314 	 Best Test Loss: 1.65697 	 Best epoch 270
EarlyStopping counter: 1 out of 50
train epoch 276 avg loss: 1.26446 (A-MSE: 1.08447) avg lploss: 0.00000
train epoch 277 avg loss: 1.13251 (A-MSE: 0.98884) avg lploss: 0.00000
train epoch 278 avg loss: 0.96557 (A-MSE: 0.82774) avg lploss: 0.00000
train epoch 279 avg loss: 0.94008 (A-MSE: 0.80535) avg lploss: 0.00000
train epoch 280 avg loss: 0.95635 (A-MSE: 0.83065) avg lploss: 0.00000
==> val epoch 280 avg loss: 1.61134 (A-MSE: 1.38871) avg lploss: 0.00000
==> test epoch 280 avg loss: 1.81652 (A-MSE: 1.61259) avg lploss: 0.00000
*** Best Val Loss: 1.42314 	 Best Test Loss: 1.65697 	 Best epoch 270
EarlyStopping counter: 2 out of 50
train epoch 281 avg loss: 1.04649 (A-MSE: 0.89694) avg lploss: 0.00000
train epoch 282 avg loss: 1.01988 (A-MSE: 0.87845) avg lploss: 0.00000
train epoch 283 avg loss: 1.08319 (A-MSE: 0.93108) avg lploss: 0.00000
train epoch 284 avg loss: 1.02840 (A-MSE: 0.88987) avg lploss: 0.00000
train epoch 285 avg loss: 1.02136 (A-MSE: 0.88687) avg lploss: 0.00000
==> val epoch 285 avg loss: 1.79728 (A-MSE: 1.54337) avg lploss: 0.00000
==> test epoch 285 avg loss: 1.99482 (A-MSE: 1.76166) avg lploss: 0.00000
*** Best Val Loss: 1.42314 	 Best Test Loss: 1.65697 	 Best epoch 270
EarlyStopping counter: 3 out of 50
train epoch 286 avg loss: 1.06975 (A-MSE: 0.91401) avg lploss: 0.00000
train epoch 287 avg loss: 0.97404 (A-MSE: 0.84644) avg lploss: 0.00000
train epoch 288 avg loss: 1.03812 (A-MSE: 0.89241) avg lploss: 0.00000
train epoch 289 avg loss: 1.00391 (A-MSE: 0.87005) avg lploss: 0.00000
train epoch 290 avg loss: 0.97766 (A-MSE: 0.83884) avg lploss: 0.00000
==> val epoch 290 avg loss: 1.40664 (A-MSE: 1.20741) avg lploss: 0.00000
==> test epoch 290 avg loss: 1.57160 (A-MSE: 1.38104) avg lploss: 0.00000
*** Best Val Loss: 1.40664 	 Best Test Loss: 1.57160 	 Best epoch 290
Validation loss decreased (1.423136 --> 1.406640).  Saving model ...
train epoch 291 avg loss: 0.96997 (A-MSE: 0.83574) avg lploss: 0.00000
train epoch 292 avg loss: 0.98942 (A-MSE: 0.85528) avg lploss: 0.00000
train epoch 293 avg loss: 1.00023 (A-MSE: 0.86282) avg lploss: 0.00000
train epoch 294 avg loss: 0.94079 (A-MSE: 0.81588) avg lploss: 0.00000
train epoch 295 avg loss: 0.98577 (A-MSE: 0.84413) avg lploss: 0.00000
==> val epoch 295 avg loss: 1.25891 (A-MSE: 1.08506) avg lploss: 0.00000
==> test epoch 295 avg loss: 1.43678 (A-MSE: 1.27433) avg lploss: 0.00000
*** Best Val Loss: 1.25891 	 Best Test Loss: 1.43678 	 Best epoch 295
Validation loss decreased (1.406640 --> 1.258907).  Saving model ...
train epoch 296 avg loss: 1.11697 (A-MSE: 0.96437) avg lploss: 0.00000
train epoch 297 avg loss: 1.04108 (A-MSE: 0.90834) avg lploss: 0.00000
train epoch 298 avg loss: 1.03359 (A-MSE: 0.89287) avg lploss: 0.00000
train epoch 299 avg loss: 1.02189 (A-MSE: 0.88798) avg lploss: 0.00000
train epoch 300 avg loss: 0.95359 (A-MSE: 0.82047) avg lploss: 0.00000
==> val epoch 300 avg loss: 1.37911 (A-MSE: 1.20896) avg lploss: 0.00000
==> test epoch 300 avg loss: 1.57896 (A-MSE: 1.41513) avg lploss: 0.00000
*** Best Val Loss: 1.25891 	 Best Test Loss: 1.43678 	 Best epoch 295
EarlyStopping counter: 1 out of 50
train epoch 301 avg loss: 0.92734 (A-MSE: 0.80509) avg lploss: 0.00000
train epoch 302 avg loss: 1.02247 (A-MSE: 0.87697) avg lploss: 0.00000
train epoch 303 avg loss: 1.09261 (A-MSE: 0.94487) avg lploss: 0.00000
train epoch 304 avg loss: 0.92244 (A-MSE: 0.80293) avg lploss: 0.00000
train epoch 305 avg loss: 0.98604 (A-MSE: 0.84539) avg lploss: 0.00000
==> val epoch 305 avg loss: 1.50429 (A-MSE: 1.38745) avg lploss: 0.00000
==> test epoch 305 avg loss: 1.74479 (A-MSE: 1.62040) avg lploss: 0.00000
*** Best Val Loss: 1.25891 	 Best Test Loss: 1.43678 	 Best epoch 295
EarlyStopping counter: 2 out of 50
train epoch 306 avg loss: 0.96253 (A-MSE: 0.84003) avg lploss: 0.00000
train epoch 307 avg loss: 0.92452 (A-MSE: 0.79293) avg lploss: 0.00000
train epoch 308 avg loss: 1.04266 (A-MSE: 0.90553) avg lploss: 0.00000
train epoch 309 avg loss: 1.05956 (A-MSE: 0.91518) avg lploss: 0.00000
train epoch 310 avg loss: 0.99393 (A-MSE: 0.85788) avg lploss: 0.00000
==> val epoch 310 avg loss: 1.23390 (A-MSE: 1.08617) avg lploss: 0.00000
==> test epoch 310 avg loss: 1.38557 (A-MSE: 1.25345) avg lploss: 0.00000
*** Best Val Loss: 1.23390 	 Best Test Loss: 1.38557 	 Best epoch 310
Validation loss decreased (1.258907 --> 1.233898).  Saving model ...
train epoch 311 avg loss: 0.88432 (A-MSE: 0.76680) avg lploss: 0.00000
train epoch 312 avg loss: 0.92282 (A-MSE: 0.79935) avg lploss: 0.00000
train epoch 313 avg loss: 0.95617 (A-MSE: 0.82732) avg lploss: 0.00000
train epoch 314 avg loss: 0.91189 (A-MSE: 0.79332) avg lploss: 0.00000
train epoch 315 avg loss: 0.86455 (A-MSE: 0.74718) avg lploss: 0.00000
==> val epoch 315 avg loss: 1.25819 (A-MSE: 1.12368) avg lploss: 0.00000
==> test epoch 315 avg loss: 1.46392 (A-MSE: 1.33447) avg lploss: 0.00000
*** Best Val Loss: 1.23390 	 Best Test Loss: 1.38557 	 Best epoch 310
EarlyStopping counter: 1 out of 50
train epoch 316 avg loss: 0.81980 (A-MSE: 0.70960) avg lploss: 0.00000
train epoch 317 avg loss: 0.84164 (A-MSE: 0.72299) avg lploss: 0.00000
train epoch 318 avg loss: 0.84401 (A-MSE: 0.73891) avg lploss: 0.00000
train epoch 319 avg loss: 0.86434 (A-MSE: 0.74457) avg lploss: 0.00000
train epoch 320 avg loss: 0.82532 (A-MSE: 0.70632) avg lploss: 0.00000
==> val epoch 320 avg loss: 1.39125 (A-MSE: 1.25177) avg lploss: 0.00000
==> test epoch 320 avg loss: 1.58983 (A-MSE: 1.44678) avg lploss: 0.00000
*** Best Val Loss: 1.23390 	 Best Test Loss: 1.38557 	 Best epoch 310
EarlyStopping counter: 2 out of 50
train epoch 321 avg loss: 0.77489 (A-MSE: 0.67698) avg lploss: 0.00000
train epoch 322 avg loss: 0.96071 (A-MSE: 0.83423) avg lploss: 0.00000
train epoch 323 avg loss: 0.99631 (A-MSE: 0.86339) avg lploss: 0.00000
train epoch 324 avg loss: 0.90701 (A-MSE: 0.78513) avg lploss: 0.00000
train epoch 325 avg loss: 0.90923 (A-MSE: 0.79055) avg lploss: 0.00000
==> val epoch 325 avg loss: 1.36266 (A-MSE: 1.15904) avg lploss: 0.00000
==> test epoch 325 avg loss: 1.55446 (A-MSE: 1.34935) avg lploss: 0.00000
*** Best Val Loss: 1.23390 	 Best Test Loss: 1.38557 	 Best epoch 310
EarlyStopping counter: 3 out of 50
train epoch 326 avg loss: 0.85841 (A-MSE: 0.73913) avg lploss: 0.00000
train epoch 327 avg loss: 0.91128 (A-MSE: 0.78859) avg lploss: 0.00000
train epoch 328 avg loss: 0.83837 (A-MSE: 0.72315) avg lploss: 0.00000
train epoch 329 avg loss: 0.81126 (A-MSE: 0.70646) avg lploss: 0.00000
train epoch 330 avg loss: 0.79802 (A-MSE: 0.69027) avg lploss: 0.00000
==> val epoch 330 avg loss: 1.12724 (A-MSE: 0.98941) avg lploss: 0.00000
==> test epoch 330 avg loss: 1.32996 (A-MSE: 1.18993) avg lploss: 0.00000
*** Best Val Loss: 1.12724 	 Best Test Loss: 1.32996 	 Best epoch 330
Validation loss decreased (1.233898 --> 1.127245).  Saving model ...
train epoch 331 avg loss: 0.81193 (A-MSE: 0.70925) avg lploss: 0.00000
train epoch 332 avg loss: 0.86448 (A-MSE: 0.74799) avg lploss: 0.00000
train epoch 333 avg loss: 0.83723 (A-MSE: 0.72369) avg lploss: 0.00000
train epoch 334 avg loss: 0.73978 (A-MSE: 0.64320) avg lploss: 0.00000
train epoch 335 avg loss: 0.87794 (A-MSE: 0.75683) avg lploss: 0.00000
==> val epoch 335 avg loss: 1.40667 (A-MSE: 1.26842) avg lploss: 0.00000
==> test epoch 335 avg loss: 1.54625 (A-MSE: 1.41645) avg lploss: 0.00000
*** Best Val Loss: 1.12724 	 Best Test Loss: 1.32996 	 Best epoch 330
EarlyStopping counter: 1 out of 50
train epoch 336 avg loss: 0.81533 (A-MSE: 0.71031) avg lploss: 0.00000
train epoch 337 avg loss: 0.78061 (A-MSE: 0.67272) avg lploss: 0.00000
train epoch 338 avg loss: 0.79982 (A-MSE: 0.68910) avg lploss: 0.00000
train epoch 339 avg loss: 0.77633 (A-MSE: 0.67190) avg lploss: 0.00000
train epoch 340 avg loss: 0.82617 (A-MSE: 0.72276) avg lploss: 0.00000
==> val epoch 340 avg loss: 1.24625 (A-MSE: 1.07971) avg lploss: 0.00000
==> test epoch 340 avg loss: 1.48017 (A-MSE: 1.30918) avg lploss: 0.00000
*** Best Val Loss: 1.12724 	 Best Test Loss: 1.32996 	 Best epoch 330
EarlyStopping counter: 2 out of 50
train epoch 341 avg loss: 0.89529 (A-MSE: 0.78101) avg lploss: 0.00000
train epoch 342 avg loss: 0.88474 (A-MSE: 0.76615) avg lploss: 0.00000
train epoch 343 avg loss: 0.91541 (A-MSE: 0.79616) avg lploss: 0.00000
train epoch 344 avg loss: 0.87763 (A-MSE: 0.76741) avg lploss: 0.00000
train epoch 345 avg loss: 0.77532 (A-MSE: 0.66520) avg lploss: 0.00000
==> val epoch 345 avg loss: 1.03633 (A-MSE: 0.92709) avg lploss: 0.00000
==> test epoch 345 avg loss: 1.22961 (A-MSE: 1.11463) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
Validation loss decreased (1.127245 --> 1.036330).  Saving model ...
train epoch 346 avg loss: 0.81890 (A-MSE: 0.71203) avg lploss: 0.00000
train epoch 347 avg loss: 0.87226 (A-MSE: 0.74943) avg lploss: 0.00000
train epoch 348 avg loss: 0.90913 (A-MSE: 0.79644) avg lploss: 0.00000
train epoch 349 avg loss: 0.86397 (A-MSE: 0.74337) avg lploss: 0.00000
train epoch 350 avg loss: 0.78043 (A-MSE: 0.67668) avg lploss: 0.00000
==> val epoch 350 avg loss: 1.32457 (A-MSE: 1.12593) avg lploss: 0.00000
==> test epoch 350 avg loss: 1.43181 (A-MSE: 1.24333) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 1 out of 50
train epoch 351 avg loss: 0.84929 (A-MSE: 0.73923) avg lploss: 0.00000
train epoch 352 avg loss: 0.87597 (A-MSE: 0.75736) avg lploss: 0.00000
train epoch 353 avg loss: 0.78120 (A-MSE: 0.68418) avg lploss: 0.00000
train epoch 354 avg loss: 0.84818 (A-MSE: 0.73471) avg lploss: 0.00000
train epoch 355 avg loss: 0.79233 (A-MSE: 0.68768) avg lploss: 0.00000
==> val epoch 355 avg loss: 1.06117 (A-MSE: 0.93600) avg lploss: 0.00000
==> test epoch 355 avg loss: 1.27771 (A-MSE: 1.14713) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 2 out of 50
train epoch 356 avg loss: 0.83389 (A-MSE: 0.72987) avg lploss: 0.00000
train epoch 357 avg loss: 0.87561 (A-MSE: 0.75456) avg lploss: 0.00000
train epoch 358 avg loss: 0.76176 (A-MSE: 0.65852) avg lploss: 0.00000
train epoch 359 avg loss: 0.77062 (A-MSE: 0.67426) avg lploss: 0.00000
train epoch 360 avg loss: 0.81101 (A-MSE: 0.69958) avg lploss: 0.00000
==> val epoch 360 avg loss: 1.22293 (A-MSE: 1.04302) avg lploss: 0.00000
==> test epoch 360 avg loss: 1.38718 (A-MSE: 1.20997) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 3 out of 50
train epoch 361 avg loss: 0.76860 (A-MSE: 0.66761) avg lploss: 0.00000
train epoch 362 avg loss: 0.79957 (A-MSE: 0.69151) avg lploss: 0.00000
train epoch 363 avg loss: 0.87406 (A-MSE: 0.75808) avg lploss: 0.00000
train epoch 364 avg loss: 0.86826 (A-MSE: 0.75555) avg lploss: 0.00000
train epoch 365 avg loss: 0.81620 (A-MSE: 0.71214) avg lploss: 0.00000
==> val epoch 365 avg loss: 1.40458 (A-MSE: 1.23954) avg lploss: 0.00000
==> test epoch 365 avg loss: 1.48898 (A-MSE: 1.34624) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 4 out of 50
train epoch 366 avg loss: 0.82395 (A-MSE: 0.71746) avg lploss: 0.00000
train epoch 367 avg loss: 0.82925 (A-MSE: 0.71892) avg lploss: 0.00000
train epoch 368 avg loss: 0.73366 (A-MSE: 0.63680) avg lploss: 0.00000
train epoch 369 avg loss: 0.81998 (A-MSE: 0.70739) avg lploss: 0.00000
train epoch 370 avg loss: 0.84794 (A-MSE: 0.74166) avg lploss: 0.00000
==> val epoch 370 avg loss: 1.08049 (A-MSE: 0.95061) avg lploss: 0.00000
==> test epoch 370 avg loss: 1.32769 (A-MSE: 1.19272) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 5 out of 50
train epoch 371 avg loss: 0.87094 (A-MSE: 0.75084) avg lploss: 0.00000
train epoch 372 avg loss: 0.76601 (A-MSE: 0.66029) avg lploss: 0.00000
train epoch 373 avg loss: 0.69579 (A-MSE: 0.60253) avg lploss: 0.00000
train epoch 374 avg loss: 0.64020 (A-MSE: 0.55607) avg lploss: 0.00000
train epoch 375 avg loss: 0.68027 (A-MSE: 0.58593) avg lploss: 0.00000
==> val epoch 375 avg loss: 1.18290 (A-MSE: 1.02768) avg lploss: 0.00000
==> test epoch 375 avg loss: 1.35793 (A-MSE: 1.19877) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 6 out of 50
train epoch 376 avg loss: 0.70204 (A-MSE: 0.61301) avg lploss: 0.00000
train epoch 377 avg loss: 0.71798 (A-MSE: 0.62420) avg lploss: 0.00000
train epoch 378 avg loss: 0.77522 (A-MSE: 0.67228) avg lploss: 0.00000
train epoch 379 avg loss: 0.73133 (A-MSE: 0.63412) avg lploss: 0.00000
train epoch 380 avg loss: 0.74725 (A-MSE: 0.64585) avg lploss: 0.00000
==> val epoch 380 avg loss: 1.30801 (A-MSE: 1.11133) avg lploss: 0.00000
==> test epoch 380 avg loss: 1.50338 (A-MSE: 1.30560) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 7 out of 50
train epoch 381 avg loss: 0.70026 (A-MSE: 0.60403) avg lploss: 0.00000
train epoch 382 avg loss: 0.67267 (A-MSE: 0.58505) avg lploss: 0.00000
train epoch 383 avg loss: 0.65563 (A-MSE: 0.56978) avg lploss: 0.00000
train epoch 384 avg loss: 0.71083 (A-MSE: 0.61493) avg lploss: 0.00000
train epoch 385 avg loss: 0.80333 (A-MSE: 0.69883) avg lploss: 0.00000
==> val epoch 385 avg loss: 1.47696 (A-MSE: 1.25276) avg lploss: 0.00000
==> test epoch 385 avg loss: 1.56844 (A-MSE: 1.36722) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 8 out of 50
train epoch 386 avg loss: 0.81041 (A-MSE: 0.70248) avg lploss: 0.00000
train epoch 387 avg loss: 0.76314 (A-MSE: 0.66456) avg lploss: 0.00000
train epoch 388 avg loss: 0.76862 (A-MSE: 0.66823) avg lploss: 0.00000
train epoch 389 avg loss: 0.76849 (A-MSE: 0.66507) avg lploss: 0.00000
train epoch 390 avg loss: 0.70742 (A-MSE: 0.61058) avg lploss: 0.00000
==> val epoch 390 avg loss: 1.07373 (A-MSE: 0.92756) avg lploss: 0.00000
==> test epoch 390 avg loss: 1.25758 (A-MSE: 1.10017) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 9 out of 50
train epoch 391 avg loss: 0.79541 (A-MSE: 0.69472) avg lploss: 0.00000
train epoch 392 avg loss: 0.67187 (A-MSE: 0.57653) avg lploss: 0.00000
train epoch 393 avg loss: 0.63032 (A-MSE: 0.54818) avg lploss: 0.00000
train epoch 394 avg loss: 0.71443 (A-MSE: 0.62246) avg lploss: 0.00000
train epoch 395 avg loss: 0.76461 (A-MSE: 0.66166) avg lploss: 0.00000
==> val epoch 395 avg loss: 1.21809 (A-MSE: 1.05764) avg lploss: 0.00000
==> test epoch 395 avg loss: 1.30726 (A-MSE: 1.16472) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 10 out of 50
train epoch 396 avg loss: 0.81434 (A-MSE: 0.71312) avg lploss: 0.00000
train epoch 397 avg loss: 0.82472 (A-MSE: 0.71072) avg lploss: 0.00000
train epoch 398 avg loss: 0.75090 (A-MSE: 0.65259) avg lploss: 0.00000
train epoch 399 avg loss: 0.66217 (A-MSE: 0.57526) avg lploss: 0.00000
train epoch 400 avg loss: 0.67530 (A-MSE: 0.58941) avg lploss: 0.00000
==> val epoch 400 avg loss: 1.37877 (A-MSE: 1.17609) avg lploss: 0.00000
==> test epoch 400 avg loss: 1.45671 (A-MSE: 1.26608) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 11 out of 50
train epoch 401 avg loss: 0.67760 (A-MSE: 0.58851) avg lploss: 0.00000
train epoch 402 avg loss: 0.62794 (A-MSE: 0.54613) avg lploss: 0.00000
train epoch 403 avg loss: 0.59743 (A-MSE: 0.51900) avg lploss: 0.00000
train epoch 404 avg loss: 0.64510 (A-MSE: 0.55735) avg lploss: 0.00000
train epoch 405 avg loss: 0.63375 (A-MSE: 0.55072) avg lploss: 0.00000
==> val epoch 405 avg loss: 1.08506 (A-MSE: 0.93520) avg lploss: 0.00000
==> test epoch 405 avg loss: 1.20274 (A-MSE: 1.05582) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 12 out of 50
train epoch 406 avg loss: 0.64892 (A-MSE: 0.56360) avg lploss: 0.00000
train epoch 407 avg loss: 0.69130 (A-MSE: 0.60142) avg lploss: 0.00000
train epoch 408 avg loss: 0.66811 (A-MSE: 0.57669) avg lploss: 0.00000
train epoch 409 avg loss: 0.64025 (A-MSE: 0.56170) avg lploss: 0.00000
train epoch 410 avg loss: 0.69022 (A-MSE: 0.60431) avg lploss: 0.00000
==> val epoch 410 avg loss: 1.43356 (A-MSE: 1.21676) avg lploss: 0.00000
==> test epoch 410 avg loss: 1.54679 (A-MSE: 1.34834) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 13 out of 50
train epoch 411 avg loss: 0.71917 (A-MSE: 0.61975) avg lploss: 0.00000
train epoch 412 avg loss: 0.69690 (A-MSE: 0.60505) avg lploss: 0.00000
train epoch 413 avg loss: 0.58601 (A-MSE: 0.50720) avg lploss: 0.00000
train epoch 414 avg loss: 0.58839 (A-MSE: 0.51136) avg lploss: 0.00000
train epoch 415 avg loss: 0.68254 (A-MSE: 0.60014) avg lploss: 0.00000
==> val epoch 415 avg loss: 1.20817 (A-MSE: 1.03097) avg lploss: 0.00000
==> test epoch 415 avg loss: 1.37864 (A-MSE: 1.20362) avg lploss: 0.00000
*** Best Val Loss: 1.03633 	 Best Test Loss: 1.22961 	 Best epoch 345
EarlyStopping counter: 14 out of 50
train epoch 416 avg loss: 0.74972 (A-MSE: 0.65195) avg lploss: 0.00000
train epoch 417 avg loss: 0.72132 (A-MSE: 0.62635) avg lploss: 0.00000
train epoch 418 avg loss: 0.62456 (A-MSE: 0.54790) avg lploss: 0.00000
train epoch 419 avg loss: 0.65197 (A-MSE: 0.56310) avg lploss: 0.00000
train epoch 420 avg loss: 0.59926 (A-MSE: 0.52131) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.93619 (A-MSE: 0.81990) avg lploss: 0.00000
==> test epoch 420 avg loss: 1.13378 (A-MSE: 1.00563) avg lploss: 0.00000
*** Best Val Loss: 0.93619 	 Best Test Loss: 1.13378 	 Best epoch 420
Validation loss decreased (1.036330 --> 0.936191).  Saving model ...
train epoch 421 avg loss: 0.68987 (A-MSE: 0.60003) avg lploss: 0.00000
train epoch 422 avg loss: 0.65799 (A-MSE: 0.57429) avg lploss: 0.00000
train epoch 423 avg loss: 0.61943 (A-MSE: 0.53887) avg lploss: 0.00000
train epoch 424 avg loss: 0.64230 (A-MSE: 0.55474) avg lploss: 0.00000
train epoch 425 avg loss: 0.67600 (A-MSE: 0.59462) avg lploss: 0.00000
==> val epoch 425 avg loss: 1.13245 (A-MSE: 0.97586) avg lploss: 0.00000
==> test epoch 425 avg loss: 1.20545 (A-MSE: 1.07795) avg lploss: 0.00000
*** Best Val Loss: 0.93619 	 Best Test Loss: 1.13378 	 Best epoch 420
EarlyStopping counter: 1 out of 50
train epoch 426 avg loss: 0.63471 (A-MSE: 0.54645) avg lploss: 0.00000
train epoch 427 avg loss: 0.58884 (A-MSE: 0.51097) avg lploss: 0.00000
train epoch 428 avg loss: 0.57129 (A-MSE: 0.49993) avg lploss: 0.00000
train epoch 429 avg loss: 0.59397 (A-MSE: 0.51184) avg lploss: 0.00000
train epoch 430 avg loss: 0.61695 (A-MSE: 0.53993) avg lploss: 0.00000
==> val epoch 430 avg loss: 1.10938 (A-MSE: 0.93368) avg lploss: 0.00000
==> test epoch 430 avg loss: 1.30141 (A-MSE: 1.11774) avg lploss: 0.00000
*** Best Val Loss: 0.93619 	 Best Test Loss: 1.13378 	 Best epoch 420
EarlyStopping counter: 2 out of 50
train epoch 431 avg loss: 0.63932 (A-MSE: 0.55389) avg lploss: 0.00000
train epoch 432 avg loss: 0.59258 (A-MSE: 0.51375) avg lploss: 0.00000
train epoch 433 avg loss: 0.64420 (A-MSE: 0.56278) avg lploss: 0.00000
train epoch 434 avg loss: 0.56622 (A-MSE: 0.49115) avg lploss: 0.00000
train epoch 435 avg loss: 0.62609 (A-MSE: 0.54320) avg lploss: 0.00000
==> val epoch 435 avg loss: 1.06241 (A-MSE: 0.91845) avg lploss: 0.00000
==> test epoch 435 avg loss: 1.11231 (A-MSE: 0.99200) avg lploss: 0.00000
*** Best Val Loss: 0.93619 	 Best Test Loss: 1.13378 	 Best epoch 420
EarlyStopping counter: 3 out of 50
train epoch 436 avg loss: 0.66979 (A-MSE: 0.58573) avg lploss: 0.00000
train epoch 437 avg loss: 0.66015 (A-MSE: 0.57349) avg lploss: 0.00000
train epoch 438 avg loss: 0.66827 (A-MSE: 0.58017) avg lploss: 0.00000
train epoch 439 avg loss: 0.62404 (A-MSE: 0.54350) avg lploss: 0.00000
train epoch 440 avg loss: 0.54853 (A-MSE: 0.47372) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.81964 (A-MSE: 0.74557) avg lploss: 0.00000
==> test epoch 440 avg loss: 1.03379 (A-MSE: 0.94930) avg lploss: 0.00000
*** Best Val Loss: 0.81964 	 Best Test Loss: 1.03379 	 Best epoch 440
Validation loss decreased (0.936191 --> 0.819639).  Saving model ...
train epoch 441 avg loss: 0.58131 (A-MSE: 0.50856) avg lploss: 0.00000
train epoch 442 avg loss: 0.68627 (A-MSE: 0.60043) avg lploss: 0.00000
train epoch 443 avg loss: 0.71305 (A-MSE: 0.61706) avg lploss: 0.00000
train epoch 444 avg loss: 0.61472 (A-MSE: 0.53945) avg lploss: 0.00000
train epoch 445 avg loss: 0.62947 (A-MSE: 0.54401) avg lploss: 0.00000
==> val epoch 445 avg loss: 1.10395 (A-MSE: 0.94577) avg lploss: 0.00000
==> test epoch 445 avg loss: 1.26197 (A-MSE: 1.09720) avg lploss: 0.00000
*** Best Val Loss: 0.81964 	 Best Test Loss: 1.03379 	 Best epoch 440
EarlyStopping counter: 1 out of 50
train epoch 446 avg loss: 0.55068 (A-MSE: 0.47822) avg lploss: 0.00000
train epoch 447 avg loss: 0.57825 (A-MSE: 0.50584) avg lploss: 0.00000
train epoch 448 avg loss: 0.56874 (A-MSE: 0.49380) avg lploss: 0.00000
train epoch 449 avg loss: 0.57557 (A-MSE: 0.50544) avg lploss: 0.00000
train epoch 450 avg loss: 0.55735 (A-MSE: 0.48334) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.98443 (A-MSE: 0.84482) avg lploss: 0.00000
==> test epoch 450 avg loss: 1.10266 (A-MSE: 0.97197) avg lploss: 0.00000
*** Best Val Loss: 0.81964 	 Best Test Loss: 1.03379 	 Best epoch 440
EarlyStopping counter: 2 out of 50
train epoch 451 avg loss: 0.57793 (A-MSE: 0.50419) avg lploss: 0.00000
train epoch 452 avg loss: 0.59671 (A-MSE: 0.51997) avg lploss: 0.00000
train epoch 453 avg loss: 0.55101 (A-MSE: 0.47952) avg lploss: 0.00000
train epoch 454 avg loss: 0.65491 (A-MSE: 0.57163) avg lploss: 0.00000
train epoch 455 avg loss: 0.53595 (A-MSE: 0.46925) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.92903 (A-MSE: 0.81741) avg lploss: 0.00000
==> test epoch 455 avg loss: 1.05356 (A-MSE: 0.94549) avg lploss: 0.00000
*** Best Val Loss: 0.81964 	 Best Test Loss: 1.03379 	 Best epoch 440
EarlyStopping counter: 3 out of 50
train epoch 456 avg loss: 0.55221 (A-MSE: 0.48022) avg lploss: 0.00000
train epoch 457 avg loss: 0.56620 (A-MSE: 0.49348) avg lploss: 0.00000
train epoch 458 avg loss: 0.57104 (A-MSE: 0.49604) avg lploss: 0.00000
train epoch 459 avg loss: 0.51717 (A-MSE: 0.45053) avg lploss: 0.00000
train epoch 460 avg loss: 0.55319 (A-MSE: 0.48117) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.86692 (A-MSE: 0.78441) avg lploss: 0.00000
==> test epoch 460 avg loss: 1.01063 (A-MSE: 0.92596) avg lploss: 0.00000
*** Best Val Loss: 0.81964 	 Best Test Loss: 1.03379 	 Best epoch 440
EarlyStopping counter: 4 out of 50
train epoch 461 avg loss: 0.67364 (A-MSE: 0.58883) avg lploss: 0.00000
train epoch 462 avg loss: 0.64460 (A-MSE: 0.56052) avg lploss: 0.00000
train epoch 463 avg loss: 0.57860 (A-MSE: 0.50276) avg lploss: 0.00000
train epoch 464 avg loss: 0.54694 (A-MSE: 0.47910) avg lploss: 0.00000
train epoch 465 avg loss: 0.58813 (A-MSE: 0.51431) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.86329 (A-MSE: 0.73955) avg lploss: 0.00000
==> test epoch 465 avg loss: 1.04910 (A-MSE: 0.92282) avg lploss: 0.00000
*** Best Val Loss: 0.81964 	 Best Test Loss: 1.03379 	 Best epoch 440
EarlyStopping counter: 5 out of 50
train epoch 466 avg loss: 0.60491 (A-MSE: 0.52554) avg lploss: 0.00000
train epoch 467 avg loss: 0.56718 (A-MSE: 0.49228) avg lploss: 0.00000
train epoch 468 avg loss: 0.52203 (A-MSE: 0.45322) avg lploss: 0.00000
train epoch 469 avg loss: 0.58426 (A-MSE: 0.50708) avg lploss: 0.00000
train epoch 470 avg loss: 0.56396 (A-MSE: 0.49063) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.81242 (A-MSE: 0.71409) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.97988 (A-MSE: 0.87042) avg lploss: 0.00000
*** Best Val Loss: 0.81242 	 Best Test Loss: 0.97988 	 Best epoch 470
Validation loss decreased (0.819639 --> 0.812421).  Saving model ...
train epoch 471 avg loss: 0.52883 (A-MSE: 0.46212) avg lploss: 0.00000
train epoch 472 avg loss: 0.54716 (A-MSE: 0.47540) avg lploss: 0.00000
train epoch 473 avg loss: 0.51916 (A-MSE: 0.45123) avg lploss: 0.00000
train epoch 474 avg loss: 0.50124 (A-MSE: 0.43306) avg lploss: 0.00000
train epoch 475 avg loss: 0.58136 (A-MSE: 0.51602) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.12937 (A-MSE: 0.95281) avg lploss: 0.00000
==> test epoch 475 avg loss: 1.20065 (A-MSE: 1.04885) avg lploss: 0.00000
*** Best Val Loss: 0.81242 	 Best Test Loss: 0.97988 	 Best epoch 470
EarlyStopping counter: 1 out of 50
train epoch 476 avg loss: 0.63194 (A-MSE: 0.54698) avg lploss: 0.00000
train epoch 477 avg loss: 0.55720 (A-MSE: 0.48636) avg lploss: 0.00000
train epoch 478 avg loss: 0.57327 (A-MSE: 0.49931) avg lploss: 0.00000
train epoch 479 avg loss: 0.50391 (A-MSE: 0.44007) avg lploss: 0.00000
train epoch 480 avg loss: 0.56366 (A-MSE: 0.49347) avg lploss: 0.00000
==> val epoch 480 avg loss: 1.01390 (A-MSE: 0.88139) avg lploss: 0.00000
==> test epoch 480 avg loss: 1.01802 (A-MSE: 0.91213) avg lploss: 0.00000
*** Best Val Loss: 0.81242 	 Best Test Loss: 0.97988 	 Best epoch 470
EarlyStopping counter: 2 out of 50
train epoch 481 avg loss: 0.65767 (A-MSE: 0.57595) avg lploss: 0.00000
train epoch 482 avg loss: 0.54588 (A-MSE: 0.47261) avg lploss: 0.00000
train epoch 483 avg loss: 0.55339 (A-MSE: 0.48203) avg lploss: 0.00000
train epoch 484 avg loss: 0.60001 (A-MSE: 0.52160) avg lploss: 0.00000
train epoch 485 avg loss: 0.59664 (A-MSE: 0.52153) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.90191 (A-MSE: 0.79376) avg lploss: 0.00000
==> test epoch 485 avg loss: 1.12718 (A-MSE: 1.01117) avg lploss: 0.00000
*** Best Val Loss: 0.81242 	 Best Test Loss: 0.97988 	 Best epoch 470
EarlyStopping counter: 3 out of 50
train epoch 486 avg loss: 0.56816 (A-MSE: 0.49560) avg lploss: 0.00000
train epoch 487 avg loss: 0.52954 (A-MSE: 0.46171) avg lploss: 0.00000
train epoch 488 avg loss: 0.51759 (A-MSE: 0.45333) avg lploss: 0.00000
train epoch 489 avg loss: 0.51156 (A-MSE: 0.44477) avg lploss: 0.00000
train epoch 490 avg loss: 0.55383 (A-MSE: 0.48041) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.91357 (A-MSE: 0.82383) avg lploss: 0.00000
==> test epoch 490 avg loss: 1.09644 (A-MSE: 0.99457) avg lploss: 0.00000
*** Best Val Loss: 0.81242 	 Best Test Loss: 0.97988 	 Best epoch 470
EarlyStopping counter: 4 out of 50
train epoch 491 avg loss: 0.61795 (A-MSE: 0.54405) avg lploss: 0.00000
train epoch 492 avg loss: 0.58178 (A-MSE: 0.50626) avg lploss: 0.00000
train epoch 493 avg loss: 0.56193 (A-MSE: 0.49389) avg lploss: 0.00000
train epoch 494 avg loss: 0.52732 (A-MSE: 0.46071) avg lploss: 0.00000
train epoch 495 avg loss: 0.52525 (A-MSE: 0.46059) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.80665 (A-MSE: 0.70597) avg lploss: 0.00000
==> test epoch 495 avg loss: 1.01273 (A-MSE: 0.90003) avg lploss: 0.00000
*** Best Val Loss: 0.80665 	 Best Test Loss: 1.01273 	 Best epoch 495
Validation loss decreased (0.812421 --> 0.806654).  Saving model ...
train epoch 496 avg loss: 0.52867 (A-MSE: 0.46232) avg lploss: 0.00000
train epoch 497 avg loss: 0.49413 (A-MSE: 0.42916) avg lploss: 0.00000
train epoch 498 avg loss: 0.55867 (A-MSE: 0.48668) avg lploss: 0.00000
train epoch 499 avg loss: 0.58230 (A-MSE: 0.51362) avg lploss: 0.00000
train epoch 500 avg loss: 0.50688 (A-MSE: 0.43664) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.81853 (A-MSE: 0.70005) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.98051 (A-MSE: 0.86319) avg lploss: 0.00000
*** Best Val Loss: 0.80665 	 Best Test Loss: 1.01273 	 Best epoch 495
EarlyStopping counter: 1 out of 50
train epoch 501 avg loss: 0.50752 (A-MSE: 0.44128) avg lploss: 0.00000
train epoch 502 avg loss: 0.65756 (A-MSE: 0.57956) avg lploss: 0.00000
train epoch 503 avg loss: 0.58156 (A-MSE: 0.50420) avg lploss: 0.00000
train epoch 504 avg loss: 0.54550 (A-MSE: 0.47812) avg lploss: 0.00000
train epoch 505 avg loss: 0.51197 (A-MSE: 0.44907) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.82432 (A-MSE: 0.71731) avg lploss: 0.00000
==> test epoch 505 avg loss: 1.00736 (A-MSE: 0.88616) avg lploss: 0.00000
*** Best Val Loss: 0.80665 	 Best Test Loss: 1.01273 	 Best epoch 495
EarlyStopping counter: 2 out of 50
train epoch 506 avg loss: 0.50012 (A-MSE: 0.43693) avg lploss: 0.00000
train epoch 507 avg loss: 0.51134 (A-MSE: 0.44576) avg lploss: 0.00000
train epoch 508 avg loss: 0.48461 (A-MSE: 0.42564) avg lploss: 0.00000
train epoch 509 avg loss: 0.45692 (A-MSE: 0.39779) avg lploss: 0.00000
train epoch 510 avg loss: 0.45030 (A-MSE: 0.39262) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.84242 (A-MSE: 0.73584) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.91111 (A-MSE: 0.81782) avg lploss: 0.00000
*** Best Val Loss: 0.80665 	 Best Test Loss: 1.01273 	 Best epoch 495
EarlyStopping counter: 3 out of 50
train epoch 511 avg loss: 0.47062 (A-MSE: 0.41061) avg lploss: 0.00000
train epoch 512 avg loss: 0.48790 (A-MSE: 0.42854) avg lploss: 0.00000
train epoch 513 avg loss: 0.47090 (A-MSE: 0.41097) avg lploss: 0.00000
train epoch 514 avg loss: 0.58794 (A-MSE: 0.51306) avg lploss: 0.00000
train epoch 515 avg loss: 0.53497 (A-MSE: 0.46509) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.77931 (A-MSE: 0.69453) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.93354 (A-MSE: 0.85171) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
Validation loss decreased (0.806654 --> 0.779313).  Saving model ...
train epoch 516 avg loss: 0.43838 (A-MSE: 0.38368) avg lploss: 0.00000
train epoch 517 avg loss: 0.41860 (A-MSE: 0.36516) avg lploss: 0.00000
train epoch 518 avg loss: 0.43640 (A-MSE: 0.38123) avg lploss: 0.00000
train epoch 519 avg loss: 0.47374 (A-MSE: 0.41392) avg lploss: 0.00000
train epoch 520 avg loss: 0.55568 (A-MSE: 0.48845) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.35659 (A-MSE: 1.15538) avg lploss: 0.00000
==> test epoch 520 avg loss: 1.30183 (A-MSE: 1.14350) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 1 out of 50
train epoch 521 avg loss: 0.59455 (A-MSE: 0.51968) avg lploss: 0.00000
train epoch 522 avg loss: 0.50195 (A-MSE: 0.43671) avg lploss: 0.00000
train epoch 523 avg loss: 0.48096 (A-MSE: 0.42091) avg lploss: 0.00000
train epoch 524 avg loss: 0.52729 (A-MSE: 0.46230) avg lploss: 0.00000
train epoch 525 avg loss: 0.50797 (A-MSE: 0.44398) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.81376 (A-MSE: 0.69675) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.97764 (A-MSE: 0.86058) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 2 out of 50
train epoch 526 avg loss: 0.49658 (A-MSE: 0.43084) avg lploss: 0.00000
train epoch 527 avg loss: 0.47504 (A-MSE: 0.41225) avg lploss: 0.00000
train epoch 528 avg loss: 0.48424 (A-MSE: 0.42051) avg lploss: 0.00000
train epoch 529 avg loss: 0.46866 (A-MSE: 0.41038) avg lploss: 0.00000
train epoch 530 avg loss: 0.42876 (A-MSE: 0.37671) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.78728 (A-MSE: 0.66176) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.92744 (A-MSE: 0.79809) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 3 out of 50
train epoch 531 avg loss: 0.47617 (A-MSE: 0.41620) avg lploss: 0.00000
train epoch 532 avg loss: 0.49248 (A-MSE: 0.43109) avg lploss: 0.00000
train epoch 533 avg loss: 0.50909 (A-MSE: 0.44349) avg lploss: 0.00000
train epoch 534 avg loss: 0.48191 (A-MSE: 0.42267) avg lploss: 0.00000
train epoch 535 avg loss: 0.43217 (A-MSE: 0.37551) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.80883 (A-MSE: 0.70098) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.89991 (A-MSE: 0.80549) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 4 out of 50
train epoch 536 avg loss: 0.43906 (A-MSE: 0.38471) avg lploss: 0.00000
train epoch 537 avg loss: 0.42599 (A-MSE: 0.37342) avg lploss: 0.00000
train epoch 538 avg loss: 0.45104 (A-MSE: 0.39459) avg lploss: 0.00000
train epoch 539 avg loss: 0.46380 (A-MSE: 0.40563) avg lploss: 0.00000
train epoch 540 avg loss: 0.47317 (A-MSE: 0.41620) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.78017 (A-MSE: 0.67245) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.91616 (A-MSE: 0.80564) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 5 out of 50
train epoch 541 avg loss: 0.45115 (A-MSE: 0.39465) avg lploss: 0.00000
train epoch 542 avg loss: 0.39965 (A-MSE: 0.34996) avg lploss: 0.00000
train epoch 543 avg loss: 0.45463 (A-MSE: 0.39863) avg lploss: 0.00000
train epoch 544 avg loss: 0.47744 (A-MSE: 0.42070) avg lploss: 0.00000
train epoch 545 avg loss: 0.42433 (A-MSE: 0.36954) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.84958 (A-MSE: 0.72543) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.91978 (A-MSE: 0.80723) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 6 out of 50
train epoch 546 avg loss: 0.42369 (A-MSE: 0.36802) avg lploss: 0.00000
train epoch 547 avg loss: 0.44863 (A-MSE: 0.39202) avg lploss: 0.00000
train epoch 548 avg loss: 0.47924 (A-MSE: 0.41891) avg lploss: 0.00000
train epoch 549 avg loss: 0.39734 (A-MSE: 0.34989) avg lploss: 0.00000
train epoch 550 avg loss: 0.41285 (A-MSE: 0.35900) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.88286 (A-MSE: 0.77117) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.90137 (A-MSE: 0.81007) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 7 out of 50
train epoch 551 avg loss: 0.48238 (A-MSE: 0.41878) avg lploss: 0.00000
train epoch 552 avg loss: 0.42699 (A-MSE: 0.37465) avg lploss: 0.00000
train epoch 553 avg loss: 0.47416 (A-MSE: 0.41832) avg lploss: 0.00000
train epoch 554 avg loss: 0.47087 (A-MSE: 0.41105) avg lploss: 0.00000
train epoch 555 avg loss: 0.52699 (A-MSE: 0.45866) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.84024 (A-MSE: 0.72676) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.93440 (A-MSE: 0.82746) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 8 out of 50
train epoch 556 avg loss: 0.46427 (A-MSE: 0.40520) avg lploss: 0.00000
train epoch 557 avg loss: 0.47819 (A-MSE: 0.41896) avg lploss: 0.00000
train epoch 558 avg loss: 0.47805 (A-MSE: 0.42026) avg lploss: 0.00000
train epoch 559 avg loss: 0.43755 (A-MSE: 0.37972) avg lploss: 0.00000
train epoch 560 avg loss: 0.43450 (A-MSE: 0.37817) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.90391 (A-MSE: 0.78282) avg lploss: 0.00000
==> test epoch 560 avg loss: 1.04890 (A-MSE: 0.93447) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 9 out of 50
train epoch 561 avg loss: 0.41892 (A-MSE: 0.36744) avg lploss: 0.00000
train epoch 562 avg loss: 0.42546 (A-MSE: 0.37244) avg lploss: 0.00000
train epoch 563 avg loss: 0.43558 (A-MSE: 0.37888) avg lploss: 0.00000
train epoch 564 avg loss: 0.46471 (A-MSE: 0.40809) avg lploss: 0.00000
train epoch 565 avg loss: 0.41346 (A-MSE: 0.36239) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.88976 (A-MSE: 0.77201) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.93642 (A-MSE: 0.83870) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 10 out of 50
train epoch 566 avg loss: 0.54188 (A-MSE: 0.47370) avg lploss: 0.00000
train epoch 567 avg loss: 0.49921 (A-MSE: 0.44215) avg lploss: 0.00000
train epoch 568 avg loss: 0.44833 (A-MSE: 0.39390) avg lploss: 0.00000
train epoch 569 avg loss: 0.42828 (A-MSE: 0.37517) avg lploss: 0.00000
train epoch 570 avg loss: 0.41883 (A-MSE: 0.36867) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.85980 (A-MSE: 0.74707) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.92483 (A-MSE: 0.82756) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 11 out of 50
train epoch 571 avg loss: 0.41256 (A-MSE: 0.36367) avg lploss: 0.00000
train epoch 572 avg loss: 0.39170 (A-MSE: 0.34101) avg lploss: 0.00000
train epoch 573 avg loss: 0.40024 (A-MSE: 0.35237) avg lploss: 0.00000
train epoch 574 avg loss: 0.43792 (A-MSE: 0.38399) avg lploss: 0.00000
train epoch 575 avg loss: 0.42662 (A-MSE: 0.37454) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.84653 (A-MSE: 0.71044) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.95572 (A-MSE: 0.82930) avg lploss: 0.00000
*** Best Val Loss: 0.77931 	 Best Test Loss: 0.93354 	 Best epoch 515
EarlyStopping counter: 12 out of 50
train epoch 576 avg loss: 0.44477 (A-MSE: 0.38439) avg lploss: 0.00000
train epoch 577 avg loss: 0.41000 (A-MSE: 0.35674) avg lploss: 0.00000
train epoch 578 avg loss: 0.41202 (A-MSE: 0.36649) avg lploss: 0.00000
train epoch 579 avg loss: 0.38529 (A-MSE: 0.33594) avg lploss: 0.00000
train epoch 580 avg loss: 0.39274 (A-MSE: 0.34382) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.72639 (A-MSE: 0.64028) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.83030 (A-MSE: 0.74589) avg lploss: 0.00000
*** Best Val Loss: 0.72639 	 Best Test Loss: 0.83030 	 Best epoch 580
Validation loss decreased (0.779313 --> 0.726393).  Saving model ...
train epoch 581 avg loss: 0.39233 (A-MSE: 0.34754) avg lploss: 0.00000
train epoch 582 avg loss: 0.40726 (A-MSE: 0.35834) avg lploss: 0.00000
train epoch 583 avg loss: 0.43063 (A-MSE: 0.37799) avg lploss: 0.00000
train epoch 584 avg loss: 0.45817 (A-MSE: 0.40238) avg lploss: 0.00000
train epoch 585 avg loss: 0.46956 (A-MSE: 0.40840) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.67971 (A-MSE: 0.58295) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.80286 (A-MSE: 0.70946) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
Validation loss decreased (0.726393 --> 0.679708).  Saving model ...
train epoch 586 avg loss: 0.42242 (A-MSE: 0.37140) avg lploss: 0.00000
train epoch 587 avg loss: 0.40711 (A-MSE: 0.35613) avg lploss: 0.00000
train epoch 588 avg loss: 0.43678 (A-MSE: 0.38520) avg lploss: 0.00000
train epoch 589 avg loss: 0.38917 (A-MSE: 0.34076) avg lploss: 0.00000
train epoch 590 avg loss: 0.40580 (A-MSE: 0.35476) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.71803 (A-MSE: 0.63153) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.79471 (A-MSE: 0.71314) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 1 out of 50
train epoch 591 avg loss: 0.38600 (A-MSE: 0.33849) avg lploss: 0.00000
train epoch 592 avg loss: 0.37439 (A-MSE: 0.32982) avg lploss: 0.00000
train epoch 593 avg loss: 0.43526 (A-MSE: 0.38164) avg lploss: 0.00000
train epoch 594 avg loss: 0.40536 (A-MSE: 0.35618) avg lploss: 0.00000
train epoch 595 avg loss: 0.46575 (A-MSE: 0.40341) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.83646 (A-MSE: 0.72472) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.85656 (A-MSE: 0.76511) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 2 out of 50
train epoch 596 avg loss: 0.36904 (A-MSE: 0.32429) avg lploss: 0.00000
train epoch 597 avg loss: 0.37851 (A-MSE: 0.33311) avg lploss: 0.00000
train epoch 598 avg loss: 0.40774 (A-MSE: 0.35873) avg lploss: 0.00000
train epoch 599 avg loss: 0.38902 (A-MSE: 0.34123) avg lploss: 0.00000
train epoch 600 avg loss: 0.35875 (A-MSE: 0.31280) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.70198 (A-MSE: 0.61291) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.79872 (A-MSE: 0.71605) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 3 out of 50
train epoch 601 avg loss: 0.34368 (A-MSE: 0.30275) avg lploss: 0.00000
train epoch 602 avg loss: 0.40131 (A-MSE: 0.35079) avg lploss: 0.00000
train epoch 603 avg loss: 0.46778 (A-MSE: 0.41030) avg lploss: 0.00000
train epoch 604 avg loss: 0.42378 (A-MSE: 0.37280) avg lploss: 0.00000
train epoch 605 avg loss: 0.38220 (A-MSE: 0.33481) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.85670 (A-MSE: 0.72924) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.80637 (A-MSE: 0.71316) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 4 out of 50
train epoch 606 avg loss: 0.38753 (A-MSE: 0.33710) avg lploss: 0.00000
train epoch 607 avg loss: 0.36329 (A-MSE: 0.32347) avg lploss: 0.00000
train epoch 608 avg loss: 0.43852 (A-MSE: 0.38595) avg lploss: 0.00000
train epoch 609 avg loss: 0.42515 (A-MSE: 0.37219) avg lploss: 0.00000
train epoch 610 avg loss: 0.41117 (A-MSE: 0.35972) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.74278 (A-MSE: 0.63308) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.79568 (A-MSE: 0.70131) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 5 out of 50
train epoch 611 avg loss: 0.39846 (A-MSE: 0.34946) avg lploss: 0.00000
train epoch 612 avg loss: 0.41338 (A-MSE: 0.36137) avg lploss: 0.00000
train epoch 613 avg loss: 0.40048 (A-MSE: 0.35036) avg lploss: 0.00000
train epoch 614 avg loss: 0.37609 (A-MSE: 0.32699) avg lploss: 0.00000
train epoch 615 avg loss: 0.37187 (A-MSE: 0.32785) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.70389 (A-MSE: 0.61553) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.79114 (A-MSE: 0.71239) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 6 out of 50
train epoch 616 avg loss: 0.35300 (A-MSE: 0.31061) avg lploss: 0.00000
train epoch 617 avg loss: 0.39344 (A-MSE: 0.34488) avg lploss: 0.00000
train epoch 618 avg loss: 0.36761 (A-MSE: 0.32365) avg lploss: 0.00000
train epoch 619 avg loss: 0.36213 (A-MSE: 0.31976) avg lploss: 0.00000
train epoch 620 avg loss: 0.36211 (A-MSE: 0.31821) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.68003 (A-MSE: 0.59191) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.75634 (A-MSE: 0.68002) avg lploss: 0.00000
*** Best Val Loss: 0.67971 	 Best Test Loss: 0.80286 	 Best epoch 585
EarlyStopping counter: 7 out of 50
train epoch 621 avg loss: 0.38979 (A-MSE: 0.34389) avg lploss: 0.00000
train epoch 622 avg loss: 0.37592 (A-MSE: 0.33038) avg lploss: 0.00000
train epoch 623 avg loss: 0.36594 (A-MSE: 0.32006) avg lploss: 0.00000
train epoch 624 avg loss: 0.35351 (A-MSE: 0.31013) avg lploss: 0.00000
train epoch 625 avg loss: 0.32675 (A-MSE: 0.28613) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.67267 (A-MSE: 0.59856) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.72762 (A-MSE: 0.66703) avg lploss: 0.00000
*** Best Val Loss: 0.67267 	 Best Test Loss: 0.72762 	 Best epoch 625
Validation loss decreased (0.679708 --> 0.672669).  Saving model ...
train epoch 626 avg loss: 0.34999 (A-MSE: 0.31032) avg lploss: 0.00000
train epoch 627 avg loss: 0.39242 (A-MSE: 0.34380) avg lploss: 0.00000
train epoch 628 avg loss: 0.40789 (A-MSE: 0.35811) avg lploss: 0.00000
train epoch 629 avg loss: 0.37148 (A-MSE: 0.32446) avg lploss: 0.00000
train epoch 630 avg loss: 0.38582 (A-MSE: 0.34255) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.81935 (A-MSE: 0.71754) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.89680 (A-MSE: 0.80552) avg lploss: 0.00000
*** Best Val Loss: 0.67267 	 Best Test Loss: 0.72762 	 Best epoch 625
EarlyStopping counter: 1 out of 50
train epoch 631 avg loss: 0.44213 (A-MSE: 0.38973) avg lploss: 0.00000
train epoch 632 avg loss: 0.35502 (A-MSE: 0.31220) avg lploss: 0.00000
train epoch 633 avg loss: 0.37707 (A-MSE: 0.32879) avg lploss: 0.00000
train epoch 634 avg loss: 0.42626 (A-MSE: 0.36853) avg lploss: 0.00000
train epoch 635 avg loss: 0.37619 (A-MSE: 0.33105) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.71070 (A-MSE: 0.64217) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.80589 (A-MSE: 0.73161) avg lploss: 0.00000
*** Best Val Loss: 0.67267 	 Best Test Loss: 0.72762 	 Best epoch 625
EarlyStopping counter: 2 out of 50
train epoch 636 avg loss: 0.43011 (A-MSE: 0.37819) avg lploss: 0.00000
train epoch 637 avg loss: 0.44568 (A-MSE: 0.39347) avg lploss: 0.00000
train epoch 638 avg loss: 0.36459 (A-MSE: 0.32241) avg lploss: 0.00000
train epoch 639 avg loss: 0.38247 (A-MSE: 0.33210) avg lploss: 0.00000
train epoch 640 avg loss: 0.36126 (A-MSE: 0.31643) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.66702 (A-MSE: 0.57549) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.67400 (A-MSE: 0.60586) avg lploss: 0.00000
*** Best Val Loss: 0.66702 	 Best Test Loss: 0.67400 	 Best epoch 640
Validation loss decreased (0.672669 --> 0.667016).  Saving model ...
train epoch 641 avg loss: 0.32185 (A-MSE: 0.28300) avg lploss: 0.00000
train epoch 642 avg loss: 0.34453 (A-MSE: 0.30140) avg lploss: 0.00000
train epoch 643 avg loss: 0.37445 (A-MSE: 0.33292) avg lploss: 0.00000
train epoch 644 avg loss: 0.34778 (A-MSE: 0.30457) avg lploss: 0.00000
train epoch 645 avg loss: 0.31968 (A-MSE: 0.28096) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.63160 (A-MSE: 0.54474) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.70251 (A-MSE: 0.63358) avg lploss: 0.00000
*** Best Val Loss: 0.63160 	 Best Test Loss: 0.70251 	 Best epoch 645
Validation loss decreased (0.667016 --> 0.631599).  Saving model ...
train epoch 646 avg loss: 0.30750 (A-MSE: 0.27086) avg lploss: 0.00000
train epoch 647 avg loss: 0.31828 (A-MSE: 0.28023) avg lploss: 0.00000
train epoch 648 avg loss: 0.36133 (A-MSE: 0.31562) avg lploss: 0.00000
train epoch 649 avg loss: 0.34230 (A-MSE: 0.30041) avg lploss: 0.00000
train epoch 650 avg loss: 0.31146 (A-MSE: 0.27582) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.72048 (A-MSE: 0.62328) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.81923 (A-MSE: 0.73497) avg lploss: 0.00000
*** Best Val Loss: 0.63160 	 Best Test Loss: 0.70251 	 Best epoch 645
EarlyStopping counter: 1 out of 50
train epoch 651 avg loss: 0.34836 (A-MSE: 0.30818) avg lploss: 0.00000
train epoch 652 avg loss: 0.36527 (A-MSE: 0.32069) avg lploss: 0.00000
train epoch 653 avg loss: 0.35327 (A-MSE: 0.31035) avg lploss: 0.00000
train epoch 654 avg loss: 0.34572 (A-MSE: 0.30680) avg lploss: 0.00000
train epoch 655 avg loss: 0.31103 (A-MSE: 0.27394) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.71357 (A-MSE: 0.61658) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.74248 (A-MSE: 0.66488) avg lploss: 0.00000
*** Best Val Loss: 0.63160 	 Best Test Loss: 0.70251 	 Best epoch 645
EarlyStopping counter: 2 out of 50
train epoch 656 avg loss: 0.31697 (A-MSE: 0.27733) avg lploss: 0.00000
train epoch 657 avg loss: 0.34084 (A-MSE: 0.29806) avg lploss: 0.00000
train epoch 658 avg loss: 0.36620 (A-MSE: 0.32181) avg lploss: 0.00000
train epoch 659 avg loss: 0.33835 (A-MSE: 0.29635) avg lploss: 0.00000
train epoch 660 avg loss: 0.37261 (A-MSE: 0.32611) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.72432 (A-MSE: 0.62617) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.79643 (A-MSE: 0.70610) avg lploss: 0.00000
*** Best Val Loss: 0.63160 	 Best Test Loss: 0.70251 	 Best epoch 645
EarlyStopping counter: 3 out of 50
train epoch 661 avg loss: 0.29828 (A-MSE: 0.26559) avg lploss: 0.00000
train epoch 662 avg loss: 0.38335 (A-MSE: 0.33303) avg lploss: 0.00000
train epoch 663 avg loss: 0.39217 (A-MSE: 0.34217) avg lploss: 0.00000
train epoch 664 avg loss: 0.31096 (A-MSE: 0.27469) avg lploss: 0.00000
train epoch 665 avg loss: 0.34970 (A-MSE: 0.31019) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.62625 (A-MSE: 0.53669) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.65641 (A-MSE: 0.58792) avg lploss: 0.00000
*** Best Val Loss: 0.62625 	 Best Test Loss: 0.65641 	 Best epoch 665
Validation loss decreased (0.631599 --> 0.626252).  Saving model ...
train epoch 666 avg loss: 0.32537 (A-MSE: 0.28551) avg lploss: 0.00000
train epoch 667 avg loss: 0.34788 (A-MSE: 0.30428) avg lploss: 0.00000
train epoch 668 avg loss: 0.30804 (A-MSE: 0.27353) avg lploss: 0.00000
train epoch 669 avg loss: 0.28793 (A-MSE: 0.25407) avg lploss: 0.00000
train epoch 670 avg loss: 0.29159 (A-MSE: 0.25660) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.60617 (A-MSE: 0.53576) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.67364 (A-MSE: 0.60823) avg lploss: 0.00000
*** Best Val Loss: 0.60617 	 Best Test Loss: 0.67364 	 Best epoch 670
Validation loss decreased (0.626252 --> 0.606167).  Saving model ...
train epoch 671 avg loss: 0.30944 (A-MSE: 0.27160) avg lploss: 0.00000
train epoch 672 avg loss: 0.33353 (A-MSE: 0.29343) avg lploss: 0.00000
train epoch 673 avg loss: 0.34495 (A-MSE: 0.30246) avg lploss: 0.00000
train epoch 674 avg loss: 0.29424 (A-MSE: 0.25944) avg lploss: 0.00000
train epoch 675 avg loss: 0.27323 (A-MSE: 0.23992) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.59586 (A-MSE: 0.51257) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.68865 (A-MSE: 0.61510) avg lploss: 0.00000
*** Best Val Loss: 0.59586 	 Best Test Loss: 0.68865 	 Best epoch 675
Validation loss decreased (0.606167 --> 0.595863).  Saving model ...
train epoch 676 avg loss: 0.29389 (A-MSE: 0.25949) avg lploss: 0.00000
train epoch 677 avg loss: 0.27735 (A-MSE: 0.24488) avg lploss: 0.00000
train epoch 678 avg loss: 0.31059 (A-MSE: 0.27105) avg lploss: 0.00000
train epoch 679 avg loss: 0.30189 (A-MSE: 0.26556) avg lploss: 0.00000
train epoch 680 avg loss: 0.31121 (A-MSE: 0.27547) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.59932 (A-MSE: 0.51754) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.60154 (A-MSE: 0.54552) avg lploss: 0.00000
*** Best Val Loss: 0.59586 	 Best Test Loss: 0.68865 	 Best epoch 675
EarlyStopping counter: 1 out of 50
train epoch 681 avg loss: 0.33875 (A-MSE: 0.29843) avg lploss: 0.00000
train epoch 682 avg loss: 0.35935 (A-MSE: 0.31868) avg lploss: 0.00000
train epoch 683 avg loss: 0.29296 (A-MSE: 0.25954) avg lploss: 0.00000
train epoch 684 avg loss: 0.28218 (A-MSE: 0.24865) avg lploss: 0.00000
train epoch 685 avg loss: 0.30165 (A-MSE: 0.26533) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.62261 (A-MSE: 0.54258) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.66972 (A-MSE: 0.60535) avg lploss: 0.00000
*** Best Val Loss: 0.59586 	 Best Test Loss: 0.68865 	 Best epoch 675
EarlyStopping counter: 2 out of 50
train epoch 686 avg loss: 0.31852 (A-MSE: 0.27855) avg lploss: 0.00000
train epoch 687 avg loss: 0.31611 (A-MSE: 0.27883) avg lploss: 0.00000
train epoch 688 avg loss: 0.31765 (A-MSE: 0.28029) avg lploss: 0.00000
train epoch 689 avg loss: 0.32762 (A-MSE: 0.28685) avg lploss: 0.00000
train epoch 690 avg loss: 0.36693 (A-MSE: 0.32169) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.72015 (A-MSE: 0.61543) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.69626 (A-MSE: 0.62064) avg lploss: 0.00000
*** Best Val Loss: 0.59586 	 Best Test Loss: 0.68865 	 Best epoch 675
EarlyStopping counter: 3 out of 50
train epoch 691 avg loss: 0.37094 (A-MSE: 0.32754) avg lploss: 0.00000
train epoch 692 avg loss: 0.31428 (A-MSE: 0.27624) avg lploss: 0.00000
train epoch 693 avg loss: 0.28945 (A-MSE: 0.25570) avg lploss: 0.00000
train epoch 694 avg loss: 0.28958 (A-MSE: 0.25483) avg lploss: 0.00000
train epoch 695 avg loss: 0.32497 (A-MSE: 0.28565) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.70163 (A-MSE: 0.60036) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.65418 (A-MSE: 0.58602) avg lploss: 0.00000
*** Best Val Loss: 0.59586 	 Best Test Loss: 0.68865 	 Best epoch 675
EarlyStopping counter: 4 out of 50
train epoch 696 avg loss: 0.36219 (A-MSE: 0.32068) avg lploss: 0.00000
train epoch 697 avg loss: 0.31082 (A-MSE: 0.27357) avg lploss: 0.00000
train epoch 698 avg loss: 0.33829 (A-MSE: 0.29589) avg lploss: 0.00000
train epoch 699 avg loss: 0.31146 (A-MSE: 0.27383) avg lploss: 0.00000
train epoch 700 avg loss: 0.26827 (A-MSE: 0.23496) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.63568 (A-MSE: 0.54384) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.70361 (A-MSE: 0.63113) avg lploss: 0.00000
*** Best Val Loss: 0.59586 	 Best Test Loss: 0.68865 	 Best epoch 675
EarlyStopping counter: 5 out of 50
train epoch 701 avg loss: 0.32496 (A-MSE: 0.28524) avg lploss: 0.00000
train epoch 702 avg loss: 0.32944 (A-MSE: 0.29153) avg lploss: 0.00000
train epoch 703 avg loss: 0.32228 (A-MSE: 0.28156) avg lploss: 0.00000
train epoch 704 avg loss: 0.29677 (A-MSE: 0.26453) avg lploss: 0.00000
train epoch 705 avg loss: 0.30804 (A-MSE: 0.26946) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.57735 (A-MSE: 0.49991) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.66959 (A-MSE: 0.59498) avg lploss: 0.00000
*** Best Val Loss: 0.57735 	 Best Test Loss: 0.66959 	 Best epoch 705
Validation loss decreased (0.595863 --> 0.577352).  Saving model ...
train epoch 706 avg loss: 0.29244 (A-MSE: 0.25888) avg lploss: 0.00000
train epoch 707 avg loss: 0.26727 (A-MSE: 0.23628) avg lploss: 0.00000
train epoch 708 avg loss: 0.29741 (A-MSE: 0.26023) avg lploss: 0.00000
train epoch 709 avg loss: 0.29728 (A-MSE: 0.26176) avg lploss: 0.00000
train epoch 710 avg loss: 0.28944 (A-MSE: 0.25412) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.59899 (A-MSE: 0.51089) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.64758 (A-MSE: 0.57483) avg lploss: 0.00000
*** Best Val Loss: 0.57735 	 Best Test Loss: 0.66959 	 Best epoch 705
EarlyStopping counter: 1 out of 50
train epoch 711 avg loss: 0.30344 (A-MSE: 0.26813) avg lploss: 0.00000
train epoch 712 avg loss: 0.30280 (A-MSE: 0.26697) avg lploss: 0.00000
train epoch 713 avg loss: 0.30096 (A-MSE: 0.26322) avg lploss: 0.00000
train epoch 714 avg loss: 0.32375 (A-MSE: 0.28424) avg lploss: 0.00000
train epoch 715 avg loss: 0.31156 (A-MSE: 0.27582) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.51441 (A-MSE: 0.45147) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.56131 (A-MSE: 0.50450) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
Validation loss decreased (0.577352 --> 0.514408).  Saving model ...
train epoch 716 avg loss: 0.31422 (A-MSE: 0.27610) avg lploss: 0.00000
train epoch 717 avg loss: 0.30388 (A-MSE: 0.26940) avg lploss: 0.00000
train epoch 718 avg loss: 0.28096 (A-MSE: 0.24779) avg lploss: 0.00000
train epoch 719 avg loss: 0.29799 (A-MSE: 0.26255) avg lploss: 0.00000
train epoch 720 avg loss: 0.30369 (A-MSE: 0.26759) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.54520 (A-MSE: 0.47185) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.58416 (A-MSE: 0.52542) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 1 out of 50
train epoch 721 avg loss: 0.29452 (A-MSE: 0.25920) avg lploss: 0.00000
train epoch 722 avg loss: 0.29478 (A-MSE: 0.26006) avg lploss: 0.00000
train epoch 723 avg loss: 0.31764 (A-MSE: 0.27723) avg lploss: 0.00000
train epoch 724 avg loss: 0.29340 (A-MSE: 0.25917) avg lploss: 0.00000
train epoch 725 avg loss: 0.33994 (A-MSE: 0.29913) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.56363 (A-MSE: 0.49645) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.61227 (A-MSE: 0.55680) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 2 out of 50
train epoch 726 avg loss: 0.29332 (A-MSE: 0.25963) avg lploss: 0.00000
train epoch 727 avg loss: 0.26912 (A-MSE: 0.23637) avg lploss: 0.00000
train epoch 728 avg loss: 0.24351 (A-MSE: 0.21553) avg lploss: 0.00000
train epoch 729 avg loss: 0.29097 (A-MSE: 0.25768) avg lploss: 0.00000
train epoch 730 avg loss: 0.31541 (A-MSE: 0.27903) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.70903 (A-MSE: 0.61881) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.75638 (A-MSE: 0.68119) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 3 out of 50
train epoch 731 avg loss: 0.30904 (A-MSE: 0.27101) avg lploss: 0.00000
train epoch 732 avg loss: 0.44412 (A-MSE: 0.39108) avg lploss: 0.00000
train epoch 733 avg loss: 0.39244 (A-MSE: 0.34737) avg lploss: 0.00000
train epoch 734 avg loss: 0.30421 (A-MSE: 0.26868) avg lploss: 0.00000
train epoch 735 avg loss: 0.30042 (A-MSE: 0.26312) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.62134 (A-MSE: 0.52368) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.64811 (A-MSE: 0.56958) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 4 out of 50
train epoch 736 avg loss: 0.27765 (A-MSE: 0.24387) avg lploss: 0.00000
train epoch 737 avg loss: 0.24436 (A-MSE: 0.21432) avg lploss: 0.00000
train epoch 738 avg loss: 0.26847 (A-MSE: 0.23696) avg lploss: 0.00000
train epoch 739 avg loss: 0.31190 (A-MSE: 0.27423) avg lploss: 0.00000
train epoch 740 avg loss: 0.37443 (A-MSE: 0.33040) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.59907 (A-MSE: 0.51193) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.65271 (A-MSE: 0.58686) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 5 out of 50
train epoch 741 avg loss: 0.34554 (A-MSE: 0.30523) avg lploss: 0.00000
train epoch 742 avg loss: 0.28750 (A-MSE: 0.25153) avg lploss: 0.00000
train epoch 743 avg loss: 0.28546 (A-MSE: 0.25074) avg lploss: 0.00000
train epoch 744 avg loss: 0.33840 (A-MSE: 0.29769) avg lploss: 0.00000
train epoch 745 avg loss: 0.32323 (A-MSE: 0.28440) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.58252 (A-MSE: 0.50081) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.60825 (A-MSE: 0.54425) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 6 out of 50
train epoch 746 avg loss: 0.25811 (A-MSE: 0.22806) avg lploss: 0.00000
train epoch 747 avg loss: 0.28192 (A-MSE: 0.25095) avg lploss: 0.00000
train epoch 748 avg loss: 0.32597 (A-MSE: 0.28528) avg lploss: 0.00000
train epoch 749 avg loss: 0.25566 (A-MSE: 0.22601) avg lploss: 0.00000
train epoch 750 avg loss: 0.27863 (A-MSE: 0.24609) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.65789 (A-MSE: 0.55254) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.67731 (A-MSE: 0.58942) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 7 out of 50
train epoch 751 avg loss: 0.27101 (A-MSE: 0.23883) avg lploss: 0.00000
train epoch 752 avg loss: 0.31604 (A-MSE: 0.27710) avg lploss: 0.00000
train epoch 753 avg loss: 0.26089 (A-MSE: 0.22828) avg lploss: 0.00000
train epoch 754 avg loss: 0.27912 (A-MSE: 0.24712) avg lploss: 0.00000
train epoch 755 avg loss: 0.25626 (A-MSE: 0.22676) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.58217 (A-MSE: 0.49792) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.62719 (A-MSE: 0.55923) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 8 out of 50
train epoch 756 avg loss: 0.27597 (A-MSE: 0.24128) avg lploss: 0.00000
train epoch 757 avg loss: 0.25549 (A-MSE: 0.22609) avg lploss: 0.00000
train epoch 758 avg loss: 0.25386 (A-MSE: 0.22282) avg lploss: 0.00000
train epoch 759 avg loss: 0.27049 (A-MSE: 0.23706) avg lploss: 0.00000
train epoch 760 avg loss: 0.27505 (A-MSE: 0.24412) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.59234 (A-MSE: 0.50084) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.61092 (A-MSE: 0.54340) avg lploss: 0.00000
*** Best Val Loss: 0.51441 	 Best Test Loss: 0.56131 	 Best epoch 715
EarlyStopping counter: 9 out of 50
train epoch 761 avg loss: 0.25585 (A-MSE: 0.22502) avg lploss: 0.00000
train epoch 762 avg loss: 0.24621 (A-MSE: 0.21698) avg lploss: 0.00000
train epoch 763 avg loss: 0.25355 (A-MSE: 0.22448) avg lploss: 0.00000
train epoch 764 avg loss: 0.24513 (A-MSE: 0.21594) avg lploss: 0.00000
train epoch 765 avg loss: 0.22834 (A-MSE: 0.20237) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.46733 (A-MSE: 0.40779) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.53351 (A-MSE: 0.48376) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
Validation loss decreased (0.514408 --> 0.467333).  Saving model ...
train epoch 766 avg loss: 0.24220 (A-MSE: 0.21577) avg lploss: 0.00000
train epoch 767 avg loss: 0.30520 (A-MSE: 0.26786) avg lploss: 0.00000
train epoch 768 avg loss: 0.30881 (A-MSE: 0.27082) avg lploss: 0.00000
train epoch 769 avg loss: 0.28752 (A-MSE: 0.25094) avg lploss: 0.00000
train epoch 770 avg loss: 0.31848 (A-MSE: 0.28208) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.90257 (A-MSE: 0.74886) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.82063 (A-MSE: 0.71049) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 1 out of 50
train epoch 771 avg loss: 0.29968 (A-MSE: 0.26347) avg lploss: 0.00000
train epoch 772 avg loss: 0.26254 (A-MSE: 0.23046) avg lploss: 0.00000
train epoch 773 avg loss: 0.27090 (A-MSE: 0.23711) avg lploss: 0.00000
train epoch 774 avg loss: 0.30814 (A-MSE: 0.27176) avg lploss: 0.00000
train epoch 775 avg loss: 0.26581 (A-MSE: 0.23699) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.90416 (A-MSE: 0.77781) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.84007 (A-MSE: 0.74824) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 2 out of 50
train epoch 776 avg loss: 0.27876 (A-MSE: 0.24759) avg lploss: 0.00000
train epoch 777 avg loss: 0.21649 (A-MSE: 0.19175) avg lploss: 0.00000
train epoch 778 avg loss: 0.26067 (A-MSE: 0.22902) avg lploss: 0.00000
train epoch 779 avg loss: 0.27344 (A-MSE: 0.24135) avg lploss: 0.00000
train epoch 780 avg loss: 0.28936 (A-MSE: 0.25619) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.56295 (A-MSE: 0.47635) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.58891 (A-MSE: 0.51894) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 3 out of 50
train epoch 781 avg loss: 0.24841 (A-MSE: 0.21802) avg lploss: 0.00000
train epoch 782 avg loss: 0.24566 (A-MSE: 0.21569) avg lploss: 0.00000
train epoch 783 avg loss: 0.21518 (A-MSE: 0.19051) avg lploss: 0.00000
train epoch 784 avg loss: 0.23590 (A-MSE: 0.20689) avg lploss: 0.00000
train epoch 785 avg loss: 0.24820 (A-MSE: 0.22101) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.65199 (A-MSE: 0.56260) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.60676 (A-MSE: 0.54671) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 4 out of 50
train epoch 786 avg loss: 0.27170 (A-MSE: 0.23892) avg lploss: 0.00000
train epoch 787 avg loss: 0.28025 (A-MSE: 0.24786) avg lploss: 0.00000
train epoch 788 avg loss: 0.25437 (A-MSE: 0.22442) avg lploss: 0.00000
train epoch 789 avg loss: 0.24498 (A-MSE: 0.21595) avg lploss: 0.00000
train epoch 790 avg loss: 0.25917 (A-MSE: 0.22875) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.56524 (A-MSE: 0.48177) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.53249 (A-MSE: 0.47351) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 5 out of 50
train epoch 791 avg loss: 0.25101 (A-MSE: 0.22080) avg lploss: 0.00000
train epoch 792 avg loss: 0.28623 (A-MSE: 0.25093) avg lploss: 0.00000
train epoch 793 avg loss: 0.32280 (A-MSE: 0.28388) avg lploss: 0.00000
train epoch 794 avg loss: 0.24741 (A-MSE: 0.21542) avg lploss: 0.00000
train epoch 795 avg loss: 0.27145 (A-MSE: 0.23886) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.62138 (A-MSE: 0.52300) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.67479 (A-MSE: 0.59881) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 6 out of 50
train epoch 796 avg loss: 0.34889 (A-MSE: 0.30608) avg lploss: 0.00000
train epoch 797 avg loss: 0.29852 (A-MSE: 0.26227) avg lploss: 0.00000
train epoch 798 avg loss: 0.25653 (A-MSE: 0.22867) avg lploss: 0.00000
train epoch 799 avg loss: 0.23966 (A-MSE: 0.21027) avg lploss: 0.00000
train epoch 800 avg loss: 0.22488 (A-MSE: 0.19949) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.61914 (A-MSE: 0.53019) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.59935 (A-MSE: 0.52744) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 7 out of 50
train epoch 801 avg loss: 0.23109 (A-MSE: 0.20240) avg lploss: 0.00000
train epoch 802 avg loss: 0.24668 (A-MSE: 0.21724) avg lploss: 0.00000
train epoch 803 avg loss: 0.24088 (A-MSE: 0.21231) avg lploss: 0.00000
train epoch 804 avg loss: 0.26105 (A-MSE: 0.23167) avg lploss: 0.00000
train epoch 805 avg loss: 0.26759 (A-MSE: 0.23491) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.55014 (A-MSE: 0.46364) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.55697 (A-MSE: 0.49811) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 8 out of 50
train epoch 806 avg loss: 0.28960 (A-MSE: 0.25347) avg lploss: 0.00000
train epoch 807 avg loss: 0.26487 (A-MSE: 0.23064) avg lploss: 0.00000
train epoch 808 avg loss: 0.23051 (A-MSE: 0.20333) avg lploss: 0.00000
train epoch 809 avg loss: 0.22997 (A-MSE: 0.20351) avg lploss: 0.00000
train epoch 810 avg loss: 0.22569 (A-MSE: 0.19917) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.50393 (A-MSE: 0.43175) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.55436 (A-MSE: 0.49379) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 9 out of 50
train epoch 811 avg loss: 0.25570 (A-MSE: 0.22149) avg lploss: 0.00000
train epoch 812 avg loss: 0.27069 (A-MSE: 0.23904) avg lploss: 0.00000
train epoch 813 avg loss: 0.23941 (A-MSE: 0.21038) avg lploss: 0.00000
train epoch 814 avg loss: 0.24354 (A-MSE: 0.21356) avg lploss: 0.00000
train epoch 815 avg loss: 0.26138 (A-MSE: 0.22861) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.54278 (A-MSE: 0.45491) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.56583 (A-MSE: 0.49900) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 10 out of 50
train epoch 816 avg loss: 0.23578 (A-MSE: 0.20760) avg lploss: 0.00000
train epoch 817 avg loss: 0.23796 (A-MSE: 0.20781) avg lploss: 0.00000
train epoch 818 avg loss: 0.22128 (A-MSE: 0.19494) avg lploss: 0.00000
train epoch 819 avg loss: 0.20909 (A-MSE: 0.18653) avg lploss: 0.00000
train epoch 820 avg loss: 0.21346 (A-MSE: 0.18862) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.53663 (A-MSE: 0.45900) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.53072 (A-MSE: 0.47533) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 11 out of 50
train epoch 821 avg loss: 0.19651 (A-MSE: 0.17400) avg lploss: 0.00000
train epoch 822 avg loss: 0.23103 (A-MSE: 0.20194) avg lploss: 0.00000
train epoch 823 avg loss: 0.26345 (A-MSE: 0.23252) avg lploss: 0.00000
train epoch 824 avg loss: 0.20927 (A-MSE: 0.18430) avg lploss: 0.00000
train epoch 825 avg loss: 0.23373 (A-MSE: 0.20775) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.47818 (A-MSE: 0.43033) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.56806 (A-MSE: 0.51863) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 12 out of 50
train epoch 826 avg loss: 0.24781 (A-MSE: 0.22057) avg lploss: 0.00000
train epoch 827 avg loss: 0.24520 (A-MSE: 0.21600) avg lploss: 0.00000
train epoch 828 avg loss: 0.22988 (A-MSE: 0.20067) avg lploss: 0.00000
train epoch 829 avg loss: 0.24080 (A-MSE: 0.21328) avg lploss: 0.00000
train epoch 830 avg loss: 0.21348 (A-MSE: 0.18826) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.60976 (A-MSE: 0.52482) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.63231 (A-MSE: 0.55939) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 13 out of 50
train epoch 831 avg loss: 0.20759 (A-MSE: 0.18419) avg lploss: 0.00000
train epoch 832 avg loss: 0.20919 (A-MSE: 0.18447) avg lploss: 0.00000
train epoch 833 avg loss: 0.29165 (A-MSE: 0.25678) avg lploss: 0.00000
train epoch 834 avg loss: 0.31854 (A-MSE: 0.27981) avg lploss: 0.00000
train epoch 835 avg loss: 0.32675 (A-MSE: 0.28656) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.54605 (A-MSE: 0.47292) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.61239 (A-MSE: 0.54074) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 14 out of 50
train epoch 836 avg loss: 0.23598 (A-MSE: 0.20821) avg lploss: 0.00000
train epoch 837 avg loss: 0.21516 (A-MSE: 0.19109) avg lploss: 0.00000
train epoch 838 avg loss: 0.22003 (A-MSE: 0.19408) avg lploss: 0.00000
train epoch 839 avg loss: 0.25584 (A-MSE: 0.22356) avg lploss: 0.00000
train epoch 840 avg loss: 0.20359 (A-MSE: 0.18016) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.47201 (A-MSE: 0.40368) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.49144 (A-MSE: 0.44262) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 15 out of 50
train epoch 841 avg loss: 0.21774 (A-MSE: 0.19117) avg lploss: 0.00000
train epoch 842 avg loss: 0.23467 (A-MSE: 0.20666) avg lploss: 0.00000
train epoch 843 avg loss: 0.22034 (A-MSE: 0.19312) avg lploss: 0.00000
train epoch 844 avg loss: 0.22223 (A-MSE: 0.19357) avg lploss: 0.00000
train epoch 845 avg loss: 0.24067 (A-MSE: 0.21266) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.56815 (A-MSE: 0.49047) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.62549 (A-MSE: 0.55525) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 16 out of 50
train epoch 846 avg loss: 0.27986 (A-MSE: 0.24679) avg lploss: 0.00000
train epoch 847 avg loss: 0.28286 (A-MSE: 0.24759) avg lploss: 0.00000
train epoch 848 avg loss: 0.22764 (A-MSE: 0.20032) avg lploss: 0.00000
train epoch 849 avg loss: 0.24543 (A-MSE: 0.21605) avg lploss: 0.00000
train epoch 850 avg loss: 0.22900 (A-MSE: 0.20130) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.55380 (A-MSE: 0.47729) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.55591 (A-MSE: 0.49489) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 17 out of 50
train epoch 851 avg loss: 0.22875 (A-MSE: 0.20067) avg lploss: 0.00000
train epoch 852 avg loss: 0.20032 (A-MSE: 0.17607) avg lploss: 0.00000
train epoch 853 avg loss: 0.24463 (A-MSE: 0.21518) avg lploss: 0.00000
train epoch 854 avg loss: 0.29989 (A-MSE: 0.26373) avg lploss: 0.00000
train epoch 855 avg loss: 0.26582 (A-MSE: 0.23190) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.57686 (A-MSE: 0.50206) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.60894 (A-MSE: 0.53399) avg lploss: 0.00000
*** Best Val Loss: 0.46733 	 Best Test Loss: 0.53351 	 Best epoch 765
EarlyStopping counter: 18 out of 50
train epoch 856 avg loss: 0.24068 (A-MSE: 0.21249) avg lploss: 0.00000
train epoch 857 avg loss: 0.22164 (A-MSE: 0.19292) avg lploss: 0.00000
train epoch 858 avg loss: 0.21949 (A-MSE: 0.19299) avg lploss: 0.00000
train epoch 859 avg loss: 0.24244 (A-MSE: 0.21429) avg lploss: 0.00000
train epoch 860 avg loss: 0.24590 (A-MSE: 0.21525) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.44384 (A-MSE: 0.38127) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.48906 (A-MSE: 0.43735) avg lploss: 0.00000
*** Best Val Loss: 0.44384 	 Best Test Loss: 0.48906 	 Best epoch 860
Validation loss decreased (0.467333 --> 0.443841).  Saving model ...
train epoch 861 avg loss: 0.21054 (A-MSE: 0.18470) avg lploss: 0.00000
train epoch 862 avg loss: 0.24343 (A-MSE: 0.21487) avg lploss: 0.00000
train epoch 863 avg loss: 0.27886 (A-MSE: 0.24197) avg lploss: 0.00000
train epoch 864 avg loss: 0.23360 (A-MSE: 0.20558) avg lploss: 0.00000
train epoch 865 avg loss: 0.23945 (A-MSE: 0.21264) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.43997 (A-MSE: 0.37851) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.50733 (A-MSE: 0.45200) avg lploss: 0.00000
*** Best Val Loss: 0.43997 	 Best Test Loss: 0.50733 	 Best epoch 865
Validation loss decreased (0.443841 --> 0.439968).  Saving model ...
train epoch 866 avg loss: 0.23663 (A-MSE: 0.20877) avg lploss: 0.00000
train epoch 867 avg loss: 0.27939 (A-MSE: 0.24857) avg lploss: 0.00000
train epoch 868 avg loss: 0.26961 (A-MSE: 0.23453) avg lploss: 0.00000
train epoch 869 avg loss: 0.25895 (A-MSE: 0.22772) avg lploss: 0.00000
train epoch 870 avg loss: 0.27114 (A-MSE: 0.23691) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.72762 (A-MSE: 0.63008) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.75415 (A-MSE: 0.66770) avg lploss: 0.00000
*** Best Val Loss: 0.43997 	 Best Test Loss: 0.50733 	 Best epoch 865
EarlyStopping counter: 1 out of 50
train epoch 871 avg loss: 0.26915 (A-MSE: 0.23717) avg lploss: 0.00000
train epoch 872 avg loss: 0.20832 (A-MSE: 0.18281) avg lploss: 0.00000
train epoch 873 avg loss: 0.19977 (A-MSE: 0.17716) avg lploss: 0.00000
train epoch 874 avg loss: 0.21142 (A-MSE: 0.18486) avg lploss: 0.00000
train epoch 875 avg loss: 0.24031 (A-MSE: 0.21094) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.41029 (A-MSE: 0.35845) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.47497 (A-MSE: 0.42716) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
Validation loss decreased (0.439968 --> 0.410293).  Saving model ...
train epoch 876 avg loss: 0.23818 (A-MSE: 0.21009) avg lploss: 0.00000
train epoch 877 avg loss: 0.23415 (A-MSE: 0.20709) avg lploss: 0.00000
train epoch 878 avg loss: 0.25873 (A-MSE: 0.22647) avg lploss: 0.00000
train epoch 879 avg loss: 0.27420 (A-MSE: 0.24059) avg lploss: 0.00000
train epoch 880 avg loss: 0.26017 (A-MSE: 0.22840) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.63944 (A-MSE: 0.53913) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.65955 (A-MSE: 0.57786) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 1 out of 50
train epoch 881 avg loss: 0.23152 (A-MSE: 0.20079) avg lploss: 0.00000
train epoch 882 avg loss: 0.21312 (A-MSE: 0.18863) avg lploss: 0.00000
train epoch 883 avg loss: 0.24057 (A-MSE: 0.21202) avg lploss: 0.00000
train epoch 884 avg loss: 0.19162 (A-MSE: 0.16913) avg lploss: 0.00000
train epoch 885 avg loss: 0.21824 (A-MSE: 0.19178) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.45128 (A-MSE: 0.38637) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.49039 (A-MSE: 0.43738) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 2 out of 50
train epoch 886 avg loss: 0.22999 (A-MSE: 0.20204) avg lploss: 0.00000
train epoch 887 avg loss: 0.25444 (A-MSE: 0.22361) avg lploss: 0.00000
train epoch 888 avg loss: 0.21752 (A-MSE: 0.19136) avg lploss: 0.00000
train epoch 889 avg loss: 0.21525 (A-MSE: 0.19096) avg lploss: 0.00000
train epoch 890 avg loss: 0.21280 (A-MSE: 0.18654) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.60381 (A-MSE: 0.52349) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.61247 (A-MSE: 0.53985) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 3 out of 50
train epoch 891 avg loss: 0.22146 (A-MSE: 0.19436) avg lploss: 0.00000
train epoch 892 avg loss: 0.20100 (A-MSE: 0.17939) avg lploss: 0.00000
train epoch 893 avg loss: 0.20819 (A-MSE: 0.18340) avg lploss: 0.00000
train epoch 894 avg loss: 0.21880 (A-MSE: 0.19287) avg lploss: 0.00000
train epoch 895 avg loss: 0.21823 (A-MSE: 0.19145) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.53990 (A-MSE: 0.46949) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.56013 (A-MSE: 0.50274) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 4 out of 50
train epoch 896 avg loss: 0.20259 (A-MSE: 0.17891) avg lploss: 0.00000
train epoch 897 avg loss: 0.21251 (A-MSE: 0.18644) avg lploss: 0.00000
train epoch 898 avg loss: 0.21397 (A-MSE: 0.18795) avg lploss: 0.00000
train epoch 899 avg loss: 0.21170 (A-MSE: 0.18621) avg lploss: 0.00000
train epoch 900 avg loss: 0.26475 (A-MSE: 0.23245) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.59447 (A-MSE: 0.49309) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.57845 (A-MSE: 0.50391) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 5 out of 50
train epoch 901 avg loss: 0.27640 (A-MSE: 0.23996) avg lploss: 0.00000
train epoch 902 avg loss: 0.25205 (A-MSE: 0.22586) avg lploss: 0.00000
train epoch 903 avg loss: 0.21209 (A-MSE: 0.18832) avg lploss: 0.00000
train epoch 904 avg loss: 0.18199 (A-MSE: 0.15904) avg lploss: 0.00000
train epoch 905 avg loss: 0.18367 (A-MSE: 0.16185) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.50004 (A-MSE: 0.42255) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.49968 (A-MSE: 0.44256) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 6 out of 50
train epoch 906 avg loss: 0.18075 (A-MSE: 0.15907) avg lploss: 0.00000
train epoch 907 avg loss: 0.20035 (A-MSE: 0.17615) avg lploss: 0.00000
train epoch 908 avg loss: 0.20904 (A-MSE: 0.18508) avg lploss: 0.00000
train epoch 909 avg loss: 0.19988 (A-MSE: 0.17561) avg lploss: 0.00000
train epoch 910 avg loss: 0.23710 (A-MSE: 0.20857) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.57171 (A-MSE: 0.47735) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.55972 (A-MSE: 0.48999) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 7 out of 50
train epoch 911 avg loss: 0.19492 (A-MSE: 0.17220) avg lploss: 0.00000
train epoch 912 avg loss: 0.19353 (A-MSE: 0.17055) avg lploss: 0.00000
train epoch 913 avg loss: 0.19147 (A-MSE: 0.16793) avg lploss: 0.00000
train epoch 914 avg loss: 0.19623 (A-MSE: 0.17437) avg lploss: 0.00000
train epoch 915 avg loss: 0.22209 (A-MSE: 0.19318) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.45221 (A-MSE: 0.38977) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.51655 (A-MSE: 0.45248) avg lploss: 0.00000
*** Best Val Loss: 0.41029 	 Best Test Loss: 0.47497 	 Best epoch 875
EarlyStopping counter: 8 out of 50
train epoch 916 avg loss: 0.25416 (A-MSE: 0.22304) avg lploss: 0.00000
train epoch 917 avg loss: 0.31514 (A-MSE: 0.27534) avg lploss: 0.00000
train epoch 918 avg loss: 0.25425 (A-MSE: 0.22590) avg lploss: 0.00000
train epoch 919 avg loss: 0.21390 (A-MSE: 0.18944) avg lploss: 0.00000
train epoch 920 avg loss: 0.20088 (A-MSE: 0.17671) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.40376 (A-MSE: 0.35337) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.44851 (A-MSE: 0.40651) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
Validation loss decreased (0.410293 --> 0.403757).  Saving model ...
train epoch 921 avg loss: 0.19349 (A-MSE: 0.17079) avg lploss: 0.00000
train epoch 922 avg loss: 0.18195 (A-MSE: 0.15966) avg lploss: 0.00000
train epoch 923 avg loss: 0.17674 (A-MSE: 0.15507) avg lploss: 0.00000
train epoch 924 avg loss: 0.17966 (A-MSE: 0.15946) avg lploss: 0.00000
train epoch 925 avg loss: 0.19383 (A-MSE: 0.17127) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.66978 (A-MSE: 0.56748) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.61864 (A-MSE: 0.54593) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 1 out of 50
train epoch 926 avg loss: 0.20759 (A-MSE: 0.18195) avg lploss: 0.00000
train epoch 927 avg loss: 0.17351 (A-MSE: 0.15470) avg lploss: 0.00000
train epoch 928 avg loss: 0.19020 (A-MSE: 0.16746) avg lploss: 0.00000
train epoch 929 avg loss: 0.18410 (A-MSE: 0.16184) avg lploss: 0.00000
train epoch 930 avg loss: 0.20308 (A-MSE: 0.17706) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.64071 (A-MSE: 0.54364) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.64075 (A-MSE: 0.56344) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 2 out of 50
train epoch 931 avg loss: 0.19419 (A-MSE: 0.17112) avg lploss: 0.00000
train epoch 932 avg loss: 0.19806 (A-MSE: 0.17425) avg lploss: 0.00000
train epoch 933 avg loss: 0.20776 (A-MSE: 0.18232) avg lploss: 0.00000
train epoch 934 avg loss: 0.20952 (A-MSE: 0.18651) avg lploss: 0.00000
train epoch 935 avg loss: 0.21972 (A-MSE: 0.19373) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.61407 (A-MSE: 0.51851) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.58400 (A-MSE: 0.51907) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 3 out of 50
train epoch 936 avg loss: 0.25112 (A-MSE: 0.21846) avg lploss: 0.00000
train epoch 937 avg loss: 0.22365 (A-MSE: 0.19599) avg lploss: 0.00000
train epoch 938 avg loss: 0.22983 (A-MSE: 0.20253) avg lploss: 0.00000
train epoch 939 avg loss: 0.21565 (A-MSE: 0.19009) avg lploss: 0.00000
train epoch 940 avg loss: 0.17020 (A-MSE: 0.15064) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.44802 (A-MSE: 0.37726) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.45234 (A-MSE: 0.39908) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 4 out of 50
train epoch 941 avg loss: 0.18837 (A-MSE: 0.16624) avg lploss: 0.00000
train epoch 942 avg loss: 0.21338 (A-MSE: 0.18638) avg lploss: 0.00000
train epoch 943 avg loss: 0.22755 (A-MSE: 0.20107) avg lploss: 0.00000
train epoch 944 avg loss: 0.20261 (A-MSE: 0.17825) avg lploss: 0.00000
train epoch 945 avg loss: 0.18014 (A-MSE: 0.15742) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.49759 (A-MSE: 0.44010) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.59746 (A-MSE: 0.53347) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 5 out of 50
train epoch 946 avg loss: 0.19724 (A-MSE: 0.17583) avg lploss: 0.00000
train epoch 947 avg loss: 0.21738 (A-MSE: 0.19012) avg lploss: 0.00000
train epoch 948 avg loss: 0.21198 (A-MSE: 0.18920) avg lploss: 0.00000
train epoch 949 avg loss: 0.22760 (A-MSE: 0.19983) avg lploss: 0.00000
train epoch 950 avg loss: 0.18475 (A-MSE: 0.16293) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.44457 (A-MSE: 0.37697) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.47470 (A-MSE: 0.41515) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 6 out of 50
train epoch 951 avg loss: 0.20459 (A-MSE: 0.18072) avg lploss: 0.00000
train epoch 952 avg loss: 0.21630 (A-MSE: 0.18909) avg lploss: 0.00000
train epoch 953 avg loss: 0.18486 (A-MSE: 0.16364) avg lploss: 0.00000
train epoch 954 avg loss: 0.19337 (A-MSE: 0.17019) avg lploss: 0.00000
train epoch 955 avg loss: 0.19736 (A-MSE: 0.17394) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.46793 (A-MSE: 0.40371) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.50339 (A-MSE: 0.44637) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 7 out of 50
train epoch 956 avg loss: 0.16736 (A-MSE: 0.14748) avg lploss: 0.00000
train epoch 957 avg loss: 0.23708 (A-MSE: 0.20759) avg lploss: 0.00000
train epoch 958 avg loss: 0.21769 (A-MSE: 0.19099) avg lploss: 0.00000
train epoch 959 avg loss: 0.19312 (A-MSE: 0.17125) avg lploss: 0.00000
train epoch 960 avg loss: 0.20594 (A-MSE: 0.18076) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.46690 (A-MSE: 0.39609) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.49292 (A-MSE: 0.43766) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 8 out of 50
train epoch 961 avg loss: 0.19236 (A-MSE: 0.16909) avg lploss: 0.00000
train epoch 962 avg loss: 0.20287 (A-MSE: 0.17729) avg lploss: 0.00000
train epoch 963 avg loss: 0.20357 (A-MSE: 0.17929) avg lploss: 0.00000
train epoch 964 avg loss: 0.17933 (A-MSE: 0.15717) avg lploss: 0.00000
train epoch 965 avg loss: 0.18387 (A-MSE: 0.16114) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.57950 (A-MSE: 0.49876) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.54402 (A-MSE: 0.48301) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 9 out of 50
train epoch 966 avg loss: 0.20621 (A-MSE: 0.18246) avg lploss: 0.00000
train epoch 967 avg loss: 0.19145 (A-MSE: 0.16793) avg lploss: 0.00000
train epoch 968 avg loss: 0.17680 (A-MSE: 0.15645) avg lploss: 0.00000
train epoch 969 avg loss: 0.19898 (A-MSE: 0.17286) avg lploss: 0.00000
train epoch 970 avg loss: 0.17774 (A-MSE: 0.15823) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.41735 (A-MSE: 0.35478) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.43234 (A-MSE: 0.38380) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 10 out of 50
train epoch 971 avg loss: 0.17639 (A-MSE: 0.15565) avg lploss: 0.00000
train epoch 972 avg loss: 0.20360 (A-MSE: 0.17954) avg lploss: 0.00000
train epoch 973 avg loss: 0.22788 (A-MSE: 0.20080) avg lploss: 0.00000
train epoch 974 avg loss: 0.20409 (A-MSE: 0.17949) avg lploss: 0.00000
train epoch 975 avg loss: 0.17742 (A-MSE: 0.15631) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.44118 (A-MSE: 0.37819) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.45830 (A-MSE: 0.40812) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 11 out of 50
train epoch 976 avg loss: 0.17056 (A-MSE: 0.15062) avg lploss: 0.00000
train epoch 977 avg loss: 0.17954 (A-MSE: 0.15897) avg lploss: 0.00000
train epoch 978 avg loss: 0.17818 (A-MSE: 0.15705) avg lploss: 0.00000
train epoch 979 avg loss: 0.20639 (A-MSE: 0.18298) avg lploss: 0.00000
train epoch 980 avg loss: 0.23516 (A-MSE: 0.20685) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.46184 (A-MSE: 0.39655) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.52324 (A-MSE: 0.46025) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 12 out of 50
train epoch 981 avg loss: 0.23468 (A-MSE: 0.20610) avg lploss: 0.00000
train epoch 982 avg loss: 0.19155 (A-MSE: 0.16726) avg lploss: 0.00000
train epoch 983 avg loss: 0.20546 (A-MSE: 0.18227) avg lploss: 0.00000
train epoch 984 avg loss: 0.22005 (A-MSE: 0.19336) avg lploss: 0.00000
train epoch 985 avg loss: 0.22819 (A-MSE: 0.20110) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.45482 (A-MSE: 0.38400) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.49881 (A-MSE: 0.43693) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 13 out of 50
train epoch 986 avg loss: 0.18438 (A-MSE: 0.16339) avg lploss: 0.00000
train epoch 987 avg loss: 0.19379 (A-MSE: 0.16943) avg lploss: 0.00000
train epoch 988 avg loss: 0.17281 (A-MSE: 0.15179) avg lploss: 0.00000
train epoch 989 avg loss: 0.19417 (A-MSE: 0.17357) avg lploss: 0.00000
train epoch 990 avg loss: 0.20014 (A-MSE: 0.17302) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.50620 (A-MSE: 0.43783) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.52422 (A-MSE: 0.47022) avg lploss: 0.00000
*** Best Val Loss: 0.40376 	 Best Test Loss: 0.44851 	 Best epoch 920
EarlyStopping counter: 14 out of 50
train epoch 991 avg loss: 0.18570 (A-MSE: 0.16285) avg lploss: 0.00000
train epoch 992 avg loss: 0.16393 (A-MSE: 0.14511) avg lploss: 0.00000
train epoch 993 avg loss: 0.15083 (A-MSE: 0.13413) avg lploss: 0.00000
train epoch 994 avg loss: 0.16963 (A-MSE: 0.14876) avg lploss: 0.00000
train epoch 995 avg loss: 0.17575 (A-MSE: 0.15374) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.37621 (A-MSE: 0.32390) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.44902 (A-MSE: 0.40137) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
Validation loss decreased (0.403757 --> 0.376210).  Saving model ...
train epoch 996 avg loss: 0.19120 (A-MSE: 0.16889) avg lploss: 0.00000
train epoch 997 avg loss: 0.17331 (A-MSE: 0.15393) avg lploss: 0.00000
train epoch 998 avg loss: 0.15725 (A-MSE: 0.13838) avg lploss: 0.00000
train epoch 999 avg loss: 0.16972 (A-MSE: 0.15061) avg lploss: 0.00000
train epoch 1000 avg loss: 0.19048 (A-MSE: 0.16603) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.52339 (A-MSE: 0.45020) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.53665 (A-MSE: 0.47029) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 1 out of 50
train epoch 1001 avg loss: 0.18825 (A-MSE: 0.16514) avg lploss: 0.00000
train epoch 1002 avg loss: 0.18138 (A-MSE: 0.15963) avg lploss: 0.00000
train epoch 1003 avg loss: 0.17527 (A-MSE: 0.15538) avg lploss: 0.00000
train epoch 1004 avg loss: 0.17350 (A-MSE: 0.15325) avg lploss: 0.00000
train epoch 1005 avg loss: 0.19002 (A-MSE: 0.16750) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.48971 (A-MSE: 0.41656) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.51659 (A-MSE: 0.45114) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 2 out of 50
train epoch 1006 avg loss: 0.17517 (A-MSE: 0.15412) avg lploss: 0.00000
train epoch 1007 avg loss: 0.15455 (A-MSE: 0.13593) avg lploss: 0.00000
train epoch 1008 avg loss: 0.16773 (A-MSE: 0.14811) avg lploss: 0.00000
train epoch 1009 avg loss: 0.16457 (A-MSE: 0.14515) avg lploss: 0.00000
train epoch 1010 avg loss: 0.17153 (A-MSE: 0.15104) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.41468 (A-MSE: 0.35617) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.47992 (A-MSE: 0.42669) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 3 out of 50
train epoch 1011 avg loss: 0.15631 (A-MSE: 0.13728) avg lploss: 0.00000
train epoch 1012 avg loss: 0.16872 (A-MSE: 0.14969) avg lploss: 0.00000
train epoch 1013 avg loss: 0.20311 (A-MSE: 0.17911) avg lploss: 0.00000
train epoch 1014 avg loss: 0.20825 (A-MSE: 0.18351) avg lploss: 0.00000
train epoch 1015 avg loss: 0.18676 (A-MSE: 0.16513) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.42022 (A-MSE: 0.37172) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.52545 (A-MSE: 0.46911) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 4 out of 50
train epoch 1016 avg loss: 0.18250 (A-MSE: 0.16061) avg lploss: 0.00000
train epoch 1017 avg loss: 0.20024 (A-MSE: 0.17496) avg lploss: 0.00000
train epoch 1018 avg loss: 0.18900 (A-MSE: 0.16669) avg lploss: 0.00000
train epoch 1019 avg loss: 0.15605 (A-MSE: 0.13862) avg lploss: 0.00000
train epoch 1020 avg loss: 0.16371 (A-MSE: 0.14443) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.39472 (A-MSE: 0.33760) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.41200 (A-MSE: 0.36771) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 5 out of 50
train epoch 1021 avg loss: 0.19798 (A-MSE: 0.17548) avg lploss: 0.00000
train epoch 1022 avg loss: 0.16058 (A-MSE: 0.14118) avg lploss: 0.00000
train epoch 1023 avg loss: 0.16842 (A-MSE: 0.14892) avg lploss: 0.00000
train epoch 1024 avg loss: 0.17477 (A-MSE: 0.15421) avg lploss: 0.00000
train epoch 1025 avg loss: 0.17789 (A-MSE: 0.15688) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.51869 (A-MSE: 0.44626) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.51917 (A-MSE: 0.46441) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 6 out of 50
train epoch 1026 avg loss: 0.16727 (A-MSE: 0.14779) avg lploss: 0.00000
train epoch 1027 avg loss: 0.15738 (A-MSE: 0.13826) avg lploss: 0.00000
train epoch 1028 avg loss: 0.16955 (A-MSE: 0.15009) avg lploss: 0.00000
train epoch 1029 avg loss: 0.18208 (A-MSE: 0.16136) avg lploss: 0.00000
train epoch 1030 avg loss: 0.17229 (A-MSE: 0.15136) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.53587 (A-MSE: 0.45911) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.51622 (A-MSE: 0.45732) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 7 out of 50
train epoch 1031 avg loss: 0.18853 (A-MSE: 0.16747) avg lploss: 0.00000
train epoch 1032 avg loss: 0.18766 (A-MSE: 0.16401) avg lploss: 0.00000
train epoch 1033 avg loss: 0.16748 (A-MSE: 0.14839) avg lploss: 0.00000
train epoch 1034 avg loss: 0.16524 (A-MSE: 0.14488) avg lploss: 0.00000
train epoch 1035 avg loss: 0.18310 (A-MSE: 0.16150) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.41257 (A-MSE: 0.35432) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.43732 (A-MSE: 0.39145) avg lploss: 0.00000
*** Best Val Loss: 0.37621 	 Best Test Loss: 0.44902 	 Best epoch 995
EarlyStopping counter: 8 out of 50
train epoch 1036 avg loss: 0.16270 (A-MSE: 0.14400) avg lploss: 0.00000
train epoch 1037 avg loss: 0.17648 (A-MSE: 0.15567) avg lploss: 0.00000
train epoch 1038 avg loss: 0.16766 (A-MSE: 0.14689) avg lploss: 0.00000
train epoch 1039 avg loss: 0.15224 (A-MSE: 0.13495) avg lploss: 0.00000
train epoch 1040 avg loss: 0.17716 (A-MSE: 0.15659) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.37217 (A-MSE: 0.32054) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.41504 (A-MSE: 0.36929) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
Validation loss decreased (0.376210 --> 0.372166).  Saving model ...
train epoch 1041 avg loss: 0.17154 (A-MSE: 0.15131) avg lploss: 0.00000
train epoch 1042 avg loss: 0.16243 (A-MSE: 0.14232) avg lploss: 0.00000
train epoch 1043 avg loss: 0.15938 (A-MSE: 0.14087) avg lploss: 0.00000
train epoch 1044 avg loss: 0.19547 (A-MSE: 0.17240) avg lploss: 0.00000
train epoch 1045 avg loss: 0.17015 (A-MSE: 0.15006) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.47765 (A-MSE: 0.40861) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.49714 (A-MSE: 0.43886) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 1 out of 50
train epoch 1046 avg loss: 0.18415 (A-MSE: 0.15943) avg lploss: 0.00000
train epoch 1047 avg loss: 0.17086 (A-MSE: 0.15064) avg lploss: 0.00000
train epoch 1048 avg loss: 0.17624 (A-MSE: 0.15504) avg lploss: 0.00000
train epoch 1049 avg loss: 0.16815 (A-MSE: 0.14884) avg lploss: 0.00000
train epoch 1050 avg loss: 0.16523 (A-MSE: 0.14576) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.41118 (A-MSE: 0.34937) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.43086 (A-MSE: 0.38159) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 2 out of 50
train epoch 1051 avg loss: 0.16761 (A-MSE: 0.14799) avg lploss: 0.00000
train epoch 1052 avg loss: 0.17087 (A-MSE: 0.14963) avg lploss: 0.00000
train epoch 1053 avg loss: 0.14686 (A-MSE: 0.12946) avg lploss: 0.00000
train epoch 1054 avg loss: 0.15943 (A-MSE: 0.14064) avg lploss: 0.00000
train epoch 1055 avg loss: 0.16671 (A-MSE: 0.14716) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.47386 (A-MSE: 0.40492) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.45822 (A-MSE: 0.40631) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 3 out of 50
train epoch 1056 avg loss: 0.15236 (A-MSE: 0.13399) avg lploss: 0.00000
train epoch 1057 avg loss: 0.16875 (A-MSE: 0.14699) avg lploss: 0.00000
train epoch 1058 avg loss: 0.15603 (A-MSE: 0.13729) avg lploss: 0.00000
train epoch 1059 avg loss: 0.15645 (A-MSE: 0.13875) avg lploss: 0.00000
train epoch 1060 avg loss: 0.18375 (A-MSE: 0.16220) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.41544 (A-MSE: 0.36379) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.46141 (A-MSE: 0.40824) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 4 out of 50
train epoch 1061 avg loss: 0.21166 (A-MSE: 0.18813) avg lploss: 0.00000
train epoch 1062 avg loss: 0.16005 (A-MSE: 0.14078) avg lploss: 0.00000
train epoch 1063 avg loss: 0.17344 (A-MSE: 0.15256) avg lploss: 0.00000
train epoch 1064 avg loss: 0.16858 (A-MSE: 0.14811) avg lploss: 0.00000
train epoch 1065 avg loss: 0.18295 (A-MSE: 0.16243) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.42613 (A-MSE: 0.36502) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.46780 (A-MSE: 0.41243) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 5 out of 50
train epoch 1066 avg loss: 0.16093 (A-MSE: 0.14117) avg lploss: 0.00000
train epoch 1067 avg loss: 0.16296 (A-MSE: 0.14399) avg lploss: 0.00000
train epoch 1068 avg loss: 0.19276 (A-MSE: 0.16906) avg lploss: 0.00000
train epoch 1069 avg loss: 0.15697 (A-MSE: 0.13934) avg lploss: 0.00000
train epoch 1070 avg loss: 0.14972 (A-MSE: 0.13237) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.40573 (A-MSE: 0.35074) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.45624 (A-MSE: 0.40547) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 6 out of 50
train epoch 1071 avg loss: 0.14950 (A-MSE: 0.13276) avg lploss: 0.00000
train epoch 1072 avg loss: 0.16910 (A-MSE: 0.14869) avg lploss: 0.00000
train epoch 1073 avg loss: 0.18473 (A-MSE: 0.16306) avg lploss: 0.00000
train epoch 1074 avg loss: 0.15971 (A-MSE: 0.14111) avg lploss: 0.00000
train epoch 1075 avg loss: 0.14795 (A-MSE: 0.13127) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.40945 (A-MSE: 0.35106) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.43524 (A-MSE: 0.38726) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 7 out of 50
train epoch 1076 avg loss: 0.14273 (A-MSE: 0.12568) avg lploss: 0.00000
train epoch 1077 avg loss: 0.13480 (A-MSE: 0.11876) avg lploss: 0.00000
train epoch 1078 avg loss: 0.15888 (A-MSE: 0.13821) avg lploss: 0.00000
train epoch 1079 avg loss: 0.17281 (A-MSE: 0.15278) avg lploss: 0.00000
train epoch 1080 avg loss: 0.15066 (A-MSE: 0.13307) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.41397 (A-MSE: 0.35821) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.44401 (A-MSE: 0.39658) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 8 out of 50
train epoch 1081 avg loss: 0.16297 (A-MSE: 0.14360) avg lploss: 0.00000
train epoch 1082 avg loss: 0.15818 (A-MSE: 0.14050) avg lploss: 0.00000
train epoch 1083 avg loss: 0.15774 (A-MSE: 0.13865) avg lploss: 0.00000
train epoch 1084 avg loss: 0.16869 (A-MSE: 0.14872) avg lploss: 0.00000
train epoch 1085 avg loss: 0.16850 (A-MSE: 0.14828) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.40537 (A-MSE: 0.34979) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.42235 (A-MSE: 0.37617) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 9 out of 50
train epoch 1086 avg loss: 0.15905 (A-MSE: 0.14163) avg lploss: 0.00000
train epoch 1087 avg loss: 0.15869 (A-MSE: 0.13938) avg lploss: 0.00000
train epoch 1088 avg loss: 0.13992 (A-MSE: 0.12377) avg lploss: 0.00000
train epoch 1089 avg loss: 0.15797 (A-MSE: 0.14031) avg lploss: 0.00000
train epoch 1090 avg loss: 0.16379 (A-MSE: 0.14404) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.48102 (A-MSE: 0.41587) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.49266 (A-MSE: 0.43640) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 10 out of 50
train epoch 1091 avg loss: 0.13658 (A-MSE: 0.12118) avg lploss: 0.00000
train epoch 1092 avg loss: 0.14351 (A-MSE: 0.12569) avg lploss: 0.00000
train epoch 1093 avg loss: 0.15850 (A-MSE: 0.13924) avg lploss: 0.00000
train epoch 1094 avg loss: 0.14390 (A-MSE: 0.12610) avg lploss: 0.00000
train epoch 1095 avg loss: 0.13109 (A-MSE: 0.11573) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.38240 (A-MSE: 0.32594) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.41539 (A-MSE: 0.36798) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 11 out of 50
train epoch 1096 avg loss: 0.14685 (A-MSE: 0.12801) avg lploss: 0.00000
train epoch 1097 avg loss: 0.15731 (A-MSE: 0.14027) avg lploss: 0.00000
train epoch 1098 avg loss: 0.16679 (A-MSE: 0.14843) avg lploss: 0.00000
train epoch 1099 avg loss: 0.18478 (A-MSE: 0.16117) avg lploss: 0.00000
train epoch 1100 avg loss: 0.17283 (A-MSE: 0.15318) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.39246 (A-MSE: 0.34131) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.42202 (A-MSE: 0.37507) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 12 out of 50
train epoch 1101 avg loss: 0.15580 (A-MSE: 0.13883) avg lploss: 0.00000
train epoch 1102 avg loss: 0.13624 (A-MSE: 0.12091) avg lploss: 0.00000
train epoch 1103 avg loss: 0.16990 (A-MSE: 0.14952) avg lploss: 0.00000
train epoch 1104 avg loss: 0.16524 (A-MSE: 0.14651) avg lploss: 0.00000
train epoch 1105 avg loss: 0.14713 (A-MSE: 0.12953) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.38082 (A-MSE: 0.33423) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.41777 (A-MSE: 0.37601) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 13 out of 50
train epoch 1106 avg loss: 0.14503 (A-MSE: 0.12806) avg lploss: 0.00000
train epoch 1107 avg loss: 0.17711 (A-MSE: 0.15634) avg lploss: 0.00000
train epoch 1108 avg loss: 0.18443 (A-MSE: 0.16422) avg lploss: 0.00000
train epoch 1109 avg loss: 0.16272 (A-MSE: 0.14329) avg lploss: 0.00000
train epoch 1110 avg loss: 0.18236 (A-MSE: 0.15981) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.43274 (A-MSE: 0.37374) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.44214 (A-MSE: 0.39782) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 14 out of 50
train epoch 1111 avg loss: 0.15262 (A-MSE: 0.13359) avg lploss: 0.00000
train epoch 1112 avg loss: 0.15373 (A-MSE: 0.13694) avg lploss: 0.00000
train epoch 1113 avg loss: 0.17797 (A-MSE: 0.15708) avg lploss: 0.00000
train epoch 1114 avg loss: 0.18254 (A-MSE: 0.15995) avg lploss: 0.00000
train epoch 1115 avg loss: 0.16586 (A-MSE: 0.14851) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.38670 (A-MSE: 0.32996) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.43908 (A-MSE: 0.38765) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 15 out of 50
train epoch 1116 avg loss: 0.15267 (A-MSE: 0.13616) avg lploss: 0.00000
train epoch 1117 avg loss: 0.15494 (A-MSE: 0.13653) avg lploss: 0.00000
train epoch 1118 avg loss: 0.14507 (A-MSE: 0.12801) avg lploss: 0.00000
train epoch 1119 avg loss: 0.12974 (A-MSE: 0.11435) avg lploss: 0.00000
train epoch 1120 avg loss: 0.12616 (A-MSE: 0.11105) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.39701 (A-MSE: 0.33979) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.41490 (A-MSE: 0.36636) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 16 out of 50
train epoch 1121 avg loss: 0.15020 (A-MSE: 0.13327) avg lploss: 0.00000
train epoch 1122 avg loss: 0.14244 (A-MSE: 0.12559) avg lploss: 0.00000
train epoch 1123 avg loss: 0.13147 (A-MSE: 0.11603) avg lploss: 0.00000
train epoch 1124 avg loss: 0.13052 (A-MSE: 0.11524) avg lploss: 0.00000
train epoch 1125 avg loss: 0.11798 (A-MSE: 0.10384) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.38711 (A-MSE: 0.33553) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.42066 (A-MSE: 0.37368) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 17 out of 50
train epoch 1126 avg loss: 0.16404 (A-MSE: 0.14477) avg lploss: 0.00000
train epoch 1127 avg loss: 0.14634 (A-MSE: 0.12937) avg lploss: 0.00000
train epoch 1128 avg loss: 0.14000 (A-MSE: 0.12318) avg lploss: 0.00000
train epoch 1129 avg loss: 0.19112 (A-MSE: 0.16714) avg lploss: 0.00000
train epoch 1130 avg loss: 0.16815 (A-MSE: 0.14847) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.40692 (A-MSE: 0.34679) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.43590 (A-MSE: 0.37689) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 18 out of 50
train epoch 1131 avg loss: 0.13621 (A-MSE: 0.11892) avg lploss: 0.00000
train epoch 1132 avg loss: 0.16439 (A-MSE: 0.14601) avg lploss: 0.00000
train epoch 1133 avg loss: 0.19192 (A-MSE: 0.17064) avg lploss: 0.00000
train epoch 1134 avg loss: 0.17755 (A-MSE: 0.15497) avg lploss: 0.00000
train epoch 1135 avg loss: 0.17817 (A-MSE: 0.15789) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.48309 (A-MSE: 0.42456) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.48397 (A-MSE: 0.43428) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 19 out of 50
train epoch 1136 avg loss: 0.15260 (A-MSE: 0.13521) avg lploss: 0.00000
train epoch 1137 avg loss: 0.14089 (A-MSE: 0.12539) avg lploss: 0.00000
train epoch 1138 avg loss: 0.12907 (A-MSE: 0.11368) avg lploss: 0.00000
train epoch 1139 avg loss: 0.13990 (A-MSE: 0.12421) avg lploss: 0.00000
train epoch 1140 avg loss: 0.14369 (A-MSE: 0.12653) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.47395 (A-MSE: 0.40255) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.48349 (A-MSE: 0.42484) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 20 out of 50
train epoch 1141 avg loss: 0.13698 (A-MSE: 0.12206) avg lploss: 0.00000
train epoch 1142 avg loss: 0.12268 (A-MSE: 0.10765) avg lploss: 0.00000
train epoch 1143 avg loss: 0.13376 (A-MSE: 0.11954) avg lploss: 0.00000
train epoch 1144 avg loss: 0.11247 (A-MSE: 0.09884) avg lploss: 0.00000
train epoch 1145 avg loss: 0.14297 (A-MSE: 0.12614) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.42947 (A-MSE: 0.36752) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.43651 (A-MSE: 0.38445) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 21 out of 50
train epoch 1146 avg loss: 0.15636 (A-MSE: 0.13637) avg lploss: 0.00000
train epoch 1147 avg loss: 0.14001 (A-MSE: 0.12301) avg lploss: 0.00000
train epoch 1148 avg loss: 0.14870 (A-MSE: 0.13130) avg lploss: 0.00000
train epoch 1149 avg loss: 0.14370 (A-MSE: 0.12710) avg lploss: 0.00000
train epoch 1150 avg loss: 0.14375 (A-MSE: 0.12685) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.42030 (A-MSE: 0.36654) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.45520 (A-MSE: 0.40107) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 22 out of 50
train epoch 1151 avg loss: 0.17082 (A-MSE: 0.14972) avg lploss: 0.00000
train epoch 1152 avg loss: 0.16469 (A-MSE: 0.14664) avg lploss: 0.00000
train epoch 1153 avg loss: 0.14919 (A-MSE: 0.13125) avg lploss: 0.00000
train epoch 1154 avg loss: 0.13312 (A-MSE: 0.11730) avg lploss: 0.00000
train epoch 1155 avg loss: 0.12179 (A-MSE: 0.10775) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.39370 (A-MSE: 0.34073) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.43656 (A-MSE: 0.38601) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 23 out of 50
train epoch 1156 avg loss: 0.12080 (A-MSE: 0.10620) avg lploss: 0.00000
train epoch 1157 avg loss: 0.11594 (A-MSE: 0.10249) avg lploss: 0.00000
train epoch 1158 avg loss: 0.11423 (A-MSE: 0.10115) avg lploss: 0.00000
train epoch 1159 avg loss: 0.11604 (A-MSE: 0.10256) avg lploss: 0.00000
train epoch 1160 avg loss: 0.12017 (A-MSE: 0.10723) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.46798 (A-MSE: 0.40066) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.44258 (A-MSE: 0.39174) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 24 out of 50
train epoch 1161 avg loss: 0.11965 (A-MSE: 0.10550) avg lploss: 0.00000
train epoch 1162 avg loss: 0.14073 (A-MSE: 0.12438) avg lploss: 0.00000
train epoch 1163 avg loss: 0.14491 (A-MSE: 0.12735) avg lploss: 0.00000
train epoch 1164 avg loss: 0.12378 (A-MSE: 0.10960) avg lploss: 0.00000
train epoch 1165 avg loss: 0.12782 (A-MSE: 0.11228) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.42100 (A-MSE: 0.36115) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.41722 (A-MSE: 0.36815) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 25 out of 50
train epoch 1166 avg loss: 0.11456 (A-MSE: 0.10103) avg lploss: 0.00000
train epoch 1167 avg loss: 0.11591 (A-MSE: 0.10262) avg lploss: 0.00000
train epoch 1168 avg loss: 0.13407 (A-MSE: 0.11868) avg lploss: 0.00000
train epoch 1169 avg loss: 0.15334 (A-MSE: 0.13449) avg lploss: 0.00000
train epoch 1170 avg loss: 0.14906 (A-MSE: 0.13142) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.44526 (A-MSE: 0.38365) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.47102 (A-MSE: 0.41376) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 26 out of 50
train epoch 1171 avg loss: 0.13618 (A-MSE: 0.12017) avg lploss: 0.00000
train epoch 1172 avg loss: 0.14005 (A-MSE: 0.12484) avg lploss: 0.00000
train epoch 1173 avg loss: 0.14412 (A-MSE: 0.12779) avg lploss: 0.00000
train epoch 1174 avg loss: 0.12667 (A-MSE: 0.11193) avg lploss: 0.00000
train epoch 1175 avg loss: 0.11942 (A-MSE: 0.10594) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.42675 (A-MSE: 0.36608) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.43805 (A-MSE: 0.38456) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 27 out of 50
train epoch 1176 avg loss: 0.14275 (A-MSE: 0.12700) avg lploss: 0.00000
train epoch 1177 avg loss: 0.14169 (A-MSE: 0.12518) avg lploss: 0.00000
train epoch 1178 avg loss: 0.16016 (A-MSE: 0.14131) avg lploss: 0.00000
train epoch 1179 avg loss: 0.11958 (A-MSE: 0.10600) avg lploss: 0.00000
train epoch 1180 avg loss: 0.13322 (A-MSE: 0.11667) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.43357 (A-MSE: 0.37360) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.41924 (A-MSE: 0.37050) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 28 out of 50
train epoch 1181 avg loss: 0.11965 (A-MSE: 0.10440) avg lploss: 0.00000
train epoch 1182 avg loss: 0.12518 (A-MSE: 0.11118) avg lploss: 0.00000
train epoch 1183 avg loss: 0.13358 (A-MSE: 0.11805) avg lploss: 0.00000
train epoch 1184 avg loss: 0.14375 (A-MSE: 0.12733) avg lploss: 0.00000
train epoch 1185 avg loss: 0.13072 (A-MSE: 0.11603) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.48453 (A-MSE: 0.41669) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.49137 (A-MSE: 0.44078) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 29 out of 50
train epoch 1186 avg loss: 0.16230 (A-MSE: 0.14399) avg lploss: 0.00000
train epoch 1187 avg loss: 0.16487 (A-MSE: 0.14639) avg lploss: 0.00000
train epoch 1188 avg loss: 0.14160 (A-MSE: 0.12440) avg lploss: 0.00000
train epoch 1189 avg loss: 0.13338 (A-MSE: 0.11765) avg lploss: 0.00000
train epoch 1190 avg loss: 0.13254 (A-MSE: 0.11679) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.45165 (A-MSE: 0.38133) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.42499 (A-MSE: 0.37330) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 30 out of 50
train epoch 1191 avg loss: 0.11943 (A-MSE: 0.10517) avg lploss: 0.00000
train epoch 1192 avg loss: 0.11570 (A-MSE: 0.10206) avg lploss: 0.00000
train epoch 1193 avg loss: 0.11615 (A-MSE: 0.10205) avg lploss: 0.00000
train epoch 1194 avg loss: 0.15358 (A-MSE: 0.13492) avg lploss: 0.00000
train epoch 1195 avg loss: 0.15146 (A-MSE: 0.13311) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.40135 (A-MSE: 0.34541) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.42400 (A-MSE: 0.37813) avg lploss: 0.00000
*** Best Val Loss: 0.37217 	 Best Test Loss: 0.41504 	 Best epoch 1040
EarlyStopping counter: 31 out of 50
train epoch 1196 avg loss: 0.14420 (A-MSE: 0.12782) avg lploss: 0.00000
train epoch 1197 avg loss: 0.13175 (A-MSE: 0.11495) avg lploss: 0.00000
train epoch 1198 avg loss: 0.12360 (A-MSE: 0.10987) avg lploss: 0.00000
train epoch 1199 avg loss: 0.12298 (A-MSE: 0.10911) avg lploss: 0.00000
train epoch 1200 avg loss: 0.11850 (A-MSE: 0.10430) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.36300 (A-MSE: 0.30963) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.39228 (A-MSE: 0.34888) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
Validation loss decreased (0.372166 --> 0.362997).  Saving model ...
train epoch 1201 avg loss: 0.14109 (A-MSE: 0.12547) avg lploss: 0.00000
train epoch 1202 avg loss: 0.14848 (A-MSE: 0.13114) avg lploss: 0.00000
train epoch 1203 avg loss: 0.13521 (A-MSE: 0.11921) avg lploss: 0.00000
train epoch 1204 avg loss: 0.13405 (A-MSE: 0.11857) avg lploss: 0.00000
train epoch 1205 avg loss: 0.14917 (A-MSE: 0.13202) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.39036 (A-MSE: 0.33177) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.38928 (A-MSE: 0.34391) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
EarlyStopping counter: 1 out of 50
train epoch 1206 avg loss: 0.13541 (A-MSE: 0.11921) avg lploss: 0.00000
train epoch 1207 avg loss: 0.12745 (A-MSE: 0.11275) avg lploss: 0.00000
train epoch 1208 avg loss: 0.13096 (A-MSE: 0.11567) avg lploss: 0.00000
train epoch 1209 avg loss: 0.13917 (A-MSE: 0.12322) avg lploss: 0.00000
train epoch 1210 avg loss: 0.13129 (A-MSE: 0.11471) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.38876 (A-MSE: 0.33525) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.41669 (A-MSE: 0.36812) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
EarlyStopping counter: 2 out of 50
train epoch 1211 avg loss: 0.12622 (A-MSE: 0.11149) avg lploss: 0.00000
train epoch 1212 avg loss: 0.10984 (A-MSE: 0.09691) avg lploss: 0.00000
train epoch 1213 avg loss: 0.11561 (A-MSE: 0.10265) avg lploss: 0.00000
train epoch 1214 avg loss: 0.15983 (A-MSE: 0.14137) avg lploss: 0.00000
train epoch 1215 avg loss: 0.14442 (A-MSE: 0.12767) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.41141 (A-MSE: 0.35320) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.41369 (A-MSE: 0.36700) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
EarlyStopping counter: 3 out of 50
train epoch 1216 avg loss: 0.13951 (A-MSE: 0.12224) avg lploss: 0.00000
train epoch 1217 avg loss: 0.14590 (A-MSE: 0.12902) avg lploss: 0.00000
train epoch 1218 avg loss: 0.11463 (A-MSE: 0.10116) avg lploss: 0.00000
train epoch 1219 avg loss: 0.11450 (A-MSE: 0.10173) avg lploss: 0.00000
train epoch 1220 avg loss: 0.14119 (A-MSE: 0.12455) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.42281 (A-MSE: 0.36463) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.42412 (A-MSE: 0.37646) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
EarlyStopping counter: 4 out of 50
train epoch 1221 avg loss: 0.15813 (A-MSE: 0.14035) avg lploss: 0.00000
train epoch 1222 avg loss: 0.16347 (A-MSE: 0.14400) avg lploss: 0.00000
train epoch 1223 avg loss: 0.17118 (A-MSE: 0.15099) avg lploss: 0.00000
train epoch 1224 avg loss: 0.17983 (A-MSE: 0.15720) avg lploss: 0.00000
train epoch 1225 avg loss: 0.14946 (A-MSE: 0.13326) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.40656 (A-MSE: 0.34469) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.45287 (A-MSE: 0.39495) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
EarlyStopping counter: 5 out of 50
train epoch 1226 avg loss: 0.14818 (A-MSE: 0.13155) avg lploss: 0.00000
train epoch 1227 avg loss: 0.14226 (A-MSE: 0.12455) avg lploss: 0.00000
train epoch 1228 avg loss: 0.11944 (A-MSE: 0.10477) avg lploss: 0.00000
train epoch 1229 avg loss: 0.11075 (A-MSE: 0.09828) avg lploss: 0.00000
train epoch 1230 avg loss: 0.12644 (A-MSE: 0.11229) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.41558 (A-MSE: 0.35302) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.45431 (A-MSE: 0.40012) avg lploss: 0.00000
*** Best Val Loss: 0.36300 	 Best Test Loss: 0.39228 	 Best epoch 1200
EarlyStopping counter: 6 out of 50
train epoch 1231 avg loss: 0.13531 (A-MSE: 0.11986) avg lploss: 0.00000
train epoch 1232 avg loss: 0.14835 (A-MSE: 0.13195) avg lploss: 0.00000
train epoch 1233 avg loss: 0.15645 (A-MSE: 0.13916) avg lploss: 0.00000
train epoch 1234 avg loss: 0.13638 (A-MSE: 0.11993) avg lploss: 0.00000
train epoch 1235 avg loss: 0.11421 (A-MSE: 0.10035) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.34144 (A-MSE: 0.29190) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.39144 (A-MSE: 0.34543) avg lploss: 0.00000
*** Best Val Loss: 0.34144 	 Best Test Loss: 0.39144 	 Best epoch 1235
Validation loss decreased (0.362997 --> 0.341441).  Saving model ...
train epoch 1236 avg loss: 0.12270 (A-MSE: 0.10796) avg lploss: 0.00000
train epoch 1237 avg loss: 0.12340 (A-MSE: 0.10914) avg lploss: 0.00000
train epoch 1238 avg loss: 0.12331 (A-MSE: 0.10926) avg lploss: 0.00000
train epoch 1239 avg loss: 0.12727 (A-MSE: 0.11271) avg lploss: 0.00000
train epoch 1240 avg loss: 0.10796 (A-MSE: 0.09580) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.37594 (A-MSE: 0.31823) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.38696 (A-MSE: 0.33846) avg lploss: 0.00000
*** Best Val Loss: 0.34144 	 Best Test Loss: 0.39144 	 Best epoch 1235
EarlyStopping counter: 1 out of 50
train epoch 1241 avg loss: 0.12520 (A-MSE: 0.11127) avg lploss: 0.00000
train epoch 1242 avg loss: 0.13388 (A-MSE: 0.11794) avg lploss: 0.00000
train epoch 1243 avg loss: 0.11241 (A-MSE: 0.09898) avg lploss: 0.00000
train epoch 1244 avg loss: 0.13725 (A-MSE: 0.12142) avg lploss: 0.00000
train epoch 1245 avg loss: 0.15664 (A-MSE: 0.13973) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.42998 (A-MSE: 0.36370) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.46272 (A-MSE: 0.40372) avg lploss: 0.00000
*** Best Val Loss: 0.34144 	 Best Test Loss: 0.39144 	 Best epoch 1235
EarlyStopping counter: 2 out of 50
train epoch 1246 avg loss: 0.17627 (A-MSE: 0.15446) avg lploss: 0.00000
train epoch 1247 avg loss: 0.16366 (A-MSE: 0.14280) avg lploss: 0.00000
train epoch 1248 avg loss: 0.16176 (A-MSE: 0.14287) avg lploss: 0.00000
train epoch 1249 avg loss: 0.15939 (A-MSE: 0.14009) avg lploss: 0.00000
train epoch 1250 avg loss: 0.14245 (A-MSE: 0.12561) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.43566 (A-MSE: 0.37163) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.44470 (A-MSE: 0.39326) avg lploss: 0.00000
*** Best Val Loss: 0.34144 	 Best Test Loss: 0.39144 	 Best epoch 1235
EarlyStopping counter: 3 out of 50
train epoch 1251 avg loss: 0.13647 (A-MSE: 0.12044) avg lploss: 0.00000
train epoch 1252 avg loss: 0.12017 (A-MSE: 0.10591) avg lploss: 0.00000
train epoch 1253 avg loss: 0.11489 (A-MSE: 0.10171) avg lploss: 0.00000
train epoch 1254 avg loss: 0.11900 (A-MSE: 0.10509) avg lploss: 0.00000
train epoch 1255 avg loss: 0.11173 (A-MSE: 0.09741) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.32552 (A-MSE: 0.27823) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.35345 (A-MSE: 0.31421) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
Validation loss decreased (0.341441 --> 0.325522).  Saving model ...
train epoch 1256 avg loss: 0.10688 (A-MSE: 0.09365) avg lploss: 0.00000
train epoch 1257 avg loss: 0.10937 (A-MSE: 0.09721) avg lploss: 0.00000
train epoch 1258 avg loss: 0.10700 (A-MSE: 0.09426) avg lploss: 0.00000
train epoch 1259 avg loss: 0.10718 (A-MSE: 0.09540) avg lploss: 0.00000
train epoch 1260 avg loss: 0.10492 (A-MSE: 0.09308) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.38229 (A-MSE: 0.33019) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.40086 (A-MSE: 0.35590) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 1 out of 50
train epoch 1261 avg loss: 0.10924 (A-MSE: 0.09633) avg lploss: 0.00000
train epoch 1262 avg loss: 0.12382 (A-MSE: 0.10945) avg lploss: 0.00000
train epoch 1263 avg loss: 0.13698 (A-MSE: 0.12108) avg lploss: 0.00000
train epoch 1264 avg loss: 0.14990 (A-MSE: 0.13339) avg lploss: 0.00000
train epoch 1265 avg loss: 0.10726 (A-MSE: 0.09573) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.44909 (A-MSE: 0.37807) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.43453 (A-MSE: 0.37896) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 2 out of 50
train epoch 1266 avg loss: 0.10511 (A-MSE: 0.09263) avg lploss: 0.00000
train epoch 1267 avg loss: 0.09941 (A-MSE: 0.08761) avg lploss: 0.00000
train epoch 1268 avg loss: 0.09776 (A-MSE: 0.08565) avg lploss: 0.00000
train epoch 1269 avg loss: 0.09011 (A-MSE: 0.07966) avg lploss: 0.00000
train epoch 1270 avg loss: 0.09524 (A-MSE: 0.08455) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.38384 (A-MSE: 0.32576) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.39595 (A-MSE: 0.34865) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 3 out of 50
train epoch 1271 avg loss: 0.10454 (A-MSE: 0.09304) avg lploss: 0.00000
train epoch 1272 avg loss: 0.12674 (A-MSE: 0.11188) avg lploss: 0.00000
train epoch 1273 avg loss: 0.11395 (A-MSE: 0.09976) avg lploss: 0.00000
train epoch 1274 avg loss: 0.10905 (A-MSE: 0.09702) avg lploss: 0.00000
train epoch 1275 avg loss: 0.12229 (A-MSE: 0.10831) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.46249 (A-MSE: 0.39836) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.44792 (A-MSE: 0.40019) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 4 out of 50
train epoch 1276 avg loss: 0.11279 (A-MSE: 0.09976) avg lploss: 0.00000
train epoch 1277 avg loss: 0.11223 (A-MSE: 0.09877) avg lploss: 0.00000
train epoch 1278 avg loss: 0.14334 (A-MSE: 0.12491) avg lploss: 0.00000
train epoch 1279 avg loss: 0.15171 (A-MSE: 0.13349) avg lploss: 0.00000
train epoch 1280 avg loss: 0.11660 (A-MSE: 0.10406) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.36522 (A-MSE: 0.30886) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.36804 (A-MSE: 0.32202) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 5 out of 50
train epoch 1281 avg loss: 0.10907 (A-MSE: 0.09590) avg lploss: 0.00000
train epoch 1282 avg loss: 0.11120 (A-MSE: 0.09769) avg lploss: 0.00000
train epoch 1283 avg loss: 0.10587 (A-MSE: 0.09402) avg lploss: 0.00000
train epoch 1284 avg loss: 0.11569 (A-MSE: 0.10190) avg lploss: 0.00000
train epoch 1285 avg loss: 0.12701 (A-MSE: 0.11347) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.43565 (A-MSE: 0.36987) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.46415 (A-MSE: 0.40632) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 6 out of 50
train epoch 1286 avg loss: 0.11627 (A-MSE: 0.10218) avg lploss: 0.00000
train epoch 1287 avg loss: 0.12350 (A-MSE: 0.10988) avg lploss: 0.00000
train epoch 1288 avg loss: 0.14424 (A-MSE: 0.12666) avg lploss: 0.00000
train epoch 1289 avg loss: 0.11441 (A-MSE: 0.10132) avg lploss: 0.00000
train epoch 1290 avg loss: 0.09913 (A-MSE: 0.08673) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.37326 (A-MSE: 0.31814) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.38112 (A-MSE: 0.33980) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 7 out of 50
train epoch 1291 avg loss: 0.13009 (A-MSE: 0.11428) avg lploss: 0.00000
train epoch 1292 avg loss: 0.11058 (A-MSE: 0.09826) avg lploss: 0.00000
train epoch 1293 avg loss: 0.12015 (A-MSE: 0.10663) avg lploss: 0.00000
train epoch 1294 avg loss: 0.12961 (A-MSE: 0.11375) avg lploss: 0.00000
train epoch 1295 avg loss: 0.11032 (A-MSE: 0.09763) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.39714 (A-MSE: 0.33906) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.42093 (A-MSE: 0.37371) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 8 out of 50
train epoch 1296 avg loss: 0.09740 (A-MSE: 0.08664) avg lploss: 0.00000
train epoch 1297 avg loss: 0.10306 (A-MSE: 0.09113) avg lploss: 0.00000
train epoch 1298 avg loss: 0.10773 (A-MSE: 0.09460) avg lploss: 0.00000
train epoch 1299 avg loss: 0.10615 (A-MSE: 0.09378) avg lploss: 0.00000
train epoch 1300 avg loss: 0.10750 (A-MSE: 0.09489) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.39787 (A-MSE: 0.33935) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.39410 (A-MSE: 0.34775) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 9 out of 50
train epoch 1301 avg loss: 0.12865 (A-MSE: 0.11367) avg lploss: 0.00000
train epoch 1302 avg loss: 0.12830 (A-MSE: 0.11281) avg lploss: 0.00000
train epoch 1303 avg loss: 0.11723 (A-MSE: 0.10374) avg lploss: 0.00000
train epoch 1304 avg loss: 0.09131 (A-MSE: 0.08170) avg lploss: 0.00000
train epoch 1305 avg loss: 0.10270 (A-MSE: 0.09087) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.33580 (A-MSE: 0.28775) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.36758 (A-MSE: 0.32647) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 10 out of 50
train epoch 1306 avg loss: 0.10880 (A-MSE: 0.09535) avg lploss: 0.00000
train epoch 1307 avg loss: 0.09244 (A-MSE: 0.08192) avg lploss: 0.00000
train epoch 1308 avg loss: 0.11405 (A-MSE: 0.10122) avg lploss: 0.00000
train epoch 1309 avg loss: 0.11993 (A-MSE: 0.10598) avg lploss: 0.00000
train epoch 1310 avg loss: 0.11112 (A-MSE: 0.09863) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.37638 (A-MSE: 0.32443) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.38606 (A-MSE: 0.34185) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 11 out of 50
train epoch 1311 avg loss: 0.12891 (A-MSE: 0.11362) avg lploss: 0.00000
train epoch 1312 avg loss: 0.10807 (A-MSE: 0.09544) avg lploss: 0.00000
train epoch 1313 avg loss: 0.12373 (A-MSE: 0.10906) avg lploss: 0.00000
train epoch 1314 avg loss: 0.11625 (A-MSE: 0.10289) avg lploss: 0.00000
train epoch 1315 avg loss: 0.11585 (A-MSE: 0.10211) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.40755 (A-MSE: 0.34641) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.43388 (A-MSE: 0.38412) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 12 out of 50
train epoch 1316 avg loss: 0.13769 (A-MSE: 0.12243) avg lploss: 0.00000
train epoch 1317 avg loss: 0.12516 (A-MSE: 0.11021) avg lploss: 0.00000
train epoch 1318 avg loss: 0.11514 (A-MSE: 0.10250) avg lploss: 0.00000
train epoch 1319 avg loss: 0.11502 (A-MSE: 0.10145) avg lploss: 0.00000
train epoch 1320 avg loss: 0.10513 (A-MSE: 0.09378) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.37140 (A-MSE: 0.31753) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.36083 (A-MSE: 0.32075) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 13 out of 50
train epoch 1321 avg loss: 0.10285 (A-MSE: 0.09065) avg lploss: 0.00000
train epoch 1322 avg loss: 0.09341 (A-MSE: 0.08249) avg lploss: 0.00000
train epoch 1323 avg loss: 0.12115 (A-MSE: 0.10735) avg lploss: 0.00000
train epoch 1324 avg loss: 0.13092 (A-MSE: 0.11572) avg lploss: 0.00000
train epoch 1325 avg loss: 0.13556 (A-MSE: 0.11989) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.41225 (A-MSE: 0.35289) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.41572 (A-MSE: 0.37082) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 14 out of 50
train epoch 1326 avg loss: 0.16175 (A-MSE: 0.14272) avg lploss: 0.00000
train epoch 1327 avg loss: 0.13829 (A-MSE: 0.12260) avg lploss: 0.00000
train epoch 1328 avg loss: 0.15969 (A-MSE: 0.14037) avg lploss: 0.00000
train epoch 1329 avg loss: 0.12983 (A-MSE: 0.11376) avg lploss: 0.00000
train epoch 1330 avg loss: 0.10690 (A-MSE: 0.09461) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.37611 (A-MSE: 0.32623) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.38252 (A-MSE: 0.34159) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 15 out of 50
train epoch 1331 avg loss: 0.09725 (A-MSE: 0.08735) avg lploss: 0.00000
train epoch 1332 avg loss: 0.10748 (A-MSE: 0.09497) avg lploss: 0.00000
train epoch 1333 avg loss: 0.10687 (A-MSE: 0.09478) avg lploss: 0.00000
train epoch 1334 avg loss: 0.08955 (A-MSE: 0.07863) avg lploss: 0.00000
train epoch 1335 avg loss: 0.08772 (A-MSE: 0.07815) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.35490 (A-MSE: 0.30624) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.37987 (A-MSE: 0.33902) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 16 out of 50
train epoch 1336 avg loss: 0.12975 (A-MSE: 0.11620) avg lploss: 0.00000
train epoch 1337 avg loss: 0.11061 (A-MSE: 0.09889) avg lploss: 0.00000
train epoch 1338 avg loss: 0.10286 (A-MSE: 0.08996) avg lploss: 0.00000
train epoch 1339 avg loss: 0.11273 (A-MSE: 0.09857) avg lploss: 0.00000
train epoch 1340 avg loss: 0.11594 (A-MSE: 0.10232) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.45451 (A-MSE: 0.38974) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.44898 (A-MSE: 0.39780) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 17 out of 50
train epoch 1341 avg loss: 0.11266 (A-MSE: 0.09966) avg lploss: 0.00000
train epoch 1342 avg loss: 0.09965 (A-MSE: 0.08782) avg lploss: 0.00000
train epoch 1343 avg loss: 0.10421 (A-MSE: 0.09257) avg lploss: 0.00000
train epoch 1344 avg loss: 0.11827 (A-MSE: 0.10440) avg lploss: 0.00000
train epoch 1345 avg loss: 0.11206 (A-MSE: 0.09920) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.39069 (A-MSE: 0.33361) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.39262 (A-MSE: 0.34852) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 18 out of 50
train epoch 1346 avg loss: 0.11900 (A-MSE: 0.10664) avg lploss: 0.00000
train epoch 1347 avg loss: 0.10682 (A-MSE: 0.09367) avg lploss: 0.00000
train epoch 1348 avg loss: 0.10604 (A-MSE: 0.09363) avg lploss: 0.00000
train epoch 1349 avg loss: 0.10636 (A-MSE: 0.09417) avg lploss: 0.00000
train epoch 1350 avg loss: 0.10478 (A-MSE: 0.09272) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.36622 (A-MSE: 0.31374) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.35639 (A-MSE: 0.31980) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 19 out of 50
train epoch 1351 avg loss: 0.12049 (A-MSE: 0.10722) avg lploss: 0.00000
train epoch 1352 avg loss: 0.12228 (A-MSE: 0.10826) avg lploss: 0.00000
train epoch 1353 avg loss: 0.11768 (A-MSE: 0.10379) avg lploss: 0.00000
train epoch 1354 avg loss: 0.10762 (A-MSE: 0.09474) avg lploss: 0.00000
train epoch 1355 avg loss: 0.10796 (A-MSE: 0.09483) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.42365 (A-MSE: 0.35930) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.39853 (A-MSE: 0.34794) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 20 out of 50
train epoch 1356 avg loss: 0.09329 (A-MSE: 0.08238) avg lploss: 0.00000
train epoch 1357 avg loss: 0.10133 (A-MSE: 0.08988) avg lploss: 0.00000
train epoch 1358 avg loss: 0.11084 (A-MSE: 0.09714) avg lploss: 0.00000
train epoch 1359 avg loss: 0.11360 (A-MSE: 0.10086) avg lploss: 0.00000
train epoch 1360 avg loss: 0.10308 (A-MSE: 0.09126) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.37748 (A-MSE: 0.32264) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.38571 (A-MSE: 0.34198) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 21 out of 50
train epoch 1361 avg loss: 0.09763 (A-MSE: 0.08596) avg lploss: 0.00000
train epoch 1362 avg loss: 0.09840 (A-MSE: 0.08705) avg lploss: 0.00000
train epoch 1363 avg loss: 0.09200 (A-MSE: 0.08202) avg lploss: 0.00000
train epoch 1364 avg loss: 0.12854 (A-MSE: 0.11257) avg lploss: 0.00000
train epoch 1365 avg loss: 0.10696 (A-MSE: 0.09485) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.33888 (A-MSE: 0.29392) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.37548 (A-MSE: 0.33852) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 22 out of 50
train epoch 1366 avg loss: 0.09272 (A-MSE: 0.08128) avg lploss: 0.00000
train epoch 1367 avg loss: 0.09815 (A-MSE: 0.08664) avg lploss: 0.00000
train epoch 1368 avg loss: 0.08580 (A-MSE: 0.07650) avg lploss: 0.00000
train epoch 1369 avg loss: 0.10928 (A-MSE: 0.09653) avg lploss: 0.00000
train epoch 1370 avg loss: 0.10634 (A-MSE: 0.09311) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.41406 (A-MSE: 0.35587) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.41694 (A-MSE: 0.37064) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 23 out of 50
train epoch 1371 avg loss: 0.11344 (A-MSE: 0.09993) avg lploss: 0.00000
train epoch 1372 avg loss: 0.10306 (A-MSE: 0.09145) avg lploss: 0.00000
train epoch 1373 avg loss: 0.09745 (A-MSE: 0.08506) avg lploss: 0.00000
train epoch 1374 avg loss: 0.08012 (A-MSE: 0.07105) avg lploss: 0.00000
train epoch 1375 avg loss: 0.09865 (A-MSE: 0.08793) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.40225 (A-MSE: 0.34485) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.41456 (A-MSE: 0.36595) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 24 out of 50
train epoch 1376 avg loss: 0.09241 (A-MSE: 0.08175) avg lploss: 0.00000
train epoch 1377 avg loss: 0.09862 (A-MSE: 0.08671) avg lploss: 0.00000
train epoch 1378 avg loss: 0.08838 (A-MSE: 0.07841) avg lploss: 0.00000
train epoch 1379 avg loss: 0.08238 (A-MSE: 0.07328) avg lploss: 0.00000
train epoch 1380 avg loss: 0.08887 (A-MSE: 0.07883) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.40484 (A-MSE: 0.34607) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.41420 (A-MSE: 0.36721) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 25 out of 50
train epoch 1381 avg loss: 0.09576 (A-MSE: 0.08469) avg lploss: 0.00000
train epoch 1382 avg loss: 0.08642 (A-MSE: 0.07647) avg lploss: 0.00000
train epoch 1383 avg loss: 0.09193 (A-MSE: 0.08145) avg lploss: 0.00000
train epoch 1384 avg loss: 0.09303 (A-MSE: 0.08177) avg lploss: 0.00000
train epoch 1385 avg loss: 0.12671 (A-MSE: 0.11070) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.42001 (A-MSE: 0.35993) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.41980 (A-MSE: 0.37186) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 26 out of 50
train epoch 1386 avg loss: 0.11239 (A-MSE: 0.09973) avg lploss: 0.00000
train epoch 1387 avg loss: 0.09187 (A-MSE: 0.08095) avg lploss: 0.00000
train epoch 1388 avg loss: 0.09054 (A-MSE: 0.08119) avg lploss: 0.00000
train epoch 1389 avg loss: 0.09520 (A-MSE: 0.08464) avg lploss: 0.00000
train epoch 1390 avg loss: 0.11183 (A-MSE: 0.09951) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.36806 (A-MSE: 0.31692) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.36940 (A-MSE: 0.33028) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 27 out of 50
train epoch 1391 avg loss: 0.12930 (A-MSE: 0.11364) avg lploss: 0.00000
train epoch 1392 avg loss: 0.15517 (A-MSE: 0.13729) avg lploss: 0.00000
train epoch 1393 avg loss: 0.11801 (A-MSE: 0.10348) avg lploss: 0.00000
train epoch 1394 avg loss: 0.09614 (A-MSE: 0.08599) avg lploss: 0.00000
train epoch 1395 avg loss: 0.10826 (A-MSE: 0.09628) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.43804 (A-MSE: 0.37661) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.41681 (A-MSE: 0.37415) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 28 out of 50
train epoch 1396 avg loss: 0.11713 (A-MSE: 0.10450) avg lploss: 0.00000
train epoch 1397 avg loss: 0.11987 (A-MSE: 0.10609) avg lploss: 0.00000
train epoch 1398 avg loss: 0.09503 (A-MSE: 0.08429) avg lploss: 0.00000
train epoch 1399 avg loss: 0.09125 (A-MSE: 0.08029) avg lploss: 0.00000
train epoch 1400 avg loss: 0.09679 (A-MSE: 0.08577) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.37946 (A-MSE: 0.32765) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.39351 (A-MSE: 0.35309) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 29 out of 50
train epoch 1401 avg loss: 0.08251 (A-MSE: 0.07331) avg lploss: 0.00000
train epoch 1402 avg loss: 0.09468 (A-MSE: 0.08348) avg lploss: 0.00000
train epoch 1403 avg loss: 0.14877 (A-MSE: 0.13251) avg lploss: 0.00000
train epoch 1404 avg loss: 0.11351 (A-MSE: 0.10044) avg lploss: 0.00000
train epoch 1405 avg loss: 0.10804 (A-MSE: 0.09496) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.35277 (A-MSE: 0.30082) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.35464 (A-MSE: 0.31466) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 30 out of 50
train epoch 1406 avg loss: 0.09618 (A-MSE: 0.08523) avg lploss: 0.00000
train epoch 1407 avg loss: 0.08960 (A-MSE: 0.07979) avg lploss: 0.00000
train epoch 1408 avg loss: 0.08455 (A-MSE: 0.07448) avg lploss: 0.00000
train epoch 1409 avg loss: 0.09246 (A-MSE: 0.08318) avg lploss: 0.00000
train epoch 1410 avg loss: 0.09617 (A-MSE: 0.08534) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.37037 (A-MSE: 0.31853) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.36876 (A-MSE: 0.32836) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 31 out of 50
train epoch 1411 avg loss: 0.09332 (A-MSE: 0.08296) avg lploss: 0.00000
train epoch 1412 avg loss: 0.08990 (A-MSE: 0.07981) avg lploss: 0.00000
train epoch 1413 avg loss: 0.08879 (A-MSE: 0.07893) avg lploss: 0.00000
train epoch 1414 avg loss: 0.09405 (A-MSE: 0.08204) avg lploss: 0.00000
train epoch 1415 avg loss: 0.09372 (A-MSE: 0.08331) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.43955 (A-MSE: 0.37891) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.44696 (A-MSE: 0.40000) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 32 out of 50
train epoch 1416 avg loss: 0.10288 (A-MSE: 0.09082) avg lploss: 0.00000
train epoch 1417 avg loss: 0.10752 (A-MSE: 0.09518) avg lploss: 0.00000
train epoch 1418 avg loss: 0.10272 (A-MSE: 0.09094) avg lploss: 0.00000
train epoch 1419 avg loss: 0.10009 (A-MSE: 0.08891) avg lploss: 0.00000
train epoch 1420 avg loss: 0.10730 (A-MSE: 0.09492) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.39666 (A-MSE: 0.34074) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.40300 (A-MSE: 0.35977) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 33 out of 50
train epoch 1421 avg loss: 0.09652 (A-MSE: 0.08531) avg lploss: 0.00000
train epoch 1422 avg loss: 0.08595 (A-MSE: 0.07533) avg lploss: 0.00000
train epoch 1423 avg loss: 0.08289 (A-MSE: 0.07363) avg lploss: 0.00000
train epoch 1424 avg loss: 0.08465 (A-MSE: 0.07524) avg lploss: 0.00000
train epoch 1425 avg loss: 0.11305 (A-MSE: 0.09944) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.39234 (A-MSE: 0.34621) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.42616 (A-MSE: 0.38535) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 34 out of 50
train epoch 1426 avg loss: 0.10076 (A-MSE: 0.08893) avg lploss: 0.00000
train epoch 1427 avg loss: 0.09015 (A-MSE: 0.07951) avg lploss: 0.00000
train epoch 1428 avg loss: 0.11487 (A-MSE: 0.10162) avg lploss: 0.00000
train epoch 1429 avg loss: 0.10388 (A-MSE: 0.09189) avg lploss: 0.00000
train epoch 1430 avg loss: 0.09610 (A-MSE: 0.08508) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.33113 (A-MSE: 0.28662) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.34143 (A-MSE: 0.30546) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 35 out of 50
train epoch 1431 avg loss: 0.07791 (A-MSE: 0.06849) avg lploss: 0.00000
train epoch 1432 avg loss: 0.07286 (A-MSE: 0.06412) avg lploss: 0.00000
train epoch 1433 avg loss: 0.07960 (A-MSE: 0.07115) avg lploss: 0.00000
train epoch 1434 avg loss: 0.09112 (A-MSE: 0.08003) avg lploss: 0.00000
train epoch 1435 avg loss: 0.09576 (A-MSE: 0.08413) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.37754 (A-MSE: 0.32824) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.38902 (A-MSE: 0.35138) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 36 out of 50
train epoch 1436 avg loss: 0.09567 (A-MSE: 0.08506) avg lploss: 0.00000
train epoch 1437 avg loss: 0.09593 (A-MSE: 0.08510) avg lploss: 0.00000
train epoch 1438 avg loss: 0.08384 (A-MSE: 0.07461) avg lploss: 0.00000
train epoch 1439 avg loss: 0.08378 (A-MSE: 0.07443) avg lploss: 0.00000
train epoch 1440 avg loss: 0.09409 (A-MSE: 0.08313) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.36078 (A-MSE: 0.31453) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.38820 (A-MSE: 0.35078) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 37 out of 50
train epoch 1441 avg loss: 0.09143 (A-MSE: 0.08125) avg lploss: 0.00000
train epoch 1442 avg loss: 0.09480 (A-MSE: 0.08393) avg lploss: 0.00000
train epoch 1443 avg loss: 0.09221 (A-MSE: 0.08168) avg lploss: 0.00000
train epoch 1444 avg loss: 0.10314 (A-MSE: 0.09112) avg lploss: 0.00000
train epoch 1445 avg loss: 0.10754 (A-MSE: 0.09533) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.37048 (A-MSE: 0.32362) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.37616 (A-MSE: 0.33710) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 38 out of 50
train epoch 1446 avg loss: 0.09319 (A-MSE: 0.08196) avg lploss: 0.00000
train epoch 1447 avg loss: 0.08474 (A-MSE: 0.07541) avg lploss: 0.00000
train epoch 1448 avg loss: 0.08047 (A-MSE: 0.07088) avg lploss: 0.00000
train epoch 1449 avg loss: 0.09429 (A-MSE: 0.08367) avg lploss: 0.00000
train epoch 1450 avg loss: 0.11550 (A-MSE: 0.10218) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.41741 (A-MSE: 0.36458) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.42431 (A-MSE: 0.38490) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 39 out of 50
train epoch 1451 avg loss: 0.10562 (A-MSE: 0.09246) avg lploss: 0.00000
train epoch 1452 avg loss: 0.10077 (A-MSE: 0.08905) avg lploss: 0.00000
train epoch 1453 avg loss: 0.10993 (A-MSE: 0.09829) avg lploss: 0.00000
train epoch 1454 avg loss: 0.09004 (A-MSE: 0.08008) avg lploss: 0.00000
train epoch 1455 avg loss: 0.08604 (A-MSE: 0.07703) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.34357 (A-MSE: 0.29617) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.37184 (A-MSE: 0.33133) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 40 out of 50
train epoch 1456 avg loss: 0.10820 (A-MSE: 0.09532) avg lploss: 0.00000
train epoch 1457 avg loss: 0.13391 (A-MSE: 0.12042) avg lploss: 0.00000
train epoch 1458 avg loss: 0.10991 (A-MSE: 0.09653) avg lploss: 0.00000
train epoch 1459 avg loss: 0.09474 (A-MSE: 0.08406) avg lploss: 0.00000
train epoch 1460 avg loss: 0.09130 (A-MSE: 0.07975) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.33715 (A-MSE: 0.29036) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.36339 (A-MSE: 0.32519) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 41 out of 50
train epoch 1461 avg loss: 0.09032 (A-MSE: 0.07980) avg lploss: 0.00000
train epoch 1462 avg loss: 0.09428 (A-MSE: 0.08412) avg lploss: 0.00000
train epoch 1463 avg loss: 0.09481 (A-MSE: 0.08381) avg lploss: 0.00000
train epoch 1464 avg loss: 0.10126 (A-MSE: 0.09035) avg lploss: 0.00000
train epoch 1465 avg loss: 0.11194 (A-MSE: 0.09879) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.44026 (A-MSE: 0.37066) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.42126 (A-MSE: 0.36805) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 42 out of 50
train epoch 1466 avg loss: 0.10887 (A-MSE: 0.09729) avg lploss: 0.00000
train epoch 1467 avg loss: 0.12903 (A-MSE: 0.11452) avg lploss: 0.00000
train epoch 1468 avg loss: 0.10772 (A-MSE: 0.09510) avg lploss: 0.00000
train epoch 1469 avg loss: 0.09535 (A-MSE: 0.08410) avg lploss: 0.00000
train epoch 1470 avg loss: 0.09068 (A-MSE: 0.08027) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.33296 (A-MSE: 0.28865) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.37359 (A-MSE: 0.33540) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 43 out of 50
train epoch 1471 avg loss: 0.11723 (A-MSE: 0.10500) avg lploss: 0.00000
train epoch 1472 avg loss: 0.11551 (A-MSE: 0.10223) avg lploss: 0.00000
train epoch 1473 avg loss: 0.10107 (A-MSE: 0.08958) avg lploss: 0.00000
train epoch 1474 avg loss: 0.09910 (A-MSE: 0.08807) avg lploss: 0.00000
train epoch 1475 avg loss: 0.11628 (A-MSE: 0.10322) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.47652 (A-MSE: 0.39973) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.48561 (A-MSE: 0.42075) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 44 out of 50
train epoch 1476 avg loss: 0.11192 (A-MSE: 0.09921) avg lploss: 0.00000
train epoch 1477 avg loss: 0.09602 (A-MSE: 0.08440) avg lploss: 0.00000
train epoch 1478 avg loss: 0.08353 (A-MSE: 0.07392) avg lploss: 0.00000
train epoch 1479 avg loss: 0.09638 (A-MSE: 0.08514) avg lploss: 0.00000
train epoch 1480 avg loss: 0.11154 (A-MSE: 0.09812) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.35821 (A-MSE: 0.30594) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.35257 (A-MSE: 0.31152) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 45 out of 50
train epoch 1481 avg loss: 0.11913 (A-MSE: 0.10612) avg lploss: 0.00000
train epoch 1482 avg loss: 0.11338 (A-MSE: 0.10016) avg lploss: 0.00000
train epoch 1483 avg loss: 0.09397 (A-MSE: 0.08361) avg lploss: 0.00000
train epoch 1484 avg loss: 0.08365 (A-MSE: 0.07413) avg lploss: 0.00000
train epoch 1485 avg loss: 0.08109 (A-MSE: 0.07196) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.34553 (A-MSE: 0.29681) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.34480 (A-MSE: 0.30644) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 46 out of 50
train epoch 1486 avg loss: 0.07301 (A-MSE: 0.06424) avg lploss: 0.00000
train epoch 1487 avg loss: 0.07283 (A-MSE: 0.06422) avg lploss: 0.00000
train epoch 1488 avg loss: 0.06994 (A-MSE: 0.06160) avg lploss: 0.00000
train epoch 1489 avg loss: 0.07415 (A-MSE: 0.06572) avg lploss: 0.00000
train epoch 1490 avg loss: 0.07970 (A-MSE: 0.07074) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.40660 (A-MSE: 0.34561) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.40057 (A-MSE: 0.35396) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 47 out of 50
train epoch 1491 avg loss: 0.10411 (A-MSE: 0.09136) avg lploss: 0.00000
train epoch 1492 avg loss: 0.09109 (A-MSE: 0.08067) avg lploss: 0.00000
train epoch 1493 avg loss: 0.07233 (A-MSE: 0.06466) avg lploss: 0.00000
train epoch 1494 avg loss: 0.08200 (A-MSE: 0.07223) avg lploss: 0.00000
train epoch 1495 avg loss: 0.07869 (A-MSE: 0.06944) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.35217 (A-MSE: 0.30263) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.35625 (A-MSE: 0.31898) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 48 out of 50
train epoch 1496 avg loss: 0.08263 (A-MSE: 0.07398) avg lploss: 0.00000
train epoch 1497 avg loss: 0.07134 (A-MSE: 0.06277) avg lploss: 0.00000
train epoch 1498 avg loss: 0.07740 (A-MSE: 0.06924) avg lploss: 0.00000
train epoch 1499 avg loss: 0.09082 (A-MSE: 0.08017) avg lploss: 0.00000
train epoch 1500 avg loss: 0.09417 (A-MSE: 0.08326) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.37035 (A-MSE: 0.32198) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.37418 (A-MSE: 0.33534) avg lploss: 0.00000
*** Best Val Loss: 0.32552 	 Best Test Loss: 0.35345 	 Best epoch 1255
EarlyStopping counter: 49 out of 50
train epoch 1501 avg loss: 0.10324 (A-MSE: 0.09125) avg lploss: 0.00000
train epoch 1502 avg loss: 0.09266 (A-MSE: 0.08162) avg lploss: 0.00000
train epoch 1503 avg loss: 0.08184 (A-MSE: 0.07276) avg lploss: 0.00000
train epoch 1504 avg loss: 0.07681 (A-MSE: 0.06744) avg lploss: 0.00000
train epoch 1505 avg loss: 0.06802 (A-MSE: 0.05966) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.31406 (A-MSE: 0.27050) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.33797 (A-MSE: 0.30299) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
Validation loss decreased (0.325522 --> 0.314062).  Saving model ...
train epoch 1506 avg loss: 0.07116 (A-MSE: 0.06262) avg lploss: 0.00000
train epoch 1507 avg loss: 0.07019 (A-MSE: 0.06198) avg lploss: 0.00000
train epoch 1508 avg loss: 0.08931 (A-MSE: 0.07917) avg lploss: 0.00000
train epoch 1509 avg loss: 0.08154 (A-MSE: 0.07210) avg lploss: 0.00000
train epoch 1510 avg loss: 0.07510 (A-MSE: 0.06635) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.33401 (A-MSE: 0.28938) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.34373 (A-MSE: 0.30976) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 1 out of 50
train epoch 1511 avg loss: 0.08050 (A-MSE: 0.07154) avg lploss: 0.00000
train epoch 1512 avg loss: 0.08465 (A-MSE: 0.07538) avg lploss: 0.00000
train epoch 1513 avg loss: 0.07914 (A-MSE: 0.06952) avg lploss: 0.00000
train epoch 1514 avg loss: 0.07629 (A-MSE: 0.06708) avg lploss: 0.00000
train epoch 1515 avg loss: 0.10149 (A-MSE: 0.09039) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.35055 (A-MSE: 0.30231) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.36917 (A-MSE: 0.33448) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 2 out of 50
train epoch 1516 avg loss: 0.09343 (A-MSE: 0.08250) avg lploss: 0.00000
train epoch 1517 avg loss: 0.08147 (A-MSE: 0.07271) avg lploss: 0.00000
train epoch 1518 avg loss: 0.08676 (A-MSE: 0.07715) avg lploss: 0.00000
train epoch 1519 avg loss: 0.08279 (A-MSE: 0.07320) avg lploss: 0.00000
train epoch 1520 avg loss: 0.08399 (A-MSE: 0.07456) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.37103 (A-MSE: 0.31887) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.38138 (A-MSE: 0.33763) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 3 out of 50
train epoch 1521 avg loss: 0.07885 (A-MSE: 0.06968) avg lploss: 0.00000
train epoch 1522 avg loss: 0.08594 (A-MSE: 0.07526) avg lploss: 0.00000
train epoch 1523 avg loss: 0.08314 (A-MSE: 0.07374) avg lploss: 0.00000
train epoch 1524 avg loss: 0.07663 (A-MSE: 0.06763) avg lploss: 0.00000
train epoch 1525 avg loss: 0.08040 (A-MSE: 0.07133) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.35165 (A-MSE: 0.31079) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.35939 (A-MSE: 0.32635) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 4 out of 50
train epoch 1526 avg loss: 0.09162 (A-MSE: 0.08091) avg lploss: 0.00000
train epoch 1527 avg loss: 0.08809 (A-MSE: 0.07781) avg lploss: 0.00000
train epoch 1528 avg loss: 0.09096 (A-MSE: 0.08004) avg lploss: 0.00000
train epoch 1529 avg loss: 0.08638 (A-MSE: 0.07690) avg lploss: 0.00000
train epoch 1530 avg loss: 0.08531 (A-MSE: 0.07574) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.32119 (A-MSE: 0.27850) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.34249 (A-MSE: 0.30987) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 5 out of 50
train epoch 1531 avg loss: 0.07957 (A-MSE: 0.06996) avg lploss: 0.00000
train epoch 1532 avg loss: 0.08141 (A-MSE: 0.07321) avg lploss: 0.00000
train epoch 1533 avg loss: 0.08356 (A-MSE: 0.07388) avg lploss: 0.00000
train epoch 1534 avg loss: 0.08158 (A-MSE: 0.07203) avg lploss: 0.00000
train epoch 1535 avg loss: 0.07763 (A-MSE: 0.06867) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.36034 (A-MSE: 0.31482) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.36421 (A-MSE: 0.32788) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 6 out of 50
train epoch 1536 avg loss: 0.07175 (A-MSE: 0.06329) avg lploss: 0.00000
train epoch 1537 avg loss: 0.07610 (A-MSE: 0.06740) avg lploss: 0.00000
train epoch 1538 avg loss: 0.08459 (A-MSE: 0.07496) avg lploss: 0.00000
train epoch 1539 avg loss: 0.07807 (A-MSE: 0.06875) avg lploss: 0.00000
train epoch 1540 avg loss: 0.07180 (A-MSE: 0.06391) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.38405 (A-MSE: 0.32847) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.37961 (A-MSE: 0.33629) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 7 out of 50
train epoch 1541 avg loss: 0.09717 (A-MSE: 0.08620) avg lploss: 0.00000
train epoch 1542 avg loss: 0.12066 (A-MSE: 0.10597) avg lploss: 0.00000
train epoch 1543 avg loss: 0.09509 (A-MSE: 0.08322) avg lploss: 0.00000
train epoch 1544 avg loss: 0.07728 (A-MSE: 0.06799) avg lploss: 0.00000
train epoch 1545 avg loss: 0.07619 (A-MSE: 0.06696) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.33113 (A-MSE: 0.28734) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.35446 (A-MSE: 0.31827) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 8 out of 50
train epoch 1546 avg loss: 0.06789 (A-MSE: 0.05990) avg lploss: 0.00000
train epoch 1547 avg loss: 0.07489 (A-MSE: 0.06648) avg lploss: 0.00000
train epoch 1548 avg loss: 0.08052 (A-MSE: 0.07106) avg lploss: 0.00000
train epoch 1549 avg loss: 0.10367 (A-MSE: 0.09206) avg lploss: 0.00000
train epoch 1550 avg loss: 0.10105 (A-MSE: 0.08991) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.33755 (A-MSE: 0.28782) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.35440 (A-MSE: 0.31647) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 9 out of 50
train epoch 1551 avg loss: 0.09028 (A-MSE: 0.08003) avg lploss: 0.00000
train epoch 1552 avg loss: 0.07395 (A-MSE: 0.06493) avg lploss: 0.00000
train epoch 1553 avg loss: 0.07055 (A-MSE: 0.06229) avg lploss: 0.00000
train epoch 1554 avg loss: 0.06470 (A-MSE: 0.05708) avg lploss: 0.00000
train epoch 1555 avg loss: 0.06341 (A-MSE: 0.05567) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.35326 (A-MSE: 0.30494) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.35997 (A-MSE: 0.32179) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 10 out of 50
train epoch 1556 avg loss: 0.08556 (A-MSE: 0.07594) avg lploss: 0.00000
train epoch 1557 avg loss: 0.07913 (A-MSE: 0.06947) avg lploss: 0.00000
train epoch 1558 avg loss: 0.08294 (A-MSE: 0.07378) avg lploss: 0.00000
train epoch 1559 avg loss: 0.07178 (A-MSE: 0.06352) avg lploss: 0.00000
train epoch 1560 avg loss: 0.08778 (A-MSE: 0.07774) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.34842 (A-MSE: 0.30484) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.37962 (A-MSE: 0.34277) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 11 out of 50
train epoch 1561 avg loss: 0.08617 (A-MSE: 0.07676) avg lploss: 0.00000
train epoch 1562 avg loss: 0.11214 (A-MSE: 0.09882) avg lploss: 0.00000
train epoch 1563 avg loss: 0.12003 (A-MSE: 0.10675) avg lploss: 0.00000
train epoch 1564 avg loss: 0.10915 (A-MSE: 0.09609) avg lploss: 0.00000
train epoch 1565 avg loss: 0.10943 (A-MSE: 0.09733) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.34947 (A-MSE: 0.30738) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.37559 (A-MSE: 0.34043) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 12 out of 50
train epoch 1566 avg loss: 0.11240 (A-MSE: 0.09985) avg lploss: 0.00000
train epoch 1567 avg loss: 0.09805 (A-MSE: 0.08780) avg lploss: 0.00000
train epoch 1568 avg loss: 0.09719 (A-MSE: 0.08513) avg lploss: 0.00000
train epoch 1569 avg loss: 0.07949 (A-MSE: 0.07021) avg lploss: 0.00000
train epoch 1570 avg loss: 0.06530 (A-MSE: 0.05776) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.33454 (A-MSE: 0.29034) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.35201 (A-MSE: 0.31707) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 13 out of 50
train epoch 1571 avg loss: 0.07220 (A-MSE: 0.06385) avg lploss: 0.00000
train epoch 1572 avg loss: 0.07460 (A-MSE: 0.06666) avg lploss: 0.00000
train epoch 1573 avg loss: 0.07692 (A-MSE: 0.06855) avg lploss: 0.00000
train epoch 1574 avg loss: 0.07096 (A-MSE: 0.06290) avg lploss: 0.00000
train epoch 1575 avg loss: 0.07751 (A-MSE: 0.06841) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.38268 (A-MSE: 0.32916) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.39267 (A-MSE: 0.34768) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 14 out of 50
train epoch 1576 avg loss: 0.08181 (A-MSE: 0.07205) avg lploss: 0.00000
train epoch 1577 avg loss: 0.07627 (A-MSE: 0.06744) avg lploss: 0.00000
train epoch 1578 avg loss: 0.10333 (A-MSE: 0.09127) avg lploss: 0.00000
train epoch 1579 avg loss: 0.08975 (A-MSE: 0.07982) avg lploss: 0.00000
train epoch 1580 avg loss: 0.09509 (A-MSE: 0.08487) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.35678 (A-MSE: 0.30267) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.35350 (A-MSE: 0.31348) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 15 out of 50
train epoch 1581 avg loss: 0.07769 (A-MSE: 0.06866) avg lploss: 0.00000
train epoch 1582 avg loss: 0.06974 (A-MSE: 0.06172) avg lploss: 0.00000
train epoch 1583 avg loss: 0.06438 (A-MSE: 0.05684) avg lploss: 0.00000
train epoch 1584 avg loss: 0.05567 (A-MSE: 0.04894) avg lploss: 0.00000
train epoch 1585 avg loss: 0.05427 (A-MSE: 0.04767) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.32845 (A-MSE: 0.28250) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.35841 (A-MSE: 0.32192) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 16 out of 50
train epoch 1586 avg loss: 0.05372 (A-MSE: 0.04756) avg lploss: 0.00000
train epoch 1587 avg loss: 0.06676 (A-MSE: 0.05872) avg lploss: 0.00000
train epoch 1588 avg loss: 0.10128 (A-MSE: 0.08912) avg lploss: 0.00000
train epoch 1589 avg loss: 0.13716 (A-MSE: 0.12191) avg lploss: 0.00000
train epoch 1590 avg loss: 0.13099 (A-MSE: 0.11738) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.43286 (A-MSE: 0.36840) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.47654 (A-MSE: 0.41842) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 17 out of 50
train epoch 1591 avg loss: 0.17115 (A-MSE: 0.14965) avg lploss: 0.00000
train epoch 1592 avg loss: 0.12669 (A-MSE: 0.11243) avg lploss: 0.00000
train epoch 1593 avg loss: 0.12683 (A-MSE: 0.11189) avg lploss: 0.00000
train epoch 1594 avg loss: 0.10360 (A-MSE: 0.09256) avg lploss: 0.00000
train epoch 1595 avg loss: 0.11191 (A-MSE: 0.09924) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.37177 (A-MSE: 0.32098) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.40872 (A-MSE: 0.36422) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 18 out of 50
train epoch 1596 avg loss: 0.10635 (A-MSE: 0.09360) avg lploss: 0.00000
train epoch 1597 avg loss: 0.10661 (A-MSE: 0.09523) avg lploss: 0.00000
train epoch 1598 avg loss: 0.09290 (A-MSE: 0.08110) avg lploss: 0.00000
train epoch 1599 avg loss: 0.07417 (A-MSE: 0.06578) avg lploss: 0.00000
train epoch 1600 avg loss: 0.07363 (A-MSE: 0.06566) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.32309 (A-MSE: 0.27891) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.34307 (A-MSE: 0.30845) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 19 out of 50
train epoch 1601 avg loss: 0.06736 (A-MSE: 0.05959) avg lploss: 0.00000
train epoch 1602 avg loss: 0.06526 (A-MSE: 0.05827) avg lploss: 0.00000
train epoch 1603 avg loss: 0.08715 (A-MSE: 0.07707) avg lploss: 0.00000
train epoch 1604 avg loss: 0.06750 (A-MSE: 0.05999) avg lploss: 0.00000
train epoch 1605 avg loss: 0.07165 (A-MSE: 0.06370) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.33815 (A-MSE: 0.29652) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.35929 (A-MSE: 0.32486) avg lploss: 0.00000
*** Best Val Loss: 0.31406 	 Best Test Loss: 0.33797 	 Best epoch 1505
EarlyStopping counter: 20 out of 50
train epoch 1606 avg loss: 0.06440 (A-MSE: 0.05661) avg lploss: 0.00000
train epoch 1607 avg loss: 0.06390 (A-MSE: 0.05661) avg lploss: 0.00000
train epoch 1608 avg loss: 0.06888 (A-MSE: 0.06144) avg lploss: 0.00000
train epoch 1609 avg loss: 0.06395 (A-MSE: 0.05621) avg lploss: 0.00000
train epoch 1610 avg loss: 0.07524 (A-MSE: 0.06653) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.30969 (A-MSE: 0.26641) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.32846 (A-MSE: 0.29572) avg lploss: 0.00000
*** Best Val Loss: 0.30969 	 Best Test Loss: 0.32846 	 Best epoch 1610
Validation loss decreased (0.314062 --> 0.309692).  Saving model ...
train epoch 1611 avg loss: 0.07357 (A-MSE: 0.06478) avg lploss: 0.00000
train epoch 1612 avg loss: 0.07376 (A-MSE: 0.06497) avg lploss: 0.00000
train epoch 1613 avg loss: 0.08277 (A-MSE: 0.07370) avg lploss: 0.00000
train epoch 1614 avg loss: 0.06867 (A-MSE: 0.06051) avg lploss: 0.00000
train epoch 1615 avg loss: 0.06147 (A-MSE: 0.05365) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.31118 (A-MSE: 0.26869) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.33804 (A-MSE: 0.30481) avg lploss: 0.00000
*** Best Val Loss: 0.30969 	 Best Test Loss: 0.32846 	 Best epoch 1610
EarlyStopping counter: 1 out of 50
train epoch 1616 avg loss: 0.06582 (A-MSE: 0.05812) avg lploss: 0.00000
train epoch 1617 avg loss: 0.06425 (A-MSE: 0.05642) avg lploss: 0.00000
train epoch 1618 avg loss: 0.07500 (A-MSE: 0.06618) avg lploss: 0.00000
train epoch 1619 avg loss: 0.08707 (A-MSE: 0.07686) avg lploss: 0.00000
train epoch 1620 avg loss: 0.07996 (A-MSE: 0.07050) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.35967 (A-MSE: 0.31381) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.37394 (A-MSE: 0.33634) avg lploss: 0.00000
*** Best Val Loss: 0.30969 	 Best Test Loss: 0.32846 	 Best epoch 1610
EarlyStopping counter: 2 out of 50
train epoch 1621 avg loss: 0.07911 (A-MSE: 0.07002) avg lploss: 0.00000
train epoch 1622 avg loss: 0.06683 (A-MSE: 0.05908) avg lploss: 0.00000
train epoch 1623 avg loss: 0.05940 (A-MSE: 0.05281) avg lploss: 0.00000
train epoch 1624 avg loss: 0.05723 (A-MSE: 0.05064) avg lploss: 0.00000
train epoch 1625 avg loss: 0.05199 (A-MSE: 0.04574) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.33060 (A-MSE: 0.28818) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.35413 (A-MSE: 0.31812) avg lploss: 0.00000
*** Best Val Loss: 0.30969 	 Best Test Loss: 0.32846 	 Best epoch 1610
EarlyStopping counter: 3 out of 50
train epoch 1626 avg loss: 0.05235 (A-MSE: 0.04598) avg lploss: 0.00000
train epoch 1627 avg loss: 0.05933 (A-MSE: 0.05219) avg lploss: 0.00000
train epoch 1628 avg loss: 0.06011 (A-MSE: 0.05347) avg lploss: 0.00000
train epoch 1629 avg loss: 0.06588 (A-MSE: 0.05831) avg lploss: 0.00000
train epoch 1630 avg loss: 0.06447 (A-MSE: 0.05669) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.29219 (A-MSE: 0.25022) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.31596 (A-MSE: 0.28250) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
Validation loss decreased (0.309692 --> 0.292190).  Saving model ...
train epoch 1631 avg loss: 0.05385 (A-MSE: 0.04782) avg lploss: 0.00000
train epoch 1632 avg loss: 0.06243 (A-MSE: 0.05519) avg lploss: 0.00000
train epoch 1633 avg loss: 0.06171 (A-MSE: 0.05458) avg lploss: 0.00000
train epoch 1634 avg loss: 0.07180 (A-MSE: 0.06353) avg lploss: 0.00000
train epoch 1635 avg loss: 0.06832 (A-MSE: 0.06020) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.33171 (A-MSE: 0.28500) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.34370 (A-MSE: 0.30639) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 1 out of 50
train epoch 1636 avg loss: 0.05756 (A-MSE: 0.05062) avg lploss: 0.00000
train epoch 1637 avg loss: 0.07174 (A-MSE: 0.06332) avg lploss: 0.00000
train epoch 1638 avg loss: 0.06657 (A-MSE: 0.05939) avg lploss: 0.00000
train epoch 1639 avg loss: 0.06897 (A-MSE: 0.06127) avg lploss: 0.00000
train epoch 1640 avg loss: 0.07544 (A-MSE: 0.06711) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.29428 (A-MSE: 0.25669) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.33530 (A-MSE: 0.30299) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 2 out of 50
train epoch 1641 avg loss: 0.06437 (A-MSE: 0.05688) avg lploss: 0.00000
train epoch 1642 avg loss: 0.06867 (A-MSE: 0.06096) avg lploss: 0.00000
train epoch 1643 avg loss: 0.06809 (A-MSE: 0.05961) avg lploss: 0.00000
train epoch 1644 avg loss: 0.07159 (A-MSE: 0.06362) avg lploss: 0.00000
train epoch 1645 avg loss: 0.07604 (A-MSE: 0.06804) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.32303 (A-MSE: 0.27920) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.36136 (A-MSE: 0.32119) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 3 out of 50
train epoch 1646 avg loss: 0.08000 (A-MSE: 0.07084) avg lploss: 0.00000
train epoch 1647 avg loss: 0.07623 (A-MSE: 0.06715) avg lploss: 0.00000
train epoch 1648 avg loss: 0.06953 (A-MSE: 0.06236) avg lploss: 0.00000
train epoch 1649 avg loss: 0.07188 (A-MSE: 0.06333) avg lploss: 0.00000
train epoch 1650 avg loss: 0.07296 (A-MSE: 0.06455) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.29975 (A-MSE: 0.26073) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.34141 (A-MSE: 0.30904) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 4 out of 50
train epoch 1651 avg loss: 0.07085 (A-MSE: 0.06244) avg lploss: 0.00000
train epoch 1652 avg loss: 0.07271 (A-MSE: 0.06381) avg lploss: 0.00000
train epoch 1653 avg loss: 0.06837 (A-MSE: 0.06132) avg lploss: 0.00000
train epoch 1654 avg loss: 0.07293 (A-MSE: 0.06478) avg lploss: 0.00000
train epoch 1655 avg loss: 0.07039 (A-MSE: 0.06243) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.32435 (A-MSE: 0.28406) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.36862 (A-MSE: 0.33269) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 5 out of 50
train epoch 1656 avg loss: 0.07064 (A-MSE: 0.06314) avg lploss: 0.00000
train epoch 1657 avg loss: 0.07667 (A-MSE: 0.06845) avg lploss: 0.00000
train epoch 1658 avg loss: 0.07591 (A-MSE: 0.06708) avg lploss: 0.00000
train epoch 1659 avg loss: 0.07527 (A-MSE: 0.06679) avg lploss: 0.00000
train epoch 1660 avg loss: 0.07571 (A-MSE: 0.06654) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.35297 (A-MSE: 0.30321) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.36630 (A-MSE: 0.32605) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 6 out of 50
train epoch 1661 avg loss: 0.07089 (A-MSE: 0.06255) avg lploss: 0.00000
train epoch 1662 avg loss: 0.06975 (A-MSE: 0.06174) avg lploss: 0.00000
train epoch 1663 avg loss: 0.07305 (A-MSE: 0.06510) avg lploss: 0.00000
train epoch 1664 avg loss: 0.07858 (A-MSE: 0.06940) avg lploss: 0.00000
train epoch 1665 avg loss: 0.07099 (A-MSE: 0.06249) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.34346 (A-MSE: 0.29959) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.35475 (A-MSE: 0.31931) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 7 out of 50
train epoch 1666 avg loss: 0.07108 (A-MSE: 0.06285) avg lploss: 0.00000
train epoch 1667 avg loss: 0.06040 (A-MSE: 0.05382) avg lploss: 0.00000
train epoch 1668 avg loss: 0.04945 (A-MSE: 0.04388) avg lploss: 0.00000
train epoch 1669 avg loss: 0.05438 (A-MSE: 0.04786) avg lploss: 0.00000
train epoch 1670 avg loss: 0.06111 (A-MSE: 0.05394) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.29292 (A-MSE: 0.25478) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.33404 (A-MSE: 0.30052) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 8 out of 50
train epoch 1671 avg loss: 0.06499 (A-MSE: 0.05746) avg lploss: 0.00000
train epoch 1672 avg loss: 0.06331 (A-MSE: 0.05611) avg lploss: 0.00000
train epoch 1673 avg loss: 0.06745 (A-MSE: 0.06025) avg lploss: 0.00000
train epoch 1674 avg loss: 0.07399 (A-MSE: 0.06500) avg lploss: 0.00000
train epoch 1675 avg loss: 0.06439 (A-MSE: 0.05623) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.32300 (A-MSE: 0.28180) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.37510 (A-MSE: 0.33838) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 9 out of 50
train epoch 1676 avg loss: 0.06024 (A-MSE: 0.05265) avg lploss: 0.00000
train epoch 1677 avg loss: 0.07197 (A-MSE: 0.06296) avg lploss: 0.00000
train epoch 1678 avg loss: 0.09204 (A-MSE: 0.08206) avg lploss: 0.00000
train epoch 1679 avg loss: 0.09246 (A-MSE: 0.08133) avg lploss: 0.00000
train epoch 1680 avg loss: 0.07798 (A-MSE: 0.06867) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.34220 (A-MSE: 0.28792) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.36789 (A-MSE: 0.32386) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 10 out of 50
train epoch 1681 avg loss: 0.08932 (A-MSE: 0.07857) avg lploss: 0.00000
train epoch 1682 avg loss: 0.10054 (A-MSE: 0.08902) avg lploss: 0.00000
train epoch 1683 avg loss: 0.07997 (A-MSE: 0.07048) avg lploss: 0.00000
train epoch 1684 avg loss: 0.06566 (A-MSE: 0.05848) avg lploss: 0.00000
train epoch 1685 avg loss: 0.05626 (A-MSE: 0.04994) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.34941 (A-MSE: 0.30326) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.35516 (A-MSE: 0.31999) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 11 out of 50
train epoch 1686 avg loss: 0.05858 (A-MSE: 0.05198) avg lploss: 0.00000
train epoch 1687 avg loss: 0.06733 (A-MSE: 0.05967) avg lploss: 0.00000
train epoch 1688 avg loss: 0.06119 (A-MSE: 0.05502) avg lploss: 0.00000
train epoch 1689 avg loss: 0.06233 (A-MSE: 0.05519) avg lploss: 0.00000
train epoch 1690 avg loss: 0.06660 (A-MSE: 0.05906) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.31831 (A-MSE: 0.27601) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.37990 (A-MSE: 0.33786) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 12 out of 50
train epoch 1691 avg loss: 0.07700 (A-MSE: 0.06857) avg lploss: 0.00000
train epoch 1692 avg loss: 0.08876 (A-MSE: 0.07814) avg lploss: 0.00000
train epoch 1693 avg loss: 0.11843 (A-MSE: 0.10569) avg lploss: 0.00000
train epoch 1694 avg loss: 0.11015 (A-MSE: 0.09741) avg lploss: 0.00000
train epoch 1695 avg loss: 0.08294 (A-MSE: 0.07367) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.32177 (A-MSE: 0.27580) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.34949 (A-MSE: 0.31334) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 13 out of 50
train epoch 1696 avg loss: 0.06127 (A-MSE: 0.05459) avg lploss: 0.00000
train epoch 1697 avg loss: 0.07154 (A-MSE: 0.06356) avg lploss: 0.00000
train epoch 1698 avg loss: 0.07385 (A-MSE: 0.06509) avg lploss: 0.00000
train epoch 1699 avg loss: 0.06507 (A-MSE: 0.05707) avg lploss: 0.00000
train epoch 1700 avg loss: 0.07557 (A-MSE: 0.06704) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.35615 (A-MSE: 0.30987) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.38965 (A-MSE: 0.35142) avg lploss: 0.00000
*** Best Val Loss: 0.29219 	 Best Test Loss: 0.31596 	 Best epoch 1630
EarlyStopping counter: 14 out of 50
train epoch 1701 avg loss: 0.08225 (A-MSE: 0.07240) avg lploss: 0.00000
train epoch 1702 avg loss: 0.06073 (A-MSE: 0.05283) avg lploss: 0.00000
train epoch 1703 avg loss: 0.05763 (A-MSE: 0.05122) avg lploss: 0.00000
train epoch 1704 avg loss: 0.05801 (A-MSE: 0.05091) avg lploss: 0.00000
train epoch 1705 avg loss: 0.05582 (A-MSE: 0.04902) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.27994 (A-MSE: 0.24363) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.32837 (A-MSE: 0.29803) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
Validation loss decreased (0.292190 --> 0.279940).  Saving model ...
train epoch 1706 avg loss: 0.05470 (A-MSE: 0.04836) avg lploss: 0.00000
train epoch 1707 avg loss: 0.05701 (A-MSE: 0.05117) avg lploss: 0.00000
train epoch 1708 avg loss: 0.06129 (A-MSE: 0.05462) avg lploss: 0.00000
train epoch 1709 avg loss: 0.06572 (A-MSE: 0.05804) avg lploss: 0.00000
train epoch 1710 avg loss: 0.07416 (A-MSE: 0.06561) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.37533 (A-MSE: 0.32133) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.38998 (A-MSE: 0.34758) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 1 out of 50
train epoch 1711 avg loss: 0.07014 (A-MSE: 0.06129) avg lploss: 0.00000
train epoch 1712 avg loss: 0.06612 (A-MSE: 0.05834) avg lploss: 0.00000
train epoch 1713 avg loss: 0.05960 (A-MSE: 0.05236) avg lploss: 0.00000
train epoch 1714 avg loss: 0.06478 (A-MSE: 0.05735) avg lploss: 0.00000
train epoch 1715 avg loss: 0.06380 (A-MSE: 0.05667) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.28551 (A-MSE: 0.24818) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.32548 (A-MSE: 0.29260) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 2 out of 50
train epoch 1716 avg loss: 0.06380 (A-MSE: 0.05666) avg lploss: 0.00000
train epoch 1717 avg loss: 0.07292 (A-MSE: 0.06502) avg lploss: 0.00000
train epoch 1718 avg loss: 0.06979 (A-MSE: 0.06131) avg lploss: 0.00000
train epoch 1719 avg loss: 0.05497 (A-MSE: 0.04875) avg lploss: 0.00000
train epoch 1720 avg loss: 0.05800 (A-MSE: 0.05076) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.29881 (A-MSE: 0.26134) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.33627 (A-MSE: 0.30563) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 3 out of 50
train epoch 1721 avg loss: 0.05781 (A-MSE: 0.05141) avg lploss: 0.00000
train epoch 1722 avg loss: 0.05258 (A-MSE: 0.04657) avg lploss: 0.00000
train epoch 1723 avg loss: 0.06520 (A-MSE: 0.05767) avg lploss: 0.00000
train epoch 1724 avg loss: 0.06266 (A-MSE: 0.05545) avg lploss: 0.00000
train epoch 1725 avg loss: 0.05392 (A-MSE: 0.04803) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.33566 (A-MSE: 0.29014) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.36290 (A-MSE: 0.32654) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 4 out of 50
train epoch 1726 avg loss: 0.06074 (A-MSE: 0.05333) avg lploss: 0.00000
train epoch 1727 avg loss: 0.06821 (A-MSE: 0.06067) avg lploss: 0.00000
train epoch 1728 avg loss: 0.06593 (A-MSE: 0.05821) avg lploss: 0.00000
train epoch 1729 avg loss: 0.06157 (A-MSE: 0.05431) avg lploss: 0.00000
train epoch 1730 avg loss: 0.06267 (A-MSE: 0.05536) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.29823 (A-MSE: 0.25724) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.34160 (A-MSE: 0.30785) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 5 out of 50
train epoch 1731 avg loss: 0.07660 (A-MSE: 0.06809) avg lploss: 0.00000
train epoch 1732 avg loss: 0.08987 (A-MSE: 0.08073) avg lploss: 0.00000
train epoch 1733 avg loss: 0.06921 (A-MSE: 0.06152) avg lploss: 0.00000
train epoch 1734 avg loss: 0.07530 (A-MSE: 0.06624) avg lploss: 0.00000
train epoch 1735 avg loss: 0.06333 (A-MSE: 0.05553) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.32849 (A-MSE: 0.27904) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.34896 (A-MSE: 0.30742) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 6 out of 50
train epoch 1736 avg loss: 0.06082 (A-MSE: 0.05284) avg lploss: 0.00000
train epoch 1737 avg loss: 0.05845 (A-MSE: 0.05158) avg lploss: 0.00000
train epoch 1738 avg loss: 0.05420 (A-MSE: 0.04752) avg lploss: 0.00000
train epoch 1739 avg loss: 0.05462 (A-MSE: 0.04824) avg lploss: 0.00000
train epoch 1740 avg loss: 0.07405 (A-MSE: 0.06596) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.41656 (A-MSE: 0.35394) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.41986 (A-MSE: 0.37169) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 7 out of 50
train epoch 1741 avg loss: 0.07308 (A-MSE: 0.06423) avg lploss: 0.00000
train epoch 1742 avg loss: 0.06640 (A-MSE: 0.05907) avg lploss: 0.00000
train epoch 1743 avg loss: 0.06166 (A-MSE: 0.05452) avg lploss: 0.00000
train epoch 1744 avg loss: 0.05951 (A-MSE: 0.05289) avg lploss: 0.00000
train epoch 1745 avg loss: 0.05151 (A-MSE: 0.04531) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.28992 (A-MSE: 0.25046) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.33111 (A-MSE: 0.29652) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 8 out of 50
train epoch 1746 avg loss: 0.05724 (A-MSE: 0.05063) avg lploss: 0.00000
train epoch 1747 avg loss: 0.06011 (A-MSE: 0.05317) avg lploss: 0.00000
train epoch 1748 avg loss: 0.08035 (A-MSE: 0.07134) avg lploss: 0.00000
train epoch 1749 avg loss: 0.07824 (A-MSE: 0.06927) avg lploss: 0.00000
train epoch 1750 avg loss: 0.07677 (A-MSE: 0.06791) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.31359 (A-MSE: 0.27031) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.34860 (A-MSE: 0.31185) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 9 out of 50
train epoch 1751 avg loss: 0.06518 (A-MSE: 0.05794) avg lploss: 0.00000
train epoch 1752 avg loss: 0.08258 (A-MSE: 0.07328) avg lploss: 0.00000
train epoch 1753 avg loss: 0.08607 (A-MSE: 0.07544) avg lploss: 0.00000
train epoch 1754 avg loss: 0.09069 (A-MSE: 0.08097) avg lploss: 0.00000
train epoch 1755 avg loss: 0.07062 (A-MSE: 0.06251) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.33179 (A-MSE: 0.28813) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.35251 (A-MSE: 0.31728) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 10 out of 50
train epoch 1756 avg loss: 0.06142 (A-MSE: 0.05450) avg lploss: 0.00000
train epoch 1757 avg loss: 0.06908 (A-MSE: 0.06034) avg lploss: 0.00000
train epoch 1758 avg loss: 0.07880 (A-MSE: 0.06999) avg lploss: 0.00000
train epoch 1759 avg loss: 0.06618 (A-MSE: 0.05845) avg lploss: 0.00000
train epoch 1760 avg loss: 0.06666 (A-MSE: 0.05896) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.34759 (A-MSE: 0.30185) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.38203 (A-MSE: 0.34181) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 11 out of 50
train epoch 1761 avg loss: 0.06801 (A-MSE: 0.06012) avg lploss: 0.00000
train epoch 1762 avg loss: 0.06713 (A-MSE: 0.05899) avg lploss: 0.00000
train epoch 1763 avg loss: 0.05281 (A-MSE: 0.04642) avg lploss: 0.00000
train epoch 1764 avg loss: 0.04545 (A-MSE: 0.04008) avg lploss: 0.00000
train epoch 1765 avg loss: 0.04985 (A-MSE: 0.04446) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.30342 (A-MSE: 0.26202) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.34795 (A-MSE: 0.31153) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 12 out of 50
train epoch 1766 avg loss: 0.04657 (A-MSE: 0.04088) avg lploss: 0.00000
train epoch 1767 avg loss: 0.04692 (A-MSE: 0.04110) avg lploss: 0.00000
train epoch 1768 avg loss: 0.06285 (A-MSE: 0.05523) avg lploss: 0.00000
train epoch 1769 avg loss: 0.06298 (A-MSE: 0.05603) avg lploss: 0.00000
train epoch 1770 avg loss: 0.05717 (A-MSE: 0.05045) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.32851 (A-MSE: 0.28383) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.35288 (A-MSE: 0.31558) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 13 out of 50
train epoch 1771 avg loss: 0.05490 (A-MSE: 0.04865) avg lploss: 0.00000
train epoch 1772 avg loss: 0.06778 (A-MSE: 0.05990) avg lploss: 0.00000
train epoch 1773 avg loss: 0.05696 (A-MSE: 0.05011) avg lploss: 0.00000
train epoch 1774 avg loss: 0.05463 (A-MSE: 0.04849) avg lploss: 0.00000
train epoch 1775 avg loss: 0.05364 (A-MSE: 0.04760) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.41348 (A-MSE: 0.36151) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.42586 (A-MSE: 0.38331) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 14 out of 50
train epoch 1776 avg loss: 0.05272 (A-MSE: 0.04651) avg lploss: 0.00000
train epoch 1777 avg loss: 0.05410 (A-MSE: 0.04794) avg lploss: 0.00000
train epoch 1778 avg loss: 0.05746 (A-MSE: 0.05072) avg lploss: 0.00000
train epoch 1779 avg loss: 0.06030 (A-MSE: 0.05390) avg lploss: 0.00000
train epoch 1780 avg loss: 0.06500 (A-MSE: 0.05784) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.34782 (A-MSE: 0.29739) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.36959 (A-MSE: 0.32737) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 15 out of 50
train epoch 1781 avg loss: 0.05685 (A-MSE: 0.04965) avg lploss: 0.00000
train epoch 1782 avg loss: 0.05285 (A-MSE: 0.04662) avg lploss: 0.00000
train epoch 1783 avg loss: 0.06204 (A-MSE: 0.05517) avg lploss: 0.00000
train epoch 1784 avg loss: 0.06286 (A-MSE: 0.05541) avg lploss: 0.00000
train epoch 1785 avg loss: 0.05212 (A-MSE: 0.04568) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.32505 (A-MSE: 0.28531) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.36204 (A-MSE: 0.32827) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 16 out of 50
train epoch 1786 avg loss: 0.05255 (A-MSE: 0.04656) avg lploss: 0.00000
train epoch 1787 avg loss: 0.05216 (A-MSE: 0.04645) avg lploss: 0.00000
train epoch 1788 avg loss: 0.05758 (A-MSE: 0.05052) avg lploss: 0.00000
train epoch 1789 avg loss: 0.05035 (A-MSE: 0.04433) avg lploss: 0.00000
train epoch 1790 avg loss: 0.05367 (A-MSE: 0.04777) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.30113 (A-MSE: 0.26152) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.34137 (A-MSE: 0.30849) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 17 out of 50
train epoch 1791 avg loss: 0.04715 (A-MSE: 0.04212) avg lploss: 0.00000
train epoch 1792 avg loss: 0.06366 (A-MSE: 0.05603) avg lploss: 0.00000
train epoch 1793 avg loss: 0.05691 (A-MSE: 0.05030) avg lploss: 0.00000
train epoch 1794 avg loss: 0.10024 (A-MSE: 0.08881) avg lploss: 0.00000
train epoch 1795 avg loss: 0.11089 (A-MSE: 0.09803) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.43444 (A-MSE: 0.38497) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.44231 (A-MSE: 0.40317) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 18 out of 50
train epoch 1796 avg loss: 0.09257 (A-MSE: 0.08231) avg lploss: 0.00000
train epoch 1797 avg loss: 0.07600 (A-MSE: 0.06713) avg lploss: 0.00000
train epoch 1798 avg loss: 0.06602 (A-MSE: 0.05849) avg lploss: 0.00000
train epoch 1799 avg loss: 0.06083 (A-MSE: 0.05406) avg lploss: 0.00000
train epoch 1800 avg loss: 0.05641 (A-MSE: 0.05032) avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.29462 (A-MSE: 0.25512) avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.33888 (A-MSE: 0.30504) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 19 out of 50
train epoch 1801 avg loss: 0.05805 (A-MSE: 0.05129) avg lploss: 0.00000
train epoch 1802 avg loss: 0.05669 (A-MSE: 0.05026) avg lploss: 0.00000
train epoch 1803 avg loss: 0.05513 (A-MSE: 0.04853) avg lploss: 0.00000
train epoch 1804 avg loss: 0.07271 (A-MSE: 0.06426) avg lploss: 0.00000
train epoch 1805 avg loss: 0.09582 (A-MSE: 0.08391) avg lploss: 0.00000
==> val epoch 1805 avg loss: 0.32418 (A-MSE: 0.27901) avg lploss: 0.00000
==> test epoch 1805 avg loss: 0.38150 (A-MSE: 0.33952) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 20 out of 50
train epoch 1806 avg loss: 0.07543 (A-MSE: 0.06673) avg lploss: 0.00000
train epoch 1807 avg loss: 0.08102 (A-MSE: 0.07249) avg lploss: 0.00000
train epoch 1808 avg loss: 0.06002 (A-MSE: 0.05336) avg lploss: 0.00000
train epoch 1809 avg loss: 0.05754 (A-MSE: 0.05071) avg lploss: 0.00000
train epoch 1810 avg loss: 0.04708 (A-MSE: 0.04174) avg lploss: 0.00000
==> val epoch 1810 avg loss: 0.32419 (A-MSE: 0.28132) avg lploss: 0.00000
==> test epoch 1810 avg loss: 0.35102 (A-MSE: 0.31469) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 21 out of 50
train epoch 1811 avg loss: 0.04428 (A-MSE: 0.03917) avg lploss: 0.00000
train epoch 1812 avg loss: 0.05322 (A-MSE: 0.04707) avg lploss: 0.00000
train epoch 1813 avg loss: 0.05384 (A-MSE: 0.04756) avg lploss: 0.00000
train epoch 1814 avg loss: 0.05630 (A-MSE: 0.04993) avg lploss: 0.00000
train epoch 1815 avg loss: 0.07365 (A-MSE: 0.06580) avg lploss: 0.00000
==> val epoch 1815 avg loss: 0.32099 (A-MSE: 0.27809) avg lploss: 0.00000
==> test epoch 1815 avg loss: 0.36146 (A-MSE: 0.32513) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 22 out of 50
train epoch 1816 avg loss: 0.06513 (A-MSE: 0.05719) avg lploss: 0.00000
train epoch 1817 avg loss: 0.07060 (A-MSE: 0.06229) avg lploss: 0.00000
train epoch 1818 avg loss: 0.06741 (A-MSE: 0.05971) avg lploss: 0.00000
train epoch 1819 avg loss: 0.05533 (A-MSE: 0.04874) avg lploss: 0.00000
train epoch 1820 avg loss: 0.06309 (A-MSE: 0.05538) avg lploss: 0.00000
==> val epoch 1820 avg loss: 0.32591 (A-MSE: 0.28448) avg lploss: 0.00000
==> test epoch 1820 avg loss: 0.34264 (A-MSE: 0.30765) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 23 out of 50
train epoch 1821 avg loss: 0.05463 (A-MSE: 0.04877) avg lploss: 0.00000
train epoch 1822 avg loss: 0.05303 (A-MSE: 0.04647) avg lploss: 0.00000
train epoch 1823 avg loss: 0.04619 (A-MSE: 0.04107) avg lploss: 0.00000
train epoch 1824 avg loss: 0.06027 (A-MSE: 0.05306) avg lploss: 0.00000
train epoch 1825 avg loss: 0.05848 (A-MSE: 0.05168) avg lploss: 0.00000
==> val epoch 1825 avg loss: 0.33624 (A-MSE: 0.29199) avg lploss: 0.00000
==> test epoch 1825 avg loss: 0.35739 (A-MSE: 0.31959) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 24 out of 50
train epoch 1826 avg loss: 0.05922 (A-MSE: 0.05160) avg lploss: 0.00000
train epoch 1827 avg loss: 0.05495 (A-MSE: 0.04945) avg lploss: 0.00000
train epoch 1828 avg loss: 0.05562 (A-MSE: 0.04896) avg lploss: 0.00000
train epoch 1829 avg loss: 0.04487 (A-MSE: 0.03961) avg lploss: 0.00000
train epoch 1830 avg loss: 0.04416 (A-MSE: 0.03901) avg lploss: 0.00000
==> val epoch 1830 avg loss: 0.31176 (A-MSE: 0.27065) avg lploss: 0.00000
==> test epoch 1830 avg loss: 0.35678 (A-MSE: 0.32026) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 25 out of 50
train epoch 1831 avg loss: 0.04668 (A-MSE: 0.04077) avg lploss: 0.00000
train epoch 1832 avg loss: 0.04625 (A-MSE: 0.04055) avg lploss: 0.00000
train epoch 1833 avg loss: 0.04234 (A-MSE: 0.03735) avg lploss: 0.00000
train epoch 1834 avg loss: 0.04768 (A-MSE: 0.04223) avg lploss: 0.00000
train epoch 1835 avg loss: 0.05682 (A-MSE: 0.05128) avg lploss: 0.00000
==> val epoch 1835 avg loss: 0.32828 (A-MSE: 0.28770) avg lploss: 0.00000
==> test epoch 1835 avg loss: 0.36746 (A-MSE: 0.33271) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 26 out of 50
train epoch 1836 avg loss: 0.05528 (A-MSE: 0.04890) avg lploss: 0.00000
train epoch 1837 avg loss: 0.05508 (A-MSE: 0.04801) avg lploss: 0.00000
train epoch 1838 avg loss: 0.05786 (A-MSE: 0.05090) avg lploss: 0.00000
train epoch 1839 avg loss: 0.05365 (A-MSE: 0.04738) avg lploss: 0.00000
train epoch 1840 avg loss: 0.04571 (A-MSE: 0.04065) avg lploss: 0.00000
==> val epoch 1840 avg loss: 0.31835 (A-MSE: 0.27580) avg lploss: 0.00000
==> test epoch 1840 avg loss: 0.33821 (A-MSE: 0.30262) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 27 out of 50
train epoch 1841 avg loss: 0.04924 (A-MSE: 0.04331) avg lploss: 0.00000
train epoch 1842 avg loss: 0.07090 (A-MSE: 0.06224) avg lploss: 0.00000
train epoch 1843 avg loss: 0.05685 (A-MSE: 0.05029) avg lploss: 0.00000
train epoch 1844 avg loss: 0.07974 (A-MSE: 0.07067) avg lploss: 0.00000
train epoch 1845 avg loss: 0.06270 (A-MSE: 0.05575) avg lploss: 0.00000
==> val epoch 1845 avg loss: 0.34659 (A-MSE: 0.30005) avg lploss: 0.00000
==> test epoch 1845 avg loss: 0.40081 (A-MSE: 0.35940) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 28 out of 50
train epoch 1846 avg loss: 0.07012 (A-MSE: 0.06204) avg lploss: 0.00000
train epoch 1847 avg loss: 0.05729 (A-MSE: 0.05100) avg lploss: 0.00000
train epoch 1848 avg loss: 0.04796 (A-MSE: 0.04244) avg lploss: 0.00000
train epoch 1849 avg loss: 0.05012 (A-MSE: 0.04441) avg lploss: 0.00000
train epoch 1850 avg loss: 0.04824 (A-MSE: 0.04246) avg lploss: 0.00000
==> val epoch 1850 avg loss: 0.31300 (A-MSE: 0.27005) avg lploss: 0.00000
==> test epoch 1850 avg loss: 0.33413 (A-MSE: 0.29991) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 29 out of 50
train epoch 1851 avg loss: 0.04641 (A-MSE: 0.04090) avg lploss: 0.00000
train epoch 1852 avg loss: 0.04532 (A-MSE: 0.04032) avg lploss: 0.00000
train epoch 1853 avg loss: 0.04310 (A-MSE: 0.03828) avg lploss: 0.00000
train epoch 1854 avg loss: 0.04144 (A-MSE: 0.03681) avg lploss: 0.00000
train epoch 1855 avg loss: 0.05041 (A-MSE: 0.04449) avg lploss: 0.00000
==> val epoch 1855 avg loss: 0.34258 (A-MSE: 0.29207) avg lploss: 0.00000
==> test epoch 1855 avg loss: 0.36302 (A-MSE: 0.32204) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 30 out of 50
train epoch 1856 avg loss: 0.05719 (A-MSE: 0.05043) avg lploss: 0.00000
train epoch 1857 avg loss: 0.05903 (A-MSE: 0.05239) avg lploss: 0.00000
train epoch 1858 avg loss: 0.06153 (A-MSE: 0.05476) avg lploss: 0.00000
train epoch 1859 avg loss: 0.05928 (A-MSE: 0.05249) avg lploss: 0.00000
train epoch 1860 avg loss: 0.05987 (A-MSE: 0.05263) avg lploss: 0.00000
==> val epoch 1860 avg loss: 0.30198 (A-MSE: 0.26424) avg lploss: 0.00000
==> test epoch 1860 avg loss: 0.34746 (A-MSE: 0.31211) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 31 out of 50
train epoch 1861 avg loss: 0.07396 (A-MSE: 0.06569) avg lploss: 0.00000
train epoch 1862 avg loss: 0.09387 (A-MSE: 0.08256) avg lploss: 0.00000
train epoch 1863 avg loss: 0.10601 (A-MSE: 0.09445) avg lploss: 0.00000
train epoch 1864 avg loss: 0.08168 (A-MSE: 0.07273) avg lploss: 0.00000
train epoch 1865 avg loss: 0.05612 (A-MSE: 0.05017) avg lploss: 0.00000
==> val epoch 1865 avg loss: 0.35861 (A-MSE: 0.31651) avg lploss: 0.00000
==> test epoch 1865 avg loss: 0.36935 (A-MSE: 0.33341) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 32 out of 50
train epoch 1866 avg loss: 0.06214 (A-MSE: 0.05449) avg lploss: 0.00000
train epoch 1867 avg loss: 0.04623 (A-MSE: 0.04124) avg lploss: 0.00000
train epoch 1868 avg loss: 0.04854 (A-MSE: 0.04315) avg lploss: 0.00000
train epoch 1869 avg loss: 0.05558 (A-MSE: 0.04838) avg lploss: 0.00000
train epoch 1870 avg loss: 0.05633 (A-MSE: 0.05045) avg lploss: 0.00000
==> val epoch 1870 avg loss: 0.34677 (A-MSE: 0.29793) avg lploss: 0.00000
==> test epoch 1870 avg loss: 0.36683 (A-MSE: 0.32708) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 33 out of 50
train epoch 1871 avg loss: 0.04558 (A-MSE: 0.04019) avg lploss: 0.00000
train epoch 1872 avg loss: 0.04884 (A-MSE: 0.04273) avg lploss: 0.00000
train epoch 1873 avg loss: 0.05379 (A-MSE: 0.04799) avg lploss: 0.00000
train epoch 1874 avg loss: 0.05412 (A-MSE: 0.04842) avg lploss: 0.00000
train epoch 1875 avg loss: 0.05265 (A-MSE: 0.04654) avg lploss: 0.00000
==> val epoch 1875 avg loss: 0.35587 (A-MSE: 0.31154) avg lploss: 0.00000
==> test epoch 1875 avg loss: 0.39091 (A-MSE: 0.35168) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 34 out of 50
train epoch 1876 avg loss: 0.05361 (A-MSE: 0.04743) avg lploss: 0.00000
train epoch 1877 avg loss: 0.05331 (A-MSE: 0.04660) avg lploss: 0.00000
train epoch 1878 avg loss: 0.04887 (A-MSE: 0.04303) avg lploss: 0.00000
train epoch 1879 avg loss: 0.05530 (A-MSE: 0.04910) avg lploss: 0.00000
train epoch 1880 avg loss: 0.04825 (A-MSE: 0.04206) avg lploss: 0.00000
==> val epoch 1880 avg loss: 0.33201 (A-MSE: 0.28895) avg lploss: 0.00000
==> test epoch 1880 avg loss: 0.35363 (A-MSE: 0.31577) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 35 out of 50
train epoch 1881 avg loss: 0.05340 (A-MSE: 0.04711) avg lploss: 0.00000
train epoch 1882 avg loss: 0.05133 (A-MSE: 0.04556) avg lploss: 0.00000
train epoch 1883 avg loss: 0.04963 (A-MSE: 0.04364) avg lploss: 0.00000
train epoch 1884 avg loss: 0.04158 (A-MSE: 0.03680) avg lploss: 0.00000
train epoch 1885 avg loss: 0.03871 (A-MSE: 0.03404) avg lploss: 0.00000
==> val epoch 1885 avg loss: 0.30205 (A-MSE: 0.26206) avg lploss: 0.00000
==> test epoch 1885 avg loss: 0.34442 (A-MSE: 0.30861) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 36 out of 50
train epoch 1886 avg loss: 0.03906 (A-MSE: 0.03469) avg lploss: 0.00000
train epoch 1887 avg loss: 0.03914 (A-MSE: 0.03459) avg lploss: 0.00000
train epoch 1888 avg loss: 0.04102 (A-MSE: 0.03603) avg lploss: 0.00000
train epoch 1889 avg loss: 0.04859 (A-MSE: 0.04283) avg lploss: 0.00000
train epoch 1890 avg loss: 0.03755 (A-MSE: 0.03280) avg lploss: 0.00000
==> val epoch 1890 avg loss: 0.32537 (A-MSE: 0.28316) avg lploss: 0.00000
==> test epoch 1890 avg loss: 0.35827 (A-MSE: 0.32243) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 37 out of 50
train epoch 1891 avg loss: 0.03773 (A-MSE: 0.03375) avg lploss: 0.00000
train epoch 1892 avg loss: 0.04191 (A-MSE: 0.03660) avg lploss: 0.00000
train epoch 1893 avg loss: 0.04154 (A-MSE: 0.03652) avg lploss: 0.00000
train epoch 1894 avg loss: 0.04989 (A-MSE: 0.04406) avg lploss: 0.00000
train epoch 1895 avg loss: 0.05313 (A-MSE: 0.04767) avg lploss: 0.00000
==> val epoch 1895 avg loss: 0.32745 (A-MSE: 0.28216) avg lploss: 0.00000
==> test epoch 1895 avg loss: 0.34720 (A-MSE: 0.31125) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 38 out of 50
train epoch 1896 avg loss: 0.06600 (A-MSE: 0.05866) avg lploss: 0.00000
train epoch 1897 avg loss: 0.06760 (A-MSE: 0.05996) avg lploss: 0.00000
train epoch 1898 avg loss: 0.05802 (A-MSE: 0.05123) avg lploss: 0.00000
train epoch 1899 avg loss: 0.04767 (A-MSE: 0.04171) avg lploss: 0.00000
train epoch 1900 avg loss: 0.04303 (A-MSE: 0.03778) avg lploss: 0.00000
==> val epoch 1900 avg loss: 0.29467 (A-MSE: 0.25523) avg lploss: 0.00000
==> test epoch 1900 avg loss: 0.33887 (A-MSE: 0.30522) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 39 out of 50
train epoch 1901 avg loss: 0.05052 (A-MSE: 0.04520) avg lploss: 0.00000
train epoch 1902 avg loss: 0.05373 (A-MSE: 0.04766) avg lploss: 0.00000
train epoch 1903 avg loss: 0.05556 (A-MSE: 0.04870) avg lploss: 0.00000
train epoch 1904 avg loss: 0.04981 (A-MSE: 0.04367) avg lploss: 0.00000
train epoch 1905 avg loss: 0.05199 (A-MSE: 0.04601) avg lploss: 0.00000
==> val epoch 1905 avg loss: 0.31109 (A-MSE: 0.27128) avg lploss: 0.00000
==> test epoch 1905 avg loss: 0.34426 (A-MSE: 0.31035) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 40 out of 50
train epoch 1906 avg loss: 0.04190 (A-MSE: 0.03710) avg lploss: 0.00000
train epoch 1907 avg loss: 0.04482 (A-MSE: 0.03981) avg lploss: 0.00000
train epoch 1908 avg loss: 0.04259 (A-MSE: 0.03712) avg lploss: 0.00000
train epoch 1909 avg loss: 0.04124 (A-MSE: 0.03650) avg lploss: 0.00000
train epoch 1910 avg loss: 0.03974 (A-MSE: 0.03578) avg lploss: 0.00000
==> val epoch 1910 avg loss: 0.29114 (A-MSE: 0.25146) avg lploss: 0.00000
==> test epoch 1910 avg loss: 0.33795 (A-MSE: 0.30129) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 41 out of 50
train epoch 1911 avg loss: 0.04027 (A-MSE: 0.03487) avg lploss: 0.00000
train epoch 1912 avg loss: 0.03563 (A-MSE: 0.03119) avg lploss: 0.00000
train epoch 1913 avg loss: 0.03642 (A-MSE: 0.03220) avg lploss: 0.00000
train epoch 1914 avg loss: 0.04004 (A-MSE: 0.03568) avg lploss: 0.00000
train epoch 1915 avg loss: 0.04378 (A-MSE: 0.03881) avg lploss: 0.00000
==> val epoch 1915 avg loss: 0.32223 (A-MSE: 0.27988) avg lploss: 0.00000
==> test epoch 1915 avg loss: 0.35805 (A-MSE: 0.32225) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 42 out of 50
train epoch 1916 avg loss: 0.04233 (A-MSE: 0.03690) avg lploss: 0.00000
train epoch 1917 avg loss: 0.03794 (A-MSE: 0.03354) avg lploss: 0.00000
train epoch 1918 avg loss: 0.03449 (A-MSE: 0.03020) avg lploss: 0.00000
train epoch 1919 avg loss: 0.03528 (A-MSE: 0.03088) avg lploss: 0.00000
train epoch 1920 avg loss: 0.03508 (A-MSE: 0.03085) avg lploss: 0.00000
==> val epoch 1920 avg loss: 0.31849 (A-MSE: 0.27565) avg lploss: 0.00000
==> test epoch 1920 avg loss: 0.35656 (A-MSE: 0.32085) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 43 out of 50
train epoch 1921 avg loss: 0.04268 (A-MSE: 0.03819) avg lploss: 0.00000
train epoch 1922 avg loss: 0.05057 (A-MSE: 0.04472) avg lploss: 0.00000
train epoch 1923 avg loss: 0.05738 (A-MSE: 0.05163) avg lploss: 0.00000
train epoch 1924 avg loss: 0.06213 (A-MSE: 0.05443) avg lploss: 0.00000
train epoch 1925 avg loss: 0.06076 (A-MSE: 0.05439) avg lploss: 0.00000
==> val epoch 1925 avg loss: 0.38586 (A-MSE: 0.33857) avg lploss: 0.00000
==> test epoch 1925 avg loss: 0.42016 (A-MSE: 0.37998) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 44 out of 50
train epoch 1926 avg loss: 0.06394 (A-MSE: 0.05632) avg lploss: 0.00000
train epoch 1927 avg loss: 0.06461 (A-MSE: 0.05692) avg lploss: 0.00000
train epoch 1928 avg loss: 0.07141 (A-MSE: 0.06361) avg lploss: 0.00000
train epoch 1929 avg loss: 0.07257 (A-MSE: 0.06581) avg lploss: 0.00000
train epoch 1930 avg loss: 0.05412 (A-MSE: 0.04755) avg lploss: 0.00000
==> val epoch 1930 avg loss: 0.34669 (A-MSE: 0.30106) avg lploss: 0.00000
==> test epoch 1930 avg loss: 0.36198 (A-MSE: 0.32548) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 45 out of 50
train epoch 1931 avg loss: 0.04692 (A-MSE: 0.04093) avg lploss: 0.00000
train epoch 1932 avg loss: 0.06535 (A-MSE: 0.05808) avg lploss: 0.00000
train epoch 1933 avg loss: 0.05514 (A-MSE: 0.04904) avg lploss: 0.00000
train epoch 1934 avg loss: 0.05442 (A-MSE: 0.04804) avg lploss: 0.00000
train epoch 1935 avg loss: 0.05200 (A-MSE: 0.04582) avg lploss: 0.00000
==> val epoch 1935 avg loss: 0.33438 (A-MSE: 0.29110) avg lploss: 0.00000
==> test epoch 1935 avg loss: 0.37258 (A-MSE: 0.33472) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 46 out of 50
train epoch 1936 avg loss: 0.05675 (A-MSE: 0.04951) avg lploss: 0.00000
train epoch 1937 avg loss: 0.05511 (A-MSE: 0.04906) avg lploss: 0.00000
train epoch 1938 avg loss: 0.05754 (A-MSE: 0.05049) avg lploss: 0.00000
train epoch 1939 avg loss: 0.04658 (A-MSE: 0.04145) avg lploss: 0.00000
train epoch 1940 avg loss: 0.04479 (A-MSE: 0.03915) avg lploss: 0.00000
==> val epoch 1940 avg loss: 0.33175 (A-MSE: 0.28958) avg lploss: 0.00000
==> test epoch 1940 avg loss: 0.37591 (A-MSE: 0.33813) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 47 out of 50
train epoch 1941 avg loss: 0.03759 (A-MSE: 0.03312) avg lploss: 0.00000
train epoch 1942 avg loss: 0.03270 (A-MSE: 0.02885) avg lploss: 0.00000
train epoch 1943 avg loss: 0.03924 (A-MSE: 0.03428) avg lploss: 0.00000
train epoch 1944 avg loss: 0.03792 (A-MSE: 0.03365) avg lploss: 0.00000
train epoch 1945 avg loss: 0.03907 (A-MSE: 0.03467) avg lploss: 0.00000
==> val epoch 1945 avg loss: 0.31448 (A-MSE: 0.26996) avg lploss: 0.00000
==> test epoch 1945 avg loss: 0.33693 (A-MSE: 0.30158) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 48 out of 50
train epoch 1946 avg loss: 0.05073 (A-MSE: 0.04521) avg lploss: 0.00000
train epoch 1947 avg loss: 0.06847 (A-MSE: 0.06044) avg lploss: 0.00000
train epoch 1948 avg loss: 0.06098 (A-MSE: 0.05406) avg lploss: 0.00000
train epoch 1949 avg loss: 0.05624 (A-MSE: 0.05029) avg lploss: 0.00000
train epoch 1950 avg loss: 0.05761 (A-MSE: 0.05081) avg lploss: 0.00000
==> val epoch 1950 avg loss: 0.30615 (A-MSE: 0.26260) avg lploss: 0.00000
==> test epoch 1950 avg loss: 0.33980 (A-MSE: 0.30207) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 49 out of 50
train epoch 1951 avg loss: 0.05794 (A-MSE: 0.05107) avg lploss: 0.00000
train epoch 1952 avg loss: 0.05226 (A-MSE: 0.04644) avg lploss: 0.00000
train epoch 1953 avg loss: 0.05066 (A-MSE: 0.04486) avg lploss: 0.00000
train epoch 1954 avg loss: 0.04354 (A-MSE: 0.03842) avg lploss: 0.00000
train epoch 1955 avg loss: 0.05172 (A-MSE: 0.04554) avg lploss: 0.00000
==> val epoch 1955 avg loss: 0.30282 (A-MSE: 0.26437) avg lploss: 0.00000
==> test epoch 1955 avg loss: 0.34555 (A-MSE: 0.31389) avg lploss: 0.00000
*** Best Val Loss: 0.27994 	 Best Test Loss: 0.32837 	 Best epoch 1705
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.055824
best_lp = 0.000000
best_val = 0.279940
best_test = 0.328375
best_epoch = 1705
best_train = 0.055824, best_lp = 0.000000, best_val = 0.279940, best_test = 0.328375, best_epoch = 1705
Training completed for seed 3 with num_modes=1
