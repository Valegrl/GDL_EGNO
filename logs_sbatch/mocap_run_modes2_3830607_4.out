Running Mocap-Run with num_modes=2 for seed 4
Job ID: 3831017, Array Task ID: 4
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes2_seed4.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes2_seed4', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes2_seed4/saved_model.pth
train epoch 0 avg loss: 214916.88657 (A-MSE: 196493.16886) avg lploss: 0.00000
==> val epoch 0 avg loss: 88.93688 (A-MSE: 78.28187) avg lploss: 0.00000
==> test epoch 0 avg loss: 84.73430 (A-MSE: 74.58913) avg lploss: 0.00000
*** Best Val Loss: 88.93688 	 Best Test Loss: 84.73430 	 Best epoch 0
Validation loss decreased (inf --> 88.936876).  Saving model ...
train epoch 1 avg loss: 85.81437 (A-MSE: 75.59186) avg lploss: 0.00000
train epoch 2 avg loss: 83.80710 (A-MSE: 73.82320) avg lploss: 0.00000
train epoch 3 avg loss: 80.25924 (A-MSE: 70.75879) avg lploss: 0.00000
train epoch 4 avg loss: 69.65228 (A-MSE: 61.04781) avg lploss: 0.00000
train epoch 5 avg loss: 51.34568 (A-MSE: 44.73028) avg lploss: 0.00000
==> val epoch 5 avg loss: 43.41387 (A-MSE: 37.84631) avg lploss: 0.00000
==> test epoch 5 avg loss: 40.90501 (A-MSE: 35.68075) avg lploss: 0.00000
*** Best Val Loss: 43.41387 	 Best Test Loss: 40.90501 	 Best epoch 5
Validation loss decreased (88.936876 --> 43.413865).  Saving model ...
train epoch 6 avg loss: 39.83116 (A-MSE: 34.53508) avg lploss: 0.00000
train epoch 7 avg loss: 33.88664 (A-MSE: 29.37022) avg lploss: 0.00000
train epoch 8 avg loss: 29.89215 (A-MSE: 25.84841) avg lploss: 0.00000
train epoch 9 avg loss: 27.35239 (A-MSE: 23.68053) avg lploss: 0.00000
train epoch 10 avg loss: 25.76648 (A-MSE: 22.37873) avg lploss: 0.00000
==> val epoch 10 avg loss: 25.32028 (A-MSE: 21.74864) avg lploss: 0.00000
==> test epoch 10 avg loss: 23.90630 (A-MSE: 20.47596) avg lploss: 0.00000
*** Best Val Loss: 25.32028 	 Best Test Loss: 23.90630 	 Best epoch 10
Validation loss decreased (43.413865 --> 25.320280).  Saving model ...
train epoch 11 avg loss: 24.38065 (A-MSE: 21.04696) avg lploss: 0.00000
train epoch 12 avg loss: 23.50078 (A-MSE: 20.36953) avg lploss: 0.00000
train epoch 13 avg loss: 22.34602 (A-MSE: 19.35677) avg lploss: 0.00000
train epoch 14 avg loss: 20.94554 (A-MSE: 18.15176) avg lploss: 0.00000
train epoch 15 avg loss: 20.27809 (A-MSE: 17.57990) avg lploss: 0.00000
==> val epoch 15 avg loss: 19.33599 (A-MSE: 16.58551) avg lploss: 0.00000
==> test epoch 15 avg loss: 18.33775 (A-MSE: 15.65812) avg lploss: 0.00000
*** Best Val Loss: 19.33599 	 Best Test Loss: 18.33775 	 Best epoch 15
Validation loss decreased (25.320280 --> 19.335989).  Saving model ...
train epoch 16 avg loss: 20.01026 (A-MSE: 17.38015) avg lploss: 0.00000
train epoch 17 avg loss: 19.56757 (A-MSE: 17.00414) avg lploss: 0.00000
train epoch 18 avg loss: 18.81872 (A-MSE: 16.33917) avg lploss: 0.00000
train epoch 19 avg loss: 17.78853 (A-MSE: 15.46337) avg lploss: 0.00000
train epoch 20 avg loss: 17.51697 (A-MSE: 15.25262) avg lploss: 0.00000
==> val epoch 20 avg loss: 18.57498 (A-MSE: 16.23247) avg lploss: 0.00000
==> test epoch 20 avg loss: 17.27428 (A-MSE: 14.98286) avg lploss: 0.00000
*** Best Val Loss: 18.57498 	 Best Test Loss: 17.27428 	 Best epoch 20
Validation loss decreased (19.335989 --> 18.574982).  Saving model ...
train epoch 21 avg loss: 17.14459 (A-MSE: 14.91833) avg lploss: 0.00000
train epoch 22 avg loss: 16.93806 (A-MSE: 14.76267) avg lploss: 0.00000
train epoch 23 avg loss: 16.30914 (A-MSE: 14.22138) avg lploss: 0.00000
train epoch 24 avg loss: 16.40372 (A-MSE: 14.30682) avg lploss: 0.00000
train epoch 25 avg loss: 16.23240 (A-MSE: 14.16258) avg lploss: 0.00000
==> val epoch 25 avg loss: 15.94225 (A-MSE: 13.75439) avg lploss: 0.00000
==> test epoch 25 avg loss: 15.10919 (A-MSE: 12.95900) avg lploss: 0.00000
*** Best Val Loss: 15.94225 	 Best Test Loss: 15.10919 	 Best epoch 25
Validation loss decreased (18.574982 --> 15.942247).  Saving model ...
train epoch 26 avg loss: 15.67764 (A-MSE: 13.69444) avg lploss: 0.00000
train epoch 27 avg loss: 15.28839 (A-MSE: 13.35015) avg lploss: 0.00000
train epoch 28 avg loss: 14.94207 (A-MSE: 13.05803) avg lploss: 0.00000
train epoch 29 avg loss: 14.97824 (A-MSE: 13.10033) avg lploss: 0.00000
train epoch 30 avg loss: 14.79641 (A-MSE: 12.92495) avg lploss: 0.00000
==> val epoch 30 avg loss: 14.69851 (A-MSE: 12.61181) avg lploss: 0.00000
==> test epoch 30 avg loss: 14.19674 (A-MSE: 12.15773) avg lploss: 0.00000
*** Best Val Loss: 14.69851 	 Best Test Loss: 14.19674 	 Best epoch 30
Validation loss decreased (15.942247 --> 14.698512).  Saving model ...
train epoch 31 avg loss: 14.28333 (A-MSE: 12.46828) avg lploss: 0.00000
train epoch 32 avg loss: 13.86483 (A-MSE: 12.09838) avg lploss: 0.00000
train epoch 33 avg loss: 13.81293 (A-MSE: 12.07039) avg lploss: 0.00000
train epoch 34 avg loss: 13.49546 (A-MSE: 11.76972) avg lploss: 0.00000
train epoch 35 avg loss: 13.14504 (A-MSE: 11.47859) avg lploss: 0.00000
==> val epoch 35 avg loss: 13.10801 (A-MSE: 11.32631) avg lploss: 0.00000
==> test epoch 35 avg loss: 12.79250 (A-MSE: 11.05143) avg lploss: 0.00000
*** Best Val Loss: 13.10801 	 Best Test Loss: 12.79250 	 Best epoch 35
Validation loss decreased (14.698512 --> 13.108014).  Saving model ...
train epoch 36 avg loss: 12.26450 (A-MSE: 10.68758) avg lploss: 0.00000
train epoch 37 avg loss: 12.24751 (A-MSE: 10.68891) avg lploss: 0.00000
train epoch 38 avg loss: 11.95659 (A-MSE: 10.42396) avg lploss: 0.00000
train epoch 39 avg loss: 12.70321 (A-MSE: 11.11704) avg lploss: 0.00000
train epoch 40 avg loss: 12.24635 (A-MSE: 10.72695) avg lploss: 0.00000
==> val epoch 40 avg loss: 11.77544 (A-MSE: 10.18818) avg lploss: 0.00000
==> test epoch 40 avg loss: 11.44996 (A-MSE: 9.89008) avg lploss: 0.00000
*** Best Val Loss: 11.77544 	 Best Test Loss: 11.44996 	 Best epoch 40
Validation loss decreased (13.108014 --> 11.775445).  Saving model ...
train epoch 41 avg loss: 11.38752 (A-MSE: 9.89353) avg lploss: 0.00000
train epoch 42 avg loss: 10.98282 (A-MSE: 9.62335) avg lploss: 0.00000
train epoch 43 avg loss: 10.78763 (A-MSE: 9.41968) avg lploss: 0.00000
train epoch 44 avg loss: 10.47667 (A-MSE: 9.12549) avg lploss: 0.00000
train epoch 45 avg loss: 10.32468 (A-MSE: 9.01206) avg lploss: 0.00000
==> val epoch 45 avg loss: 10.02083 (A-MSE: 8.68202) avg lploss: 0.00000
==> test epoch 45 avg loss: 9.80930 (A-MSE: 8.48430) avg lploss: 0.00000
*** Best Val Loss: 10.02083 	 Best Test Loss: 9.80930 	 Best epoch 45
Validation loss decreased (11.775445 --> 10.020834).  Saving model ...
train epoch 46 avg loss: 9.60141 (A-MSE: 8.36655) avg lploss: 0.00000
train epoch 47 avg loss: 10.21223 (A-MSE: 8.91414) avg lploss: 0.00000
train epoch 48 avg loss: 9.40347 (A-MSE: 8.20013) avg lploss: 0.00000
train epoch 49 avg loss: 8.66614 (A-MSE: 7.55415) avg lploss: 0.00000
train epoch 50 avg loss: 9.12986 (A-MSE: 7.94438) avg lploss: 0.00000
==> val epoch 50 avg loss: 8.94336 (A-MSE: 7.88883) avg lploss: 0.00000
==> test epoch 50 avg loss: 9.01835 (A-MSE: 7.94977) avg lploss: 0.00000
*** Best Val Loss: 8.94336 	 Best Test Loss: 9.01835 	 Best epoch 50
Validation loss decreased (10.020834 --> 8.943357).  Saving model ...
train epoch 51 avg loss: 8.43118 (A-MSE: 7.36097) avg lploss: 0.00000
train epoch 52 avg loss: 8.36721 (A-MSE: 7.28062) avg lploss: 0.00000
train epoch 53 avg loss: 8.36888 (A-MSE: 7.28890) avg lploss: 0.00000
train epoch 54 avg loss: 7.83739 (A-MSE: 6.84379) avg lploss: 0.00000
train epoch 55 avg loss: 7.87728 (A-MSE: 6.82637) avg lploss: 0.00000
==> val epoch 55 avg loss: 8.16195 (A-MSE: 7.25278) avg lploss: 0.00000
==> test epoch 55 avg loss: 8.05403 (A-MSE: 7.12583) avg lploss: 0.00000
*** Best Val Loss: 8.16195 	 Best Test Loss: 8.05403 	 Best epoch 55
Validation loss decreased (8.943357 --> 8.161955).  Saving model ...
train epoch 56 avg loss: 7.66192 (A-MSE: 6.72104) avg lploss: 0.00000
train epoch 57 avg loss: 7.58832 (A-MSE: 6.58234) avg lploss: 0.00000
train epoch 58 avg loss: 7.41453 (A-MSE: 6.49932) avg lploss: 0.00000
train epoch 59 avg loss: 7.47893 (A-MSE: 6.51439) avg lploss: 0.00000
train epoch 60 avg loss: 7.19202 (A-MSE: 6.27864) avg lploss: 0.00000
==> val epoch 60 avg loss: 8.35711 (A-MSE: 7.23222) avg lploss: 0.00000
==> test epoch 60 avg loss: 8.26880 (A-MSE: 7.16089) avg lploss: 0.00000
*** Best Val Loss: 8.16195 	 Best Test Loss: 8.05403 	 Best epoch 55
EarlyStopping counter: 1 out of 50
train epoch 61 avg loss: 7.22266 (A-MSE: 6.30880) avg lploss: 0.00000
train epoch 62 avg loss: 6.92062 (A-MSE: 6.05139) avg lploss: 0.00000
train epoch 63 avg loss: 7.48647 (A-MSE: 6.54276) avg lploss: 0.00000
train epoch 64 avg loss: 6.95977 (A-MSE: 6.05873) avg lploss: 0.00000
train epoch 65 avg loss: 6.69349 (A-MSE: 5.86124) avg lploss: 0.00000
==> val epoch 65 avg loss: 7.53702 (A-MSE: 6.75011) avg lploss: 0.00000
==> test epoch 65 avg loss: 7.35909 (A-MSE: 6.57219) avg lploss: 0.00000
*** Best Val Loss: 7.53702 	 Best Test Loss: 7.35909 	 Best epoch 65
Validation loss decreased (8.161955 --> 7.537018).  Saving model ...
train epoch 66 avg loss: 6.99673 (A-MSE: 6.12393) avg lploss: 0.00000
train epoch 67 avg loss: 6.85018 (A-MSE: 5.97924) avg lploss: 0.00000
train epoch 68 avg loss: 6.61560 (A-MSE: 5.79463) avg lploss: 0.00000
train epoch 69 avg loss: 6.86954 (A-MSE: 6.04169) avg lploss: 0.00000
train epoch 70 avg loss: 6.91790 (A-MSE: 6.05619) avg lploss: 0.00000
==> val epoch 70 avg loss: 7.23314 (A-MSE: 6.25522) avg lploss: 0.00000
==> test epoch 70 avg loss: 7.21875 (A-MSE: 6.23794) avg lploss: 0.00000
*** Best Val Loss: 7.23314 	 Best Test Loss: 7.21875 	 Best epoch 70
Validation loss decreased (7.537018 --> 7.233141).  Saving model ...
train epoch 71 avg loss: 6.50006 (A-MSE: 5.69927) avg lploss: 0.00000
train epoch 72 avg loss: 6.58118 (A-MSE: 5.74271) avg lploss: 0.00000
train epoch 73 avg loss: 6.66546 (A-MSE: 5.86004) avg lploss: 0.00000
train epoch 74 avg loss: 6.70740 (A-MSE: 5.88218) avg lploss: 0.00000
train epoch 75 avg loss: 6.50136 (A-MSE: 5.72212) avg lploss: 0.00000
==> val epoch 75 avg loss: 9.14452 (A-MSE: 7.96416) avg lploss: 0.00000
==> test epoch 75 avg loss: 9.09392 (A-MSE: 7.94472) avg lploss: 0.00000
*** Best Val Loss: 7.23314 	 Best Test Loss: 7.21875 	 Best epoch 70
EarlyStopping counter: 1 out of 50
train epoch 76 avg loss: 7.12265 (A-MSE: 6.23633) avg lploss: 0.00000
train epoch 77 avg loss: 6.24558 (A-MSE: 5.48421) avg lploss: 0.00000
train epoch 78 avg loss: 6.46916 (A-MSE: 5.67079) avg lploss: 0.00000
train epoch 79 avg loss: 6.14498 (A-MSE: 5.40264) avg lploss: 0.00000
train epoch 80 avg loss: 6.12072 (A-MSE: 5.36600) avg lploss: 0.00000
==> val epoch 80 avg loss: 7.12793 (A-MSE: 6.35719) avg lploss: 0.00000
==> test epoch 80 avg loss: 7.10737 (A-MSE: 6.34821) avg lploss: 0.00000
*** Best Val Loss: 7.12793 	 Best Test Loss: 7.10737 	 Best epoch 80
Validation loss decreased (7.233141 --> 7.127935).  Saving model ...
train epoch 81 avg loss: 5.82133 (A-MSE: 5.12811) avg lploss: 0.00000
train epoch 82 avg loss: 6.13744 (A-MSE: 5.40555) avg lploss: 0.00000
train epoch 83 avg loss: 6.23779 (A-MSE: 5.47684) avg lploss: 0.00000
train epoch 84 avg loss: 6.35017 (A-MSE: 5.60781) avg lploss: 0.00000
train epoch 85 avg loss: 6.02493 (A-MSE: 5.28291) avg lploss: 0.00000
==> val epoch 85 avg loss: 6.57430 (A-MSE: 5.76265) avg lploss: 0.00000
==> test epoch 85 avg loss: 6.37704 (A-MSE: 5.59343) avg lploss: 0.00000
*** Best Val Loss: 6.57430 	 Best Test Loss: 6.37704 	 Best epoch 85
Validation loss decreased (7.127935 --> 6.574301).  Saving model ...
train epoch 86 avg loss: 5.87155 (A-MSE: 5.17309) avg lploss: 0.00000
train epoch 87 avg loss: 5.77058 (A-MSE: 5.06999) avg lploss: 0.00000
train epoch 88 avg loss: 5.71320 (A-MSE: 5.03472) avg lploss: 0.00000
train epoch 89 avg loss: 6.08346 (A-MSE: 5.38999) avg lploss: 0.00000
train epoch 90 avg loss: 5.72302 (A-MSE: 5.02385) avg lploss: 0.00000
==> val epoch 90 avg loss: 6.34089 (A-MSE: 5.53300) avg lploss: 0.00000
==> test epoch 90 avg loss: 6.27855 (A-MSE: 5.50396) avg lploss: 0.00000
*** Best Val Loss: 6.34089 	 Best Test Loss: 6.27855 	 Best epoch 90
Validation loss decreased (6.574301 --> 6.340889).  Saving model ...
train epoch 91 avg loss: 5.66946 (A-MSE: 5.01228) avg lploss: 0.00000
train epoch 92 avg loss: 5.69269 (A-MSE: 5.01654) avg lploss: 0.00000
train epoch 93 avg loss: 5.52023 (A-MSE: 4.87316) avg lploss: 0.00000
train epoch 94 avg loss: 5.41521 (A-MSE: 4.75521) avg lploss: 0.00000
train epoch 95 avg loss: 5.34588 (A-MSE: 4.71447) avg lploss: 0.00000
==> val epoch 95 avg loss: 6.40968 (A-MSE: 5.68814) avg lploss: 0.00000
==> test epoch 95 avg loss: 6.29467 (A-MSE: 5.59747) avg lploss: 0.00000
*** Best Val Loss: 6.34089 	 Best Test Loss: 6.27855 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 5.33634 (A-MSE: 4.72062) avg lploss: 0.00000
train epoch 97 avg loss: 5.21211 (A-MSE: 4.59813) avg lploss: 0.00000
train epoch 98 avg loss: 5.20417 (A-MSE: 4.59855) avg lploss: 0.00000
train epoch 99 avg loss: 5.22736 (A-MSE: 4.60539) avg lploss: 0.00000
train epoch 100 avg loss: 5.44015 (A-MSE: 4.83820) avg lploss: 0.00000
==> val epoch 100 avg loss: 6.89220 (A-MSE: 5.96294) avg lploss: 0.00000
==> test epoch 100 avg loss: 6.67831 (A-MSE: 5.81346) avg lploss: 0.00000
*** Best Val Loss: 6.34089 	 Best Test Loss: 6.27855 	 Best epoch 90
EarlyStopping counter: 2 out of 50
train epoch 101 avg loss: 5.57062 (A-MSE: 4.91626) avg lploss: 0.00000
train epoch 102 avg loss: 5.29257 (A-MSE: 4.68708) avg lploss: 0.00000
train epoch 103 avg loss: 5.01753 (A-MSE: 4.43155) avg lploss: 0.00000
train epoch 104 avg loss: 4.93075 (A-MSE: 4.36134) avg lploss: 0.00000
train epoch 105 avg loss: 4.97593 (A-MSE: 4.40150) avg lploss: 0.00000
==> val epoch 105 avg loss: 6.55614 (A-MSE: 5.86688) avg lploss: 0.00000
==> test epoch 105 avg loss: 6.67440 (A-MSE: 6.01588) avg lploss: 0.00000
*** Best Val Loss: 6.34089 	 Best Test Loss: 6.27855 	 Best epoch 90
EarlyStopping counter: 3 out of 50
train epoch 106 avg loss: 4.71544 (A-MSE: 4.17297) avg lploss: 0.00000
train epoch 107 avg loss: 4.82739 (A-MSE: 4.25995) avg lploss: 0.00000
train epoch 108 avg loss: 4.80278 (A-MSE: 4.27200) avg lploss: 0.00000
train epoch 109 avg loss: 4.70499 (A-MSE: 4.17180) avg lploss: 0.00000
train epoch 110 avg loss: 4.77049 (A-MSE: 4.25893) avg lploss: 0.00000
==> val epoch 110 avg loss: 5.54452 (A-MSE: 4.95427) avg lploss: 0.00000
==> test epoch 110 avg loss: 5.46446 (A-MSE: 4.92632) avg lploss: 0.00000
*** Best Val Loss: 5.54452 	 Best Test Loss: 5.46446 	 Best epoch 110
Validation loss decreased (6.340889 --> 5.544519).  Saving model ...
train epoch 111 avg loss: 4.69760 (A-MSE: 4.16206) avg lploss: 0.00000
train epoch 112 avg loss: 4.71409 (A-MSE: 4.18508) avg lploss: 0.00000
train epoch 113 avg loss: 5.04822 (A-MSE: 4.48224) avg lploss: 0.00000
train epoch 114 avg loss: 4.82858 (A-MSE: 4.29362) avg lploss: 0.00000
train epoch 115 avg loss: 4.66347 (A-MSE: 4.12881) avg lploss: 0.00000
==> val epoch 115 avg loss: 6.05619 (A-MSE: 5.38540) avg lploss: 0.00000
==> test epoch 115 avg loss: 6.24876 (A-MSE: 5.63255) avg lploss: 0.00000
*** Best Val Loss: 5.54452 	 Best Test Loss: 5.46446 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 4.84664 (A-MSE: 4.30592) avg lploss: 0.00000
train epoch 117 avg loss: 4.44851 (A-MSE: 3.95935) avg lploss: 0.00000
train epoch 118 avg loss: 4.49963 (A-MSE: 4.01324) avg lploss: 0.00000
train epoch 119 avg loss: 4.89588 (A-MSE: 4.36875) avg lploss: 0.00000
train epoch 120 avg loss: 4.53719 (A-MSE: 4.04291) avg lploss: 0.00000
==> val epoch 120 avg loss: 5.03427 (A-MSE: 4.45800) avg lploss: 0.00000
==> test epoch 120 avg loss: 5.02052 (A-MSE: 4.51058) avg lploss: 0.00000
*** Best Val Loss: 5.03427 	 Best Test Loss: 5.02052 	 Best epoch 120
Validation loss decreased (5.544519 --> 5.034274).  Saving model ...
train epoch 121 avg loss: 4.33979 (A-MSE: 3.85629) avg lploss: 0.00000
train epoch 122 avg loss: 4.23710 (A-MSE: 3.77297) avg lploss: 0.00000
train epoch 123 avg loss: 4.12943 (A-MSE: 3.68705) avg lploss: 0.00000
train epoch 124 avg loss: 4.04973 (A-MSE: 3.61310) avg lploss: 0.00000
train epoch 125 avg loss: 4.02611 (A-MSE: 3.59725) avg lploss: 0.00000
==> val epoch 125 avg loss: 4.81541 (A-MSE: 4.30712) avg lploss: 0.00000
==> test epoch 125 avg loss: 4.78548 (A-MSE: 4.33182) avg lploss: 0.00000
*** Best Val Loss: 4.81541 	 Best Test Loss: 4.78548 	 Best epoch 125
Validation loss decreased (5.034274 --> 4.815412).  Saving model ...
train epoch 126 avg loss: 4.21246 (A-MSE: 3.75895) avg lploss: 0.00000
train epoch 127 avg loss: 4.10330 (A-MSE: 3.66422) avg lploss: 0.00000
train epoch 128 avg loss: 3.93549 (A-MSE: 3.50366) avg lploss: 0.00000
train epoch 129 avg loss: 3.87778 (A-MSE: 3.45546) avg lploss: 0.00000
train epoch 130 avg loss: 3.77415 (A-MSE: 3.38285) avg lploss: 0.00000
==> val epoch 130 avg loss: 4.78700 (A-MSE: 4.28631) avg lploss: 0.00000
==> test epoch 130 avg loss: 4.91365 (A-MSE: 4.46992) avg lploss: 0.00000
*** Best Val Loss: 4.78700 	 Best Test Loss: 4.91365 	 Best epoch 130
Validation loss decreased (4.815412 --> 4.787004).  Saving model ...
train epoch 131 avg loss: 4.09603 (A-MSE: 3.67451) avg lploss: 0.00000
train epoch 132 avg loss: 4.28782 (A-MSE: 3.81106) avg lploss: 0.00000
train epoch 133 avg loss: 4.07896 (A-MSE: 3.64902) avg lploss: 0.00000
train epoch 134 avg loss: 3.70601 (A-MSE: 3.31599) avg lploss: 0.00000
train epoch 135 avg loss: 3.72479 (A-MSE: 3.33079) avg lploss: 0.00000
==> val epoch 135 avg loss: 4.53936 (A-MSE: 4.11210) avg lploss: 0.00000
==> test epoch 135 avg loss: 4.54589 (A-MSE: 4.19123) avg lploss: 0.00000
*** Best Val Loss: 4.53936 	 Best Test Loss: 4.54589 	 Best epoch 135
Validation loss decreased (4.787004 --> 4.539359).  Saving model ...
train epoch 136 avg loss: 3.63040 (A-MSE: 3.24387) avg lploss: 0.00000
train epoch 137 avg loss: 3.57017 (A-MSE: 3.19188) avg lploss: 0.00000
train epoch 138 avg loss: 3.67366 (A-MSE: 3.27520) avg lploss: 0.00000
train epoch 139 avg loss: 3.73234 (A-MSE: 3.35378) avg lploss: 0.00000
train epoch 140 avg loss: 4.08725 (A-MSE: 3.66846) avg lploss: 0.00000
==> val epoch 140 avg loss: 4.61520 (A-MSE: 4.15534) avg lploss: 0.00000
==> test epoch 140 avg loss: 4.71946 (A-MSE: 4.31470) avg lploss: 0.00000
*** Best Val Loss: 4.53936 	 Best Test Loss: 4.54589 	 Best epoch 135
EarlyStopping counter: 1 out of 50
train epoch 141 avg loss: 3.95245 (A-MSE: 3.53586) avg lploss: 0.00000
train epoch 142 avg loss: 3.71901 (A-MSE: 3.33812) avg lploss: 0.00000
train epoch 143 avg loss: 3.45966 (A-MSE: 3.09264) avg lploss: 0.00000
train epoch 144 avg loss: 3.48559 (A-MSE: 3.12418) avg lploss: 0.00000
train epoch 145 avg loss: 3.53337 (A-MSE: 3.16014) avg lploss: 0.00000
==> val epoch 145 avg loss: 4.33218 (A-MSE: 3.94924) avg lploss: 0.00000
==> test epoch 145 avg loss: 4.58304 (A-MSE: 4.24023) avg lploss: 0.00000
*** Best Val Loss: 4.33218 	 Best Test Loss: 4.58304 	 Best epoch 145
Validation loss decreased (4.539359 --> 4.332182).  Saving model ...
train epoch 146 avg loss: 3.31285 (A-MSE: 2.97867) avg lploss: 0.00000
train epoch 147 avg loss: 3.55295 (A-MSE: 3.18988) avg lploss: 0.00000
train epoch 148 avg loss: 3.65127 (A-MSE: 3.26301) avg lploss: 0.00000
train epoch 149 avg loss: 3.83070 (A-MSE: 3.44104) avg lploss: 0.00000
train epoch 150 avg loss: 3.49791 (A-MSE: 3.12947) avg lploss: 0.00000
==> val epoch 150 avg loss: 4.40639 (A-MSE: 3.98737) avg lploss: 0.00000
==> test epoch 150 avg loss: 4.67712 (A-MSE: 4.30237) avg lploss: 0.00000
*** Best Val Loss: 4.33218 	 Best Test Loss: 4.58304 	 Best epoch 145
EarlyStopping counter: 1 out of 50
train epoch 151 avg loss: 3.26072 (A-MSE: 2.91972) avg lploss: 0.00000
train epoch 152 avg loss: 3.26185 (A-MSE: 2.92249) avg lploss: 0.00000
train epoch 153 avg loss: 3.42667 (A-MSE: 3.07233) avg lploss: 0.00000
train epoch 154 avg loss: 3.81732 (A-MSE: 3.41576) avg lploss: 0.00000
train epoch 155 avg loss: 3.39822 (A-MSE: 3.04092) avg lploss: 0.00000
==> val epoch 155 avg loss: 4.55796 (A-MSE: 4.06831) avg lploss: 0.00000
==> test epoch 155 avg loss: 4.71714 (A-MSE: 4.28036) avg lploss: 0.00000
*** Best Val Loss: 4.33218 	 Best Test Loss: 4.58304 	 Best epoch 145
EarlyStopping counter: 2 out of 50
train epoch 156 avg loss: 3.14314 (A-MSE: 2.81425) avg lploss: 0.00000
train epoch 157 avg loss: 3.21616 (A-MSE: 2.88177) avg lploss: 0.00000
train epoch 158 avg loss: 3.19380 (A-MSE: 2.86681) avg lploss: 0.00000
train epoch 159 avg loss: 3.62331 (A-MSE: 3.24289) avg lploss: 0.00000
train epoch 160 avg loss: 3.09632 (A-MSE: 2.77289) avg lploss: 0.00000
==> val epoch 160 avg loss: 4.10566 (A-MSE: 3.64662) avg lploss: 0.00000
==> test epoch 160 avg loss: 4.20132 (A-MSE: 3.77771) avg lploss: 0.00000
*** Best Val Loss: 4.10566 	 Best Test Loss: 4.20132 	 Best epoch 160
Validation loss decreased (4.332182 --> 4.105660).  Saving model ...
train epoch 161 avg loss: 3.30413 (A-MSE: 2.95237) avg lploss: 0.00000
train epoch 162 avg loss: 3.28422 (A-MSE: 2.94545) avg lploss: 0.00000
train epoch 163 avg loss: 3.07653 (A-MSE: 2.75333) avg lploss: 0.00000
train epoch 164 avg loss: 3.32078 (A-MSE: 2.97798) avg lploss: 0.00000
train epoch 165 avg loss: 3.07388 (A-MSE: 2.75732) avg lploss: 0.00000
==> val epoch 165 avg loss: 4.01620 (A-MSE: 3.61602) avg lploss: 0.00000
==> test epoch 165 avg loss: 4.09820 (A-MSE: 3.73204) avg lploss: 0.00000
*** Best Val Loss: 4.01620 	 Best Test Loss: 4.09820 	 Best epoch 165
Validation loss decreased (4.105660 --> 4.016202).  Saving model ...
train epoch 166 avg loss: 3.02397 (A-MSE: 2.70843) avg lploss: 0.00000
train epoch 167 avg loss: 3.09624 (A-MSE: 2.77443) avg lploss: 0.00000
train epoch 168 avg loss: 3.00160 (A-MSE: 2.68651) avg lploss: 0.00000
train epoch 169 avg loss: 2.89772 (A-MSE: 2.59854) avg lploss: 0.00000
train epoch 170 avg loss: 3.05536 (A-MSE: 2.73524) avg lploss: 0.00000
==> val epoch 170 avg loss: 4.01790 (A-MSE: 3.57659) avg lploss: 0.00000
==> test epoch 170 avg loss: 4.24764 (A-MSE: 3.81783) avg lploss: 0.00000
*** Best Val Loss: 4.01620 	 Best Test Loss: 4.09820 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 2.79316 (A-MSE: 2.49959) avg lploss: 0.00000
train epoch 172 avg loss: 2.84952 (A-MSE: 2.54999) avg lploss: 0.00000
train epoch 173 avg loss: 2.87629 (A-MSE: 2.57609) avg lploss: 0.00000
train epoch 174 avg loss: 2.75543 (A-MSE: 2.47074) avg lploss: 0.00000
train epoch 175 avg loss: 2.88716 (A-MSE: 2.58512) avg lploss: 0.00000
==> val epoch 175 avg loss: 4.24378 (A-MSE: 3.77740) avg lploss: 0.00000
==> test epoch 175 avg loss: 4.55138 (A-MSE: 4.08758) avg lploss: 0.00000
*** Best Val Loss: 4.01620 	 Best Test Loss: 4.09820 	 Best epoch 165
EarlyStopping counter: 2 out of 50
train epoch 176 avg loss: 3.24212 (A-MSE: 2.90745) avg lploss: 0.00000
train epoch 177 avg loss: 2.81794 (A-MSE: 2.51152) avg lploss: 0.00000
train epoch 178 avg loss: 3.08590 (A-MSE: 2.76550) avg lploss: 0.00000
train epoch 179 avg loss: 3.22531 (A-MSE: 2.88776) avg lploss: 0.00000
train epoch 180 avg loss: 3.68058 (A-MSE: 3.30047) avg lploss: 0.00000
==> val epoch 180 avg loss: 4.67887 (A-MSE: 4.15597) avg lploss: 0.00000
==> test epoch 180 avg loss: 4.77541 (A-MSE: 4.29675) avg lploss: 0.00000
*** Best Val Loss: 4.01620 	 Best Test Loss: 4.09820 	 Best epoch 165
EarlyStopping counter: 3 out of 50
train epoch 181 avg loss: 3.22937 (A-MSE: 2.89105) avg lploss: 0.00000
train epoch 182 avg loss: 2.89053 (A-MSE: 2.58933) avg lploss: 0.00000
train epoch 183 avg loss: 2.61142 (A-MSE: 2.34375) avg lploss: 0.00000
train epoch 184 avg loss: 2.91239 (A-MSE: 2.60503) avg lploss: 0.00000
train epoch 185 avg loss: 2.82863 (A-MSE: 2.53786) avg lploss: 0.00000
==> val epoch 185 avg loss: 4.07942 (A-MSE: 3.62254) avg lploss: 0.00000
==> test epoch 185 avg loss: 4.25425 (A-MSE: 3.81219) avg lploss: 0.00000
*** Best Val Loss: 4.01620 	 Best Test Loss: 4.09820 	 Best epoch 165
EarlyStopping counter: 4 out of 50
train epoch 186 avg loss: 2.63533 (A-MSE: 2.36064) avg lploss: 0.00000
train epoch 187 avg loss: 2.83432 (A-MSE: 2.53756) avg lploss: 0.00000
train epoch 188 avg loss: 3.23768 (A-MSE: 2.89487) avg lploss: 0.00000
train epoch 189 avg loss: 2.85228 (A-MSE: 2.55478) avg lploss: 0.00000
train epoch 190 avg loss: 2.83578 (A-MSE: 2.54209) avg lploss: 0.00000
==> val epoch 190 avg loss: 3.49465 (A-MSE: 3.14050) avg lploss: 0.00000
==> test epoch 190 avg loss: 3.58763 (A-MSE: 3.25777) avg lploss: 0.00000
*** Best Val Loss: 3.49465 	 Best Test Loss: 3.58763 	 Best epoch 190
Validation loss decreased (4.016202 --> 3.494651).  Saving model ...
train epoch 191 avg loss: 2.71439 (A-MSE: 2.42928) avg lploss: 0.00000
train epoch 192 avg loss: 2.68778 (A-MSE: 2.42088) avg lploss: 0.00000
train epoch 193 avg loss: 2.54622 (A-MSE: 2.27746) avg lploss: 0.00000
train epoch 194 avg loss: 2.51692 (A-MSE: 2.25388) avg lploss: 0.00000
train epoch 195 avg loss: 2.77106 (A-MSE: 2.48953) avg lploss: 0.00000
==> val epoch 195 avg loss: 3.93097 (A-MSE: 3.48930) avg lploss: 0.00000
==> test epoch 195 avg loss: 4.03274 (A-MSE: 3.60760) avg lploss: 0.00000
*** Best Val Loss: 3.49465 	 Best Test Loss: 3.58763 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 2.50334 (A-MSE: 2.23385) avg lploss: 0.00000
train epoch 197 avg loss: 2.62996 (A-MSE: 2.35313) avg lploss: 0.00000
train epoch 198 avg loss: 2.50215 (A-MSE: 2.23051) avg lploss: 0.00000
train epoch 199 avg loss: 2.55969 (A-MSE: 2.28754) avg lploss: 0.00000
train epoch 200 avg loss: 2.63905 (A-MSE: 2.36318) avg lploss: 0.00000
==> val epoch 200 avg loss: 3.47229 (A-MSE: 3.06898) avg lploss: 0.00000
==> test epoch 200 avg loss: 3.49605 (A-MSE: 3.12216) avg lploss: 0.00000
*** Best Val Loss: 3.47229 	 Best Test Loss: 3.49605 	 Best epoch 200
Validation loss decreased (3.494651 --> 3.472294).  Saving model ...
train epoch 201 avg loss: 2.43065 (A-MSE: 2.17739) avg lploss: 0.00000
train epoch 202 avg loss: 2.39305 (A-MSE: 2.13929) avg lploss: 0.00000
train epoch 203 avg loss: 2.61617 (A-MSE: 2.33603) avg lploss: 0.00000
train epoch 204 avg loss: 2.60468 (A-MSE: 2.33541) avg lploss: 0.00000
train epoch 205 avg loss: 2.56105 (A-MSE: 2.28743) avg lploss: 0.00000
==> val epoch 205 avg loss: 3.63629 (A-MSE: 3.27482) avg lploss: 0.00000
==> test epoch 205 avg loss: 3.76732 (A-MSE: 3.40945) avg lploss: 0.00000
*** Best Val Loss: 3.47229 	 Best Test Loss: 3.49605 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 2.38058 (A-MSE: 2.12757) avg lploss: 0.00000
train epoch 207 avg loss: 2.49097 (A-MSE: 2.22738) avg lploss: 0.00000
train epoch 208 avg loss: 2.47797 (A-MSE: 2.21528) avg lploss: 0.00000
train epoch 209 avg loss: 2.52740 (A-MSE: 2.26024) avg lploss: 0.00000
train epoch 210 avg loss: 2.44450 (A-MSE: 2.19126) avg lploss: 0.00000
==> val epoch 210 avg loss: 3.65775 (A-MSE: 3.26899) avg lploss: 0.00000
==> test epoch 210 avg loss: 3.72575 (A-MSE: 3.36120) avg lploss: 0.00000
*** Best Val Loss: 3.47229 	 Best Test Loss: 3.49605 	 Best epoch 200
EarlyStopping counter: 2 out of 50
train epoch 211 avg loss: 2.39815 (A-MSE: 2.13715) avg lploss: 0.00000
train epoch 212 avg loss: 2.43271 (A-MSE: 2.17975) avg lploss: 0.00000
train epoch 213 avg loss: 2.34988 (A-MSE: 2.10616) avg lploss: 0.00000
train epoch 214 avg loss: 2.41145 (A-MSE: 2.15206) avg lploss: 0.00000
train epoch 215 avg loss: 2.29468 (A-MSE: 2.04421) avg lploss: 0.00000
==> val epoch 215 avg loss: 3.66097 (A-MSE: 3.28092) avg lploss: 0.00000
==> test epoch 215 avg loss: 3.77581 (A-MSE: 3.40738) avg lploss: 0.00000
*** Best Val Loss: 3.47229 	 Best Test Loss: 3.49605 	 Best epoch 200
EarlyStopping counter: 3 out of 50
train epoch 216 avg loss: 2.53131 (A-MSE: 2.27206) avg lploss: 0.00000
train epoch 217 avg loss: 2.48124 (A-MSE: 2.21759) avg lploss: 0.00000
train epoch 218 avg loss: 2.45658 (A-MSE: 2.20573) avg lploss: 0.00000
train epoch 219 avg loss: 2.36766 (A-MSE: 2.11174) avg lploss: 0.00000
train epoch 220 avg loss: 2.27511 (A-MSE: 2.02886) avg lploss: 0.00000
==> val epoch 220 avg loss: 3.81365 (A-MSE: 3.36356) avg lploss: 0.00000
==> test epoch 220 avg loss: 4.08234 (A-MSE: 3.63839) avg lploss: 0.00000
*** Best Val Loss: 3.47229 	 Best Test Loss: 3.49605 	 Best epoch 200
EarlyStopping counter: 4 out of 50
train epoch 221 avg loss: 2.46896 (A-MSE: 2.20529) avg lploss: 0.00000
train epoch 222 avg loss: 2.61632 (A-MSE: 2.33885) avg lploss: 0.00000
train epoch 223 avg loss: 2.23832 (A-MSE: 1.99853) avg lploss: 0.00000
train epoch 224 avg loss: 2.23828 (A-MSE: 2.00124) avg lploss: 0.00000
train epoch 225 avg loss: 2.34566 (A-MSE: 2.09990) avg lploss: 0.00000
==> val epoch 225 avg loss: 3.39947 (A-MSE: 3.01240) avg lploss: 0.00000
==> test epoch 225 avg loss: 3.54280 (A-MSE: 3.16202) avg lploss: 0.00000
*** Best Val Loss: 3.39947 	 Best Test Loss: 3.54280 	 Best epoch 225
Validation loss decreased (3.472294 --> 3.399473).  Saving model ...
train epoch 226 avg loss: 2.36205 (A-MSE: 2.11783) avg lploss: 0.00000
train epoch 227 avg loss: 2.41099 (A-MSE: 2.15701) avg lploss: 0.00000
train epoch 228 avg loss: 2.35000 (A-MSE: 2.09876) avg lploss: 0.00000
train epoch 229 avg loss: 2.15692 (A-MSE: 1.92703) avg lploss: 0.00000
train epoch 230 avg loss: 2.03545 (A-MSE: 1.81727) avg lploss: 0.00000
==> val epoch 230 avg loss: 4.07982 (A-MSE: 3.63513) avg lploss: 0.00000
==> test epoch 230 avg loss: 4.39789 (A-MSE: 3.93987) avg lploss: 0.00000
*** Best Val Loss: 3.39947 	 Best Test Loss: 3.54280 	 Best epoch 225
EarlyStopping counter: 1 out of 50
train epoch 231 avg loss: 2.30019 (A-MSE: 2.04872) avg lploss: 0.00000
train epoch 232 avg loss: 2.37052 (A-MSE: 2.12491) avg lploss: 0.00000
train epoch 233 avg loss: 2.32887 (A-MSE: 2.07553) avg lploss: 0.00000
train epoch 234 avg loss: 2.20410 (A-MSE: 1.96702) avg lploss: 0.00000
train epoch 235 avg loss: 2.11879 (A-MSE: 1.89487) avg lploss: 0.00000
==> val epoch 235 avg loss: 2.95868 (A-MSE: 2.64000) avg lploss: 0.00000
==> test epoch 235 avg loss: 3.10827 (A-MSE: 2.80302) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
Validation loss decreased (3.399473 --> 2.958685).  Saving model ...
train epoch 236 avg loss: 2.03570 (A-MSE: 1.81468) avg lploss: 0.00000
train epoch 237 avg loss: 2.24439 (A-MSE: 2.00491) avg lploss: 0.00000
train epoch 238 avg loss: 2.51485 (A-MSE: 2.24234) avg lploss: 0.00000
train epoch 239 avg loss: 2.10158 (A-MSE: 1.87418) avg lploss: 0.00000
train epoch 240 avg loss: 2.13011 (A-MSE: 1.90300) avg lploss: 0.00000
==> val epoch 240 avg loss: 3.66121 (A-MSE: 3.28446) avg lploss: 0.00000
==> test epoch 240 avg loss: 3.77222 (A-MSE: 3.41154) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 2.30296 (A-MSE: 2.06411) avg lploss: 0.00000
train epoch 242 avg loss: 2.13214 (A-MSE: 1.90169) avg lploss: 0.00000
train epoch 243 avg loss: 2.03726 (A-MSE: 1.81564) avg lploss: 0.00000
train epoch 244 avg loss: 2.12124 (A-MSE: 1.88750) avg lploss: 0.00000
train epoch 245 avg loss: 2.30394 (A-MSE: 2.06868) avg lploss: 0.00000
==> val epoch 245 avg loss: 3.10267 (A-MSE: 2.76588) avg lploss: 0.00000
==> test epoch 245 avg loss: 3.40310 (A-MSE: 3.06013) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 2.02449 (A-MSE: 1.80407) avg lploss: 0.00000
train epoch 247 avg loss: 2.18514 (A-MSE: 1.94835) avg lploss: 0.00000
train epoch 248 avg loss: 2.09767 (A-MSE: 1.87728) avg lploss: 0.00000
train epoch 249 avg loss: 2.26815 (A-MSE: 2.02763) avg lploss: 0.00000
train epoch 250 avg loss: 2.46228 (A-MSE: 2.18699) avg lploss: 0.00000
==> val epoch 250 avg loss: 3.10561 (A-MSE: 2.76342) avg lploss: 0.00000
==> test epoch 250 avg loss: 3.26151 (A-MSE: 2.92424) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 2.03607 (A-MSE: 1.82061) avg lploss: 0.00000
train epoch 252 avg loss: 2.25751 (A-MSE: 2.01687) avg lploss: 0.00000
train epoch 253 avg loss: 2.19028 (A-MSE: 1.95309) avg lploss: 0.00000
train epoch 254 avg loss: 2.05674 (A-MSE: 1.83473) avg lploss: 0.00000
train epoch 255 avg loss: 2.11259 (A-MSE: 1.88779) avg lploss: 0.00000
==> val epoch 255 avg loss: 2.98894 (A-MSE: 2.64781) avg lploss: 0.00000
==> test epoch 255 avg loss: 3.09457 (A-MSE: 2.76766) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 4 out of 50
train epoch 256 avg loss: 2.17947 (A-MSE: 1.94472) avg lploss: 0.00000
train epoch 257 avg loss: 2.22308 (A-MSE: 1.98327) avg lploss: 0.00000
train epoch 258 avg loss: 1.92077 (A-MSE: 1.71584) avg lploss: 0.00000
train epoch 259 avg loss: 1.98941 (A-MSE: 1.77799) avg lploss: 0.00000
train epoch 260 avg loss: 1.98623 (A-MSE: 1.77456) avg lploss: 0.00000
==> val epoch 260 avg loss: 3.07443 (A-MSE: 2.72926) avg lploss: 0.00000
==> test epoch 260 avg loss: 3.25470 (A-MSE: 2.90580) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 5 out of 50
train epoch 261 avg loss: 2.01914 (A-MSE: 1.79936) avg lploss: 0.00000
train epoch 262 avg loss: 1.93210 (A-MSE: 1.72583) avg lploss: 0.00000
train epoch 263 avg loss: 1.86909 (A-MSE: 1.66380) avg lploss: 0.00000
train epoch 264 avg loss: 1.90112 (A-MSE: 1.69844) avg lploss: 0.00000
train epoch 265 avg loss: 1.89045 (A-MSE: 1.68221) avg lploss: 0.00000
==> val epoch 265 avg loss: 3.01601 (A-MSE: 2.69242) avg lploss: 0.00000
==> test epoch 265 avg loss: 3.16054 (A-MSE: 2.84232) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 6 out of 50
train epoch 266 avg loss: 1.93015 (A-MSE: 1.72096) avg lploss: 0.00000
train epoch 267 avg loss: 1.98844 (A-MSE: 1.78043) avg lploss: 0.00000
train epoch 268 avg loss: 1.80146 (A-MSE: 1.60742) avg lploss: 0.00000
train epoch 269 avg loss: 1.83372 (A-MSE: 1.64138) avg lploss: 0.00000
train epoch 270 avg loss: 1.89265 (A-MSE: 1.68257) avg lploss: 0.00000
==> val epoch 270 avg loss: 3.08183 (A-MSE: 2.74658) avg lploss: 0.00000
==> test epoch 270 avg loss: 3.33698 (A-MSE: 3.01116) avg lploss: 0.00000
*** Best Val Loss: 2.95868 	 Best Test Loss: 3.10827 	 Best epoch 235
EarlyStopping counter: 7 out of 50
train epoch 271 avg loss: 1.87186 (A-MSE: 1.66793) avg lploss: 0.00000
train epoch 272 avg loss: 1.80148 (A-MSE: 1.60908) avg lploss: 0.00000
train epoch 273 avg loss: 1.93622 (A-MSE: 1.72747) avg lploss: 0.00000
train epoch 274 avg loss: 1.89158 (A-MSE: 1.68206) avg lploss: 0.00000
train epoch 275 avg loss: 1.84023 (A-MSE: 1.64403) avg lploss: 0.00000
==> val epoch 275 avg loss: 2.82681 (A-MSE: 2.49739) avg lploss: 0.00000
==> test epoch 275 avg loss: 3.06832 (A-MSE: 2.73375) avg lploss: 0.00000
*** Best Val Loss: 2.82681 	 Best Test Loss: 3.06832 	 Best epoch 275
Validation loss decreased (2.958685 --> 2.826810).  Saving model ...
train epoch 276 avg loss: 1.85054 (A-MSE: 1.64754) avg lploss: 0.00000
train epoch 277 avg loss: 1.90748 (A-MSE: 1.69958) avg lploss: 0.00000
train epoch 278 avg loss: 1.86090 (A-MSE: 1.65888) avg lploss: 0.00000
train epoch 279 avg loss: 2.10327 (A-MSE: 1.87589) avg lploss: 0.00000
train epoch 280 avg loss: 2.16625 (A-MSE: 1.93775) avg lploss: 0.00000
==> val epoch 280 avg loss: 2.81685 (A-MSE: 2.51814) avg lploss: 0.00000
==> test epoch 280 avg loss: 3.01691 (A-MSE: 2.71617) avg lploss: 0.00000
*** Best Val Loss: 2.81685 	 Best Test Loss: 3.01691 	 Best epoch 280
Validation loss decreased (2.826810 --> 2.816854).  Saving model ...
train epoch 281 avg loss: 1.97438 (A-MSE: 1.76002) avg lploss: 0.00000
train epoch 282 avg loss: 1.95663 (A-MSE: 1.75317) avg lploss: 0.00000
train epoch 283 avg loss: 1.71175 (A-MSE: 1.52648) avg lploss: 0.00000
train epoch 284 avg loss: 1.93477 (A-MSE: 1.72616) avg lploss: 0.00000
train epoch 285 avg loss: 1.89744 (A-MSE: 1.69158) avg lploss: 0.00000
==> val epoch 285 avg loss: 3.15885 (A-MSE: 2.83249) avg lploss: 0.00000
==> test epoch 285 avg loss: 3.35386 (A-MSE: 3.03049) avg lploss: 0.00000
*** Best Val Loss: 2.81685 	 Best Test Loss: 3.01691 	 Best epoch 280
EarlyStopping counter: 1 out of 50
train epoch 286 avg loss: 1.94887 (A-MSE: 1.73881) avg lploss: 0.00000
train epoch 287 avg loss: 1.83010 (A-MSE: 1.63194) avg lploss: 0.00000
train epoch 288 avg loss: 1.75259 (A-MSE: 1.56696) avg lploss: 0.00000
train epoch 289 avg loss: 1.70655 (A-MSE: 1.51960) avg lploss: 0.00000
train epoch 290 avg loss: 1.68527 (A-MSE: 1.50508) avg lploss: 0.00000
==> val epoch 290 avg loss: 2.67187 (A-MSE: 2.36496) avg lploss: 0.00000
==> test epoch 290 avg loss: 2.78471 (A-MSE: 2.48706) avg lploss: 0.00000
*** Best Val Loss: 2.67187 	 Best Test Loss: 2.78471 	 Best epoch 290
Validation loss decreased (2.816854 --> 2.671867).  Saving model ...
train epoch 291 avg loss: 2.21427 (A-MSE: 1.98136) avg lploss: 0.00000
train epoch 292 avg loss: 1.93973 (A-MSE: 1.73153) avg lploss: 0.00000
train epoch 293 avg loss: 1.85211 (A-MSE: 1.64990) avg lploss: 0.00000
train epoch 294 avg loss: 1.91278 (A-MSE: 1.71181) avg lploss: 0.00000
train epoch 295 avg loss: 1.87262 (A-MSE: 1.66967) avg lploss: 0.00000
==> val epoch 295 avg loss: 3.02137 (A-MSE: 2.67993) avg lploss: 0.00000
==> test epoch 295 avg loss: 3.20950 (A-MSE: 2.86763) avg lploss: 0.00000
*** Best Val Loss: 2.67187 	 Best Test Loss: 2.78471 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 1.86086 (A-MSE: 1.65798) avg lploss: 0.00000
train epoch 297 avg loss: 1.74556 (A-MSE: 1.55751) avg lploss: 0.00000
train epoch 298 avg loss: 1.85968 (A-MSE: 1.65958) avg lploss: 0.00000
train epoch 299 avg loss: 1.65577 (A-MSE: 1.48005) avg lploss: 0.00000
train epoch 300 avg loss: 1.73044 (A-MSE: 1.54033) avg lploss: 0.00000
==> val epoch 300 avg loss: 2.63175 (A-MSE: 2.34107) avg lploss: 0.00000
==> test epoch 300 avg loss: 2.81003 (A-MSE: 2.52245) avg lploss: 0.00000
*** Best Val Loss: 2.63175 	 Best Test Loss: 2.81003 	 Best epoch 300
Validation loss decreased (2.671867 --> 2.631754).  Saving model ...
train epoch 301 avg loss: 1.70951 (A-MSE: 1.53159) avg lploss: 0.00000
train epoch 302 avg loss: 1.82006 (A-MSE: 1.62158) avg lploss: 0.00000
train epoch 303 avg loss: 1.73606 (A-MSE: 1.54415) avg lploss: 0.00000
train epoch 304 avg loss: 1.65030 (A-MSE: 1.47291) avg lploss: 0.00000
train epoch 305 avg loss: 1.71337 (A-MSE: 1.52079) avg lploss: 0.00000
==> val epoch 305 avg loss: 2.86528 (A-MSE: 2.54321) avg lploss: 0.00000
==> test epoch 305 avg loss: 3.15425 (A-MSE: 2.81994) avg lploss: 0.00000
*** Best Val Loss: 2.63175 	 Best Test Loss: 2.81003 	 Best epoch 300
EarlyStopping counter: 1 out of 50
train epoch 306 avg loss: 1.68843 (A-MSE: 1.50323) avg lploss: 0.00000
train epoch 307 avg loss: 1.84344 (A-MSE: 1.64355) avg lploss: 0.00000
train epoch 308 avg loss: 1.81317 (A-MSE: 1.61957) avg lploss: 0.00000
train epoch 309 avg loss: 1.63295 (A-MSE: 1.45458) avg lploss: 0.00000
train epoch 310 avg loss: 1.66773 (A-MSE: 1.48537) avg lploss: 0.00000
==> val epoch 310 avg loss: 2.96697 (A-MSE: 2.65445) avg lploss: 0.00000
==> test epoch 310 avg loss: 3.20912 (A-MSE: 2.89217) avg lploss: 0.00000
*** Best Val Loss: 2.63175 	 Best Test Loss: 2.81003 	 Best epoch 300
EarlyStopping counter: 2 out of 50
train epoch 311 avg loss: 1.70112 (A-MSE: 1.52212) avg lploss: 0.00000
train epoch 312 avg loss: 1.67700 (A-MSE: 1.49555) avg lploss: 0.00000
train epoch 313 avg loss: 1.61012 (A-MSE: 1.44090) avg lploss: 0.00000
train epoch 314 avg loss: 1.58807 (A-MSE: 1.41417) avg lploss: 0.00000
train epoch 315 avg loss: 1.75502 (A-MSE: 1.56377) avg lploss: 0.00000
==> val epoch 315 avg loss: 2.86458 (A-MSE: 2.57989) avg lploss: 0.00000
==> test epoch 315 avg loss: 3.20369 (A-MSE: 2.91057) avg lploss: 0.00000
*** Best Val Loss: 2.63175 	 Best Test Loss: 2.81003 	 Best epoch 300
EarlyStopping counter: 3 out of 50
train epoch 316 avg loss: 1.77841 (A-MSE: 1.59332) avg lploss: 0.00000
train epoch 317 avg loss: 1.71393 (A-MSE: 1.52470) avg lploss: 0.00000
train epoch 318 avg loss: 1.89497 (A-MSE: 1.69896) avg lploss: 0.00000
train epoch 319 avg loss: 1.82120 (A-MSE: 1.63206) avg lploss: 0.00000
train epoch 320 avg loss: 2.22524 (A-MSE: 1.99088) avg lploss: 0.00000
==> val epoch 320 avg loss: 3.75642 (A-MSE: 3.30843) avg lploss: 0.00000
==> test epoch 320 avg loss: 3.79130 (A-MSE: 3.36825) avg lploss: 0.00000
*** Best Val Loss: 2.63175 	 Best Test Loss: 2.81003 	 Best epoch 300
EarlyStopping counter: 4 out of 50
train epoch 321 avg loss: 2.21304 (A-MSE: 1.96746) avg lploss: 0.00000
train epoch 322 avg loss: 1.84844 (A-MSE: 1.64293) avg lploss: 0.00000
train epoch 323 avg loss: 1.51874 (A-MSE: 1.35503) avg lploss: 0.00000
train epoch 324 avg loss: 1.68690 (A-MSE: 1.51054) avg lploss: 0.00000
train epoch 325 avg loss: 1.81666 (A-MSE: 1.61466) avg lploss: 0.00000
==> val epoch 325 avg loss: 2.83355 (A-MSE: 2.55415) avg lploss: 0.00000
==> test epoch 325 avg loss: 3.12323 (A-MSE: 2.84410) avg lploss: 0.00000
*** Best Val Loss: 2.63175 	 Best Test Loss: 2.81003 	 Best epoch 300
EarlyStopping counter: 5 out of 50
train epoch 326 avg loss: 1.59379 (A-MSE: 1.42442) avg lploss: 0.00000
train epoch 327 avg loss: 1.52610 (A-MSE: 1.36058) avg lploss: 0.00000
train epoch 328 avg loss: 1.46938 (A-MSE: 1.31093) avg lploss: 0.00000
train epoch 329 avg loss: 1.48954 (A-MSE: 1.32334) avg lploss: 0.00000
train epoch 330 avg loss: 1.60275 (A-MSE: 1.43067) avg lploss: 0.00000
==> val epoch 330 avg loss: 2.31030 (A-MSE: 2.06914) avg lploss: 0.00000
==> test epoch 330 avg loss: 2.57289 (A-MSE: 2.31968) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
Validation loss decreased (2.631754 --> 2.310298).  Saving model ...
train epoch 331 avg loss: 1.61388 (A-MSE: 1.43760) avg lploss: 0.00000
train epoch 332 avg loss: 1.61073 (A-MSE: 1.43832) avg lploss: 0.00000
train epoch 333 avg loss: 1.57290 (A-MSE: 1.39688) avg lploss: 0.00000
train epoch 334 avg loss: 1.55439 (A-MSE: 1.38481) avg lploss: 0.00000
train epoch 335 avg loss: 1.72781 (A-MSE: 1.53993) avg lploss: 0.00000
==> val epoch 335 avg loss: 3.09022 (A-MSE: 2.78110) avg lploss: 0.00000
==> test epoch 335 avg loss: 3.38096 (A-MSE: 3.06118) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 1 out of 50
train epoch 336 avg loss: 1.68793 (A-MSE: 1.50060) avg lploss: 0.00000
train epoch 337 avg loss: 1.68645 (A-MSE: 1.50548) avg lploss: 0.00000
train epoch 338 avg loss: 1.51399 (A-MSE: 1.34992) avg lploss: 0.00000
train epoch 339 avg loss: 1.47645 (A-MSE: 1.31625) avg lploss: 0.00000
train epoch 340 avg loss: 1.43744 (A-MSE: 1.28256) avg lploss: 0.00000
==> val epoch 340 avg loss: 2.53578 (A-MSE: 2.27164) avg lploss: 0.00000
==> test epoch 340 avg loss: 2.89958 (A-MSE: 2.61650) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 2 out of 50
train epoch 341 avg loss: 1.68005 (A-MSE: 1.49728) avg lploss: 0.00000
train epoch 342 avg loss: 1.51503 (A-MSE: 1.35283) avg lploss: 0.00000
train epoch 343 avg loss: 1.44818 (A-MSE: 1.28678) avg lploss: 0.00000
train epoch 344 avg loss: 1.36446 (A-MSE: 1.21776) avg lploss: 0.00000
train epoch 345 avg loss: 1.38516 (A-MSE: 1.23230) avg lploss: 0.00000
==> val epoch 345 avg loss: 2.37726 (A-MSE: 2.13012) avg lploss: 0.00000
==> test epoch 345 avg loss: 2.56712 (A-MSE: 2.31482) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 3 out of 50
train epoch 346 avg loss: 1.43058 (A-MSE: 1.28228) avg lploss: 0.00000
train epoch 347 avg loss: 1.48351 (A-MSE: 1.32056) avg lploss: 0.00000
train epoch 348 avg loss: 1.51851 (A-MSE: 1.35131) avg lploss: 0.00000
train epoch 349 avg loss: 1.71532 (A-MSE: 1.53451) avg lploss: 0.00000
train epoch 350 avg loss: 1.53681 (A-MSE: 1.36663) avg lploss: 0.00000
==> val epoch 350 avg loss: 3.00452 (A-MSE: 2.68346) avg lploss: 0.00000
==> test epoch 350 avg loss: 3.27758 (A-MSE: 2.94508) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 4 out of 50
train epoch 351 avg loss: 1.61588 (A-MSE: 1.44631) avg lploss: 0.00000
train epoch 352 avg loss: 1.66392 (A-MSE: 1.48827) avg lploss: 0.00000
train epoch 353 avg loss: 1.56791 (A-MSE: 1.39988) avg lploss: 0.00000
train epoch 354 avg loss: 1.48206 (A-MSE: 1.32164) avg lploss: 0.00000
train epoch 355 avg loss: 1.52997 (A-MSE: 1.36068) avg lploss: 0.00000
==> val epoch 355 avg loss: 3.19995 (A-MSE: 2.85455) avg lploss: 0.00000
==> test epoch 355 avg loss: 3.38809 (A-MSE: 3.04724) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 5 out of 50
train epoch 356 avg loss: 1.64306 (A-MSE: 1.46721) avg lploss: 0.00000
train epoch 357 avg loss: 1.40063 (A-MSE: 1.24282) avg lploss: 0.00000
train epoch 358 avg loss: 1.35362 (A-MSE: 1.20300) avg lploss: 0.00000
train epoch 359 avg loss: 1.43382 (A-MSE: 1.27964) avg lploss: 0.00000
train epoch 360 avg loss: 1.40948 (A-MSE: 1.24991) avg lploss: 0.00000
==> val epoch 360 avg loss: 2.56232 (A-MSE: 2.28919) avg lploss: 0.00000
==> test epoch 360 avg loss: 2.93298 (A-MSE: 2.63698) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 6 out of 50
train epoch 361 avg loss: 1.45404 (A-MSE: 1.29560) avg lploss: 0.00000
train epoch 362 avg loss: 1.44973 (A-MSE: 1.29169) avg lploss: 0.00000
train epoch 363 avg loss: 1.28942 (A-MSE: 1.14865) avg lploss: 0.00000
train epoch 364 avg loss: 1.30814 (A-MSE: 1.16616) avg lploss: 0.00000
train epoch 365 avg loss: 1.51980 (A-MSE: 1.35854) avg lploss: 0.00000
==> val epoch 365 avg loss: 2.77283 (A-MSE: 2.45776) avg lploss: 0.00000
==> test epoch 365 avg loss: 3.00000 (A-MSE: 2.68221) avg lploss: 0.00000
*** Best Val Loss: 2.31030 	 Best Test Loss: 2.57289 	 Best epoch 330
EarlyStopping counter: 7 out of 50
train epoch 366 avg loss: 1.54272 (A-MSE: 1.37026) avg lploss: 0.00000
train epoch 367 avg loss: 1.54763 (A-MSE: 1.37721) avg lploss: 0.00000
train epoch 368 avg loss: 1.48888 (A-MSE: 1.32923) avg lploss: 0.00000
train epoch 369 avg loss: 1.44648 (A-MSE: 1.28861) avg lploss: 0.00000
train epoch 370 avg loss: 1.43639 (A-MSE: 1.28221) avg lploss: 0.00000
==> val epoch 370 avg loss: 2.24821 (A-MSE: 2.01099) avg lploss: 0.00000
==> test epoch 370 avg loss: 2.57028 (A-MSE: 2.31495) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
Validation loss decreased (2.310298 --> 2.248208).  Saving model ...
train epoch 371 avg loss: 1.40773 (A-MSE: 1.25837) avg lploss: 0.00000
train epoch 372 avg loss: 1.32093 (A-MSE: 1.17664) avg lploss: 0.00000
train epoch 373 avg loss: 1.30258 (A-MSE: 1.16140) avg lploss: 0.00000
train epoch 374 avg loss: 1.35624 (A-MSE: 1.20764) avg lploss: 0.00000
train epoch 375 avg loss: 1.41402 (A-MSE: 1.25558) avg lploss: 0.00000
==> val epoch 375 avg loss: 2.27049 (A-MSE: 2.01266) avg lploss: 0.00000
==> test epoch 375 avg loss: 2.52553 (A-MSE: 2.25833) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 1 out of 50
train epoch 376 avg loss: 1.35674 (A-MSE: 1.21178) avg lploss: 0.00000
train epoch 377 avg loss: 1.42007 (A-MSE: 1.26273) avg lploss: 0.00000
train epoch 378 avg loss: 1.40494 (A-MSE: 1.25783) avg lploss: 0.00000
train epoch 379 avg loss: 1.32838 (A-MSE: 1.18546) avg lploss: 0.00000
train epoch 380 avg loss: 1.33556 (A-MSE: 1.19092) avg lploss: 0.00000
==> val epoch 380 avg loss: 2.30089 (A-MSE: 2.05893) avg lploss: 0.00000
==> test epoch 380 avg loss: 2.45567 (A-MSE: 2.21771) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 2 out of 50
train epoch 381 avg loss: 1.25851 (A-MSE: 1.12340) avg lploss: 0.00000
train epoch 382 avg loss: 1.25349 (A-MSE: 1.11392) avg lploss: 0.00000
train epoch 383 avg loss: 1.26666 (A-MSE: 1.12799) avg lploss: 0.00000
train epoch 384 avg loss: 1.27234 (A-MSE: 1.13144) avg lploss: 0.00000
train epoch 385 avg loss: 1.22721 (A-MSE: 1.08839) avg lploss: 0.00000
==> val epoch 385 avg loss: 2.90351 (A-MSE: 2.59653) avg lploss: 0.00000
==> test epoch 385 avg loss: 3.11215 (A-MSE: 2.79977) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 3 out of 50
train epoch 386 avg loss: 1.31945 (A-MSE: 1.17742) avg lploss: 0.00000
train epoch 387 avg loss: 1.86758 (A-MSE: 1.66001) avg lploss: 0.00000
train epoch 388 avg loss: 3.12828 (A-MSE: 2.75747) avg lploss: 0.00000
train epoch 389 avg loss: 1.79431 (A-MSE: 1.58263) avg lploss: 0.00000
train epoch 390 avg loss: 1.82342 (A-MSE: 1.61459) avg lploss: 0.00000
==> val epoch 390 avg loss: 2.89684 (A-MSE: 2.54100) avg lploss: 0.00000
==> test epoch 390 avg loss: 3.17694 (A-MSE: 2.80255) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 4 out of 50
train epoch 391 avg loss: 1.50962 (A-MSE: 1.34653) avg lploss: 0.00000
train epoch 392 avg loss: 1.40676 (A-MSE: 1.24681) avg lploss: 0.00000
train epoch 393 avg loss: 1.38002 (A-MSE: 1.22532) avg lploss: 0.00000
train epoch 394 avg loss: 1.31859 (A-MSE: 1.17436) avg lploss: 0.00000
train epoch 395 avg loss: 1.32193 (A-MSE: 1.17247) avg lploss: 0.00000
==> val epoch 395 avg loss: 2.36921 (A-MSE: 2.12183) avg lploss: 0.00000
==> test epoch 395 avg loss: 2.65104 (A-MSE: 2.39513) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 5 out of 50
train epoch 396 avg loss: 1.37363 (A-MSE: 1.23107) avg lploss: 0.00000
train epoch 397 avg loss: 1.33127 (A-MSE: 1.18742) avg lploss: 0.00000
train epoch 398 avg loss: 1.36017 (A-MSE: 1.20978) avg lploss: 0.00000
train epoch 399 avg loss: 1.24764 (A-MSE: 1.11076) avg lploss: 0.00000
train epoch 400 avg loss: 1.23947 (A-MSE: 1.10147) avg lploss: 0.00000
==> val epoch 400 avg loss: 2.44398 (A-MSE: 2.19623) avg lploss: 0.00000
==> test epoch 400 avg loss: 2.65849 (A-MSE: 2.40626) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 6 out of 50
train epoch 401 avg loss: 1.22343 (A-MSE: 1.08595) avg lploss: 0.00000
train epoch 402 avg loss: 1.25084 (A-MSE: 1.11224) avg lploss: 0.00000
train epoch 403 avg loss: 1.26391 (A-MSE: 1.12782) avg lploss: 0.00000
train epoch 404 avg loss: 1.26442 (A-MSE: 1.12586) avg lploss: 0.00000
train epoch 405 avg loss: 1.25995 (A-MSE: 1.11916) avg lploss: 0.00000
==> val epoch 405 avg loss: 2.44174 (A-MSE: 2.18709) avg lploss: 0.00000
==> test epoch 405 avg loss: 2.69225 (A-MSE: 2.42594) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 7 out of 50
train epoch 406 avg loss: 1.23029 (A-MSE: 1.10171) avg lploss: 0.00000
train epoch 407 avg loss: 1.33388 (A-MSE: 1.18819) avg lploss: 0.00000
train epoch 408 avg loss: 1.25583 (A-MSE: 1.11346) avg lploss: 0.00000
train epoch 409 avg loss: 1.18485 (A-MSE: 1.05509) avg lploss: 0.00000
train epoch 410 avg loss: 1.20956 (A-MSE: 1.07722) avg lploss: 0.00000
==> val epoch 410 avg loss: 2.30541 (A-MSE: 2.05791) avg lploss: 0.00000
==> test epoch 410 avg loss: 2.58663 (A-MSE: 2.32907) avg lploss: 0.00000
*** Best Val Loss: 2.24821 	 Best Test Loss: 2.57028 	 Best epoch 370
EarlyStopping counter: 8 out of 50
train epoch 411 avg loss: 1.23131 (A-MSE: 1.09861) avg lploss: 0.00000
train epoch 412 avg loss: 1.19637 (A-MSE: 1.06170) avg lploss: 0.00000
train epoch 413 avg loss: 1.23483 (A-MSE: 1.10323) avg lploss: 0.00000
train epoch 414 avg loss: 1.39291 (A-MSE: 1.24493) avg lploss: 0.00000
train epoch 415 avg loss: 1.40825 (A-MSE: 1.25727) avg lploss: 0.00000
==> val epoch 415 avg loss: 2.07999 (A-MSE: 1.86280) avg lploss: 0.00000
==> test epoch 415 avg loss: 2.38427 (A-MSE: 2.15438) avg lploss: 0.00000
*** Best Val Loss: 2.07999 	 Best Test Loss: 2.38427 	 Best epoch 415
Validation loss decreased (2.248208 --> 2.079993).  Saving model ...
train epoch 416 avg loss: 1.29837 (A-MSE: 1.15731) avg lploss: 0.00000
train epoch 417 avg loss: 1.20825 (A-MSE: 1.07919) avg lploss: 0.00000
train epoch 418 avg loss: 1.18369 (A-MSE: 1.04610) avg lploss: 0.00000
train epoch 419 avg loss: 1.28348 (A-MSE: 1.13955) avg lploss: 0.00000
train epoch 420 avg loss: 1.24171 (A-MSE: 1.10712) avg lploss: 0.00000
==> val epoch 420 avg loss: 3.02390 (A-MSE: 2.69014) avg lploss: 0.00000
==> test epoch 420 avg loss: 3.11442 (A-MSE: 2.78545) avg lploss: 0.00000
*** Best Val Loss: 2.07999 	 Best Test Loss: 2.38427 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 1.40281 (A-MSE: 1.24910) avg lploss: 0.00000
train epoch 422 avg loss: 1.49483 (A-MSE: 1.33591) avg lploss: 0.00000
train epoch 423 avg loss: 1.24883 (A-MSE: 1.11312) avg lploss: 0.00000
train epoch 424 avg loss: 1.29809 (A-MSE: 1.15105) avg lploss: 0.00000
train epoch 425 avg loss: 1.14793 (A-MSE: 1.02530) avg lploss: 0.00000
==> val epoch 425 avg loss: 2.28024 (A-MSE: 2.02718) avg lploss: 0.00000
==> test epoch 425 avg loss: 2.53888 (A-MSE: 2.27776) avg lploss: 0.00000
*** Best Val Loss: 2.07999 	 Best Test Loss: 2.38427 	 Best epoch 415
EarlyStopping counter: 2 out of 50
train epoch 426 avg loss: 1.19952 (A-MSE: 1.06716) avg lploss: 0.00000
train epoch 427 avg loss: 1.21838 (A-MSE: 1.08117) avg lploss: 0.00000
train epoch 428 avg loss: 1.18493 (A-MSE: 1.05385) avg lploss: 0.00000
train epoch 429 avg loss: 1.19848 (A-MSE: 1.06828) avg lploss: 0.00000
train epoch 430 avg loss: 1.29554 (A-MSE: 1.14989) avg lploss: 0.00000
==> val epoch 430 avg loss: 2.23003 (A-MSE: 2.00598) avg lploss: 0.00000
==> test epoch 430 avg loss: 2.44587 (A-MSE: 2.21698) avg lploss: 0.00000
*** Best Val Loss: 2.07999 	 Best Test Loss: 2.38427 	 Best epoch 415
EarlyStopping counter: 3 out of 50
train epoch 431 avg loss: 1.33648 (A-MSE: 1.19265) avg lploss: 0.00000
train epoch 432 avg loss: 1.34873 (A-MSE: 1.19253) avg lploss: 0.00000
train epoch 433 avg loss: 1.26053 (A-MSE: 1.12628) avg lploss: 0.00000
train epoch 434 avg loss: 1.24769 (A-MSE: 1.10811) avg lploss: 0.00000
train epoch 435 avg loss: 1.20288 (A-MSE: 1.07230) avg lploss: 0.00000
==> val epoch 435 avg loss: 2.06288 (A-MSE: 1.83311) avg lploss: 0.00000
==> test epoch 435 avg loss: 2.27467 (A-MSE: 2.04116) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
Validation loss decreased (2.079993 --> 2.062876).  Saving model ...
train epoch 436 avg loss: 1.06600 (A-MSE: 0.94350) avg lploss: 0.00000
train epoch 437 avg loss: 1.06091 (A-MSE: 0.94020) avg lploss: 0.00000
train epoch 438 avg loss: 1.14163 (A-MSE: 1.01250) avg lploss: 0.00000
train epoch 439 avg loss: 1.27869 (A-MSE: 1.14039) avg lploss: 0.00000
train epoch 440 avg loss: 1.17922 (A-MSE: 1.04785) avg lploss: 0.00000
==> val epoch 440 avg loss: 2.09903 (A-MSE: 1.86783) avg lploss: 0.00000
==> test epoch 440 avg loss: 2.25940 (A-MSE: 2.02314) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 1.09197 (A-MSE: 0.96745) avg lploss: 0.00000
train epoch 442 avg loss: 1.09054 (A-MSE: 0.97094) avg lploss: 0.00000
train epoch 443 avg loss: 1.11998 (A-MSE: 0.99690) avg lploss: 0.00000
train epoch 444 avg loss: 1.14773 (A-MSE: 1.01615) avg lploss: 0.00000
train epoch 445 avg loss: 1.11588 (A-MSE: 0.99194) avg lploss: 0.00000
==> val epoch 445 avg loss: 2.27231 (A-MSE: 2.02097) avg lploss: 0.00000
==> test epoch 445 avg loss: 2.41561 (A-MSE: 2.17205) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 1.10248 (A-MSE: 0.98494) avg lploss: 0.00000
train epoch 447 avg loss: 1.02693 (A-MSE: 0.91254) avg lploss: 0.00000
train epoch 448 avg loss: 1.01633 (A-MSE: 0.89945) avg lploss: 0.00000
train epoch 449 avg loss: 1.09188 (A-MSE: 0.96970) avg lploss: 0.00000
train epoch 450 avg loss: 1.17332 (A-MSE: 1.03962) avg lploss: 0.00000
==> val epoch 450 avg loss: 2.13497 (A-MSE: 1.89155) avg lploss: 0.00000
==> test epoch 450 avg loss: 2.34339 (A-MSE: 2.10066) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 3 out of 50
train epoch 451 avg loss: 1.30613 (A-MSE: 1.16328) avg lploss: 0.00000
train epoch 452 avg loss: 1.40245 (A-MSE: 1.24933) avg lploss: 0.00000
train epoch 453 avg loss: 1.16774 (A-MSE: 1.04021) avg lploss: 0.00000
train epoch 454 avg loss: 1.12290 (A-MSE: 0.99604) avg lploss: 0.00000
train epoch 455 avg loss: 1.11885 (A-MSE: 0.99678) avg lploss: 0.00000
==> val epoch 455 avg loss: 2.45056 (A-MSE: 2.19215) avg lploss: 0.00000
==> test epoch 455 avg loss: 2.45519 (A-MSE: 2.21557) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 4 out of 50
train epoch 456 avg loss: 1.31429 (A-MSE: 1.16752) avg lploss: 0.00000
train epoch 457 avg loss: 1.19201 (A-MSE: 1.06181) avg lploss: 0.00000
train epoch 458 avg loss: 1.19162 (A-MSE: 1.06170) avg lploss: 0.00000
train epoch 459 avg loss: 1.07329 (A-MSE: 0.95831) avg lploss: 0.00000
train epoch 460 avg loss: 1.36349 (A-MSE: 1.21328) avg lploss: 0.00000
==> val epoch 460 avg loss: 2.21523 (A-MSE: 1.96529) avg lploss: 0.00000
==> test epoch 460 avg loss: 2.45885 (A-MSE: 2.20093) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 5 out of 50
train epoch 461 avg loss: 1.21607 (A-MSE: 1.08389) avg lploss: 0.00000
train epoch 462 avg loss: 1.14239 (A-MSE: 1.02023) avg lploss: 0.00000
train epoch 463 avg loss: 1.09449 (A-MSE: 0.97149) avg lploss: 0.00000
train epoch 464 avg loss: 1.11271 (A-MSE: 0.98498) avg lploss: 0.00000
train epoch 465 avg loss: 1.09916 (A-MSE: 0.97487) avg lploss: 0.00000
==> val epoch 465 avg loss: 2.07251 (A-MSE: 1.84707) avg lploss: 0.00000
==> test epoch 465 avg loss: 2.28735 (A-MSE: 2.05495) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 6 out of 50
train epoch 466 avg loss: 1.00556 (A-MSE: 0.89436) avg lploss: 0.00000
train epoch 467 avg loss: 1.01212 (A-MSE: 0.90059) avg lploss: 0.00000
train epoch 468 avg loss: 1.08631 (A-MSE: 0.96061) avg lploss: 0.00000
train epoch 469 avg loss: 1.05788 (A-MSE: 0.94235) avg lploss: 0.00000
train epoch 470 avg loss: 1.13686 (A-MSE: 1.00962) avg lploss: 0.00000
==> val epoch 470 avg loss: 2.70115 (A-MSE: 2.40834) avg lploss: 0.00000
==> test epoch 470 avg loss: 2.93082 (A-MSE: 2.63776) avg lploss: 0.00000
*** Best Val Loss: 2.06288 	 Best Test Loss: 2.27467 	 Best epoch 435
EarlyStopping counter: 7 out of 50
train epoch 471 avg loss: 1.15669 (A-MSE: 1.02634) avg lploss: 0.00000
train epoch 472 avg loss: 1.10794 (A-MSE: 0.98745) avg lploss: 0.00000
train epoch 473 avg loss: 0.99209 (A-MSE: 0.88121) avg lploss: 0.00000
train epoch 474 avg loss: 1.06100 (A-MSE: 0.94066) avg lploss: 0.00000
train epoch 475 avg loss: 1.07241 (A-MSE: 0.95423) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.93527 (A-MSE: 1.72433) avg lploss: 0.00000
==> test epoch 475 avg loss: 2.18729 (A-MSE: 1.97466) avg lploss: 0.00000
*** Best Val Loss: 1.93527 	 Best Test Loss: 2.18729 	 Best epoch 475
Validation loss decreased (2.062876 --> 1.935274).  Saving model ...
train epoch 476 avg loss: 0.99684 (A-MSE: 0.89005) avg lploss: 0.00000
train epoch 477 avg loss: 1.02012 (A-MSE: 0.90401) avg lploss: 0.00000
train epoch 478 avg loss: 1.00379 (A-MSE: 0.89227) avg lploss: 0.00000
train epoch 479 avg loss: 1.10330 (A-MSE: 0.98406) avg lploss: 0.00000
train epoch 480 avg loss: 1.03176 (A-MSE: 0.91204) avg lploss: 0.00000
==> val epoch 480 avg loss: 2.35378 (A-MSE: 2.12514) avg lploss: 0.00000
==> test epoch 480 avg loss: 2.46109 (A-MSE: 2.23484) avg lploss: 0.00000
*** Best Val Loss: 1.93527 	 Best Test Loss: 2.18729 	 Best epoch 475
EarlyStopping counter: 1 out of 50
train epoch 481 avg loss: 1.03660 (A-MSE: 0.92105) avg lploss: 0.00000
train epoch 482 avg loss: 1.01080 (A-MSE: 0.89389) avg lploss: 0.00000
train epoch 483 avg loss: 1.03667 (A-MSE: 0.92107) avg lploss: 0.00000
train epoch 484 avg loss: 1.02848 (A-MSE: 0.91467) avg lploss: 0.00000
train epoch 485 avg loss: 1.14368 (A-MSE: 1.01730) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.98402 (A-MSE: 1.75991) avg lploss: 0.00000
==> test epoch 485 avg loss: 2.20476 (A-MSE: 1.97623) avg lploss: 0.00000
*** Best Val Loss: 1.93527 	 Best Test Loss: 2.18729 	 Best epoch 475
EarlyStopping counter: 2 out of 50
train epoch 486 avg loss: 1.08949 (A-MSE: 0.96686) avg lploss: 0.00000
train epoch 487 avg loss: 1.03628 (A-MSE: 0.92244) avg lploss: 0.00000
train epoch 488 avg loss: 0.98597 (A-MSE: 0.87412) avg lploss: 0.00000
train epoch 489 avg loss: 0.97788 (A-MSE: 0.86955) avg lploss: 0.00000
train epoch 490 avg loss: 1.09105 (A-MSE: 0.96649) avg lploss: 0.00000
==> val epoch 490 avg loss: 1.99284 (A-MSE: 1.78776) avg lploss: 0.00000
==> test epoch 490 avg loss: 2.22000 (A-MSE: 2.01402) avg lploss: 0.00000
*** Best Val Loss: 1.93527 	 Best Test Loss: 2.18729 	 Best epoch 475
EarlyStopping counter: 3 out of 50
train epoch 491 avg loss: 1.00157 (A-MSE: 0.88848) avg lploss: 0.00000
train epoch 492 avg loss: 0.98181 (A-MSE: 0.87082) avg lploss: 0.00000
train epoch 493 avg loss: 0.99794 (A-MSE: 0.88691) avg lploss: 0.00000
train epoch 494 avg loss: 1.07785 (A-MSE: 0.96019) avg lploss: 0.00000
train epoch 495 avg loss: 1.11575 (A-MSE: 0.99249) avg lploss: 0.00000
==> val epoch 495 avg loss: 2.23965 (A-MSE: 1.99996) avg lploss: 0.00000
==> test epoch 495 avg loss: 2.62887 (A-MSE: 2.38504) avg lploss: 0.00000
*** Best Val Loss: 1.93527 	 Best Test Loss: 2.18729 	 Best epoch 475
EarlyStopping counter: 4 out of 50
train epoch 496 avg loss: 1.14746 (A-MSE: 1.01276) avg lploss: 0.00000
train epoch 497 avg loss: 0.96572 (A-MSE: 0.85982) avg lploss: 0.00000
train epoch 498 avg loss: 0.99121 (A-MSE: 0.88066) avg lploss: 0.00000
train epoch 499 avg loss: 1.26671 (A-MSE: 1.12467) avg lploss: 0.00000
train epoch 500 avg loss: 1.17104 (A-MSE: 1.04618) avg lploss: 0.00000
==> val epoch 500 avg loss: 2.29412 (A-MSE: 2.02822) avg lploss: 0.00000
==> test epoch 500 avg loss: 2.50098 (A-MSE: 2.23675) avg lploss: 0.00000
*** Best Val Loss: 1.93527 	 Best Test Loss: 2.18729 	 Best epoch 475
EarlyStopping counter: 5 out of 50
train epoch 501 avg loss: 1.01402 (A-MSE: 0.89727) avg lploss: 0.00000
train epoch 502 avg loss: 0.94856 (A-MSE: 0.84210) avg lploss: 0.00000
train epoch 503 avg loss: 0.92570 (A-MSE: 0.82049) avg lploss: 0.00000
train epoch 504 avg loss: 1.01219 (A-MSE: 0.89938) avg lploss: 0.00000
train epoch 505 avg loss: 1.02578 (A-MSE: 0.91367) avg lploss: 0.00000
==> val epoch 505 avg loss: 1.90930 (A-MSE: 1.70160) avg lploss: 0.00000
==> test epoch 505 avg loss: 2.24382 (A-MSE: 2.02968) avg lploss: 0.00000
*** Best Val Loss: 1.90930 	 Best Test Loss: 2.24382 	 Best epoch 505
Validation loss decreased (1.935274 --> 1.909298).  Saving model ...
train epoch 506 avg loss: 0.93118 (A-MSE: 0.82624) avg lploss: 0.00000
train epoch 507 avg loss: 0.89933 (A-MSE: 0.79847) avg lploss: 0.00000
train epoch 508 avg loss: 0.96373 (A-MSE: 0.85636) avg lploss: 0.00000
train epoch 509 avg loss: 0.95041 (A-MSE: 0.83741) avg lploss: 0.00000
train epoch 510 avg loss: 0.93059 (A-MSE: 0.82914) avg lploss: 0.00000
==> val epoch 510 avg loss: 2.20589 (A-MSE: 1.95597) avg lploss: 0.00000
==> test epoch 510 avg loss: 2.37457 (A-MSE: 2.12631) avg lploss: 0.00000
*** Best Val Loss: 1.90930 	 Best Test Loss: 2.24382 	 Best epoch 505
EarlyStopping counter: 1 out of 50
train epoch 511 avg loss: 0.97448 (A-MSE: 0.86630) avg lploss: 0.00000
train epoch 512 avg loss: 0.93975 (A-MSE: 0.83795) avg lploss: 0.00000
train epoch 513 avg loss: 1.01668 (A-MSE: 0.90185) avg lploss: 0.00000
train epoch 514 avg loss: 0.91085 (A-MSE: 0.80784) avg lploss: 0.00000
train epoch 515 avg loss: 0.82560 (A-MSE: 0.73283) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.99092 (A-MSE: 1.76147) avg lploss: 0.00000
==> test epoch 515 avg loss: 2.14136 (A-MSE: 1.92168) avg lploss: 0.00000
*** Best Val Loss: 1.90930 	 Best Test Loss: 2.24382 	 Best epoch 505
EarlyStopping counter: 2 out of 50
train epoch 516 avg loss: 0.87146 (A-MSE: 0.77355) avg lploss: 0.00000
train epoch 517 avg loss: 0.92335 (A-MSE: 0.81908) avg lploss: 0.00000
train epoch 518 avg loss: 0.87902 (A-MSE: 0.78140) avg lploss: 0.00000
train epoch 519 avg loss: 1.00395 (A-MSE: 0.89208) avg lploss: 0.00000
train epoch 520 avg loss: 1.02146 (A-MSE: 0.91067) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.82981 (A-MSE: 1.62986) avg lploss: 0.00000
==> test epoch 520 avg loss: 2.05393 (A-MSE: 1.85753) avg lploss: 0.00000
*** Best Val Loss: 1.82981 	 Best Test Loss: 2.05393 	 Best epoch 520
Validation loss decreased (1.909298 --> 1.829814).  Saving model ...
train epoch 521 avg loss: 0.94390 (A-MSE: 0.84164) avg lploss: 0.00000
train epoch 522 avg loss: 0.93105 (A-MSE: 0.82545) avg lploss: 0.00000
train epoch 523 avg loss: 0.96950 (A-MSE: 0.85694) avg lploss: 0.00000
train epoch 524 avg loss: 0.89832 (A-MSE: 0.79819) avg lploss: 0.00000
train epoch 525 avg loss: 1.05991 (A-MSE: 0.94744) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.80382 (A-MSE: 1.60511) avg lploss: 0.00000
==> test epoch 525 avg loss: 2.11496 (A-MSE: 1.91420) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
Validation loss decreased (1.829814 --> 1.803822).  Saving model ...
train epoch 526 avg loss: 1.04538 (A-MSE: 0.93438) avg lploss: 0.00000
train epoch 527 avg loss: 0.96564 (A-MSE: 0.85842) avg lploss: 0.00000
train epoch 528 avg loss: 0.98696 (A-MSE: 0.87428) avg lploss: 0.00000
train epoch 529 avg loss: 0.99793 (A-MSE: 0.89019) avg lploss: 0.00000
train epoch 530 avg loss: 0.91094 (A-MSE: 0.80818) avg lploss: 0.00000
==> val epoch 530 avg loss: 2.07164 (A-MSE: 1.85368) avg lploss: 0.00000
==> test epoch 530 avg loss: 2.25028 (A-MSE: 2.02575) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 1 out of 50
train epoch 531 avg loss: 0.94499 (A-MSE: 0.84921) avg lploss: 0.00000
train epoch 532 avg loss: 0.92414 (A-MSE: 0.81778) avg lploss: 0.00000
train epoch 533 avg loss: 0.95137 (A-MSE: 0.84382) avg lploss: 0.00000
train epoch 534 avg loss: 0.97753 (A-MSE: 0.87048) avg lploss: 0.00000
train epoch 535 avg loss: 0.88528 (A-MSE: 0.79298) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.84278 (A-MSE: 1.63179) avg lploss: 0.00000
==> test epoch 535 avg loss: 2.02703 (A-MSE: 1.82048) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 2 out of 50
train epoch 536 avg loss: 0.82182 (A-MSE: 0.72590) avg lploss: 0.00000
train epoch 537 avg loss: 0.89454 (A-MSE: 0.79288) avg lploss: 0.00000
train epoch 538 avg loss: 0.87697 (A-MSE: 0.77922) avg lploss: 0.00000
train epoch 539 avg loss: 0.83127 (A-MSE: 0.74022) avg lploss: 0.00000
train epoch 540 avg loss: 0.86917 (A-MSE: 0.76945) avg lploss: 0.00000
==> val epoch 540 avg loss: 2.01163 (A-MSE: 1.78039) avg lploss: 0.00000
==> test epoch 540 avg loss: 2.18641 (A-MSE: 1.96114) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 3 out of 50
train epoch 541 avg loss: 0.87141 (A-MSE: 0.77005) avg lploss: 0.00000
train epoch 542 avg loss: 0.84149 (A-MSE: 0.74534) avg lploss: 0.00000
train epoch 543 avg loss: 0.94220 (A-MSE: 0.83407) avg lploss: 0.00000
train epoch 544 avg loss: 0.97538 (A-MSE: 0.87492) avg lploss: 0.00000
train epoch 545 avg loss: 1.04834 (A-MSE: 0.92821) avg lploss: 0.00000
==> val epoch 545 avg loss: 1.87846 (A-MSE: 1.68986) avg lploss: 0.00000
==> test epoch 545 avg loss: 2.17162 (A-MSE: 1.96879) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 4 out of 50
train epoch 546 avg loss: 0.92665 (A-MSE: 0.82569) avg lploss: 0.00000
train epoch 547 avg loss: 0.98651 (A-MSE: 0.87300) avg lploss: 0.00000
train epoch 548 avg loss: 0.83359 (A-MSE: 0.73871) avg lploss: 0.00000
train epoch 549 avg loss: 0.79262 (A-MSE: 0.69900) avg lploss: 0.00000
train epoch 550 avg loss: 0.80003 (A-MSE: 0.71085) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.88932 (A-MSE: 1.67106) avg lploss: 0.00000
==> test epoch 550 avg loss: 2.14432 (A-MSE: 1.91756) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 5 out of 50
train epoch 551 avg loss: 0.99769 (A-MSE: 0.88240) avg lploss: 0.00000
train epoch 552 avg loss: 1.04302 (A-MSE: 0.92737) avg lploss: 0.00000
train epoch 553 avg loss: 0.87435 (A-MSE: 0.77317) avg lploss: 0.00000
train epoch 554 avg loss: 0.82553 (A-MSE: 0.73362) avg lploss: 0.00000
train epoch 555 avg loss: 0.90242 (A-MSE: 0.79791) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.95133 (A-MSE: 1.72117) avg lploss: 0.00000
==> test epoch 555 avg loss: 2.12951 (A-MSE: 1.90569) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 6 out of 50
train epoch 556 avg loss: 0.87188 (A-MSE: 0.77438) avg lploss: 0.00000
train epoch 557 avg loss: 0.90007 (A-MSE: 0.79749) avg lploss: 0.00000
train epoch 558 avg loss: 0.89910 (A-MSE: 0.79386) avg lploss: 0.00000
train epoch 559 avg loss: 0.87302 (A-MSE: 0.78177) avg lploss: 0.00000
train epoch 560 avg loss: 0.96597 (A-MSE: 0.85845) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.89177 (A-MSE: 1.68872) avg lploss: 0.00000
==> test epoch 560 avg loss: 2.22916 (A-MSE: 2.00893) avg lploss: 0.00000
*** Best Val Loss: 1.80382 	 Best Test Loss: 2.11496 	 Best epoch 525
EarlyStopping counter: 7 out of 50
train epoch 561 avg loss: 0.87553 (A-MSE: 0.77412) avg lploss: 0.00000
train epoch 562 avg loss: 0.81905 (A-MSE: 0.72776) avg lploss: 0.00000
train epoch 563 avg loss: 0.83571 (A-MSE: 0.74028) avg lploss: 0.00000
train epoch 564 avg loss: 0.80011 (A-MSE: 0.70673) avg lploss: 0.00000
train epoch 565 avg loss: 0.78970 (A-MSE: 0.69928) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.77293 (A-MSE: 1.58956) avg lploss: 0.00000
==> test epoch 565 avg loss: 1.94289 (A-MSE: 1.75558) avg lploss: 0.00000
*** Best Val Loss: 1.77293 	 Best Test Loss: 1.94289 	 Best epoch 565
Validation loss decreased (1.803822 --> 1.772933).  Saving model ...
train epoch 566 avg loss: 0.81443 (A-MSE: 0.72493) avg lploss: 0.00000
train epoch 567 avg loss: 0.89161 (A-MSE: 0.79042) avg lploss: 0.00000
train epoch 568 avg loss: 0.85223 (A-MSE: 0.75195) avg lploss: 0.00000
train epoch 569 avg loss: 0.84016 (A-MSE: 0.74680) avg lploss: 0.00000
train epoch 570 avg loss: 0.84202 (A-MSE: 0.74727) avg lploss: 0.00000
==> val epoch 570 avg loss: 1.67382 (A-MSE: 1.49501) avg lploss: 0.00000
==> test epoch 570 avg loss: 1.99189 (A-MSE: 1.81288) avg lploss: 0.00000
*** Best Val Loss: 1.67382 	 Best Test Loss: 1.99189 	 Best epoch 570
Validation loss decreased (1.772933 --> 1.673815).  Saving model ...
train epoch 571 avg loss: 0.86733 (A-MSE: 0.77448) avg lploss: 0.00000
train epoch 572 avg loss: 0.82705 (A-MSE: 0.73301) avg lploss: 0.00000
train epoch 573 avg loss: 0.78234 (A-MSE: 0.69046) avg lploss: 0.00000
train epoch 574 avg loss: 0.78501 (A-MSE: 0.69723) avg lploss: 0.00000
train epoch 575 avg loss: 0.76663 (A-MSE: 0.68094) avg lploss: 0.00000
==> val epoch 575 avg loss: 1.79431 (A-MSE: 1.59155) avg lploss: 0.00000
==> test epoch 575 avg loss: 2.01486 (A-MSE: 1.80664) avg lploss: 0.00000
*** Best Val Loss: 1.67382 	 Best Test Loss: 1.99189 	 Best epoch 570
EarlyStopping counter: 1 out of 50
train epoch 576 avg loss: 0.80854 (A-MSE: 0.71620) avg lploss: 0.00000
train epoch 577 avg loss: 0.80697 (A-MSE: 0.71463) avg lploss: 0.00000
train epoch 578 avg loss: 0.78714 (A-MSE: 0.69812) avg lploss: 0.00000
train epoch 579 avg loss: 0.89298 (A-MSE: 0.79101) avg lploss: 0.00000
train epoch 580 avg loss: 0.87472 (A-MSE: 0.77735) avg lploss: 0.00000
==> val epoch 580 avg loss: 1.93946 (A-MSE: 1.71458) avg lploss: 0.00000
==> test epoch 580 avg loss: 2.22881 (A-MSE: 1.99542) avg lploss: 0.00000
*** Best Val Loss: 1.67382 	 Best Test Loss: 1.99189 	 Best epoch 570
EarlyStopping counter: 2 out of 50
train epoch 581 avg loss: 0.78252 (A-MSE: 0.69335) avg lploss: 0.00000
train epoch 582 avg loss: 0.82517 (A-MSE: 0.73243) avg lploss: 0.00000
train epoch 583 avg loss: 0.80747 (A-MSE: 0.71537) avg lploss: 0.00000
train epoch 584 avg loss: 1.01838 (A-MSE: 0.91164) avg lploss: 0.00000
train epoch 585 avg loss: 0.90247 (A-MSE: 0.79814) avg lploss: 0.00000
==> val epoch 585 avg loss: 2.04326 (A-MSE: 1.82748) avg lploss: 0.00000
==> test epoch 585 avg loss: 2.13523 (A-MSE: 1.91910) avg lploss: 0.00000
*** Best Val Loss: 1.67382 	 Best Test Loss: 1.99189 	 Best epoch 570
EarlyStopping counter: 3 out of 50
train epoch 586 avg loss: 0.79662 (A-MSE: 0.70496) avg lploss: 0.00000
train epoch 587 avg loss: 0.83624 (A-MSE: 0.74096) avg lploss: 0.00000
train epoch 588 avg loss: 0.90944 (A-MSE: 0.80441) avg lploss: 0.00000
train epoch 589 avg loss: 0.88016 (A-MSE: 0.77865) avg lploss: 0.00000
train epoch 590 avg loss: 0.95049 (A-MSE: 0.84730) avg lploss: 0.00000
==> val epoch 590 avg loss: 2.08251 (A-MSE: 1.84273) avg lploss: 0.00000
==> test epoch 590 avg loss: 2.39816 (A-MSE: 2.15093) avg lploss: 0.00000
*** Best Val Loss: 1.67382 	 Best Test Loss: 1.99189 	 Best epoch 570
EarlyStopping counter: 4 out of 50
train epoch 591 avg loss: 0.83215 (A-MSE: 0.73007) avg lploss: 0.00000
train epoch 592 avg loss: 0.80812 (A-MSE: 0.71566) avg lploss: 0.00000
train epoch 593 avg loss: 0.73651 (A-MSE: 0.65297) avg lploss: 0.00000
train epoch 594 avg loss: 0.84981 (A-MSE: 0.75032) avg lploss: 0.00000
train epoch 595 avg loss: 0.86228 (A-MSE: 0.76532) avg lploss: 0.00000
==> val epoch 595 avg loss: 1.79918 (A-MSE: 1.59920) avg lploss: 0.00000
==> test epoch 595 avg loss: 2.06334 (A-MSE: 1.84970) avg lploss: 0.00000
*** Best Val Loss: 1.67382 	 Best Test Loss: 1.99189 	 Best epoch 570
EarlyStopping counter: 5 out of 50
train epoch 596 avg loss: 0.81346 (A-MSE: 0.72595) avg lploss: 0.00000
train epoch 597 avg loss: 0.84241 (A-MSE: 0.74822) avg lploss: 0.00000
train epoch 598 avg loss: 0.84914 (A-MSE: 0.75423) avg lploss: 0.00000
train epoch 599 avg loss: 0.90668 (A-MSE: 0.80117) avg lploss: 0.00000
train epoch 600 avg loss: 0.84117 (A-MSE: 0.74387) avg lploss: 0.00000
==> val epoch 600 avg loss: 1.63420 (A-MSE: 1.44399) avg lploss: 0.00000
==> test epoch 600 avg loss: 1.88125 (A-MSE: 1.69563) avg lploss: 0.00000
*** Best Val Loss: 1.63420 	 Best Test Loss: 1.88125 	 Best epoch 600
Validation loss decreased (1.673815 --> 1.634200).  Saving model ...
train epoch 601 avg loss: 0.73716 (A-MSE: 0.65620) avg lploss: 0.00000
train epoch 602 avg loss: 0.69863 (A-MSE: 0.61922) avg lploss: 0.00000
train epoch 603 avg loss: 0.73315 (A-MSE: 0.64656) avg lploss: 0.00000
train epoch 604 avg loss: 0.76344 (A-MSE: 0.67479) avg lploss: 0.00000
train epoch 605 avg loss: 0.80980 (A-MSE: 0.72025) avg lploss: 0.00000
==> val epoch 605 avg loss: 1.70246 (A-MSE: 1.52531) avg lploss: 0.00000
==> test epoch 605 avg loss: 1.84487 (A-MSE: 1.66574) avg lploss: 0.00000
*** Best Val Loss: 1.63420 	 Best Test Loss: 1.88125 	 Best epoch 600
EarlyStopping counter: 1 out of 50
train epoch 606 avg loss: 0.78523 (A-MSE: 0.69180) avg lploss: 0.00000
train epoch 607 avg loss: 0.75807 (A-MSE: 0.67405) avg lploss: 0.00000
train epoch 608 avg loss: 0.80107 (A-MSE: 0.70808) avg lploss: 0.00000
train epoch 609 avg loss: 0.88544 (A-MSE: 0.78654) avg lploss: 0.00000
train epoch 610 avg loss: 0.75803 (A-MSE: 0.67520) avg lploss: 0.00000
==> val epoch 610 avg loss: 1.82652 (A-MSE: 1.61601) avg lploss: 0.00000
==> test epoch 610 avg loss: 2.05514 (A-MSE: 1.84280) avg lploss: 0.00000
*** Best Val Loss: 1.63420 	 Best Test Loss: 1.88125 	 Best epoch 600
EarlyStopping counter: 2 out of 50
train epoch 611 avg loss: 0.77647 (A-MSE: 0.68980) avg lploss: 0.00000
train epoch 612 avg loss: 0.79970 (A-MSE: 0.70778) avg lploss: 0.00000
train epoch 613 avg loss: 0.84620 (A-MSE: 0.74674) avg lploss: 0.00000
train epoch 614 avg loss: 0.87223 (A-MSE: 0.77124) avg lploss: 0.00000
train epoch 615 avg loss: 0.78574 (A-MSE: 0.69959) avg lploss: 0.00000
==> val epoch 615 avg loss: 1.60087 (A-MSE: 1.42416) avg lploss: 0.00000
==> test epoch 615 avg loss: 1.74730 (A-MSE: 1.57324) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
Validation loss decreased (1.634200 --> 1.600874).  Saving model ...
train epoch 616 avg loss: 0.75369 (A-MSE: 0.66869) avg lploss: 0.00000
train epoch 617 avg loss: 0.73818 (A-MSE: 0.65399) avg lploss: 0.00000
train epoch 618 avg loss: 0.72313 (A-MSE: 0.63944) avg lploss: 0.00000
train epoch 619 avg loss: 0.80820 (A-MSE: 0.71576) avg lploss: 0.00000
train epoch 620 avg loss: 0.81685 (A-MSE: 0.72315) avg lploss: 0.00000
==> val epoch 620 avg loss: 1.69952 (A-MSE: 1.50907) avg lploss: 0.00000
==> test epoch 620 avg loss: 2.04823 (A-MSE: 1.84933) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.76488 (A-MSE: 0.67964) avg lploss: 0.00000
train epoch 622 avg loss: 0.74626 (A-MSE: 0.65644) avg lploss: 0.00000
train epoch 623 avg loss: 0.69187 (A-MSE: 0.61181) avg lploss: 0.00000
train epoch 624 avg loss: 0.78522 (A-MSE: 0.70026) avg lploss: 0.00000
train epoch 625 avg loss: 0.74701 (A-MSE: 0.66178) avg lploss: 0.00000
==> val epoch 625 avg loss: 1.69222 (A-MSE: 1.50622) avg lploss: 0.00000
==> test epoch 625 avg loss: 1.81286 (A-MSE: 1.63028) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.77677 (A-MSE: 0.68817) avg lploss: 0.00000
train epoch 627 avg loss: 0.72482 (A-MSE: 0.64462) avg lploss: 0.00000
train epoch 628 avg loss: 0.75647 (A-MSE: 0.66835) avg lploss: 0.00000
train epoch 629 avg loss: 0.84975 (A-MSE: 0.75710) avg lploss: 0.00000
train epoch 630 avg loss: 0.91332 (A-MSE: 0.80897) avg lploss: 0.00000
==> val epoch 630 avg loss: 2.29149 (A-MSE: 2.06758) avg lploss: 0.00000
==> test epoch 630 avg loss: 2.61656 (A-MSE: 2.36306) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 3 out of 50
train epoch 631 avg loss: 0.92061 (A-MSE: 0.81363) avg lploss: 0.00000
train epoch 632 avg loss: 0.86044 (A-MSE: 0.76440) avg lploss: 0.00000
train epoch 633 avg loss: 0.73262 (A-MSE: 0.65002) avg lploss: 0.00000
train epoch 634 avg loss: 0.70698 (A-MSE: 0.62748) avg lploss: 0.00000
train epoch 635 avg loss: 0.67026 (A-MSE: 0.59238) avg lploss: 0.00000
==> val epoch 635 avg loss: 1.79099 (A-MSE: 1.59181) avg lploss: 0.00000
==> test epoch 635 avg loss: 1.88448 (A-MSE: 1.69670) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 4 out of 50
train epoch 636 avg loss: 0.71335 (A-MSE: 0.63082) avg lploss: 0.00000
train epoch 637 avg loss: 0.69331 (A-MSE: 0.61607) avg lploss: 0.00000
train epoch 638 avg loss: 0.74562 (A-MSE: 0.65960) avg lploss: 0.00000
train epoch 639 avg loss: 0.76003 (A-MSE: 0.67349) avg lploss: 0.00000
train epoch 640 avg loss: 0.71208 (A-MSE: 0.63159) avg lploss: 0.00000
==> val epoch 640 avg loss: 1.68189 (A-MSE: 1.49268) avg lploss: 0.00000
==> test epoch 640 avg loss: 1.82415 (A-MSE: 1.63865) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 5 out of 50
train epoch 641 avg loss: 0.74786 (A-MSE: 0.66414) avg lploss: 0.00000
train epoch 642 avg loss: 0.77303 (A-MSE: 0.68665) avg lploss: 0.00000
train epoch 643 avg loss: 0.71354 (A-MSE: 0.62836) avg lploss: 0.00000
train epoch 644 avg loss: 0.77924 (A-MSE: 0.69356) avg lploss: 0.00000
train epoch 645 avg loss: 0.81441 (A-MSE: 0.72010) avg lploss: 0.00000
==> val epoch 645 avg loss: 1.72169 (A-MSE: 1.53905) avg lploss: 0.00000
==> test epoch 645 avg loss: 1.80091 (A-MSE: 1.61388) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 6 out of 50
train epoch 646 avg loss: 0.65092 (A-MSE: 0.57572) avg lploss: 0.00000
train epoch 647 avg loss: 0.68491 (A-MSE: 0.60968) avg lploss: 0.00000
train epoch 648 avg loss: 0.72843 (A-MSE: 0.64347) avg lploss: 0.00000
train epoch 649 avg loss: 0.63926 (A-MSE: 0.56576) avg lploss: 0.00000
train epoch 650 avg loss: 0.67411 (A-MSE: 0.59797) avg lploss: 0.00000
==> val epoch 650 avg loss: 1.68421 (A-MSE: 1.50720) avg lploss: 0.00000
==> test epoch 650 avg loss: 1.83004 (A-MSE: 1.65982) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 7 out of 50
train epoch 651 avg loss: 0.74784 (A-MSE: 0.66532) avg lploss: 0.00000
train epoch 652 avg loss: 0.76961 (A-MSE: 0.68178) avg lploss: 0.00000
train epoch 653 avg loss: 0.69976 (A-MSE: 0.62006) avg lploss: 0.00000
train epoch 654 avg loss: 0.74597 (A-MSE: 0.66148) avg lploss: 0.00000
train epoch 655 avg loss: 0.69600 (A-MSE: 0.61697) avg lploss: 0.00000
==> val epoch 655 avg loss: 1.82931 (A-MSE: 1.62674) avg lploss: 0.00000
==> test epoch 655 avg loss: 1.93046 (A-MSE: 1.72817) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 8 out of 50
train epoch 656 avg loss: 0.66234 (A-MSE: 0.58453) avg lploss: 0.00000
train epoch 657 avg loss: 0.65510 (A-MSE: 0.58089) avg lploss: 0.00000
train epoch 658 avg loss: 0.63265 (A-MSE: 0.55861) avg lploss: 0.00000
train epoch 659 avg loss: 0.70606 (A-MSE: 0.62438) avg lploss: 0.00000
train epoch 660 avg loss: 0.69935 (A-MSE: 0.61915) avg lploss: 0.00000
==> val epoch 660 avg loss: 1.78630 (A-MSE: 1.59367) avg lploss: 0.00000
==> test epoch 660 avg loss: 1.81345 (A-MSE: 1.63523) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 9 out of 50
train epoch 661 avg loss: 0.63427 (A-MSE: 0.56192) avg lploss: 0.00000
train epoch 662 avg loss: 0.69449 (A-MSE: 0.61348) avg lploss: 0.00000
train epoch 663 avg loss: 0.66796 (A-MSE: 0.59050) avg lploss: 0.00000
train epoch 664 avg loss: 0.65072 (A-MSE: 0.57771) avg lploss: 0.00000
train epoch 665 avg loss: 0.63979 (A-MSE: 0.56640) avg lploss: 0.00000
==> val epoch 665 avg loss: 1.60601 (A-MSE: 1.43335) avg lploss: 0.00000
==> test epoch 665 avg loss: 1.81564 (A-MSE: 1.62613) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 10 out of 50
train epoch 666 avg loss: 0.66000 (A-MSE: 0.58302) avg lploss: 0.00000
train epoch 667 avg loss: 0.67313 (A-MSE: 0.59500) avg lploss: 0.00000
train epoch 668 avg loss: 0.69146 (A-MSE: 0.61546) avg lploss: 0.00000
train epoch 669 avg loss: 0.81291 (A-MSE: 0.72285) avg lploss: 0.00000
train epoch 670 avg loss: 0.79860 (A-MSE: 0.70730) avg lploss: 0.00000
==> val epoch 670 avg loss: 1.67425 (A-MSE: 1.48314) avg lploss: 0.00000
==> test epoch 670 avg loss: 1.95881 (A-MSE: 1.75873) avg lploss: 0.00000
*** Best Val Loss: 1.60087 	 Best Test Loss: 1.74730 	 Best epoch 615
EarlyStopping counter: 11 out of 50
train epoch 671 avg loss: 0.80551 (A-MSE: 0.71365) avg lploss: 0.00000
train epoch 672 avg loss: 0.79687 (A-MSE: 0.71073) avg lploss: 0.00000
train epoch 673 avg loss: 0.77078 (A-MSE: 0.68416) avg lploss: 0.00000
train epoch 674 avg loss: 0.69801 (A-MSE: 0.61809) avg lploss: 0.00000
train epoch 675 avg loss: 0.69148 (A-MSE: 0.61113) avg lploss: 0.00000
==> val epoch 675 avg loss: 1.58079 (A-MSE: 1.40851) avg lploss: 0.00000
==> test epoch 675 avg loss: 1.86863 (A-MSE: 1.69030) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
Validation loss decreased (1.600874 --> 1.580791).  Saving model ...
train epoch 676 avg loss: 0.66560 (A-MSE: 0.58847) avg lploss: 0.00000
train epoch 677 avg loss: 0.66975 (A-MSE: 0.59668) avg lploss: 0.00000
train epoch 678 avg loss: 0.67683 (A-MSE: 0.59603) avg lploss: 0.00000
train epoch 679 avg loss: 0.73097 (A-MSE: 0.64785) avg lploss: 0.00000
train epoch 680 avg loss: 0.82183 (A-MSE: 0.72941) avg lploss: 0.00000
==> val epoch 680 avg loss: 1.61074 (A-MSE: 1.42696) avg lploss: 0.00000
==> test epoch 680 avg loss: 1.77455 (A-MSE: 1.58555) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 1 out of 50
train epoch 681 avg loss: 0.71450 (A-MSE: 0.63100) avg lploss: 0.00000
train epoch 682 avg loss: 0.74843 (A-MSE: 0.66145) avg lploss: 0.00000
train epoch 683 avg loss: 0.66903 (A-MSE: 0.59486) avg lploss: 0.00000
train epoch 684 avg loss: 0.70387 (A-MSE: 0.62156) avg lploss: 0.00000
train epoch 685 avg loss: 0.70186 (A-MSE: 0.61881) avg lploss: 0.00000
==> val epoch 685 avg loss: 1.74643 (A-MSE: 1.55227) avg lploss: 0.00000
==> test epoch 685 avg loss: 1.90319 (A-MSE: 1.71354) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 2 out of 50
train epoch 686 avg loss: 0.75512 (A-MSE: 0.66899) avg lploss: 0.00000
train epoch 687 avg loss: 0.73559 (A-MSE: 0.65179) avg lploss: 0.00000
train epoch 688 avg loss: 0.66909 (A-MSE: 0.59447) avg lploss: 0.00000
train epoch 689 avg loss: 0.63021 (A-MSE: 0.55646) avg lploss: 0.00000
train epoch 690 avg loss: 0.60954 (A-MSE: 0.53881) avg lploss: 0.00000
==> val epoch 690 avg loss: 1.62739 (A-MSE: 1.45582) avg lploss: 0.00000
==> test epoch 690 avg loss: 1.65133 (A-MSE: 1.48218) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 3 out of 50
train epoch 691 avg loss: 0.65083 (A-MSE: 0.57455) avg lploss: 0.00000
train epoch 692 avg loss: 0.65902 (A-MSE: 0.58217) avg lploss: 0.00000
train epoch 693 avg loss: 0.72520 (A-MSE: 0.64075) avg lploss: 0.00000
train epoch 694 avg loss: 0.70480 (A-MSE: 0.62575) avg lploss: 0.00000
train epoch 695 avg loss: 0.69962 (A-MSE: 0.62349) avg lploss: 0.00000
==> val epoch 695 avg loss: 1.75789 (A-MSE: 1.56576) avg lploss: 0.00000
==> test epoch 695 avg loss: 1.95854 (A-MSE: 1.76026) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 4 out of 50
train epoch 696 avg loss: 0.69248 (A-MSE: 0.61410) avg lploss: 0.00000
train epoch 697 avg loss: 0.62607 (A-MSE: 0.55399) avg lploss: 0.00000
train epoch 698 avg loss: 0.70787 (A-MSE: 0.62202) avg lploss: 0.00000
train epoch 699 avg loss: 0.68001 (A-MSE: 0.60849) avg lploss: 0.00000
train epoch 700 avg loss: 0.67167 (A-MSE: 0.59588) avg lploss: 0.00000
==> val epoch 700 avg loss: 1.68862 (A-MSE: 1.51393) avg lploss: 0.00000
==> test epoch 700 avg loss: 1.74608 (A-MSE: 1.57207) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 5 out of 50
train epoch 701 avg loss: 0.75734 (A-MSE: 0.67147) avg lploss: 0.00000
train epoch 702 avg loss: 0.71399 (A-MSE: 0.63528) avg lploss: 0.00000
train epoch 703 avg loss: 0.60180 (A-MSE: 0.53149) avg lploss: 0.00000
train epoch 704 avg loss: 0.61615 (A-MSE: 0.54312) avg lploss: 0.00000
train epoch 705 avg loss: 0.63246 (A-MSE: 0.56045) avg lploss: 0.00000
==> val epoch 705 avg loss: 1.60313 (A-MSE: 1.43606) avg lploss: 0.00000
==> test epoch 705 avg loss: 1.67393 (A-MSE: 1.50528) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 6 out of 50
train epoch 706 avg loss: 0.59393 (A-MSE: 0.52610) avg lploss: 0.00000
train epoch 707 avg loss: 0.59413 (A-MSE: 0.52334) avg lploss: 0.00000
train epoch 708 avg loss: 0.61776 (A-MSE: 0.54635) avg lploss: 0.00000
train epoch 709 avg loss: 0.62852 (A-MSE: 0.55536) avg lploss: 0.00000
train epoch 710 avg loss: 0.60413 (A-MSE: 0.53301) avg lploss: 0.00000
==> val epoch 710 avg loss: 1.71101 (A-MSE: 1.52594) avg lploss: 0.00000
==> test epoch 710 avg loss: 1.89460 (A-MSE: 1.70333) avg lploss: 0.00000
*** Best Val Loss: 1.58079 	 Best Test Loss: 1.86863 	 Best epoch 675
EarlyStopping counter: 7 out of 50
train epoch 711 avg loss: 0.61249 (A-MSE: 0.54121) avg lploss: 0.00000
train epoch 712 avg loss: 0.63821 (A-MSE: 0.56693) avg lploss: 0.00000
train epoch 713 avg loss: 0.63668 (A-MSE: 0.56367) avg lploss: 0.00000
train epoch 714 avg loss: 0.58283 (A-MSE: 0.51595) avg lploss: 0.00000
train epoch 715 avg loss: 0.59870 (A-MSE: 0.52974) avg lploss: 0.00000
==> val epoch 715 avg loss: 1.43905 (A-MSE: 1.27102) avg lploss: 0.00000
==> test epoch 715 avg loss: 1.54089 (A-MSE: 1.37821) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
Validation loss decreased (1.580791 --> 1.439053).  Saving model ...
train epoch 716 avg loss: 0.57683 (A-MSE: 0.50978) avg lploss: 0.00000
train epoch 717 avg loss: 0.63220 (A-MSE: 0.55988) avg lploss: 0.00000
train epoch 718 avg loss: 0.59004 (A-MSE: 0.52145) avg lploss: 0.00000
train epoch 719 avg loss: 0.62310 (A-MSE: 0.55254) avg lploss: 0.00000
train epoch 720 avg loss: 0.58239 (A-MSE: 0.51637) avg lploss: 0.00000
==> val epoch 720 avg loss: 1.67806 (A-MSE: 1.48287) avg lploss: 0.00000
==> test epoch 720 avg loss: 1.84478 (A-MSE: 1.65616) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 1 out of 50
train epoch 721 avg loss: 0.61683 (A-MSE: 0.54796) avg lploss: 0.00000
train epoch 722 avg loss: 0.64298 (A-MSE: 0.57256) avg lploss: 0.00000
train epoch 723 avg loss: 0.59815 (A-MSE: 0.52940) avg lploss: 0.00000
train epoch 724 avg loss: 0.64162 (A-MSE: 0.56628) avg lploss: 0.00000
train epoch 725 avg loss: 0.58009 (A-MSE: 0.51494) avg lploss: 0.00000
==> val epoch 725 avg loss: 1.46279 (A-MSE: 1.29352) avg lploss: 0.00000
==> test epoch 725 avg loss: 1.59991 (A-MSE: 1.42652) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 2 out of 50
train epoch 726 avg loss: 0.58690 (A-MSE: 0.51919) avg lploss: 0.00000
train epoch 727 avg loss: 0.67665 (A-MSE: 0.60174) avg lploss: 0.00000
train epoch 728 avg loss: 0.64872 (A-MSE: 0.57046) avg lploss: 0.00000
train epoch 729 avg loss: 0.60656 (A-MSE: 0.53697) avg lploss: 0.00000
train epoch 730 avg loss: 0.65001 (A-MSE: 0.57356) avg lploss: 0.00000
==> val epoch 730 avg loss: 1.81685 (A-MSE: 1.60752) avg lploss: 0.00000
==> test epoch 730 avg loss: 2.06154 (A-MSE: 1.83167) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 3 out of 50
train epoch 731 avg loss: 0.64881 (A-MSE: 0.57665) avg lploss: 0.00000
train epoch 732 avg loss: 0.62491 (A-MSE: 0.55412) avg lploss: 0.00000
train epoch 733 avg loss: 0.64798 (A-MSE: 0.56945) avg lploss: 0.00000
train epoch 734 avg loss: 0.64419 (A-MSE: 0.56926) avg lploss: 0.00000
train epoch 735 avg loss: 0.59306 (A-MSE: 0.52448) avg lploss: 0.00000
==> val epoch 735 avg loss: 1.45834 (A-MSE: 1.30185) avg lploss: 0.00000
==> test epoch 735 avg loss: 1.57558 (A-MSE: 1.41215) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 4 out of 50
train epoch 736 avg loss: 0.57616 (A-MSE: 0.51117) avg lploss: 0.00000
train epoch 737 avg loss: 0.57360 (A-MSE: 0.50642) avg lploss: 0.00000
train epoch 738 avg loss: 0.59945 (A-MSE: 0.52987) avg lploss: 0.00000
train epoch 739 avg loss: 0.55767 (A-MSE: 0.49463) avg lploss: 0.00000
train epoch 740 avg loss: 0.56383 (A-MSE: 0.49901) avg lploss: 0.00000
==> val epoch 740 avg loss: 1.63092 (A-MSE: 1.42866) avg lploss: 0.00000
==> test epoch 740 avg loss: 1.71018 (A-MSE: 1.52169) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 5 out of 50
train epoch 741 avg loss: 0.60084 (A-MSE: 0.52733) avg lploss: 0.00000
train epoch 742 avg loss: 0.57418 (A-MSE: 0.50706) avg lploss: 0.00000
train epoch 743 avg loss: 0.56840 (A-MSE: 0.50226) avg lploss: 0.00000
train epoch 744 avg loss: 0.66675 (A-MSE: 0.59270) avg lploss: 0.00000
train epoch 745 avg loss: 0.61495 (A-MSE: 0.54706) avg lploss: 0.00000
==> val epoch 745 avg loss: 1.51222 (A-MSE: 1.33980) avg lploss: 0.00000
==> test epoch 745 avg loss: 1.62823 (A-MSE: 1.44857) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 6 out of 50
train epoch 746 avg loss: 0.56325 (A-MSE: 0.49837) avg lploss: 0.00000
train epoch 747 avg loss: 0.57906 (A-MSE: 0.51039) avg lploss: 0.00000
train epoch 748 avg loss: 0.55829 (A-MSE: 0.49363) avg lploss: 0.00000
train epoch 749 avg loss: 0.59636 (A-MSE: 0.52806) avg lploss: 0.00000
train epoch 750 avg loss: 0.55577 (A-MSE: 0.49117) avg lploss: 0.00000
==> val epoch 750 avg loss: 1.64242 (A-MSE: 1.45760) avg lploss: 0.00000
==> test epoch 750 avg loss: 1.74950 (A-MSE: 1.55518) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 7 out of 50
train epoch 751 avg loss: 0.56432 (A-MSE: 0.49777) avg lploss: 0.00000
train epoch 752 avg loss: 0.52347 (A-MSE: 0.46212) avg lploss: 0.00000
train epoch 753 avg loss: 0.58644 (A-MSE: 0.51416) avg lploss: 0.00000
train epoch 754 avg loss: 0.62388 (A-MSE: 0.55204) avg lploss: 0.00000
train epoch 755 avg loss: 0.60360 (A-MSE: 0.53824) avg lploss: 0.00000
==> val epoch 755 avg loss: 1.49292 (A-MSE: 1.31854) avg lploss: 0.00000
==> test epoch 755 avg loss: 1.66891 (A-MSE: 1.48445) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 8 out of 50
train epoch 756 avg loss: 0.62395 (A-MSE: 0.55121) avg lploss: 0.00000
train epoch 757 avg loss: 0.58115 (A-MSE: 0.51187) avg lploss: 0.00000
train epoch 758 avg loss: 0.50978 (A-MSE: 0.44873) avg lploss: 0.00000
train epoch 759 avg loss: 0.50937 (A-MSE: 0.44823) avg lploss: 0.00000
train epoch 760 avg loss: 0.55400 (A-MSE: 0.49121) avg lploss: 0.00000
==> val epoch 760 avg loss: 1.46079 (A-MSE: 1.28570) avg lploss: 0.00000
==> test epoch 760 avg loss: 1.58778 (A-MSE: 1.41473) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 9 out of 50
train epoch 761 avg loss: 0.61047 (A-MSE: 0.53744) avg lploss: 0.00000
train epoch 762 avg loss: 0.53456 (A-MSE: 0.46774) avg lploss: 0.00000
train epoch 763 avg loss: 0.61398 (A-MSE: 0.54475) avg lploss: 0.00000
train epoch 764 avg loss: 0.63286 (A-MSE: 0.56360) avg lploss: 0.00000
train epoch 765 avg loss: 0.64899 (A-MSE: 0.57161) avg lploss: 0.00000
==> val epoch 765 avg loss: 1.64305 (A-MSE: 1.41766) avg lploss: 0.00000
==> test epoch 765 avg loss: 1.74855 (A-MSE: 1.52024) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 10 out of 50
train epoch 766 avg loss: 0.54572 (A-MSE: 0.48123) avg lploss: 0.00000
train epoch 767 avg loss: 0.55047 (A-MSE: 0.48493) avg lploss: 0.00000
train epoch 768 avg loss: 0.54520 (A-MSE: 0.48388) avg lploss: 0.00000
train epoch 769 avg loss: 0.56377 (A-MSE: 0.49740) avg lploss: 0.00000
train epoch 770 avg loss: 0.51688 (A-MSE: 0.45632) avg lploss: 0.00000
==> val epoch 770 avg loss: 1.54502 (A-MSE: 1.33731) avg lploss: 0.00000
==> test epoch 770 avg loss: 1.61038 (A-MSE: 1.41680) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 11 out of 50
train epoch 771 avg loss: 0.52839 (A-MSE: 0.46689) avg lploss: 0.00000
train epoch 772 avg loss: 0.54857 (A-MSE: 0.48390) avg lploss: 0.00000
train epoch 773 avg loss: 0.55043 (A-MSE: 0.48524) avg lploss: 0.00000
train epoch 774 avg loss: 0.55125 (A-MSE: 0.48781) avg lploss: 0.00000
train epoch 775 avg loss: 0.56767 (A-MSE: 0.50213) avg lploss: 0.00000
==> val epoch 775 avg loss: 1.55339 (A-MSE: 1.37616) avg lploss: 0.00000
==> test epoch 775 avg loss: 1.66116 (A-MSE: 1.48119) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 12 out of 50
train epoch 776 avg loss: 0.49407 (A-MSE: 0.43557) avg lploss: 0.00000
train epoch 777 avg loss: 0.49265 (A-MSE: 0.43334) avg lploss: 0.00000
train epoch 778 avg loss: 0.62152 (A-MSE: 0.55111) avg lploss: 0.00000
train epoch 779 avg loss: 0.60921 (A-MSE: 0.53638) avg lploss: 0.00000
train epoch 780 avg loss: 0.60192 (A-MSE: 0.53252) avg lploss: 0.00000
==> val epoch 780 avg loss: 1.94181 (A-MSE: 1.68620) avg lploss: 0.00000
==> test epoch 780 avg loss: 2.01398 (A-MSE: 1.76652) avg lploss: 0.00000
*** Best Val Loss: 1.43905 	 Best Test Loss: 1.54089 	 Best epoch 715
EarlyStopping counter: 13 out of 50
train epoch 781 avg loss: 0.60780 (A-MSE: 0.54154) avg lploss: 0.00000
train epoch 782 avg loss: 0.59123 (A-MSE: 0.52148) avg lploss: 0.00000
train epoch 783 avg loss: 0.50380 (A-MSE: 0.44748) avg lploss: 0.00000
train epoch 784 avg loss: 0.54161 (A-MSE: 0.47968) avg lploss: 0.00000
train epoch 785 avg loss: 0.58475 (A-MSE: 0.51921) avg lploss: 0.00000
==> val epoch 785 avg loss: 1.35403 (A-MSE: 1.17677) avg lploss: 0.00000
==> test epoch 785 avg loss: 1.54382 (A-MSE: 1.36652) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
Validation loss decreased (1.439053 --> 1.354031).  Saving model ...
train epoch 786 avg loss: 0.56946 (A-MSE: 0.49819) avg lploss: 0.00000
train epoch 787 avg loss: 0.58097 (A-MSE: 0.51396) avg lploss: 0.00000
train epoch 788 avg loss: 0.53089 (A-MSE: 0.46951) avg lploss: 0.00000
train epoch 789 avg loss: 0.54589 (A-MSE: 0.48228) avg lploss: 0.00000
train epoch 790 avg loss: 0.58362 (A-MSE: 0.51065) avg lploss: 0.00000
==> val epoch 790 avg loss: 1.43071 (A-MSE: 1.26084) avg lploss: 0.00000
==> test epoch 790 avg loss: 1.54599 (A-MSE: 1.37320) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 1 out of 50
train epoch 791 avg loss: 0.58270 (A-MSE: 0.51509) avg lploss: 0.00000
train epoch 792 avg loss: 0.56922 (A-MSE: 0.50605) avg lploss: 0.00000
train epoch 793 avg loss: 0.52635 (A-MSE: 0.46250) avg lploss: 0.00000
train epoch 794 avg loss: 0.51245 (A-MSE: 0.45716) avg lploss: 0.00000
train epoch 795 avg loss: 0.53912 (A-MSE: 0.47668) avg lploss: 0.00000
==> val epoch 795 avg loss: 1.81146 (A-MSE: 1.59772) avg lploss: 0.00000
==> test epoch 795 avg loss: 2.02571 (A-MSE: 1.80319) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 2 out of 50
train epoch 796 avg loss: 0.63365 (A-MSE: 0.55691) avg lploss: 0.00000
train epoch 797 avg loss: 0.58907 (A-MSE: 0.52219) avg lploss: 0.00000
train epoch 798 avg loss: 0.55310 (A-MSE: 0.48767) avg lploss: 0.00000
train epoch 799 avg loss: 0.55772 (A-MSE: 0.49242) avg lploss: 0.00000
train epoch 800 avg loss: 0.50631 (A-MSE: 0.44874) avg lploss: 0.00000
==> val epoch 800 avg loss: 1.54328 (A-MSE: 1.36375) avg lploss: 0.00000
==> test epoch 800 avg loss: 1.65176 (A-MSE: 1.46373) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 3 out of 50
train epoch 801 avg loss: 0.48705 (A-MSE: 0.42969) avg lploss: 0.00000
train epoch 802 avg loss: 0.46348 (A-MSE: 0.40893) avg lploss: 0.00000
train epoch 803 avg loss: 0.49498 (A-MSE: 0.43788) avg lploss: 0.00000
train epoch 804 avg loss: 0.52094 (A-MSE: 0.45811) avg lploss: 0.00000
train epoch 805 avg loss: 0.49407 (A-MSE: 0.43641) avg lploss: 0.00000
==> val epoch 805 avg loss: 1.63934 (A-MSE: 1.43701) avg lploss: 0.00000
==> test epoch 805 avg loss: 1.77636 (A-MSE: 1.56403) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 4 out of 50
train epoch 806 avg loss: 0.46293 (A-MSE: 0.41020) avg lploss: 0.00000
train epoch 807 avg loss: 0.50391 (A-MSE: 0.44417) avg lploss: 0.00000
train epoch 808 avg loss: 0.51678 (A-MSE: 0.45842) avg lploss: 0.00000
train epoch 809 avg loss: 0.53708 (A-MSE: 0.47646) avg lploss: 0.00000
train epoch 810 avg loss: 0.51650 (A-MSE: 0.45444) avg lploss: 0.00000
==> val epoch 810 avg loss: 1.52414 (A-MSE: 1.37785) avg lploss: 0.00000
==> test epoch 810 avg loss: 1.69477 (A-MSE: 1.53587) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 5 out of 50
train epoch 811 avg loss: 0.47080 (A-MSE: 0.41920) avg lploss: 0.00000
train epoch 812 avg loss: 0.46195 (A-MSE: 0.40736) avg lploss: 0.00000
train epoch 813 avg loss: 0.49542 (A-MSE: 0.43672) avg lploss: 0.00000
train epoch 814 avg loss: 0.53021 (A-MSE: 0.46908) avg lploss: 0.00000
train epoch 815 avg loss: 0.56036 (A-MSE: 0.49493) avg lploss: 0.00000
==> val epoch 815 avg loss: 1.76702 (A-MSE: 1.53089) avg lploss: 0.00000
==> test epoch 815 avg loss: 2.11209 (A-MSE: 1.82914) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 6 out of 50
train epoch 816 avg loss: 0.52529 (A-MSE: 0.46476) avg lploss: 0.00000
train epoch 817 avg loss: 0.49736 (A-MSE: 0.43716) avg lploss: 0.00000
train epoch 818 avg loss: 0.51491 (A-MSE: 0.45390) avg lploss: 0.00000
train epoch 819 avg loss: 0.52247 (A-MSE: 0.46028) avg lploss: 0.00000
train epoch 820 avg loss: 0.47915 (A-MSE: 0.42318) avg lploss: 0.00000
==> val epoch 820 avg loss: 1.37273 (A-MSE: 1.19392) avg lploss: 0.00000
==> test epoch 820 avg loss: 1.40968 (A-MSE: 1.24664) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 7 out of 50
train epoch 821 avg loss: 0.52134 (A-MSE: 0.46079) avg lploss: 0.00000
train epoch 822 avg loss: 0.52244 (A-MSE: 0.46196) avg lploss: 0.00000
train epoch 823 avg loss: 0.49331 (A-MSE: 0.43489) avg lploss: 0.00000
train epoch 824 avg loss: 0.43629 (A-MSE: 0.38524) avg lploss: 0.00000
train epoch 825 avg loss: 0.44748 (A-MSE: 0.39427) avg lploss: 0.00000
==> val epoch 825 avg loss: 1.39888 (A-MSE: 1.21218) avg lploss: 0.00000
==> test epoch 825 avg loss: 1.50319 (A-MSE: 1.31723) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 8 out of 50
train epoch 826 avg loss: 0.45218 (A-MSE: 0.39806) avg lploss: 0.00000
train epoch 827 avg loss: 0.48398 (A-MSE: 0.42939) avg lploss: 0.00000
train epoch 828 avg loss: 0.50942 (A-MSE: 0.45030) avg lploss: 0.00000
train epoch 829 avg loss: 0.48054 (A-MSE: 0.42621) avg lploss: 0.00000
train epoch 830 avg loss: 0.46235 (A-MSE: 0.40970) avg lploss: 0.00000
==> val epoch 830 avg loss: 1.38654 (A-MSE: 1.23145) avg lploss: 0.00000
==> test epoch 830 avg loss: 1.56552 (A-MSE: 1.39504) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 9 out of 50
train epoch 831 avg loss: 0.53863 (A-MSE: 0.47327) avg lploss: 0.00000
train epoch 832 avg loss: 0.54497 (A-MSE: 0.48226) avg lploss: 0.00000
train epoch 833 avg loss: 0.50883 (A-MSE: 0.44738) avg lploss: 0.00000
train epoch 834 avg loss: 0.52351 (A-MSE: 0.46297) avg lploss: 0.00000
train epoch 835 avg loss: 0.48572 (A-MSE: 0.42965) avg lploss: 0.00000
==> val epoch 835 avg loss: 1.50961 (A-MSE: 1.34500) avg lploss: 0.00000
==> test epoch 835 avg loss: 1.61121 (A-MSE: 1.44154) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 10 out of 50
train epoch 836 avg loss: 0.52003 (A-MSE: 0.46304) avg lploss: 0.00000
train epoch 837 avg loss: 0.58804 (A-MSE: 0.52040) avg lploss: 0.00000
train epoch 838 avg loss: 0.51507 (A-MSE: 0.45611) avg lploss: 0.00000
train epoch 839 avg loss: 0.47780 (A-MSE: 0.42194) avg lploss: 0.00000
train epoch 840 avg loss: 0.50493 (A-MSE: 0.44492) avg lploss: 0.00000
==> val epoch 840 avg loss: 1.39830 (A-MSE: 1.24677) avg lploss: 0.00000
==> test epoch 840 avg loss: 1.54681 (A-MSE: 1.37791) avg lploss: 0.00000
*** Best Val Loss: 1.35403 	 Best Test Loss: 1.54382 	 Best epoch 785
EarlyStopping counter: 11 out of 50
train epoch 841 avg loss: 0.59654 (A-MSE: 0.53197) avg lploss: 0.00000
train epoch 842 avg loss: 0.56853 (A-MSE: 0.50271) avg lploss: 0.00000
train epoch 843 avg loss: 0.45718 (A-MSE: 0.40351) avg lploss: 0.00000
train epoch 844 avg loss: 0.43456 (A-MSE: 0.38222) avg lploss: 0.00000
train epoch 845 avg loss: 0.44432 (A-MSE: 0.39316) avg lploss: 0.00000
==> val epoch 845 avg loss: 1.27714 (A-MSE: 1.12616) avg lploss: 0.00000
==> test epoch 845 avg loss: 1.43823 (A-MSE: 1.26044) avg lploss: 0.00000
*** Best Val Loss: 1.27714 	 Best Test Loss: 1.43823 	 Best epoch 845
Validation loss decreased (1.354031 --> 1.277141).  Saving model ...
train epoch 846 avg loss: 0.42397 (A-MSE: 0.37680) avg lploss: 0.00000
train epoch 847 avg loss: 0.42760 (A-MSE: 0.37760) avg lploss: 0.00000
train epoch 848 avg loss: 0.45654 (A-MSE: 0.40481) avg lploss: 0.00000
train epoch 849 avg loss: 0.53487 (A-MSE: 0.46992) avg lploss: 0.00000
train epoch 850 avg loss: 0.50944 (A-MSE: 0.45048) avg lploss: 0.00000
==> val epoch 850 avg loss: 1.24946 (A-MSE: 1.10142) avg lploss: 0.00000
==> test epoch 850 avg loss: 1.35973 (A-MSE: 1.19775) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
Validation loss decreased (1.277141 --> 1.249457).  Saving model ...
train epoch 851 avg loss: 0.45214 (A-MSE: 0.39952) avg lploss: 0.00000
train epoch 852 avg loss: 0.45802 (A-MSE: 0.40467) avg lploss: 0.00000
train epoch 853 avg loss: 0.46949 (A-MSE: 0.41596) avg lploss: 0.00000
train epoch 854 avg loss: 0.44217 (A-MSE: 0.39124) avg lploss: 0.00000
train epoch 855 avg loss: 0.53449 (A-MSE: 0.46979) avg lploss: 0.00000
==> val epoch 855 avg loss: 1.39906 (A-MSE: 1.22114) avg lploss: 0.00000
==> test epoch 855 avg loss: 1.56894 (A-MSE: 1.37714) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 1 out of 50
train epoch 856 avg loss: 0.49630 (A-MSE: 0.44002) avg lploss: 0.00000
train epoch 857 avg loss: 0.46412 (A-MSE: 0.40972) avg lploss: 0.00000
train epoch 858 avg loss: 0.45774 (A-MSE: 0.40365) avg lploss: 0.00000
train epoch 859 avg loss: 0.48601 (A-MSE: 0.42839) avg lploss: 0.00000
train epoch 860 avg loss: 0.46770 (A-MSE: 0.41550) avg lploss: 0.00000
==> val epoch 860 avg loss: 1.34112 (A-MSE: 1.18438) avg lploss: 0.00000
==> test epoch 860 avg loss: 1.51171 (A-MSE: 1.34262) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 2 out of 50
train epoch 861 avg loss: 0.47245 (A-MSE: 0.41752) avg lploss: 0.00000
train epoch 862 avg loss: 0.44401 (A-MSE: 0.39152) avg lploss: 0.00000
train epoch 863 avg loss: 0.41595 (A-MSE: 0.36798) avg lploss: 0.00000
train epoch 864 avg loss: 0.45308 (A-MSE: 0.40041) avg lploss: 0.00000
train epoch 865 avg loss: 0.47845 (A-MSE: 0.42229) avg lploss: 0.00000
==> val epoch 865 avg loss: 1.37637 (A-MSE: 1.22137) avg lploss: 0.00000
==> test epoch 865 avg loss: 1.61350 (A-MSE: 1.43442) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 3 out of 50
train epoch 866 avg loss: 0.42939 (A-MSE: 0.38227) avg lploss: 0.00000
train epoch 867 avg loss: 0.42837 (A-MSE: 0.38074) avg lploss: 0.00000
train epoch 868 avg loss: 0.43134 (A-MSE: 0.38121) avg lploss: 0.00000
train epoch 869 avg loss: 0.45909 (A-MSE: 0.40670) avg lploss: 0.00000
train epoch 870 avg loss: 0.45382 (A-MSE: 0.40085) avg lploss: 0.00000
==> val epoch 870 avg loss: 1.34828 (A-MSE: 1.17770) avg lploss: 0.00000
==> test epoch 870 avg loss: 1.46700 (A-MSE: 1.29762) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 4 out of 50
train epoch 871 avg loss: 0.47241 (A-MSE: 0.41589) avg lploss: 0.00000
train epoch 872 avg loss: 0.47871 (A-MSE: 0.42569) avg lploss: 0.00000
train epoch 873 avg loss: 0.48625 (A-MSE: 0.43260) avg lploss: 0.00000
train epoch 874 avg loss: 0.45712 (A-MSE: 0.40121) avg lploss: 0.00000
train epoch 875 avg loss: 0.52579 (A-MSE: 0.46404) avg lploss: 0.00000
==> val epoch 875 avg loss: 1.26872 (A-MSE: 1.13613) avg lploss: 0.00000
==> test epoch 875 avg loss: 1.42393 (A-MSE: 1.28182) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 5 out of 50
train epoch 876 avg loss: 0.51128 (A-MSE: 0.45154) avg lploss: 0.00000
train epoch 877 avg loss: 0.62562 (A-MSE: 0.55468) avg lploss: 0.00000
train epoch 878 avg loss: 0.56484 (A-MSE: 0.49807) avg lploss: 0.00000
train epoch 879 avg loss: 0.44814 (A-MSE: 0.39841) avg lploss: 0.00000
train epoch 880 avg loss: 0.43183 (A-MSE: 0.38042) avg lploss: 0.00000
==> val epoch 880 avg loss: 1.38575 (A-MSE: 1.21886) avg lploss: 0.00000
==> test epoch 880 avg loss: 1.59391 (A-MSE: 1.39191) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 6 out of 50
train epoch 881 avg loss: 0.43294 (A-MSE: 0.38633) avg lploss: 0.00000
train epoch 882 avg loss: 0.42557 (A-MSE: 0.37532) avg lploss: 0.00000
train epoch 883 avg loss: 0.40262 (A-MSE: 0.35455) avg lploss: 0.00000
train epoch 884 avg loss: 0.45103 (A-MSE: 0.40402) avg lploss: 0.00000
train epoch 885 avg loss: 0.40677 (A-MSE: 0.35975) avg lploss: 0.00000
==> val epoch 885 avg loss: 1.41830 (A-MSE: 1.25763) avg lploss: 0.00000
==> test epoch 885 avg loss: 1.56993 (A-MSE: 1.38500) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 7 out of 50
train epoch 886 avg loss: 0.40303 (A-MSE: 0.35751) avg lploss: 0.00000
train epoch 887 avg loss: 0.46595 (A-MSE: 0.41325) avg lploss: 0.00000
train epoch 888 avg loss: 0.43833 (A-MSE: 0.38727) avg lploss: 0.00000
train epoch 889 avg loss: 0.43959 (A-MSE: 0.38809) avg lploss: 0.00000
train epoch 890 avg loss: 0.46114 (A-MSE: 0.40548) avg lploss: 0.00000
==> val epoch 890 avg loss: 1.35332 (A-MSE: 1.16787) avg lploss: 0.00000
==> test epoch 890 avg loss: 1.48038 (A-MSE: 1.28083) avg lploss: 0.00000
*** Best Val Loss: 1.24946 	 Best Test Loss: 1.35973 	 Best epoch 850
EarlyStopping counter: 8 out of 50
train epoch 891 avg loss: 0.42507 (A-MSE: 0.37699) avg lploss: 0.00000
train epoch 892 avg loss: 0.38920 (A-MSE: 0.34555) avg lploss: 0.00000
train epoch 893 avg loss: 0.44742 (A-MSE: 0.39649) avg lploss: 0.00000
train epoch 894 avg loss: 0.44976 (A-MSE: 0.40053) avg lploss: 0.00000
train epoch 895 avg loss: 0.39126 (A-MSE: 0.34500) avg lploss: 0.00000
==> val epoch 895 avg loss: 1.12593 (A-MSE: 1.00821) avg lploss: 0.00000
==> test epoch 895 avg loss: 1.24157 (A-MSE: 1.11986) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
Validation loss decreased (1.249457 --> 1.125930).  Saving model ...
train epoch 896 avg loss: 0.39030 (A-MSE: 0.34701) avg lploss: 0.00000
train epoch 897 avg loss: 0.44179 (A-MSE: 0.38854) avg lploss: 0.00000
train epoch 898 avg loss: 0.42067 (A-MSE: 0.37331) avg lploss: 0.00000
train epoch 899 avg loss: 0.39044 (A-MSE: 0.34524) avg lploss: 0.00000
train epoch 900 avg loss: 0.43771 (A-MSE: 0.39119) avg lploss: 0.00000
==> val epoch 900 avg loss: 1.49571 (A-MSE: 1.30715) avg lploss: 0.00000
==> test epoch 900 avg loss: 1.59562 (A-MSE: 1.40529) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 1 out of 50
train epoch 901 avg loss: 0.42359 (A-MSE: 0.37404) avg lploss: 0.00000
train epoch 902 avg loss: 0.39482 (A-MSE: 0.35076) avg lploss: 0.00000
train epoch 903 avg loss: 0.40121 (A-MSE: 0.35435) avg lploss: 0.00000
train epoch 904 avg loss: 0.39555 (A-MSE: 0.34974) avg lploss: 0.00000
train epoch 905 avg loss: 0.41468 (A-MSE: 0.36813) avg lploss: 0.00000
==> val epoch 905 avg loss: 1.26743 (A-MSE: 1.11771) avg lploss: 0.00000
==> test epoch 905 avg loss: 1.40676 (A-MSE: 1.25124) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 2 out of 50
train epoch 906 avg loss: 0.41110 (A-MSE: 0.36053) avg lploss: 0.00000
train epoch 907 avg loss: 0.42779 (A-MSE: 0.37729) avg lploss: 0.00000
train epoch 908 avg loss: 0.36493 (A-MSE: 0.32381) avg lploss: 0.00000
train epoch 909 avg loss: 0.36619 (A-MSE: 0.32345) avg lploss: 0.00000
train epoch 910 avg loss: 0.39995 (A-MSE: 0.35617) avg lploss: 0.00000
==> val epoch 910 avg loss: 1.25323 (A-MSE: 1.10461) avg lploss: 0.00000
==> test epoch 910 avg loss: 1.36824 (A-MSE: 1.21293) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 3 out of 50
train epoch 911 avg loss: 0.38077 (A-MSE: 0.33841) avg lploss: 0.00000
train epoch 912 avg loss: 0.38947 (A-MSE: 0.34448) avg lploss: 0.00000
train epoch 913 avg loss: 0.45155 (A-MSE: 0.39952) avg lploss: 0.00000
train epoch 914 avg loss: 0.45750 (A-MSE: 0.40642) avg lploss: 0.00000
train epoch 915 avg loss: 0.49814 (A-MSE: 0.43674) avg lploss: 0.00000
==> val epoch 915 avg loss: 1.26895 (A-MSE: 1.11367) avg lploss: 0.00000
==> test epoch 915 avg loss: 1.50705 (A-MSE: 1.30814) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 4 out of 50
train epoch 916 avg loss: 0.43361 (A-MSE: 0.38480) avg lploss: 0.00000
train epoch 917 avg loss: 0.49457 (A-MSE: 0.43646) avg lploss: 0.00000
train epoch 918 avg loss: 0.40677 (A-MSE: 0.36045) avg lploss: 0.00000
train epoch 919 avg loss: 0.38987 (A-MSE: 0.34734) avg lploss: 0.00000
train epoch 920 avg loss: 0.42642 (A-MSE: 0.37681) avg lploss: 0.00000
==> val epoch 920 avg loss: 1.17370 (A-MSE: 1.03196) avg lploss: 0.00000
==> test epoch 920 avg loss: 1.26579 (A-MSE: 1.12031) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 5 out of 50
train epoch 921 avg loss: 0.42429 (A-MSE: 0.37565) avg lploss: 0.00000
train epoch 922 avg loss: 0.41327 (A-MSE: 0.36495) avg lploss: 0.00000
train epoch 923 avg loss: 0.38692 (A-MSE: 0.34411) avg lploss: 0.00000
train epoch 924 avg loss: 0.38485 (A-MSE: 0.34120) avg lploss: 0.00000
train epoch 925 avg loss: 0.41185 (A-MSE: 0.36111) avg lploss: 0.00000
==> val epoch 925 avg loss: 1.43213 (A-MSE: 1.26496) avg lploss: 0.00000
==> test epoch 925 avg loss: 1.58860 (A-MSE: 1.40484) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 6 out of 50
train epoch 926 avg loss: 0.44630 (A-MSE: 0.39738) avg lploss: 0.00000
train epoch 927 avg loss: 0.45000 (A-MSE: 0.39611) avg lploss: 0.00000
train epoch 928 avg loss: 0.38898 (A-MSE: 0.34502) avg lploss: 0.00000
train epoch 929 avg loss: 0.36799 (A-MSE: 0.32401) avg lploss: 0.00000
train epoch 930 avg loss: 0.40483 (A-MSE: 0.35927) avg lploss: 0.00000
==> val epoch 930 avg loss: 1.28130 (A-MSE: 1.13455) avg lploss: 0.00000
==> test epoch 930 avg loss: 1.41789 (A-MSE: 1.25530) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 7 out of 50
train epoch 931 avg loss: 0.41019 (A-MSE: 0.36367) avg lploss: 0.00000
train epoch 932 avg loss: 0.39096 (A-MSE: 0.34404) avg lploss: 0.00000
train epoch 933 avg loss: 0.43918 (A-MSE: 0.38989) avg lploss: 0.00000
train epoch 934 avg loss: 0.44627 (A-MSE: 0.39454) avg lploss: 0.00000
train epoch 935 avg loss: 0.41357 (A-MSE: 0.36357) avg lploss: 0.00000
==> val epoch 935 avg loss: 1.14849 (A-MSE: 1.01527) avg lploss: 0.00000
==> test epoch 935 avg loss: 1.28871 (A-MSE: 1.13709) avg lploss: 0.00000
*** Best Val Loss: 1.12593 	 Best Test Loss: 1.24157 	 Best epoch 895
EarlyStopping counter: 8 out of 50
train epoch 936 avg loss: 0.40005 (A-MSE: 0.35406) avg lploss: 0.00000
train epoch 937 avg loss: 0.46741 (A-MSE: 0.41465) avg lploss: 0.00000
train epoch 938 avg loss: 0.44655 (A-MSE: 0.39051) avg lploss: 0.00000
train epoch 939 avg loss: 0.43357 (A-MSE: 0.38559) avg lploss: 0.00000
train epoch 940 avg loss: 0.45006 (A-MSE: 0.40166) avg lploss: 0.00000
==> val epoch 940 avg loss: 1.12388 (A-MSE: 0.99171) avg lploss: 0.00000
==> test epoch 940 avg loss: 1.29711 (A-MSE: 1.14823) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
Validation loss decreased (1.125930 --> 1.123885).  Saving model ...
train epoch 941 avg loss: 0.40398 (A-MSE: 0.35871) avg lploss: 0.00000
train epoch 942 avg loss: 0.38717 (A-MSE: 0.34411) avg lploss: 0.00000
train epoch 943 avg loss: 0.42243 (A-MSE: 0.37385) avg lploss: 0.00000
train epoch 944 avg loss: 0.43558 (A-MSE: 0.38436) avg lploss: 0.00000
train epoch 945 avg loss: 0.43431 (A-MSE: 0.38409) avg lploss: 0.00000
==> val epoch 945 avg loss: 1.22246 (A-MSE: 1.07597) avg lploss: 0.00000
==> test epoch 945 avg loss: 1.35417 (A-MSE: 1.20141) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 1 out of 50
train epoch 946 avg loss: 0.40053 (A-MSE: 0.35597) avg lploss: 0.00000
train epoch 947 avg loss: 0.37714 (A-MSE: 0.33142) avg lploss: 0.00000
train epoch 948 avg loss: 0.35606 (A-MSE: 0.31622) avg lploss: 0.00000
train epoch 949 avg loss: 0.34918 (A-MSE: 0.31019) avg lploss: 0.00000
train epoch 950 avg loss: 0.34244 (A-MSE: 0.30110) avg lploss: 0.00000
==> val epoch 950 avg loss: 1.16878 (A-MSE: 1.01567) avg lploss: 0.00000
==> test epoch 950 avg loss: 1.37892 (A-MSE: 1.19576) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 2 out of 50
train epoch 951 avg loss: 0.36400 (A-MSE: 0.32319) avg lploss: 0.00000
train epoch 952 avg loss: 0.42436 (A-MSE: 0.37263) avg lploss: 0.00000
train epoch 953 avg loss: 0.47811 (A-MSE: 0.42315) avg lploss: 0.00000
train epoch 954 avg loss: 0.43909 (A-MSE: 0.38706) avg lploss: 0.00000
train epoch 955 avg loss: 0.41690 (A-MSE: 0.36580) avg lploss: 0.00000
==> val epoch 955 avg loss: 1.28395 (A-MSE: 1.12674) avg lploss: 0.00000
==> test epoch 955 avg loss: 1.47349 (A-MSE: 1.28260) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 3 out of 50
train epoch 956 avg loss: 0.41011 (A-MSE: 0.36265) avg lploss: 0.00000
train epoch 957 avg loss: 0.41781 (A-MSE: 0.36937) avg lploss: 0.00000
train epoch 958 avg loss: 0.37702 (A-MSE: 0.33336) avg lploss: 0.00000
train epoch 959 avg loss: 0.35867 (A-MSE: 0.31572) avg lploss: 0.00000
train epoch 960 avg loss: 0.36398 (A-MSE: 0.31951) avg lploss: 0.00000
==> val epoch 960 avg loss: 1.13991 (A-MSE: 0.99864) avg lploss: 0.00000
==> test epoch 960 avg loss: 1.31831 (A-MSE: 1.16017) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 4 out of 50
train epoch 961 avg loss: 0.32382 (A-MSE: 0.28480) avg lploss: 0.00000
train epoch 962 avg loss: 0.33074 (A-MSE: 0.29177) avg lploss: 0.00000
train epoch 963 avg loss: 0.34807 (A-MSE: 0.30825) avg lploss: 0.00000
train epoch 964 avg loss: 0.37861 (A-MSE: 0.33260) avg lploss: 0.00000
train epoch 965 avg loss: 0.34528 (A-MSE: 0.30459) avg lploss: 0.00000
==> val epoch 965 avg loss: 1.21315 (A-MSE: 1.05754) avg lploss: 0.00000
==> test epoch 965 avg loss: 1.37651 (A-MSE: 1.20193) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 5 out of 50
train epoch 966 avg loss: 0.37928 (A-MSE: 0.33697) avg lploss: 0.00000
train epoch 967 avg loss: 0.39573 (A-MSE: 0.35110) avg lploss: 0.00000
train epoch 968 avg loss: 0.35200 (A-MSE: 0.31124) avg lploss: 0.00000
train epoch 969 avg loss: 0.33173 (A-MSE: 0.29325) avg lploss: 0.00000
train epoch 970 avg loss: 0.34192 (A-MSE: 0.30280) avg lploss: 0.00000
==> val epoch 970 avg loss: 1.13976 (A-MSE: 1.00636) avg lploss: 0.00000
==> test epoch 970 avg loss: 1.27839 (A-MSE: 1.12973) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 6 out of 50
train epoch 971 avg loss: 0.33512 (A-MSE: 0.29644) avg lploss: 0.00000
train epoch 972 avg loss: 0.40253 (A-MSE: 0.35392) avg lploss: 0.00000
train epoch 973 avg loss: 0.35524 (A-MSE: 0.31518) avg lploss: 0.00000
train epoch 974 avg loss: 0.30570 (A-MSE: 0.27201) avg lploss: 0.00000
train epoch 975 avg loss: 0.33262 (A-MSE: 0.29464) avg lploss: 0.00000
==> val epoch 975 avg loss: 1.24442 (A-MSE: 1.10123) avg lploss: 0.00000
==> test epoch 975 avg loss: 1.34164 (A-MSE: 1.19715) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 7 out of 50
train epoch 976 avg loss: 0.35906 (A-MSE: 0.31876) avg lploss: 0.00000
train epoch 977 avg loss: 0.38472 (A-MSE: 0.33776) avg lploss: 0.00000
train epoch 978 avg loss: 0.38501 (A-MSE: 0.34174) avg lploss: 0.00000
train epoch 979 avg loss: 0.43411 (A-MSE: 0.38469) avg lploss: 0.00000
train epoch 980 avg loss: 0.39046 (A-MSE: 0.34332) avg lploss: 0.00000
==> val epoch 980 avg loss: 1.19934 (A-MSE: 1.03862) avg lploss: 0.00000
==> test epoch 980 avg loss: 1.42660 (A-MSE: 1.24369) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 8 out of 50
train epoch 981 avg loss: 0.35482 (A-MSE: 0.31287) avg lploss: 0.00000
train epoch 982 avg loss: 0.33898 (A-MSE: 0.29814) avg lploss: 0.00000
train epoch 983 avg loss: 0.32448 (A-MSE: 0.28730) avg lploss: 0.00000
train epoch 984 avg loss: 0.34880 (A-MSE: 0.31083) avg lploss: 0.00000
train epoch 985 avg loss: 0.35125 (A-MSE: 0.31189) avg lploss: 0.00000
==> val epoch 985 avg loss: 1.25198 (A-MSE: 1.08249) avg lploss: 0.00000
==> test epoch 985 avg loss: 1.28967 (A-MSE: 1.14173) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 9 out of 50
train epoch 986 avg loss: 0.36796 (A-MSE: 0.32089) avg lploss: 0.00000
train epoch 987 avg loss: 0.47798 (A-MSE: 0.42714) avg lploss: 0.00000
train epoch 988 avg loss: 0.42732 (A-MSE: 0.37761) avg lploss: 0.00000
train epoch 989 avg loss: 0.41785 (A-MSE: 0.36902) avg lploss: 0.00000
train epoch 990 avg loss: 0.43374 (A-MSE: 0.38494) avg lploss: 0.00000
==> val epoch 990 avg loss: 1.15520 (A-MSE: 1.02086) avg lploss: 0.00000
==> test epoch 990 avg loss: 1.21813 (A-MSE: 1.09242) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 10 out of 50
train epoch 991 avg loss: 0.40331 (A-MSE: 0.35555) avg lploss: 0.00000
train epoch 992 avg loss: 0.36186 (A-MSE: 0.31879) avg lploss: 0.00000
train epoch 993 avg loss: 0.33392 (A-MSE: 0.29491) avg lploss: 0.00000
train epoch 994 avg loss: 0.32238 (A-MSE: 0.28117) avg lploss: 0.00000
train epoch 995 avg loss: 0.29788 (A-MSE: 0.26129) avg lploss: 0.00000
==> val epoch 995 avg loss: 1.17455 (A-MSE: 1.01845) avg lploss: 0.00000
==> test epoch 995 avg loss: 1.33965 (A-MSE: 1.16995) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 11 out of 50
train epoch 996 avg loss: 0.29896 (A-MSE: 0.26483) avg lploss: 0.00000
train epoch 997 avg loss: 0.29727 (A-MSE: 0.26323) avg lploss: 0.00000
train epoch 998 avg loss: 0.32323 (A-MSE: 0.28526) avg lploss: 0.00000
train epoch 999 avg loss: 0.33827 (A-MSE: 0.29837) avg lploss: 0.00000
train epoch 1000 avg loss: 0.36929 (A-MSE: 0.32781) avg lploss: 0.00000
==> val epoch 1000 avg loss: 1.25525 (A-MSE: 1.10044) avg lploss: 0.00000
==> test epoch 1000 avg loss: 1.43544 (A-MSE: 1.27936) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 12 out of 50
train epoch 1001 avg loss: 0.39841 (A-MSE: 0.35063) avg lploss: 0.00000
train epoch 1002 avg loss: 0.31821 (A-MSE: 0.28199) avg lploss: 0.00000
train epoch 1003 avg loss: 0.32743 (A-MSE: 0.29029) avg lploss: 0.00000
train epoch 1004 avg loss: 0.31806 (A-MSE: 0.27965) avg lploss: 0.00000
train epoch 1005 avg loss: 0.29957 (A-MSE: 0.26598) avg lploss: 0.00000
==> val epoch 1005 avg loss: 1.13306 (A-MSE: 0.99408) avg lploss: 0.00000
==> test epoch 1005 avg loss: 1.20282 (A-MSE: 1.07152) avg lploss: 0.00000
*** Best Val Loss: 1.12388 	 Best Test Loss: 1.29711 	 Best epoch 940
EarlyStopping counter: 13 out of 50
train epoch 1006 avg loss: 0.32880 (A-MSE: 0.29152) avg lploss: 0.00000
train epoch 1007 avg loss: 0.33450 (A-MSE: 0.29605) avg lploss: 0.00000
train epoch 1008 avg loss: 0.35422 (A-MSE: 0.31310) avg lploss: 0.00000
train epoch 1009 avg loss: 0.34692 (A-MSE: 0.30621) avg lploss: 0.00000
train epoch 1010 avg loss: 0.37289 (A-MSE: 0.32899) avg lploss: 0.00000
==> val epoch 1010 avg loss: 1.03198 (A-MSE: 0.90673) avg lploss: 0.00000
==> test epoch 1010 avg loss: 1.14984 (A-MSE: 1.02762) avg lploss: 0.00000
*** Best Val Loss: 1.03198 	 Best Test Loss: 1.14984 	 Best epoch 1010
Validation loss decreased (1.123885 --> 1.031975).  Saving model ...
train epoch 1011 avg loss: 0.30733 (A-MSE: 0.27125) avg lploss: 0.00000
train epoch 1012 avg loss: 0.29919 (A-MSE: 0.26402) avg lploss: 0.00000
train epoch 1013 avg loss: 0.30519 (A-MSE: 0.27021) avg lploss: 0.00000
train epoch 1014 avg loss: 0.32782 (A-MSE: 0.28941) avg lploss: 0.00000
train epoch 1015 avg loss: 0.29952 (A-MSE: 0.26520) avg lploss: 0.00000
==> val epoch 1015 avg loss: 1.13654 (A-MSE: 1.00845) avg lploss: 0.00000
==> test epoch 1015 avg loss: 1.26068 (A-MSE: 1.12434) avg lploss: 0.00000
*** Best Val Loss: 1.03198 	 Best Test Loss: 1.14984 	 Best epoch 1010
EarlyStopping counter: 1 out of 50
train epoch 1016 avg loss: 0.32164 (A-MSE: 0.28367) avg lploss: 0.00000
train epoch 1017 avg loss: 0.29628 (A-MSE: 0.26331) avg lploss: 0.00000
train epoch 1018 avg loss: 0.32961 (A-MSE: 0.28947) avg lploss: 0.00000
train epoch 1019 avg loss: 0.37376 (A-MSE: 0.33182) avg lploss: 0.00000
train epoch 1020 avg loss: 0.35268 (A-MSE: 0.30991) avg lploss: 0.00000
==> val epoch 1020 avg loss: 1.17123 (A-MSE: 1.02378) avg lploss: 0.00000
==> test epoch 1020 avg loss: 1.35009 (A-MSE: 1.18855) avg lploss: 0.00000
*** Best Val Loss: 1.03198 	 Best Test Loss: 1.14984 	 Best epoch 1010
EarlyStopping counter: 2 out of 50
train epoch 1021 avg loss: 0.30529 (A-MSE: 0.26977) avg lploss: 0.00000
train epoch 1022 avg loss: 0.31824 (A-MSE: 0.28254) avg lploss: 0.00000
train epoch 1023 avg loss: 0.30372 (A-MSE: 0.26806) avg lploss: 0.00000
train epoch 1024 avg loss: 0.32571 (A-MSE: 0.28701) avg lploss: 0.00000
train epoch 1025 avg loss: 0.33020 (A-MSE: 0.29335) avg lploss: 0.00000
==> val epoch 1025 avg loss: 1.03788 (A-MSE: 0.89500) avg lploss: 0.00000
==> test epoch 1025 avg loss: 1.20293 (A-MSE: 1.05777) avg lploss: 0.00000
*** Best Val Loss: 1.03198 	 Best Test Loss: 1.14984 	 Best epoch 1010
EarlyStopping counter: 3 out of 50
train epoch 1026 avg loss: 0.31765 (A-MSE: 0.28015) avg lploss: 0.00000
train epoch 1027 avg loss: 0.35741 (A-MSE: 0.31401) avg lploss: 0.00000
train epoch 1028 avg loss: 0.32628 (A-MSE: 0.28990) avg lploss: 0.00000
train epoch 1029 avg loss: 0.30702 (A-MSE: 0.27152) avg lploss: 0.00000
train epoch 1030 avg loss: 0.29343 (A-MSE: 0.25834) avg lploss: 0.00000
==> val epoch 1030 avg loss: 1.09609 (A-MSE: 0.96153) avg lploss: 0.00000
==> test epoch 1030 avg loss: 1.25240 (A-MSE: 1.10298) avg lploss: 0.00000
*** Best Val Loss: 1.03198 	 Best Test Loss: 1.14984 	 Best epoch 1010
EarlyStopping counter: 4 out of 50
train epoch 1031 avg loss: 0.30468 (A-MSE: 0.27016) avg lploss: 0.00000
train epoch 1032 avg loss: 0.32829 (A-MSE: 0.29218) avg lploss: 0.00000
train epoch 1033 avg loss: 0.31823 (A-MSE: 0.27899) avg lploss: 0.00000
train epoch 1034 avg loss: 0.31731 (A-MSE: 0.28008) avg lploss: 0.00000
train epoch 1035 avg loss: 0.29765 (A-MSE: 0.26263) avg lploss: 0.00000
==> val epoch 1035 avg loss: 1.00059 (A-MSE: 0.89208) avg lploss: 0.00000
==> test epoch 1035 avg loss: 1.11601 (A-MSE: 0.99974) avg lploss: 0.00000
*** Best Val Loss: 1.00059 	 Best Test Loss: 1.11601 	 Best epoch 1035
Validation loss decreased (1.031975 --> 1.000594).  Saving model ...
train epoch 1036 avg loss: 0.29432 (A-MSE: 0.26173) avg lploss: 0.00000
train epoch 1037 avg loss: 0.32543 (A-MSE: 0.28803) avg lploss: 0.00000
train epoch 1038 avg loss: 0.90068 (A-MSE: 0.78261) avg lploss: 0.00000
train epoch 1039 avg loss: 3.33914 (A-MSE: 2.85484) avg lploss: 0.00000
train epoch 1040 avg loss: 3.07712 (A-MSE: 2.69394) avg lploss: 0.00000
==> val epoch 1040 avg loss: 2.97670 (A-MSE: 2.53898) avg lploss: 0.00000
==> test epoch 1040 avg loss: 3.15347 (A-MSE: 2.72799) avg lploss: 0.00000
*** Best Val Loss: 1.00059 	 Best Test Loss: 1.11601 	 Best epoch 1035
EarlyStopping counter: 1 out of 50
train epoch 1041 avg loss: 1.57621 (A-MSE: 1.38643) avg lploss: 0.00000
train epoch 1042 avg loss: 0.93793 (A-MSE: 0.80865) avg lploss: 0.00000
train epoch 1043 avg loss: 0.63151 (A-MSE: 0.55594) avg lploss: 0.00000
train epoch 1044 avg loss: 0.50537 (A-MSE: 0.43839) avg lploss: 0.00000
train epoch 1045 avg loss: 0.44064 (A-MSE: 0.38881) avg lploss: 0.00000
==> val epoch 1045 avg loss: 1.20771 (A-MSE: 1.07347) avg lploss: 0.00000
==> test epoch 1045 avg loss: 1.33438 (A-MSE: 1.20382) avg lploss: 0.00000
*** Best Val Loss: 1.00059 	 Best Test Loss: 1.11601 	 Best epoch 1035
EarlyStopping counter: 2 out of 50
train epoch 1046 avg loss: 0.40923 (A-MSE: 0.35703) avg lploss: 0.00000
train epoch 1047 avg loss: 0.36811 (A-MSE: 0.32318) avg lploss: 0.00000
train epoch 1048 avg loss: 0.37773 (A-MSE: 0.33266) avg lploss: 0.00000
train epoch 1049 avg loss: 0.39299 (A-MSE: 0.34625) avg lploss: 0.00000
train epoch 1050 avg loss: 0.40569 (A-MSE: 0.35720) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.97354 (A-MSE: 0.85955) avg lploss: 0.00000
==> test epoch 1050 avg loss: 1.05579 (A-MSE: 0.94476) avg lploss: 0.00000
*** Best Val Loss: 0.97354 	 Best Test Loss: 1.05579 	 Best epoch 1050
Validation loss decreased (1.000594 --> 0.973535).  Saving model ...
train epoch 1051 avg loss: 0.36727 (A-MSE: 0.32426) avg lploss: 0.00000
train epoch 1052 avg loss: 0.36926 (A-MSE: 0.32556) avg lploss: 0.00000
train epoch 1053 avg loss: 0.34455 (A-MSE: 0.30212) avg lploss: 0.00000
train epoch 1054 avg loss: 0.35290 (A-MSE: 0.31030) avg lploss: 0.00000
train epoch 1055 avg loss: 0.35878 (A-MSE: 0.31559) avg lploss: 0.00000
==> val epoch 1055 avg loss: 1.10883 (A-MSE: 0.96797) avg lploss: 0.00000
==> test epoch 1055 avg loss: 1.25098 (A-MSE: 1.11328) avg lploss: 0.00000
*** Best Val Loss: 0.97354 	 Best Test Loss: 1.05579 	 Best epoch 1050
EarlyStopping counter: 1 out of 50
train epoch 1056 avg loss: 0.35188 (A-MSE: 0.31111) avg lploss: 0.00000
train epoch 1057 avg loss: 0.35050 (A-MSE: 0.30919) avg lploss: 0.00000
train epoch 1058 avg loss: 0.35802 (A-MSE: 0.31547) avg lploss: 0.00000
train epoch 1059 avg loss: 0.35484 (A-MSE: 0.31583) avg lploss: 0.00000
train epoch 1060 avg loss: 0.34070 (A-MSE: 0.29860) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.99849 (A-MSE: 0.88245) avg lploss: 0.00000
==> test epoch 1060 avg loss: 1.13935 (A-MSE: 1.01145) avg lploss: 0.00000
*** Best Val Loss: 0.97354 	 Best Test Loss: 1.05579 	 Best epoch 1050
EarlyStopping counter: 2 out of 50
train epoch 1061 avg loss: 0.28832 (A-MSE: 0.25378) avg lploss: 0.00000
train epoch 1062 avg loss: 0.29621 (A-MSE: 0.26151) avg lploss: 0.00000
train epoch 1063 avg loss: 0.28901 (A-MSE: 0.25580) avg lploss: 0.00000
train epoch 1064 avg loss: 0.30765 (A-MSE: 0.27095) avg lploss: 0.00000
train epoch 1065 avg loss: 0.28766 (A-MSE: 0.25499) avg lploss: 0.00000
==> val epoch 1065 avg loss: 1.02938 (A-MSE: 0.89001) avg lploss: 0.00000
==> test epoch 1065 avg loss: 1.14439 (A-MSE: 1.01498) avg lploss: 0.00000
*** Best Val Loss: 0.97354 	 Best Test Loss: 1.05579 	 Best epoch 1050
EarlyStopping counter: 3 out of 50
train epoch 1066 avg loss: 0.29387 (A-MSE: 0.26088) avg lploss: 0.00000
train epoch 1067 avg loss: 0.29290 (A-MSE: 0.25755) avg lploss: 0.00000
train epoch 1068 avg loss: 0.28432 (A-MSE: 0.25284) avg lploss: 0.00000
train epoch 1069 avg loss: 0.29902 (A-MSE: 0.26228) avg lploss: 0.00000
train epoch 1070 avg loss: 0.28904 (A-MSE: 0.25583) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.90002 (A-MSE: 0.78841) avg lploss: 0.00000
==> test epoch 1070 avg loss: 1.03516 (A-MSE: 0.91028) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
Validation loss decreased (0.973535 --> 0.900019).  Saving model ...
train epoch 1071 avg loss: 0.30913 (A-MSE: 0.27182) avg lploss: 0.00000
train epoch 1072 avg loss: 0.31336 (A-MSE: 0.27512) avg lploss: 0.00000
train epoch 1073 avg loss: 0.28533 (A-MSE: 0.25363) avg lploss: 0.00000
train epoch 1074 avg loss: 0.28509 (A-MSE: 0.25369) avg lploss: 0.00000
train epoch 1075 avg loss: 0.27295 (A-MSE: 0.24170) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.90941 (A-MSE: 0.80659) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.99837 (A-MSE: 0.90518) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 1 out of 50
train epoch 1076 avg loss: 0.25642 (A-MSE: 0.22833) avg lploss: 0.00000
train epoch 1077 avg loss: 0.28749 (A-MSE: 0.25297) avg lploss: 0.00000
train epoch 1078 avg loss: 0.30029 (A-MSE: 0.26633) avg lploss: 0.00000
train epoch 1079 avg loss: 0.30272 (A-MSE: 0.26849) avg lploss: 0.00000
train epoch 1080 avg loss: 0.27891 (A-MSE: 0.24763) avg lploss: 0.00000
==> val epoch 1080 avg loss: 1.09784 (A-MSE: 0.96389) avg lploss: 0.00000
==> test epoch 1080 avg loss: 1.21769 (A-MSE: 1.08522) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 2 out of 50
train epoch 1081 avg loss: 0.28984 (A-MSE: 0.25710) avg lploss: 0.00000
train epoch 1082 avg loss: 0.27348 (A-MSE: 0.24470) avg lploss: 0.00000
train epoch 1083 avg loss: 0.27461 (A-MSE: 0.24277) avg lploss: 0.00000
train epoch 1084 avg loss: 0.28229 (A-MSE: 0.24974) avg lploss: 0.00000
train epoch 1085 avg loss: 0.30377 (A-MSE: 0.26836) avg lploss: 0.00000
==> val epoch 1085 avg loss: 1.16081 (A-MSE: 1.01802) avg lploss: 0.00000
==> test epoch 1085 avg loss: 1.28072 (A-MSE: 1.14214) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 3 out of 50
train epoch 1086 avg loss: 0.29092 (A-MSE: 0.25760) avg lploss: 0.00000
train epoch 1087 avg loss: 0.26438 (A-MSE: 0.23622) avg lploss: 0.00000
train epoch 1088 avg loss: 0.26709 (A-MSE: 0.23795) avg lploss: 0.00000
train epoch 1089 avg loss: 0.26469 (A-MSE: 0.23580) avg lploss: 0.00000
train epoch 1090 avg loss: 0.25414 (A-MSE: 0.22458) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.95923 (A-MSE: 0.83515) avg lploss: 0.00000
==> test epoch 1090 avg loss: 1.05968 (A-MSE: 0.93622) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 4 out of 50
train epoch 1091 avg loss: 0.25360 (A-MSE: 0.22530) avg lploss: 0.00000
train epoch 1092 avg loss: 0.27837 (A-MSE: 0.24710) avg lploss: 0.00000
train epoch 1093 avg loss: 0.30773 (A-MSE: 0.27151) avg lploss: 0.00000
train epoch 1094 avg loss: 0.31301 (A-MSE: 0.27714) avg lploss: 0.00000
train epoch 1095 avg loss: 0.27967 (A-MSE: 0.24948) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.98817 (A-MSE: 0.85919) avg lploss: 0.00000
==> test epoch 1095 avg loss: 1.11263 (A-MSE: 0.97662) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 5 out of 50
train epoch 1096 avg loss: 0.29511 (A-MSE: 0.26169) avg lploss: 0.00000
train epoch 1097 avg loss: 0.31073 (A-MSE: 0.27401) avg lploss: 0.00000
train epoch 1098 avg loss: 0.27250 (A-MSE: 0.24187) avg lploss: 0.00000
train epoch 1099 avg loss: 0.28112 (A-MSE: 0.24909) avg lploss: 0.00000
train epoch 1100 avg loss: 0.26477 (A-MSE: 0.23434) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.96046 (A-MSE: 0.84244) avg lploss: 0.00000
==> test epoch 1100 avg loss: 1.10849 (A-MSE: 0.99457) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 6 out of 50
train epoch 1101 avg loss: 0.25837 (A-MSE: 0.22904) avg lploss: 0.00000
train epoch 1102 avg loss: 0.27200 (A-MSE: 0.24315) avg lploss: 0.00000
train epoch 1103 avg loss: 0.29007 (A-MSE: 0.25810) avg lploss: 0.00000
train epoch 1104 avg loss: 0.25968 (A-MSE: 0.23193) avg lploss: 0.00000
train epoch 1105 avg loss: 0.25826 (A-MSE: 0.23010) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.93345 (A-MSE: 0.81426) avg lploss: 0.00000
==> test epoch 1105 avg loss: 1.08087 (A-MSE: 0.95365) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 7 out of 50
train epoch 1106 avg loss: 0.25915 (A-MSE: 0.23063) avg lploss: 0.00000
train epoch 1107 avg loss: 0.23859 (A-MSE: 0.21059) avg lploss: 0.00000
train epoch 1108 avg loss: 0.23041 (A-MSE: 0.20478) avg lploss: 0.00000
train epoch 1109 avg loss: 0.23451 (A-MSE: 0.20792) avg lploss: 0.00000
train epoch 1110 avg loss: 0.25932 (A-MSE: 0.23026) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.93143 (A-MSE: 0.82143) avg lploss: 0.00000
==> test epoch 1110 avg loss: 1.02278 (A-MSE: 0.92159) avg lploss: 0.00000
*** Best Val Loss: 0.90002 	 Best Test Loss: 1.03516 	 Best epoch 1070
EarlyStopping counter: 8 out of 50
train epoch 1111 avg loss: 0.25321 (A-MSE: 0.22406) avg lploss: 0.00000
train epoch 1112 avg loss: 0.27086 (A-MSE: 0.23958) avg lploss: 0.00000
train epoch 1113 avg loss: 0.28755 (A-MSE: 0.25586) avg lploss: 0.00000
train epoch 1114 avg loss: 0.25498 (A-MSE: 0.22687) avg lploss: 0.00000
train epoch 1115 avg loss: 0.23490 (A-MSE: 0.20852) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.88339 (A-MSE: 0.77290) avg lploss: 0.00000
==> test epoch 1115 avg loss: 1.00044 (A-MSE: 0.89261) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
Validation loss decreased (0.900019 --> 0.883395).  Saving model ...
train epoch 1116 avg loss: 0.23345 (A-MSE: 0.20799) avg lploss: 0.00000
train epoch 1117 avg loss: 0.24577 (A-MSE: 0.21859) avg lploss: 0.00000
train epoch 1118 avg loss: 0.28094 (A-MSE: 0.25121) avg lploss: 0.00000
train epoch 1119 avg loss: 0.25995 (A-MSE: 0.23072) avg lploss: 0.00000
train epoch 1120 avg loss: 0.27141 (A-MSE: 0.23904) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.92530 (A-MSE: 0.80372) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.99560 (A-MSE: 0.88310) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 1 out of 50
train epoch 1121 avg loss: 0.26010 (A-MSE: 0.23015) avg lploss: 0.00000
train epoch 1122 avg loss: 0.25439 (A-MSE: 0.22424) avg lploss: 0.00000
train epoch 1123 avg loss: 0.25481 (A-MSE: 0.22693) avg lploss: 0.00000
train epoch 1124 avg loss: 0.29130 (A-MSE: 0.25670) avg lploss: 0.00000
train epoch 1125 avg loss: 0.34940 (A-MSE: 0.31158) avg lploss: 0.00000
==> val epoch 1125 avg loss: 1.13951 (A-MSE: 0.95295) avg lploss: 0.00000
==> test epoch 1125 avg loss: 1.20910 (A-MSE: 1.04480) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 2 out of 50
train epoch 1126 avg loss: 0.29875 (A-MSE: 0.26549) avg lploss: 0.00000
train epoch 1127 avg loss: 0.28373 (A-MSE: 0.25223) avg lploss: 0.00000
train epoch 1128 avg loss: 0.31178 (A-MSE: 0.27829) avg lploss: 0.00000
train epoch 1129 avg loss: 0.29906 (A-MSE: 0.26544) avg lploss: 0.00000
train epoch 1130 avg loss: 0.25312 (A-MSE: 0.22434) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.93092 (A-MSE: 0.81140) avg lploss: 0.00000
==> test epoch 1130 avg loss: 1.06262 (A-MSE: 0.94852) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 3 out of 50
train epoch 1131 avg loss: 0.24988 (A-MSE: 0.22254) avg lploss: 0.00000
train epoch 1132 avg loss: 0.23581 (A-MSE: 0.21003) avg lploss: 0.00000
train epoch 1133 avg loss: 0.24680 (A-MSE: 0.21901) avg lploss: 0.00000
train epoch 1134 avg loss: 0.24351 (A-MSE: 0.21629) avg lploss: 0.00000
train epoch 1135 avg loss: 0.25403 (A-MSE: 0.22751) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.96481 (A-MSE: 0.83122) avg lploss: 0.00000
==> test epoch 1135 avg loss: 1.08511 (A-MSE: 0.95527) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 4 out of 50
train epoch 1136 avg loss: 0.23459 (A-MSE: 0.20754) avg lploss: 0.00000
train epoch 1137 avg loss: 0.22930 (A-MSE: 0.20323) avg lploss: 0.00000
train epoch 1138 avg loss: 0.23719 (A-MSE: 0.21030) avg lploss: 0.00000
train epoch 1139 avg loss: 0.24979 (A-MSE: 0.22355) avg lploss: 0.00000
train epoch 1140 avg loss: 0.26153 (A-MSE: 0.23100) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.93681 (A-MSE: 0.81489) avg lploss: 0.00000
==> test epoch 1140 avg loss: 1.13280 (A-MSE: 1.00043) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 5 out of 50
train epoch 1141 avg loss: 0.26332 (A-MSE: 0.23367) avg lploss: 0.00000
train epoch 1142 avg loss: 0.26627 (A-MSE: 0.23651) avg lploss: 0.00000
train epoch 1143 avg loss: 0.27377 (A-MSE: 0.24311) avg lploss: 0.00000
train epoch 1144 avg loss: 0.25286 (A-MSE: 0.22501) avg lploss: 0.00000
train epoch 1145 avg loss: 0.25011 (A-MSE: 0.22251) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.90537 (A-MSE: 0.79089) avg lploss: 0.00000
==> test epoch 1145 avg loss: 1.03309 (A-MSE: 0.90765) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 6 out of 50
train epoch 1146 avg loss: 0.23369 (A-MSE: 0.20755) avg lploss: 0.00000
train epoch 1147 avg loss: 0.26439 (A-MSE: 0.23466) avg lploss: 0.00000
train epoch 1148 avg loss: 0.26623 (A-MSE: 0.23543) avg lploss: 0.00000
train epoch 1149 avg loss: 0.25917 (A-MSE: 0.22958) avg lploss: 0.00000
train epoch 1150 avg loss: 0.25017 (A-MSE: 0.22368) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.91610 (A-MSE: 0.78774) avg lploss: 0.00000
==> test epoch 1150 avg loss: 1.06458 (A-MSE: 0.92670) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 7 out of 50
train epoch 1151 avg loss: 0.22785 (A-MSE: 0.20265) avg lploss: 0.00000
train epoch 1152 avg loss: 0.24922 (A-MSE: 0.21994) avg lploss: 0.00000
train epoch 1153 avg loss: 0.23812 (A-MSE: 0.21098) avg lploss: 0.00000
train epoch 1154 avg loss: 0.25233 (A-MSE: 0.22296) avg lploss: 0.00000
train epoch 1155 avg loss: 0.27971 (A-MSE: 0.24869) avg lploss: 0.00000
==> val epoch 1155 avg loss: 1.00391 (A-MSE: 0.87694) avg lploss: 0.00000
==> test epoch 1155 avg loss: 1.09819 (A-MSE: 0.97855) avg lploss: 0.00000
*** Best Val Loss: 0.88339 	 Best Test Loss: 1.00044 	 Best epoch 1115
EarlyStopping counter: 8 out of 50
train epoch 1156 avg loss: 0.29561 (A-MSE: 0.26288) avg lploss: 0.00000
train epoch 1157 avg loss: 0.30389 (A-MSE: 0.26863) avg lploss: 0.00000
train epoch 1158 avg loss: 0.34424 (A-MSE: 0.30311) avg lploss: 0.00000
train epoch 1159 avg loss: 0.28576 (A-MSE: 0.25343) avg lploss: 0.00000
train epoch 1160 avg loss: 0.25642 (A-MSE: 0.22779) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.80253 (A-MSE: 0.70549) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.90224 (A-MSE: 0.80767) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
Validation loss decreased (0.883395 --> 0.802527).  Saving model ...
train epoch 1161 avg loss: 0.25534 (A-MSE: 0.22547) avg lploss: 0.00000
train epoch 1162 avg loss: 0.27298 (A-MSE: 0.24112) avg lploss: 0.00000
train epoch 1163 avg loss: 0.32659 (A-MSE: 0.28877) avg lploss: 0.00000
train epoch 1164 avg loss: 0.30115 (A-MSE: 0.26671) avg lploss: 0.00000
train epoch 1165 avg loss: 0.25335 (A-MSE: 0.22367) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.86280 (A-MSE: 0.74904) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.96723 (A-MSE: 0.86448) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
EarlyStopping counter: 1 out of 50
train epoch 1166 avg loss: 0.22290 (A-MSE: 0.19810) avg lploss: 0.00000
train epoch 1167 avg loss: 0.23916 (A-MSE: 0.21130) avg lploss: 0.00000
train epoch 1168 avg loss: 0.21070 (A-MSE: 0.18682) avg lploss: 0.00000
train epoch 1169 avg loss: 0.24141 (A-MSE: 0.21324) avg lploss: 0.00000
train epoch 1170 avg loss: 0.25743 (A-MSE: 0.22899) avg lploss: 0.00000
==> val epoch 1170 avg loss: 1.08278 (A-MSE: 0.93580) avg lploss: 0.00000
==> test epoch 1170 avg loss: 1.21560 (A-MSE: 1.06221) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
EarlyStopping counter: 2 out of 50
train epoch 1171 avg loss: 0.27764 (A-MSE: 0.24696) avg lploss: 0.00000
train epoch 1172 avg loss: 0.26435 (A-MSE: 0.23526) avg lploss: 0.00000
train epoch 1173 avg loss: 0.26304 (A-MSE: 0.23446) avg lploss: 0.00000
train epoch 1174 avg loss: 0.26072 (A-MSE: 0.23064) avg lploss: 0.00000
train epoch 1175 avg loss: 0.26725 (A-MSE: 0.23822) avg lploss: 0.00000
==> val epoch 1175 avg loss: 1.00806 (A-MSE: 0.88894) avg lploss: 0.00000
==> test epoch 1175 avg loss: 1.05594 (A-MSE: 0.95492) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
EarlyStopping counter: 3 out of 50
train epoch 1176 avg loss: 0.28298 (A-MSE: 0.24691) avg lploss: 0.00000
train epoch 1177 avg loss: 0.24827 (A-MSE: 0.22179) avg lploss: 0.00000
train epoch 1178 avg loss: 0.27689 (A-MSE: 0.24630) avg lploss: 0.00000
train epoch 1179 avg loss: 0.24283 (A-MSE: 0.21445) avg lploss: 0.00000
train epoch 1180 avg loss: 0.21310 (A-MSE: 0.18962) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.81442 (A-MSE: 0.71169) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.94855 (A-MSE: 0.84349) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
EarlyStopping counter: 4 out of 50
train epoch 1181 avg loss: 0.22819 (A-MSE: 0.20244) avg lploss: 0.00000
train epoch 1182 avg loss: 0.22984 (A-MSE: 0.20376) avg lploss: 0.00000
train epoch 1183 avg loss: 0.22259 (A-MSE: 0.19616) avg lploss: 0.00000
train epoch 1184 avg loss: 0.25793 (A-MSE: 0.22921) avg lploss: 0.00000
train epoch 1185 avg loss: 0.23687 (A-MSE: 0.21083) avg lploss: 0.00000
==> val epoch 1185 avg loss: 1.02912 (A-MSE: 0.88149) avg lploss: 0.00000
==> test epoch 1185 avg loss: 1.26825 (A-MSE: 1.09367) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
EarlyStopping counter: 5 out of 50
train epoch 1186 avg loss: 0.26881 (A-MSE: 0.23685) avg lploss: 0.00000
train epoch 1187 avg loss: 0.23867 (A-MSE: 0.21089) avg lploss: 0.00000
train epoch 1188 avg loss: 0.22301 (A-MSE: 0.19815) avg lploss: 0.00000
train epoch 1189 avg loss: 0.23355 (A-MSE: 0.20578) avg lploss: 0.00000
train epoch 1190 avg loss: 0.26560 (A-MSE: 0.23638) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.96610 (A-MSE: 0.82782) avg lploss: 0.00000
==> test epoch 1190 avg loss: 1.08736 (A-MSE: 0.95487) avg lploss: 0.00000
*** Best Val Loss: 0.80253 	 Best Test Loss: 0.90224 	 Best epoch 1160
EarlyStopping counter: 6 out of 50
train epoch 1191 avg loss: 0.31036 (A-MSE: 0.27565) avg lploss: 0.00000
train epoch 1192 avg loss: 0.25159 (A-MSE: 0.22310) avg lploss: 0.00000
train epoch 1193 avg loss: 0.20819 (A-MSE: 0.18698) avg lploss: 0.00000
train epoch 1194 avg loss: 0.24402 (A-MSE: 0.21597) avg lploss: 0.00000
train epoch 1195 avg loss: 0.24992 (A-MSE: 0.21922) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.79100 (A-MSE: 0.68651) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.92913 (A-MSE: 0.81983) avg lploss: 0.00000
*** Best Val Loss: 0.79100 	 Best Test Loss: 0.92913 	 Best epoch 1195
Validation loss decreased (0.802527 --> 0.790996).  Saving model ...
train epoch 1196 avg loss: 0.26523 (A-MSE: 0.23602) avg lploss: 0.00000
train epoch 1197 avg loss: 0.25321 (A-MSE: 0.22537) avg lploss: 0.00000
train epoch 1198 avg loss: 0.23919 (A-MSE: 0.21176) avg lploss: 0.00000
train epoch 1199 avg loss: 0.26358 (A-MSE: 0.23300) avg lploss: 0.00000
train epoch 1200 avg loss: 0.24869 (A-MSE: 0.21951) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.96927 (A-MSE: 0.83322) avg lploss: 0.00000
==> test epoch 1200 avg loss: 1.09174 (A-MSE: 0.95541) avg lploss: 0.00000
*** Best Val Loss: 0.79100 	 Best Test Loss: 0.92913 	 Best epoch 1195
EarlyStopping counter: 1 out of 50
train epoch 1201 avg loss: 0.25066 (A-MSE: 0.22089) avg lploss: 0.00000
train epoch 1202 avg loss: 0.23393 (A-MSE: 0.20807) avg lploss: 0.00000
train epoch 1203 avg loss: 0.20536 (A-MSE: 0.18237) avg lploss: 0.00000
train epoch 1204 avg loss: 0.23974 (A-MSE: 0.21430) avg lploss: 0.00000
train epoch 1205 avg loss: 0.24225 (A-MSE: 0.21567) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.77319 (A-MSE: 0.67410) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.89330 (A-MSE: 0.79652) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
Validation loss decreased (0.790996 --> 0.773188).  Saving model ...
train epoch 1206 avg loss: 0.23226 (A-MSE: 0.20396) avg lploss: 0.00000
train epoch 1207 avg loss: 0.21251 (A-MSE: 0.19003) avg lploss: 0.00000
train epoch 1208 avg loss: 0.27113 (A-MSE: 0.23935) avg lploss: 0.00000
train epoch 1209 avg loss: 0.22907 (A-MSE: 0.20112) avg lploss: 0.00000
train epoch 1210 avg loss: 0.24353 (A-MSE: 0.21839) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.85079 (A-MSE: 0.73811) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.96365 (A-MSE: 0.85426) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 1 out of 50
train epoch 1211 avg loss: 0.20061 (A-MSE: 0.17871) avg lploss: 0.00000
train epoch 1212 avg loss: 0.20341 (A-MSE: 0.17909) avg lploss: 0.00000
train epoch 1213 avg loss: 0.22771 (A-MSE: 0.20348) avg lploss: 0.00000
train epoch 1214 avg loss: 0.23384 (A-MSE: 0.20787) avg lploss: 0.00000
train epoch 1215 avg loss: 0.23104 (A-MSE: 0.20435) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.98294 (A-MSE: 0.86649) avg lploss: 0.00000
==> test epoch 1215 avg loss: 1.12234 (A-MSE: 1.00806) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 2 out of 50
train epoch 1216 avg loss: 0.27598 (A-MSE: 0.24490) avg lploss: 0.00000
train epoch 1217 avg loss: 0.29991 (A-MSE: 0.26477) avg lploss: 0.00000
train epoch 1218 avg loss: 0.23096 (A-MSE: 0.20523) avg lploss: 0.00000
train epoch 1219 avg loss: 0.22560 (A-MSE: 0.19898) avg lploss: 0.00000
train epoch 1220 avg loss: 0.21246 (A-MSE: 0.18864) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.99516 (A-MSE: 0.86113) avg lploss: 0.00000
==> test epoch 1220 avg loss: 1.13122 (A-MSE: 0.99157) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 3 out of 50
train epoch 1221 avg loss: 0.20780 (A-MSE: 0.18535) avg lploss: 0.00000
train epoch 1222 avg loss: 0.21810 (A-MSE: 0.19385) avg lploss: 0.00000
train epoch 1223 avg loss: 0.23506 (A-MSE: 0.20843) avg lploss: 0.00000
train epoch 1224 avg loss: 0.22909 (A-MSE: 0.20295) avg lploss: 0.00000
train epoch 1225 avg loss: 0.20141 (A-MSE: 0.17850) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.87982 (A-MSE: 0.75081) avg lploss: 0.00000
==> test epoch 1225 avg loss: 1.00245 (A-MSE: 0.87956) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 4 out of 50
train epoch 1226 avg loss: 0.19790 (A-MSE: 0.17626) avg lploss: 0.00000
train epoch 1227 avg loss: 0.22141 (A-MSE: 0.19561) avg lploss: 0.00000
train epoch 1228 avg loss: 0.25137 (A-MSE: 0.22318) avg lploss: 0.00000
train epoch 1229 avg loss: 0.21932 (A-MSE: 0.19498) avg lploss: 0.00000
train epoch 1230 avg loss: 0.21476 (A-MSE: 0.19079) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.81104 (A-MSE: 0.71020) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.91955 (A-MSE: 0.81999) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 5 out of 50
train epoch 1231 avg loss: 0.20459 (A-MSE: 0.18219) avg lploss: 0.00000
train epoch 1232 avg loss: 0.21556 (A-MSE: 0.19110) avg lploss: 0.00000
train epoch 1233 avg loss: 0.20932 (A-MSE: 0.18689) avg lploss: 0.00000
train epoch 1234 avg loss: 0.23928 (A-MSE: 0.21247) avg lploss: 0.00000
train epoch 1235 avg loss: 0.24599 (A-MSE: 0.21664) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.95847 (A-MSE: 0.82071) avg lploss: 0.00000
==> test epoch 1235 avg loss: 1.08676 (A-MSE: 0.95822) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 6 out of 50
train epoch 1236 avg loss: 0.25749 (A-MSE: 0.22756) avg lploss: 0.00000
train epoch 1237 avg loss: 0.24013 (A-MSE: 0.21248) avg lploss: 0.00000
train epoch 1238 avg loss: 0.20087 (A-MSE: 0.17813) avg lploss: 0.00000
train epoch 1239 avg loss: 0.19313 (A-MSE: 0.17201) avg lploss: 0.00000
train epoch 1240 avg loss: 0.20080 (A-MSE: 0.17987) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.79516 (A-MSE: 0.69797) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.93172 (A-MSE: 0.83922) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 7 out of 50
train epoch 1241 avg loss: 0.21168 (A-MSE: 0.18802) avg lploss: 0.00000
train epoch 1242 avg loss: 0.20536 (A-MSE: 0.18226) avg lploss: 0.00000
train epoch 1243 avg loss: 0.23300 (A-MSE: 0.20698) avg lploss: 0.00000
train epoch 1244 avg loss: 0.21556 (A-MSE: 0.19248) avg lploss: 0.00000
train epoch 1245 avg loss: 0.19504 (A-MSE: 0.17367) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.85853 (A-MSE: 0.73874) avg lploss: 0.00000
==> test epoch 1245 avg loss: 1.00597 (A-MSE: 0.88312) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 8 out of 50
train epoch 1246 avg loss: 0.18683 (A-MSE: 0.16633) avg lploss: 0.00000
train epoch 1247 avg loss: 0.21265 (A-MSE: 0.18996) avg lploss: 0.00000
train epoch 1248 avg loss: 0.22150 (A-MSE: 0.19711) avg lploss: 0.00000
train epoch 1249 avg loss: 0.23832 (A-MSE: 0.21055) avg lploss: 0.00000
train epoch 1250 avg loss: 0.20631 (A-MSE: 0.18408) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.99611 (A-MSE: 0.86259) avg lploss: 0.00000
==> test epoch 1250 avg loss: 1.18005 (A-MSE: 1.03851) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 9 out of 50
train epoch 1251 avg loss: 0.20156 (A-MSE: 0.17890) avg lploss: 0.00000
train epoch 1252 avg loss: 0.20738 (A-MSE: 0.18429) avg lploss: 0.00000
train epoch 1253 avg loss: 0.23384 (A-MSE: 0.20764) avg lploss: 0.00000
train epoch 1254 avg loss: 0.22399 (A-MSE: 0.19882) avg lploss: 0.00000
train epoch 1255 avg loss: 0.21276 (A-MSE: 0.18868) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.91049 (A-MSE: 0.77526) avg lploss: 0.00000
==> test epoch 1255 avg loss: 1.08451 (A-MSE: 0.95452) avg lploss: 0.00000
*** Best Val Loss: 0.77319 	 Best Test Loss: 0.89330 	 Best epoch 1205
EarlyStopping counter: 10 out of 50
train epoch 1256 avg loss: 0.21745 (A-MSE: 0.19193) avg lploss: 0.00000
train epoch 1257 avg loss: 0.25996 (A-MSE: 0.23163) avg lploss: 0.00000
train epoch 1258 avg loss: 0.25123 (A-MSE: 0.22140) avg lploss: 0.00000
train epoch 1259 avg loss: 0.22186 (A-MSE: 0.19475) avg lploss: 0.00000
train epoch 1260 avg loss: 0.23962 (A-MSE: 0.21165) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.74010 (A-MSE: 0.64266) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.82990 (A-MSE: 0.73568) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
Validation loss decreased (0.773188 --> 0.740096).  Saving model ...
train epoch 1261 avg loss: 0.22243 (A-MSE: 0.19693) avg lploss: 0.00000
train epoch 1262 avg loss: 0.25055 (A-MSE: 0.22315) avg lploss: 0.00000
train epoch 1263 avg loss: 0.24132 (A-MSE: 0.21419) avg lploss: 0.00000
train epoch 1264 avg loss: 0.22467 (A-MSE: 0.19807) avg lploss: 0.00000
train epoch 1265 avg loss: 0.21038 (A-MSE: 0.18714) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.74890 (A-MSE: 0.65787) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.87826 (A-MSE: 0.78354) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 1 out of 50
train epoch 1266 avg loss: 0.20443 (A-MSE: 0.18215) avg lploss: 0.00000
train epoch 1267 avg loss: 0.20105 (A-MSE: 0.17956) avg lploss: 0.00000
train epoch 1268 avg loss: 0.27482 (A-MSE: 0.24427) avg lploss: 0.00000
train epoch 1269 avg loss: 0.28462 (A-MSE: 0.25114) avg lploss: 0.00000
train epoch 1270 avg loss: 0.25802 (A-MSE: 0.22774) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.94545 (A-MSE: 0.83589) avg lploss: 0.00000
==> test epoch 1270 avg loss: 1.06505 (A-MSE: 0.95822) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 2 out of 50
train epoch 1271 avg loss: 0.23126 (A-MSE: 0.20435) avg lploss: 0.00000
train epoch 1272 avg loss: 0.22924 (A-MSE: 0.20241) avg lploss: 0.00000
train epoch 1273 avg loss: 0.20854 (A-MSE: 0.18641) avg lploss: 0.00000
train epoch 1274 avg loss: 0.19621 (A-MSE: 0.17421) avg lploss: 0.00000
train epoch 1275 avg loss: 0.17514 (A-MSE: 0.15489) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.80858 (A-MSE: 0.71191) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.95335 (A-MSE: 0.85482) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 3 out of 50
train epoch 1276 avg loss: 0.18492 (A-MSE: 0.16443) avg lploss: 0.00000
train epoch 1277 avg loss: 0.21501 (A-MSE: 0.19117) avg lploss: 0.00000
train epoch 1278 avg loss: 0.20759 (A-MSE: 0.18522) avg lploss: 0.00000
train epoch 1279 avg loss: 0.18892 (A-MSE: 0.16728) avg lploss: 0.00000
train epoch 1280 avg loss: 0.18976 (A-MSE: 0.16832) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.83682 (A-MSE: 0.72578) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.95560 (A-MSE: 0.84892) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 4 out of 50
train epoch 1281 avg loss: 0.19527 (A-MSE: 0.17338) avg lploss: 0.00000
train epoch 1282 avg loss: 0.22933 (A-MSE: 0.20185) avg lploss: 0.00000
train epoch 1283 avg loss: 0.23293 (A-MSE: 0.20581) avg lploss: 0.00000
train epoch 1284 avg loss: 0.19710 (A-MSE: 0.17632) avg lploss: 0.00000
train epoch 1285 avg loss: 0.18566 (A-MSE: 0.16502) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.91098 (A-MSE: 0.80607) avg lploss: 0.00000
==> test epoch 1285 avg loss: 1.00241 (A-MSE: 0.90771) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 5 out of 50
train epoch 1286 avg loss: 0.19521 (A-MSE: 0.17383) avg lploss: 0.00000
train epoch 1287 avg loss: 0.19131 (A-MSE: 0.17149) avg lploss: 0.00000
train epoch 1288 avg loss: 0.22764 (A-MSE: 0.20014) avg lploss: 0.00000
train epoch 1289 avg loss: 0.19751 (A-MSE: 0.17584) avg lploss: 0.00000
train epoch 1290 avg loss: 0.21250 (A-MSE: 0.18861) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.88214 (A-MSE: 0.78981) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.94101 (A-MSE: 0.85805) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 6 out of 50
train epoch 1291 avg loss: 0.21620 (A-MSE: 0.19364) avg lploss: 0.00000
train epoch 1292 avg loss: 0.21986 (A-MSE: 0.19344) avg lploss: 0.00000
train epoch 1293 avg loss: 0.22182 (A-MSE: 0.19681) avg lploss: 0.00000
train epoch 1294 avg loss: 0.22875 (A-MSE: 0.20250) avg lploss: 0.00000
train epoch 1295 avg loss: 0.22354 (A-MSE: 0.19799) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.84158 (A-MSE: 0.74449) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.96259 (A-MSE: 0.86909) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 7 out of 50
train epoch 1296 avg loss: 0.19285 (A-MSE: 0.16990) avg lploss: 0.00000
train epoch 1297 avg loss: 0.18086 (A-MSE: 0.16126) avg lploss: 0.00000
train epoch 1298 avg loss: 0.18068 (A-MSE: 0.15979) avg lploss: 0.00000
train epoch 1299 avg loss: 0.18681 (A-MSE: 0.16478) avg lploss: 0.00000
train epoch 1300 avg loss: 0.20305 (A-MSE: 0.18135) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.86261 (A-MSE: 0.75591) avg lploss: 0.00000
==> test epoch 1300 avg loss: 1.03494 (A-MSE: 0.92398) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 8 out of 50
train epoch 1301 avg loss: 0.24494 (A-MSE: 0.21610) avg lploss: 0.00000
train epoch 1302 avg loss: 0.27411 (A-MSE: 0.24214) avg lploss: 0.00000
train epoch 1303 avg loss: 0.20724 (A-MSE: 0.18397) avg lploss: 0.00000
train epoch 1304 avg loss: 0.19993 (A-MSE: 0.17828) avg lploss: 0.00000
train epoch 1305 avg loss: 0.20261 (A-MSE: 0.17920) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.85228 (A-MSE: 0.76240) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.94107 (A-MSE: 0.86406) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 9 out of 50
train epoch 1306 avg loss: 0.21915 (A-MSE: 0.19441) avg lploss: 0.00000
train epoch 1307 avg loss: 0.20259 (A-MSE: 0.18018) avg lploss: 0.00000
train epoch 1308 avg loss: 0.19138 (A-MSE: 0.17069) avg lploss: 0.00000
train epoch 1309 avg loss: 0.18549 (A-MSE: 0.16347) avg lploss: 0.00000
train epoch 1310 avg loss: 0.19582 (A-MSE: 0.17500) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.79424 (A-MSE: 0.70196) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.84943 (A-MSE: 0.77062) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 10 out of 50
train epoch 1311 avg loss: 0.18555 (A-MSE: 0.16471) avg lploss: 0.00000
train epoch 1312 avg loss: 0.22076 (A-MSE: 0.19579) avg lploss: 0.00000
train epoch 1313 avg loss: 0.28318 (A-MSE: 0.24912) avg lploss: 0.00000
train epoch 1314 avg loss: 0.25929 (A-MSE: 0.23040) avg lploss: 0.00000
train epoch 1315 avg loss: 0.21714 (A-MSE: 0.19307) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.81297 (A-MSE: 0.71825) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.95200 (A-MSE: 0.85399) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 11 out of 50
train epoch 1316 avg loss: 0.26135 (A-MSE: 0.23243) avg lploss: 0.00000
train epoch 1317 avg loss: 0.42245 (A-MSE: 0.37189) avg lploss: 0.00000
train epoch 1318 avg loss: 0.32770 (A-MSE: 0.28687) avg lploss: 0.00000
train epoch 1319 avg loss: 0.21556 (A-MSE: 0.19118) avg lploss: 0.00000
train epoch 1320 avg loss: 0.19159 (A-MSE: 0.17108) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.82170 (A-MSE: 0.71717) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.92912 (A-MSE: 0.83202) avg lploss: 0.00000
*** Best Val Loss: 0.74010 	 Best Test Loss: 0.82990 	 Best epoch 1260
EarlyStopping counter: 12 out of 50
train epoch 1321 avg loss: 0.20694 (A-MSE: 0.18447) avg lploss: 0.00000
train epoch 1322 avg loss: 0.19834 (A-MSE: 0.17666) avg lploss: 0.00000
train epoch 1323 avg loss: 0.18958 (A-MSE: 0.16925) avg lploss: 0.00000
train epoch 1324 avg loss: 0.20389 (A-MSE: 0.18180) avg lploss: 0.00000
train epoch 1325 avg loss: 0.17494 (A-MSE: 0.15579) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.73115 (A-MSE: 0.64698) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.80673 (A-MSE: 0.73109) avg lploss: 0.00000
*** Best Val Loss: 0.73115 	 Best Test Loss: 0.80673 	 Best epoch 1325
Validation loss decreased (0.740096 --> 0.731153).  Saving model ...
train epoch 1326 avg loss: 0.16905 (A-MSE: 0.15045) avg lploss: 0.00000
train epoch 1327 avg loss: 0.17677 (A-MSE: 0.15694) avg lploss: 0.00000
train epoch 1328 avg loss: 0.18357 (A-MSE: 0.16152) avg lploss: 0.00000
train epoch 1329 avg loss: 0.21086 (A-MSE: 0.18802) avg lploss: 0.00000
train epoch 1330 avg loss: 0.26163 (A-MSE: 0.23043) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.83015 (A-MSE: 0.72930) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.91334 (A-MSE: 0.81547) avg lploss: 0.00000
*** Best Val Loss: 0.73115 	 Best Test Loss: 0.80673 	 Best epoch 1325
EarlyStopping counter: 1 out of 50
train epoch 1331 avg loss: 0.18658 (A-MSE: 0.16692) avg lploss: 0.00000
train epoch 1332 avg loss: 0.18416 (A-MSE: 0.16430) avg lploss: 0.00000
train epoch 1333 avg loss: 0.18329 (A-MSE: 0.16256) avg lploss: 0.00000
train epoch 1334 avg loss: 0.18277 (A-MSE: 0.16232) avg lploss: 0.00000
train epoch 1335 avg loss: 0.19066 (A-MSE: 0.16966) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.71304 (A-MSE: 0.62315) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.80246 (A-MSE: 0.72116) avg lploss: 0.00000
*** Best Val Loss: 0.71304 	 Best Test Loss: 0.80246 	 Best epoch 1335
Validation loss decreased (0.731153 --> 0.713035).  Saving model ...
train epoch 1336 avg loss: 0.19058 (A-MSE: 0.17043) avg lploss: 0.00000
train epoch 1337 avg loss: 0.19318 (A-MSE: 0.17165) avg lploss: 0.00000
train epoch 1338 avg loss: 0.17214 (A-MSE: 0.15270) avg lploss: 0.00000
train epoch 1339 avg loss: 0.17210 (A-MSE: 0.15297) avg lploss: 0.00000
train epoch 1340 avg loss: 0.20007 (A-MSE: 0.17749) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.76614 (A-MSE: 0.66922) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.88332 (A-MSE: 0.78768) avg lploss: 0.00000
*** Best Val Loss: 0.71304 	 Best Test Loss: 0.80246 	 Best epoch 1335
EarlyStopping counter: 1 out of 50
train epoch 1341 avg loss: 0.19309 (A-MSE: 0.17196) avg lploss: 0.00000
train epoch 1342 avg loss: 0.20114 (A-MSE: 0.17766) avg lploss: 0.00000
train epoch 1343 avg loss: 0.21000 (A-MSE: 0.18566) avg lploss: 0.00000
train epoch 1344 avg loss: 0.21471 (A-MSE: 0.19193) avg lploss: 0.00000
train epoch 1345 avg loss: 0.21471 (A-MSE: 0.18915) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.77815 (A-MSE: 0.70542) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.93909 (A-MSE: 0.86718) avg lploss: 0.00000
*** Best Val Loss: 0.71304 	 Best Test Loss: 0.80246 	 Best epoch 1335
EarlyStopping counter: 2 out of 50
train epoch 1346 avg loss: 0.19680 (A-MSE: 0.17340) avg lploss: 0.00000
train epoch 1347 avg loss: 0.17022 (A-MSE: 0.15089) avg lploss: 0.00000
train epoch 1348 avg loss: 0.15696 (A-MSE: 0.14025) avg lploss: 0.00000
train epoch 1349 avg loss: 0.18371 (A-MSE: 0.16359) avg lploss: 0.00000
train epoch 1350 avg loss: 0.20734 (A-MSE: 0.18451) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.69473 (A-MSE: 0.61526) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.77659 (A-MSE: 0.70321) avg lploss: 0.00000
*** Best Val Loss: 0.69473 	 Best Test Loss: 0.77659 	 Best epoch 1350
Validation loss decreased (0.713035 --> 0.694731).  Saving model ...
train epoch 1351 avg loss: 0.18702 (A-MSE: 0.16840) avg lploss: 0.00000
train epoch 1352 avg loss: 0.18544 (A-MSE: 0.16433) avg lploss: 0.00000
train epoch 1353 avg loss: 0.17886 (A-MSE: 0.16000) avg lploss: 0.00000
train epoch 1354 avg loss: 0.16995 (A-MSE: 0.15117) avg lploss: 0.00000
train epoch 1355 avg loss: 0.17239 (A-MSE: 0.15219) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.64979 (A-MSE: 0.57189) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.76233 (A-MSE: 0.69033) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
Validation loss decreased (0.694731 --> 0.649786).  Saving model ...
train epoch 1356 avg loss: 0.15853 (A-MSE: 0.14083) avg lploss: 0.00000
train epoch 1357 avg loss: 0.15700 (A-MSE: 0.14054) avg lploss: 0.00000
train epoch 1358 avg loss: 0.16778 (A-MSE: 0.14946) avg lploss: 0.00000
train epoch 1359 avg loss: 0.18518 (A-MSE: 0.16491) avg lploss: 0.00000
train epoch 1360 avg loss: 0.18418 (A-MSE: 0.16316) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.69957 (A-MSE: 0.61722) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.83320 (A-MSE: 0.74617) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 1 out of 50
train epoch 1361 avg loss: 0.17656 (A-MSE: 0.15693) avg lploss: 0.00000
train epoch 1362 avg loss: 0.18656 (A-MSE: 0.16454) avg lploss: 0.00000
train epoch 1363 avg loss: 0.19489 (A-MSE: 0.17266) avg lploss: 0.00000
train epoch 1364 avg loss: 0.19670 (A-MSE: 0.17593) avg lploss: 0.00000
train epoch 1365 avg loss: 0.20404 (A-MSE: 0.18055) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.86900 (A-MSE: 0.77236) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.98353 (A-MSE: 0.89302) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 2 out of 50
train epoch 1366 avg loss: 0.20818 (A-MSE: 0.18409) avg lploss: 0.00000
train epoch 1367 avg loss: 0.20471 (A-MSE: 0.18123) avg lploss: 0.00000
train epoch 1368 avg loss: 0.20564 (A-MSE: 0.18079) avg lploss: 0.00000
train epoch 1369 avg loss: 0.20931 (A-MSE: 0.18504) avg lploss: 0.00000
train epoch 1370 avg loss: 0.19601 (A-MSE: 0.17476) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.82987 (A-MSE: 0.70754) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.93667 (A-MSE: 0.83658) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 3 out of 50
train epoch 1371 avg loss: 0.21843 (A-MSE: 0.19346) avg lploss: 0.00000
train epoch 1372 avg loss: 0.20759 (A-MSE: 0.18513) avg lploss: 0.00000
train epoch 1373 avg loss: 0.19184 (A-MSE: 0.17069) avg lploss: 0.00000
train epoch 1374 avg loss: 0.16712 (A-MSE: 0.14810) avg lploss: 0.00000
train epoch 1375 avg loss: 0.16430 (A-MSE: 0.14671) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.74145 (A-MSE: 0.65201) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.90669 (A-MSE: 0.81405) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 4 out of 50
train epoch 1376 avg loss: 0.17560 (A-MSE: 0.15521) avg lploss: 0.00000
train epoch 1377 avg loss: 0.17089 (A-MSE: 0.15145) avg lploss: 0.00000
train epoch 1378 avg loss: 0.16509 (A-MSE: 0.14713) avg lploss: 0.00000
train epoch 1379 avg loss: 0.14566 (A-MSE: 0.13034) avg lploss: 0.00000
train epoch 1380 avg loss: 0.15350 (A-MSE: 0.13552) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.69566 (A-MSE: 0.61599) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.81819 (A-MSE: 0.74076) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 5 out of 50
train epoch 1381 avg loss: 0.16080 (A-MSE: 0.14235) avg lploss: 0.00000
train epoch 1382 avg loss: 0.15568 (A-MSE: 0.13866) avg lploss: 0.00000
train epoch 1383 avg loss: 0.23054 (A-MSE: 0.20319) avg lploss: 0.00000
train epoch 1384 avg loss: 0.25587 (A-MSE: 0.22591) avg lploss: 0.00000
train epoch 1385 avg loss: 0.23023 (A-MSE: 0.20335) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.79438 (A-MSE: 0.69398) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.89772 (A-MSE: 0.80596) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 6 out of 50
train epoch 1386 avg loss: 0.19927 (A-MSE: 0.17687) avg lploss: 0.00000
train epoch 1387 avg loss: 0.21242 (A-MSE: 0.18717) avg lploss: 0.00000
train epoch 1388 avg loss: 0.23929 (A-MSE: 0.21250) avg lploss: 0.00000
train epoch 1389 avg loss: 0.18480 (A-MSE: 0.16362) avg lploss: 0.00000
train epoch 1390 avg loss: 0.18874 (A-MSE: 0.16725) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.80179 (A-MSE: 0.69822) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.88877 (A-MSE: 0.79640) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 7 out of 50
train epoch 1391 avg loss: 0.17069 (A-MSE: 0.15106) avg lploss: 0.00000
train epoch 1392 avg loss: 0.15785 (A-MSE: 0.14108) avg lploss: 0.00000
train epoch 1393 avg loss: 0.17985 (A-MSE: 0.15906) avg lploss: 0.00000
train epoch 1394 avg loss: 0.18536 (A-MSE: 0.16441) avg lploss: 0.00000
train epoch 1395 avg loss: 0.18475 (A-MSE: 0.16372) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.76222 (A-MSE: 0.67790) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.87820 (A-MSE: 0.79964) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 8 out of 50
train epoch 1396 avg loss: 0.16395 (A-MSE: 0.14601) avg lploss: 0.00000
train epoch 1397 avg loss: 0.17277 (A-MSE: 0.15370) avg lploss: 0.00000
train epoch 1398 avg loss: 0.14784 (A-MSE: 0.13204) avg lploss: 0.00000
train epoch 1399 avg loss: 0.16750 (A-MSE: 0.14774) avg lploss: 0.00000
train epoch 1400 avg loss: 0.17222 (A-MSE: 0.15360) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.72914 (A-MSE: 0.64298) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.85841 (A-MSE: 0.77633) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 9 out of 50
train epoch 1401 avg loss: 0.15257 (A-MSE: 0.13499) avg lploss: 0.00000
train epoch 1402 avg loss: 0.14706 (A-MSE: 0.13120) avg lploss: 0.00000
train epoch 1403 avg loss: 0.15473 (A-MSE: 0.13714) avg lploss: 0.00000
train epoch 1404 avg loss: 0.16091 (A-MSE: 0.14325) avg lploss: 0.00000
train epoch 1405 avg loss: 0.15413 (A-MSE: 0.13654) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.78996 (A-MSE: 0.68929) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.87872 (A-MSE: 0.78672) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 10 out of 50
train epoch 1406 avg loss: 0.15252 (A-MSE: 0.13503) avg lploss: 0.00000
train epoch 1407 avg loss: 0.13564 (A-MSE: 0.12143) avg lploss: 0.00000
train epoch 1408 avg loss: 0.13912 (A-MSE: 0.12385) avg lploss: 0.00000
train epoch 1409 avg loss: 0.14863 (A-MSE: 0.13203) avg lploss: 0.00000
train epoch 1410 avg loss: 0.14764 (A-MSE: 0.13139) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.65100 (A-MSE: 0.57896) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.78433 (A-MSE: 0.70893) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 11 out of 50
train epoch 1411 avg loss: 0.15929 (A-MSE: 0.14251) avg lploss: 0.00000
train epoch 1412 avg loss: 0.14366 (A-MSE: 0.12797) avg lploss: 0.00000
train epoch 1413 avg loss: 0.15728 (A-MSE: 0.14021) avg lploss: 0.00000
train epoch 1414 avg loss: 0.15806 (A-MSE: 0.13948) avg lploss: 0.00000
train epoch 1415 avg loss: 0.16758 (A-MSE: 0.14848) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.82013 (A-MSE: 0.71597) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.97740 (A-MSE: 0.87207) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 12 out of 50
train epoch 1416 avg loss: 0.18046 (A-MSE: 0.16022) avg lploss: 0.00000
train epoch 1417 avg loss: 0.21204 (A-MSE: 0.18912) avg lploss: 0.00000
train epoch 1418 avg loss: 0.19028 (A-MSE: 0.16770) avg lploss: 0.00000
train epoch 1419 avg loss: 0.17742 (A-MSE: 0.15733) avg lploss: 0.00000
train epoch 1420 avg loss: 0.18823 (A-MSE: 0.16414) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.73504 (A-MSE: 0.64381) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.87470 (A-MSE: 0.79066) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 13 out of 50
train epoch 1421 avg loss: 0.15336 (A-MSE: 0.13748) avg lploss: 0.00000
train epoch 1422 avg loss: 0.16530 (A-MSE: 0.14632) avg lploss: 0.00000
train epoch 1423 avg loss: 0.16580 (A-MSE: 0.14714) avg lploss: 0.00000
train epoch 1424 avg loss: 0.16048 (A-MSE: 0.14159) avg lploss: 0.00000
train epoch 1425 avg loss: 0.15161 (A-MSE: 0.13585) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.78857 (A-MSE: 0.70187) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.91674 (A-MSE: 0.83458) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 14 out of 50
train epoch 1426 avg loss: 0.15183 (A-MSE: 0.13516) avg lploss: 0.00000
train epoch 1427 avg loss: 0.17358 (A-MSE: 0.15419) avg lploss: 0.00000
train epoch 1428 avg loss: 0.20612 (A-MSE: 0.18236) avg lploss: 0.00000
train epoch 1429 avg loss: 0.18515 (A-MSE: 0.16283) avg lploss: 0.00000
train epoch 1430 avg loss: 0.20901 (A-MSE: 0.18554) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.75365 (A-MSE: 0.66199) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.86124 (A-MSE: 0.77436) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 15 out of 50
train epoch 1431 avg loss: 0.18344 (A-MSE: 0.16331) avg lploss: 0.00000
train epoch 1432 avg loss: 0.17000 (A-MSE: 0.14914) avg lploss: 0.00000
train epoch 1433 avg loss: 0.17470 (A-MSE: 0.15426) avg lploss: 0.00000
train epoch 1434 avg loss: 0.17882 (A-MSE: 0.15921) avg lploss: 0.00000
train epoch 1435 avg loss: 0.15777 (A-MSE: 0.14112) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.72596 (A-MSE: 0.64501) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.82062 (A-MSE: 0.74040) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 16 out of 50
train epoch 1436 avg loss: 0.15343 (A-MSE: 0.13468) avg lploss: 0.00000
train epoch 1437 avg loss: 0.19460 (A-MSE: 0.16996) avg lploss: 0.00000
train epoch 1438 avg loss: 0.20357 (A-MSE: 0.18127) avg lploss: 0.00000
train epoch 1439 avg loss: 0.17149 (A-MSE: 0.15435) avg lploss: 0.00000
train epoch 1440 avg loss: 0.18708 (A-MSE: 0.16638) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.65857 (A-MSE: 0.59113) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.80643 (A-MSE: 0.72869) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 17 out of 50
train epoch 1441 avg loss: 0.15826 (A-MSE: 0.13965) avg lploss: 0.00000
train epoch 1442 avg loss: 0.15525 (A-MSE: 0.13850) avg lploss: 0.00000
train epoch 1443 avg loss: 0.17300 (A-MSE: 0.15269) avg lploss: 0.00000
train epoch 1444 avg loss: 0.15789 (A-MSE: 0.13907) avg lploss: 0.00000
train epoch 1445 avg loss: 0.16761 (A-MSE: 0.14865) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.82124 (A-MSE: 0.73051) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.88840 (A-MSE: 0.80356) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 18 out of 50
train epoch 1446 avg loss: 0.15735 (A-MSE: 0.14042) avg lploss: 0.00000
train epoch 1447 avg loss: 0.19145 (A-MSE: 0.17204) avg lploss: 0.00000
train epoch 1448 avg loss: 0.19943 (A-MSE: 0.17329) avg lploss: 0.00000
train epoch 1449 avg loss: 0.19131 (A-MSE: 0.17079) avg lploss: 0.00000
train epoch 1450 avg loss: 0.15438 (A-MSE: 0.13860) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.73083 (A-MSE: 0.65072) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.85800 (A-MSE: 0.78477) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 19 out of 50
train epoch 1451 avg loss: 0.14299 (A-MSE: 0.12653) avg lploss: 0.00000
train epoch 1452 avg loss: 0.14849 (A-MSE: 0.13077) avg lploss: 0.00000
train epoch 1453 avg loss: 0.14236 (A-MSE: 0.12707) avg lploss: 0.00000
train epoch 1454 avg loss: 0.14606 (A-MSE: 0.13008) avg lploss: 0.00000
train epoch 1455 avg loss: 0.17950 (A-MSE: 0.15754) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.65085 (A-MSE: 0.57092) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.77504 (A-MSE: 0.69825) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 20 out of 50
train epoch 1456 avg loss: 0.21591 (A-MSE: 0.19038) avg lploss: 0.00000
train epoch 1457 avg loss: 0.19238 (A-MSE: 0.16904) avg lploss: 0.00000
train epoch 1458 avg loss: 0.22581 (A-MSE: 0.19940) avg lploss: 0.00000
train epoch 1459 avg loss: 0.19311 (A-MSE: 0.17032) avg lploss: 0.00000
train epoch 1460 avg loss: 0.17897 (A-MSE: 0.15827) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.74933 (A-MSE: 0.66282) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.89717 (A-MSE: 0.80463) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 21 out of 50
train epoch 1461 avg loss: 0.15214 (A-MSE: 0.13568) avg lploss: 0.00000
train epoch 1462 avg loss: 0.16360 (A-MSE: 0.14407) avg lploss: 0.00000
train epoch 1463 avg loss: 0.14237 (A-MSE: 0.12561) avg lploss: 0.00000
train epoch 1464 avg loss: 0.13976 (A-MSE: 0.12535) avg lploss: 0.00000
train epoch 1465 avg loss: 0.14377 (A-MSE: 0.12783) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.70685 (A-MSE: 0.60830) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.82154 (A-MSE: 0.73340) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 22 out of 50
train epoch 1466 avg loss: 0.13954 (A-MSE: 0.12388) avg lploss: 0.00000
train epoch 1467 avg loss: 0.13354 (A-MSE: 0.11906) avg lploss: 0.00000
train epoch 1468 avg loss: 0.14028 (A-MSE: 0.12423) avg lploss: 0.00000
train epoch 1469 avg loss: 0.16315 (A-MSE: 0.14534) avg lploss: 0.00000
train epoch 1470 avg loss: 0.18281 (A-MSE: 0.16046) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.76419 (A-MSE: 0.66021) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.91164 (A-MSE: 0.80718) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 23 out of 50
train epoch 1471 avg loss: 0.19785 (A-MSE: 0.17478) avg lploss: 0.00000
train epoch 1472 avg loss: 0.21762 (A-MSE: 0.19270) avg lploss: 0.00000
train epoch 1473 avg loss: 0.22708 (A-MSE: 0.19970) avg lploss: 0.00000
train epoch 1474 avg loss: 0.20391 (A-MSE: 0.18011) avg lploss: 0.00000
train epoch 1475 avg loss: 0.17666 (A-MSE: 0.15586) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.69111 (A-MSE: 0.60833) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.78925 (A-MSE: 0.71620) avg lploss: 0.00000
*** Best Val Loss: 0.64979 	 Best Test Loss: 0.76233 	 Best epoch 1355
EarlyStopping counter: 24 out of 50
train epoch 1476 avg loss: 0.14934 (A-MSE: 0.13182) avg lploss: 0.00000
train epoch 1477 avg loss: 0.15056 (A-MSE: 0.13440) avg lploss: 0.00000
train epoch 1478 avg loss: 0.16094 (A-MSE: 0.14184) avg lploss: 0.00000
train epoch 1479 avg loss: 0.13783 (A-MSE: 0.12295) avg lploss: 0.00000
train epoch 1480 avg loss: 0.13681 (A-MSE: 0.12140) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.64934 (A-MSE: 0.57800) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.76755 (A-MSE: 0.69262) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
Validation loss decreased (0.649786 --> 0.649343).  Saving model ...
train epoch 1481 avg loss: 0.15479 (A-MSE: 0.13741) avg lploss: 0.00000
train epoch 1482 avg loss: 0.16498 (A-MSE: 0.14578) avg lploss: 0.00000
train epoch 1483 avg loss: 0.16575 (A-MSE: 0.14765) avg lploss: 0.00000
train epoch 1484 avg loss: 0.18274 (A-MSE: 0.16307) avg lploss: 0.00000
train epoch 1485 avg loss: 0.19188 (A-MSE: 0.16984) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.66204 (A-MSE: 0.58156) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.77270 (A-MSE: 0.69479) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 1 out of 50
train epoch 1486 avg loss: 0.17396 (A-MSE: 0.15414) avg lploss: 0.00000
train epoch 1487 avg loss: 0.16854 (A-MSE: 0.14926) avg lploss: 0.00000
train epoch 1488 avg loss: 0.15583 (A-MSE: 0.13811) avg lploss: 0.00000
train epoch 1489 avg loss: 0.13965 (A-MSE: 0.12375) avg lploss: 0.00000
train epoch 1490 avg loss: 0.13399 (A-MSE: 0.11880) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.68608 (A-MSE: 0.60778) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.79835 (A-MSE: 0.72504) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 2 out of 50
train epoch 1491 avg loss: 0.13754 (A-MSE: 0.12247) avg lploss: 0.00000
train epoch 1492 avg loss: 0.14415 (A-MSE: 0.12758) avg lploss: 0.00000
train epoch 1493 avg loss: 0.15107 (A-MSE: 0.13466) avg lploss: 0.00000
train epoch 1494 avg loss: 0.15859 (A-MSE: 0.14100) avg lploss: 0.00000
train epoch 1495 avg loss: 0.15146 (A-MSE: 0.13325) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.68875 (A-MSE: 0.60663) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.80560 (A-MSE: 0.72284) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 3 out of 50
train epoch 1496 avg loss: 0.17831 (A-MSE: 0.15661) avg lploss: 0.00000
train epoch 1497 avg loss: 0.19436 (A-MSE: 0.17074) avg lploss: 0.00000
train epoch 1498 avg loss: 0.19054 (A-MSE: 0.16978) avg lploss: 0.00000
train epoch 1499 avg loss: 0.17622 (A-MSE: 0.15617) avg lploss: 0.00000
train epoch 1500 avg loss: 0.17713 (A-MSE: 0.15636) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.75341 (A-MSE: 0.66285) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.88432 (A-MSE: 0.79928) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 4 out of 50
train epoch 1501 avg loss: 0.14992 (A-MSE: 0.13234) avg lploss: 0.00000
train epoch 1502 avg loss: 0.14893 (A-MSE: 0.13364) avg lploss: 0.00000
train epoch 1503 avg loss: 0.15808 (A-MSE: 0.14014) avg lploss: 0.00000
train epoch 1504 avg loss: 0.17021 (A-MSE: 0.15105) avg lploss: 0.00000
train epoch 1505 avg loss: 0.16252 (A-MSE: 0.14442) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.75873 (A-MSE: 0.66601) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.81499 (A-MSE: 0.73894) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 5 out of 50
train epoch 1506 avg loss: 0.14186 (A-MSE: 0.12603) avg lploss: 0.00000
train epoch 1507 avg loss: 0.14275 (A-MSE: 0.12759) avg lploss: 0.00000
train epoch 1508 avg loss: 0.13456 (A-MSE: 0.11974) avg lploss: 0.00000
train epoch 1509 avg loss: 0.13366 (A-MSE: 0.11836) avg lploss: 0.00000
train epoch 1510 avg loss: 0.12174 (A-MSE: 0.10900) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.65115 (A-MSE: 0.57655) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.74563 (A-MSE: 0.67607) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 6 out of 50
train epoch 1511 avg loss: 0.12320 (A-MSE: 0.11029) avg lploss: 0.00000
train epoch 1512 avg loss: 0.13154 (A-MSE: 0.11623) avg lploss: 0.00000
train epoch 1513 avg loss: 0.13363 (A-MSE: 0.11822) avg lploss: 0.00000
train epoch 1514 avg loss: 0.13290 (A-MSE: 0.11803) avg lploss: 0.00000
train epoch 1515 avg loss: 0.15719 (A-MSE: 0.14006) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.73525 (A-MSE: 0.64945) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.87736 (A-MSE: 0.78734) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 7 out of 50
train epoch 1516 avg loss: 0.16120 (A-MSE: 0.14487) avg lploss: 0.00000
train epoch 1517 avg loss: 0.16640 (A-MSE: 0.14795) avg lploss: 0.00000
train epoch 1518 avg loss: 0.15877 (A-MSE: 0.13979) avg lploss: 0.00000
train epoch 1519 avg loss: 0.13283 (A-MSE: 0.11746) avg lploss: 0.00000
train epoch 1520 avg loss: 0.14728 (A-MSE: 0.13042) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.72025 (A-MSE: 0.63832) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.85202 (A-MSE: 0.77158) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 8 out of 50
train epoch 1521 avg loss: 0.18380 (A-MSE: 0.16281) avg lploss: 0.00000
train epoch 1522 avg loss: 0.14784 (A-MSE: 0.13090) avg lploss: 0.00000
train epoch 1523 avg loss: 0.13101 (A-MSE: 0.11604) avg lploss: 0.00000
train epoch 1524 avg loss: 0.11924 (A-MSE: 0.10611) avg lploss: 0.00000
train epoch 1525 avg loss: 0.12862 (A-MSE: 0.11497) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.77011 (A-MSE: 0.67573) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.87362 (A-MSE: 0.78376) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 9 out of 50
train epoch 1526 avg loss: 0.13133 (A-MSE: 0.11585) avg lploss: 0.00000
train epoch 1527 avg loss: 0.15165 (A-MSE: 0.13421) avg lploss: 0.00000
train epoch 1528 avg loss: 0.14862 (A-MSE: 0.12967) avg lploss: 0.00000
train epoch 1529 avg loss: 0.14517 (A-MSE: 0.12880) avg lploss: 0.00000
train epoch 1530 avg loss: 0.14300 (A-MSE: 0.12736) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.85297 (A-MSE: 0.75342) avg lploss: 0.00000
==> test epoch 1530 avg loss: 1.00271 (A-MSE: 0.90607) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 10 out of 50
train epoch 1531 avg loss: 0.15117 (A-MSE: 0.13401) avg lploss: 0.00000
train epoch 1532 avg loss: 0.14581 (A-MSE: 0.13094) avg lploss: 0.00000
train epoch 1533 avg loss: 0.13183 (A-MSE: 0.11825) avg lploss: 0.00000
train epoch 1534 avg loss: 0.14989 (A-MSE: 0.13336) avg lploss: 0.00000
train epoch 1535 avg loss: 0.14956 (A-MSE: 0.13241) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.77513 (A-MSE: 0.68933) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.89702 (A-MSE: 0.81432) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 11 out of 50
train epoch 1536 avg loss: 0.14470 (A-MSE: 0.12663) avg lploss: 0.00000
train epoch 1537 avg loss: 0.15752 (A-MSE: 0.13959) avg lploss: 0.00000
train epoch 1538 avg loss: 0.15539 (A-MSE: 0.13718) avg lploss: 0.00000
train epoch 1539 avg loss: 0.16804 (A-MSE: 0.14894) avg lploss: 0.00000
train epoch 1540 avg loss: 0.14585 (A-MSE: 0.12997) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.77042 (A-MSE: 0.68679) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.87562 (A-MSE: 0.79765) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 12 out of 50
train epoch 1541 avg loss: 0.16487 (A-MSE: 0.14533) avg lploss: 0.00000
train epoch 1542 avg loss: 0.15505 (A-MSE: 0.13670) avg lploss: 0.00000
train epoch 1543 avg loss: 0.17347 (A-MSE: 0.15201) avg lploss: 0.00000
train epoch 1544 avg loss: 0.32901 (A-MSE: 0.28566) avg lploss: 0.00000
train epoch 1545 avg loss: 0.30456 (A-MSE: 0.26716) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.74717 (A-MSE: 0.66222) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.87055 (A-MSE: 0.78644) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 13 out of 50
train epoch 1546 avg loss: 0.23923 (A-MSE: 0.21334) avg lploss: 0.00000
train epoch 1547 avg loss: 0.21778 (A-MSE: 0.19263) avg lploss: 0.00000
train epoch 1548 avg loss: 0.18622 (A-MSE: 0.16450) avg lploss: 0.00000
train epoch 1549 avg loss: 0.16437 (A-MSE: 0.14686) avg lploss: 0.00000
train epoch 1550 avg loss: 0.15916 (A-MSE: 0.14188) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.77041 (A-MSE: 0.68752) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.90138 (A-MSE: 0.82143) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 14 out of 50
train epoch 1551 avg loss: 0.13989 (A-MSE: 0.12504) avg lploss: 0.00000
train epoch 1552 avg loss: 0.14172 (A-MSE: 0.12485) avg lploss: 0.00000
train epoch 1553 avg loss: 0.12774 (A-MSE: 0.11381) avg lploss: 0.00000
train epoch 1554 avg loss: 0.12313 (A-MSE: 0.10970) avg lploss: 0.00000
train epoch 1555 avg loss: 0.12844 (A-MSE: 0.11545) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.67050 (A-MSE: 0.60220) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.79538 (A-MSE: 0.73692) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 15 out of 50
train epoch 1556 avg loss: 0.13560 (A-MSE: 0.12110) avg lploss: 0.00000
train epoch 1557 avg loss: 0.12974 (A-MSE: 0.11502) avg lploss: 0.00000
train epoch 1558 avg loss: 0.13290 (A-MSE: 0.11775) avg lploss: 0.00000
train epoch 1559 avg loss: 0.12778 (A-MSE: 0.11370) avg lploss: 0.00000
train epoch 1560 avg loss: 0.13129 (A-MSE: 0.11714) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.68855 (A-MSE: 0.61071) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.78716 (A-MSE: 0.72179) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 16 out of 50
train epoch 1561 avg loss: 0.13939 (A-MSE: 0.12355) avg lploss: 0.00000
train epoch 1562 avg loss: 0.14935 (A-MSE: 0.13091) avg lploss: 0.00000
train epoch 1563 avg loss: 0.13655 (A-MSE: 0.12191) avg lploss: 0.00000
train epoch 1564 avg loss: 0.11641 (A-MSE: 0.10381) avg lploss: 0.00000
train epoch 1565 avg loss: 0.12330 (A-MSE: 0.11089) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.65141 (A-MSE: 0.58275) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.73153 (A-MSE: 0.67085) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 17 out of 50
train epoch 1566 avg loss: 0.13215 (A-MSE: 0.11945) avg lploss: 0.00000
train epoch 1567 avg loss: 0.14308 (A-MSE: 0.12726) avg lploss: 0.00000
train epoch 1568 avg loss: 0.18579 (A-MSE: 0.16404) avg lploss: 0.00000
train epoch 1569 avg loss: 0.17559 (A-MSE: 0.15606) avg lploss: 0.00000
train epoch 1570 avg loss: 0.16318 (A-MSE: 0.14620) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.72547 (A-MSE: 0.63955) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.78684 (A-MSE: 0.72085) avg lploss: 0.00000
*** Best Val Loss: 0.64934 	 Best Test Loss: 0.76755 	 Best epoch 1480
EarlyStopping counter: 18 out of 50
train epoch 1571 avg loss: 0.18644 (A-MSE: 0.16672) avg lploss: 0.00000
train epoch 1572 avg loss: 0.18734 (A-MSE: 0.16644) avg lploss: 0.00000
train epoch 1573 avg loss: 0.14599 (A-MSE: 0.13161) avg lploss: 0.00000
train epoch 1574 avg loss: 0.12538 (A-MSE: 0.11128) avg lploss: 0.00000
train epoch 1575 avg loss: 0.11397 (A-MSE: 0.10208) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.63327 (A-MSE: 0.54958) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.74511 (A-MSE: 0.66734) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
Validation loss decreased (0.649343 --> 0.633275).  Saving model ...
train epoch 1576 avg loss: 0.12641 (A-MSE: 0.11233) avg lploss: 0.00000
train epoch 1577 avg loss: 0.13995 (A-MSE: 0.12444) avg lploss: 0.00000
train epoch 1578 avg loss: 0.12160 (A-MSE: 0.10788) avg lploss: 0.00000
train epoch 1579 avg loss: 0.11114 (A-MSE: 0.09844) avg lploss: 0.00000
train epoch 1580 avg loss: 0.10952 (A-MSE: 0.09778) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.69833 (A-MSE: 0.61046) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.83591 (A-MSE: 0.74832) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
EarlyStopping counter: 1 out of 50
train epoch 1581 avg loss: 0.12645 (A-MSE: 0.11139) avg lploss: 0.00000
train epoch 1582 avg loss: 0.12383 (A-MSE: 0.11107) avg lploss: 0.00000
train epoch 1583 avg loss: 0.12223 (A-MSE: 0.10836) avg lploss: 0.00000
train epoch 1584 avg loss: 0.13573 (A-MSE: 0.12071) avg lploss: 0.00000
train epoch 1585 avg loss: 0.16098 (A-MSE: 0.14301) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.65390 (A-MSE: 0.58845) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.78078 (A-MSE: 0.71325) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
EarlyStopping counter: 2 out of 50
train epoch 1586 avg loss: 0.13595 (A-MSE: 0.11997) avg lploss: 0.00000
train epoch 1587 avg loss: 0.14043 (A-MSE: 0.12462) avg lploss: 0.00000
train epoch 1588 avg loss: 0.12524 (A-MSE: 0.11116) avg lploss: 0.00000
train epoch 1589 avg loss: 0.13675 (A-MSE: 0.12170) avg lploss: 0.00000
train epoch 1590 avg loss: 0.12318 (A-MSE: 0.10931) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.69480 (A-MSE: 0.59770) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.75176 (A-MSE: 0.66795) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
EarlyStopping counter: 3 out of 50
train epoch 1591 avg loss: 0.13772 (A-MSE: 0.12186) avg lploss: 0.00000
train epoch 1592 avg loss: 0.12460 (A-MSE: 0.11032) avg lploss: 0.00000
train epoch 1593 avg loss: 0.12614 (A-MSE: 0.11248) avg lploss: 0.00000
train epoch 1594 avg loss: 0.12126 (A-MSE: 0.10807) avg lploss: 0.00000
train epoch 1595 avg loss: 0.13963 (A-MSE: 0.12459) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.71619 (A-MSE: 0.63106) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.82538 (A-MSE: 0.74858) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
EarlyStopping counter: 4 out of 50
train epoch 1596 avg loss: 0.16063 (A-MSE: 0.14211) avg lploss: 0.00000
train epoch 1597 avg loss: 0.14325 (A-MSE: 0.12708) avg lploss: 0.00000
train epoch 1598 avg loss: 0.14749 (A-MSE: 0.13247) avg lploss: 0.00000
train epoch 1599 avg loss: 0.12490 (A-MSE: 0.11145) avg lploss: 0.00000
train epoch 1600 avg loss: 0.13779 (A-MSE: 0.12194) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.69622 (A-MSE: 0.61271) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.83228 (A-MSE: 0.75730) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
EarlyStopping counter: 5 out of 50
train epoch 1601 avg loss: 0.13822 (A-MSE: 0.12230) avg lploss: 0.00000
train epoch 1602 avg loss: 0.14747 (A-MSE: 0.13033) avg lploss: 0.00000
train epoch 1603 avg loss: 0.14469 (A-MSE: 0.12704) avg lploss: 0.00000
train epoch 1604 avg loss: 0.16496 (A-MSE: 0.14599) avg lploss: 0.00000
train epoch 1605 avg loss: 0.16394 (A-MSE: 0.14528) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.85811 (A-MSE: 0.76856) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.95276 (A-MSE: 0.86966) avg lploss: 0.00000
*** Best Val Loss: 0.63327 	 Best Test Loss: 0.74511 	 Best epoch 1575
EarlyStopping counter: 6 out of 50
train epoch 1606 avg loss: 0.14575 (A-MSE: 0.12908) avg lploss: 0.00000
train epoch 1607 avg loss: 0.12328 (A-MSE: 0.11040) avg lploss: 0.00000
train epoch 1608 avg loss: 0.12159 (A-MSE: 0.10882) avg lploss: 0.00000
train epoch 1609 avg loss: 0.13528 (A-MSE: 0.12123) avg lploss: 0.00000
train epoch 1610 avg loss: 0.11959 (A-MSE: 0.10627) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.61145 (A-MSE: 0.53912) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.75529 (A-MSE: 0.68559) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
Validation loss decreased (0.633275 --> 0.611447).  Saving model ...
train epoch 1611 avg loss: 0.13145 (A-MSE: 0.11682) avg lploss: 0.00000
train epoch 1612 avg loss: 0.13112 (A-MSE: 0.11536) avg lploss: 0.00000
train epoch 1613 avg loss: 0.13659 (A-MSE: 0.12206) avg lploss: 0.00000
train epoch 1614 avg loss: 0.13702 (A-MSE: 0.12267) avg lploss: 0.00000
train epoch 1615 avg loss: 0.14086 (A-MSE: 0.12586) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.69790 (A-MSE: 0.61980) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.79993 (A-MSE: 0.73644) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 1 out of 50
train epoch 1616 avg loss: 0.14211 (A-MSE: 0.12711) avg lploss: 0.00000
train epoch 1617 avg loss: 0.17718 (A-MSE: 0.15838) avg lploss: 0.00000
train epoch 1618 avg loss: 0.14504 (A-MSE: 0.12909) avg lploss: 0.00000
train epoch 1619 avg loss: 0.12853 (A-MSE: 0.11350) avg lploss: 0.00000
train epoch 1620 avg loss: 0.12094 (A-MSE: 0.10785) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.70013 (A-MSE: 0.61908) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.84299 (A-MSE: 0.76653) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 2 out of 50
train epoch 1621 avg loss: 0.15534 (A-MSE: 0.13858) avg lploss: 0.00000
train epoch 1622 avg loss: 0.14849 (A-MSE: 0.13175) avg lploss: 0.00000
train epoch 1623 avg loss: 0.12110 (A-MSE: 0.10737) avg lploss: 0.00000
train epoch 1624 avg loss: 0.13927 (A-MSE: 0.12324) avg lploss: 0.00000
train epoch 1625 avg loss: 0.12929 (A-MSE: 0.11510) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.62381 (A-MSE: 0.54685) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.76916 (A-MSE: 0.69342) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 3 out of 50
train epoch 1626 avg loss: 0.13040 (A-MSE: 0.11620) avg lploss: 0.00000
train epoch 1627 avg loss: 0.13583 (A-MSE: 0.12047) avg lploss: 0.00000
train epoch 1628 avg loss: 0.15598 (A-MSE: 0.13792) avg lploss: 0.00000
train epoch 1629 avg loss: 0.13219 (A-MSE: 0.11744) avg lploss: 0.00000
train epoch 1630 avg loss: 0.12907 (A-MSE: 0.11393) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.68316 (A-MSE: 0.59520) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.80046 (A-MSE: 0.71448) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 4 out of 50
train epoch 1631 avg loss: 0.12558 (A-MSE: 0.11086) avg lploss: 0.00000
train epoch 1632 avg loss: 0.13161 (A-MSE: 0.11650) avg lploss: 0.00000
train epoch 1633 avg loss: 0.11332 (A-MSE: 0.10128) avg lploss: 0.00000
train epoch 1634 avg loss: 0.11321 (A-MSE: 0.10047) avg lploss: 0.00000
train epoch 1635 avg loss: 0.12702 (A-MSE: 0.11360) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.75604 (A-MSE: 0.66169) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.84276 (A-MSE: 0.75969) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 5 out of 50
train epoch 1636 avg loss: 0.12591 (A-MSE: 0.11148) avg lploss: 0.00000
train epoch 1637 avg loss: 0.10880 (A-MSE: 0.09679) avg lploss: 0.00000
train epoch 1638 avg loss: 0.11739 (A-MSE: 0.10529) avg lploss: 0.00000
train epoch 1639 avg loss: 0.11090 (A-MSE: 0.09814) avg lploss: 0.00000
train epoch 1640 avg loss: 0.11682 (A-MSE: 0.10404) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.69389 (A-MSE: 0.61193) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.80057 (A-MSE: 0.73020) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 6 out of 50
train epoch 1641 avg loss: 0.12187 (A-MSE: 0.10912) avg lploss: 0.00000
train epoch 1642 avg loss: 0.11998 (A-MSE: 0.10652) avg lploss: 0.00000
train epoch 1643 avg loss: 0.15283 (A-MSE: 0.13576) avg lploss: 0.00000
train epoch 1644 avg loss: 0.14682 (A-MSE: 0.13162) avg lploss: 0.00000
train epoch 1645 avg loss: 0.15378 (A-MSE: 0.13675) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.61238 (A-MSE: 0.54402) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.75115 (A-MSE: 0.68124) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 7 out of 50
train epoch 1646 avg loss: 0.15647 (A-MSE: 0.14021) avg lploss: 0.00000
train epoch 1647 avg loss: 0.20108 (A-MSE: 0.17484) avg lploss: 0.00000
train epoch 1648 avg loss: 0.16609 (A-MSE: 0.14900) avg lploss: 0.00000
train epoch 1649 avg loss: 0.15864 (A-MSE: 0.14004) avg lploss: 0.00000
train epoch 1650 avg loss: 0.17373 (A-MSE: 0.15448) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.66421 (A-MSE: 0.58421) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.77878 (A-MSE: 0.70465) avg lploss: 0.00000
*** Best Val Loss: 0.61145 	 Best Test Loss: 0.75529 	 Best epoch 1610
EarlyStopping counter: 8 out of 50
train epoch 1651 avg loss: 0.15487 (A-MSE: 0.13823) avg lploss: 0.00000
train epoch 1652 avg loss: 0.20772 (A-MSE: 0.18296) avg lploss: 0.00000
train epoch 1653 avg loss: 0.18893 (A-MSE: 0.16508) avg lploss: 0.00000
train epoch 1654 avg loss: 0.14781 (A-MSE: 0.13022) avg lploss: 0.00000
train epoch 1655 avg loss: 0.12586 (A-MSE: 0.11225) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.60527 (A-MSE: 0.52297) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.74084 (A-MSE: 0.65967) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
Validation loss decreased (0.611447 --> 0.605269).  Saving model ...
train epoch 1656 avg loss: 0.12713 (A-MSE: 0.11239) avg lploss: 0.00000
train epoch 1657 avg loss: 0.13171 (A-MSE: 0.11645) avg lploss: 0.00000
train epoch 1658 avg loss: 0.13051 (A-MSE: 0.11700) avg lploss: 0.00000
train epoch 1659 avg loss: 0.15880 (A-MSE: 0.13926) avg lploss: 0.00000
train epoch 1660 avg loss: 0.16111 (A-MSE: 0.14211) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.71262 (A-MSE: 0.64976) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.86243 (A-MSE: 0.80578) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 1 out of 50
train epoch 1661 avg loss: 0.14030 (A-MSE: 0.12505) avg lploss: 0.00000
train epoch 1662 avg loss: 0.12325 (A-MSE: 0.10889) avg lploss: 0.00000
train epoch 1663 avg loss: 0.12896 (A-MSE: 0.11404) avg lploss: 0.00000
train epoch 1664 avg loss: 0.11794 (A-MSE: 0.10551) avg lploss: 0.00000
train epoch 1665 avg loss: 0.12373 (A-MSE: 0.11020) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.63377 (A-MSE: 0.54591) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.76267 (A-MSE: 0.68208) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 2 out of 50
train epoch 1666 avg loss: 0.10936 (A-MSE: 0.09716) avg lploss: 0.00000
train epoch 1667 avg loss: 0.12683 (A-MSE: 0.11374) avg lploss: 0.00000
train epoch 1668 avg loss: 0.12546 (A-MSE: 0.11130) avg lploss: 0.00000
train epoch 1669 avg loss: 0.13248 (A-MSE: 0.11763) avg lploss: 0.00000
train epoch 1670 avg loss: 0.13250 (A-MSE: 0.11717) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.66698 (A-MSE: 0.60051) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.79416 (A-MSE: 0.73107) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 3 out of 50
train epoch 1671 avg loss: 0.14266 (A-MSE: 0.12620) avg lploss: 0.00000
train epoch 1672 avg loss: 0.12608 (A-MSE: 0.11221) avg lploss: 0.00000
train epoch 1673 avg loss: 0.11357 (A-MSE: 0.10068) avg lploss: 0.00000
train epoch 1674 avg loss: 0.09812 (A-MSE: 0.08745) avg lploss: 0.00000
train epoch 1675 avg loss: 0.10632 (A-MSE: 0.09436) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.61367 (A-MSE: 0.53904) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.73886 (A-MSE: 0.66770) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 4 out of 50
train epoch 1676 avg loss: 0.09553 (A-MSE: 0.08508) avg lploss: 0.00000
train epoch 1677 avg loss: 0.12397 (A-MSE: 0.11162) avg lploss: 0.00000
train epoch 1678 avg loss: 0.14426 (A-MSE: 0.12686) avg lploss: 0.00000
train epoch 1679 avg loss: 0.16592 (A-MSE: 0.14515) avg lploss: 0.00000
train epoch 1680 avg loss: 0.14025 (A-MSE: 0.12372) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.61357 (A-MSE: 0.54149) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.74351 (A-MSE: 0.67093) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 5 out of 50
train epoch 1681 avg loss: 0.12486 (A-MSE: 0.10999) avg lploss: 0.00000
train epoch 1682 avg loss: 0.11595 (A-MSE: 0.10448) avg lploss: 0.00000
train epoch 1683 avg loss: 0.11368 (A-MSE: 0.10050) avg lploss: 0.00000
train epoch 1684 avg loss: 0.12296 (A-MSE: 0.10910) avg lploss: 0.00000
train epoch 1685 avg loss: 0.12203 (A-MSE: 0.10940) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.61142 (A-MSE: 0.53189) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.70323 (A-MSE: 0.62826) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 6 out of 50
train epoch 1686 avg loss: 0.11990 (A-MSE: 0.10752) avg lploss: 0.00000
train epoch 1687 avg loss: 0.10554 (A-MSE: 0.09404) avg lploss: 0.00000
train epoch 1688 avg loss: 0.11294 (A-MSE: 0.10049) avg lploss: 0.00000
train epoch 1689 avg loss: 0.10407 (A-MSE: 0.09290) avg lploss: 0.00000
train epoch 1690 avg loss: 0.09997 (A-MSE: 0.08805) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.73094 (A-MSE: 0.63881) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.85885 (A-MSE: 0.76973) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 7 out of 50
train epoch 1691 avg loss: 0.11652 (A-MSE: 0.10341) avg lploss: 0.00000
train epoch 1692 avg loss: 0.10502 (A-MSE: 0.09322) avg lploss: 0.00000
train epoch 1693 avg loss: 0.10396 (A-MSE: 0.09313) avg lploss: 0.00000
train epoch 1694 avg loss: 0.12538 (A-MSE: 0.11233) avg lploss: 0.00000
train epoch 1695 avg loss: 0.11455 (A-MSE: 0.10202) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.67575 (A-MSE: 0.60359) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.79689 (A-MSE: 0.72829) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 8 out of 50
train epoch 1696 avg loss: 0.11915 (A-MSE: 0.10633) avg lploss: 0.00000
train epoch 1697 avg loss: 0.13363 (A-MSE: 0.11818) avg lploss: 0.00000
train epoch 1698 avg loss: 0.17750 (A-MSE: 0.15682) avg lploss: 0.00000
train epoch 1699 avg loss: 0.17447 (A-MSE: 0.15174) avg lploss: 0.00000
train epoch 1700 avg loss: 0.13972 (A-MSE: 0.12475) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.63671 (A-MSE: 0.56596) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.78547 (A-MSE: 0.70867) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 9 out of 50
train epoch 1701 avg loss: 0.11935 (A-MSE: 0.10729) avg lploss: 0.00000
train epoch 1702 avg loss: 0.10624 (A-MSE: 0.09492) avg lploss: 0.00000
train epoch 1703 avg loss: 0.09298 (A-MSE: 0.08265) avg lploss: 0.00000
train epoch 1704 avg loss: 0.09102 (A-MSE: 0.08129) avg lploss: 0.00000
train epoch 1705 avg loss: 0.09667 (A-MSE: 0.08712) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.66349 (A-MSE: 0.58504) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.79863 (A-MSE: 0.72377) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 10 out of 50
train epoch 1706 avg loss: 0.11097 (A-MSE: 0.09898) avg lploss: 0.00000
train epoch 1707 avg loss: 0.12530 (A-MSE: 0.10995) avg lploss: 0.00000
train epoch 1708 avg loss: 0.13286 (A-MSE: 0.11829) avg lploss: 0.00000
train epoch 1709 avg loss: 0.13811 (A-MSE: 0.12271) avg lploss: 0.00000
train epoch 1710 avg loss: 0.15401 (A-MSE: 0.13535) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.73508 (A-MSE: 0.64834) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.91262 (A-MSE: 0.81470) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 11 out of 50
train epoch 1711 avg loss: 0.17665 (A-MSE: 0.15706) avg lploss: 0.00000
train epoch 1712 avg loss: 0.14594 (A-MSE: 0.13005) avg lploss: 0.00000
train epoch 1713 avg loss: 0.12720 (A-MSE: 0.11212) avg lploss: 0.00000
train epoch 1714 avg loss: 0.12870 (A-MSE: 0.11514) avg lploss: 0.00000
train epoch 1715 avg loss: 0.11187 (A-MSE: 0.09994) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.67723 (A-MSE: 0.60004) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.82502 (A-MSE: 0.74989) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 12 out of 50
train epoch 1716 avg loss: 0.10418 (A-MSE: 0.09325) avg lploss: 0.00000
train epoch 1717 avg loss: 0.10365 (A-MSE: 0.09372) avg lploss: 0.00000
train epoch 1718 avg loss: 0.12248 (A-MSE: 0.10881) avg lploss: 0.00000
train epoch 1719 avg loss: 0.11607 (A-MSE: 0.10349) avg lploss: 0.00000
train epoch 1720 avg loss: 0.11732 (A-MSE: 0.10339) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.61477 (A-MSE: 0.54689) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.72311 (A-MSE: 0.65578) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 13 out of 50
train epoch 1721 avg loss: 0.12870 (A-MSE: 0.11441) avg lploss: 0.00000
train epoch 1722 avg loss: 0.10525 (A-MSE: 0.09387) avg lploss: 0.00000
train epoch 1723 avg loss: 0.09478 (A-MSE: 0.08426) avg lploss: 0.00000
train epoch 1724 avg loss: 0.10268 (A-MSE: 0.09107) avg lploss: 0.00000
train epoch 1725 avg loss: 0.11928 (A-MSE: 0.10650) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.65390 (A-MSE: 0.56897) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.73235 (A-MSE: 0.65269) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 14 out of 50
train epoch 1726 avg loss: 0.15803 (A-MSE: 0.13889) avg lploss: 0.00000
train epoch 1727 avg loss: 0.18339 (A-MSE: 0.16234) avg lploss: 0.00000
train epoch 1728 avg loss: 0.17174 (A-MSE: 0.15147) avg lploss: 0.00000
train epoch 1729 avg loss: 0.15198 (A-MSE: 0.13465) avg lploss: 0.00000
train epoch 1730 avg loss: 0.11270 (A-MSE: 0.10038) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.62460 (A-MSE: 0.55354) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.76442 (A-MSE: 0.69659) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 15 out of 50
train epoch 1731 avg loss: 0.10546 (A-MSE: 0.09340) avg lploss: 0.00000
train epoch 1732 avg loss: 0.11117 (A-MSE: 0.09879) avg lploss: 0.00000
train epoch 1733 avg loss: 0.09729 (A-MSE: 0.08721) avg lploss: 0.00000
train epoch 1734 avg loss: 0.09624 (A-MSE: 0.08691) avg lploss: 0.00000
train epoch 1735 avg loss: 0.10188 (A-MSE: 0.09158) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.62034 (A-MSE: 0.54750) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.73540 (A-MSE: 0.66942) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 16 out of 50
train epoch 1736 avg loss: 0.12776 (A-MSE: 0.11337) avg lploss: 0.00000
train epoch 1737 avg loss: 0.11468 (A-MSE: 0.10256) avg lploss: 0.00000
train epoch 1738 avg loss: 0.10779 (A-MSE: 0.09626) avg lploss: 0.00000
train epoch 1739 avg loss: 0.10314 (A-MSE: 0.09229) avg lploss: 0.00000
train epoch 1740 avg loss: 0.11228 (A-MSE: 0.10029) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.62618 (A-MSE: 0.56463) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.74554 (A-MSE: 0.68247) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 17 out of 50
train epoch 1741 avg loss: 0.10647 (A-MSE: 0.09554) avg lploss: 0.00000
train epoch 1742 avg loss: 0.10949 (A-MSE: 0.09743) avg lploss: 0.00000
train epoch 1743 avg loss: 0.10336 (A-MSE: 0.09166) avg lploss: 0.00000
train epoch 1744 avg loss: 0.11954 (A-MSE: 0.10660) avg lploss: 0.00000
train epoch 1745 avg loss: 0.13168 (A-MSE: 0.11731) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.61372 (A-MSE: 0.55394) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.78012 (A-MSE: 0.71516) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 18 out of 50
train epoch 1746 avg loss: 0.11786 (A-MSE: 0.10563) avg lploss: 0.00000
train epoch 1747 avg loss: 0.11181 (A-MSE: 0.09896) avg lploss: 0.00000
train epoch 1748 avg loss: 0.12053 (A-MSE: 0.10701) avg lploss: 0.00000
train epoch 1749 avg loss: 0.12124 (A-MSE: 0.10777) avg lploss: 0.00000
train epoch 1750 avg loss: 0.11845 (A-MSE: 0.10450) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.69582 (A-MSE: 0.61388) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.82221 (A-MSE: 0.74452) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 19 out of 50
train epoch 1751 avg loss: 0.11160 (A-MSE: 0.09923) avg lploss: 0.00000
train epoch 1752 avg loss: 0.10728 (A-MSE: 0.09653) avg lploss: 0.00000
train epoch 1753 avg loss: 0.10151 (A-MSE: 0.09048) avg lploss: 0.00000
train epoch 1754 avg loss: 0.10924 (A-MSE: 0.09726) avg lploss: 0.00000
train epoch 1755 avg loss: 0.11654 (A-MSE: 0.10399) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.66037 (A-MSE: 0.58900) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.81444 (A-MSE: 0.73223) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 20 out of 50
train epoch 1756 avg loss: 0.13026 (A-MSE: 0.11574) avg lploss: 0.00000
train epoch 1757 avg loss: 0.11822 (A-MSE: 0.10458) avg lploss: 0.00000
train epoch 1758 avg loss: 0.10373 (A-MSE: 0.09209) avg lploss: 0.00000
train epoch 1759 avg loss: 0.10835 (A-MSE: 0.09577) avg lploss: 0.00000
train epoch 1760 avg loss: 0.09954 (A-MSE: 0.08911) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.63811 (A-MSE: 0.56303) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.75978 (A-MSE: 0.68607) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 21 out of 50
train epoch 1761 avg loss: 0.09348 (A-MSE: 0.08362) avg lploss: 0.00000
train epoch 1762 avg loss: 0.10563 (A-MSE: 0.09406) avg lploss: 0.00000
train epoch 1763 avg loss: 0.11475 (A-MSE: 0.10187) avg lploss: 0.00000
train epoch 1764 avg loss: 0.12264 (A-MSE: 0.10972) avg lploss: 0.00000
train epoch 1765 avg loss: 0.11223 (A-MSE: 0.09922) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.62344 (A-MSE: 0.55461) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.75382 (A-MSE: 0.68699) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 22 out of 50
train epoch 1766 avg loss: 0.10653 (A-MSE: 0.09525) avg lploss: 0.00000
train epoch 1767 avg loss: 0.13089 (A-MSE: 0.11519) avg lploss: 0.00000
train epoch 1768 avg loss: 0.11140 (A-MSE: 0.09772) avg lploss: 0.00000
train epoch 1769 avg loss: 0.11201 (A-MSE: 0.09983) avg lploss: 0.00000
train epoch 1770 avg loss: 0.11346 (A-MSE: 0.10072) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.63497 (A-MSE: 0.56722) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.71474 (A-MSE: 0.65717) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 23 out of 50
train epoch 1771 avg loss: 0.11013 (A-MSE: 0.09804) avg lploss: 0.00000
train epoch 1772 avg loss: 0.10222 (A-MSE: 0.09098) avg lploss: 0.00000
train epoch 1773 avg loss: 0.09650 (A-MSE: 0.08616) avg lploss: 0.00000
train epoch 1774 avg loss: 0.12433 (A-MSE: 0.11041) avg lploss: 0.00000
train epoch 1775 avg loss: 0.12362 (A-MSE: 0.10997) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.62721 (A-MSE: 0.55351) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.75063 (A-MSE: 0.68036) avg lploss: 0.00000
*** Best Val Loss: 0.60527 	 Best Test Loss: 0.74084 	 Best epoch 1655
EarlyStopping counter: 24 out of 50
train epoch 1776 avg loss: 0.12240 (A-MSE: 0.10846) avg lploss: 0.00000
train epoch 1777 avg loss: 0.11585 (A-MSE: 0.10245) avg lploss: 0.00000
train epoch 1778 avg loss: 0.10047 (A-MSE: 0.08921) avg lploss: 0.00000
train epoch 1779 avg loss: 0.11355 (A-MSE: 0.10085) avg lploss: 0.00000
train epoch 1780 avg loss: 0.11375 (A-MSE: 0.10065) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.56950 (A-MSE: 0.51347) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.69235 (A-MSE: 0.64251) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
Validation loss decreased (0.605269 --> 0.569498).  Saving model ...
train epoch 1781 avg loss: 0.11971 (A-MSE: 0.10612) avg lploss: 0.00000
train epoch 1782 avg loss: 0.14754 (A-MSE: 0.12957) avg lploss: 0.00000
train epoch 1783 avg loss: 0.15546 (A-MSE: 0.13887) avg lploss: 0.00000
train epoch 1784 avg loss: 0.14769 (A-MSE: 0.13241) avg lploss: 0.00000
train epoch 1785 avg loss: 0.13901 (A-MSE: 0.12299) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.73339 (A-MSE: 0.64844) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.90119 (A-MSE: 0.80727) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 1 out of 50
train epoch 1786 avg loss: 0.11212 (A-MSE: 0.09951) avg lploss: 0.00000
train epoch 1787 avg loss: 0.10375 (A-MSE: 0.09223) avg lploss: 0.00000
train epoch 1788 avg loss: 0.10132 (A-MSE: 0.09008) avg lploss: 0.00000
train epoch 1789 avg loss: 0.10168 (A-MSE: 0.09003) avg lploss: 0.00000
train epoch 1790 avg loss: 0.09065 (A-MSE: 0.08096) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.59119 (A-MSE: 0.53399) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.74506 (A-MSE: 0.67921) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 2 out of 50
train epoch 1791 avg loss: 0.09707 (A-MSE: 0.08645) avg lploss: 0.00000
train epoch 1792 avg loss: 0.10874 (A-MSE: 0.09675) avg lploss: 0.00000
train epoch 1793 avg loss: 0.09687 (A-MSE: 0.08628) avg lploss: 0.00000
train epoch 1794 avg loss: 0.10009 (A-MSE: 0.08919) avg lploss: 0.00000
train epoch 1795 avg loss: 0.10325 (A-MSE: 0.09111) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.65942 (A-MSE: 0.57412) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.76653 (A-MSE: 0.68361) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 3 out of 50
train epoch 1796 avg loss: 0.10431 (A-MSE: 0.09320) avg lploss: 0.00000
train epoch 1797 avg loss: 0.12392 (A-MSE: 0.10945) avg lploss: 0.00000
train epoch 1798 avg loss: 0.15034 (A-MSE: 0.13392) avg lploss: 0.00000
train epoch 1799 avg loss: 0.16769 (A-MSE: 0.14827) avg lploss: 0.00000
train epoch 1800 avg loss: 0.17256 (A-MSE: 0.15172) avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.67583 (A-MSE: 0.59226) avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.80715 (A-MSE: 0.72157) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 4 out of 50
train epoch 1801 avg loss: 1294.70546 (A-MSE: 611.82677) avg lploss: 0.00000
train epoch 1802 avg loss: 169.32711 (A-MSE: 155.12636) avg lploss: 0.00000
train epoch 1803 avg loss: 154.83716 (A-MSE: 143.99581) avg lploss: 0.00000
train epoch 1804 avg loss: 147.58313 (A-MSE: 134.66576) avg lploss: 0.00000
train epoch 1805 avg loss: 112.29053 (A-MSE: 101.24896) avg lploss: 0.00000
==> val epoch 1805 avg loss: 95.80629 (A-MSE: 86.70727) avg lploss: 0.00000
==> test epoch 1805 avg loss: 90.40026 (A-MSE: 81.87788) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 5 out of 50
train epoch 1806 avg loss: 84.68876 (A-MSE: 76.06999) avg lploss: 0.00000
train epoch 1807 avg loss: 87.28730 (A-MSE: 78.23216) avg lploss: 0.00000
train epoch 1808 avg loss: 68.08498 (A-MSE: 59.95479) avg lploss: 0.00000
train epoch 1809 avg loss: 40.07189 (A-MSE: 34.80812) avg lploss: 0.00000
train epoch 1810 avg loss: 27.19782 (A-MSE: 23.43783) avg lploss: 0.00000
==> val epoch 1810 avg loss: 23.05344 (A-MSE: 19.48432) avg lploss: 0.00000
==> test epoch 1810 avg loss: 22.01590 (A-MSE: 18.57524) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 6 out of 50
train epoch 1811 avg loss: 20.98386 (A-MSE: 17.90487) avg lploss: 0.00000
train epoch 1812 avg loss: 17.80296 (A-MSE: 15.19017) avg lploss: 0.00000
train epoch 1813 avg loss: 16.18185 (A-MSE: 13.72473) avg lploss: 0.00000
train epoch 1814 avg loss: 14.53108 (A-MSE: 12.28966) avg lploss: 0.00000
train epoch 1815 avg loss: 12.66606 (A-MSE: 10.63511) avg lploss: 0.00000
==> val epoch 1815 avg loss: 11.38346 (A-MSE: 9.52976) avg lploss: 0.00000
==> test epoch 1815 avg loss: 10.97709 (A-MSE: 9.17416) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 7 out of 50
train epoch 1816 avg loss: 11.81967 (A-MSE: 9.87793) avg lploss: 0.00000
train epoch 1817 avg loss: 10.71945 (A-MSE: 8.99927) avg lploss: 0.00000
train epoch 1818 avg loss: 10.08988 (A-MSE: 8.41842) avg lploss: 0.00000
train epoch 1819 avg loss: 9.31491 (A-MSE: 7.77592) avg lploss: 0.00000
train epoch 1820 avg loss: 8.73602 (A-MSE: 7.28674) avg lploss: 0.00000
==> val epoch 1820 avg loss: 8.17403 (A-MSE: 6.72651) avg lploss: 0.00000
==> test epoch 1820 avg loss: 7.97150 (A-MSE: 6.55996) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 8 out of 50
train epoch 1821 avg loss: 8.22075 (A-MSE: 6.87077) avg lploss: 0.00000
train epoch 1822 avg loss: 7.72285 (A-MSE: 6.40679) avg lploss: 0.00000
train epoch 1823 avg loss: 7.28778 (A-MSE: 6.04043) avg lploss: 0.00000
train epoch 1824 avg loss: 7.18005 (A-MSE: 5.94357) avg lploss: 0.00000
train epoch 1825 avg loss: 6.38794 (A-MSE: 5.29385) avg lploss: 0.00000
==> val epoch 1825 avg loss: 5.81734 (A-MSE: 4.91893) avg lploss: 0.00000
==> test epoch 1825 avg loss: 5.70639 (A-MSE: 4.86863) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 9 out of 50
train epoch 1826 avg loss: 6.14682 (A-MSE: 5.10286) avg lploss: 0.00000
train epoch 1827 avg loss: 5.74517 (A-MSE: 4.73176) avg lploss: 0.00000
train epoch 1828 avg loss: 5.49779 (A-MSE: 4.53556) avg lploss: 0.00000
train epoch 1829 avg loss: 5.34196 (A-MSE: 4.40830) avg lploss: 0.00000
train epoch 1830 avg loss: 4.88548 (A-MSE: 4.02591) avg lploss: 0.00000
==> val epoch 1830 avg loss: 4.93324 (A-MSE: 3.97413) avg lploss: 0.00000
==> test epoch 1830 avg loss: 4.81595 (A-MSE: 3.90729) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 10 out of 50
train epoch 1831 avg loss: 4.60981 (A-MSE: 3.79220) avg lploss: 0.00000
train epoch 1832 avg loss: 4.46095 (A-MSE: 3.69907) avg lploss: 0.00000
train epoch 1833 avg loss: 4.35009 (A-MSE: 3.61288) avg lploss: 0.00000
train epoch 1834 avg loss: 4.07559 (A-MSE: 3.37507) avg lploss: 0.00000
train epoch 1835 avg loss: 4.00222 (A-MSE: 3.31946) avg lploss: 0.00000
==> val epoch 1835 avg loss: 4.13645 (A-MSE: 3.38243) avg lploss: 0.00000
==> test epoch 1835 avg loss: 4.05797 (A-MSE: 3.36130) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 11 out of 50
train epoch 1836 avg loss: 3.81979 (A-MSE: 3.17090) avg lploss: 0.00000
train epoch 1837 avg loss: 3.68822 (A-MSE: 3.05713) avg lploss: 0.00000
train epoch 1838 avg loss: 3.59775 (A-MSE: 2.98656) avg lploss: 0.00000
train epoch 1839 avg loss: 3.51668 (A-MSE: 2.91390) avg lploss: 0.00000
train epoch 1840 avg loss: 3.35789 (A-MSE: 2.77583) avg lploss: 0.00000
==> val epoch 1840 avg loss: 3.84349 (A-MSE: 3.13303) avg lploss: 0.00000
==> test epoch 1840 avg loss: 3.79435 (A-MSE: 3.14313) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 12 out of 50
train epoch 1841 avg loss: 3.44087 (A-MSE: 2.86655) avg lploss: 0.00000
train epoch 1842 avg loss: 3.27375 (A-MSE: 2.71538) avg lploss: 0.00000
train epoch 1843 avg loss: 3.35106 (A-MSE: 2.79735) avg lploss: 0.00000
train epoch 1844 avg loss: 3.44041 (A-MSE: 2.87580) avg lploss: 0.00000
train epoch 1845 avg loss: 3.36500 (A-MSE: 2.79689) avg lploss: 0.00000
==> val epoch 1845 avg loss: 3.47570 (A-MSE: 2.82209) avg lploss: 0.00000
==> test epoch 1845 avg loss: 3.54928 (A-MSE: 2.94446) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 13 out of 50
train epoch 1846 avg loss: 3.35331 (A-MSE: 2.78897) avg lploss: 0.00000
train epoch 1847 avg loss: 3.16430 (A-MSE: 2.63256) avg lploss: 0.00000
train epoch 1848 avg loss: 3.01973 (A-MSE: 2.48345) avg lploss: 0.00000
train epoch 1849 avg loss: 3.06345 (A-MSE: 2.55561) avg lploss: 0.00000
train epoch 1850 avg loss: 2.96854 (A-MSE: 2.46579) avg lploss: 0.00000
==> val epoch 1850 avg loss: 3.02864 (A-MSE: 2.54502) avg lploss: 0.00000
==> test epoch 1850 avg loss: 3.03942 (A-MSE: 2.60369) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 14 out of 50
train epoch 1851 avg loss: 2.93270 (A-MSE: 2.44146) avg lploss: 0.00000
train epoch 1852 avg loss: 2.85119 (A-MSE: 2.36803) avg lploss: 0.00000
train epoch 1853 avg loss: 2.82656 (A-MSE: 2.34995) avg lploss: 0.00000
train epoch 1854 avg loss: 2.71044 (A-MSE: 2.24944) avg lploss: 0.00000
train epoch 1855 avg loss: 2.76811 (A-MSE: 2.30437) avg lploss: 0.00000
==> val epoch 1855 avg loss: 3.05405 (A-MSE: 2.46243) avg lploss: 0.00000
==> test epoch 1855 avg loss: 3.11838 (A-MSE: 2.58359) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 15 out of 50
train epoch 1856 avg loss: 2.69242 (A-MSE: 2.24039) avg lploss: 0.00000
train epoch 1857 avg loss: 2.74974 (A-MSE: 2.27878) avg lploss: 0.00000
train epoch 1858 avg loss: 2.68970 (A-MSE: 2.22712) avg lploss: 0.00000
train epoch 1859 avg loss: 2.68115 (A-MSE: 2.24424) avg lploss: 0.00000
train epoch 1860 avg loss: 2.63283 (A-MSE: 2.18099) avg lploss: 0.00000
==> val epoch 1860 avg loss: 2.97628 (A-MSE: 2.38398) avg lploss: 0.00000
==> test epoch 1860 avg loss: 3.06626 (A-MSE: 2.51908) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 16 out of 50
train epoch 1861 avg loss: 2.56570 (A-MSE: 2.12736) avg lploss: 0.00000
train epoch 1862 avg loss: 2.56490 (A-MSE: 2.12613) avg lploss: 0.00000
train epoch 1863 avg loss: 2.63754 (A-MSE: 2.20143) avg lploss: 0.00000
train epoch 1864 avg loss: 2.68934 (A-MSE: 2.24069) avg lploss: 0.00000
train epoch 1865 avg loss: 2.53500 (A-MSE: 2.11002) avg lploss: 0.00000
==> val epoch 1865 avg loss: 2.75602 (A-MSE: 2.23903) avg lploss: 0.00000
==> test epoch 1865 avg loss: 2.79801 (A-MSE: 2.32629) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 17 out of 50
train epoch 1866 avg loss: 2.53306 (A-MSE: 2.10649) avg lploss: 0.00000
train epoch 1867 avg loss: 2.38991 (A-MSE: 1.98098) avg lploss: 0.00000
train epoch 1868 avg loss: 2.45789 (A-MSE: 2.03657) avg lploss: 0.00000
train epoch 1869 avg loss: 2.42273 (A-MSE: 2.02793) avg lploss: 0.00000
train epoch 1870 avg loss: 2.32747 (A-MSE: 1.93600) avg lploss: 0.00000
==> val epoch 1870 avg loss: 2.45751 (A-MSE: 2.00380) avg lploss: 0.00000
==> test epoch 1870 avg loss: 2.54455 (A-MSE: 2.13203) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 18 out of 50
train epoch 1871 avg loss: 2.30624 (A-MSE: 1.91312) avg lploss: 0.00000
train epoch 1872 avg loss: 2.34890 (A-MSE: 1.96560) avg lploss: 0.00000
train epoch 1873 avg loss: 2.35915 (A-MSE: 1.96533) avg lploss: 0.00000
train epoch 1874 avg loss: 2.34252 (A-MSE: 1.95658) avg lploss: 0.00000
train epoch 1875 avg loss: 2.35479 (A-MSE: 1.96860) avg lploss: 0.00000
==> val epoch 1875 avg loss: 2.47540 (A-MSE: 2.06604) avg lploss: 0.00000
==> test epoch 1875 avg loss: 2.56083 (A-MSE: 2.18552) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 19 out of 50
train epoch 1876 avg loss: 2.28788 (A-MSE: 1.90639) avg lploss: 0.00000
train epoch 1877 avg loss: 2.20151 (A-MSE: 1.83157) avg lploss: 0.00000
train epoch 1878 avg loss: 2.16273 (A-MSE: 1.80821) avg lploss: 0.00000
train epoch 1879 avg loss: 2.30869 (A-MSE: 1.92852) avg lploss: 0.00000
train epoch 1880 avg loss: 2.22532 (A-MSE: 1.85041) avg lploss: 0.00000
==> val epoch 1880 avg loss: 2.42432 (A-MSE: 2.03635) avg lploss: 0.00000
==> test epoch 1880 avg loss: 2.51195 (A-MSE: 2.15943) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 20 out of 50
train epoch 1881 avg loss: 2.20656 (A-MSE: 1.84551) avg lploss: 0.00000
train epoch 1882 avg loss: 2.15814 (A-MSE: 1.80747) avg lploss: 0.00000
train epoch 1883 avg loss: 2.28723 (A-MSE: 1.91114) avg lploss: 0.00000
train epoch 1884 avg loss: 2.23857 (A-MSE: 1.88279) avg lploss: 0.00000
train epoch 1885 avg loss: 2.34664 (A-MSE: 1.97708) avg lploss: 0.00000
==> val epoch 1885 avg loss: 2.40095 (A-MSE: 2.03306) avg lploss: 0.00000
==> test epoch 1885 avg loss: 2.50684 (A-MSE: 2.17654) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 21 out of 50
train epoch 1886 avg loss: 2.20362 (A-MSE: 1.84116) avg lploss: 0.00000
train epoch 1887 avg loss: 2.23679 (A-MSE: 1.87217) avg lploss: 0.00000
train epoch 1888 avg loss: 2.08673 (A-MSE: 1.74103) avg lploss: 0.00000
train epoch 1889 avg loss: 2.09447 (A-MSE: 1.75329) avg lploss: 0.00000
train epoch 1890 avg loss: 2.04291 (A-MSE: 1.70468) avg lploss: 0.00000
==> val epoch 1890 avg loss: 2.44909 (A-MSE: 1.96632) avg lploss: 0.00000
==> test epoch 1890 avg loss: 2.53833 (A-MSE: 2.10171) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 22 out of 50
train epoch 1891 avg loss: 2.26679 (A-MSE: 1.89886) avg lploss: 0.00000
train epoch 1892 avg loss: 2.29705 (A-MSE: 1.94350) avg lploss: 0.00000
train epoch 1893 avg loss: 2.15653 (A-MSE: 1.80660) avg lploss: 0.00000
train epoch 1894 avg loss: 2.07923 (A-MSE: 1.75470) avg lploss: 0.00000
train epoch 1895 avg loss: 2.16760 (A-MSE: 1.81108) avg lploss: 0.00000
==> val epoch 1895 avg loss: 2.13504 (A-MSE: 1.74022) avg lploss: 0.00000
==> test epoch 1895 avg loss: 2.28032 (A-MSE: 1.91253) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 23 out of 50
train epoch 1896 avg loss: 1.99683 (A-MSE: 1.66792) avg lploss: 0.00000
train epoch 1897 avg loss: 1.98019 (A-MSE: 1.65755) avg lploss: 0.00000
train epoch 1898 avg loss: 1.91885 (A-MSE: 1.60780) avg lploss: 0.00000
train epoch 1899 avg loss: 2.01122 (A-MSE: 1.69070) avg lploss: 0.00000
train epoch 1900 avg loss: 2.01597 (A-MSE: 1.69462) avg lploss: 0.00000
==> val epoch 1900 avg loss: 2.07287 (A-MSE: 1.72846) avg lploss: 0.00000
==> test epoch 1900 avg loss: 2.15185 (A-MSE: 1.84144) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 24 out of 50
train epoch 1901 avg loss: 1.94215 (A-MSE: 1.63001) avg lploss: 0.00000
train epoch 1902 avg loss: 1.99206 (A-MSE: 1.67033) avg lploss: 0.00000
train epoch 1903 avg loss: 1.88723 (A-MSE: 1.58113) avg lploss: 0.00000
train epoch 1904 avg loss: 1.91918 (A-MSE: 1.60265) avg lploss: 0.00000
train epoch 1905 avg loss: 2.35000 (A-MSE: 2.00103) avg lploss: 0.00000
==> val epoch 1905 avg loss: 2.22472 (A-MSE: 1.88900) avg lploss: 0.00000
==> test epoch 1905 avg loss: 2.40118 (A-MSE: 2.08121) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 25 out of 50
train epoch 1906 avg loss: 2.04334 (A-MSE: 1.72043) avg lploss: 0.00000
train epoch 1907 avg loss: 1.96294 (A-MSE: 1.64638) avg lploss: 0.00000
train epoch 1908 avg loss: 2.00740 (A-MSE: 1.69606) avg lploss: 0.00000
train epoch 1909 avg loss: 1.95878 (A-MSE: 1.64759) avg lploss: 0.00000
train epoch 1910 avg loss: 1.90999 (A-MSE: 1.60875) avg lploss: 0.00000
==> val epoch 1910 avg loss: 2.09361 (A-MSE: 1.71386) avg lploss: 0.00000
==> test epoch 1910 avg loss: 2.18118 (A-MSE: 1.83037) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 26 out of 50
train epoch 1911 avg loss: 1.97168 (A-MSE: 1.65200) avg lploss: 0.00000
train epoch 1912 avg loss: 1.82610 (A-MSE: 1.53832) avg lploss: 0.00000
train epoch 1913 avg loss: 1.75202 (A-MSE: 1.46678) avg lploss: 0.00000
train epoch 1914 avg loss: 1.69196 (A-MSE: 1.41069) avg lploss: 0.00000
train epoch 1915 avg loss: 1.83148 (A-MSE: 1.54809) avg lploss: 0.00000
==> val epoch 1915 avg loss: 2.11047 (A-MSE: 1.75449) avg lploss: 0.00000
==> test epoch 1915 avg loss: 2.23450 (A-MSE: 1.91255) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 27 out of 50
train epoch 1916 avg loss: 1.83023 (A-MSE: 1.54350) avg lploss: 0.00000
train epoch 1917 avg loss: 1.75255 (A-MSE: 1.47563) avg lploss: 0.00000
train epoch 1918 avg loss: 1.69382 (A-MSE: 1.42677) avg lploss: 0.00000
train epoch 1919 avg loss: 1.65790 (A-MSE: 1.38702) avg lploss: 0.00000
train epoch 1920 avg loss: 1.69630 (A-MSE: 1.43496) avg lploss: 0.00000
==> val epoch 1920 avg loss: 1.89505 (A-MSE: 1.54112) avg lploss: 0.00000
==> test epoch 1920 avg loss: 1.99757 (A-MSE: 1.67663) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 28 out of 50
train epoch 1921 avg loss: 1.66784 (A-MSE: 1.40352) avg lploss: 0.00000
train epoch 1922 avg loss: 1.64884 (A-MSE: 1.39934) avg lploss: 0.00000
train epoch 1923 avg loss: 1.68265 (A-MSE: 1.41758) avg lploss: 0.00000
train epoch 1924 avg loss: 1.91797 (A-MSE: 1.63446) avg lploss: 0.00000
train epoch 1925 avg loss: 1.92251 (A-MSE: 1.63837) avg lploss: 0.00000
==> val epoch 1925 avg loss: 1.76403 (A-MSE: 1.50383) avg lploss: 0.00000
==> test epoch 1925 avg loss: 1.89665 (A-MSE: 1.65776) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 29 out of 50
train epoch 1926 avg loss: 1.66849 (A-MSE: 1.39109) avg lploss: 0.00000
train epoch 1927 avg loss: 1.61488 (A-MSE: 1.36943) avg lploss: 0.00000
train epoch 1928 avg loss: 1.61864 (A-MSE: 1.36917) avg lploss: 0.00000
train epoch 1929 avg loss: 1.84268 (A-MSE: 1.56742) avg lploss: 0.00000
train epoch 1930 avg loss: 1.72271 (A-MSE: 1.46013) avg lploss: 0.00000
==> val epoch 1930 avg loss: 1.78676 (A-MSE: 1.48491) avg lploss: 0.00000
==> test epoch 1930 avg loss: 1.90431 (A-MSE: 1.62223) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 30 out of 50
train epoch 1931 avg loss: 1.59123 (A-MSE: 1.33812) avg lploss: 0.00000
train epoch 1932 avg loss: 1.49094 (A-MSE: 1.25957) avg lploss: 0.00000
train epoch 1933 avg loss: 1.46696 (A-MSE: 1.23753) avg lploss: 0.00000
train epoch 1934 avg loss: 1.44638 (A-MSE: 1.21715) avg lploss: 0.00000
train epoch 1935 avg loss: 1.56948 (A-MSE: 1.34125) avg lploss: 0.00000
==> val epoch 1935 avg loss: 1.70568 (A-MSE: 1.41229) avg lploss: 0.00000
==> test epoch 1935 avg loss: 1.87364 (A-MSE: 1.59394) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 31 out of 50
train epoch 1936 avg loss: 1.57706 (A-MSE: 1.33245) avg lploss: 0.00000
train epoch 1937 avg loss: 1.50881 (A-MSE: 1.27615) avg lploss: 0.00000
train epoch 1938 avg loss: 1.36911 (A-MSE: 1.15531) avg lploss: 0.00000
train epoch 1939 avg loss: 1.48627 (A-MSE: 1.27746) avg lploss: 0.00000
train epoch 1940 avg loss: 1.55463 (A-MSE: 1.31430) avg lploss: 0.00000
==> val epoch 1940 avg loss: 1.68994 (A-MSE: 1.36967) avg lploss: 0.00000
==> test epoch 1940 avg loss: 1.81738 (A-MSE: 1.52524) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 32 out of 50
train epoch 1941 avg loss: 1.51987 (A-MSE: 1.29243) avg lploss: 0.00000
train epoch 1942 avg loss: 1.37531 (A-MSE: 1.16361) avg lploss: 0.00000
train epoch 1943 avg loss: 1.38960 (A-MSE: 1.17919) avg lploss: 0.00000
train epoch 1944 avg loss: 1.43379 (A-MSE: 1.21763) avg lploss: 0.00000
train epoch 1945 avg loss: 1.55841 (A-MSE: 1.31637) avg lploss: 0.00000
==> val epoch 1945 avg loss: 2.00386 (A-MSE: 1.72081) avg lploss: 0.00000
==> test epoch 1945 avg loss: 2.21654 (A-MSE: 1.95392) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 33 out of 50
train epoch 1946 avg loss: 1.74383 (A-MSE: 1.49174) avg lploss: 0.00000
train epoch 1947 avg loss: 1.45058 (A-MSE: 1.23065) avg lploss: 0.00000
train epoch 1948 avg loss: 1.27262 (A-MSE: 1.06831) avg lploss: 0.00000
train epoch 1949 avg loss: 1.26722 (A-MSE: 1.06220) avg lploss: 0.00000
train epoch 1950 avg loss: 1.26222 (A-MSE: 1.07986) avg lploss: 0.00000
==> val epoch 1950 avg loss: 1.50095 (A-MSE: 1.24538) avg lploss: 0.00000
==> test epoch 1950 avg loss: 1.66422 (A-MSE: 1.42690) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 34 out of 50
train epoch 1951 avg loss: 1.29934 (A-MSE: 1.10110) avg lploss: 0.00000
train epoch 1952 avg loss: 1.23508 (A-MSE: 1.04357) avg lploss: 0.00000
train epoch 1953 avg loss: 1.29379 (A-MSE: 1.11333) avg lploss: 0.00000
train epoch 1954 avg loss: 1.43236 (A-MSE: 1.22049) avg lploss: 0.00000
train epoch 1955 avg loss: 1.26595 (A-MSE: 1.07173) avg lploss: 0.00000
==> val epoch 1955 avg loss: 1.62645 (A-MSE: 1.41365) avg lploss: 0.00000
==> test epoch 1955 avg loss: 1.74548 (A-MSE: 1.55714) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 35 out of 50
train epoch 1956 avg loss: 1.19253 (A-MSE: 1.01263) avg lploss: 0.00000
train epoch 1957 avg loss: 1.12434 (A-MSE: 0.95680) avg lploss: 0.00000
train epoch 1958 avg loss: 1.14025 (A-MSE: 0.96762) avg lploss: 0.00000
train epoch 1959 avg loss: 1.10237 (A-MSE: 0.93898) avg lploss: 0.00000
train epoch 1960 avg loss: 1.15169 (A-MSE: 0.97080) avg lploss: 0.00000
==> val epoch 1960 avg loss: 1.27717 (A-MSE: 1.06989) avg lploss: 0.00000
==> test epoch 1960 avg loss: 1.41834 (A-MSE: 1.22457) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 36 out of 50
train epoch 1961 avg loss: 1.17549 (A-MSE: 1.00276) avg lploss: 0.00000
train epoch 1962 avg loss: 1.21262 (A-MSE: 1.05805) avg lploss: 0.00000
train epoch 1963 avg loss: 1.19049 (A-MSE: 1.01214) avg lploss: 0.00000
train epoch 1964 avg loss: 1.03165 (A-MSE: 0.87387) avg lploss: 0.00000
train epoch 1965 avg loss: 1.16945 (A-MSE: 1.00687) avg lploss: 0.00000
==> val epoch 1965 avg loss: 1.37573 (A-MSE: 1.20635) avg lploss: 0.00000
==> test epoch 1965 avg loss: 1.48527 (A-MSE: 1.34568) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 37 out of 50
train epoch 1966 avg loss: 1.19751 (A-MSE: 1.02428) avg lploss: 0.00000
train epoch 1967 avg loss: 1.09198 (A-MSE: 0.93923) avg lploss: 0.00000
train epoch 1968 avg loss: 0.99194 (A-MSE: 0.84255) avg lploss: 0.00000
train epoch 1969 avg loss: 1.03980 (A-MSE: 0.88220) avg lploss: 0.00000
train epoch 1970 avg loss: 1.20913 (A-MSE: 1.04876) avg lploss: 0.00000
==> val epoch 1970 avg loss: 1.25516 (A-MSE: 1.00967) avg lploss: 0.00000
==> test epoch 1970 avg loss: 1.30865 (A-MSE: 1.09454) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 38 out of 50
train epoch 1971 avg loss: 1.10130 (A-MSE: 0.93923) avg lploss: 0.00000
train epoch 1972 avg loss: 0.95853 (A-MSE: 0.81659) avg lploss: 0.00000
train epoch 1973 avg loss: 1.24222 (A-MSE: 1.07287) avg lploss: 0.00000
train epoch 1974 avg loss: 1.09772 (A-MSE: 0.94469) avg lploss: 0.00000
train epoch 1975 avg loss: 1.00857 (A-MSE: 0.85428) avg lploss: 0.00000
==> val epoch 1975 avg loss: 1.15384 (A-MSE: 0.98988) avg lploss: 0.00000
==> test epoch 1975 avg loss: 1.26727 (A-MSE: 1.12872) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 39 out of 50
train epoch 1976 avg loss: 0.94322 (A-MSE: 0.80664) avg lploss: 0.00000
train epoch 1977 avg loss: 0.99286 (A-MSE: 0.84569) avg lploss: 0.00000
train epoch 1978 avg loss: 0.95774 (A-MSE: 0.81735) avg lploss: 0.00000
train epoch 1979 avg loss: 1.00145 (A-MSE: 0.87124) avg lploss: 0.00000
train epoch 1980 avg loss: 0.94360 (A-MSE: 0.81238) avg lploss: 0.00000
==> val epoch 1980 avg loss: 1.26258 (A-MSE: 1.01357) avg lploss: 0.00000
==> test epoch 1980 avg loss: 1.30748 (A-MSE: 1.09047) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 40 out of 50
train epoch 1981 avg loss: 0.97572 (A-MSE: 0.82080) avg lploss: 0.00000
train epoch 1982 avg loss: 1.08651 (A-MSE: 0.94298) avg lploss: 0.00000
train epoch 1983 avg loss: 0.94627 (A-MSE: 0.80398) avg lploss: 0.00000
train epoch 1984 avg loss: 0.92009 (A-MSE: 0.79339) avg lploss: 0.00000
train epoch 1985 avg loss: 0.97039 (A-MSE: 0.83740) avg lploss: 0.00000
==> val epoch 1985 avg loss: 1.12771 (A-MSE: 0.96661) avg lploss: 0.00000
==> test epoch 1985 avg loss: 1.24673 (A-MSE: 1.10615) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 41 out of 50
train epoch 1986 avg loss: 1.09359 (A-MSE: 0.94905) avg lploss: 0.00000
train epoch 1987 avg loss: 0.99370 (A-MSE: 0.85119) avg lploss: 0.00000
train epoch 1988 avg loss: 0.95056 (A-MSE: 0.82380) avg lploss: 0.00000
train epoch 1989 avg loss: 0.85150 (A-MSE: 0.73412) avg lploss: 0.00000
train epoch 1990 avg loss: 0.84908 (A-MSE: 0.72086) avg lploss: 0.00000
==> val epoch 1990 avg loss: 1.39475 (A-MSE: 1.23171) avg lploss: 0.00000
==> test epoch 1990 avg loss: 1.49655 (A-MSE: 1.36631) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 42 out of 50
train epoch 1991 avg loss: 0.93735 (A-MSE: 0.80540) avg lploss: 0.00000
train epoch 1992 avg loss: 0.79426 (A-MSE: 0.68026) avg lploss: 0.00000
train epoch 1993 avg loss: 0.81583 (A-MSE: 0.70454) avg lploss: 0.00000
train epoch 1994 avg loss: 0.80995 (A-MSE: 0.68569) avg lploss: 0.00000
train epoch 1995 avg loss: 0.91351 (A-MSE: 0.79592) avg lploss: 0.00000
==> val epoch 1995 avg loss: 1.30575 (A-MSE: 1.10328) avg lploss: 0.00000
==> test epoch 1995 avg loss: 1.34288 (A-MSE: 1.17385) avg lploss: 0.00000
*** Best Val Loss: 0.56950 	 Best Test Loss: 0.69235 	 Best epoch 1780
EarlyStopping counter: 43 out of 50
train epoch 1996 avg loss: 0.86654 (A-MSE: 0.74392) avg lploss: 0.00000
train epoch 1997 avg loss: 0.77482 (A-MSE: 0.66806) avg lploss: 0.00000
train epoch 1998 avg loss: 0.72314 (A-MSE: 0.62665) avg lploss: 0.00000
train epoch 1999 avg loss: 0.78913 (A-MSE: 0.68213) avg lploss: 0.00000
best_train = 0.113754
best_lp = 0.000000
best_val = 0.569498
best_test = 0.692349
best_epoch = 1780
best_train = 0.113754, best_lp = 0.000000, best_val = 0.569498, best_test = 0.692349, best_epoch = 1780
Training completed for seed 4 with num_modes=2
