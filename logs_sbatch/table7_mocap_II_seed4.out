Date              = Mon Dec  8 22:46:18 CET 2025
Hostname          = mel2040
Array Task ID     = 8
Running config: configs/table7_mocap_variant_II_seed4.json
Namespace(batch_size=12, case='run', config_by_file='configs/table7_mocap_variant_II_seed4.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='table7_mocap_variant_II_seed4', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/table7_mocap', pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, use_h_conv=True, use_x_conv=False, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/table7_mocap/table7_mocap_variant_II_seed4/saved_model.pth
train epoch 0 avg loss: 95.58126 (A-MSE: 87.57132) avg lploss: 0.00000
==> val epoch 0 avg loss: 30.07405 (A-MSE: 27.25881) avg lploss: 0.00000
==> test epoch 0 avg loss: 28.68750 (A-MSE: 25.98815) avg lploss: 0.00000
*** Best Val Loss: 30.07405 	 Best Test Loss: 28.68750 	 Best epoch 0
Validation loss decreased (inf --> 30.074045).  Saving model ...
train epoch 1 avg loss: 19.29196 (A-MSE: 16.74670) avg lploss: 0.00000
train epoch 2 avg loss: 13.26300 (A-MSE: 11.19298) avg lploss: 0.00000
train epoch 3 avg loss: 12.49695 (A-MSE: 10.64571) avg lploss: 0.00000
train epoch 4 avg loss: 14.60797 (A-MSE: 12.04429) avg lploss: 0.00000
train epoch 5 avg loss: 14.18739 (A-MSE: 12.10263) avg lploss: 0.00000
==> val epoch 5 avg loss: 13.41311 (A-MSE: 11.77769) avg lploss: 0.00000
==> test epoch 5 avg loss: 13.08240 (A-MSE: 11.51528) avg lploss: 0.00000
*** Best Val Loss: 13.41311 	 Best Test Loss: 13.08240 	 Best epoch 5
Validation loss decreased (30.074045 --> 13.413108).  Saving model ...
train epoch 6 avg loss: 13.35665 (A-MSE: 11.48607) avg lploss: 0.00000
train epoch 7 avg loss: 12.45594 (A-MSE: 10.64608) avg lploss: 0.00000
train epoch 8 avg loss: 11.45320 (A-MSE: 9.68178) avg lploss: 0.00000
train epoch 9 avg loss: 10.13529 (A-MSE: 8.55363) avg lploss: 0.00000
train epoch 10 avg loss: 8.96370 (A-MSE: 7.61167) avg lploss: 0.00000
==> val epoch 10 avg loss: 8.29448 (A-MSE: 6.95938) avg lploss: 0.00000
==> test epoch 10 avg loss: 8.15981 (A-MSE: 6.85542) avg lploss: 0.00000
*** Best Val Loss: 8.29448 	 Best Test Loss: 8.15981 	 Best epoch 10
Validation loss decreased (13.413108 --> 8.294478).  Saving model ...
train epoch 11 avg loss: 8.18123 (A-MSE: 6.94339) avg lploss: 0.00000
train epoch 12 avg loss: 7.44643 (A-MSE: 6.32447) avg lploss: 0.00000
train epoch 13 avg loss: 6.70429 (A-MSE: 5.73418) avg lploss: 0.00000
train epoch 14 avg loss: 6.13790 (A-MSE: 5.22604) avg lploss: 0.00000
train epoch 15 avg loss: 5.77122 (A-MSE: 4.94243) avg lploss: 0.00000
==> val epoch 15 avg loss: 5.08449 (A-MSE: 4.25864) avg lploss: 0.00000
==> test epoch 15 avg loss: 4.99658 (A-MSE: 4.20568) avg lploss: 0.00000
*** Best Val Loss: 5.08449 	 Best Test Loss: 4.99658 	 Best epoch 15
Validation loss decreased (8.294478 --> 5.084490).  Saving model ...
train epoch 16 avg loss: 4.59724 (A-MSE: 3.93768) avg lploss: 0.00000
train epoch 17 avg loss: 4.25234 (A-MSE: 3.63225) avg lploss: 0.00000
train epoch 18 avg loss: 3.60789 (A-MSE: 3.08182) avg lploss: 0.00000
train epoch 19 avg loss: 3.41061 (A-MSE: 2.92537) avg lploss: 0.00000
train epoch 20 avg loss: 2.96171 (A-MSE: 2.54881) avg lploss: 0.00000
==> val epoch 20 avg loss: 3.04002 (A-MSE: 2.58110) avg lploss: 0.00000
==> test epoch 20 avg loss: 3.15212 (A-MSE: 2.70805) avg lploss: 0.00000
*** Best Val Loss: 3.04002 	 Best Test Loss: 3.15212 	 Best epoch 20
Validation loss decreased (5.084490 --> 3.040017).  Saving model ...
train epoch 21 avg loss: 2.65503 (A-MSE: 2.27966) avg lploss: 0.00000
train epoch 22 avg loss: 2.49352 (A-MSE: 2.15544) avg lploss: 0.00000
train epoch 23 avg loss: 2.43051 (A-MSE: 2.10474) avg lploss: 0.00000
train epoch 24 avg loss: 2.37281 (A-MSE: 2.05723) avg lploss: 0.00000
train epoch 25 avg loss: 2.21491 (A-MSE: 1.92347) avg lploss: 0.00000
==> val epoch 25 avg loss: 2.32114 (A-MSE: 2.01717) avg lploss: 0.00000
==> test epoch 25 avg loss: 2.44310 (A-MSE: 2.14828) avg lploss: 0.00000
*** Best Val Loss: 2.32114 	 Best Test Loss: 2.44310 	 Best epoch 25
Validation loss decreased (3.040017 --> 2.321144).  Saving model ...
train epoch 26 avg loss: 2.29038 (A-MSE: 1.97666) avg lploss: 0.00000
train epoch 27 avg loss: 2.11981 (A-MSE: 1.83218) avg lploss: 0.00000
train epoch 28 avg loss: 2.07020 (A-MSE: 1.80105) avg lploss: 0.00000
train epoch 29 avg loss: 1.87835 (A-MSE: 1.63776) avg lploss: 0.00000
train epoch 30 avg loss: 1.88326 (A-MSE: 1.62957) avg lploss: 0.00000
==> val epoch 30 avg loss: 2.00106 (A-MSE: 1.75824) avg lploss: 0.00000
==> test epoch 30 avg loss: 2.12121 (A-MSE: 1.89284) avg lploss: 0.00000
*** Best Val Loss: 2.00106 	 Best Test Loss: 2.12121 	 Best epoch 30
Validation loss decreased (2.321144 --> 2.001058).  Saving model ...
train epoch 31 avg loss: 1.85812 (A-MSE: 1.61599) avg lploss: 0.00000
train epoch 32 avg loss: 1.83414 (A-MSE: 1.60805) avg lploss: 0.00000
train epoch 33 avg loss: 1.75904 (A-MSE: 1.53708) avg lploss: 0.00000
train epoch 34 avg loss: 1.68062 (A-MSE: 1.46168) avg lploss: 0.00000
train epoch 35 avg loss: 1.47263 (A-MSE: 1.27779) avg lploss: 0.00000
==> val epoch 35 avg loss: 1.65703 (A-MSE: 1.44268) avg lploss: 0.00000
==> test epoch 35 avg loss: 1.77552 (A-MSE: 1.57100) avg lploss: 0.00000
*** Best Val Loss: 1.65703 	 Best Test Loss: 1.77552 	 Best epoch 35
Validation loss decreased (2.001058 --> 1.657031).  Saving model ...
train epoch 36 avg loss: 1.55484 (A-MSE: 1.35200) avg lploss: 0.00000
train epoch 37 avg loss: 1.57781 (A-MSE: 1.36641) avg lploss: 0.00000
train epoch 38 avg loss: 1.41758 (A-MSE: 1.22429) avg lploss: 0.00000
train epoch 39 avg loss: 1.39418 (A-MSE: 1.20599) avg lploss: 0.00000
train epoch 40 avg loss: 1.34395 (A-MSE: 1.17624) avg lploss: 0.00000
==> val epoch 40 avg loss: 1.64997 (A-MSE: 1.44657) avg lploss: 0.00000
==> test epoch 40 avg loss: 1.85986 (A-MSE: 1.66500) avg lploss: 0.00000
*** Best Val Loss: 1.64997 	 Best Test Loss: 1.85986 	 Best epoch 40
Validation loss decreased (1.657031 --> 1.649966).  Saving model ...
train epoch 41 avg loss: 1.38508 (A-MSE: 1.20287) avg lploss: 0.00000
train epoch 42 avg loss: 1.20320 (A-MSE: 1.04882) avg lploss: 0.00000
train epoch 43 avg loss: 1.15794 (A-MSE: 1.01153) avg lploss: 0.00000
train epoch 44 avg loss: 1.23439 (A-MSE: 1.06909) avg lploss: 0.00000
train epoch 45 avg loss: 1.37578 (A-MSE: 1.19487) avg lploss: 0.00000
==> val epoch 45 avg loss: 1.35804 (A-MSE: 1.18135) avg lploss: 0.00000
==> test epoch 45 avg loss: 1.34128 (A-MSE: 1.19538) avg lploss: 0.00000
*** Best Val Loss: 1.35804 	 Best Test Loss: 1.34128 	 Best epoch 45
Validation loss decreased (1.649966 --> 1.358041).  Saving model ...
train epoch 46 avg loss: 1.11964 (A-MSE: 0.97030) avg lploss: 0.00000
train epoch 47 avg loss: 1.12543 (A-MSE: 0.97722) avg lploss: 0.00000
train epoch 48 avg loss: 1.03406 (A-MSE: 0.89594) avg lploss: 0.00000
train epoch 49 avg loss: 1.00118 (A-MSE: 0.86342) avg lploss: 0.00000
train epoch 50 avg loss: 1.04041 (A-MSE: 0.90613) avg lploss: 0.00000
==> val epoch 50 avg loss: 1.12366 (A-MSE: 0.96789) avg lploss: 0.00000
==> test epoch 50 avg loss: 1.17484 (A-MSE: 1.04089) avg lploss: 0.00000
*** Best Val Loss: 1.12366 	 Best Test Loss: 1.17484 	 Best epoch 50
Validation loss decreased (1.358041 --> 1.123665).  Saving model ...
train epoch 51 avg loss: 0.94910 (A-MSE: 0.81638) avg lploss: 0.00000
train epoch 52 avg loss: 1.05858 (A-MSE: 0.90708) avg lploss: 0.00000
train epoch 53 avg loss: 1.12517 (A-MSE: 0.96308) avg lploss: 0.00000
train epoch 54 avg loss: 1.01186 (A-MSE: 0.87773) avg lploss: 0.00000
train epoch 55 avg loss: 0.88065 (A-MSE: 0.76259) avg lploss: 0.00000
==> val epoch 55 avg loss: 1.11613 (A-MSE: 0.95266) avg lploss: 0.00000
==> test epoch 55 avg loss: 1.09550 (A-MSE: 0.96880) avg lploss: 0.00000
*** Best Val Loss: 1.11613 	 Best Test Loss: 1.09550 	 Best epoch 55
Validation loss decreased (1.123665 --> 1.116131).  Saving model ...
train epoch 56 avg loss: 0.82582 (A-MSE: 0.71504) avg lploss: 0.00000
train epoch 57 avg loss: 0.79603 (A-MSE: 0.68659) avg lploss: 0.00000
train epoch 58 avg loss: 0.87820 (A-MSE: 0.76241) avg lploss: 0.00000
train epoch 59 avg loss: 0.86123 (A-MSE: 0.74529) avg lploss: 0.00000
train epoch 60 avg loss: 0.77602 (A-MSE: 0.66888) avg lploss: 0.00000
==> val epoch 60 avg loss: 1.00892 (A-MSE: 0.86010) avg lploss: 0.00000
==> test epoch 60 avg loss: 1.01104 (A-MSE: 0.89205) avg lploss: 0.00000
*** Best Val Loss: 1.00892 	 Best Test Loss: 1.01104 	 Best epoch 60
Validation loss decreased (1.116131 --> 1.008920).  Saving model ...
train epoch 61 avg loss: 0.74216 (A-MSE: 0.64466) avg lploss: 0.00000
train epoch 62 avg loss: 0.67841 (A-MSE: 0.58393) avg lploss: 0.00000
train epoch 63 avg loss: 0.73390 (A-MSE: 0.63826) avg lploss: 0.00000
train epoch 64 avg loss: 0.67280 (A-MSE: 0.58492) avg lploss: 0.00000
train epoch 65 avg loss: 0.64024 (A-MSE: 0.55342) avg lploss: 0.00000
==> val epoch 65 avg loss: 0.80516 (A-MSE: 0.69588) avg lploss: 0.00000
==> test epoch 65 avg loss: 0.82781 (A-MSE: 0.73619) avg lploss: 0.00000
*** Best Val Loss: 0.80516 	 Best Test Loss: 0.82781 	 Best epoch 65
Validation loss decreased (1.008920 --> 0.805156).  Saving model ...
train epoch 66 avg loss: 0.71003 (A-MSE: 0.61797) avg lploss: 0.00000
train epoch 67 avg loss: 0.70222 (A-MSE: 0.60786) avg lploss: 0.00000
train epoch 68 avg loss: 0.61252 (A-MSE: 0.53041) avg lploss: 0.00000
train epoch 69 avg loss: 0.56738 (A-MSE: 0.49100) avg lploss: 0.00000
train epoch 70 avg loss: 0.60185 (A-MSE: 0.52326) avg lploss: 0.00000
==> val epoch 70 avg loss: 0.79092 (A-MSE: 0.69153) avg lploss: 0.00000
==> test epoch 70 avg loss: 0.84368 (A-MSE: 0.75789) avg lploss: 0.00000
*** Best Val Loss: 0.79092 	 Best Test Loss: 0.84368 	 Best epoch 70
Validation loss decreased (0.805156 --> 0.790925).  Saving model ...
train epoch 71 avg loss: 0.58740 (A-MSE: 0.50826) avg lploss: 0.00000
train epoch 72 avg loss: 0.68981 (A-MSE: 0.60505) avg lploss: 0.00000
train epoch 73 avg loss: 0.58152 (A-MSE: 0.50945) avg lploss: 0.00000
train epoch 74 avg loss: 0.57658 (A-MSE: 0.50390) avg lploss: 0.00000
train epoch 75 avg loss: 0.51645 (A-MSE: 0.44698) avg lploss: 0.00000
==> val epoch 75 avg loss: 0.71937 (A-MSE: 0.62518) avg lploss: 0.00000
==> test epoch 75 avg loss: 0.71158 (A-MSE: 0.63109) avg lploss: 0.00000
*** Best Val Loss: 0.71937 	 Best Test Loss: 0.71158 	 Best epoch 75
Validation loss decreased (0.790925 --> 0.719369).  Saving model ...
train epoch 76 avg loss: 0.59079 (A-MSE: 0.51289) avg lploss: 0.00000
train epoch 77 avg loss: 0.70721 (A-MSE: 0.61824) avg lploss: 0.00000
train epoch 78 avg loss: 0.70476 (A-MSE: 0.61910) avg lploss: 0.00000
train epoch 79 avg loss: 0.56669 (A-MSE: 0.49324) avg lploss: 0.00000
train epoch 80 avg loss: 0.54804 (A-MSE: 0.47627) avg lploss: 0.00000
==> val epoch 80 avg loss: 0.68551 (A-MSE: 0.60143) avg lploss: 0.00000
==> test epoch 80 avg loss: 0.72380 (A-MSE: 0.65296) avg lploss: 0.00000
*** Best Val Loss: 0.68551 	 Best Test Loss: 0.72380 	 Best epoch 80
Validation loss decreased (0.719369 --> 0.685508).  Saving model ...
train epoch 81 avg loss: 0.50096 (A-MSE: 0.44183) avg lploss: 0.00000
train epoch 82 avg loss: 0.53466 (A-MSE: 0.46595) avg lploss: 0.00000
train epoch 83 avg loss: 0.52976 (A-MSE: 0.46064) avg lploss: 0.00000
train epoch 84 avg loss: 0.54475 (A-MSE: 0.48026) avg lploss: 0.00000
train epoch 85 avg loss: 0.48512 (A-MSE: 0.42161) avg lploss: 0.00000
==> val epoch 85 avg loss: 0.67756 (A-MSE: 0.59511) avg lploss: 0.00000
==> test epoch 85 avg loss: 0.71612 (A-MSE: 0.64604) avg lploss: 0.00000
*** Best Val Loss: 0.67756 	 Best Test Loss: 0.71612 	 Best epoch 85
Validation loss decreased (0.685508 --> 0.677558).  Saving model ...
train epoch 86 avg loss: 0.41949 (A-MSE: 0.36650) avg lploss: 0.00000
train epoch 87 avg loss: 0.43570 (A-MSE: 0.38320) avg lploss: 0.00000
train epoch 88 avg loss: 0.47766 (A-MSE: 0.42002) avg lploss: 0.00000
train epoch 89 avg loss: 0.49190 (A-MSE: 0.42953) avg lploss: 0.00000
train epoch 90 avg loss: 0.52400 (A-MSE: 0.45725) avg lploss: 0.00000
==> val epoch 90 avg loss: 0.63423 (A-MSE: 0.55363) avg lploss: 0.00000
==> test epoch 90 avg loss: 0.64625 (A-MSE: 0.58116) avg lploss: 0.00000
*** Best Val Loss: 0.63423 	 Best Test Loss: 0.64625 	 Best epoch 90
Validation loss decreased (0.677558 --> 0.634234).  Saving model ...
train epoch 91 avg loss: 0.46060 (A-MSE: 0.40419) avg lploss: 0.00000
train epoch 92 avg loss: 0.45954 (A-MSE: 0.40424) avg lploss: 0.00000
train epoch 93 avg loss: 0.46730 (A-MSE: 0.41008) avg lploss: 0.00000
train epoch 94 avg loss: 0.47387 (A-MSE: 0.41591) avg lploss: 0.00000
train epoch 95 avg loss: 0.46524 (A-MSE: 0.40668) avg lploss: 0.00000
==> val epoch 95 avg loss: 0.65000 (A-MSE: 0.56450) avg lploss: 0.00000
==> test epoch 95 avg loss: 0.66587 (A-MSE: 0.58510) avg lploss: 0.00000
*** Best Val Loss: 0.63423 	 Best Test Loss: 0.64625 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 0.46838 (A-MSE: 0.41125) avg lploss: 0.00000
train epoch 97 avg loss: 0.41363 (A-MSE: 0.36386) avg lploss: 0.00000
train epoch 98 avg loss: 0.48411 (A-MSE: 0.42724) avg lploss: 0.00000
train epoch 99 avg loss: 0.46165 (A-MSE: 0.40492) avg lploss: 0.00000
train epoch 100 avg loss: 0.47019 (A-MSE: 0.41090) avg lploss: 0.00000
==> val epoch 100 avg loss: 0.64222 (A-MSE: 0.54915) avg lploss: 0.00000
==> test epoch 100 avg loss: 0.66235 (A-MSE: 0.57658) avg lploss: 0.00000
*** Best Val Loss: 0.63423 	 Best Test Loss: 0.64625 	 Best epoch 90
EarlyStopping counter: 2 out of 50
train epoch 101 avg loss: 0.42179 (A-MSE: 0.36993) avg lploss: 0.00000
train epoch 102 avg loss: 0.41034 (A-MSE: 0.35706) avg lploss: 0.00000
train epoch 103 avg loss: 0.39081 (A-MSE: 0.34249) avg lploss: 0.00000
train epoch 104 avg loss: 0.37304 (A-MSE: 0.32502) avg lploss: 0.00000
train epoch 105 avg loss: 0.39526 (A-MSE: 0.34606) avg lploss: 0.00000
==> val epoch 105 avg loss: 0.55722 (A-MSE: 0.48714) avg lploss: 0.00000
==> test epoch 105 avg loss: 0.57704 (A-MSE: 0.50945) avg lploss: 0.00000
*** Best Val Loss: 0.55722 	 Best Test Loss: 0.57704 	 Best epoch 105
Validation loss decreased (0.634234 --> 0.557222).  Saving model ...
train epoch 106 avg loss: 0.37446 (A-MSE: 0.32623) avg lploss: 0.00000
train epoch 107 avg loss: 0.37311 (A-MSE: 0.32561) avg lploss: 0.00000
train epoch 108 avg loss: 0.38226 (A-MSE: 0.33845) avg lploss: 0.00000
train epoch 109 avg loss: 0.38873 (A-MSE: 0.34019) avg lploss: 0.00000
train epoch 110 avg loss: 0.35097 (A-MSE: 0.30675) avg lploss: 0.00000
==> val epoch 110 avg loss: 0.58076 (A-MSE: 0.50691) avg lploss: 0.00000
==> test epoch 110 avg loss: 0.62304 (A-MSE: 0.55688) avg lploss: 0.00000
*** Best Val Loss: 0.55722 	 Best Test Loss: 0.57704 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 0.38797 (A-MSE: 0.33934) avg lploss: 0.00000
train epoch 112 avg loss: 0.37084 (A-MSE: 0.32670) avg lploss: 0.00000
train epoch 113 avg loss: 0.38337 (A-MSE: 0.33828) avg lploss: 0.00000
train epoch 114 avg loss: 0.36501 (A-MSE: 0.32030) avg lploss: 0.00000
train epoch 115 avg loss: 0.39395 (A-MSE: 0.34550) avg lploss: 0.00000
==> val epoch 115 avg loss: 0.73071 (A-MSE: 0.64282) avg lploss: 0.00000
==> test epoch 115 avg loss: 0.70212 (A-MSE: 0.63656) avg lploss: 0.00000
*** Best Val Loss: 0.55722 	 Best Test Loss: 0.57704 	 Best epoch 105
EarlyStopping counter: 2 out of 50
train epoch 116 avg loss: 0.41085 (A-MSE: 0.36083) avg lploss: 0.00000
train epoch 117 avg loss: 0.41679 (A-MSE: 0.36197) avg lploss: 0.00000
train epoch 118 avg loss: 0.38537 (A-MSE: 0.33909) avg lploss: 0.00000
train epoch 119 avg loss: 0.39078 (A-MSE: 0.34593) avg lploss: 0.00000
train epoch 120 avg loss: 0.37725 (A-MSE: 0.32997) avg lploss: 0.00000
==> val epoch 120 avg loss: 0.51126 (A-MSE: 0.44064) avg lploss: 0.00000
==> test epoch 120 avg loss: 0.54546 (A-MSE: 0.47583) avg lploss: 0.00000
*** Best Val Loss: 0.51126 	 Best Test Loss: 0.54546 	 Best epoch 120
Validation loss decreased (0.557222 --> 0.511256).  Saving model ...
train epoch 121 avg loss: 0.40453 (A-MSE: 0.35428) avg lploss: 0.00000
train epoch 122 avg loss: 0.37350 (A-MSE: 0.32813) avg lploss: 0.00000
train epoch 123 avg loss: 0.38604 (A-MSE: 0.33829) avg lploss: 0.00000
train epoch 124 avg loss: 0.42387 (A-MSE: 0.37570) avg lploss: 0.00000
train epoch 125 avg loss: 0.37686 (A-MSE: 0.32907) avg lploss: 0.00000
==> val epoch 125 avg loss: 0.54970 (A-MSE: 0.47374) avg lploss: 0.00000
==> test epoch 125 avg loss: 0.53068 (A-MSE: 0.46454) avg lploss: 0.00000
*** Best Val Loss: 0.51126 	 Best Test Loss: 0.54546 	 Best epoch 120
EarlyStopping counter: 1 out of 50
train epoch 126 avg loss: 0.32555 (A-MSE: 0.28380) avg lploss: 0.00000
train epoch 127 avg loss: 0.34658 (A-MSE: 0.30242) avg lploss: 0.00000
train epoch 128 avg loss: 0.38571 (A-MSE: 0.33799) avg lploss: 0.00000
train epoch 129 avg loss: 0.33254 (A-MSE: 0.29065) avg lploss: 0.00000
train epoch 130 avg loss: 0.35962 (A-MSE: 0.31486) avg lploss: 0.00000
==> val epoch 130 avg loss: 0.50720 (A-MSE: 0.44654) avg lploss: 0.00000
==> test epoch 130 avg loss: 0.54318 (A-MSE: 0.49234) avg lploss: 0.00000
*** Best Val Loss: 0.50720 	 Best Test Loss: 0.54318 	 Best epoch 130
Validation loss decreased (0.511256 --> 0.507197).  Saving model ...
train epoch 131 avg loss: 0.35963 (A-MSE: 0.31792) avg lploss: 0.00000
train epoch 132 avg loss: 0.34163 (A-MSE: 0.29933) avg lploss: 0.00000
train epoch 133 avg loss: 0.31134 (A-MSE: 0.27353) avg lploss: 0.00000
train epoch 134 avg loss: 0.32320 (A-MSE: 0.28197) avg lploss: 0.00000
train epoch 135 avg loss: 0.31440 (A-MSE: 0.27640) avg lploss: 0.00000
==> val epoch 135 avg loss: 0.52217 (A-MSE: 0.44670) avg lploss: 0.00000
==> test epoch 135 avg loss: 0.54699 (A-MSE: 0.47377) avg lploss: 0.00000
*** Best Val Loss: 0.50720 	 Best Test Loss: 0.54318 	 Best epoch 130
EarlyStopping counter: 1 out of 50
train epoch 136 avg loss: 0.38659 (A-MSE: 0.33690) avg lploss: 0.00000
train epoch 137 avg loss: 0.32897 (A-MSE: 0.29027) avg lploss: 0.00000
train epoch 138 avg loss: 0.31413 (A-MSE: 0.27590) avg lploss: 0.00000
train epoch 139 avg loss: 0.29570 (A-MSE: 0.25957) avg lploss: 0.00000
train epoch 140 avg loss: 0.32626 (A-MSE: 0.28481) avg lploss: 0.00000
==> val epoch 140 avg loss: 0.56049 (A-MSE: 0.49390) avg lploss: 0.00000
==> test epoch 140 avg loss: 0.56927 (A-MSE: 0.51066) avg lploss: 0.00000
*** Best Val Loss: 0.50720 	 Best Test Loss: 0.54318 	 Best epoch 130
EarlyStopping counter: 2 out of 50
train epoch 141 avg loss: 0.36079 (A-MSE: 0.31889) avg lploss: 0.00000
train epoch 142 avg loss: 0.33383 (A-MSE: 0.29168) avg lploss: 0.00000
train epoch 143 avg loss: 0.31906 (A-MSE: 0.27862) avg lploss: 0.00000
train epoch 144 avg loss: 0.32101 (A-MSE: 0.28136) avg lploss: 0.00000
train epoch 145 avg loss: 0.29084 (A-MSE: 0.25462) avg lploss: 0.00000
==> val epoch 145 avg loss: 0.45196 (A-MSE: 0.39039) avg lploss: 0.00000
==> test epoch 145 avg loss: 0.48152 (A-MSE: 0.42664) avg lploss: 0.00000
*** Best Val Loss: 0.45196 	 Best Test Loss: 0.48152 	 Best epoch 145
Validation loss decreased (0.507197 --> 0.451957).  Saving model ...
train epoch 146 avg loss: 0.31429 (A-MSE: 0.27473) avg lploss: 0.00000
train epoch 147 avg loss: 0.34212 (A-MSE: 0.29955) avg lploss: 0.00000
train epoch 148 avg loss: 0.31660 (A-MSE: 0.27648) avg lploss: 0.00000
train epoch 149 avg loss: 0.27056 (A-MSE: 0.23645) avg lploss: 0.00000
train epoch 150 avg loss: 0.26316 (A-MSE: 0.23138) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.44191 (A-MSE: 0.38123) avg lploss: 0.00000
==> test epoch 150 avg loss: 0.46934 (A-MSE: 0.41254) avg lploss: 0.00000
*** Best Val Loss: 0.44191 	 Best Test Loss: 0.46934 	 Best epoch 150
Validation loss decreased (0.451957 --> 0.441906).  Saving model ...
train epoch 151 avg loss: 0.30436 (A-MSE: 0.26618) avg lploss: 0.00000
train epoch 152 avg loss: 0.30067 (A-MSE: 0.26184) avg lploss: 0.00000
train epoch 153 avg loss: 0.27831 (A-MSE: 0.24643) avg lploss: 0.00000
train epoch 154 avg loss: 0.26757 (A-MSE: 0.23310) avg lploss: 0.00000
train epoch 155 avg loss: 0.27316 (A-MSE: 0.24013) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.44481 (A-MSE: 0.38260) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.44830 (A-MSE: 0.39670) avg lploss: 0.00000
*** Best Val Loss: 0.44191 	 Best Test Loss: 0.46934 	 Best epoch 150
EarlyStopping counter: 1 out of 50
train epoch 156 avg loss: 0.28963 (A-MSE: 0.25431) avg lploss: 0.00000
train epoch 157 avg loss: 0.26941 (A-MSE: 0.23695) avg lploss: 0.00000
train epoch 158 avg loss: 0.27062 (A-MSE: 0.23591) avg lploss: 0.00000
train epoch 159 avg loss: 0.31604 (A-MSE: 0.27599) avg lploss: 0.00000
train epoch 160 avg loss: 0.31481 (A-MSE: 0.27484) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.52101 (A-MSE: 0.45509) avg lploss: 0.00000
==> test epoch 160 avg loss: 0.54715 (A-MSE: 0.48021) avg lploss: 0.00000
*** Best Val Loss: 0.44191 	 Best Test Loss: 0.46934 	 Best epoch 150
EarlyStopping counter: 2 out of 50
train epoch 161 avg loss: 0.27936 (A-MSE: 0.24542) avg lploss: 0.00000
train epoch 162 avg loss: 0.28250 (A-MSE: 0.24614) avg lploss: 0.00000
train epoch 163 avg loss: 0.24614 (A-MSE: 0.21542) avg lploss: 0.00000
train epoch 164 avg loss: 0.25888 (A-MSE: 0.22712) avg lploss: 0.00000
train epoch 165 avg loss: 0.26677 (A-MSE: 0.23383) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.54483 (A-MSE: 0.46351) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.52928 (A-MSE: 0.46604) avg lploss: 0.00000
*** Best Val Loss: 0.44191 	 Best Test Loss: 0.46934 	 Best epoch 150
EarlyStopping counter: 3 out of 50
train epoch 166 avg loss: 0.28030 (A-MSE: 0.24454) avg lploss: 0.00000
train epoch 167 avg loss: 0.26455 (A-MSE: 0.23194) avg lploss: 0.00000
train epoch 168 avg loss: 0.26611 (A-MSE: 0.23284) avg lploss: 0.00000
train epoch 169 avg loss: 0.28491 (A-MSE: 0.25171) avg lploss: 0.00000
train epoch 170 avg loss: 0.29792 (A-MSE: 0.26085) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.55669 (A-MSE: 0.48198) avg lploss: 0.00000
==> test epoch 170 avg loss: 0.55816 (A-MSE: 0.48841) avg lploss: 0.00000
*** Best Val Loss: 0.44191 	 Best Test Loss: 0.46934 	 Best epoch 150
EarlyStopping counter: 4 out of 50
train epoch 171 avg loss: 0.38346 (A-MSE: 0.33308) avg lploss: 0.00000
train epoch 172 avg loss: 0.32179 (A-MSE: 0.28437) avg lploss: 0.00000
train epoch 173 avg loss: 0.28385 (A-MSE: 0.25017) avg lploss: 0.00000
train epoch 174 avg loss: 0.29083 (A-MSE: 0.25188) avg lploss: 0.00000
train epoch 175 avg loss: 0.27398 (A-MSE: 0.23930) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.42044 (A-MSE: 0.36717) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.42442 (A-MSE: 0.38154) avg lploss: 0.00000
*** Best Val Loss: 0.42044 	 Best Test Loss: 0.42442 	 Best epoch 175
Validation loss decreased (0.441906 --> 0.420438).  Saving model ...
train epoch 176 avg loss: 0.26210 (A-MSE: 0.23126) avg lploss: 0.00000
train epoch 177 avg loss: 0.26586 (A-MSE: 0.23355) avg lploss: 0.00000
train epoch 178 avg loss: 0.27889 (A-MSE: 0.24456) avg lploss: 0.00000
train epoch 179 avg loss: 0.26482 (A-MSE: 0.23158) avg lploss: 0.00000
train epoch 180 avg loss: 0.23785 (A-MSE: 0.20970) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.45466 (A-MSE: 0.39637) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.47175 (A-MSE: 0.41936) avg lploss: 0.00000
*** Best Val Loss: 0.42044 	 Best Test Loss: 0.42442 	 Best epoch 175
EarlyStopping counter: 1 out of 50
train epoch 181 avg loss: 0.26602 (A-MSE: 0.23502) avg lploss: 0.00000
train epoch 182 avg loss: 0.26840 (A-MSE: 0.23367) avg lploss: 0.00000
train epoch 183 avg loss: 0.26264 (A-MSE: 0.23053) avg lploss: 0.00000
train epoch 184 avg loss: 0.24386 (A-MSE: 0.21546) avg lploss: 0.00000
train epoch 185 avg loss: 0.26942 (A-MSE: 0.23758) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.45374 (A-MSE: 0.38993) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.44637 (A-MSE: 0.39084) avg lploss: 0.00000
*** Best Val Loss: 0.42044 	 Best Test Loss: 0.42442 	 Best epoch 175
EarlyStopping counter: 2 out of 50
train epoch 186 avg loss: 0.26487 (A-MSE: 0.23128) avg lploss: 0.00000
train epoch 187 avg loss: 0.24606 (A-MSE: 0.21438) avg lploss: 0.00000
train epoch 188 avg loss: 0.23436 (A-MSE: 0.20404) avg lploss: 0.00000
train epoch 189 avg loss: 0.25523 (A-MSE: 0.22342) avg lploss: 0.00000
train epoch 190 avg loss: 0.23668 (A-MSE: 0.20705) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.41462 (A-MSE: 0.36691) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.45336 (A-MSE: 0.40992) avg lploss: 0.00000
*** Best Val Loss: 0.41462 	 Best Test Loss: 0.45336 	 Best epoch 190
Validation loss decreased (0.420438 --> 0.414620).  Saving model ...
train epoch 191 avg loss: 0.21334 (A-MSE: 0.18796) avg lploss: 0.00000
train epoch 192 avg loss: 0.24229 (A-MSE: 0.21176) avg lploss: 0.00000
train epoch 193 avg loss: 0.26399 (A-MSE: 0.22896) avg lploss: 0.00000
train epoch 194 avg loss: 0.28763 (A-MSE: 0.25066) avg lploss: 0.00000
train epoch 195 avg loss: 0.26835 (A-MSE: 0.23627) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.41864 (A-MSE: 0.36128) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.42263 (A-MSE: 0.37607) avg lploss: 0.00000
*** Best Val Loss: 0.41462 	 Best Test Loss: 0.45336 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 0.29426 (A-MSE: 0.25643) avg lploss: 0.00000
train epoch 197 avg loss: 0.25918 (A-MSE: 0.22719) avg lploss: 0.00000
train epoch 198 avg loss: 0.23217 (A-MSE: 0.20407) avg lploss: 0.00000
train epoch 199 avg loss: 0.24391 (A-MSE: 0.21289) avg lploss: 0.00000
train epoch 200 avg loss: 0.24044 (A-MSE: 0.21097) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.40967 (A-MSE: 0.35643) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.41195 (A-MSE: 0.37241) avg lploss: 0.00000
*** Best Val Loss: 0.40967 	 Best Test Loss: 0.41195 	 Best epoch 200
Validation loss decreased (0.414620 --> 0.409671).  Saving model ...
train epoch 201 avg loss: 0.22345 (A-MSE: 0.19599) avg lploss: 0.00000
train epoch 202 avg loss: 0.23713 (A-MSE: 0.20815) avg lploss: 0.00000
train epoch 203 avg loss: 0.24461 (A-MSE: 0.21508) avg lploss: 0.00000
train epoch 204 avg loss: 0.24427 (A-MSE: 0.21393) avg lploss: 0.00000
train epoch 205 avg loss: 0.25294 (A-MSE: 0.22352) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.47555 (A-MSE: 0.41301) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.45365 (A-MSE: 0.39778) avg lploss: 0.00000
*** Best Val Loss: 0.40967 	 Best Test Loss: 0.41195 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 0.22442 (A-MSE: 0.19616) avg lploss: 0.00000
train epoch 207 avg loss: 0.22316 (A-MSE: 0.19586) avg lploss: 0.00000
train epoch 208 avg loss: 0.22162 (A-MSE: 0.19397) avg lploss: 0.00000
train epoch 209 avg loss: 0.24819 (A-MSE: 0.21602) avg lploss: 0.00000
train epoch 210 avg loss: 0.23385 (A-MSE: 0.20605) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.42468 (A-MSE: 0.36643) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.41290 (A-MSE: 0.36477) avg lploss: 0.00000
*** Best Val Loss: 0.40967 	 Best Test Loss: 0.41195 	 Best epoch 200
EarlyStopping counter: 2 out of 50
train epoch 211 avg loss: 0.23418 (A-MSE: 0.20379) avg lploss: 0.00000
train epoch 212 avg loss: 0.22708 (A-MSE: 0.19977) avg lploss: 0.00000
train epoch 213 avg loss: 0.20854 (A-MSE: 0.18265) avg lploss: 0.00000
train epoch 214 avg loss: 0.21521 (A-MSE: 0.18845) avg lploss: 0.00000
train epoch 215 avg loss: 0.21263 (A-MSE: 0.18570) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.41641 (A-MSE: 0.35866) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.40863 (A-MSE: 0.36069) avg lploss: 0.00000
*** Best Val Loss: 0.40967 	 Best Test Loss: 0.41195 	 Best epoch 200
EarlyStopping counter: 3 out of 50
train epoch 216 avg loss: 0.21373 (A-MSE: 0.18748) avg lploss: 0.00000
train epoch 217 avg loss: 0.22868 (A-MSE: 0.20053) avg lploss: 0.00000
train epoch 218 avg loss: 0.22926 (A-MSE: 0.19895) avg lploss: 0.00000
train epoch 219 avg loss: 0.22508 (A-MSE: 0.19803) avg lploss: 0.00000
train epoch 220 avg loss: 0.22384 (A-MSE: 0.19723) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.41577 (A-MSE: 0.36141) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.44380 (A-MSE: 0.39389) avg lploss: 0.00000
*** Best Val Loss: 0.40967 	 Best Test Loss: 0.41195 	 Best epoch 200
EarlyStopping counter: 4 out of 50
train epoch 221 avg loss: 0.21059 (A-MSE: 0.18405) avg lploss: 0.00000
train epoch 222 avg loss: 0.22976 (A-MSE: 0.20011) avg lploss: 0.00000
train epoch 223 avg loss: 0.21429 (A-MSE: 0.18781) avg lploss: 0.00000
train epoch 224 avg loss: 0.25414 (A-MSE: 0.22299) avg lploss: 0.00000
train epoch 225 avg loss: 0.23859 (A-MSE: 0.20918) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.48722 (A-MSE: 0.42610) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.53773 (A-MSE: 0.47764) avg lploss: 0.00000
*** Best Val Loss: 0.40967 	 Best Test Loss: 0.41195 	 Best epoch 200
EarlyStopping counter: 5 out of 50
train epoch 226 avg loss: 0.26080 (A-MSE: 0.23120) avg lploss: 0.00000
train epoch 227 avg loss: 0.22684 (A-MSE: 0.19684) avg lploss: 0.00000
train epoch 228 avg loss: 0.23213 (A-MSE: 0.20565) avg lploss: 0.00000
train epoch 229 avg loss: 0.21785 (A-MSE: 0.19057) avg lploss: 0.00000
train epoch 230 avg loss: 0.24135 (A-MSE: 0.21271) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.38485 (A-MSE: 0.33082) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.39305 (A-MSE: 0.34962) avg lploss: 0.00000
*** Best Val Loss: 0.38485 	 Best Test Loss: 0.39305 	 Best epoch 230
Validation loss decreased (0.409671 --> 0.384850).  Saving model ...
train epoch 231 avg loss: 0.22350 (A-MSE: 0.19671) avg lploss: 0.00000
train epoch 232 avg loss: 0.23874 (A-MSE: 0.20916) avg lploss: 0.00000
train epoch 233 avg loss: 0.26023 (A-MSE: 0.22881) avg lploss: 0.00000
train epoch 234 avg loss: 0.21619 (A-MSE: 0.19065) avg lploss: 0.00000
train epoch 235 avg loss: 0.19467 (A-MSE: 0.17004) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.38185 (A-MSE: 0.33045) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.38476 (A-MSE: 0.34318) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
Validation loss decreased (0.384850 --> 0.381853).  Saving model ...
train epoch 236 avg loss: 0.20793 (A-MSE: 0.18252) avg lploss: 0.00000
train epoch 237 avg loss: 0.20509 (A-MSE: 0.17866) avg lploss: 0.00000
train epoch 238 avg loss: 0.22805 (A-MSE: 0.19897) avg lploss: 0.00000
train epoch 239 avg loss: 0.20282 (A-MSE: 0.17851) avg lploss: 0.00000
train epoch 240 avg loss: 0.19034 (A-MSE: 0.16778) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.42985 (A-MSE: 0.37329) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.41929 (A-MSE: 0.37149) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.21697 (A-MSE: 0.18951) avg lploss: 0.00000
train epoch 242 avg loss: 0.24479 (A-MSE: 0.21532) avg lploss: 0.00000
train epoch 243 avg loss: 0.26067 (A-MSE: 0.22698) avg lploss: 0.00000
train epoch 244 avg loss: 0.22547 (A-MSE: 0.19639) avg lploss: 0.00000
train epoch 245 avg loss: 0.21195 (A-MSE: 0.18733) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.39733 (A-MSE: 0.34139) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.38367 (A-MSE: 0.33959) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.21693 (A-MSE: 0.19000) avg lploss: 0.00000
train epoch 247 avg loss: 0.20717 (A-MSE: 0.18145) avg lploss: 0.00000
train epoch 248 avg loss: 0.21891 (A-MSE: 0.19025) avg lploss: 0.00000
train epoch 249 avg loss: 0.19005 (A-MSE: 0.16704) avg lploss: 0.00000
train epoch 250 avg loss: 0.20688 (A-MSE: 0.18204) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.41835 (A-MSE: 0.35502) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.43063 (A-MSE: 0.37364) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 0.21506 (A-MSE: 0.18680) avg lploss: 0.00000
train epoch 252 avg loss: 0.19434 (A-MSE: 0.17027) avg lploss: 0.00000
train epoch 253 avg loss: 0.20576 (A-MSE: 0.18024) avg lploss: 0.00000
train epoch 254 avg loss: 0.20330 (A-MSE: 0.17864) avg lploss: 0.00000
train epoch 255 avg loss: 0.18601 (A-MSE: 0.16345) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.38559 (A-MSE: 0.34083) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.37427 (A-MSE: 0.33457) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
EarlyStopping counter: 4 out of 50
train epoch 256 avg loss: 0.22459 (A-MSE: 0.19762) avg lploss: 0.00000
train epoch 257 avg loss: 0.25923 (A-MSE: 0.22687) avg lploss: 0.00000
train epoch 258 avg loss: 0.22083 (A-MSE: 0.19494) avg lploss: 0.00000
train epoch 259 avg loss: 0.20798 (A-MSE: 0.18274) avg lploss: 0.00000
train epoch 260 avg loss: 0.20399 (A-MSE: 0.17985) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.44928 (A-MSE: 0.38261) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.42377 (A-MSE: 0.36702) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
EarlyStopping counter: 5 out of 50
train epoch 261 avg loss: 0.19495 (A-MSE: 0.17128) avg lploss: 0.00000
train epoch 262 avg loss: 0.18673 (A-MSE: 0.16250) avg lploss: 0.00000
train epoch 263 avg loss: 0.21807 (A-MSE: 0.19117) avg lploss: 0.00000
train epoch 264 avg loss: 0.21167 (A-MSE: 0.18491) avg lploss: 0.00000
train epoch 265 avg loss: 0.18434 (A-MSE: 0.16226) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.40193 (A-MSE: 0.34442) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.39094 (A-MSE: 0.33820) avg lploss: 0.00000
*** Best Val Loss: 0.38185 	 Best Test Loss: 0.38476 	 Best epoch 235
EarlyStopping counter: 6 out of 50
train epoch 266 avg loss: 0.17572 (A-MSE: 0.15281) avg lploss: 0.00000
train epoch 267 avg loss: 0.17047 (A-MSE: 0.15020) avg lploss: 0.00000
train epoch 268 avg loss: 0.17392 (A-MSE: 0.15348) avg lploss: 0.00000
train epoch 269 avg loss: 0.18957 (A-MSE: 0.16803) avg lploss: 0.00000
train epoch 270 avg loss: 0.17682 (A-MSE: 0.15542) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.37668 (A-MSE: 0.32918) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.38942 (A-MSE: 0.35194) avg lploss: 0.00000
*** Best Val Loss: 0.37668 	 Best Test Loss: 0.38942 	 Best epoch 270
Validation loss decreased (0.381853 --> 0.376684).  Saving model ...
train epoch 271 avg loss: 0.18166 (A-MSE: 0.15868) avg lploss: 0.00000
train epoch 272 avg loss: 0.20752 (A-MSE: 0.18292) avg lploss: 0.00000
train epoch 273 avg loss: 0.18171 (A-MSE: 0.15878) avg lploss: 0.00000
train epoch 274 avg loss: 0.18984 (A-MSE: 0.16715) avg lploss: 0.00000
train epoch 275 avg loss: 0.18785 (A-MSE: 0.16454) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.35457 (A-MSE: 0.31401) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.36400 (A-MSE: 0.32897) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
Validation loss decreased (0.376684 --> 0.354571).  Saving model ...
train epoch 276 avg loss: 0.17878 (A-MSE: 0.15551) avg lploss: 0.00000
train epoch 277 avg loss: 0.17601 (A-MSE: 0.15478) avg lploss: 0.00000
train epoch 278 avg loss: 0.17798 (A-MSE: 0.15654) avg lploss: 0.00000
train epoch 279 avg loss: 0.16987 (A-MSE: 0.14880) avg lploss: 0.00000
train epoch 280 avg loss: 0.16109 (A-MSE: 0.14201) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.36899 (A-MSE: 0.31615) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.38088 (A-MSE: 0.33420) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 0.17330 (A-MSE: 0.15104) avg lploss: 0.00000
train epoch 282 avg loss: 0.15574 (A-MSE: 0.13742) avg lploss: 0.00000
train epoch 283 avg loss: 0.16991 (A-MSE: 0.14882) avg lploss: 0.00000
train epoch 284 avg loss: 0.18493 (A-MSE: 0.16238) avg lploss: 0.00000
train epoch 285 avg loss: 0.17428 (A-MSE: 0.15429) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.41035 (A-MSE: 0.35521) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.38470 (A-MSE: 0.34924) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 0.18468 (A-MSE: 0.16318) avg lploss: 0.00000
train epoch 287 avg loss: 0.20561 (A-MSE: 0.18031) avg lploss: 0.00000
train epoch 288 avg loss: 0.18650 (A-MSE: 0.16410) avg lploss: 0.00000
train epoch 289 avg loss: 0.19969 (A-MSE: 0.17680) avg lploss: 0.00000
train epoch 290 avg loss: 0.17535 (A-MSE: 0.15560) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.38997 (A-MSE: 0.33935) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.37869 (A-MSE: 0.33595) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 3 out of 50
train epoch 291 avg loss: 0.16977 (A-MSE: 0.14813) avg lploss: 0.00000
train epoch 292 avg loss: 0.19087 (A-MSE: 0.16715) avg lploss: 0.00000
train epoch 293 avg loss: 0.18815 (A-MSE: 0.16576) avg lploss: 0.00000
train epoch 294 avg loss: 0.19596 (A-MSE: 0.17184) avg lploss: 0.00000
train epoch 295 avg loss: 0.19005 (A-MSE: 0.16757) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.41446 (A-MSE: 0.35387) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.41647 (A-MSE: 0.36641) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 4 out of 50
train epoch 296 avg loss: 0.15775 (A-MSE: 0.13935) avg lploss: 0.00000
train epoch 297 avg loss: 0.15434 (A-MSE: 0.13554) avg lploss: 0.00000
train epoch 298 avg loss: 0.17190 (A-MSE: 0.15111) avg lploss: 0.00000
train epoch 299 avg loss: 0.15169 (A-MSE: 0.13334) avg lploss: 0.00000
train epoch 300 avg loss: 0.15994 (A-MSE: 0.14037) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.39128 (A-MSE: 0.33884) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.38714 (A-MSE: 0.34144) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 5 out of 50
train epoch 301 avg loss: 0.20663 (A-MSE: 0.18214) avg lploss: 0.00000
train epoch 302 avg loss: 0.20661 (A-MSE: 0.18190) avg lploss: 0.00000
train epoch 303 avg loss: 0.17555 (A-MSE: 0.15520) avg lploss: 0.00000
train epoch 304 avg loss: 0.18911 (A-MSE: 0.16570) avg lploss: 0.00000
train epoch 305 avg loss: 0.16893 (A-MSE: 0.14812) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.41879 (A-MSE: 0.36510) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.44233 (A-MSE: 0.39531) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 6 out of 50
train epoch 306 avg loss: 0.15738 (A-MSE: 0.13875) avg lploss: 0.00000
train epoch 307 avg loss: 0.16759 (A-MSE: 0.14666) avg lploss: 0.00000
train epoch 308 avg loss: 0.21073 (A-MSE: 0.18352) avg lploss: 0.00000
train epoch 309 avg loss: 0.20814 (A-MSE: 0.18390) avg lploss: 0.00000
train epoch 310 avg loss: 0.17994 (A-MSE: 0.15722) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.39806 (A-MSE: 0.34287) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.38758 (A-MSE: 0.34228) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 7 out of 50
train epoch 311 avg loss: 0.19480 (A-MSE: 0.17246) avg lploss: 0.00000
train epoch 312 avg loss: 0.20081 (A-MSE: 0.17736) avg lploss: 0.00000
train epoch 313 avg loss: 0.18945 (A-MSE: 0.16521) avg lploss: 0.00000
train epoch 314 avg loss: 0.18000 (A-MSE: 0.15938) avg lploss: 0.00000
train epoch 315 avg loss: 0.18112 (A-MSE: 0.16011) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.38324 (A-MSE: 0.33498) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.36832 (A-MSE: 0.33117) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 8 out of 50
train epoch 316 avg loss: 0.16895 (A-MSE: 0.14964) avg lploss: 0.00000
train epoch 317 avg loss: 0.18870 (A-MSE: 0.16473) avg lploss: 0.00000
train epoch 318 avg loss: 0.16600 (A-MSE: 0.14713) avg lploss: 0.00000
train epoch 319 avg loss: 0.17507 (A-MSE: 0.15370) avg lploss: 0.00000
train epoch 320 avg loss: 0.17127 (A-MSE: 0.15109) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.37378 (A-MSE: 0.32141) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.39195 (A-MSE: 0.34241) avg lploss: 0.00000
*** Best Val Loss: 0.35457 	 Best Test Loss: 0.36400 	 Best epoch 275
EarlyStopping counter: 9 out of 50
train epoch 321 avg loss: 0.19396 (A-MSE: 0.17110) avg lploss: 0.00000
train epoch 322 avg loss: 0.18617 (A-MSE: 0.16379) avg lploss: 0.00000
train epoch 323 avg loss: 0.19483 (A-MSE: 0.16992) avg lploss: 0.00000
train epoch 324 avg loss: 0.18049 (A-MSE: 0.16007) avg lploss: 0.00000
train epoch 325 avg loss: 0.16094 (A-MSE: 0.14129) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.33877 (A-MSE: 0.29284) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.36045 (A-MSE: 0.32015) avg lploss: 0.00000
*** Best Val Loss: 0.33877 	 Best Test Loss: 0.36045 	 Best epoch 325
Validation loss decreased (0.354571 --> 0.338765).  Saving model ...
train epoch 326 avg loss: 0.15068 (A-MSE: 0.13255) avg lploss: 0.00000
train epoch 327 avg loss: 0.15955 (A-MSE: 0.14114) avg lploss: 0.00000
train epoch 328 avg loss: 0.14114 (A-MSE: 0.12400) avg lploss: 0.00000
train epoch 329 avg loss: 0.13672 (A-MSE: 0.12032) avg lploss: 0.00000
train epoch 330 avg loss: 0.14926 (A-MSE: 0.13073) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.39001 (A-MSE: 0.33982) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.39417 (A-MSE: 0.35233) avg lploss: 0.00000
*** Best Val Loss: 0.33877 	 Best Test Loss: 0.36045 	 Best epoch 325
EarlyStopping counter: 1 out of 50
train epoch 331 avg loss: 0.16055 (A-MSE: 0.14170) avg lploss: 0.00000
train epoch 332 avg loss: 0.19318 (A-MSE: 0.16862) avg lploss: 0.00000
train epoch 333 avg loss: 0.21126 (A-MSE: 0.18737) avg lploss: 0.00000
train epoch 334 avg loss: 0.18603 (A-MSE: 0.16464) avg lploss: 0.00000
train epoch 335 avg loss: 0.16906 (A-MSE: 0.14894) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.45994 (A-MSE: 0.39788) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.44999 (A-MSE: 0.39714) avg lploss: 0.00000
*** Best Val Loss: 0.33877 	 Best Test Loss: 0.36045 	 Best epoch 325
EarlyStopping counter: 2 out of 50
train epoch 336 avg loss: 0.16519 (A-MSE: 0.14643) avg lploss: 0.00000
train epoch 337 avg loss: 0.16265 (A-MSE: 0.14257) avg lploss: 0.00000
train epoch 338 avg loss: 0.19612 (A-MSE: 0.17302) avg lploss: 0.00000
train epoch 339 avg loss: 0.15776 (A-MSE: 0.13898) avg lploss: 0.00000
train epoch 340 avg loss: 0.16142 (A-MSE: 0.14139) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.35890 (A-MSE: 0.31656) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.37983 (A-MSE: 0.33900) avg lploss: 0.00000
*** Best Val Loss: 0.33877 	 Best Test Loss: 0.36045 	 Best epoch 325
EarlyStopping counter: 3 out of 50
train epoch 341 avg loss: 0.17924 (A-MSE: 0.15779) avg lploss: 0.00000
train epoch 342 avg loss: 0.18681 (A-MSE: 0.16389) avg lploss: 0.00000
train epoch 343 avg loss: 0.19895 (A-MSE: 0.17527) avg lploss: 0.00000
train epoch 344 avg loss: 0.18037 (A-MSE: 0.15916) avg lploss: 0.00000
train epoch 345 avg loss: 0.18643 (A-MSE: 0.16498) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.37428 (A-MSE: 0.33267) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.38765 (A-MSE: 0.35673) avg lploss: 0.00000
*** Best Val Loss: 0.33877 	 Best Test Loss: 0.36045 	 Best epoch 325
EarlyStopping counter: 4 out of 50
train epoch 346 avg loss: 0.15686 (A-MSE: 0.13878) avg lploss: 0.00000
train epoch 347 avg loss: 0.14373 (A-MSE: 0.12612) avg lploss: 0.00000
train epoch 348 avg loss: 0.13909 (A-MSE: 0.12345) avg lploss: 0.00000
train epoch 349 avg loss: 0.15450 (A-MSE: 0.13664) avg lploss: 0.00000
train epoch 350 avg loss: 0.15684 (A-MSE: 0.13840) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.32861 (A-MSE: 0.28898) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.34940 (A-MSE: 0.31446) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
Validation loss decreased (0.338765 --> 0.328609).  Saving model ...
train epoch 351 avg loss: 0.16046 (A-MSE: 0.14183) avg lploss: 0.00000
train epoch 352 avg loss: 0.22438 (A-MSE: 0.19851) avg lploss: 0.00000
train epoch 353 avg loss: 0.18312 (A-MSE: 0.16231) avg lploss: 0.00000
train epoch 354 avg loss: 0.15183 (A-MSE: 0.13297) avg lploss: 0.00000
train epoch 355 avg loss: 0.15671 (A-MSE: 0.13751) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.35377 (A-MSE: 0.30979) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.37392 (A-MSE: 0.33064) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.15663 (A-MSE: 0.13833) avg lploss: 0.00000
train epoch 357 avg loss: 0.16489 (A-MSE: 0.14437) avg lploss: 0.00000
train epoch 358 avg loss: 0.15927 (A-MSE: 0.14028) avg lploss: 0.00000
train epoch 359 avg loss: 0.16112 (A-MSE: 0.14237) avg lploss: 0.00000
train epoch 360 avg loss: 0.14627 (A-MSE: 0.12905) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.34682 (A-MSE: 0.30727) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.34925 (A-MSE: 0.31468) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 2 out of 50
train epoch 361 avg loss: 0.13105 (A-MSE: 0.11636) avg lploss: 0.00000
train epoch 362 avg loss: 0.13787 (A-MSE: 0.12130) avg lploss: 0.00000
train epoch 363 avg loss: 0.12862 (A-MSE: 0.11231) avg lploss: 0.00000
train epoch 364 avg loss: 0.14846 (A-MSE: 0.13261) avg lploss: 0.00000
train epoch 365 avg loss: 0.13751 (A-MSE: 0.12085) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.33161 (A-MSE: 0.29680) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.34216 (A-MSE: 0.30614) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 3 out of 50
train epoch 366 avg loss: 0.13782 (A-MSE: 0.12225) avg lploss: 0.00000
train epoch 367 avg loss: 0.13267 (A-MSE: 0.11701) avg lploss: 0.00000
train epoch 368 avg loss: 0.13315 (A-MSE: 0.11723) avg lploss: 0.00000
train epoch 369 avg loss: 0.11969 (A-MSE: 0.10561) avg lploss: 0.00000
train epoch 370 avg loss: 0.12075 (A-MSE: 0.10705) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.37444 (A-MSE: 0.33595) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.39234 (A-MSE: 0.35287) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 4 out of 50
train epoch 371 avg loss: 0.13350 (A-MSE: 0.11844) avg lploss: 0.00000
train epoch 372 avg loss: 0.18326 (A-MSE: 0.16063) avg lploss: 0.00000
train epoch 373 avg loss: 0.20088 (A-MSE: 0.17770) avg lploss: 0.00000
train epoch 374 avg loss: 0.17704 (A-MSE: 0.15810) avg lploss: 0.00000
train epoch 375 avg loss: 0.18297 (A-MSE: 0.16161) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.36178 (A-MSE: 0.31954) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.36327 (A-MSE: 0.32765) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 5 out of 50
train epoch 376 avg loss: 0.14646 (A-MSE: 0.12866) avg lploss: 0.00000
train epoch 377 avg loss: 0.13703 (A-MSE: 0.12063) avg lploss: 0.00000
train epoch 378 avg loss: 0.13322 (A-MSE: 0.11681) avg lploss: 0.00000
train epoch 379 avg loss: 0.13116 (A-MSE: 0.11481) avg lploss: 0.00000
train epoch 380 avg loss: 0.13688 (A-MSE: 0.12068) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.36978 (A-MSE: 0.32358) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.34491 (A-MSE: 0.30860) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 6 out of 50
train epoch 381 avg loss: 0.13918 (A-MSE: 0.12276) avg lploss: 0.00000
train epoch 382 avg loss: 0.13930 (A-MSE: 0.12161) avg lploss: 0.00000
train epoch 383 avg loss: 0.12269 (A-MSE: 0.10831) avg lploss: 0.00000
train epoch 384 avg loss: 0.13589 (A-MSE: 0.12005) avg lploss: 0.00000
train epoch 385 avg loss: 0.15067 (A-MSE: 0.13320) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.38080 (A-MSE: 0.33620) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.37980 (A-MSE: 0.34304) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 7 out of 50
train epoch 386 avg loss: 0.14395 (A-MSE: 0.12710) avg lploss: 0.00000
train epoch 387 avg loss: 0.15060 (A-MSE: 0.13224) avg lploss: 0.00000
train epoch 388 avg loss: 0.14956 (A-MSE: 0.13108) avg lploss: 0.00000
train epoch 389 avg loss: 0.16482 (A-MSE: 0.14536) avg lploss: 0.00000
train epoch 390 avg loss: 0.15749 (A-MSE: 0.13918) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.35264 (A-MSE: 0.31859) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.35710 (A-MSE: 0.32120) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 8 out of 50
train epoch 391 avg loss: 0.12983 (A-MSE: 0.11509) avg lploss: 0.00000
train epoch 392 avg loss: 0.13191 (A-MSE: 0.11716) avg lploss: 0.00000
train epoch 393 avg loss: 0.14136 (A-MSE: 0.12471) avg lploss: 0.00000
train epoch 394 avg loss: 0.13759 (A-MSE: 0.12155) avg lploss: 0.00000
train epoch 395 avg loss: 0.15909 (A-MSE: 0.14074) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.33692 (A-MSE: 0.29677) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.34177 (A-MSE: 0.30835) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 9 out of 50
train epoch 396 avg loss: 0.15353 (A-MSE: 0.13424) avg lploss: 0.00000
train epoch 397 avg loss: 0.14255 (A-MSE: 0.12638) avg lploss: 0.00000
train epoch 398 avg loss: 0.13165 (A-MSE: 0.11754) avg lploss: 0.00000
train epoch 399 avg loss: 0.15295 (A-MSE: 0.13493) avg lploss: 0.00000
train epoch 400 avg loss: 0.16002 (A-MSE: 0.14266) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.34400 (A-MSE: 0.30482) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.37374 (A-MSE: 0.34030) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 10 out of 50
train epoch 401 avg loss: 0.16369 (A-MSE: 0.14561) avg lploss: 0.00000
train epoch 402 avg loss: 0.13899 (A-MSE: 0.12325) avg lploss: 0.00000
train epoch 403 avg loss: 0.13479 (A-MSE: 0.11912) avg lploss: 0.00000
train epoch 404 avg loss: 0.13696 (A-MSE: 0.12171) avg lploss: 0.00000
train epoch 405 avg loss: 0.13595 (A-MSE: 0.12029) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.35522 (A-MSE: 0.31449) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.36454 (A-MSE: 0.33007) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 11 out of 50
train epoch 406 avg loss: 0.12670 (A-MSE: 0.11160) avg lploss: 0.00000
train epoch 407 avg loss: 0.12859 (A-MSE: 0.11427) avg lploss: 0.00000
train epoch 408 avg loss: 0.11406 (A-MSE: 0.10114) avg lploss: 0.00000
train epoch 409 avg loss: 0.11592 (A-MSE: 0.10240) avg lploss: 0.00000
train epoch 410 avg loss: 0.13817 (A-MSE: 0.12220) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.35920 (A-MSE: 0.30630) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.34385 (A-MSE: 0.30610) avg lploss: 0.00000
*** Best Val Loss: 0.32861 	 Best Test Loss: 0.34940 	 Best epoch 350
EarlyStopping counter: 12 out of 50
train epoch 411 avg loss: 0.15422 (A-MSE: 0.13594) avg lploss: 0.00000
train epoch 412 avg loss: 0.13274 (A-MSE: 0.11718) avg lploss: 0.00000
train epoch 413 avg loss: 0.17530 (A-MSE: 0.15610) avg lploss: 0.00000
train epoch 414 avg loss: 0.14684 (A-MSE: 0.12915) avg lploss: 0.00000
train epoch 415 avg loss: 0.13275 (A-MSE: 0.11715) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.32643 (A-MSE: 0.28925) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.35152 (A-MSE: 0.31410) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
Validation loss decreased (0.328609 --> 0.326434).  Saving model ...
train epoch 416 avg loss: 0.12196 (A-MSE: 0.10792) avg lploss: 0.00000
train epoch 417 avg loss: 0.12054 (A-MSE: 0.10578) avg lploss: 0.00000
train epoch 418 avg loss: 0.12650 (A-MSE: 0.11243) avg lploss: 0.00000
train epoch 419 avg loss: 0.12262 (A-MSE: 0.10959) avg lploss: 0.00000
train epoch 420 avg loss: 0.12868 (A-MSE: 0.11472) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.44342 (A-MSE: 0.38541) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.42600 (A-MSE: 0.37749) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 0.12996 (A-MSE: 0.11484) avg lploss: 0.00000
train epoch 422 avg loss: 0.13534 (A-MSE: 0.11924) avg lploss: 0.00000
train epoch 423 avg loss: 0.14152 (A-MSE: 0.12529) avg lploss: 0.00000
train epoch 424 avg loss: 0.13115 (A-MSE: 0.11647) avg lploss: 0.00000
train epoch 425 avg loss: 0.15121 (A-MSE: 0.13436) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.37013 (A-MSE: 0.31973) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.37624 (A-MSE: 0.33520) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
EarlyStopping counter: 2 out of 50
train epoch 426 avg loss: 0.14827 (A-MSE: 0.13249) avg lploss: 0.00000
train epoch 427 avg loss: 0.13547 (A-MSE: 0.12023) avg lploss: 0.00000
train epoch 428 avg loss: 0.14133 (A-MSE: 0.12481) avg lploss: 0.00000
train epoch 429 avg loss: 0.12439 (A-MSE: 0.11030) avg lploss: 0.00000
train epoch 430 avg loss: 0.12703 (A-MSE: 0.11279) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.37563 (A-MSE: 0.32672) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.36406 (A-MSE: 0.32907) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
EarlyStopping counter: 3 out of 50
train epoch 431 avg loss: 0.11187 (A-MSE: 0.09997) avg lploss: 0.00000
train epoch 432 avg loss: 0.12033 (A-MSE: 0.10564) avg lploss: 0.00000
train epoch 433 avg loss: 0.13304 (A-MSE: 0.11950) avg lploss: 0.00000
train epoch 434 avg loss: 0.12751 (A-MSE: 0.11194) avg lploss: 0.00000
train epoch 435 avg loss: 0.12500 (A-MSE: 0.11005) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.33492 (A-MSE: 0.29494) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.34853 (A-MSE: 0.31786) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
EarlyStopping counter: 4 out of 50
train epoch 436 avg loss: 0.12471 (A-MSE: 0.11086) avg lploss: 0.00000
train epoch 437 avg loss: 0.11706 (A-MSE: 0.10346) avg lploss: 0.00000
train epoch 438 avg loss: 0.11203 (A-MSE: 0.09877) avg lploss: 0.00000
train epoch 439 avg loss: 0.12916 (A-MSE: 0.11345) avg lploss: 0.00000
train epoch 440 avg loss: 0.13851 (A-MSE: 0.12203) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.34269 (A-MSE: 0.30013) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.35941 (A-MSE: 0.31820) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
EarlyStopping counter: 5 out of 50
train epoch 441 avg loss: 0.10737 (A-MSE: 0.09481) avg lploss: 0.00000
train epoch 442 avg loss: 0.10345 (A-MSE: 0.09111) avg lploss: 0.00000
train epoch 443 avg loss: 0.11982 (A-MSE: 0.10585) avg lploss: 0.00000
train epoch 444 avg loss: 0.12015 (A-MSE: 0.10555) avg lploss: 0.00000
train epoch 445 avg loss: 0.11217 (A-MSE: 0.09970) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.35256 (A-MSE: 0.30941) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.35508 (A-MSE: 0.31867) avg lploss: 0.00000
*** Best Val Loss: 0.32643 	 Best Test Loss: 0.35152 	 Best epoch 415
EarlyStopping counter: 6 out of 50
train epoch 446 avg loss: 0.10865 (A-MSE: 0.09554) avg lploss: 0.00000
train epoch 447 avg loss: 0.10154 (A-MSE: 0.09010) avg lploss: 0.00000
train epoch 448 avg loss: 0.12386 (A-MSE: 0.10751) avg lploss: 0.00000
train epoch 449 avg loss: 0.11171 (A-MSE: 0.10016) avg lploss: 0.00000
train epoch 450 avg loss: 0.11183 (A-MSE: 0.09936) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.32444 (A-MSE: 0.28476) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.34631 (A-MSE: 0.31392) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
Validation loss decreased (0.326434 --> 0.324439).  Saving model ...
train epoch 451 avg loss: 0.10735 (A-MSE: 0.09512) avg lploss: 0.00000
train epoch 452 avg loss: 0.12258 (A-MSE: 0.11047) avg lploss: 0.00000
train epoch 453 avg loss: 0.14506 (A-MSE: 0.12847) avg lploss: 0.00000
train epoch 454 avg loss: 0.14415 (A-MSE: 0.12870) avg lploss: 0.00000
train epoch 455 avg loss: 0.14771 (A-MSE: 0.13022) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.38279 (A-MSE: 0.32813) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.37330 (A-MSE: 0.33643) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 1 out of 50
train epoch 456 avg loss: 0.13155 (A-MSE: 0.11620) avg lploss: 0.00000
train epoch 457 avg loss: 0.12257 (A-MSE: 0.10804) avg lploss: 0.00000
train epoch 458 avg loss: 0.12757 (A-MSE: 0.11248) avg lploss: 0.00000
train epoch 459 avg loss: 0.11837 (A-MSE: 0.10461) avg lploss: 0.00000
train epoch 460 avg loss: 0.11251 (A-MSE: 0.09844) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.36004 (A-MSE: 0.31906) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.35543 (A-MSE: 0.31953) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 2 out of 50
train epoch 461 avg loss: 0.10794 (A-MSE: 0.09564) avg lploss: 0.00000
train epoch 462 avg loss: 0.11062 (A-MSE: 0.09895) avg lploss: 0.00000
train epoch 463 avg loss: 0.12107 (A-MSE: 0.10725) avg lploss: 0.00000
train epoch 464 avg loss: 0.13316 (A-MSE: 0.11840) avg lploss: 0.00000
train epoch 465 avg loss: 0.14543 (A-MSE: 0.12807) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.40917 (A-MSE: 0.36169) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.41843 (A-MSE: 0.37726) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 3 out of 50
train epoch 466 avg loss: 0.14799 (A-MSE: 0.13141) avg lploss: 0.00000
train epoch 467 avg loss: 0.11844 (A-MSE: 0.10455) avg lploss: 0.00000
train epoch 468 avg loss: 0.10549 (A-MSE: 0.09317) avg lploss: 0.00000
train epoch 469 avg loss: 0.10565 (A-MSE: 0.09288) avg lploss: 0.00000
train epoch 470 avg loss: 0.11965 (A-MSE: 0.10634) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.35035 (A-MSE: 0.30952) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.35083 (A-MSE: 0.31564) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 4 out of 50
train epoch 471 avg loss: 0.10572 (A-MSE: 0.09417) avg lploss: 0.00000
train epoch 472 avg loss: 0.11998 (A-MSE: 0.10538) avg lploss: 0.00000
train epoch 473 avg loss: 0.10456 (A-MSE: 0.09257) avg lploss: 0.00000
train epoch 474 avg loss: 0.10606 (A-MSE: 0.09437) avg lploss: 0.00000
train epoch 475 avg loss: 0.14405 (A-MSE: 0.12731) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.49577 (A-MSE: 0.42370) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.45726 (A-MSE: 0.39851) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 5 out of 50
train epoch 476 avg loss: 0.16072 (A-MSE: 0.14227) avg lploss: 0.00000
train epoch 477 avg loss: 0.14753 (A-MSE: 0.12955) avg lploss: 0.00000
train epoch 478 avg loss: 0.15510 (A-MSE: 0.13760) avg lploss: 0.00000
train epoch 479 avg loss: 0.11802 (A-MSE: 0.10511) avg lploss: 0.00000
train epoch 480 avg loss: 0.11578 (A-MSE: 0.10283) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.34869 (A-MSE: 0.30709) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.37208 (A-MSE: 0.32925) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 6 out of 50
train epoch 481 avg loss: 0.12962 (A-MSE: 0.11371) avg lploss: 0.00000
train epoch 482 avg loss: 0.12748 (A-MSE: 0.11363) avg lploss: 0.00000
train epoch 483 avg loss: 0.11191 (A-MSE: 0.09949) avg lploss: 0.00000
train epoch 484 avg loss: 0.09875 (A-MSE: 0.08826) avg lploss: 0.00000
train epoch 485 avg loss: 0.11531 (A-MSE: 0.10098) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.38966 (A-MSE: 0.34317) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.37227 (A-MSE: 0.33087) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 7 out of 50
train epoch 486 avg loss: 0.12088 (A-MSE: 0.10676) avg lploss: 0.00000
train epoch 487 avg loss: 0.11637 (A-MSE: 0.10198) avg lploss: 0.00000
train epoch 488 avg loss: 0.11276 (A-MSE: 0.09999) avg lploss: 0.00000
train epoch 489 avg loss: 0.10599 (A-MSE: 0.09504) avg lploss: 0.00000
train epoch 490 avg loss: 0.10194 (A-MSE: 0.08936) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.34474 (A-MSE: 0.30340) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.35910 (A-MSE: 0.32212) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 8 out of 50
train epoch 491 avg loss: 0.10025 (A-MSE: 0.08926) avg lploss: 0.00000
train epoch 492 avg loss: 0.10913 (A-MSE: 0.09602) avg lploss: 0.00000
train epoch 493 avg loss: 0.09447 (A-MSE: 0.08420) avg lploss: 0.00000
train epoch 494 avg loss: 0.09640 (A-MSE: 0.08607) avg lploss: 0.00000
train epoch 495 avg loss: 0.09869 (A-MSE: 0.08732) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.40652 (A-MSE: 0.34905) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.39383 (A-MSE: 0.34846) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 9 out of 50
train epoch 496 avg loss: 0.10125 (A-MSE: 0.08987) avg lploss: 0.00000
train epoch 497 avg loss: 0.10203 (A-MSE: 0.09042) avg lploss: 0.00000
train epoch 498 avg loss: 0.09746 (A-MSE: 0.08683) avg lploss: 0.00000
train epoch 499 avg loss: 0.10878 (A-MSE: 0.09705) avg lploss: 0.00000
train epoch 500 avg loss: 0.10871 (A-MSE: 0.09597) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.36867 (A-MSE: 0.32619) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.37132 (A-MSE: 0.33405) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 10 out of 50
train epoch 501 avg loss: 0.09894 (A-MSE: 0.08864) avg lploss: 0.00000
train epoch 502 avg loss: 0.09461 (A-MSE: 0.08389) avg lploss: 0.00000
train epoch 503 avg loss: 0.10273 (A-MSE: 0.09141) avg lploss: 0.00000
train epoch 504 avg loss: 0.11032 (A-MSE: 0.09756) avg lploss: 0.00000
train epoch 505 avg loss: 0.11589 (A-MSE: 0.10262) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.36227 (A-MSE: 0.32374) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.36347 (A-MSE: 0.32925) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 11 out of 50
train epoch 506 avg loss: 0.12972 (A-MSE: 0.11474) avg lploss: 0.00000
train epoch 507 avg loss: 0.10949 (A-MSE: 0.09780) avg lploss: 0.00000
train epoch 508 avg loss: 0.10338 (A-MSE: 0.09144) avg lploss: 0.00000
train epoch 509 avg loss: 0.15577 (A-MSE: 0.13697) avg lploss: 0.00000
train epoch 510 avg loss: 0.15504 (A-MSE: 0.13738) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.38837 (A-MSE: 0.34775) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.37990 (A-MSE: 0.34399) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 12 out of 50
train epoch 511 avg loss: 0.14218 (A-MSE: 0.12564) avg lploss: 0.00000
train epoch 512 avg loss: 0.11194 (A-MSE: 0.09964) avg lploss: 0.00000
train epoch 513 avg loss: 0.09856 (A-MSE: 0.08647) avg lploss: 0.00000
train epoch 514 avg loss: 0.09988 (A-MSE: 0.08828) avg lploss: 0.00000
train epoch 515 avg loss: 0.09903 (A-MSE: 0.08800) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.34216 (A-MSE: 0.30219) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.34827 (A-MSE: 0.30985) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 13 out of 50
train epoch 516 avg loss: 0.08911 (A-MSE: 0.07935) avg lploss: 0.00000
train epoch 517 avg loss: 0.09784 (A-MSE: 0.08676) avg lploss: 0.00000
train epoch 518 avg loss: 0.10038 (A-MSE: 0.08829) avg lploss: 0.00000
train epoch 519 avg loss: 0.08372 (A-MSE: 0.07442) avg lploss: 0.00000
train epoch 520 avg loss: 0.09119 (A-MSE: 0.08055) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.37026 (A-MSE: 0.32647) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.36814 (A-MSE: 0.33097) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 14 out of 50
train epoch 521 avg loss: 0.10038 (A-MSE: 0.08870) avg lploss: 0.00000
train epoch 522 avg loss: 0.10719 (A-MSE: 0.09591) avg lploss: 0.00000
train epoch 523 avg loss: 0.11071 (A-MSE: 0.09831) avg lploss: 0.00000
train epoch 524 avg loss: 0.09802 (A-MSE: 0.08723) avg lploss: 0.00000
train epoch 525 avg loss: 0.10023 (A-MSE: 0.08808) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.34249 (A-MSE: 0.30078) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.39066 (A-MSE: 0.34761) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 15 out of 50
train epoch 526 avg loss: 0.10768 (A-MSE: 0.09556) avg lploss: 0.00000
train epoch 527 avg loss: 0.10720 (A-MSE: 0.09494) avg lploss: 0.00000
train epoch 528 avg loss: 0.10546 (A-MSE: 0.09391) avg lploss: 0.00000
train epoch 529 avg loss: 0.09833 (A-MSE: 0.08640) avg lploss: 0.00000
train epoch 530 avg loss: 0.09979 (A-MSE: 0.08837) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.35344 (A-MSE: 0.31017) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.38649 (A-MSE: 0.34442) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 16 out of 50
train epoch 531 avg loss: 0.10337 (A-MSE: 0.09220) avg lploss: 0.00000
train epoch 532 avg loss: 0.10871 (A-MSE: 0.09563) avg lploss: 0.00000
train epoch 533 avg loss: 0.09818 (A-MSE: 0.08757) avg lploss: 0.00000
train epoch 534 avg loss: 0.10218 (A-MSE: 0.09070) avg lploss: 0.00000
train epoch 535 avg loss: 0.09538 (A-MSE: 0.08478) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.38740 (A-MSE: 0.33790) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.39927 (A-MSE: 0.35559) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 17 out of 50
train epoch 536 avg loss: 0.12205 (A-MSE: 0.10737) avg lploss: 0.00000
train epoch 537 avg loss: 0.11777 (A-MSE: 0.10439) avg lploss: 0.00000
train epoch 538 avg loss: 0.09252 (A-MSE: 0.08229) avg lploss: 0.00000
train epoch 539 avg loss: 0.08780 (A-MSE: 0.07715) avg lploss: 0.00000
train epoch 540 avg loss: 0.10928 (A-MSE: 0.09666) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.36488 (A-MSE: 0.32410) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.37728 (A-MSE: 0.34270) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 18 out of 50
train epoch 541 avg loss: 0.10259 (A-MSE: 0.09186) avg lploss: 0.00000
train epoch 542 avg loss: 0.09068 (A-MSE: 0.08003) avg lploss: 0.00000
train epoch 543 avg loss: 0.09779 (A-MSE: 0.08658) avg lploss: 0.00000
train epoch 544 avg loss: 0.09210 (A-MSE: 0.08190) avg lploss: 0.00000
train epoch 545 avg loss: 0.11322 (A-MSE: 0.10025) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.35736 (A-MSE: 0.31260) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.37002 (A-MSE: 0.32708) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 19 out of 50
train epoch 546 avg loss: 0.12641 (A-MSE: 0.11233) avg lploss: 0.00000
train epoch 547 avg loss: 0.10473 (A-MSE: 0.09347) avg lploss: 0.00000
train epoch 548 avg loss: 0.09471 (A-MSE: 0.08443) avg lploss: 0.00000
train epoch 549 avg loss: 0.09895 (A-MSE: 0.08702) avg lploss: 0.00000
train epoch 550 avg loss: 0.09737 (A-MSE: 0.08710) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.36284 (A-MSE: 0.32150) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.37471 (A-MSE: 0.33692) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 20 out of 50
train epoch 551 avg loss: 0.10377 (A-MSE: 0.09296) avg lploss: 0.00000
train epoch 552 avg loss: 0.12551 (A-MSE: 0.11015) avg lploss: 0.00000
train epoch 553 avg loss: 0.12837 (A-MSE: 0.11492) avg lploss: 0.00000
train epoch 554 avg loss: 0.14332 (A-MSE: 0.12469) avg lploss: 0.00000
train epoch 555 avg loss: 0.13257 (A-MSE: 0.11735) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.34715 (A-MSE: 0.30473) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.38087 (A-MSE: 0.33970) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 21 out of 50
train epoch 556 avg loss: 0.11155 (A-MSE: 0.09820) avg lploss: 0.00000
train epoch 557 avg loss: 0.09274 (A-MSE: 0.08202) avg lploss: 0.00000
train epoch 558 avg loss: 0.08518 (A-MSE: 0.07590) avg lploss: 0.00000
train epoch 559 avg loss: 0.09078 (A-MSE: 0.08015) avg lploss: 0.00000
train epoch 560 avg loss: 0.08446 (A-MSE: 0.07604) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.35343 (A-MSE: 0.31042) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.36571 (A-MSE: 0.32601) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 22 out of 50
train epoch 561 avg loss: 0.08770 (A-MSE: 0.07750) avg lploss: 0.00000
train epoch 562 avg loss: 0.09334 (A-MSE: 0.08312) avg lploss: 0.00000
train epoch 563 avg loss: 0.08732 (A-MSE: 0.07721) avg lploss: 0.00000
train epoch 564 avg loss: 0.08806 (A-MSE: 0.07676) avg lploss: 0.00000
train epoch 565 avg loss: 0.08397 (A-MSE: 0.07486) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.36054 (A-MSE: 0.31274) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.36505 (A-MSE: 0.32523) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 23 out of 50
train epoch 566 avg loss: 0.09353 (A-MSE: 0.08273) avg lploss: 0.00000
train epoch 567 avg loss: 0.10146 (A-MSE: 0.09077) avg lploss: 0.00000
train epoch 568 avg loss: 0.09280 (A-MSE: 0.08244) avg lploss: 0.00000
train epoch 569 avg loss: 0.11024 (A-MSE: 0.09781) avg lploss: 0.00000
train epoch 570 avg loss: 0.11102 (A-MSE: 0.09895) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.33628 (A-MSE: 0.29609) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.36815 (A-MSE: 0.32953) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 24 out of 50
train epoch 571 avg loss: 0.12933 (A-MSE: 0.11586) avg lploss: 0.00000
train epoch 572 avg loss: 0.10402 (A-MSE: 0.09225) avg lploss: 0.00000
train epoch 573 avg loss: 0.09030 (A-MSE: 0.07956) avg lploss: 0.00000
train epoch 574 avg loss: 0.08349 (A-MSE: 0.07447) avg lploss: 0.00000
train epoch 575 avg loss: 0.08915 (A-MSE: 0.07903) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.34921 (A-MSE: 0.31303) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.36017 (A-MSE: 0.32691) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 25 out of 50
train epoch 576 avg loss: 0.09241 (A-MSE: 0.08179) avg lploss: 0.00000
train epoch 577 avg loss: 0.09238 (A-MSE: 0.08185) avg lploss: 0.00000
train epoch 578 avg loss: 0.08837 (A-MSE: 0.07893) avg lploss: 0.00000
train epoch 579 avg loss: 0.09031 (A-MSE: 0.07995) avg lploss: 0.00000
train epoch 580 avg loss: 0.09805 (A-MSE: 0.08752) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.37590 (A-MSE: 0.32855) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.37646 (A-MSE: 0.33511) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 26 out of 50
train epoch 581 avg loss: 0.08004 (A-MSE: 0.07081) avg lploss: 0.00000
train epoch 582 avg loss: 0.07387 (A-MSE: 0.06524) avg lploss: 0.00000
train epoch 583 avg loss: 0.08138 (A-MSE: 0.07364) avg lploss: 0.00000
train epoch 584 avg loss: 0.07804 (A-MSE: 0.06938) avg lploss: 0.00000
train epoch 585 avg loss: 0.07389 (A-MSE: 0.06570) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.34643 (A-MSE: 0.30202) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.36709 (A-MSE: 0.32703) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 27 out of 50
train epoch 586 avg loss: 0.08004 (A-MSE: 0.07103) avg lploss: 0.00000
train epoch 587 avg loss: 0.08654 (A-MSE: 0.07804) avg lploss: 0.00000
train epoch 588 avg loss: 0.09573 (A-MSE: 0.08453) avg lploss: 0.00000
train epoch 589 avg loss: 0.08081 (A-MSE: 0.07149) avg lploss: 0.00000
train epoch 590 avg loss: 0.08359 (A-MSE: 0.07457) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.34826 (A-MSE: 0.30685) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.41420 (A-MSE: 0.36793) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 28 out of 50
train epoch 591 avg loss: 0.09434 (A-MSE: 0.08416) avg lploss: 0.00000
train epoch 592 avg loss: 0.10461 (A-MSE: 0.09242) avg lploss: 0.00000
train epoch 593 avg loss: 0.10392 (A-MSE: 0.09268) avg lploss: 0.00000
train epoch 594 avg loss: 0.09426 (A-MSE: 0.08306) avg lploss: 0.00000
train epoch 595 avg loss: 0.08616 (A-MSE: 0.07621) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.35294 (A-MSE: 0.30832) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.36755 (A-MSE: 0.32901) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 29 out of 50
train epoch 596 avg loss: 0.08685 (A-MSE: 0.07679) avg lploss: 0.00000
train epoch 597 avg loss: 0.08979 (A-MSE: 0.08052) avg lploss: 0.00000
train epoch 598 avg loss: 0.08350 (A-MSE: 0.07404) avg lploss: 0.00000
train epoch 599 avg loss: 0.09514 (A-MSE: 0.08418) avg lploss: 0.00000
train epoch 600 avg loss: 0.07730 (A-MSE: 0.06902) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.33130 (A-MSE: 0.28973) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.35397 (A-MSE: 0.31760) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 30 out of 50
train epoch 601 avg loss: 0.07483 (A-MSE: 0.06608) avg lploss: 0.00000
train epoch 602 avg loss: 0.07115 (A-MSE: 0.06343) avg lploss: 0.00000
train epoch 603 avg loss: 0.08361 (A-MSE: 0.07450) avg lploss: 0.00000
train epoch 604 avg loss: 0.09302 (A-MSE: 0.08211) avg lploss: 0.00000
train epoch 605 avg loss: 0.09288 (A-MSE: 0.08259) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.37397 (A-MSE: 0.32421) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.38559 (A-MSE: 0.34028) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 31 out of 50
train epoch 606 avg loss: 0.10333 (A-MSE: 0.09260) avg lploss: 0.00000
train epoch 607 avg loss: 0.12592 (A-MSE: 0.11247) avg lploss: 0.00000
train epoch 608 avg loss: 0.12233 (A-MSE: 0.10893) avg lploss: 0.00000
train epoch 609 avg loss: 0.11348 (A-MSE: 0.10098) avg lploss: 0.00000
train epoch 610 avg loss: 0.10318 (A-MSE: 0.09065) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.37840 (A-MSE: 0.32813) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.37702 (A-MSE: 0.33719) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 32 out of 50
train epoch 611 avg loss: 0.10183 (A-MSE: 0.09051) avg lploss: 0.00000
train epoch 612 avg loss: 0.08478 (A-MSE: 0.07523) avg lploss: 0.00000
train epoch 613 avg loss: 0.07666 (A-MSE: 0.06830) avg lploss: 0.00000
train epoch 614 avg loss: 0.06807 (A-MSE: 0.06019) avg lploss: 0.00000
train epoch 615 avg loss: 0.07354 (A-MSE: 0.06503) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.36080 (A-MSE: 0.31527) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.36831 (A-MSE: 0.32924) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 33 out of 50
train epoch 616 avg loss: 0.08550 (A-MSE: 0.07609) avg lploss: 0.00000
train epoch 617 avg loss: 0.08694 (A-MSE: 0.07668) avg lploss: 0.00000
train epoch 618 avg loss: 0.08039 (A-MSE: 0.07177) avg lploss: 0.00000
train epoch 619 avg loss: 0.08854 (A-MSE: 0.07957) avg lploss: 0.00000
train epoch 620 avg loss: 0.10205 (A-MSE: 0.09005) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.33613 (A-MSE: 0.29636) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.38002 (A-MSE: 0.34008) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 34 out of 50
train epoch 621 avg loss: 0.08364 (A-MSE: 0.07489) avg lploss: 0.00000
train epoch 622 avg loss: 0.07106 (A-MSE: 0.06284) avg lploss: 0.00000
train epoch 623 avg loss: 0.07160 (A-MSE: 0.06383) avg lploss: 0.00000
train epoch 624 avg loss: 0.07290 (A-MSE: 0.06489) avg lploss: 0.00000
train epoch 625 avg loss: 0.08110 (A-MSE: 0.07163) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.35654 (A-MSE: 0.31231) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.35215 (A-MSE: 0.31805) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 35 out of 50
train epoch 626 avg loss: 0.06924 (A-MSE: 0.06211) avg lploss: 0.00000
train epoch 627 avg loss: 0.07424 (A-MSE: 0.06568) avg lploss: 0.00000
train epoch 628 avg loss: 0.07622 (A-MSE: 0.06730) avg lploss: 0.00000
train epoch 629 avg loss: 0.08907 (A-MSE: 0.07867) avg lploss: 0.00000
train epoch 630 avg loss: 0.12255 (A-MSE: 0.10941) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.38002 (A-MSE: 0.33988) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.44029 (A-MSE: 0.39800) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 36 out of 50
train epoch 631 avg loss: 0.10477 (A-MSE: 0.09417) avg lploss: 0.00000
train epoch 632 avg loss: 0.09686 (A-MSE: 0.08664) avg lploss: 0.00000
train epoch 633 avg loss: 0.08404 (A-MSE: 0.07433) avg lploss: 0.00000
train epoch 634 avg loss: 0.08177 (A-MSE: 0.07303) avg lploss: 0.00000
train epoch 635 avg loss: 0.09832 (A-MSE: 0.08829) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.36890 (A-MSE: 0.32519) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.38473 (A-MSE: 0.34879) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 37 out of 50
train epoch 636 avg loss: 0.10261 (A-MSE: 0.09150) avg lploss: 0.00000
train epoch 637 avg loss: 0.08150 (A-MSE: 0.07187) avg lploss: 0.00000
train epoch 638 avg loss: 0.06943 (A-MSE: 0.06222) avg lploss: 0.00000
train epoch 639 avg loss: 0.07610 (A-MSE: 0.06737) avg lploss: 0.00000
train epoch 640 avg loss: 0.07788 (A-MSE: 0.06927) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.37326 (A-MSE: 0.32526) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.38598 (A-MSE: 0.34013) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 38 out of 50
train epoch 641 avg loss: 0.07508 (A-MSE: 0.06572) avg lploss: 0.00000
train epoch 642 avg loss: 0.07002 (A-MSE: 0.06194) avg lploss: 0.00000
train epoch 643 avg loss: 0.06315 (A-MSE: 0.05591) avg lploss: 0.00000
train epoch 644 avg loss: 0.06729 (A-MSE: 0.05994) avg lploss: 0.00000
train epoch 645 avg loss: 0.08476 (A-MSE: 0.07547) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.35837 (A-MSE: 0.31370) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.39255 (A-MSE: 0.35155) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 39 out of 50
train epoch 646 avg loss: 0.07316 (A-MSE: 0.06506) avg lploss: 0.00000
train epoch 647 avg loss: 0.08048 (A-MSE: 0.07190) avg lploss: 0.00000
train epoch 648 avg loss: 0.08340 (A-MSE: 0.07388) avg lploss: 0.00000
train epoch 649 avg loss: 0.07296 (A-MSE: 0.06494) avg lploss: 0.00000
train epoch 650 avg loss: 0.08727 (A-MSE: 0.07689) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.35828 (A-MSE: 0.31441) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.40131 (A-MSE: 0.36297) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 40 out of 50
train epoch 651 avg loss: 0.09776 (A-MSE: 0.08637) avg lploss: 0.00000
train epoch 652 avg loss: 0.08174 (A-MSE: 0.07269) avg lploss: 0.00000
train epoch 653 avg loss: 0.07413 (A-MSE: 0.06619) avg lploss: 0.00000
train epoch 654 avg loss: 0.08776 (A-MSE: 0.07805) avg lploss: 0.00000
train epoch 655 avg loss: 0.08662 (A-MSE: 0.07698) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.36776 (A-MSE: 0.32706) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.38389 (A-MSE: 0.34777) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 41 out of 50
train epoch 656 avg loss: 0.07250 (A-MSE: 0.06440) avg lploss: 0.00000
train epoch 657 avg loss: 0.08247 (A-MSE: 0.07353) avg lploss: 0.00000
train epoch 658 avg loss: 0.07696 (A-MSE: 0.06878) avg lploss: 0.00000
train epoch 659 avg loss: 0.07182 (A-MSE: 0.06409) avg lploss: 0.00000
train epoch 660 avg loss: 0.07184 (A-MSE: 0.06398) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.32538 (A-MSE: 0.28486) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.34437 (A-MSE: 0.30818) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 42 out of 50
train epoch 661 avg loss: 0.07221 (A-MSE: 0.06463) avg lploss: 0.00000
train epoch 662 avg loss: 0.06864 (A-MSE: 0.06145) avg lploss: 0.00000
train epoch 663 avg loss: 0.07831 (A-MSE: 0.06966) avg lploss: 0.00000
train epoch 664 avg loss: 0.08130 (A-MSE: 0.07263) avg lploss: 0.00000
train epoch 665 avg loss: 0.07971 (A-MSE: 0.07193) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.38983 (A-MSE: 0.33879) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.40536 (A-MSE: 0.35933) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 43 out of 50
train epoch 666 avg loss: 0.06459 (A-MSE: 0.05868) avg lploss: 0.00000
train epoch 667 avg loss: 0.06312 (A-MSE: 0.05660) avg lploss: 0.00000
train epoch 668 avg loss: 0.06882 (A-MSE: 0.06124) avg lploss: 0.00000
train epoch 669 avg loss: 0.06871 (A-MSE: 0.06094) avg lploss: 0.00000
train epoch 670 avg loss: 0.06373 (A-MSE: 0.05651) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.33438 (A-MSE: 0.29368) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.34979 (A-MSE: 0.31347) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 44 out of 50
train epoch 671 avg loss: 0.07353 (A-MSE: 0.06572) avg lploss: 0.00000
train epoch 672 avg loss: 0.06744 (A-MSE: 0.06024) avg lploss: 0.00000
train epoch 673 avg loss: 0.06634 (A-MSE: 0.05811) avg lploss: 0.00000
train epoch 674 avg loss: 0.07535 (A-MSE: 0.06694) avg lploss: 0.00000
train epoch 675 avg loss: 0.08082 (A-MSE: 0.07141) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.39392 (A-MSE: 0.33927) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.39797 (A-MSE: 0.35717) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 45 out of 50
train epoch 676 avg loss: 0.07176 (A-MSE: 0.06413) avg lploss: 0.00000
train epoch 677 avg loss: 0.07383 (A-MSE: 0.06624) avg lploss: 0.00000
train epoch 678 avg loss: 0.06904 (A-MSE: 0.06105) avg lploss: 0.00000
train epoch 679 avg loss: 0.05727 (A-MSE: 0.05104) avg lploss: 0.00000
train epoch 680 avg loss: 0.06678 (A-MSE: 0.05884) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.36586 (A-MSE: 0.32086) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.40177 (A-MSE: 0.36164) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 46 out of 50
train epoch 681 avg loss: 0.06687 (A-MSE: 0.05963) avg lploss: 0.00000
train epoch 682 avg loss: 0.06494 (A-MSE: 0.05758) avg lploss: 0.00000
train epoch 683 avg loss: 0.07318 (A-MSE: 0.06529) avg lploss: 0.00000
train epoch 684 avg loss: 0.08815 (A-MSE: 0.07865) avg lploss: 0.00000
train epoch 685 avg loss: 0.09909 (A-MSE: 0.08828) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.35547 (A-MSE: 0.31655) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.38738 (A-MSE: 0.34648) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 47 out of 50
train epoch 686 avg loss: 0.10181 (A-MSE: 0.08934) avg lploss: 0.00000
train epoch 687 avg loss: 0.08019 (A-MSE: 0.07179) avg lploss: 0.00000
train epoch 688 avg loss: 0.06984 (A-MSE: 0.06222) avg lploss: 0.00000
train epoch 689 avg loss: 0.06925 (A-MSE: 0.06208) avg lploss: 0.00000
train epoch 690 avg loss: 0.06894 (A-MSE: 0.06061) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.36583 (A-MSE: 0.32115) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.38252 (A-MSE: 0.34000) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 48 out of 50
train epoch 691 avg loss: 0.07491 (A-MSE: 0.06748) avg lploss: 0.00000
train epoch 692 avg loss: 0.09746 (A-MSE: 0.08608) avg lploss: 0.00000
train epoch 693 avg loss: 0.09432 (A-MSE: 0.08391) avg lploss: 0.00000
train epoch 694 avg loss: 0.07833 (A-MSE: 0.07038) avg lploss: 0.00000
train epoch 695 avg loss: 0.07225 (A-MSE: 0.06383) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.32832 (A-MSE: 0.28857) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.37312 (A-MSE: 0.33578) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 49 out of 50
train epoch 696 avg loss: 0.06105 (A-MSE: 0.05475) avg lploss: 0.00000
train epoch 697 avg loss: 0.06842 (A-MSE: 0.06091) avg lploss: 0.00000
train epoch 698 avg loss: 0.06803 (A-MSE: 0.06075) avg lploss: 0.00000
train epoch 699 avg loss: 0.07145 (A-MSE: 0.06354) avg lploss: 0.00000
train epoch 700 avg loss: 0.08266 (A-MSE: 0.07330) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.34021 (A-MSE: 0.29929) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.39682 (A-MSE: 0.35066) avg lploss: 0.00000
*** Best Val Loss: 0.32444 	 Best Test Loss: 0.34631 	 Best epoch 450
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.111835
best_lp = 0.000000
best_val = 0.324439
best_test = 0.346307
best_epoch = 450
best_train = 0.111835, best_lp = 0.000000, best_val = 0.324439, best_test = 0.346307, best_epoch = 450
Job completed at Mon Dec  8 22:52:10 CET 2025
