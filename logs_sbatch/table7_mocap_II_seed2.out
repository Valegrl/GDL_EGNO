Date              = Mon Dec  8 22:44:19 CET 2025
Hostname          = mel2152
Array Task ID     = 6
Running config: configs/table7_mocap_variant_II_seed2.json
Namespace(batch_size=12, case='run', config_by_file='configs/table7_mocap_variant_II_seed2.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='table7_mocap_variant_II_seed2', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/table7_mocap', pooling_layer=3, seed=2, test_interval=5, time_emb_dim=32, use_h_conv=True, use_x_conv=False, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/table7_mocap/table7_mocap_variant_II_seed2/saved_model.pth
train epoch 0 avg loss: 226.09694 (A-MSE: 224.43132) avg lploss: 0.00000
==> val epoch 0 avg loss: 75.40419 (A-MSE: 64.99607) avg lploss: 0.00000
==> test epoch 0 avg loss: 71.72106 (A-MSE: 61.81906) avg lploss: 0.00000
*** Best Val Loss: 75.40419 	 Best Test Loss: 71.72106 	 Best epoch 0
Validation loss decreased (inf --> 75.404187).  Saving model ...
train epoch 1 avg loss: 50.81929 (A-MSE: 43.81138) avg lploss: 0.00000
train epoch 2 avg loss: 24.57744 (A-MSE: 20.90656) avg lploss: 0.00000
train epoch 3 avg loss: 16.22687 (A-MSE: 13.58358) avg lploss: 0.00000
train epoch 4 avg loss: 14.95115 (A-MSE: 12.48360) avg lploss: 0.00000
train epoch 5 avg loss: 14.45227 (A-MSE: 12.05592) avg lploss: 0.00000
==> val epoch 5 avg loss: 14.15147 (A-MSE: 11.75476) avg lploss: 0.00000
==> test epoch 5 avg loss: 13.62388 (A-MSE: 11.33242) avg lploss: 0.00000
*** Best Val Loss: 14.15147 	 Best Test Loss: 13.62388 	 Best epoch 5
Validation loss decreased (75.404187 --> 14.151472).  Saving model ...
train epoch 6 avg loss: 14.02753 (A-MSE: 11.73539) avg lploss: 0.00000
train epoch 7 avg loss: 13.33393 (A-MSE: 11.22225) avg lploss: 0.00000
train epoch 8 avg loss: 12.42608 (A-MSE: 10.45176) avg lploss: 0.00000
train epoch 9 avg loss: 11.76993 (A-MSE: 9.92011) avg lploss: 0.00000
train epoch 10 avg loss: 11.22668 (A-MSE: 9.46350) avg lploss: 0.00000
==> val epoch 10 avg loss: 10.84023 (A-MSE: 9.11431) avg lploss: 0.00000
==> test epoch 10 avg loss: 10.49463 (A-MSE: 8.84056) avg lploss: 0.00000
*** Best Val Loss: 10.84023 	 Best Test Loss: 10.49463 	 Best epoch 10
Validation loss decreased (14.151472 --> 10.840234).  Saving model ...
train epoch 11 avg loss: 10.69857 (A-MSE: 9.04075) avg lploss: 0.00000
train epoch 12 avg loss: 9.95767 (A-MSE: 8.44042) avg lploss: 0.00000
train epoch 13 avg loss: 9.76660 (A-MSE: 8.27695) avg lploss: 0.00000
train epoch 14 avg loss: 9.35001 (A-MSE: 7.91195) avg lploss: 0.00000
train epoch 15 avg loss: 8.71417 (A-MSE: 7.40509) avg lploss: 0.00000
==> val epoch 15 avg loss: 8.57509 (A-MSE: 7.29253) avg lploss: 0.00000
==> test epoch 15 avg loss: 8.21112 (A-MSE: 6.98499) avg lploss: 0.00000
*** Best Val Loss: 8.57509 	 Best Test Loss: 8.21112 	 Best epoch 15
Validation loss decreased (10.840234 --> 8.575089).  Saving model ...
train epoch 16 avg loss: 8.41212 (A-MSE: 7.13976) avg lploss: 0.00000
train epoch 17 avg loss: 8.32500 (A-MSE: 7.07696) avg lploss: 0.00000
train epoch 18 avg loss: 8.08175 (A-MSE: 6.88317) avg lploss: 0.00000
train epoch 19 avg loss: 8.04018 (A-MSE: 6.85659) avg lploss: 0.00000
train epoch 20 avg loss: 7.63826 (A-MSE: 6.49879) avg lploss: 0.00000
==> val epoch 20 avg loss: 7.43282 (A-MSE: 6.31308) avg lploss: 0.00000
==> test epoch 20 avg loss: 7.05706 (A-MSE: 6.01061) avg lploss: 0.00000
*** Best Val Loss: 7.43282 	 Best Test Loss: 7.05706 	 Best epoch 20
Validation loss decreased (8.575089 --> 7.432825).  Saving model ...
train epoch 21 avg loss: 7.33054 (A-MSE: 6.26077) avg lploss: 0.00000
train epoch 22 avg loss: 6.91623 (A-MSE: 5.89704) avg lploss: 0.00000
train epoch 23 avg loss: 6.64118 (A-MSE: 5.65617) avg lploss: 0.00000
train epoch 24 avg loss: 6.20294 (A-MSE: 5.30057) avg lploss: 0.00000
train epoch 25 avg loss: 6.03891 (A-MSE: 5.16127) avg lploss: 0.00000
==> val epoch 25 avg loss: 6.43969 (A-MSE: 5.50648) avg lploss: 0.00000
==> test epoch 25 avg loss: 6.16247 (A-MSE: 5.27234) avg lploss: 0.00000
*** Best Val Loss: 6.43969 	 Best Test Loss: 6.16247 	 Best epoch 25
Validation loss decreased (7.432825 --> 6.439687).  Saving model ...
train epoch 26 avg loss: 6.21502 (A-MSE: 5.30383) avg lploss: 0.00000
train epoch 27 avg loss: 5.73725 (A-MSE: 4.92785) avg lploss: 0.00000
train epoch 28 avg loss: 5.56903 (A-MSE: 4.78023) avg lploss: 0.00000
train epoch 29 avg loss: 5.21541 (A-MSE: 4.47987) avg lploss: 0.00000
train epoch 30 avg loss: 5.04798 (A-MSE: 4.34996) avg lploss: 0.00000
==> val epoch 30 avg loss: 4.93463 (A-MSE: 4.20152) avg lploss: 0.00000
==> test epoch 30 avg loss: 4.92480 (A-MSE: 4.20022) avg lploss: 0.00000
*** Best Val Loss: 4.93463 	 Best Test Loss: 4.92480 	 Best epoch 30
Validation loss decreased (6.439687 --> 4.934626).  Saving model ...
train epoch 31 avg loss: 4.99403 (A-MSE: 4.31056) avg lploss: 0.00000
train epoch 32 avg loss: 4.63026 (A-MSE: 3.99336) avg lploss: 0.00000
train epoch 33 avg loss: 4.38288 (A-MSE: 3.78945) avg lploss: 0.00000
train epoch 34 avg loss: 4.48650 (A-MSE: 3.87324) avg lploss: 0.00000
train epoch 35 avg loss: 4.29668 (A-MSE: 3.70970) avg lploss: 0.00000
==> val epoch 35 avg loss: 3.99144 (A-MSE: 3.46419) avg lploss: 0.00000
==> test epoch 35 avg loss: 4.07300 (A-MSE: 3.53782) avg lploss: 0.00000
*** Best Val Loss: 3.99144 	 Best Test Loss: 4.07300 	 Best epoch 35
Validation loss decreased (4.934626 --> 3.991441).  Saving model ...
train epoch 36 avg loss: 4.01222 (A-MSE: 3.46479) avg lploss: 0.00000
train epoch 37 avg loss: 4.02560 (A-MSE: 3.48229) avg lploss: 0.00000
train epoch 38 avg loss: 3.92378 (A-MSE: 3.40227) avg lploss: 0.00000
train epoch 39 avg loss: 3.64669 (A-MSE: 3.15509) avg lploss: 0.00000
train epoch 40 avg loss: 3.88877 (A-MSE: 3.35777) avg lploss: 0.00000
==> val epoch 40 avg loss: 4.05509 (A-MSE: 3.43340) avg lploss: 0.00000
==> test epoch 40 avg loss: 4.10106 (A-MSE: 3.49565) avg lploss: 0.00000
*** Best Val Loss: 3.99144 	 Best Test Loss: 4.07300 	 Best epoch 35
EarlyStopping counter: 1 out of 50
train epoch 41 avg loss: 3.74640 (A-MSE: 3.22871) avg lploss: 0.00000
train epoch 42 avg loss: 3.41177 (A-MSE: 2.95450) avg lploss: 0.00000
train epoch 43 avg loss: 3.34632 (A-MSE: 2.89337) avg lploss: 0.00000
train epoch 44 avg loss: 3.34856 (A-MSE: 2.89941) avg lploss: 0.00000
train epoch 45 avg loss: 3.26045 (A-MSE: 2.81847) avg lploss: 0.00000
==> val epoch 45 avg loss: 3.09056 (A-MSE: 2.65808) avg lploss: 0.00000
==> test epoch 45 avg loss: 3.17052 (A-MSE: 2.74247) avg lploss: 0.00000
*** Best Val Loss: 3.09056 	 Best Test Loss: 3.17052 	 Best epoch 45
Validation loss decreased (3.991441 --> 3.090559).  Saving model ...
train epoch 46 avg loss: 3.19519 (A-MSE: 2.76518) avg lploss: 0.00000
train epoch 47 avg loss: 3.16434 (A-MSE: 2.74776) avg lploss: 0.00000
train epoch 48 avg loss: 3.03373 (A-MSE: 2.61789) avg lploss: 0.00000
train epoch 49 avg loss: 2.98222 (A-MSE: 2.58255) avg lploss: 0.00000
train epoch 50 avg loss: 3.29217 (A-MSE: 2.83021) avg lploss: 0.00000
==> val epoch 50 avg loss: 3.04526 (A-MSE: 2.65529) avg lploss: 0.00000
==> test epoch 50 avg loss: 3.19236 (A-MSE: 2.79350) avg lploss: 0.00000
*** Best Val Loss: 3.04526 	 Best Test Loss: 3.19236 	 Best epoch 50
Validation loss decreased (3.090559 --> 3.045259).  Saving model ...
train epoch 51 avg loss: 2.93545 (A-MSE: 2.52880) avg lploss: 0.00000
train epoch 52 avg loss: 2.93550 (A-MSE: 2.53373) avg lploss: 0.00000
train epoch 53 avg loss: 2.89522 (A-MSE: 2.50886) avg lploss: 0.00000
train epoch 54 avg loss: 2.69283 (A-MSE: 2.32443) avg lploss: 0.00000
train epoch 55 avg loss: 2.71594 (A-MSE: 2.34710) avg lploss: 0.00000
==> val epoch 55 avg loss: 2.64080 (A-MSE: 2.30598) avg lploss: 0.00000
==> test epoch 55 avg loss: 2.83458 (A-MSE: 2.48429) avg lploss: 0.00000
*** Best Val Loss: 2.64080 	 Best Test Loss: 2.83458 	 Best epoch 55
Validation loss decreased (3.045259 --> 2.640798).  Saving model ...
train epoch 56 avg loss: 2.57743 (A-MSE: 2.22582) avg lploss: 0.00000
train epoch 57 avg loss: 2.44379 (A-MSE: 2.10594) avg lploss: 0.00000
train epoch 58 avg loss: 2.65426 (A-MSE: 2.29417) avg lploss: 0.00000
train epoch 59 avg loss: 2.62460 (A-MSE: 2.25088) avg lploss: 0.00000
train epoch 60 avg loss: 2.59483 (A-MSE: 2.23805) avg lploss: 0.00000
==> val epoch 60 avg loss: 2.62472 (A-MSE: 2.25733) avg lploss: 0.00000
==> test epoch 60 avg loss: 2.68792 (A-MSE: 2.33453) avg lploss: 0.00000
*** Best Val Loss: 2.62472 	 Best Test Loss: 2.68792 	 Best epoch 60
Validation loss decreased (2.640798 --> 2.624720).  Saving model ...
train epoch 61 avg loss: 2.33417 (A-MSE: 2.01699) avg lploss: 0.00000
train epoch 62 avg loss: 2.30808 (A-MSE: 1.99309) avg lploss: 0.00000
train epoch 63 avg loss: 2.19086 (A-MSE: 1.88896) avg lploss: 0.00000
train epoch 64 avg loss: 2.24500 (A-MSE: 1.92947) avg lploss: 0.00000
train epoch 65 avg loss: 2.25043 (A-MSE: 1.94065) avg lploss: 0.00000
==> val epoch 65 avg loss: 2.60864 (A-MSE: 2.17439) avg lploss: 0.00000
==> test epoch 65 avg loss: 2.84061 (A-MSE: 2.39375) avg lploss: 0.00000
*** Best Val Loss: 2.60864 	 Best Test Loss: 2.84061 	 Best epoch 65
Validation loss decreased (2.624720 --> 2.608638).  Saving model ...
train epoch 66 avg loss: 2.36022 (A-MSE: 2.02410) avg lploss: 0.00000
train epoch 67 avg loss: 2.28027 (A-MSE: 1.96030) avg lploss: 0.00000
train epoch 68 avg loss: 2.15215 (A-MSE: 1.86065) avg lploss: 0.00000
train epoch 69 avg loss: 2.00739 (A-MSE: 1.72876) avg lploss: 0.00000
train epoch 70 avg loss: 2.10466 (A-MSE: 1.80752) avg lploss: 0.00000
==> val epoch 70 avg loss: 2.35617 (A-MSE: 2.04499) avg lploss: 0.00000
==> test epoch 70 avg loss: 2.42976 (A-MSE: 2.12294) avg lploss: 0.00000
*** Best Val Loss: 2.35617 	 Best Test Loss: 2.42976 	 Best epoch 70
Validation loss decreased (2.608638 --> 2.356166).  Saving model ...
train epoch 71 avg loss: 2.07979 (A-MSE: 1.79608) avg lploss: 0.00000
train epoch 72 avg loss: 2.06365 (A-MSE: 1.78027) avg lploss: 0.00000
train epoch 73 avg loss: 1.99769 (A-MSE: 1.71745) avg lploss: 0.00000
train epoch 74 avg loss: 1.88240 (A-MSE: 1.62390) avg lploss: 0.00000
train epoch 75 avg loss: 1.76766 (A-MSE: 1.52741) avg lploss: 0.00000
==> val epoch 75 avg loss: 2.21957 (A-MSE: 1.90896) avg lploss: 0.00000
==> test epoch 75 avg loss: 2.45659 (A-MSE: 2.12001) avg lploss: 0.00000
*** Best Val Loss: 2.21957 	 Best Test Loss: 2.45659 	 Best epoch 75
Validation loss decreased (2.356166 --> 2.219575).  Saving model ...
train epoch 76 avg loss: 1.99288 (A-MSE: 1.70997) avg lploss: 0.00000
train epoch 77 avg loss: 1.94314 (A-MSE: 1.66814) avg lploss: 0.00000
train epoch 78 avg loss: 1.62687 (A-MSE: 1.41509) avg lploss: 0.00000
train epoch 79 avg loss: 1.73254 (A-MSE: 1.49518) avg lploss: 0.00000
train epoch 80 avg loss: 1.66334 (A-MSE: 1.44269) avg lploss: 0.00000
==> val epoch 80 avg loss: 1.99197 (A-MSE: 1.70974) avg lploss: 0.00000
==> test epoch 80 avg loss: 2.11001 (A-MSE: 1.82920) avg lploss: 0.00000
*** Best Val Loss: 1.99197 	 Best Test Loss: 2.11001 	 Best epoch 80
Validation loss decreased (2.219575 --> 1.991965).  Saving model ...
train epoch 81 avg loss: 1.55684 (A-MSE: 1.36053) avg lploss: 0.00000
train epoch 82 avg loss: 1.51310 (A-MSE: 1.31121) avg lploss: 0.00000
train epoch 83 avg loss: 1.55057 (A-MSE: 1.34026) avg lploss: 0.00000
train epoch 84 avg loss: 1.67931 (A-MSE: 1.46341) avg lploss: 0.00000
train epoch 85 avg loss: 1.60600 (A-MSE: 1.40090) avg lploss: 0.00000
==> val epoch 85 avg loss: 1.84658 (A-MSE: 1.59642) avg lploss: 0.00000
==> test epoch 85 avg loss: 1.97285 (A-MSE: 1.71976) avg lploss: 0.00000
*** Best Val Loss: 1.84658 	 Best Test Loss: 1.97285 	 Best epoch 85
Validation loss decreased (1.991965 --> 1.846582).  Saving model ...
train epoch 86 avg loss: 1.45555 (A-MSE: 1.26963) avg lploss: 0.00000
train epoch 87 avg loss: 1.35940 (A-MSE: 1.18125) avg lploss: 0.00000
train epoch 88 avg loss: 1.43395 (A-MSE: 1.24236) avg lploss: 0.00000
train epoch 89 avg loss: 1.49328 (A-MSE: 1.29225) avg lploss: 0.00000
train epoch 90 avg loss: 1.41335 (A-MSE: 1.22740) avg lploss: 0.00000
==> val epoch 90 avg loss: 1.60945 (A-MSE: 1.37972) avg lploss: 0.00000
==> test epoch 90 avg loss: 1.87427 (A-MSE: 1.62256) avg lploss: 0.00000
*** Best Val Loss: 1.60945 	 Best Test Loss: 1.87427 	 Best epoch 90
Validation loss decreased (1.846582 --> 1.609446).  Saving model ...
train epoch 91 avg loss: 1.36601 (A-MSE: 1.19129) avg lploss: 0.00000
train epoch 92 avg loss: 1.35199 (A-MSE: 1.16620) avg lploss: 0.00000
train epoch 93 avg loss: 1.52315 (A-MSE: 1.32556) avg lploss: 0.00000
train epoch 94 avg loss: 1.26633 (A-MSE: 1.10556) avg lploss: 0.00000
train epoch 95 avg loss: 1.25227 (A-MSE: 1.08964) avg lploss: 0.00000
==> val epoch 95 avg loss: 1.69681 (A-MSE: 1.45464) avg lploss: 0.00000
==> test epoch 95 avg loss: 1.85801 (A-MSE: 1.61707) avg lploss: 0.00000
*** Best Val Loss: 1.60945 	 Best Test Loss: 1.87427 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 1.34295 (A-MSE: 1.16167) avg lploss: 0.00000
train epoch 97 avg loss: 1.38584 (A-MSE: 1.20136) avg lploss: 0.00000
train epoch 98 avg loss: 1.21722 (A-MSE: 1.05800) avg lploss: 0.00000
train epoch 99 avg loss: 1.23945 (A-MSE: 1.07227) avg lploss: 0.00000
train epoch 100 avg loss: 1.32969 (A-MSE: 1.15302) avg lploss: 0.00000
==> val epoch 100 avg loss: 1.50210 (A-MSE: 1.30913) avg lploss: 0.00000
==> test epoch 100 avg loss: 1.72503 (A-MSE: 1.51869) avg lploss: 0.00000
*** Best Val Loss: 1.50210 	 Best Test Loss: 1.72503 	 Best epoch 100
Validation loss decreased (1.609446 --> 1.502097).  Saving model ...
train epoch 101 avg loss: 1.30008 (A-MSE: 1.13081) avg lploss: 0.00000
train epoch 102 avg loss: 1.32673 (A-MSE: 1.15042) avg lploss: 0.00000
train epoch 103 avg loss: 1.22676 (A-MSE: 1.06389) avg lploss: 0.00000
train epoch 104 avg loss: 1.09411 (A-MSE: 0.95614) avg lploss: 0.00000
train epoch 105 avg loss: 1.18844 (A-MSE: 1.02748) avg lploss: 0.00000
==> val epoch 105 avg loss: 1.59958 (A-MSE: 1.39456) avg lploss: 0.00000
==> test epoch 105 avg loss: 1.66684 (A-MSE: 1.47327) avg lploss: 0.00000
*** Best Val Loss: 1.50210 	 Best Test Loss: 1.72503 	 Best epoch 100
EarlyStopping counter: 1 out of 50
train epoch 106 avg loss: 1.15851 (A-MSE: 1.00676) avg lploss: 0.00000
train epoch 107 avg loss: 1.08489 (A-MSE: 0.93977) avg lploss: 0.00000
train epoch 108 avg loss: 1.12675 (A-MSE: 0.97712) avg lploss: 0.00000
train epoch 109 avg loss: 1.05025 (A-MSE: 0.90748) avg lploss: 0.00000
train epoch 110 avg loss: 1.14642 (A-MSE: 0.99910) avg lploss: 0.00000
==> val epoch 110 avg loss: 1.42482 (A-MSE: 1.24024) avg lploss: 0.00000
==> test epoch 110 avg loss: 1.44876 (A-MSE: 1.27627) avg lploss: 0.00000
*** Best Val Loss: 1.42482 	 Best Test Loss: 1.44876 	 Best epoch 110
Validation loss decreased (1.502097 --> 1.424824).  Saving model ...
train epoch 111 avg loss: 1.14338 (A-MSE: 0.99497) avg lploss: 0.00000
train epoch 112 avg loss: 1.20303 (A-MSE: 1.04733) avg lploss: 0.00000
train epoch 113 avg loss: 1.14290 (A-MSE: 0.99479) avg lploss: 0.00000
train epoch 114 avg loss: 1.07907 (A-MSE: 0.93557) avg lploss: 0.00000
train epoch 115 avg loss: 1.07030 (A-MSE: 0.92944) avg lploss: 0.00000
==> val epoch 115 avg loss: 1.48404 (A-MSE: 1.29032) avg lploss: 0.00000
==> test epoch 115 avg loss: 1.63691 (A-MSE: 1.44079) avg lploss: 0.00000
*** Best Val Loss: 1.42482 	 Best Test Loss: 1.44876 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 1.13495 (A-MSE: 0.98864) avg lploss: 0.00000
train epoch 117 avg loss: 1.04065 (A-MSE: 0.90166) avg lploss: 0.00000
train epoch 118 avg loss: 0.99547 (A-MSE: 0.86474) avg lploss: 0.00000
train epoch 119 avg loss: 1.13333 (A-MSE: 0.98325) avg lploss: 0.00000
train epoch 120 avg loss: 1.16836 (A-MSE: 1.01315) avg lploss: 0.00000
==> val epoch 120 avg loss: 1.27362 (A-MSE: 1.11428) avg lploss: 0.00000
==> test epoch 120 avg loss: 1.43809 (A-MSE: 1.27267) avg lploss: 0.00000
*** Best Val Loss: 1.27362 	 Best Test Loss: 1.43809 	 Best epoch 120
Validation loss decreased (1.424824 --> 1.273616).  Saving model ...
train epoch 121 avg loss: 1.17839 (A-MSE: 1.02083) avg lploss: 0.00000
train epoch 122 avg loss: 1.16226 (A-MSE: 1.00359) avg lploss: 0.00000
train epoch 123 avg loss: 1.08283 (A-MSE: 0.94138) avg lploss: 0.00000
train epoch 124 avg loss: 1.10948 (A-MSE: 0.95501) avg lploss: 0.00000
train epoch 125 avg loss: 0.99209 (A-MSE: 0.86332) avg lploss: 0.00000
==> val epoch 125 avg loss: 1.59947 (A-MSE: 1.38483) avg lploss: 0.00000
==> test epoch 125 avg loss: 1.96414 (A-MSE: 1.71940) avg lploss: 0.00000
*** Best Val Loss: 1.27362 	 Best Test Loss: 1.43809 	 Best epoch 120
EarlyStopping counter: 1 out of 50
train epoch 126 avg loss: 1.19029 (A-MSE: 1.03229) avg lploss: 0.00000
train epoch 127 avg loss: 1.05455 (A-MSE: 0.91726) avg lploss: 0.00000
train epoch 128 avg loss: 1.03687 (A-MSE: 0.90292) avg lploss: 0.00000
train epoch 129 avg loss: 0.98013 (A-MSE: 0.85309) avg lploss: 0.00000
train epoch 130 avg loss: 0.90715 (A-MSE: 0.79013) avg lploss: 0.00000
==> val epoch 130 avg loss: 1.41228 (A-MSE: 1.23295) avg lploss: 0.00000
==> test epoch 130 avg loss: 1.54658 (A-MSE: 1.36021) avg lploss: 0.00000
*** Best Val Loss: 1.27362 	 Best Test Loss: 1.43809 	 Best epoch 120
EarlyStopping counter: 2 out of 50
train epoch 131 avg loss: 0.92275 (A-MSE: 0.80203) avg lploss: 0.00000
train epoch 132 avg loss: 1.00054 (A-MSE: 0.87189) avg lploss: 0.00000
train epoch 133 avg loss: 0.91317 (A-MSE: 0.79336) avg lploss: 0.00000
train epoch 134 avg loss: 0.89790 (A-MSE: 0.78051) avg lploss: 0.00000
train epoch 135 avg loss: 0.97657 (A-MSE: 0.84573) avg lploss: 0.00000
==> val epoch 135 avg loss: 1.38620 (A-MSE: 1.20993) avg lploss: 0.00000
==> test epoch 135 avg loss: 1.50218 (A-MSE: 1.32442) avg lploss: 0.00000
*** Best Val Loss: 1.27362 	 Best Test Loss: 1.43809 	 Best epoch 120
EarlyStopping counter: 3 out of 50
train epoch 136 avg loss: 0.91175 (A-MSE: 0.79296) avg lploss: 0.00000
train epoch 137 avg loss: 0.92796 (A-MSE: 0.80927) avg lploss: 0.00000
train epoch 138 avg loss: 0.86876 (A-MSE: 0.75856) avg lploss: 0.00000
train epoch 139 avg loss: 0.91030 (A-MSE: 0.79365) avg lploss: 0.00000
train epoch 140 avg loss: 0.91682 (A-MSE: 0.79784) avg lploss: 0.00000
==> val epoch 140 avg loss: 1.24825 (A-MSE: 1.09482) avg lploss: 0.00000
==> test epoch 140 avg loss: 1.43890 (A-MSE: 1.27714) avg lploss: 0.00000
*** Best Val Loss: 1.24825 	 Best Test Loss: 1.43890 	 Best epoch 140
Validation loss decreased (1.273616 --> 1.248246).  Saving model ...
train epoch 141 avg loss: 0.85854 (A-MSE: 0.74606) avg lploss: 0.00000
train epoch 142 avg loss: 0.83634 (A-MSE: 0.72875) avg lploss: 0.00000
train epoch 143 avg loss: 0.86597 (A-MSE: 0.75799) avg lploss: 0.00000
train epoch 144 avg loss: 0.86569 (A-MSE: 0.75003) avg lploss: 0.00000
train epoch 145 avg loss: 0.91315 (A-MSE: 0.79488) avg lploss: 0.00000
==> val epoch 145 avg loss: 1.21930 (A-MSE: 1.06397) avg lploss: 0.00000
==> test epoch 145 avg loss: 1.37278 (A-MSE: 1.22263) avg lploss: 0.00000
*** Best Val Loss: 1.21930 	 Best Test Loss: 1.37278 	 Best epoch 145
Validation loss decreased (1.248246 --> 1.219299).  Saving model ...
train epoch 146 avg loss: 1.02363 (A-MSE: 0.88914) avg lploss: 0.00000
train epoch 147 avg loss: 0.92746 (A-MSE: 0.80602) avg lploss: 0.00000
train epoch 148 avg loss: 0.83654 (A-MSE: 0.72797) avg lploss: 0.00000
train epoch 149 avg loss: 0.89411 (A-MSE: 0.78069) avg lploss: 0.00000
train epoch 150 avg loss: 0.91609 (A-MSE: 0.79699) avg lploss: 0.00000
==> val epoch 150 avg loss: 1.41621 (A-MSE: 1.24678) avg lploss: 0.00000
==> test epoch 150 avg loss: 1.47895 (A-MSE: 1.30960) avg lploss: 0.00000
*** Best Val Loss: 1.21930 	 Best Test Loss: 1.37278 	 Best epoch 145
EarlyStopping counter: 1 out of 50
train epoch 151 avg loss: 0.85661 (A-MSE: 0.74662) avg lploss: 0.00000
train epoch 152 avg loss: 0.84858 (A-MSE: 0.74190) avg lploss: 0.00000
train epoch 153 avg loss: 0.81416 (A-MSE: 0.71053) avg lploss: 0.00000
train epoch 154 avg loss: 0.83553 (A-MSE: 0.73165) avg lploss: 0.00000
train epoch 155 avg loss: 0.83374 (A-MSE: 0.72842) avg lploss: 0.00000
==> val epoch 155 avg loss: 1.19434 (A-MSE: 1.04124) avg lploss: 0.00000
==> test epoch 155 avg loss: 1.39458 (A-MSE: 1.22654) avg lploss: 0.00000
*** Best Val Loss: 1.19434 	 Best Test Loss: 1.39458 	 Best epoch 155
Validation loss decreased (1.219299 --> 1.194345).  Saving model ...
train epoch 156 avg loss: 0.85897 (A-MSE: 0.74691) avg lploss: 0.00000
train epoch 157 avg loss: 0.84379 (A-MSE: 0.73788) avg lploss: 0.00000
train epoch 158 avg loss: 0.79728 (A-MSE: 0.69748) avg lploss: 0.00000
train epoch 159 avg loss: 0.82730 (A-MSE: 0.71792) avg lploss: 0.00000
train epoch 160 avg loss: 0.87510 (A-MSE: 0.76050) avg lploss: 0.00000
==> val epoch 160 avg loss: 1.27636 (A-MSE: 1.10548) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.55462 (A-MSE: 1.35677) avg lploss: 0.00000
*** Best Val Loss: 1.19434 	 Best Test Loss: 1.39458 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 0.81787 (A-MSE: 0.71323) avg lploss: 0.00000
train epoch 162 avg loss: 0.73503 (A-MSE: 0.64280) avg lploss: 0.00000
train epoch 163 avg loss: 0.77162 (A-MSE: 0.67162) avg lploss: 0.00000
train epoch 164 avg loss: 0.87867 (A-MSE: 0.77058) avg lploss: 0.00000
train epoch 165 avg loss: 0.76751 (A-MSE: 0.67127) avg lploss: 0.00000
==> val epoch 165 avg loss: 1.26172 (A-MSE: 1.11274) avg lploss: 0.00000
==> test epoch 165 avg loss: 1.28817 (A-MSE: 1.14258) avg lploss: 0.00000
*** Best Val Loss: 1.19434 	 Best Test Loss: 1.39458 	 Best epoch 155
EarlyStopping counter: 2 out of 50
train epoch 166 avg loss: 0.77194 (A-MSE: 0.67431) avg lploss: 0.00000
train epoch 167 avg loss: 0.80322 (A-MSE: 0.70267) avg lploss: 0.00000
train epoch 168 avg loss: 0.87638 (A-MSE: 0.76460) avg lploss: 0.00000
train epoch 169 avg loss: 0.73851 (A-MSE: 0.64763) avg lploss: 0.00000
train epoch 170 avg loss: 0.75299 (A-MSE: 0.65835) avg lploss: 0.00000
==> val epoch 170 avg loss: 1.07454 (A-MSE: 0.94368) avg lploss: 0.00000
==> test epoch 170 avg loss: 1.17278 (A-MSE: 1.04097) avg lploss: 0.00000
*** Best Val Loss: 1.07454 	 Best Test Loss: 1.17278 	 Best epoch 170
Validation loss decreased (1.194345 --> 1.074543).  Saving model ...
train epoch 171 avg loss: 0.71674 (A-MSE: 0.62734) avg lploss: 0.00000
train epoch 172 avg loss: 0.70385 (A-MSE: 0.61731) avg lploss: 0.00000
train epoch 173 avg loss: 0.72819 (A-MSE: 0.63437) avg lploss: 0.00000
train epoch 174 avg loss: 0.79957 (A-MSE: 0.69464) avg lploss: 0.00000
train epoch 175 avg loss: 0.77461 (A-MSE: 0.67719) avg lploss: 0.00000
==> val epoch 175 avg loss: 1.13213 (A-MSE: 0.99402) avg lploss: 0.00000
==> test epoch 175 avg loss: 1.15154 (A-MSE: 1.02437) avg lploss: 0.00000
*** Best Val Loss: 1.07454 	 Best Test Loss: 1.17278 	 Best epoch 170
EarlyStopping counter: 1 out of 50
train epoch 176 avg loss: 0.71216 (A-MSE: 0.62308) avg lploss: 0.00000
train epoch 177 avg loss: 0.76400 (A-MSE: 0.67036) avg lploss: 0.00000
train epoch 178 avg loss: 0.74486 (A-MSE: 0.64992) avg lploss: 0.00000
train epoch 179 avg loss: 0.66278 (A-MSE: 0.57986) avg lploss: 0.00000
train epoch 180 avg loss: 0.63676 (A-MSE: 0.55612) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.99168 (A-MSE: 0.86495) avg lploss: 0.00000
==> test epoch 180 avg loss: 1.22997 (A-MSE: 1.08858) avg lploss: 0.00000
*** Best Val Loss: 0.99168 	 Best Test Loss: 1.22997 	 Best epoch 180
Validation loss decreased (1.074543 --> 0.991680).  Saving model ...
train epoch 181 avg loss: 0.70832 (A-MSE: 0.61907) avg lploss: 0.00000
train epoch 182 avg loss: 0.63909 (A-MSE: 0.55945) avg lploss: 0.00000
train epoch 183 avg loss: 0.68038 (A-MSE: 0.60168) avg lploss: 0.00000
train epoch 184 avg loss: 0.66358 (A-MSE: 0.58185) avg lploss: 0.00000
train epoch 185 avg loss: 0.66572 (A-MSE: 0.58137) avg lploss: 0.00000
==> val epoch 185 avg loss: 1.06308 (A-MSE: 0.93443) avg lploss: 0.00000
==> test epoch 185 avg loss: 1.32417 (A-MSE: 1.17142) avg lploss: 0.00000
*** Best Val Loss: 0.99168 	 Best Test Loss: 1.22997 	 Best epoch 180
EarlyStopping counter: 1 out of 50
train epoch 186 avg loss: 0.68759 (A-MSE: 0.60311) avg lploss: 0.00000
train epoch 187 avg loss: 0.67019 (A-MSE: 0.58867) avg lploss: 0.00000
train epoch 188 avg loss: 0.74181 (A-MSE: 0.64827) avg lploss: 0.00000
train epoch 189 avg loss: 0.69974 (A-MSE: 0.61208) avg lploss: 0.00000
train epoch 190 avg loss: 0.69684 (A-MSE: 0.61155) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.96997 (A-MSE: 0.85032) avg lploss: 0.00000
==> test epoch 190 avg loss: 1.10537 (A-MSE: 0.98132) avg lploss: 0.00000
*** Best Val Loss: 0.96997 	 Best Test Loss: 1.10537 	 Best epoch 190
Validation loss decreased (0.991680 --> 0.969966).  Saving model ...
train epoch 191 avg loss: 0.70526 (A-MSE: 0.61841) avg lploss: 0.00000
train epoch 192 avg loss: 0.68242 (A-MSE: 0.59693) avg lploss: 0.00000
train epoch 193 avg loss: 0.66086 (A-MSE: 0.57791) avg lploss: 0.00000
train epoch 194 avg loss: 0.66952 (A-MSE: 0.58658) avg lploss: 0.00000
train epoch 195 avg loss: 0.61952 (A-MSE: 0.54420) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.91695 (A-MSE: 0.80728) avg lploss: 0.00000
==> test epoch 195 avg loss: 1.08239 (A-MSE: 0.95995) avg lploss: 0.00000
*** Best Val Loss: 0.91695 	 Best Test Loss: 1.08239 	 Best epoch 195
Validation loss decreased (0.969966 --> 0.916947).  Saving model ...
train epoch 196 avg loss: 0.62525 (A-MSE: 0.54843) avg lploss: 0.00000
train epoch 197 avg loss: 0.59505 (A-MSE: 0.52324) avg lploss: 0.00000
train epoch 198 avg loss: 0.59018 (A-MSE: 0.51791) avg lploss: 0.00000
train epoch 199 avg loss: 0.60025 (A-MSE: 0.52584) avg lploss: 0.00000
train epoch 200 avg loss: 0.61796 (A-MSE: 0.54300) avg lploss: 0.00000
==> val epoch 200 avg loss: 1.06459 (A-MSE: 0.94466) avg lploss: 0.00000
==> test epoch 200 avg loss: 1.22283 (A-MSE: 1.09428) avg lploss: 0.00000
*** Best Val Loss: 0.91695 	 Best Test Loss: 1.08239 	 Best epoch 195
EarlyStopping counter: 1 out of 50
train epoch 201 avg loss: 0.61236 (A-MSE: 0.53394) avg lploss: 0.00000
train epoch 202 avg loss: 0.63172 (A-MSE: 0.55341) avg lploss: 0.00000
train epoch 203 avg loss: 0.66589 (A-MSE: 0.58264) avg lploss: 0.00000
train epoch 204 avg loss: 0.69403 (A-MSE: 0.60516) avg lploss: 0.00000
train epoch 205 avg loss: 0.70509 (A-MSE: 0.61647) avg lploss: 0.00000
==> val epoch 205 avg loss: 1.14236 (A-MSE: 1.00789) avg lploss: 0.00000
==> test epoch 205 avg loss: 1.20288 (A-MSE: 1.07375) avg lploss: 0.00000
*** Best Val Loss: 0.91695 	 Best Test Loss: 1.08239 	 Best epoch 195
EarlyStopping counter: 2 out of 50
train epoch 206 avg loss: 0.69942 (A-MSE: 0.61709) avg lploss: 0.00000
train epoch 207 avg loss: 0.58793 (A-MSE: 0.51455) avg lploss: 0.00000
train epoch 208 avg loss: 0.55623 (A-MSE: 0.48779) avg lploss: 0.00000
train epoch 209 avg loss: 0.54785 (A-MSE: 0.47905) avg lploss: 0.00000
train epoch 210 avg loss: 0.57777 (A-MSE: 0.50630) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.89691 (A-MSE: 0.79370) avg lploss: 0.00000
==> test epoch 210 avg loss: 1.00305 (A-MSE: 0.89939) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00305 	 Best epoch 210
Validation loss decreased (0.916947 --> 0.896908).  Saving model ...
train epoch 211 avg loss: 0.53899 (A-MSE: 0.47312) avg lploss: 0.00000
train epoch 212 avg loss: 0.53549 (A-MSE: 0.46894) avg lploss: 0.00000
train epoch 213 avg loss: 0.58274 (A-MSE: 0.51227) avg lploss: 0.00000
train epoch 214 avg loss: 0.60503 (A-MSE: 0.53170) avg lploss: 0.00000
train epoch 215 avg loss: 0.59688 (A-MSE: 0.52574) avg lploss: 0.00000
==> val epoch 215 avg loss: 1.04928 (A-MSE: 0.92544) avg lploss: 0.00000
==> test epoch 215 avg loss: 1.17737 (A-MSE: 1.04818) avg lploss: 0.00000
*** Best Val Loss: 0.89691 	 Best Test Loss: 1.00305 	 Best epoch 210
EarlyStopping counter: 1 out of 50
train epoch 216 avg loss: 0.65161 (A-MSE: 0.56975) avg lploss: 0.00000
train epoch 217 avg loss: 0.58376 (A-MSE: 0.51749) avg lploss: 0.00000
train epoch 218 avg loss: 0.57110 (A-MSE: 0.50461) avg lploss: 0.00000
train epoch 219 avg loss: 0.54873 (A-MSE: 0.48196) avg lploss: 0.00000
train epoch 220 avg loss: 0.56652 (A-MSE: 0.49792) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.88458 (A-MSE: 0.77677) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.99070 (A-MSE: 0.88177) avg lploss: 0.00000
*** Best Val Loss: 0.88458 	 Best Test Loss: 0.99070 	 Best epoch 220
Validation loss decreased (0.896908 --> 0.884584).  Saving model ...
train epoch 221 avg loss: 0.54037 (A-MSE: 0.47586) avg lploss: 0.00000
train epoch 222 avg loss: 0.57140 (A-MSE: 0.50083) avg lploss: 0.00000
train epoch 223 avg loss: 0.61842 (A-MSE: 0.53797) avg lploss: 0.00000
train epoch 224 avg loss: 0.59289 (A-MSE: 0.51689) avg lploss: 0.00000
train epoch 225 avg loss: 0.59710 (A-MSE: 0.52550) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.84847 (A-MSE: 0.75502) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.97227 (A-MSE: 0.87305) avg lploss: 0.00000
*** Best Val Loss: 0.84847 	 Best Test Loss: 0.97227 	 Best epoch 225
Validation loss decreased (0.884584 --> 0.848468).  Saving model ...
train epoch 226 avg loss: 0.52080 (A-MSE: 0.45355) avg lploss: 0.00000
train epoch 227 avg loss: 0.51580 (A-MSE: 0.45471) avg lploss: 0.00000
train epoch 228 avg loss: 0.51383 (A-MSE: 0.45391) avg lploss: 0.00000
train epoch 229 avg loss: 0.57561 (A-MSE: 0.50506) avg lploss: 0.00000
train epoch 230 avg loss: 0.61328 (A-MSE: 0.53946) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.83155 (A-MSE: 0.73383) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.98228 (A-MSE: 0.88007) avg lploss: 0.00000
*** Best Val Loss: 0.83155 	 Best Test Loss: 0.98228 	 Best epoch 230
Validation loss decreased (0.848468 --> 0.831547).  Saving model ...
train epoch 231 avg loss: 0.59006 (A-MSE: 0.51852) avg lploss: 0.00000
train epoch 232 avg loss: 0.47983 (A-MSE: 0.42113) avg lploss: 0.00000
train epoch 233 avg loss: 0.54727 (A-MSE: 0.47411) avg lploss: 0.00000
train epoch 234 avg loss: 0.59715 (A-MSE: 0.52763) avg lploss: 0.00000
train epoch 235 avg loss: 0.55091 (A-MSE: 0.48395) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.78858 (A-MSE: 0.69917) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.93713 (A-MSE: 0.83263) avg lploss: 0.00000
*** Best Val Loss: 0.78858 	 Best Test Loss: 0.93713 	 Best epoch 235
Validation loss decreased (0.831547 --> 0.788584).  Saving model ...
train epoch 236 avg loss: 0.52672 (A-MSE: 0.46087) avg lploss: 0.00000
train epoch 237 avg loss: 0.51451 (A-MSE: 0.45369) avg lploss: 0.00000
train epoch 238 avg loss: 0.49064 (A-MSE: 0.43509) avg lploss: 0.00000
train epoch 239 avg loss: 0.52070 (A-MSE: 0.45426) avg lploss: 0.00000
train epoch 240 avg loss: 0.53584 (A-MSE: 0.47011) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.86624 (A-MSE: 0.77080) avg lploss: 0.00000
==> test epoch 240 avg loss: 1.07781 (A-MSE: 0.95897) avg lploss: 0.00000
*** Best Val Loss: 0.78858 	 Best Test Loss: 0.93713 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.50083 (A-MSE: 0.44236) avg lploss: 0.00000
train epoch 242 avg loss: 0.50668 (A-MSE: 0.44457) avg lploss: 0.00000
train epoch 243 avg loss: 0.49660 (A-MSE: 0.43718) avg lploss: 0.00000
train epoch 244 avg loss: 0.47994 (A-MSE: 0.42369) avg lploss: 0.00000
train epoch 245 avg loss: 0.48495 (A-MSE: 0.42500) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.85650 (A-MSE: 0.76866) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.96481 (A-MSE: 0.86840) avg lploss: 0.00000
*** Best Val Loss: 0.78858 	 Best Test Loss: 0.93713 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.60136 (A-MSE: 0.53145) avg lploss: 0.00000
train epoch 247 avg loss: 0.51733 (A-MSE: 0.45217) avg lploss: 0.00000
train epoch 248 avg loss: 0.45586 (A-MSE: 0.40151) avg lploss: 0.00000
train epoch 249 avg loss: 0.47586 (A-MSE: 0.41965) avg lploss: 0.00000
train epoch 250 avg loss: 0.48754 (A-MSE: 0.43274) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.84826 (A-MSE: 0.74599) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.90642 (A-MSE: 0.80020) avg lploss: 0.00000
*** Best Val Loss: 0.78858 	 Best Test Loss: 0.93713 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 0.43382 (A-MSE: 0.37979) avg lploss: 0.00000
train epoch 252 avg loss: 0.45497 (A-MSE: 0.40097) avg lploss: 0.00000
train epoch 253 avg loss: 0.46236 (A-MSE: 0.40663) avg lploss: 0.00000
train epoch 254 avg loss: 0.42713 (A-MSE: 0.37678) avg lploss: 0.00000
train epoch 255 avg loss: 0.42799 (A-MSE: 0.37764) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.71746 (A-MSE: 0.63645) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.86575 (A-MSE: 0.77364) avg lploss: 0.00000
*** Best Val Loss: 0.71746 	 Best Test Loss: 0.86575 	 Best epoch 255
Validation loss decreased (0.788584 --> 0.717455).  Saving model ...
train epoch 256 avg loss: 0.49054 (A-MSE: 0.42958) avg lploss: 0.00000
train epoch 257 avg loss: 0.43324 (A-MSE: 0.38090) avg lploss: 0.00000
train epoch 258 avg loss: 0.45071 (A-MSE: 0.39674) avg lploss: 0.00000
train epoch 259 avg loss: 0.43069 (A-MSE: 0.37894) avg lploss: 0.00000
train epoch 260 avg loss: 0.42517 (A-MSE: 0.37510) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.71296 (A-MSE: 0.63763) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.76893 (A-MSE: 0.69624) avg lploss: 0.00000
*** Best Val Loss: 0.71296 	 Best Test Loss: 0.76893 	 Best epoch 260
Validation loss decreased (0.717455 --> 0.712956).  Saving model ...
train epoch 261 avg loss: 0.45190 (A-MSE: 0.40074) avg lploss: 0.00000
train epoch 262 avg loss: 0.46920 (A-MSE: 0.41597) avg lploss: 0.00000
train epoch 263 avg loss: 0.46867 (A-MSE: 0.41621) avg lploss: 0.00000
train epoch 264 avg loss: 0.43498 (A-MSE: 0.38232) avg lploss: 0.00000
train epoch 265 avg loss: 0.40305 (A-MSE: 0.35508) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.75705 (A-MSE: 0.66411) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.89414 (A-MSE: 0.79422) avg lploss: 0.00000
*** Best Val Loss: 0.71296 	 Best Test Loss: 0.76893 	 Best epoch 260
EarlyStopping counter: 1 out of 50
train epoch 266 avg loss: 0.42547 (A-MSE: 0.37571) avg lploss: 0.00000
train epoch 267 avg loss: 0.46080 (A-MSE: 0.40709) avg lploss: 0.00000
train epoch 268 avg loss: 0.45456 (A-MSE: 0.40234) avg lploss: 0.00000
train epoch 269 avg loss: 0.45023 (A-MSE: 0.39801) avg lploss: 0.00000
train epoch 270 avg loss: 0.41680 (A-MSE: 0.36876) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.75353 (A-MSE: 0.67548) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.81858 (A-MSE: 0.73311) avg lploss: 0.00000
*** Best Val Loss: 0.71296 	 Best Test Loss: 0.76893 	 Best epoch 260
EarlyStopping counter: 2 out of 50
train epoch 271 avg loss: 0.50324 (A-MSE: 0.44978) avg lploss: 0.00000
train epoch 272 avg loss: 0.53860 (A-MSE: 0.47357) avg lploss: 0.00000
train epoch 273 avg loss: 0.44650 (A-MSE: 0.39220) avg lploss: 0.00000
train epoch 274 avg loss: 0.44395 (A-MSE: 0.39277) avg lploss: 0.00000
train epoch 275 avg loss: 0.41982 (A-MSE: 0.37406) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.71253 (A-MSE: 0.62623) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.83577 (A-MSE: 0.74024) avg lploss: 0.00000
*** Best Val Loss: 0.71253 	 Best Test Loss: 0.83577 	 Best epoch 275
Validation loss decreased (0.712956 --> 0.712532).  Saving model ...
train epoch 276 avg loss: 0.40005 (A-MSE: 0.35347) avg lploss: 0.00000
train epoch 277 avg loss: 0.41560 (A-MSE: 0.36713) avg lploss: 0.00000
train epoch 278 avg loss: 0.43092 (A-MSE: 0.38109) avg lploss: 0.00000
train epoch 279 avg loss: 0.46597 (A-MSE: 0.41201) avg lploss: 0.00000
train epoch 280 avg loss: 0.42352 (A-MSE: 0.37541) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.83670 (A-MSE: 0.73436) avg lploss: 0.00000
==> test epoch 280 avg loss: 1.02612 (A-MSE: 0.91497) avg lploss: 0.00000
*** Best Val Loss: 0.71253 	 Best Test Loss: 0.83577 	 Best epoch 275
EarlyStopping counter: 1 out of 50
train epoch 281 avg loss: 0.40969 (A-MSE: 0.36212) avg lploss: 0.00000
train epoch 282 avg loss: 0.38109 (A-MSE: 0.33584) avg lploss: 0.00000
train epoch 283 avg loss: 0.37273 (A-MSE: 0.33040) avg lploss: 0.00000
train epoch 284 avg loss: 0.39632 (A-MSE: 0.35098) avg lploss: 0.00000
train epoch 285 avg loss: 0.43308 (A-MSE: 0.38256) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.90150 (A-MSE: 0.79750) avg lploss: 0.00000
==> test epoch 285 avg loss: 1.05657 (A-MSE: 0.93432) avg lploss: 0.00000
*** Best Val Loss: 0.71253 	 Best Test Loss: 0.83577 	 Best epoch 275
EarlyStopping counter: 2 out of 50
train epoch 286 avg loss: 0.47087 (A-MSE: 0.41117) avg lploss: 0.00000
train epoch 287 avg loss: 0.38787 (A-MSE: 0.34371) avg lploss: 0.00000
train epoch 288 avg loss: 0.39406 (A-MSE: 0.34669) avg lploss: 0.00000
train epoch 289 avg loss: 0.40492 (A-MSE: 0.35737) avg lploss: 0.00000
train epoch 290 avg loss: 0.38090 (A-MSE: 0.33761) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.78276 (A-MSE: 0.69050) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.96099 (A-MSE: 0.85747) avg lploss: 0.00000
*** Best Val Loss: 0.71253 	 Best Test Loss: 0.83577 	 Best epoch 275
EarlyStopping counter: 3 out of 50
train epoch 291 avg loss: 0.36989 (A-MSE: 0.32754) avg lploss: 0.00000
train epoch 292 avg loss: 0.36404 (A-MSE: 0.32467) avg lploss: 0.00000
train epoch 293 avg loss: 0.42338 (A-MSE: 0.37338) avg lploss: 0.00000
train epoch 294 avg loss: 0.41045 (A-MSE: 0.35907) avg lploss: 0.00000
train epoch 295 avg loss: 0.39303 (A-MSE: 0.35115) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.69857 (A-MSE: 0.61071) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.80057 (A-MSE: 0.70737) avg lploss: 0.00000
*** Best Val Loss: 0.69857 	 Best Test Loss: 0.80057 	 Best epoch 295
Validation loss decreased (0.712532 --> 0.698566).  Saving model ...
train epoch 296 avg loss: 0.38260 (A-MSE: 0.33761) avg lploss: 0.00000
train epoch 297 avg loss: 0.35848 (A-MSE: 0.31861) avg lploss: 0.00000
train epoch 298 avg loss: 0.34701 (A-MSE: 0.30724) avg lploss: 0.00000
train epoch 299 avg loss: 0.37821 (A-MSE: 0.33422) avg lploss: 0.00000
train epoch 300 avg loss: 0.33234 (A-MSE: 0.29606) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.63811 (A-MSE: 0.56000) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.71888 (A-MSE: 0.63760) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
Validation loss decreased (0.698566 --> 0.638112).  Saving model ...
train epoch 301 avg loss: 0.36006 (A-MSE: 0.32061) avg lploss: 0.00000
train epoch 302 avg loss: 0.35021 (A-MSE: 0.30991) avg lploss: 0.00000
train epoch 303 avg loss: 0.32687 (A-MSE: 0.29041) avg lploss: 0.00000
train epoch 304 avg loss: 0.35152 (A-MSE: 0.31073) avg lploss: 0.00000
train epoch 305 avg loss: 0.32992 (A-MSE: 0.29615) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.65285 (A-MSE: 0.57759) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.70919 (A-MSE: 0.63002) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
EarlyStopping counter: 1 out of 50
train epoch 306 avg loss: 0.33689 (A-MSE: 0.29776) avg lploss: 0.00000
train epoch 307 avg loss: 0.35249 (A-MSE: 0.31264) avg lploss: 0.00000
train epoch 308 avg loss: 0.32416 (A-MSE: 0.28880) avg lploss: 0.00000
train epoch 309 avg loss: 0.36257 (A-MSE: 0.31924) avg lploss: 0.00000
train epoch 310 avg loss: 0.33259 (A-MSE: 0.29828) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.65939 (A-MSE: 0.57675) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.73246 (A-MSE: 0.64271) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
EarlyStopping counter: 2 out of 50
train epoch 311 avg loss: 0.31759 (A-MSE: 0.28100) avg lploss: 0.00000
train epoch 312 avg loss: 0.33613 (A-MSE: 0.29952) avg lploss: 0.00000
train epoch 313 avg loss: 0.37521 (A-MSE: 0.33158) avg lploss: 0.00000
train epoch 314 avg loss: 0.36367 (A-MSE: 0.32283) avg lploss: 0.00000
train epoch 315 avg loss: 0.42942 (A-MSE: 0.37772) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.87452 (A-MSE: 0.76590) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.98100 (A-MSE: 0.87123) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
EarlyStopping counter: 3 out of 50
train epoch 316 avg loss: 0.39271 (A-MSE: 0.35279) avg lploss: 0.00000
train epoch 317 avg loss: 0.38345 (A-MSE: 0.33863) avg lploss: 0.00000
train epoch 318 avg loss: 0.42471 (A-MSE: 0.37816) avg lploss: 0.00000
train epoch 319 avg loss: 0.41806 (A-MSE: 0.36872) avg lploss: 0.00000
train epoch 320 avg loss: 0.37049 (A-MSE: 0.33341) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.68145 (A-MSE: 0.60151) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.81153 (A-MSE: 0.72438) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
EarlyStopping counter: 4 out of 50
train epoch 321 avg loss: 0.33380 (A-MSE: 0.29519) avg lploss: 0.00000
train epoch 322 avg loss: 0.32344 (A-MSE: 0.28694) avg lploss: 0.00000
train epoch 323 avg loss: 0.30362 (A-MSE: 0.26930) avg lploss: 0.00000
train epoch 324 avg loss: 0.36638 (A-MSE: 0.32520) avg lploss: 0.00000
train epoch 325 avg loss: 0.36313 (A-MSE: 0.32188) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.64512 (A-MSE: 0.55972) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.72784 (A-MSE: 0.63276) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
EarlyStopping counter: 5 out of 50
train epoch 326 avg loss: 0.35760 (A-MSE: 0.31647) avg lploss: 0.00000
train epoch 327 avg loss: 0.33842 (A-MSE: 0.30027) avg lploss: 0.00000
train epoch 328 avg loss: 0.30712 (A-MSE: 0.27378) avg lploss: 0.00000
train epoch 329 avg loss: 0.29876 (A-MSE: 0.26714) avg lploss: 0.00000
train epoch 330 avg loss: 0.32196 (A-MSE: 0.28376) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.66600 (A-MSE: 0.59379) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.73447 (A-MSE: 0.65663) avg lploss: 0.00000
*** Best Val Loss: 0.63811 	 Best Test Loss: 0.71888 	 Best epoch 300
EarlyStopping counter: 6 out of 50
train epoch 331 avg loss: 0.33009 (A-MSE: 0.29321) avg lploss: 0.00000
train epoch 332 avg loss: 0.33006 (A-MSE: 0.29173) avg lploss: 0.00000
train epoch 333 avg loss: 0.33633 (A-MSE: 0.29850) avg lploss: 0.00000
train epoch 334 avg loss: 0.32902 (A-MSE: 0.29173) avg lploss: 0.00000
train epoch 335 avg loss: 0.31368 (A-MSE: 0.28016) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.57557 (A-MSE: 0.50395) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.62983 (A-MSE: 0.56043) avg lploss: 0.00000
*** Best Val Loss: 0.57557 	 Best Test Loss: 0.62983 	 Best epoch 335
Validation loss decreased (0.638112 --> 0.575567).  Saving model ...
train epoch 336 avg loss: 0.31128 (A-MSE: 0.27602) avg lploss: 0.00000
train epoch 337 avg loss: 0.32399 (A-MSE: 0.28622) avg lploss: 0.00000
train epoch 338 avg loss: 0.33846 (A-MSE: 0.30084) avg lploss: 0.00000
train epoch 339 avg loss: 0.33874 (A-MSE: 0.29977) avg lploss: 0.00000
train epoch 340 avg loss: 0.33843 (A-MSE: 0.30168) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.69063 (A-MSE: 0.60754) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.73700 (A-MSE: 0.65063) avg lploss: 0.00000
*** Best Val Loss: 0.57557 	 Best Test Loss: 0.62983 	 Best epoch 335
EarlyStopping counter: 1 out of 50
train epoch 341 avg loss: 0.30899 (A-MSE: 0.27507) avg lploss: 0.00000
train epoch 342 avg loss: 0.29008 (A-MSE: 0.25703) avg lploss: 0.00000
train epoch 343 avg loss: 0.29931 (A-MSE: 0.26795) avg lploss: 0.00000
train epoch 344 avg loss: 0.31525 (A-MSE: 0.28039) avg lploss: 0.00000
train epoch 345 avg loss: 0.30251 (A-MSE: 0.26896) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.64296 (A-MSE: 0.56557) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.72342 (A-MSE: 0.62944) avg lploss: 0.00000
*** Best Val Loss: 0.57557 	 Best Test Loss: 0.62983 	 Best epoch 335
EarlyStopping counter: 2 out of 50
train epoch 346 avg loss: 0.31582 (A-MSE: 0.27965) avg lploss: 0.00000
train epoch 347 avg loss: 0.34815 (A-MSE: 0.30805) avg lploss: 0.00000
train epoch 348 avg loss: 0.29615 (A-MSE: 0.26047) avg lploss: 0.00000
train epoch 349 avg loss: 0.33301 (A-MSE: 0.29561) avg lploss: 0.00000
train epoch 350 avg loss: 0.33688 (A-MSE: 0.29869) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.64470 (A-MSE: 0.56484) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.73133 (A-MSE: 0.65077) avg lploss: 0.00000
*** Best Val Loss: 0.57557 	 Best Test Loss: 0.62983 	 Best epoch 335
EarlyStopping counter: 3 out of 50
train epoch 351 avg loss: 0.30704 (A-MSE: 0.27227) avg lploss: 0.00000
train epoch 352 avg loss: 0.29163 (A-MSE: 0.25872) avg lploss: 0.00000
train epoch 353 avg loss: 0.27088 (A-MSE: 0.24132) avg lploss: 0.00000
train epoch 354 avg loss: 0.28683 (A-MSE: 0.25582) avg lploss: 0.00000
train epoch 355 avg loss: 0.31147 (A-MSE: 0.27844) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.63067 (A-MSE: 0.55134) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.73036 (A-MSE: 0.63724) avg lploss: 0.00000
*** Best Val Loss: 0.57557 	 Best Test Loss: 0.62983 	 Best epoch 335
EarlyStopping counter: 4 out of 50
train epoch 356 avg loss: 0.32855 (A-MSE: 0.29071) avg lploss: 0.00000
train epoch 357 avg loss: 0.28614 (A-MSE: 0.25459) avg lploss: 0.00000
train epoch 358 avg loss: 0.27581 (A-MSE: 0.24673) avg lploss: 0.00000
train epoch 359 avg loss: 0.28675 (A-MSE: 0.25426) avg lploss: 0.00000
train epoch 360 avg loss: 0.28696 (A-MSE: 0.25365) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.57456 (A-MSE: 0.50316) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.65395 (A-MSE: 0.57534) avg lploss: 0.00000
*** Best Val Loss: 0.57456 	 Best Test Loss: 0.65395 	 Best epoch 360
Validation loss decreased (0.575567 --> 0.574563).  Saving model ...
train epoch 361 avg loss: 0.28678 (A-MSE: 0.25326) avg lploss: 0.00000
train epoch 362 avg loss: 0.30656 (A-MSE: 0.26959) avg lploss: 0.00000
train epoch 363 avg loss: 0.26250 (A-MSE: 0.23297) avg lploss: 0.00000
train epoch 364 avg loss: 0.27645 (A-MSE: 0.24504) avg lploss: 0.00000
train epoch 365 avg loss: 0.25674 (A-MSE: 0.22765) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.63477 (A-MSE: 0.55244) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.70818 (A-MSE: 0.61684) avg lploss: 0.00000
*** Best Val Loss: 0.57456 	 Best Test Loss: 0.65395 	 Best epoch 360
EarlyStopping counter: 1 out of 50
train epoch 366 avg loss: 0.30461 (A-MSE: 0.27096) avg lploss: 0.00000
train epoch 367 avg loss: 0.29416 (A-MSE: 0.25980) avg lploss: 0.00000
train epoch 368 avg loss: 0.28005 (A-MSE: 0.24772) avg lploss: 0.00000
train epoch 369 avg loss: 0.27879 (A-MSE: 0.24860) avg lploss: 0.00000
train epoch 370 avg loss: 0.34605 (A-MSE: 0.30790) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.63737 (A-MSE: 0.56470) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.68759 (A-MSE: 0.60736) avg lploss: 0.00000
*** Best Val Loss: 0.57456 	 Best Test Loss: 0.65395 	 Best epoch 360
EarlyStopping counter: 2 out of 50
train epoch 371 avg loss: 0.32357 (A-MSE: 0.28609) avg lploss: 0.00000
train epoch 372 avg loss: 0.27195 (A-MSE: 0.24194) avg lploss: 0.00000
train epoch 373 avg loss: 0.27110 (A-MSE: 0.24155) avg lploss: 0.00000
train epoch 374 avg loss: 0.26024 (A-MSE: 0.22910) avg lploss: 0.00000
train epoch 375 avg loss: 0.28133 (A-MSE: 0.25168) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.57220 (A-MSE: 0.49919) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.69600 (A-MSE: 0.61201) avg lploss: 0.00000
*** Best Val Loss: 0.57220 	 Best Test Loss: 0.69600 	 Best epoch 375
Validation loss decreased (0.574563 --> 0.572201).  Saving model ...
train epoch 376 avg loss: 0.32412 (A-MSE: 0.28522) avg lploss: 0.00000
train epoch 377 avg loss: 0.29021 (A-MSE: 0.25556) avg lploss: 0.00000
train epoch 378 avg loss: 0.26736 (A-MSE: 0.23775) avg lploss: 0.00000
train epoch 379 avg loss: 0.27305 (A-MSE: 0.24238) avg lploss: 0.00000
train epoch 380 avg loss: 0.26471 (A-MSE: 0.23713) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.58660 (A-MSE: 0.51281) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.67265 (A-MSE: 0.59271) avg lploss: 0.00000
*** Best Val Loss: 0.57220 	 Best Test Loss: 0.69600 	 Best epoch 375
EarlyStopping counter: 1 out of 50
train epoch 381 avg loss: 0.27270 (A-MSE: 0.24193) avg lploss: 0.00000
train epoch 382 avg loss: 0.25658 (A-MSE: 0.22855) avg lploss: 0.00000
train epoch 383 avg loss: 0.26613 (A-MSE: 0.23750) avg lploss: 0.00000
train epoch 384 avg loss: 0.29574 (A-MSE: 0.26360) avg lploss: 0.00000
train epoch 385 avg loss: 0.25836 (A-MSE: 0.23070) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.60174 (A-MSE: 0.52491) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.66173 (A-MSE: 0.58269) avg lploss: 0.00000
*** Best Val Loss: 0.57220 	 Best Test Loss: 0.69600 	 Best epoch 375
EarlyStopping counter: 2 out of 50
train epoch 386 avg loss: 0.27266 (A-MSE: 0.24172) avg lploss: 0.00000
train epoch 387 avg loss: 0.24647 (A-MSE: 0.21888) avg lploss: 0.00000
train epoch 388 avg loss: 0.26775 (A-MSE: 0.23901) avg lploss: 0.00000
train epoch 389 avg loss: 0.26046 (A-MSE: 0.23067) avg lploss: 0.00000
train epoch 390 avg loss: 0.26456 (A-MSE: 0.23457) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.56246 (A-MSE: 0.49110) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.60244 (A-MSE: 0.53313) avg lploss: 0.00000
*** Best Val Loss: 0.56246 	 Best Test Loss: 0.60244 	 Best epoch 390
Validation loss decreased (0.572201 --> 0.562459).  Saving model ...
train epoch 391 avg loss: 0.26801 (A-MSE: 0.23671) avg lploss: 0.00000
train epoch 392 avg loss: 0.30218 (A-MSE: 0.26694) avg lploss: 0.00000
train epoch 393 avg loss: 0.29131 (A-MSE: 0.25799) avg lploss: 0.00000
train epoch 394 avg loss: 0.28016 (A-MSE: 0.24645) avg lploss: 0.00000
train epoch 395 avg loss: 0.29925 (A-MSE: 0.26461) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.66019 (A-MSE: 0.58381) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.71348 (A-MSE: 0.63046) avg lploss: 0.00000
*** Best Val Loss: 0.56246 	 Best Test Loss: 0.60244 	 Best epoch 390
EarlyStopping counter: 1 out of 50
train epoch 396 avg loss: 0.29557 (A-MSE: 0.26232) avg lploss: 0.00000
train epoch 397 avg loss: 0.27308 (A-MSE: 0.24282) avg lploss: 0.00000
train epoch 398 avg loss: 0.25915 (A-MSE: 0.22914) avg lploss: 0.00000
train epoch 399 avg loss: 0.25253 (A-MSE: 0.22404) avg lploss: 0.00000
train epoch 400 avg loss: 0.26277 (A-MSE: 0.23180) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.61790 (A-MSE: 0.54369) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.67036 (A-MSE: 0.59587) avg lploss: 0.00000
*** Best Val Loss: 0.56246 	 Best Test Loss: 0.60244 	 Best epoch 390
EarlyStopping counter: 2 out of 50
train epoch 401 avg loss: 0.24686 (A-MSE: 0.21959) avg lploss: 0.00000
train epoch 402 avg loss: 0.25362 (A-MSE: 0.22571) avg lploss: 0.00000
train epoch 403 avg loss: 0.31205 (A-MSE: 0.27841) avg lploss: 0.00000
train epoch 404 avg loss: 0.29476 (A-MSE: 0.26402) avg lploss: 0.00000
train epoch 405 avg loss: 0.26842 (A-MSE: 0.23814) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.56210 (A-MSE: 0.49276) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.61839 (A-MSE: 0.54399) avg lploss: 0.00000
*** Best Val Loss: 0.56210 	 Best Test Loss: 0.61839 	 Best epoch 405
Validation loss decreased (0.562459 --> 0.562096).  Saving model ...
train epoch 406 avg loss: 0.24382 (A-MSE: 0.21439) avg lploss: 0.00000
train epoch 407 avg loss: 0.23258 (A-MSE: 0.20643) avg lploss: 0.00000
train epoch 408 avg loss: 0.23323 (A-MSE: 0.20738) avg lploss: 0.00000
train epoch 409 avg loss: 0.24750 (A-MSE: 0.21824) avg lploss: 0.00000
train epoch 410 avg loss: 0.26700 (A-MSE: 0.23644) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.63959 (A-MSE: 0.55998) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.75649 (A-MSE: 0.66458) avg lploss: 0.00000
*** Best Val Loss: 0.56210 	 Best Test Loss: 0.61839 	 Best epoch 405
EarlyStopping counter: 1 out of 50
train epoch 411 avg loss: 0.26947 (A-MSE: 0.23769) avg lploss: 0.00000
train epoch 412 avg loss: 0.24774 (A-MSE: 0.21985) avg lploss: 0.00000
train epoch 413 avg loss: 0.23405 (A-MSE: 0.20909) avg lploss: 0.00000
train epoch 414 avg loss: 0.24171 (A-MSE: 0.21589) avg lploss: 0.00000
train epoch 415 avg loss: 0.27241 (A-MSE: 0.24111) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.68995 (A-MSE: 0.59894) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.70868 (A-MSE: 0.62104) avg lploss: 0.00000
*** Best Val Loss: 0.56210 	 Best Test Loss: 0.61839 	 Best epoch 405
EarlyStopping counter: 2 out of 50
train epoch 416 avg loss: 0.25223 (A-MSE: 0.22359) avg lploss: 0.00000
train epoch 417 avg loss: 0.27493 (A-MSE: 0.24399) avg lploss: 0.00000
train epoch 418 avg loss: 0.23197 (A-MSE: 0.20542) avg lploss: 0.00000
train epoch 419 avg loss: 0.25276 (A-MSE: 0.22336) avg lploss: 0.00000
train epoch 420 avg loss: 0.26908 (A-MSE: 0.23832) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.57156 (A-MSE: 0.50197) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.62741 (A-MSE: 0.55426) avg lploss: 0.00000
*** Best Val Loss: 0.56210 	 Best Test Loss: 0.61839 	 Best epoch 405
EarlyStopping counter: 3 out of 50
train epoch 421 avg loss: 0.24441 (A-MSE: 0.21803) avg lploss: 0.00000
train epoch 422 avg loss: 0.23133 (A-MSE: 0.20606) avg lploss: 0.00000
train epoch 423 avg loss: 0.25596 (A-MSE: 0.22478) avg lploss: 0.00000
train epoch 424 avg loss: 0.30455 (A-MSE: 0.26786) avg lploss: 0.00000
train epoch 425 avg loss: 0.24778 (A-MSE: 0.21928) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.58754 (A-MSE: 0.51618) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.60851 (A-MSE: 0.53944) avg lploss: 0.00000
*** Best Val Loss: 0.56210 	 Best Test Loss: 0.61839 	 Best epoch 405
EarlyStopping counter: 4 out of 50
train epoch 426 avg loss: 0.26550 (A-MSE: 0.23572) avg lploss: 0.00000
train epoch 427 avg loss: 0.24498 (A-MSE: 0.21769) avg lploss: 0.00000
train epoch 428 avg loss: 0.23367 (A-MSE: 0.20729) avg lploss: 0.00000
train epoch 429 avg loss: 0.23786 (A-MSE: 0.21282) avg lploss: 0.00000
train epoch 430 avg loss: 0.24639 (A-MSE: 0.21786) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.57805 (A-MSE: 0.50525) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.63948 (A-MSE: 0.56259) avg lploss: 0.00000
*** Best Val Loss: 0.56210 	 Best Test Loss: 0.61839 	 Best epoch 405
EarlyStopping counter: 5 out of 50
train epoch 431 avg loss: 0.21963 (A-MSE: 0.19503) avg lploss: 0.00000
train epoch 432 avg loss: 0.23341 (A-MSE: 0.20714) avg lploss: 0.00000
train epoch 433 avg loss: 0.22732 (A-MSE: 0.19951) avg lploss: 0.00000
train epoch 434 avg loss: 0.22395 (A-MSE: 0.19870) avg lploss: 0.00000
train epoch 435 avg loss: 0.23527 (A-MSE: 0.20733) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.55737 (A-MSE: 0.48161) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.61529 (A-MSE: 0.53650) avg lploss: 0.00000
*** Best Val Loss: 0.55737 	 Best Test Loss: 0.61529 	 Best epoch 435
Validation loss decreased (0.562096 --> 0.557367).  Saving model ...
train epoch 436 avg loss: 0.21826 (A-MSE: 0.19326) avg lploss: 0.00000
train epoch 437 avg loss: 0.24647 (A-MSE: 0.21747) avg lploss: 0.00000
train epoch 438 avg loss: 0.24640 (A-MSE: 0.21584) avg lploss: 0.00000
train epoch 439 avg loss: 0.22170 (A-MSE: 0.19719) avg lploss: 0.00000
train epoch 440 avg loss: 0.23335 (A-MSE: 0.20617) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.59743 (A-MSE: 0.50922) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.67597 (A-MSE: 0.58172) avg lploss: 0.00000
*** Best Val Loss: 0.55737 	 Best Test Loss: 0.61529 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 0.24403 (A-MSE: 0.21574) avg lploss: 0.00000
train epoch 442 avg loss: 0.23345 (A-MSE: 0.20439) avg lploss: 0.00000
train epoch 443 avg loss: 0.24610 (A-MSE: 0.21798) avg lploss: 0.00000
train epoch 444 avg loss: 0.25417 (A-MSE: 0.22363) avg lploss: 0.00000
train epoch 445 avg loss: 0.21215 (A-MSE: 0.18765) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.51634 (A-MSE: 0.44878) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.56321 (A-MSE: 0.49134) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
Validation loss decreased (0.557367 --> 0.516337).  Saving model ...
train epoch 446 avg loss: 0.21567 (A-MSE: 0.19181) avg lploss: 0.00000
train epoch 447 avg loss: 0.21796 (A-MSE: 0.19365) avg lploss: 0.00000
train epoch 448 avg loss: 0.21018 (A-MSE: 0.18524) avg lploss: 0.00000
train epoch 449 avg loss: 0.20347 (A-MSE: 0.18077) avg lploss: 0.00000
train epoch 450 avg loss: 0.23832 (A-MSE: 0.20950) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.57372 (A-MSE: 0.49815) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.64624 (A-MSE: 0.56337) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 1 out of 50
train epoch 451 avg loss: 0.23917 (A-MSE: 0.21152) avg lploss: 0.00000
train epoch 452 avg loss: 0.25130 (A-MSE: 0.22159) avg lploss: 0.00000
train epoch 453 avg loss: 0.27164 (A-MSE: 0.23999) avg lploss: 0.00000
train epoch 454 avg loss: 0.30346 (A-MSE: 0.26476) avg lploss: 0.00000
train epoch 455 avg loss: 0.30323 (A-MSE: 0.27160) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.62643 (A-MSE: 0.54900) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.65918 (A-MSE: 0.58102) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 2 out of 50
train epoch 456 avg loss: 0.23395 (A-MSE: 0.20761) avg lploss: 0.00000
train epoch 457 avg loss: 0.23996 (A-MSE: 0.21285) avg lploss: 0.00000
train epoch 458 avg loss: 0.23726 (A-MSE: 0.20741) avg lploss: 0.00000
train epoch 459 avg loss: 0.23874 (A-MSE: 0.21173) avg lploss: 0.00000
train epoch 460 avg loss: 0.23882 (A-MSE: 0.21048) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.54798 (A-MSE: 0.47277) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.56738 (A-MSE: 0.49831) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 3 out of 50
train epoch 461 avg loss: 0.23892 (A-MSE: 0.21160) avg lploss: 0.00000
train epoch 462 avg loss: 0.21955 (A-MSE: 0.19448) avg lploss: 0.00000
train epoch 463 avg loss: 0.20204 (A-MSE: 0.17987) avg lploss: 0.00000
train epoch 464 avg loss: 0.22296 (A-MSE: 0.19703) avg lploss: 0.00000
train epoch 465 avg loss: 0.21137 (A-MSE: 0.18803) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.52429 (A-MSE: 0.45585) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.60853 (A-MSE: 0.53405) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 4 out of 50
train epoch 466 avg loss: 0.22771 (A-MSE: 0.20125) avg lploss: 0.00000
train epoch 467 avg loss: 0.20246 (A-MSE: 0.18078) avg lploss: 0.00000
train epoch 468 avg loss: 0.19597 (A-MSE: 0.17476) avg lploss: 0.00000
train epoch 469 avg loss: 0.20966 (A-MSE: 0.18695) avg lploss: 0.00000
train epoch 470 avg loss: 0.20277 (A-MSE: 0.18031) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.57993 (A-MSE: 0.50411) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.65453 (A-MSE: 0.56508) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 5 out of 50
train epoch 471 avg loss: 0.21835 (A-MSE: 0.19194) avg lploss: 0.00000
train epoch 472 avg loss: 0.19902 (A-MSE: 0.17489) avg lploss: 0.00000
train epoch 473 avg loss: 0.22972 (A-MSE: 0.20372) avg lploss: 0.00000
train epoch 474 avg loss: 0.20175 (A-MSE: 0.17883) avg lploss: 0.00000
train epoch 475 avg loss: 0.21184 (A-MSE: 0.18797) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.64914 (A-MSE: 0.56698) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.69237 (A-MSE: 0.60394) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 6 out of 50
train epoch 476 avg loss: 0.23728 (A-MSE: 0.21013) avg lploss: 0.00000
train epoch 477 avg loss: 0.23431 (A-MSE: 0.20820) avg lploss: 0.00000
train epoch 478 avg loss: 0.22801 (A-MSE: 0.20065) avg lploss: 0.00000
train epoch 479 avg loss: 0.22724 (A-MSE: 0.19981) avg lploss: 0.00000
train epoch 480 avg loss: 0.21582 (A-MSE: 0.19053) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.52951 (A-MSE: 0.45578) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.56130 (A-MSE: 0.48799) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 7 out of 50
train epoch 481 avg loss: 0.22479 (A-MSE: 0.19734) avg lploss: 0.00000
train epoch 482 avg loss: 0.20565 (A-MSE: 0.18296) avg lploss: 0.00000
train epoch 483 avg loss: 0.20198 (A-MSE: 0.17759) avg lploss: 0.00000
train epoch 484 avg loss: 0.20173 (A-MSE: 0.17817) avg lploss: 0.00000
train epoch 485 avg loss: 0.19372 (A-MSE: 0.17074) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.53303 (A-MSE: 0.46147) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.60887 (A-MSE: 0.52835) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 8 out of 50
train epoch 486 avg loss: 0.18573 (A-MSE: 0.16406) avg lploss: 0.00000
train epoch 487 avg loss: 0.19031 (A-MSE: 0.16860) avg lploss: 0.00000
train epoch 488 avg loss: 0.20066 (A-MSE: 0.17696) avg lploss: 0.00000
train epoch 489 avg loss: 0.20825 (A-MSE: 0.18379) avg lploss: 0.00000
train epoch 490 avg loss: 0.24014 (A-MSE: 0.21088) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.63370 (A-MSE: 0.55341) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.61291 (A-MSE: 0.53814) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 9 out of 50
train epoch 491 avg loss: 0.23627 (A-MSE: 0.20720) avg lploss: 0.00000
train epoch 492 avg loss: 0.23195 (A-MSE: 0.20687) avg lploss: 0.00000
train epoch 493 avg loss: 0.21079 (A-MSE: 0.18510) avg lploss: 0.00000
train epoch 494 avg loss: 0.22948 (A-MSE: 0.20310) avg lploss: 0.00000
train epoch 495 avg loss: 0.22247 (A-MSE: 0.19455) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.55473 (A-MSE: 0.49053) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.57291 (A-MSE: 0.50576) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 10 out of 50
train epoch 496 avg loss: 0.21300 (A-MSE: 0.18977) avg lploss: 0.00000
train epoch 497 avg loss: 0.21730 (A-MSE: 0.19252) avg lploss: 0.00000
train epoch 498 avg loss: 0.23581 (A-MSE: 0.20988) avg lploss: 0.00000
train epoch 499 avg loss: 0.19726 (A-MSE: 0.17297) avg lploss: 0.00000
train epoch 500 avg loss: 0.19957 (A-MSE: 0.17740) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.51707 (A-MSE: 0.44477) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.58841 (A-MSE: 0.51010) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 11 out of 50
train epoch 501 avg loss: 0.19804 (A-MSE: 0.17597) avg lploss: 0.00000
train epoch 502 avg loss: 0.19397 (A-MSE: 0.17149) avg lploss: 0.00000
train epoch 503 avg loss: 0.21461 (A-MSE: 0.18890) avg lploss: 0.00000
train epoch 504 avg loss: 0.21026 (A-MSE: 0.18676) avg lploss: 0.00000
train epoch 505 avg loss: 0.19208 (A-MSE: 0.17053) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.53999 (A-MSE: 0.46165) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.58059 (A-MSE: 0.50350) avg lploss: 0.00000
*** Best Val Loss: 0.51634 	 Best Test Loss: 0.56321 	 Best epoch 445
EarlyStopping counter: 12 out of 50
train epoch 506 avg loss: 0.18517 (A-MSE: 0.16495) avg lploss: 0.00000
train epoch 507 avg loss: 0.16871 (A-MSE: 0.14878) avg lploss: 0.00000
train epoch 508 avg loss: 0.17955 (A-MSE: 0.15762) avg lploss: 0.00000
train epoch 509 avg loss: 0.18027 (A-MSE: 0.15950) avg lploss: 0.00000
train epoch 510 avg loss: 0.17946 (A-MSE: 0.15947) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.49050 (A-MSE: 0.42474) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.53232 (A-MSE: 0.46598) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
Validation loss decreased (0.516337 --> 0.490504).  Saving model ...
train epoch 511 avg loss: 0.17671 (A-MSE: 0.15705) avg lploss: 0.00000
train epoch 512 avg loss: 0.17751 (A-MSE: 0.15778) avg lploss: 0.00000
train epoch 513 avg loss: 0.17001 (A-MSE: 0.15069) avg lploss: 0.00000
train epoch 514 avg loss: 0.19179 (A-MSE: 0.17116) avg lploss: 0.00000
train epoch 515 avg loss: 0.21411 (A-MSE: 0.18986) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.51412 (A-MSE: 0.45315) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.55218 (A-MSE: 0.48928) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
EarlyStopping counter: 1 out of 50
train epoch 516 avg loss: 0.20646 (A-MSE: 0.18281) avg lploss: 0.00000
train epoch 517 avg loss: 0.18622 (A-MSE: 0.16533) avg lploss: 0.00000
train epoch 518 avg loss: 0.21931 (A-MSE: 0.19156) avg lploss: 0.00000
train epoch 519 avg loss: 0.19916 (A-MSE: 0.17567) avg lploss: 0.00000
train epoch 520 avg loss: 0.20583 (A-MSE: 0.18164) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.59579 (A-MSE: 0.51382) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.66257 (A-MSE: 0.57849) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
EarlyStopping counter: 2 out of 50
train epoch 521 avg loss: 0.22783 (A-MSE: 0.19981) avg lploss: 0.00000
train epoch 522 avg loss: 0.21098 (A-MSE: 0.18659) avg lploss: 0.00000
train epoch 523 avg loss: 0.21785 (A-MSE: 0.19236) avg lploss: 0.00000
train epoch 524 avg loss: 0.19074 (A-MSE: 0.17002) avg lploss: 0.00000
train epoch 525 avg loss: 0.20252 (A-MSE: 0.17976) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.50572 (A-MSE: 0.43812) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.56384 (A-MSE: 0.49408) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
EarlyStopping counter: 3 out of 50
train epoch 526 avg loss: 0.18571 (A-MSE: 0.16378) avg lploss: 0.00000
train epoch 527 avg loss: 0.17482 (A-MSE: 0.15495) avg lploss: 0.00000
train epoch 528 avg loss: 0.17555 (A-MSE: 0.15512) avg lploss: 0.00000
train epoch 529 avg loss: 0.17498 (A-MSE: 0.15472) avg lploss: 0.00000
train epoch 530 avg loss: 0.19524 (A-MSE: 0.17246) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.53820 (A-MSE: 0.46252) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.57510 (A-MSE: 0.50125) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
EarlyStopping counter: 4 out of 50
train epoch 531 avg loss: 0.18988 (A-MSE: 0.16745) avg lploss: 0.00000
train epoch 532 avg loss: 0.20343 (A-MSE: 0.18104) avg lploss: 0.00000
train epoch 533 avg loss: 0.19596 (A-MSE: 0.17419) avg lploss: 0.00000
train epoch 534 avg loss: 0.22820 (A-MSE: 0.20287) avg lploss: 0.00000
train epoch 535 avg loss: 0.19539 (A-MSE: 0.17262) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.50654 (A-MSE: 0.44041) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.57480 (A-MSE: 0.50634) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
EarlyStopping counter: 5 out of 50
train epoch 536 avg loss: 0.19236 (A-MSE: 0.17086) avg lploss: 0.00000
train epoch 537 avg loss: 0.17841 (A-MSE: 0.15725) avg lploss: 0.00000
train epoch 538 avg loss: 0.18369 (A-MSE: 0.16281) avg lploss: 0.00000
train epoch 539 avg loss: 0.20698 (A-MSE: 0.18164) avg lploss: 0.00000
train epoch 540 avg loss: 0.21254 (A-MSE: 0.18646) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.52375 (A-MSE: 0.45129) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.57669 (A-MSE: 0.50420) avg lploss: 0.00000
*** Best Val Loss: 0.49050 	 Best Test Loss: 0.53232 	 Best epoch 510
EarlyStopping counter: 6 out of 50
train epoch 541 avg loss: 0.20869 (A-MSE: 0.18512) avg lploss: 0.00000
train epoch 542 avg loss: 0.20991 (A-MSE: 0.18430) avg lploss: 0.00000
train epoch 543 avg loss: 0.19644 (A-MSE: 0.17458) avg lploss: 0.00000
train epoch 544 avg loss: 0.20605 (A-MSE: 0.18017) avg lploss: 0.00000
train epoch 545 avg loss: 0.19633 (A-MSE: 0.17435) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.47586 (A-MSE: 0.41834) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.53720 (A-MSE: 0.47325) avg lploss: 0.00000
*** Best Val Loss: 0.47586 	 Best Test Loss: 0.53720 	 Best epoch 545
Validation loss decreased (0.490504 --> 0.475863).  Saving model ...
train epoch 546 avg loss: 0.18200 (A-MSE: 0.16260) avg lploss: 0.00000
train epoch 547 avg loss: 0.18136 (A-MSE: 0.16023) avg lploss: 0.00000
train epoch 548 avg loss: 0.18441 (A-MSE: 0.16213) avg lploss: 0.00000
train epoch 549 avg loss: 0.18883 (A-MSE: 0.16817) avg lploss: 0.00000
train epoch 550 avg loss: 0.20625 (A-MSE: 0.18266) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.47427 (A-MSE: 0.41207) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.52016 (A-MSE: 0.45790) avg lploss: 0.00000
*** Best Val Loss: 0.47427 	 Best Test Loss: 0.52016 	 Best epoch 550
Validation loss decreased (0.475863 --> 0.474269).  Saving model ...
train epoch 551 avg loss: 0.19314 (A-MSE: 0.17045) avg lploss: 0.00000
train epoch 552 avg loss: 0.17587 (A-MSE: 0.15579) avg lploss: 0.00000
train epoch 553 avg loss: 0.18000 (A-MSE: 0.15880) avg lploss: 0.00000
train epoch 554 avg loss: 0.23438 (A-MSE: 0.20704) avg lploss: 0.00000
train epoch 555 avg loss: 0.22018 (A-MSE: 0.19593) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.57746 (A-MSE: 0.50682) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.56939 (A-MSE: 0.50401) avg lploss: 0.00000
*** Best Val Loss: 0.47427 	 Best Test Loss: 0.52016 	 Best epoch 550
EarlyStopping counter: 1 out of 50
train epoch 556 avg loss: 0.19944 (A-MSE: 0.17551) avg lploss: 0.00000
train epoch 557 avg loss: 0.16797 (A-MSE: 0.14844) avg lploss: 0.00000
train epoch 558 avg loss: 0.15711 (A-MSE: 0.13934) avg lploss: 0.00000
train epoch 559 avg loss: 0.17037 (A-MSE: 0.15090) avg lploss: 0.00000
train epoch 560 avg loss: 0.18388 (A-MSE: 0.16226) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.49720 (A-MSE: 0.43119) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.52706 (A-MSE: 0.46041) avg lploss: 0.00000
*** Best Val Loss: 0.47427 	 Best Test Loss: 0.52016 	 Best epoch 550
EarlyStopping counter: 2 out of 50
train epoch 561 avg loss: 0.22030 (A-MSE: 0.19475) avg lploss: 0.00000
train epoch 562 avg loss: 0.21143 (A-MSE: 0.18523) avg lploss: 0.00000
train epoch 563 avg loss: 0.17710 (A-MSE: 0.15795) avg lploss: 0.00000
train epoch 564 avg loss: 0.19340 (A-MSE: 0.17114) avg lploss: 0.00000
train epoch 565 avg loss: 0.15674 (A-MSE: 0.13737) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.44414 (A-MSE: 0.38449) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.53437 (A-MSE: 0.46737) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
Validation loss decreased (0.474269 --> 0.444142).  Saving model ...
train epoch 566 avg loss: 0.16055 (A-MSE: 0.14107) avg lploss: 0.00000
train epoch 567 avg loss: 0.17952 (A-MSE: 0.15897) avg lploss: 0.00000
train epoch 568 avg loss: 0.17527 (A-MSE: 0.15566) avg lploss: 0.00000
train epoch 569 avg loss: 0.17282 (A-MSE: 0.15327) avg lploss: 0.00000
train epoch 570 avg loss: 0.17665 (A-MSE: 0.15598) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.54239 (A-MSE: 0.48175) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.59065 (A-MSE: 0.52934) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 1 out of 50
train epoch 571 avg loss: 0.18231 (A-MSE: 0.16222) avg lploss: 0.00000
train epoch 572 avg loss: 0.18304 (A-MSE: 0.16096) avg lploss: 0.00000
train epoch 573 avg loss: 0.18835 (A-MSE: 0.16588) avg lploss: 0.00000
train epoch 574 avg loss: 0.18095 (A-MSE: 0.15996) avg lploss: 0.00000
train epoch 575 avg loss: 0.18119 (A-MSE: 0.16001) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.48236 (A-MSE: 0.42077) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.53367 (A-MSE: 0.47502) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 2 out of 50
train epoch 576 avg loss: 0.16956 (A-MSE: 0.15074) avg lploss: 0.00000
train epoch 577 avg loss: 0.19946 (A-MSE: 0.17714) avg lploss: 0.00000
train epoch 578 avg loss: 0.20073 (A-MSE: 0.17773) avg lploss: 0.00000
train epoch 579 avg loss: 0.20375 (A-MSE: 0.17837) avg lploss: 0.00000
train epoch 580 avg loss: 0.16680 (A-MSE: 0.14718) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.48530 (A-MSE: 0.42123) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.57357 (A-MSE: 0.50157) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 3 out of 50
train epoch 581 avg loss: 0.15655 (A-MSE: 0.13771) avg lploss: 0.00000
train epoch 582 avg loss: 0.14629 (A-MSE: 0.12894) avg lploss: 0.00000
train epoch 583 avg loss: 0.16343 (A-MSE: 0.14538) avg lploss: 0.00000
train epoch 584 avg loss: 0.14696 (A-MSE: 0.12999) avg lploss: 0.00000
train epoch 585 avg loss: 0.14714 (A-MSE: 0.13013) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.45767 (A-MSE: 0.39401) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.50156 (A-MSE: 0.43633) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 4 out of 50
train epoch 586 avg loss: 0.14568 (A-MSE: 0.12848) avg lploss: 0.00000
train epoch 587 avg loss: 0.14190 (A-MSE: 0.12636) avg lploss: 0.00000
train epoch 588 avg loss: 0.14852 (A-MSE: 0.13253) avg lploss: 0.00000
train epoch 589 avg loss: 0.16950 (A-MSE: 0.14996) avg lploss: 0.00000
train epoch 590 avg loss: 0.17785 (A-MSE: 0.15817) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.49481 (A-MSE: 0.42999) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.54657 (A-MSE: 0.47471) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 5 out of 50
train epoch 591 avg loss: 0.16485 (A-MSE: 0.14565) avg lploss: 0.00000
train epoch 592 avg loss: 0.15165 (A-MSE: 0.13499) avg lploss: 0.00000
train epoch 593 avg loss: 0.17397 (A-MSE: 0.15589) avg lploss: 0.00000
train epoch 594 avg loss: 0.16087 (A-MSE: 0.14234) avg lploss: 0.00000
train epoch 595 avg loss: 0.16497 (A-MSE: 0.14679) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.48458 (A-MSE: 0.41788) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.53415 (A-MSE: 0.46648) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 6 out of 50
train epoch 596 avg loss: 0.18781 (A-MSE: 0.16533) avg lploss: 0.00000
train epoch 597 avg loss: 0.19250 (A-MSE: 0.17043) avg lploss: 0.00000
train epoch 598 avg loss: 0.17005 (A-MSE: 0.15040) avg lploss: 0.00000
train epoch 599 avg loss: 0.19493 (A-MSE: 0.17320) avg lploss: 0.00000
train epoch 600 avg loss: 0.18522 (A-MSE: 0.16593) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.50355 (A-MSE: 0.41987) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.53849 (A-MSE: 0.46398) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 7 out of 50
train epoch 601 avg loss: 0.17481 (A-MSE: 0.15316) avg lploss: 0.00000
train epoch 602 avg loss: 0.16306 (A-MSE: 0.14514) avg lploss: 0.00000
train epoch 603 avg loss: 0.17150 (A-MSE: 0.15398) avg lploss: 0.00000
train epoch 604 avg loss: 0.20388 (A-MSE: 0.18104) avg lploss: 0.00000
train epoch 605 avg loss: 0.16905 (A-MSE: 0.15136) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.49767 (A-MSE: 0.43479) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.57550 (A-MSE: 0.51022) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 8 out of 50
train epoch 606 avg loss: 0.15353 (A-MSE: 0.13618) avg lploss: 0.00000
train epoch 607 avg loss: 0.15414 (A-MSE: 0.13697) avg lploss: 0.00000
train epoch 608 avg loss: 0.14045 (A-MSE: 0.12453) avg lploss: 0.00000
train epoch 609 avg loss: 0.15345 (A-MSE: 0.13685) avg lploss: 0.00000
train epoch 610 avg loss: 0.16739 (A-MSE: 0.14810) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.51442 (A-MSE: 0.44247) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.55457 (A-MSE: 0.48615) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 9 out of 50
train epoch 611 avg loss: 0.15695 (A-MSE: 0.13935) avg lploss: 0.00000
train epoch 612 avg loss: 0.15853 (A-MSE: 0.14065) avg lploss: 0.00000
train epoch 613 avg loss: 0.14310 (A-MSE: 0.12714) avg lploss: 0.00000
train epoch 614 avg loss: 0.14939 (A-MSE: 0.13254) avg lploss: 0.00000
train epoch 615 avg loss: 0.15296 (A-MSE: 0.13620) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.54947 (A-MSE: 0.46866) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.58158 (A-MSE: 0.51109) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 10 out of 50
train epoch 616 avg loss: 0.15620 (A-MSE: 0.13839) avg lploss: 0.00000
train epoch 617 avg loss: 0.19632 (A-MSE: 0.17567) avg lploss: 0.00000
train epoch 618 avg loss: 0.18490 (A-MSE: 0.16294) avg lploss: 0.00000
train epoch 619 avg loss: 0.17423 (A-MSE: 0.15510) avg lploss: 0.00000
train epoch 620 avg loss: 0.18235 (A-MSE: 0.16175) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.55995 (A-MSE: 0.48335) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.64214 (A-MSE: 0.56273) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 11 out of 50
train epoch 621 avg loss: 0.20015 (A-MSE: 0.17900) avg lploss: 0.00000
train epoch 622 avg loss: 0.17195 (A-MSE: 0.15198) avg lploss: 0.00000
train epoch 623 avg loss: 0.15707 (A-MSE: 0.13956) avg lploss: 0.00000
train epoch 624 avg loss: 0.15000 (A-MSE: 0.13286) avg lploss: 0.00000
train epoch 625 avg loss: 0.16749 (A-MSE: 0.14623) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.46957 (A-MSE: 0.40757) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.50889 (A-MSE: 0.45040) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 12 out of 50
train epoch 626 avg loss: 0.16025 (A-MSE: 0.14262) avg lploss: 0.00000
train epoch 627 avg loss: 0.14377 (A-MSE: 0.12751) avg lploss: 0.00000
train epoch 628 avg loss: 0.14222 (A-MSE: 0.12685) avg lploss: 0.00000
train epoch 629 avg loss: 0.14514 (A-MSE: 0.12887) avg lploss: 0.00000
train epoch 630 avg loss: 0.16806 (A-MSE: 0.14907) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.44606 (A-MSE: 0.38508) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.48428 (A-MSE: 0.42264) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 13 out of 50
train epoch 631 avg loss: 0.16261 (A-MSE: 0.14416) avg lploss: 0.00000
train epoch 632 avg loss: 0.18462 (A-MSE: 0.16442) avg lploss: 0.00000
train epoch 633 avg loss: 0.21245 (A-MSE: 0.19019) avg lploss: 0.00000
train epoch 634 avg loss: 0.21365 (A-MSE: 0.19174) avg lploss: 0.00000
train epoch 635 avg loss: 0.20603 (A-MSE: 0.18242) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.63302 (A-MSE: 0.54266) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.71324 (A-MSE: 0.61465) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 14 out of 50
train epoch 636 avg loss: 0.23906 (A-MSE: 0.21219) avg lploss: 0.00000
train epoch 637 avg loss: 0.20727 (A-MSE: 0.18352) avg lploss: 0.00000
train epoch 638 avg loss: 0.17722 (A-MSE: 0.15820) avg lploss: 0.00000
train epoch 639 avg loss: 0.17085 (A-MSE: 0.15127) avg lploss: 0.00000
train epoch 640 avg loss: 0.17282 (A-MSE: 0.15233) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.48711 (A-MSE: 0.41699) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.56592 (A-MSE: 0.49504) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 15 out of 50
train epoch 641 avg loss: 0.16151 (A-MSE: 0.14405) avg lploss: 0.00000
train epoch 642 avg loss: 0.15355 (A-MSE: 0.13599) avg lploss: 0.00000
train epoch 643 avg loss: 0.14587 (A-MSE: 0.12824) avg lploss: 0.00000
train epoch 644 avg loss: 0.14853 (A-MSE: 0.13255) avg lploss: 0.00000
train epoch 645 avg loss: 0.14178 (A-MSE: 0.12541) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.46995 (A-MSE: 0.40983) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.52339 (A-MSE: 0.46298) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 16 out of 50
train epoch 646 avg loss: 0.13175 (A-MSE: 0.11578) avg lploss: 0.00000
train epoch 647 avg loss: 0.13623 (A-MSE: 0.12063) avg lploss: 0.00000
train epoch 648 avg loss: 0.13777 (A-MSE: 0.12222) avg lploss: 0.00000
train epoch 649 avg loss: 0.14089 (A-MSE: 0.12546) avg lploss: 0.00000
train epoch 650 avg loss: 0.15642 (A-MSE: 0.13896) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.45820 (A-MSE: 0.39350) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.51995 (A-MSE: 0.45235) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 17 out of 50
train epoch 651 avg loss: 0.13443 (A-MSE: 0.11973) avg lploss: 0.00000
train epoch 652 avg loss: 0.13188 (A-MSE: 0.11811) avg lploss: 0.00000
train epoch 653 avg loss: 0.12902 (A-MSE: 0.11520) avg lploss: 0.00000
train epoch 654 avg loss: 0.13043 (A-MSE: 0.11536) avg lploss: 0.00000
train epoch 655 avg loss: 0.13522 (A-MSE: 0.12019) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.47713 (A-MSE: 0.41133) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.51101 (A-MSE: 0.44808) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 18 out of 50
train epoch 656 avg loss: 0.13694 (A-MSE: 0.12264) avg lploss: 0.00000
train epoch 657 avg loss: 0.14668 (A-MSE: 0.12910) avg lploss: 0.00000
train epoch 658 avg loss: 0.13904 (A-MSE: 0.12253) avg lploss: 0.00000
train epoch 659 avg loss: 0.13811 (A-MSE: 0.12382) avg lploss: 0.00000
train epoch 660 avg loss: 0.12910 (A-MSE: 0.11553) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.50324 (A-MSE: 0.43435) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.53236 (A-MSE: 0.46601) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 19 out of 50
train epoch 661 avg loss: 0.13770 (A-MSE: 0.12186) avg lploss: 0.00000
train epoch 662 avg loss: 0.12739 (A-MSE: 0.11385) avg lploss: 0.00000
train epoch 663 avg loss: 0.12279 (A-MSE: 0.10899) avg lploss: 0.00000
train epoch 664 avg loss: 0.14287 (A-MSE: 0.12695) avg lploss: 0.00000
train epoch 665 avg loss: 0.13989 (A-MSE: 0.12391) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.45760 (A-MSE: 0.39355) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.49308 (A-MSE: 0.43112) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 20 out of 50
train epoch 666 avg loss: 0.12115 (A-MSE: 0.10759) avg lploss: 0.00000
train epoch 667 avg loss: 0.13383 (A-MSE: 0.11882) avg lploss: 0.00000
train epoch 668 avg loss: 0.14818 (A-MSE: 0.13149) avg lploss: 0.00000
train epoch 669 avg loss: 0.12209 (A-MSE: 0.10875) avg lploss: 0.00000
train epoch 670 avg loss: 0.13858 (A-MSE: 0.12250) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.47085 (A-MSE: 0.40875) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.52881 (A-MSE: 0.46558) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 21 out of 50
train epoch 671 avg loss: 0.13924 (A-MSE: 0.12352) avg lploss: 0.00000
train epoch 672 avg loss: 0.12592 (A-MSE: 0.11159) avg lploss: 0.00000
train epoch 673 avg loss: 0.12350 (A-MSE: 0.11010) avg lploss: 0.00000
train epoch 674 avg loss: 0.13271 (A-MSE: 0.11763) avg lploss: 0.00000
train epoch 675 avg loss: 0.12404 (A-MSE: 0.11026) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.44953 (A-MSE: 0.38718) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.51183 (A-MSE: 0.44721) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 22 out of 50
train epoch 676 avg loss: 0.13558 (A-MSE: 0.12098) avg lploss: 0.00000
train epoch 677 avg loss: 0.15069 (A-MSE: 0.13280) avg lploss: 0.00000
train epoch 678 avg loss: 0.13639 (A-MSE: 0.12122) avg lploss: 0.00000
train epoch 679 avg loss: 0.14719 (A-MSE: 0.13024) avg lploss: 0.00000
train epoch 680 avg loss: 0.13348 (A-MSE: 0.11849) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.50305 (A-MSE: 0.43690) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.52141 (A-MSE: 0.45959) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 23 out of 50
train epoch 681 avg loss: 0.13111 (A-MSE: 0.11614) avg lploss: 0.00000
train epoch 682 avg loss: 0.12098 (A-MSE: 0.10787) avg lploss: 0.00000
train epoch 683 avg loss: 0.15088 (A-MSE: 0.13466) avg lploss: 0.00000
train epoch 684 avg loss: 0.15770 (A-MSE: 0.13941) avg lploss: 0.00000
train epoch 685 avg loss: 0.15500 (A-MSE: 0.13737) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.49718 (A-MSE: 0.43782) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.56107 (A-MSE: 0.49648) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 24 out of 50
train epoch 686 avg loss: 0.13910 (A-MSE: 0.12424) avg lploss: 0.00000
train epoch 687 avg loss: 0.12997 (A-MSE: 0.11529) avg lploss: 0.00000
train epoch 688 avg loss: 0.12471 (A-MSE: 0.11152) avg lploss: 0.00000
train epoch 689 avg loss: 0.13674 (A-MSE: 0.12093) avg lploss: 0.00000
train epoch 690 avg loss: 0.14726 (A-MSE: 0.13153) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.45694 (A-MSE: 0.39171) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.47871 (A-MSE: 0.42062) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 25 out of 50
train epoch 691 avg loss: 0.14099 (A-MSE: 0.12648) avg lploss: 0.00000
train epoch 692 avg loss: 0.15317 (A-MSE: 0.13570) avg lploss: 0.00000
train epoch 693 avg loss: 0.16076 (A-MSE: 0.14253) avg lploss: 0.00000
train epoch 694 avg loss: 0.17213 (A-MSE: 0.15188) avg lploss: 0.00000
train epoch 695 avg loss: 0.16731 (A-MSE: 0.14990) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.56210 (A-MSE: 0.48664) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.58455 (A-MSE: 0.51367) avg lploss: 0.00000
*** Best Val Loss: 0.44414 	 Best Test Loss: 0.53437 	 Best epoch 565
EarlyStopping counter: 26 out of 50
train epoch 696 avg loss: 0.16377 (A-MSE: 0.14554) avg lploss: 0.00000
train epoch 697 avg loss: 0.13713 (A-MSE: 0.12198) avg lploss: 0.00000
train epoch 698 avg loss: 0.13872 (A-MSE: 0.12363) avg lploss: 0.00000
train epoch 699 avg loss: 0.15098 (A-MSE: 0.13416) avg lploss: 0.00000
train epoch 700 avg loss: 0.13074 (A-MSE: 0.11666) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.43116 (A-MSE: 0.37815) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.48238 (A-MSE: 0.42368) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
Validation loss decreased (0.444142 --> 0.431161).  Saving model ...
train epoch 701 avg loss: 0.12773 (A-MSE: 0.11389) avg lploss: 0.00000
train epoch 702 avg loss: 0.13201 (A-MSE: 0.11822) avg lploss: 0.00000
train epoch 703 avg loss: 0.13562 (A-MSE: 0.12018) avg lploss: 0.00000
train epoch 704 avg loss: 0.12734 (A-MSE: 0.11316) avg lploss: 0.00000
train epoch 705 avg loss: 0.14638 (A-MSE: 0.12948) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.45488 (A-MSE: 0.39258) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.49051 (A-MSE: 0.42578) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 1 out of 50
train epoch 706 avg loss: 0.13168 (A-MSE: 0.11645) avg lploss: 0.00000
train epoch 707 avg loss: 0.12402 (A-MSE: 0.11114) avg lploss: 0.00000
train epoch 708 avg loss: 0.13300 (A-MSE: 0.11841) avg lploss: 0.00000
train epoch 709 avg loss: 0.14306 (A-MSE: 0.12610) avg lploss: 0.00000
train epoch 710 avg loss: 0.13595 (A-MSE: 0.12123) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.48620 (A-MSE: 0.41594) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.52097 (A-MSE: 0.45294) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 2 out of 50
train epoch 711 avg loss: 0.13030 (A-MSE: 0.11518) avg lploss: 0.00000
train epoch 712 avg loss: 0.15498 (A-MSE: 0.13753) avg lploss: 0.00000
train epoch 713 avg loss: 0.16236 (A-MSE: 0.14521) avg lploss: 0.00000
train epoch 714 avg loss: 0.14789 (A-MSE: 0.13247) avg lploss: 0.00000
train epoch 715 avg loss: 0.12524 (A-MSE: 0.11275) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.47513 (A-MSE: 0.40581) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.50660 (A-MSE: 0.44026) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 3 out of 50
train epoch 716 avg loss: 0.12306 (A-MSE: 0.10902) avg lploss: 0.00000
train epoch 717 avg loss: 0.12764 (A-MSE: 0.11331) avg lploss: 0.00000
train epoch 718 avg loss: 0.13506 (A-MSE: 0.12033) avg lploss: 0.00000
train epoch 719 avg loss: 0.12630 (A-MSE: 0.11311) avg lploss: 0.00000
train epoch 720 avg loss: 0.12213 (A-MSE: 0.10905) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.50412 (A-MSE: 0.43572) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.56325 (A-MSE: 0.49265) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 4 out of 50
train epoch 721 avg loss: 0.13431 (A-MSE: 0.11963) avg lploss: 0.00000
train epoch 722 avg loss: 0.14743 (A-MSE: 0.13073) avg lploss: 0.00000
train epoch 723 avg loss: 0.12161 (A-MSE: 0.10884) avg lploss: 0.00000
train epoch 724 avg loss: 0.11003 (A-MSE: 0.09831) avg lploss: 0.00000
train epoch 725 avg loss: 0.11812 (A-MSE: 0.10549) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.45724 (A-MSE: 0.40006) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.49470 (A-MSE: 0.43962) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 5 out of 50
train epoch 726 avg loss: 0.11123 (A-MSE: 0.09888) avg lploss: 0.00000
train epoch 727 avg loss: 0.10979 (A-MSE: 0.09792) avg lploss: 0.00000
train epoch 728 avg loss: 0.12581 (A-MSE: 0.11184) avg lploss: 0.00000
train epoch 729 avg loss: 0.11498 (A-MSE: 0.10304) avg lploss: 0.00000
train epoch 730 avg loss: 0.12435 (A-MSE: 0.11147) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.51493 (A-MSE: 0.45036) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.58133 (A-MSE: 0.51338) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 6 out of 50
train epoch 731 avg loss: 0.16408 (A-MSE: 0.14411) avg lploss: 0.00000
train epoch 732 avg loss: 0.18825 (A-MSE: 0.16928) avg lploss: 0.00000
train epoch 733 avg loss: 0.19547 (A-MSE: 0.17454) avg lploss: 0.00000
train epoch 734 avg loss: 0.20225 (A-MSE: 0.18105) avg lploss: 0.00000
train epoch 735 avg loss: 0.15711 (A-MSE: 0.13939) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.47311 (A-MSE: 0.40876) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.51498 (A-MSE: 0.44868) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 7 out of 50
train epoch 736 avg loss: 0.12881 (A-MSE: 0.11425) avg lploss: 0.00000
train epoch 737 avg loss: 0.13855 (A-MSE: 0.12207) avg lploss: 0.00000
train epoch 738 avg loss: 0.12420 (A-MSE: 0.11038) avg lploss: 0.00000
train epoch 739 avg loss: 0.11965 (A-MSE: 0.10680) avg lploss: 0.00000
train epoch 740 avg loss: 0.12096 (A-MSE: 0.10832) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.47395 (A-MSE: 0.41096) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.53322 (A-MSE: 0.47241) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 8 out of 50
train epoch 741 avg loss: 0.11959 (A-MSE: 0.10621) avg lploss: 0.00000
train epoch 742 avg loss: 0.12589 (A-MSE: 0.11273) avg lploss: 0.00000
train epoch 743 avg loss: 0.15231 (A-MSE: 0.13585) avg lploss: 0.00000
train epoch 744 avg loss: 0.15478 (A-MSE: 0.13825) avg lploss: 0.00000
train epoch 745 avg loss: 0.13426 (A-MSE: 0.11901) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.43217 (A-MSE: 0.37561) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.49722 (A-MSE: 0.43666) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 9 out of 50
train epoch 746 avg loss: 0.14055 (A-MSE: 0.12483) avg lploss: 0.00000
train epoch 747 avg loss: 0.14322 (A-MSE: 0.12716) avg lploss: 0.00000
train epoch 748 avg loss: 0.14740 (A-MSE: 0.13036) avg lploss: 0.00000
train epoch 749 avg loss: 0.14688 (A-MSE: 0.13012) avg lploss: 0.00000
train epoch 750 avg loss: 0.14232 (A-MSE: 0.12719) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.45899 (A-MSE: 0.39858) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.49729 (A-MSE: 0.43691) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 10 out of 50
train epoch 751 avg loss: 0.14013 (A-MSE: 0.12544) avg lploss: 0.00000
train epoch 752 avg loss: 0.12784 (A-MSE: 0.11362) avg lploss: 0.00000
train epoch 753 avg loss: 0.10600 (A-MSE: 0.09510) avg lploss: 0.00000
train epoch 754 avg loss: 0.11769 (A-MSE: 0.10478) avg lploss: 0.00000
train epoch 755 avg loss: 0.11517 (A-MSE: 0.10369) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.44440 (A-MSE: 0.38217) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.46299 (A-MSE: 0.40638) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 11 out of 50
train epoch 756 avg loss: 0.10536 (A-MSE: 0.09376) avg lploss: 0.00000
train epoch 757 avg loss: 0.10396 (A-MSE: 0.09290) avg lploss: 0.00000
train epoch 758 avg loss: 0.11079 (A-MSE: 0.09889) avg lploss: 0.00000
train epoch 759 avg loss: 0.11937 (A-MSE: 0.10621) avg lploss: 0.00000
train epoch 760 avg loss: 0.10949 (A-MSE: 0.09677) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.46479 (A-MSE: 0.39820) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.48826 (A-MSE: 0.42412) avg lploss: 0.00000
*** Best Val Loss: 0.43116 	 Best Test Loss: 0.48238 	 Best epoch 700
EarlyStopping counter: 12 out of 50
train epoch 761 avg loss: 0.09952 (A-MSE: 0.08820) avg lploss: 0.00000
train epoch 762 avg loss: 0.10546 (A-MSE: 0.09401) avg lploss: 0.00000
train epoch 763 avg loss: 0.10115 (A-MSE: 0.08962) avg lploss: 0.00000
train epoch 764 avg loss: 0.10305 (A-MSE: 0.09211) avg lploss: 0.00000
train epoch 765 avg loss: 0.11345 (A-MSE: 0.10075) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.42304 (A-MSE: 0.36991) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.49139 (A-MSE: 0.43351) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
Validation loss decreased (0.431161 --> 0.423044).  Saving model ...
train epoch 766 avg loss: 0.12735 (A-MSE: 0.11428) avg lploss: 0.00000
train epoch 767 avg loss: 0.13477 (A-MSE: 0.11926) avg lploss: 0.00000
train epoch 768 avg loss: 0.11521 (A-MSE: 0.10279) avg lploss: 0.00000
train epoch 769 avg loss: 0.12398 (A-MSE: 0.11062) avg lploss: 0.00000
train epoch 770 avg loss: 0.11369 (A-MSE: 0.10096) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.46613 (A-MSE: 0.40222) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.49726 (A-MSE: 0.43819) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 1 out of 50
train epoch 771 avg loss: 0.10869 (A-MSE: 0.09723) avg lploss: 0.00000
train epoch 772 avg loss: 0.10440 (A-MSE: 0.09308) avg lploss: 0.00000
train epoch 773 avg loss: 0.11305 (A-MSE: 0.10152) avg lploss: 0.00000
train epoch 774 avg loss: 0.10529 (A-MSE: 0.09413) avg lploss: 0.00000
train epoch 775 avg loss: 0.10626 (A-MSE: 0.09564) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.44889 (A-MSE: 0.38749) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.48556 (A-MSE: 0.42363) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 2 out of 50
train epoch 776 avg loss: 0.11785 (A-MSE: 0.10372) avg lploss: 0.00000
train epoch 777 avg loss: 0.12353 (A-MSE: 0.10923) avg lploss: 0.00000
train epoch 778 avg loss: 0.14125 (A-MSE: 0.12640) avg lploss: 0.00000
train epoch 779 avg loss: 0.12480 (A-MSE: 0.11030) avg lploss: 0.00000
train epoch 780 avg loss: 0.11540 (A-MSE: 0.10270) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.50220 (A-MSE: 0.44463) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.55927 (A-MSE: 0.49534) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 3 out of 50
train epoch 781 avg loss: 0.12078 (A-MSE: 0.10748) avg lploss: 0.00000
train epoch 782 avg loss: 0.13926 (A-MSE: 0.12452) avg lploss: 0.00000
train epoch 783 avg loss: 0.13374 (A-MSE: 0.11776) avg lploss: 0.00000
train epoch 784 avg loss: 0.10789 (A-MSE: 0.09534) avg lploss: 0.00000
train epoch 785 avg loss: 0.10871 (A-MSE: 0.09707) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.47045 (A-MSE: 0.41437) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.53580 (A-MSE: 0.47221) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 4 out of 50
train epoch 786 avg loss: 0.11231 (A-MSE: 0.10022) avg lploss: 0.00000
train epoch 787 avg loss: 0.12429 (A-MSE: 0.11130) avg lploss: 0.00000
train epoch 788 avg loss: 0.11915 (A-MSE: 0.10635) avg lploss: 0.00000
train epoch 789 avg loss: 0.11922 (A-MSE: 0.10593) avg lploss: 0.00000
train epoch 790 avg loss: 0.11931 (A-MSE: 0.10684) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.49000 (A-MSE: 0.42768) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.53501 (A-MSE: 0.46680) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 5 out of 50
train epoch 791 avg loss: 0.11082 (A-MSE: 0.09777) avg lploss: 0.00000
train epoch 792 avg loss: 0.12158 (A-MSE: 0.10838) avg lploss: 0.00000
train epoch 793 avg loss: 0.13071 (A-MSE: 0.11564) avg lploss: 0.00000
train epoch 794 avg loss: 0.12121 (A-MSE: 0.10903) avg lploss: 0.00000
train epoch 795 avg loss: 0.11882 (A-MSE: 0.10601) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.46995 (A-MSE: 0.40538) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.49532 (A-MSE: 0.43371) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 6 out of 50
train epoch 796 avg loss: 0.11160 (A-MSE: 0.09837) avg lploss: 0.00000
train epoch 797 avg loss: 0.15040 (A-MSE: 0.13436) avg lploss: 0.00000
train epoch 798 avg loss: 0.16813 (A-MSE: 0.14816) avg lploss: 0.00000
train epoch 799 avg loss: 0.12885 (A-MSE: 0.11415) avg lploss: 0.00000
train epoch 800 avg loss: 0.11379 (A-MSE: 0.10077) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.47163 (A-MSE: 0.40307) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.47467 (A-MSE: 0.41243) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 7 out of 50
train epoch 801 avg loss: 0.10390 (A-MSE: 0.09258) avg lploss: 0.00000
train epoch 802 avg loss: 0.11393 (A-MSE: 0.10117) avg lploss: 0.00000
train epoch 803 avg loss: 0.11360 (A-MSE: 0.10162) avg lploss: 0.00000
train epoch 804 avg loss: 0.11649 (A-MSE: 0.10370) avg lploss: 0.00000
train epoch 805 avg loss: 0.12642 (A-MSE: 0.11357) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.49683 (A-MSE: 0.43303) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.49375 (A-MSE: 0.43333) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 8 out of 50
train epoch 806 avg loss: 0.11014 (A-MSE: 0.09758) avg lploss: 0.00000
train epoch 807 avg loss: 0.11884 (A-MSE: 0.10531) avg lploss: 0.00000
train epoch 808 avg loss: 0.11379 (A-MSE: 0.10030) avg lploss: 0.00000
train epoch 809 avg loss: 0.12086 (A-MSE: 0.10900) avg lploss: 0.00000
train epoch 810 avg loss: 0.13806 (A-MSE: 0.12171) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.47858 (A-MSE: 0.42142) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.55422 (A-MSE: 0.48820) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 9 out of 50
train epoch 811 avg loss: 0.11887 (A-MSE: 0.10659) avg lploss: 0.00000
train epoch 812 avg loss: 0.11052 (A-MSE: 0.09809) avg lploss: 0.00000
train epoch 813 avg loss: 0.11388 (A-MSE: 0.10198) avg lploss: 0.00000
train epoch 814 avg loss: 0.11883 (A-MSE: 0.10562) avg lploss: 0.00000
train epoch 815 avg loss: 0.11648 (A-MSE: 0.10457) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.45510 (A-MSE: 0.40154) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.50865 (A-MSE: 0.44976) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 10 out of 50
train epoch 816 avg loss: 0.14607 (A-MSE: 0.13032) avg lploss: 0.00000
train epoch 817 avg loss: 0.17252 (A-MSE: 0.15490) avg lploss: 0.00000
train epoch 818 avg loss: 0.15251 (A-MSE: 0.13448) avg lploss: 0.00000
train epoch 819 avg loss: 0.13088 (A-MSE: 0.11511) avg lploss: 0.00000
train epoch 820 avg loss: 0.11997 (A-MSE: 0.10566) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.45600 (A-MSE: 0.39624) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.50505 (A-MSE: 0.44228) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 11 out of 50
train epoch 821 avg loss: 0.12706 (A-MSE: 0.11281) avg lploss: 0.00000
train epoch 822 avg loss: 0.12522 (A-MSE: 0.11223) avg lploss: 0.00000
train epoch 823 avg loss: 0.12215 (A-MSE: 0.11013) avg lploss: 0.00000
train epoch 824 avg loss: 0.12461 (A-MSE: 0.11068) avg lploss: 0.00000
train epoch 825 avg loss: 0.09797 (A-MSE: 0.08785) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.49876 (A-MSE: 0.42839) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.52958 (A-MSE: 0.45862) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 12 out of 50
train epoch 826 avg loss: 0.10980 (A-MSE: 0.09757) avg lploss: 0.00000
train epoch 827 avg loss: 0.10350 (A-MSE: 0.09378) avg lploss: 0.00000
train epoch 828 avg loss: 0.11332 (A-MSE: 0.10193) avg lploss: 0.00000
train epoch 829 avg loss: 0.10565 (A-MSE: 0.09426) avg lploss: 0.00000
train epoch 830 avg loss: 0.10675 (A-MSE: 0.09592) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.44951 (A-MSE: 0.38485) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.47725 (A-MSE: 0.41812) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 13 out of 50
train epoch 831 avg loss: 0.12381 (A-MSE: 0.11007) avg lploss: 0.00000
train epoch 832 avg loss: 0.11549 (A-MSE: 0.10367) avg lploss: 0.00000
train epoch 833 avg loss: 0.10043 (A-MSE: 0.09039) avg lploss: 0.00000
train epoch 834 avg loss: 0.10514 (A-MSE: 0.09358) avg lploss: 0.00000
train epoch 835 avg loss: 0.11341 (A-MSE: 0.10183) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.49706 (A-MSE: 0.42654) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.54306 (A-MSE: 0.46779) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 14 out of 50
train epoch 836 avg loss: 0.11527 (A-MSE: 0.10200) avg lploss: 0.00000
train epoch 837 avg loss: 0.09853 (A-MSE: 0.08818) avg lploss: 0.00000
train epoch 838 avg loss: 0.10493 (A-MSE: 0.09388) avg lploss: 0.00000
train epoch 839 avg loss: 0.10448 (A-MSE: 0.09210) avg lploss: 0.00000
train epoch 840 avg loss: 0.10645 (A-MSE: 0.09545) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.55241 (A-MSE: 0.47228) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.55941 (A-MSE: 0.48173) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 15 out of 50
train epoch 841 avg loss: 0.10829 (A-MSE: 0.09690) avg lploss: 0.00000
train epoch 842 avg loss: 0.13543 (A-MSE: 0.12111) avg lploss: 0.00000
train epoch 843 avg loss: 0.12559 (A-MSE: 0.11392) avg lploss: 0.00000
train epoch 844 avg loss: 0.14645 (A-MSE: 0.12936) avg lploss: 0.00000
train epoch 845 avg loss: 0.14899 (A-MSE: 0.13296) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.52073 (A-MSE: 0.44430) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.53996 (A-MSE: 0.46491) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 16 out of 50
train epoch 846 avg loss: 0.13511 (A-MSE: 0.12004) avg lploss: 0.00000
train epoch 847 avg loss: 0.11240 (A-MSE: 0.09989) avg lploss: 0.00000
train epoch 848 avg loss: 0.10648 (A-MSE: 0.09535) avg lploss: 0.00000
train epoch 849 avg loss: 0.10770 (A-MSE: 0.09629) avg lploss: 0.00000
train epoch 850 avg loss: 0.10248 (A-MSE: 0.09223) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.47178 (A-MSE: 0.41072) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.52996 (A-MSE: 0.46258) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 17 out of 50
train epoch 851 avg loss: 0.10299 (A-MSE: 0.09216) avg lploss: 0.00000
train epoch 852 avg loss: 0.10980 (A-MSE: 0.09811) avg lploss: 0.00000
train epoch 853 avg loss: 0.12734 (A-MSE: 0.11356) avg lploss: 0.00000
train epoch 854 avg loss: 0.11322 (A-MSE: 0.10179) avg lploss: 0.00000
train epoch 855 avg loss: 0.09480 (A-MSE: 0.08378) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.47459 (A-MSE: 0.40979) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.51148 (A-MSE: 0.44537) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 18 out of 50
train epoch 856 avg loss: 0.10308 (A-MSE: 0.09207) avg lploss: 0.00000
train epoch 857 avg loss: 0.14635 (A-MSE: 0.13049) avg lploss: 0.00000
train epoch 858 avg loss: 0.14204 (A-MSE: 0.12497) avg lploss: 0.00000
train epoch 859 avg loss: 0.12725 (A-MSE: 0.11389) avg lploss: 0.00000
train epoch 860 avg loss: 0.10956 (A-MSE: 0.09782) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.45890 (A-MSE: 0.39787) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.51820 (A-MSE: 0.45025) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 19 out of 50
train epoch 861 avg loss: 0.11905 (A-MSE: 0.10736) avg lploss: 0.00000
train epoch 862 avg loss: 0.11005 (A-MSE: 0.09856) avg lploss: 0.00000
train epoch 863 avg loss: 0.11505 (A-MSE: 0.10183) avg lploss: 0.00000
train epoch 864 avg loss: 0.12088 (A-MSE: 0.10818) avg lploss: 0.00000
train epoch 865 avg loss: 0.13919 (A-MSE: 0.12335) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.48900 (A-MSE: 0.42403) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.54465 (A-MSE: 0.47802) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 20 out of 50
train epoch 866 avg loss: 0.13935 (A-MSE: 0.12394) avg lploss: 0.00000
train epoch 867 avg loss: 0.11435 (A-MSE: 0.10226) avg lploss: 0.00000
train epoch 868 avg loss: 0.10178 (A-MSE: 0.09075) avg lploss: 0.00000
train epoch 869 avg loss: 0.10497 (A-MSE: 0.09453) avg lploss: 0.00000
train epoch 870 avg loss: 0.12899 (A-MSE: 0.11463) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.46237 (A-MSE: 0.40117) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.47940 (A-MSE: 0.42094) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 21 out of 50
train epoch 871 avg loss: 0.10291 (A-MSE: 0.09199) avg lploss: 0.00000
train epoch 872 avg loss: 0.09912 (A-MSE: 0.08873) avg lploss: 0.00000
train epoch 873 avg loss: 0.10431 (A-MSE: 0.09305) avg lploss: 0.00000
train epoch 874 avg loss: 0.09683 (A-MSE: 0.08650) avg lploss: 0.00000
train epoch 875 avg loss: 0.10898 (A-MSE: 0.09761) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.43675 (A-MSE: 0.37178) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.47122 (A-MSE: 0.40505) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 22 out of 50
train epoch 876 avg loss: 0.09627 (A-MSE: 0.08665) avg lploss: 0.00000
train epoch 877 avg loss: 0.09360 (A-MSE: 0.08333) avg lploss: 0.00000
train epoch 878 avg loss: 0.10151 (A-MSE: 0.09108) avg lploss: 0.00000
train epoch 879 avg loss: 0.09432 (A-MSE: 0.08505) avg lploss: 0.00000
train epoch 880 avg loss: 0.09531 (A-MSE: 0.08532) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.42925 (A-MSE: 0.37268) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.48107 (A-MSE: 0.42125) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 23 out of 50
train epoch 881 avg loss: 0.11010 (A-MSE: 0.09833) avg lploss: 0.00000
train epoch 882 avg loss: 0.09558 (A-MSE: 0.08545) avg lploss: 0.00000
train epoch 883 avg loss: 0.11456 (A-MSE: 0.10314) avg lploss: 0.00000
train epoch 884 avg loss: 0.09775 (A-MSE: 0.08814) avg lploss: 0.00000
train epoch 885 avg loss: 0.08461 (A-MSE: 0.07602) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.47523 (A-MSE: 0.40593) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.52090 (A-MSE: 0.44869) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 24 out of 50
train epoch 886 avg loss: 0.09264 (A-MSE: 0.08332) avg lploss: 0.00000
train epoch 887 avg loss: 0.09570 (A-MSE: 0.08495) avg lploss: 0.00000
train epoch 888 avg loss: 0.10727 (A-MSE: 0.09582) avg lploss: 0.00000
train epoch 889 avg loss: 0.12336 (A-MSE: 0.10977) avg lploss: 0.00000
train epoch 890 avg loss: 0.14179 (A-MSE: 0.12596) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.57056 (A-MSE: 0.49366) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.61025 (A-MSE: 0.53293) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 25 out of 50
train epoch 891 avg loss: 0.11145 (A-MSE: 0.09988) avg lploss: 0.00000
train epoch 892 avg loss: 0.09613 (A-MSE: 0.08601) avg lploss: 0.00000
train epoch 893 avg loss: 0.09363 (A-MSE: 0.08315) avg lploss: 0.00000
train epoch 894 avg loss: 0.10343 (A-MSE: 0.09311) avg lploss: 0.00000
train epoch 895 avg loss: 0.10718 (A-MSE: 0.09548) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.42850 (A-MSE: 0.37019) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.48991 (A-MSE: 0.42789) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 26 out of 50
train epoch 896 avg loss: 0.10840 (A-MSE: 0.09689) avg lploss: 0.00000
train epoch 897 avg loss: 0.09534 (A-MSE: 0.08522) avg lploss: 0.00000
train epoch 898 avg loss: 0.10620 (A-MSE: 0.09551) avg lploss: 0.00000
train epoch 899 avg loss: 0.09297 (A-MSE: 0.08278) avg lploss: 0.00000
train epoch 900 avg loss: 0.09439 (A-MSE: 0.08447) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.46355 (A-MSE: 0.40596) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.49703 (A-MSE: 0.43440) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 27 out of 50
train epoch 901 avg loss: 0.09626 (A-MSE: 0.08594) avg lploss: 0.00000
train epoch 902 avg loss: 0.09377 (A-MSE: 0.08310) avg lploss: 0.00000
train epoch 903 avg loss: 0.09495 (A-MSE: 0.08481) avg lploss: 0.00000
train epoch 904 avg loss: 0.11307 (A-MSE: 0.10079) avg lploss: 0.00000
train epoch 905 avg loss: 0.10269 (A-MSE: 0.09223) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.42721 (A-MSE: 0.36392) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.46700 (A-MSE: 0.40310) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 28 out of 50
train epoch 906 avg loss: 0.08856 (A-MSE: 0.07887) avg lploss: 0.00000
train epoch 907 avg loss: 0.08930 (A-MSE: 0.08042) avg lploss: 0.00000
train epoch 908 avg loss: 0.08325 (A-MSE: 0.07372) avg lploss: 0.00000
train epoch 909 avg loss: 0.08777 (A-MSE: 0.07846) avg lploss: 0.00000
train epoch 910 avg loss: 0.09868 (A-MSE: 0.08898) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.47021 (A-MSE: 0.40527) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.48817 (A-MSE: 0.42485) avg lploss: 0.00000
*** Best Val Loss: 0.42304 	 Best Test Loss: 0.49139 	 Best epoch 765
EarlyStopping counter: 29 out of 50
train epoch 911 avg loss: 0.09294 (A-MSE: 0.08345) avg lploss: 0.00000
train epoch 912 avg loss: 0.08781 (A-MSE: 0.07861) avg lploss: 0.00000
train epoch 913 avg loss: 0.08828 (A-MSE: 0.07895) avg lploss: 0.00000
train epoch 914 avg loss: 0.09104 (A-MSE: 0.08253) avg lploss: 0.00000
train epoch 915 avg loss: 0.08732 (A-MSE: 0.07845) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.42276 (A-MSE: 0.36545) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.47065 (A-MSE: 0.40784) avg lploss: 0.00000
*** Best Val Loss: 0.42276 	 Best Test Loss: 0.47065 	 Best epoch 915
Validation loss decreased (0.423044 --> 0.422756).  Saving model ...
train epoch 916 avg loss: 0.11355 (A-MSE: 0.10215) avg lploss: 0.00000
train epoch 917 avg loss: 0.08953 (A-MSE: 0.08040) avg lploss: 0.00000
train epoch 918 avg loss: 0.09989 (A-MSE: 0.08851) avg lploss: 0.00000
train epoch 919 avg loss: 0.11379 (A-MSE: 0.10125) avg lploss: 0.00000
train epoch 920 avg loss: 0.10526 (A-MSE: 0.09345) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.49387 (A-MSE: 0.42839) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.49032 (A-MSE: 0.42610) avg lploss: 0.00000
*** Best Val Loss: 0.42276 	 Best Test Loss: 0.47065 	 Best epoch 915
EarlyStopping counter: 1 out of 50
train epoch 921 avg loss: 0.08942 (A-MSE: 0.07989) avg lploss: 0.00000
train epoch 922 avg loss: 0.08505 (A-MSE: 0.07610) avg lploss: 0.00000
train epoch 923 avg loss: 0.09377 (A-MSE: 0.08405) avg lploss: 0.00000
train epoch 924 avg loss: 0.09889 (A-MSE: 0.08849) avg lploss: 0.00000
train epoch 925 avg loss: 0.10083 (A-MSE: 0.09016) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.45147 (A-MSE: 0.39258) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.48451 (A-MSE: 0.42415) avg lploss: 0.00000
*** Best Val Loss: 0.42276 	 Best Test Loss: 0.47065 	 Best epoch 915
EarlyStopping counter: 2 out of 50
train epoch 926 avg loss: 0.08112 (A-MSE: 0.07368) avg lploss: 0.00000
train epoch 927 avg loss: 0.08674 (A-MSE: 0.07801) avg lploss: 0.00000
train epoch 928 avg loss: 0.08960 (A-MSE: 0.08009) avg lploss: 0.00000
train epoch 929 avg loss: 0.09185 (A-MSE: 0.08274) avg lploss: 0.00000
train epoch 930 avg loss: 0.08609 (A-MSE: 0.07702) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.42188 (A-MSE: 0.36755) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.45682 (A-MSE: 0.39743) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
Validation loss decreased (0.422756 --> 0.421884).  Saving model ...
train epoch 931 avg loss: 0.08303 (A-MSE: 0.07438) avg lploss: 0.00000
train epoch 932 avg loss: 0.09399 (A-MSE: 0.08456) avg lploss: 0.00000
train epoch 933 avg loss: 0.09733 (A-MSE: 0.08773) avg lploss: 0.00000
train epoch 934 avg loss: 0.09235 (A-MSE: 0.08339) avg lploss: 0.00000
train epoch 935 avg loss: 0.09062 (A-MSE: 0.08070) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.43282 (A-MSE: 0.37601) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.45963 (A-MSE: 0.40105) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 1 out of 50
train epoch 936 avg loss: 0.08424 (A-MSE: 0.07563) avg lploss: 0.00000
train epoch 937 avg loss: 0.08504 (A-MSE: 0.07689) avg lploss: 0.00000
train epoch 938 avg loss: 0.08325 (A-MSE: 0.07418) avg lploss: 0.00000
train epoch 939 avg loss: 0.09817 (A-MSE: 0.08847) avg lploss: 0.00000
train epoch 940 avg loss: 0.10572 (A-MSE: 0.09504) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.49075 (A-MSE: 0.42233) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.54338 (A-MSE: 0.46425) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 2 out of 50
train epoch 941 avg loss: 0.10689 (A-MSE: 0.09573) avg lploss: 0.00000
train epoch 942 avg loss: 0.10471 (A-MSE: 0.09376) avg lploss: 0.00000
train epoch 943 avg loss: 0.10111 (A-MSE: 0.09044) avg lploss: 0.00000
train epoch 944 avg loss: 0.10469 (A-MSE: 0.09326) avg lploss: 0.00000
train epoch 945 avg loss: 0.09915 (A-MSE: 0.08821) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.43545 (A-MSE: 0.37977) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.46285 (A-MSE: 0.40681) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 3 out of 50
train epoch 946 avg loss: 0.08614 (A-MSE: 0.07719) avg lploss: 0.00000
train epoch 947 avg loss: 0.10866 (A-MSE: 0.09807) avg lploss: 0.00000
train epoch 948 avg loss: 0.10608 (A-MSE: 0.09474) avg lploss: 0.00000
train epoch 949 avg loss: 0.08747 (A-MSE: 0.07904) avg lploss: 0.00000
train epoch 950 avg loss: 0.08952 (A-MSE: 0.08012) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.52839 (A-MSE: 0.45058) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.55633 (A-MSE: 0.47938) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 4 out of 50
train epoch 951 avg loss: 0.08665 (A-MSE: 0.07781) avg lploss: 0.00000
train epoch 952 avg loss: 0.08488 (A-MSE: 0.07608) avg lploss: 0.00000
train epoch 953 avg loss: 0.08816 (A-MSE: 0.07861) avg lploss: 0.00000
train epoch 954 avg loss: 0.08998 (A-MSE: 0.08092) avg lploss: 0.00000
train epoch 955 avg loss: 0.09167 (A-MSE: 0.08202) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.44000 (A-MSE: 0.38292) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.46262 (A-MSE: 0.40225) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 5 out of 50
train epoch 956 avg loss: 0.08437 (A-MSE: 0.07546) avg lploss: 0.00000
train epoch 957 avg loss: 0.09238 (A-MSE: 0.08283) avg lploss: 0.00000
train epoch 958 avg loss: 0.08167 (A-MSE: 0.07414) avg lploss: 0.00000
train epoch 959 avg loss: 0.08008 (A-MSE: 0.07234) avg lploss: 0.00000
train epoch 960 avg loss: 0.09211 (A-MSE: 0.08309) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.42767 (A-MSE: 0.37300) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.44906 (A-MSE: 0.39439) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 6 out of 50
train epoch 961 avg loss: 0.10917 (A-MSE: 0.09732) avg lploss: 0.00000
train epoch 962 avg loss: 0.09387 (A-MSE: 0.08407) avg lploss: 0.00000
train epoch 963 avg loss: 0.08877 (A-MSE: 0.07958) avg lploss: 0.00000
train epoch 964 avg loss: 0.09004 (A-MSE: 0.08107) avg lploss: 0.00000
train epoch 965 avg loss: 0.08635 (A-MSE: 0.07709) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.46059 (A-MSE: 0.40172) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.50459 (A-MSE: 0.43829) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 7 out of 50
train epoch 966 avg loss: 0.09431 (A-MSE: 0.08414) avg lploss: 0.00000
train epoch 967 avg loss: 0.09875 (A-MSE: 0.08759) avg lploss: 0.00000
train epoch 968 avg loss: 0.09952 (A-MSE: 0.08990) avg lploss: 0.00000
train epoch 969 avg loss: 0.09963 (A-MSE: 0.08883) avg lploss: 0.00000
train epoch 970 avg loss: 0.10177 (A-MSE: 0.09249) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.46776 (A-MSE: 0.40228) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.50825 (A-MSE: 0.44153) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 8 out of 50
train epoch 971 avg loss: 0.09285 (A-MSE: 0.08323) avg lploss: 0.00000
train epoch 972 avg loss: 0.09064 (A-MSE: 0.08217) avg lploss: 0.00000
train epoch 973 avg loss: 0.08872 (A-MSE: 0.07947) avg lploss: 0.00000
train epoch 974 avg loss: 0.09237 (A-MSE: 0.08260) avg lploss: 0.00000
train epoch 975 avg loss: 0.08019 (A-MSE: 0.07252) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.47640 (A-MSE: 0.40754) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.49901 (A-MSE: 0.43194) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 9 out of 50
train epoch 976 avg loss: 0.07652 (A-MSE: 0.06841) avg lploss: 0.00000
train epoch 977 avg loss: 0.07560 (A-MSE: 0.06797) avg lploss: 0.00000
train epoch 978 avg loss: 0.08111 (A-MSE: 0.07302) avg lploss: 0.00000
train epoch 979 avg loss: 0.08529 (A-MSE: 0.07585) avg lploss: 0.00000
train epoch 980 avg loss: 0.08825 (A-MSE: 0.07925) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.46987 (A-MSE: 0.40540) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.48596 (A-MSE: 0.42140) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 10 out of 50
train epoch 981 avg loss: 0.08409 (A-MSE: 0.07603) avg lploss: 0.00000
train epoch 982 avg loss: 0.07879 (A-MSE: 0.07083) avg lploss: 0.00000
train epoch 983 avg loss: 0.07530 (A-MSE: 0.06813) avg lploss: 0.00000
train epoch 984 avg loss: 0.07667 (A-MSE: 0.06924) avg lploss: 0.00000
train epoch 985 avg loss: 0.08124 (A-MSE: 0.07246) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.51592 (A-MSE: 0.45146) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.53668 (A-MSE: 0.46875) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 11 out of 50
train epoch 986 avg loss: 0.08722 (A-MSE: 0.07859) avg lploss: 0.00000
train epoch 987 avg loss: 0.08375 (A-MSE: 0.07520) avg lploss: 0.00000
train epoch 988 avg loss: 0.07768 (A-MSE: 0.07000) avg lploss: 0.00000
train epoch 989 avg loss: 0.08434 (A-MSE: 0.07590) avg lploss: 0.00000
train epoch 990 avg loss: 0.09031 (A-MSE: 0.08066) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.46349 (A-MSE: 0.40044) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.47750 (A-MSE: 0.41326) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 12 out of 50
train epoch 991 avg loss: 0.08885 (A-MSE: 0.07982) avg lploss: 0.00000
train epoch 992 avg loss: 0.09851 (A-MSE: 0.08797) avg lploss: 0.00000
train epoch 993 avg loss: 0.09241 (A-MSE: 0.08304) avg lploss: 0.00000
train epoch 994 avg loss: 0.09429 (A-MSE: 0.08415) avg lploss: 0.00000
train epoch 995 avg loss: 0.09974 (A-MSE: 0.08933) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.42755 (A-MSE: 0.37493) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.44993 (A-MSE: 0.39750) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 13 out of 50
train epoch 996 avg loss: 0.09882 (A-MSE: 0.08897) avg lploss: 0.00000
train epoch 997 avg loss: 0.09469 (A-MSE: 0.08488) avg lploss: 0.00000
train epoch 998 avg loss: 0.07949 (A-MSE: 0.07129) avg lploss: 0.00000
train epoch 999 avg loss: 0.08277 (A-MSE: 0.07424) avg lploss: 0.00000
train epoch 1000 avg loss: 0.09034 (A-MSE: 0.08033) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.45839 (A-MSE: 0.39802) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.50218 (A-MSE: 0.43770) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 14 out of 50
train epoch 1001 avg loss: 0.08974 (A-MSE: 0.07961) avg lploss: 0.00000
train epoch 1002 avg loss: 0.09298 (A-MSE: 0.08360) avg lploss: 0.00000
train epoch 1003 avg loss: 0.09061 (A-MSE: 0.08151) avg lploss: 0.00000
train epoch 1004 avg loss: 0.10510 (A-MSE: 0.09382) avg lploss: 0.00000
train epoch 1005 avg loss: 0.09593 (A-MSE: 0.08632) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.48421 (A-MSE: 0.41397) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.48883 (A-MSE: 0.41937) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 15 out of 50
train epoch 1006 avg loss: 0.10080 (A-MSE: 0.09013) avg lploss: 0.00000
train epoch 1007 avg loss: 0.09019 (A-MSE: 0.08114) avg lploss: 0.00000
train epoch 1008 avg loss: 0.09549 (A-MSE: 0.08615) avg lploss: 0.00000
train epoch 1009 avg loss: 0.11394 (A-MSE: 0.10261) avg lploss: 0.00000
train epoch 1010 avg loss: 0.12060 (A-MSE: 0.10787) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.47279 (A-MSE: 0.41602) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.52991 (A-MSE: 0.46924) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 16 out of 50
train epoch 1011 avg loss: 0.11531 (A-MSE: 0.10259) avg lploss: 0.00000
train epoch 1012 avg loss: 0.09875 (A-MSE: 0.08749) avg lploss: 0.00000
train epoch 1013 avg loss: 0.09719 (A-MSE: 0.08625) avg lploss: 0.00000
train epoch 1014 avg loss: 0.09491 (A-MSE: 0.08498) avg lploss: 0.00000
train epoch 1015 avg loss: 0.08659 (A-MSE: 0.07813) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.43436 (A-MSE: 0.37297) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.45104 (A-MSE: 0.39043) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 17 out of 50
train epoch 1016 avg loss: 0.08634 (A-MSE: 0.07762) avg lploss: 0.00000
train epoch 1017 avg loss: 0.08871 (A-MSE: 0.07987) avg lploss: 0.00000
train epoch 1018 avg loss: 0.10404 (A-MSE: 0.09312) avg lploss: 0.00000
train epoch 1019 avg loss: 0.10134 (A-MSE: 0.09044) avg lploss: 0.00000
train epoch 1020 avg loss: 0.09574 (A-MSE: 0.08663) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.54152 (A-MSE: 0.46648) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.54820 (A-MSE: 0.46985) avg lploss: 0.00000
*** Best Val Loss: 0.42188 	 Best Test Loss: 0.45682 	 Best epoch 930
EarlyStopping counter: 18 out of 50
train epoch 1021 avg loss: 0.10009 (A-MSE: 0.08929) avg lploss: 0.00000
train epoch 1022 avg loss: 0.08456 (A-MSE: 0.07555) avg lploss: 0.00000
train epoch 1023 avg loss: 0.08393 (A-MSE: 0.07562) avg lploss: 0.00000
train epoch 1024 avg loss: 0.09064 (A-MSE: 0.08190) avg lploss: 0.00000
train epoch 1025 avg loss: 0.07503 (A-MSE: 0.06725) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.41109 (A-MSE: 0.35679) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.46520 (A-MSE: 0.40650) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
Validation loss decreased (0.421884 --> 0.411086).  Saving model ...
train epoch 1026 avg loss: 0.08576 (A-MSE: 0.07671) avg lploss: 0.00000
train epoch 1027 avg loss: 0.07918 (A-MSE: 0.07167) avg lploss: 0.00000
train epoch 1028 avg loss: 0.08715 (A-MSE: 0.07770) avg lploss: 0.00000
train epoch 1029 avg loss: 0.08586 (A-MSE: 0.07667) avg lploss: 0.00000
train epoch 1030 avg loss: 0.09409 (A-MSE: 0.08394) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.53478 (A-MSE: 0.46616) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.55818 (A-MSE: 0.48629) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 1 out of 50
train epoch 1031 avg loss: 0.09612 (A-MSE: 0.08598) avg lploss: 0.00000
train epoch 1032 avg loss: 0.09237 (A-MSE: 0.08250) avg lploss: 0.00000
train epoch 1033 avg loss: 0.09379 (A-MSE: 0.08364) avg lploss: 0.00000
train epoch 1034 avg loss: 0.08334 (A-MSE: 0.07548) avg lploss: 0.00000
train epoch 1035 avg loss: 0.08237 (A-MSE: 0.07300) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.46200 (A-MSE: 0.40212) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.51133 (A-MSE: 0.44418) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 2 out of 50
train epoch 1036 avg loss: 0.08037 (A-MSE: 0.07279) avg lploss: 0.00000
train epoch 1037 avg loss: 0.07532 (A-MSE: 0.06769) avg lploss: 0.00000
train epoch 1038 avg loss: 0.07368 (A-MSE: 0.06670) avg lploss: 0.00000
train epoch 1039 avg loss: 0.07295 (A-MSE: 0.06558) avg lploss: 0.00000
train epoch 1040 avg loss: 0.07465 (A-MSE: 0.06733) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.42462 (A-MSE: 0.36457) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.45025 (A-MSE: 0.38948) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 3 out of 50
train epoch 1041 avg loss: 0.07921 (A-MSE: 0.07110) avg lploss: 0.00000
train epoch 1042 avg loss: 0.07117 (A-MSE: 0.06406) avg lploss: 0.00000
train epoch 1043 avg loss: 0.07475 (A-MSE: 0.06723) avg lploss: 0.00000
train epoch 1044 avg loss: 0.07230 (A-MSE: 0.06486) avg lploss: 0.00000
train epoch 1045 avg loss: 0.07189 (A-MSE: 0.06412) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.44768 (A-MSE: 0.38747) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.47316 (A-MSE: 0.40522) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 4 out of 50
train epoch 1046 avg loss: 0.07379 (A-MSE: 0.06622) avg lploss: 0.00000
train epoch 1047 avg loss: 0.07349 (A-MSE: 0.06556) avg lploss: 0.00000
train epoch 1048 avg loss: 0.08356 (A-MSE: 0.07554) avg lploss: 0.00000
train epoch 1049 avg loss: 0.09487 (A-MSE: 0.08513) avg lploss: 0.00000
train epoch 1050 avg loss: 0.10165 (A-MSE: 0.09083) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.42304 (A-MSE: 0.36595) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.45087 (A-MSE: 0.39537) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 5 out of 50
train epoch 1051 avg loss: 0.09030 (A-MSE: 0.08121) avg lploss: 0.00000
train epoch 1052 avg loss: 0.07907 (A-MSE: 0.07140) avg lploss: 0.00000
train epoch 1053 avg loss: 0.07280 (A-MSE: 0.06598) avg lploss: 0.00000
train epoch 1054 avg loss: 0.07697 (A-MSE: 0.06930) avg lploss: 0.00000
train epoch 1055 avg loss: 0.07828 (A-MSE: 0.07042) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.47785 (A-MSE: 0.41144) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.48783 (A-MSE: 0.42434) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 6 out of 50
train epoch 1056 avg loss: 0.08459 (A-MSE: 0.07560) avg lploss: 0.00000
train epoch 1057 avg loss: 0.08877 (A-MSE: 0.07991) avg lploss: 0.00000
train epoch 1058 avg loss: 0.09739 (A-MSE: 0.08715) avg lploss: 0.00000
train epoch 1059 avg loss: 0.10682 (A-MSE: 0.09596) avg lploss: 0.00000
train epoch 1060 avg loss: 0.11144 (A-MSE: 0.10115) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.46253 (A-MSE: 0.39625) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.47308 (A-MSE: 0.40578) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 7 out of 50
train epoch 1061 avg loss: 0.09769 (A-MSE: 0.08714) avg lploss: 0.00000
train epoch 1062 avg loss: 0.08774 (A-MSE: 0.07721) avg lploss: 0.00000
train epoch 1063 avg loss: 0.07460 (A-MSE: 0.06758) avg lploss: 0.00000
train epoch 1064 avg loss: 0.06834 (A-MSE: 0.06126) avg lploss: 0.00000
train epoch 1065 avg loss: 0.06423 (A-MSE: 0.05762) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.42682 (A-MSE: 0.37082) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.46993 (A-MSE: 0.40437) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 8 out of 50
train epoch 1066 avg loss: 0.06267 (A-MSE: 0.05644) avg lploss: 0.00000
train epoch 1067 avg loss: 0.05778 (A-MSE: 0.05234) avg lploss: 0.00000
train epoch 1068 avg loss: 0.06303 (A-MSE: 0.05642) avg lploss: 0.00000
train epoch 1069 avg loss: 0.06375 (A-MSE: 0.05742) avg lploss: 0.00000
train epoch 1070 avg loss: 0.06842 (A-MSE: 0.06170) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.46615 (A-MSE: 0.40276) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.49708 (A-MSE: 0.43252) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 9 out of 50
train epoch 1071 avg loss: 0.07203 (A-MSE: 0.06473) avg lploss: 0.00000
train epoch 1072 avg loss: 0.07444 (A-MSE: 0.06669) avg lploss: 0.00000
train epoch 1073 avg loss: 0.06674 (A-MSE: 0.06033) avg lploss: 0.00000
train epoch 1074 avg loss: 0.06435 (A-MSE: 0.05783) avg lploss: 0.00000
train epoch 1075 avg loss: 0.06419 (A-MSE: 0.05745) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.45908 (A-MSE: 0.39835) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.48568 (A-MSE: 0.42645) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 10 out of 50
train epoch 1076 avg loss: 0.06603 (A-MSE: 0.05949) avg lploss: 0.00000
train epoch 1077 avg loss: 0.06448 (A-MSE: 0.05795) avg lploss: 0.00000
train epoch 1078 avg loss: 0.06319 (A-MSE: 0.05705) avg lploss: 0.00000
train epoch 1079 avg loss: 0.06268 (A-MSE: 0.05643) avg lploss: 0.00000
train epoch 1080 avg loss: 0.06645 (A-MSE: 0.05928) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.45743 (A-MSE: 0.39683) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.49026 (A-MSE: 0.42722) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 11 out of 50
train epoch 1081 avg loss: 0.06684 (A-MSE: 0.06053) avg lploss: 0.00000
train epoch 1082 avg loss: 0.06125 (A-MSE: 0.05510) avg lploss: 0.00000
train epoch 1083 avg loss: 0.05712 (A-MSE: 0.05175) avg lploss: 0.00000
train epoch 1084 avg loss: 0.06661 (A-MSE: 0.05991) avg lploss: 0.00000
train epoch 1085 avg loss: 0.07032 (A-MSE: 0.06365) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.44015 (A-MSE: 0.37484) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.45070 (A-MSE: 0.39040) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 12 out of 50
train epoch 1086 avg loss: 0.07148 (A-MSE: 0.06427) avg lploss: 0.00000
train epoch 1087 avg loss: 0.07739 (A-MSE: 0.06973) avg lploss: 0.00000
train epoch 1088 avg loss: 0.08123 (A-MSE: 0.07262) avg lploss: 0.00000
train epoch 1089 avg loss: 0.09077 (A-MSE: 0.08062) avg lploss: 0.00000
train epoch 1090 avg loss: 0.09189 (A-MSE: 0.08273) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.48997 (A-MSE: 0.42011) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.49166 (A-MSE: 0.42509) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 13 out of 50
train epoch 1091 avg loss: 0.07522 (A-MSE: 0.06821) avg lploss: 0.00000
train epoch 1092 avg loss: 0.08187 (A-MSE: 0.07334) avg lploss: 0.00000
train epoch 1093 avg loss: 0.06806 (A-MSE: 0.06146) avg lploss: 0.00000
train epoch 1094 avg loss: 0.07616 (A-MSE: 0.06910) avg lploss: 0.00000
train epoch 1095 avg loss: 0.10898 (A-MSE: 0.09592) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.45468 (A-MSE: 0.39838) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.49977 (A-MSE: 0.43499) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 14 out of 50
train epoch 1096 avg loss: 0.09096 (A-MSE: 0.08191) avg lploss: 0.00000
train epoch 1097 avg loss: 0.08870 (A-MSE: 0.08011) avg lploss: 0.00000
train epoch 1098 avg loss: 0.08147 (A-MSE: 0.07296) avg lploss: 0.00000
train epoch 1099 avg loss: 0.07667 (A-MSE: 0.06848) avg lploss: 0.00000
train epoch 1100 avg loss: 0.07096 (A-MSE: 0.06373) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.44372 (A-MSE: 0.38217) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.44613 (A-MSE: 0.38823) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 15 out of 50
train epoch 1101 avg loss: 0.07246 (A-MSE: 0.06495) avg lploss: 0.00000
train epoch 1102 avg loss: 0.07104 (A-MSE: 0.06418) avg lploss: 0.00000
train epoch 1103 avg loss: 0.08398 (A-MSE: 0.07555) avg lploss: 0.00000
train epoch 1104 avg loss: 0.09493 (A-MSE: 0.08491) avg lploss: 0.00000
train epoch 1105 avg loss: 0.09101 (A-MSE: 0.08153) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.48257 (A-MSE: 0.41911) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.49329 (A-MSE: 0.42777) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 16 out of 50
train epoch 1106 avg loss: 0.08644 (A-MSE: 0.07853) avg lploss: 0.00000
train epoch 1107 avg loss: 0.07358 (A-MSE: 0.06646) avg lploss: 0.00000
train epoch 1108 avg loss: 0.07404 (A-MSE: 0.06653) avg lploss: 0.00000
train epoch 1109 avg loss: 0.09593 (A-MSE: 0.08535) avg lploss: 0.00000
train epoch 1110 avg loss: 0.08281 (A-MSE: 0.07412) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.47305 (A-MSE: 0.41051) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.50827 (A-MSE: 0.44070) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 17 out of 50
train epoch 1111 avg loss: 0.07246 (A-MSE: 0.06486) avg lploss: 0.00000
train epoch 1112 avg loss: 0.06993 (A-MSE: 0.06263) avg lploss: 0.00000
train epoch 1113 avg loss: 0.08334 (A-MSE: 0.07469) avg lploss: 0.00000
train epoch 1114 avg loss: 0.08777 (A-MSE: 0.07854) avg lploss: 0.00000
train epoch 1115 avg loss: 0.08255 (A-MSE: 0.07383) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.44985 (A-MSE: 0.38712) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.46502 (A-MSE: 0.40312) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 18 out of 50
train epoch 1116 avg loss: 0.08193 (A-MSE: 0.07364) avg lploss: 0.00000
train epoch 1117 avg loss: 0.07137 (A-MSE: 0.06453) avg lploss: 0.00000
train epoch 1118 avg loss: 0.07720 (A-MSE: 0.06950) avg lploss: 0.00000
train epoch 1119 avg loss: 0.07603 (A-MSE: 0.06857) avg lploss: 0.00000
train epoch 1120 avg loss: 0.07299 (A-MSE: 0.06509) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.42966 (A-MSE: 0.37703) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.46762 (A-MSE: 0.40857) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 19 out of 50
train epoch 1121 avg loss: 0.06870 (A-MSE: 0.06171) avg lploss: 0.00000
train epoch 1122 avg loss: 0.06251 (A-MSE: 0.05641) avg lploss: 0.00000
train epoch 1123 avg loss: 0.06501 (A-MSE: 0.05842) avg lploss: 0.00000
train epoch 1124 avg loss: 0.06562 (A-MSE: 0.05884) avg lploss: 0.00000
train epoch 1125 avg loss: 0.08116 (A-MSE: 0.07230) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.46849 (A-MSE: 0.40373) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.48128 (A-MSE: 0.41499) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 20 out of 50
train epoch 1126 avg loss: 0.08112 (A-MSE: 0.07269) avg lploss: 0.00000
train epoch 1127 avg loss: 0.06868 (A-MSE: 0.06127) avg lploss: 0.00000
train epoch 1128 avg loss: 0.07070 (A-MSE: 0.06381) avg lploss: 0.00000
train epoch 1129 avg loss: 0.06711 (A-MSE: 0.06046) avg lploss: 0.00000
train epoch 1130 avg loss: 0.06836 (A-MSE: 0.06076) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.44159 (A-MSE: 0.38196) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.49410 (A-MSE: 0.42490) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 21 out of 50
train epoch 1131 avg loss: 0.06593 (A-MSE: 0.05864) avg lploss: 0.00000
train epoch 1132 avg loss: 0.06370 (A-MSE: 0.05806) avg lploss: 0.00000
train epoch 1133 avg loss: 0.06194 (A-MSE: 0.05579) avg lploss: 0.00000
train epoch 1134 avg loss: 0.06204 (A-MSE: 0.05563) avg lploss: 0.00000
train epoch 1135 avg loss: 0.06676 (A-MSE: 0.06028) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.51720 (A-MSE: 0.43327) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.54175 (A-MSE: 0.46211) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 22 out of 50
train epoch 1136 avg loss: 0.06918 (A-MSE: 0.06232) avg lploss: 0.00000
train epoch 1137 avg loss: 0.06759 (A-MSE: 0.06040) avg lploss: 0.00000
train epoch 1138 avg loss: 0.06183 (A-MSE: 0.05542) avg lploss: 0.00000
train epoch 1139 avg loss: 0.08273 (A-MSE: 0.07393) avg lploss: 0.00000
train epoch 1140 avg loss: 0.08567 (A-MSE: 0.07637) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.43926 (A-MSE: 0.37649) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.45357 (A-MSE: 0.39295) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 23 out of 50
train epoch 1141 avg loss: 0.07755 (A-MSE: 0.06978) avg lploss: 0.00000
train epoch 1142 avg loss: 0.08324 (A-MSE: 0.07478) avg lploss: 0.00000
train epoch 1143 avg loss: 0.07934 (A-MSE: 0.07082) avg lploss: 0.00000
train epoch 1144 avg loss: 0.06959 (A-MSE: 0.06276) avg lploss: 0.00000
train epoch 1145 avg loss: 0.06988 (A-MSE: 0.06265) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.42767 (A-MSE: 0.37370) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.47304 (A-MSE: 0.40975) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 24 out of 50
train epoch 1146 avg loss: 0.06582 (A-MSE: 0.05912) avg lploss: 0.00000
train epoch 1147 avg loss: 0.06192 (A-MSE: 0.05636) avg lploss: 0.00000
train epoch 1148 avg loss: 0.06323 (A-MSE: 0.05722) avg lploss: 0.00000
train epoch 1149 avg loss: 0.06506 (A-MSE: 0.05817) avg lploss: 0.00000
train epoch 1150 avg loss: 0.06428 (A-MSE: 0.05824) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.45703 (A-MSE: 0.39610) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.48795 (A-MSE: 0.42570) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 25 out of 50
train epoch 1151 avg loss: 0.06563 (A-MSE: 0.05951) avg lploss: 0.00000
train epoch 1152 avg loss: 0.07771 (A-MSE: 0.07001) avg lploss: 0.00000
train epoch 1153 avg loss: 0.06908 (A-MSE: 0.06245) avg lploss: 0.00000
train epoch 1154 avg loss: 0.07106 (A-MSE: 0.06419) avg lploss: 0.00000
train epoch 1155 avg loss: 0.07162 (A-MSE: 0.06422) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.43862 (A-MSE: 0.37962) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.48483 (A-MSE: 0.42070) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 26 out of 50
train epoch 1156 avg loss: 0.06901 (A-MSE: 0.06244) avg lploss: 0.00000
train epoch 1157 avg loss: 0.07190 (A-MSE: 0.06505) avg lploss: 0.00000
train epoch 1158 avg loss: 0.07203 (A-MSE: 0.06420) avg lploss: 0.00000
train epoch 1159 avg loss: 0.07194 (A-MSE: 0.06423) avg lploss: 0.00000
train epoch 1160 avg loss: 0.06328 (A-MSE: 0.05711) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.41447 (A-MSE: 0.36128) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.45059 (A-MSE: 0.39220) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 27 out of 50
train epoch 1161 avg loss: 0.06766 (A-MSE: 0.06031) avg lploss: 0.00000
train epoch 1162 avg loss: 0.06366 (A-MSE: 0.05688) avg lploss: 0.00000
train epoch 1163 avg loss: 0.05622 (A-MSE: 0.05046) avg lploss: 0.00000
train epoch 1164 avg loss: 0.06002 (A-MSE: 0.05373) avg lploss: 0.00000
train epoch 1165 avg loss: 0.06272 (A-MSE: 0.05607) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.43564 (A-MSE: 0.37319) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.46171 (A-MSE: 0.40275) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 28 out of 50
train epoch 1166 avg loss: 0.05755 (A-MSE: 0.05144) avg lploss: 0.00000
train epoch 1167 avg loss: 0.05610 (A-MSE: 0.05098) avg lploss: 0.00000
train epoch 1168 avg loss: 0.05391 (A-MSE: 0.04876) avg lploss: 0.00000
train epoch 1169 avg loss: 0.06270 (A-MSE: 0.05682) avg lploss: 0.00000
train epoch 1170 avg loss: 0.06885 (A-MSE: 0.06217) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.45920 (A-MSE: 0.39549) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.48191 (A-MSE: 0.41854) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 29 out of 50
train epoch 1171 avg loss: 0.05991 (A-MSE: 0.05445) avg lploss: 0.00000
train epoch 1172 avg loss: 0.06784 (A-MSE: 0.06099) avg lploss: 0.00000
train epoch 1173 avg loss: 0.07700 (A-MSE: 0.06893) avg lploss: 0.00000
train epoch 1174 avg loss: 0.09719 (A-MSE: 0.08671) avg lploss: 0.00000
train epoch 1175 avg loss: 0.09186 (A-MSE: 0.08251) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.45108 (A-MSE: 0.38566) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.48490 (A-MSE: 0.41921) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 30 out of 50
train epoch 1176 avg loss: 0.06973 (A-MSE: 0.06268) avg lploss: 0.00000
train epoch 1177 avg loss: 0.06492 (A-MSE: 0.05740) avg lploss: 0.00000
train epoch 1178 avg loss: 0.05855 (A-MSE: 0.05246) avg lploss: 0.00000
train epoch 1179 avg loss: 0.06411 (A-MSE: 0.05727) avg lploss: 0.00000
train epoch 1180 avg loss: 0.06627 (A-MSE: 0.05938) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.48089 (A-MSE: 0.41762) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.50053 (A-MSE: 0.43274) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 31 out of 50
train epoch 1181 avg loss: 0.08129 (A-MSE: 0.07270) avg lploss: 0.00000
train epoch 1182 avg loss: 0.07245 (A-MSE: 0.06611) avg lploss: 0.00000
train epoch 1183 avg loss: 0.07130 (A-MSE: 0.06377) avg lploss: 0.00000
train epoch 1184 avg loss: 0.08138 (A-MSE: 0.07414) avg lploss: 0.00000
train epoch 1185 avg loss: 0.07533 (A-MSE: 0.06778) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.48105 (A-MSE: 0.41297) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.51163 (A-MSE: 0.43893) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 32 out of 50
train epoch 1186 avg loss: 0.06161 (A-MSE: 0.05474) avg lploss: 0.00000
train epoch 1187 avg loss: 0.06212 (A-MSE: 0.05559) avg lploss: 0.00000
train epoch 1188 avg loss: 0.07043 (A-MSE: 0.06300) avg lploss: 0.00000
train epoch 1189 avg loss: 0.08219 (A-MSE: 0.07461) avg lploss: 0.00000
train epoch 1190 avg loss: 0.10663 (A-MSE: 0.09533) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.48066 (A-MSE: 0.41718) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.52730 (A-MSE: 0.46304) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 33 out of 50
train epoch 1191 avg loss: 0.09027 (A-MSE: 0.08095) avg lploss: 0.00000
train epoch 1192 avg loss: 0.07550 (A-MSE: 0.06787) avg lploss: 0.00000
train epoch 1193 avg loss: 0.06721 (A-MSE: 0.06061) avg lploss: 0.00000
train epoch 1194 avg loss: 0.06909 (A-MSE: 0.06112) avg lploss: 0.00000
train epoch 1195 avg loss: 0.07717 (A-MSE: 0.07001) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.47904 (A-MSE: 0.41725) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.49827 (A-MSE: 0.43577) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 34 out of 50
train epoch 1196 avg loss: 0.07577 (A-MSE: 0.06817) avg lploss: 0.00000
train epoch 1197 avg loss: 0.06721 (A-MSE: 0.05998) avg lploss: 0.00000
train epoch 1198 avg loss: 0.06346 (A-MSE: 0.05692) avg lploss: 0.00000
train epoch 1199 avg loss: 0.06728 (A-MSE: 0.06048) avg lploss: 0.00000
train epoch 1200 avg loss: 0.06403 (A-MSE: 0.05797) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.44587 (A-MSE: 0.38155) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.47226 (A-MSE: 0.40841) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 35 out of 50
train epoch 1201 avg loss: 0.05925 (A-MSE: 0.05278) avg lploss: 0.00000
train epoch 1202 avg loss: 0.05393 (A-MSE: 0.04861) avg lploss: 0.00000
train epoch 1203 avg loss: 0.05781 (A-MSE: 0.05199) avg lploss: 0.00000
train epoch 1204 avg loss: 0.06523 (A-MSE: 0.05890) avg lploss: 0.00000
train epoch 1205 avg loss: 0.05994 (A-MSE: 0.05414) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.46414 (A-MSE: 0.39792) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.48566 (A-MSE: 0.41924) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 36 out of 50
train epoch 1206 avg loss: 0.05779 (A-MSE: 0.05159) avg lploss: 0.00000
train epoch 1207 avg loss: 0.05716 (A-MSE: 0.05209) avg lploss: 0.00000
train epoch 1208 avg loss: 0.06753 (A-MSE: 0.06050) avg lploss: 0.00000
train epoch 1209 avg loss: 0.06788 (A-MSE: 0.06053) avg lploss: 0.00000
train epoch 1210 avg loss: 0.06510 (A-MSE: 0.05888) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.43313 (A-MSE: 0.37409) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.47801 (A-MSE: 0.41271) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 37 out of 50
train epoch 1211 avg loss: 0.05882 (A-MSE: 0.05316) avg lploss: 0.00000
train epoch 1212 avg loss: 0.05820 (A-MSE: 0.05318) avg lploss: 0.00000
train epoch 1213 avg loss: 0.05533 (A-MSE: 0.04951) avg lploss: 0.00000
train epoch 1214 avg loss: 0.05335 (A-MSE: 0.04786) avg lploss: 0.00000
train epoch 1215 avg loss: 0.05955 (A-MSE: 0.05360) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.48740 (A-MSE: 0.42202) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.48755 (A-MSE: 0.42382) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 38 out of 50
train epoch 1216 avg loss: 0.06226 (A-MSE: 0.05631) avg lploss: 0.00000
train epoch 1217 avg loss: 0.06349 (A-MSE: 0.05591) avg lploss: 0.00000
train epoch 1218 avg loss: 0.06556 (A-MSE: 0.05889) avg lploss: 0.00000
train epoch 1219 avg loss: 0.06506 (A-MSE: 0.05856) avg lploss: 0.00000
train epoch 1220 avg loss: 0.06480 (A-MSE: 0.05826) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.48877 (A-MSE: 0.42284) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.50441 (A-MSE: 0.43551) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 39 out of 50
train epoch 1221 avg loss: 0.06058 (A-MSE: 0.05428) avg lploss: 0.00000
train epoch 1222 avg loss: 0.05664 (A-MSE: 0.05072) avg lploss: 0.00000
train epoch 1223 avg loss: 0.04783 (A-MSE: 0.04323) avg lploss: 0.00000
train epoch 1224 avg loss: 0.05552 (A-MSE: 0.04941) avg lploss: 0.00000
train epoch 1225 avg loss: 0.06794 (A-MSE: 0.06118) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.49457 (A-MSE: 0.42721) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.51245 (A-MSE: 0.44472) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 40 out of 50
train epoch 1226 avg loss: 0.07573 (A-MSE: 0.06882) avg lploss: 0.00000
train epoch 1227 avg loss: 0.07178 (A-MSE: 0.06435) avg lploss: 0.00000
train epoch 1228 avg loss: 0.07342 (A-MSE: 0.06743) avg lploss: 0.00000
train epoch 1229 avg loss: 0.07010 (A-MSE: 0.06311) avg lploss: 0.00000
train epoch 1230 avg loss: 0.06513 (A-MSE: 0.05825) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.48411 (A-MSE: 0.41771) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.49941 (A-MSE: 0.43127) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 41 out of 50
train epoch 1231 avg loss: 0.05925 (A-MSE: 0.05371) avg lploss: 0.00000
train epoch 1232 avg loss: 0.05601 (A-MSE: 0.05063) avg lploss: 0.00000
train epoch 1233 avg loss: 0.05742 (A-MSE: 0.05191) avg lploss: 0.00000
train epoch 1234 avg loss: 0.05846 (A-MSE: 0.05259) avg lploss: 0.00000
train epoch 1235 avg loss: 0.06079 (A-MSE: 0.05494) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.47801 (A-MSE: 0.41099) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.48801 (A-MSE: 0.42350) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 42 out of 50
train epoch 1236 avg loss: 0.07320 (A-MSE: 0.06557) avg lploss: 0.00000
train epoch 1237 avg loss: 0.09046 (A-MSE: 0.08000) avg lploss: 0.00000
train epoch 1238 avg loss: 0.08446 (A-MSE: 0.07608) avg lploss: 0.00000
train epoch 1239 avg loss: 0.07518 (A-MSE: 0.06762) avg lploss: 0.00000
train epoch 1240 avg loss: 0.07159 (A-MSE: 0.06448) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.43318 (A-MSE: 0.37710) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.45558 (A-MSE: 0.39528) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 43 out of 50
train epoch 1241 avg loss: 0.06248 (A-MSE: 0.05652) avg lploss: 0.00000
train epoch 1242 avg loss: 0.06250 (A-MSE: 0.05629) avg lploss: 0.00000
train epoch 1243 avg loss: 0.07621 (A-MSE: 0.06862) avg lploss: 0.00000
train epoch 1244 avg loss: 0.06830 (A-MSE: 0.06159) avg lploss: 0.00000
train epoch 1245 avg loss: 0.07169 (A-MSE: 0.06417) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.45259 (A-MSE: 0.38948) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.45537 (A-MSE: 0.39180) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 44 out of 50
train epoch 1246 avg loss: 0.06980 (A-MSE: 0.06249) avg lploss: 0.00000
train epoch 1247 avg loss: 0.06267 (A-MSE: 0.05630) avg lploss: 0.00000
train epoch 1248 avg loss: 0.05504 (A-MSE: 0.04939) avg lploss: 0.00000
train epoch 1249 avg loss: 0.05033 (A-MSE: 0.04504) avg lploss: 0.00000
train epoch 1250 avg loss: 0.04924 (A-MSE: 0.04472) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.45236 (A-MSE: 0.39037) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.47564 (A-MSE: 0.41455) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 45 out of 50
train epoch 1251 avg loss: 0.06483 (A-MSE: 0.05800) avg lploss: 0.00000
train epoch 1252 avg loss: 0.05567 (A-MSE: 0.05065) avg lploss: 0.00000
train epoch 1253 avg loss: 0.05993 (A-MSE: 0.05407) avg lploss: 0.00000
train epoch 1254 avg loss: 0.05805 (A-MSE: 0.05246) avg lploss: 0.00000
train epoch 1255 avg loss: 0.05543 (A-MSE: 0.05003) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.43355 (A-MSE: 0.37021) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.46154 (A-MSE: 0.39940) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 46 out of 50
train epoch 1256 avg loss: 0.05080 (A-MSE: 0.04591) avg lploss: 0.00000
train epoch 1257 avg loss: 0.04925 (A-MSE: 0.04438) avg lploss: 0.00000
train epoch 1258 avg loss: 0.04899 (A-MSE: 0.04418) avg lploss: 0.00000
train epoch 1259 avg loss: 0.05313 (A-MSE: 0.04757) avg lploss: 0.00000
train epoch 1260 avg loss: 0.04542 (A-MSE: 0.04078) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.46175 (A-MSE: 0.39777) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.47702 (A-MSE: 0.41519) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 47 out of 50
train epoch 1261 avg loss: 0.05192 (A-MSE: 0.04698) avg lploss: 0.00000
train epoch 1262 avg loss: 0.05226 (A-MSE: 0.04696) avg lploss: 0.00000
train epoch 1263 avg loss: 0.05422 (A-MSE: 0.04875) avg lploss: 0.00000
train epoch 1264 avg loss: 0.05502 (A-MSE: 0.04989) avg lploss: 0.00000
train epoch 1265 avg loss: 0.05745 (A-MSE: 0.05212) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.51244 (A-MSE: 0.44374) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.53587 (A-MSE: 0.46733) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 48 out of 50
train epoch 1266 avg loss: 0.06159 (A-MSE: 0.05611) avg lploss: 0.00000
train epoch 1267 avg loss: 0.05694 (A-MSE: 0.05124) avg lploss: 0.00000
train epoch 1268 avg loss: 0.05291 (A-MSE: 0.04785) avg lploss: 0.00000
train epoch 1269 avg loss: 0.05140 (A-MSE: 0.04595) avg lploss: 0.00000
train epoch 1270 avg loss: 0.04315 (A-MSE: 0.03900) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.46001 (A-MSE: 0.39224) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.46682 (A-MSE: 0.40485) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 49 out of 50
train epoch 1271 avg loss: 0.05413 (A-MSE: 0.04862) avg lploss: 0.00000
train epoch 1272 avg loss: 0.05889 (A-MSE: 0.05342) avg lploss: 0.00000
train epoch 1273 avg loss: 0.05883 (A-MSE: 0.05260) avg lploss: 0.00000
train epoch 1274 avg loss: 0.05760 (A-MSE: 0.05163) avg lploss: 0.00000
train epoch 1275 avg loss: 0.04826 (A-MSE: 0.04361) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.43571 (A-MSE: 0.37397) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.45330 (A-MSE: 0.39140) avg lploss: 0.00000
*** Best Val Loss: 0.41109 	 Best Test Loss: 0.46520 	 Best epoch 1025
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.075026
best_lp = 0.000000
best_val = 0.411086
best_test = 0.465196
best_epoch = 1025
best_train = 0.075026, best_lp = 0.000000, best_val = 0.411086, best_test = 0.465196, best_epoch = 1025
Job completed at Mon Dec  8 22:54:52 CET 2025
