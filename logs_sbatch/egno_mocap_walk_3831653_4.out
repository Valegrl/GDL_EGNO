Date              = Mon Dec  8 23:11:24 CET 2025
Hostname          = mel2105
Array Task ID     = 4
Running config: configs/mocap_walk_seed5.json
Namespace(batch_size=12, case='walk', config_by_file='configs/mocap_walk_seed5.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_walk_seed5', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=5, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 198 samples!
Got Split!
Got 600 samples!
Got Split!
Got 600 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_walk_seed5/saved_model.pth
train epoch 0 avg loss: 14.36547 (A-MSE: 12.92832) avg lploss: 0.00000
==> val epoch 0 avg loss: 12.74426 (A-MSE: 11.21507) avg lploss: 0.00000
==> test epoch 0 avg loss: 12.75924 (A-MSE: 11.23684) avg lploss: 0.00000
*** Best Val Loss: 12.74426 	 Best Test Loss: 12.75924 	 Best epoch 0
Validation loss decreased (inf --> 12.744261).  Saving model ...
train epoch 1 avg loss: 10.98698 (A-MSE: 9.62117) avg lploss: 0.00000
train epoch 2 avg loss: 12.81566 (A-MSE: 15.78598) avg lploss: 0.00000
train epoch 3 avg loss: 320.42933 (A-MSE: 331.30132) avg lploss: 0.00000
train epoch 4 avg loss: 307.61596 (A-MSE: 304.07921) avg lploss: 0.00000
train epoch 5 avg loss: 12.19924 (A-MSE: 12.29705) avg lploss: 0.00000
==> val epoch 5 avg loss: 13.76192 (A-MSE: 12.33288) avg lploss: 0.00000
==> test epoch 5 avg loss: 13.85524 (A-MSE: 12.42034) avg lploss: 0.00000
*** Best Val Loss: 12.74426 	 Best Test Loss: 12.75924 	 Best epoch 0
EarlyStopping counter: 1 out of 50
train epoch 6 avg loss: 12.49717 (A-MSE: 11.20731) avg lploss: 0.00000
train epoch 7 avg loss: 9.64585 (A-MSE: 8.51426) avg lploss: 0.00000
train epoch 8 avg loss: 8.19090 (A-MSE: 7.12711) avg lploss: 0.00000
train epoch 9 avg loss: 7.27181 (A-MSE: 6.27669) avg lploss: 0.00000
train epoch 10 avg loss: 6.65734 (A-MSE: 5.71946) avg lploss: 0.00000
==> val epoch 10 avg loss: 6.89785 (A-MSE: 5.91318) avg lploss: 0.00000
==> test epoch 10 avg loss: 6.79609 (A-MSE: 5.81921) avg lploss: 0.00000
*** Best Val Loss: 6.89785 	 Best Test Loss: 6.79609 	 Best epoch 10
Validation loss decreased (12.744261 --> 6.897851).  Saving model ...
train epoch 11 avg loss: 6.05657 (A-MSE: 5.18742) avg lploss: 0.00000
train epoch 12 avg loss: 5.36895 (A-MSE: 4.58956) avg lploss: 0.00000
train epoch 13 avg loss: 4.73616 (A-MSE: 4.03811) avg lploss: 0.00000
train epoch 14 avg loss: 4.34996 (A-MSE: 3.71487) avg lploss: 0.00000
train epoch 15 avg loss: 4.08326 (A-MSE: 3.48019) avg lploss: 0.00000
==> val epoch 15 avg loss: 4.41189 (A-MSE: 3.77346) avg lploss: 0.00000
==> test epoch 15 avg loss: 4.23830 (A-MSE: 3.61007) avg lploss: 0.00000
*** Best Val Loss: 4.41189 	 Best Test Loss: 4.23830 	 Best epoch 15
Validation loss decreased (6.897851 --> 4.411895).  Saving model ...
train epoch 16 avg loss: 3.86857 (A-MSE: 3.30422) avg lploss: 0.00000
train epoch 17 avg loss: 3.68085 (A-MSE: 3.13895) avg lploss: 0.00000
train epoch 18 avg loss: 3.58517 (A-MSE: 3.06719) avg lploss: 0.00000
train epoch 19 avg loss: 3.69515 (A-MSE: 3.17783) avg lploss: 0.00000
train epoch 20 avg loss: 3.32526 (A-MSE: 2.83750) avg lploss: 0.00000
==> val epoch 20 avg loss: 3.60633 (A-MSE: 3.04889) avg lploss: 0.00000
==> test epoch 20 avg loss: 3.43379 (A-MSE: 2.88859) avg lploss: 0.00000
*** Best Val Loss: 3.60633 	 Best Test Loss: 3.43379 	 Best epoch 20
Validation loss decreased (4.411895 --> 3.606331).  Saving model ...
train epoch 21 avg loss: 3.09483 (A-MSE: 2.64035) avg lploss: 0.00000
train epoch 22 avg loss: 2.87100 (A-MSE: 2.44901) avg lploss: 0.00000
train epoch 23 avg loss: 2.63756 (A-MSE: 2.24958) avg lploss: 0.00000
train epoch 24 avg loss: 2.38645 (A-MSE: 2.04314) avg lploss: 0.00000
train epoch 25 avg loss: 2.32319 (A-MSE: 2.00314) avg lploss: 0.00000
==> val epoch 25 avg loss: 2.63041 (A-MSE: 2.27794) avg lploss: 0.00000
==> test epoch 25 avg loss: 2.46960 (A-MSE: 2.13017) avg lploss: 0.00000
*** Best Val Loss: 2.63041 	 Best Test Loss: 2.46960 	 Best epoch 25
Validation loss decreased (3.606331 --> 2.630412).  Saving model ...
train epoch 26 avg loss: 2.28252 (A-MSE: 1.96127) avg lploss: 0.00000
train epoch 27 avg loss: 2.17693 (A-MSE: 1.86850) avg lploss: 0.00000
train epoch 28 avg loss: 2.19605 (A-MSE: 1.89383) avg lploss: 0.00000
train epoch 29 avg loss: 2.15047 (A-MSE: 1.84680) avg lploss: 0.00000
train epoch 30 avg loss: 2.07953 (A-MSE: 1.78751) avg lploss: 0.00000
==> val epoch 30 avg loss: 2.32511 (A-MSE: 1.97564) avg lploss: 0.00000
==> test epoch 30 avg loss: 2.18242 (A-MSE: 1.84557) avg lploss: 0.00000
*** Best Val Loss: 2.32511 	 Best Test Loss: 2.18242 	 Best epoch 30
Validation loss decreased (2.630412 --> 2.325111).  Saving model ...
train epoch 31 avg loss: 2.05161 (A-MSE: 1.76806) avg lploss: 0.00000
train epoch 32 avg loss: 2.02168 (A-MSE: 1.74121) avg lploss: 0.00000
train epoch 33 avg loss: 1.99443 (A-MSE: 1.72034) avg lploss: 0.00000
train epoch 34 avg loss: 1.94385 (A-MSE: 1.67153) avg lploss: 0.00000
train epoch 35 avg loss: 1.93142 (A-MSE: 1.66194) avg lploss: 0.00000
==> val epoch 35 avg loss: 2.12525 (A-MSE: 1.80309) avg lploss: 0.00000
==> test epoch 35 avg loss: 1.99626 (A-MSE: 1.68706) avg lploss: 0.00000
*** Best Val Loss: 2.12525 	 Best Test Loss: 1.99626 	 Best epoch 35
Validation loss decreased (2.325111 --> 2.125249).  Saving model ...
train epoch 36 avg loss: 1.90081 (A-MSE: 1.63113) avg lploss: 0.00000
train epoch 37 avg loss: 1.85051 (A-MSE: 1.59253) avg lploss: 0.00000
train epoch 38 avg loss: 1.84704 (A-MSE: 1.58922) avg lploss: 0.00000
train epoch 39 avg loss: 1.81668 (A-MSE: 1.56124) avg lploss: 0.00000
train epoch 40 avg loss: 1.72192 (A-MSE: 1.47980) avg lploss: 0.00000
==> val epoch 40 avg loss: 1.96632 (A-MSE: 1.65054) avg lploss: 0.00000
==> test epoch 40 avg loss: 1.82179 (A-MSE: 1.51856) avg lploss: 0.00000
*** Best Val Loss: 1.96632 	 Best Test Loss: 1.82179 	 Best epoch 40
Validation loss decreased (2.125249 --> 1.966319).  Saving model ...
train epoch 41 avg loss: 1.70634 (A-MSE: 1.46527) avg lploss: 0.00000
train epoch 42 avg loss: 1.67054 (A-MSE: 1.43484) avg lploss: 0.00000
train epoch 43 avg loss: 1.64609 (A-MSE: 1.41067) avg lploss: 0.00000
train epoch 44 avg loss: 1.62915 (A-MSE: 1.40035) avg lploss: 0.00000
train epoch 45 avg loss: 1.58951 (A-MSE: 1.36413) avg lploss: 0.00000
==> val epoch 45 avg loss: 1.85878 (A-MSE: 1.57274) avg lploss: 0.00000
==> test epoch 45 avg loss: 1.70553 (A-MSE: 1.43042) avg lploss: 0.00000
*** Best Val Loss: 1.85878 	 Best Test Loss: 1.70553 	 Best epoch 45
Validation loss decreased (1.966319 --> 1.858778).  Saving model ...
train epoch 46 avg loss: 1.52188 (A-MSE: 1.30586) avg lploss: 0.00000
train epoch 47 avg loss: 1.48989 (A-MSE: 1.27216) avg lploss: 0.00000
train epoch 48 avg loss: 1.45000 (A-MSE: 1.24263) avg lploss: 0.00000
train epoch 49 avg loss: 1.41173 (A-MSE: 1.20906) avg lploss: 0.00000
train epoch 50 avg loss: 1.35036 (A-MSE: 1.15244) avg lploss: 0.00000
==> val epoch 50 avg loss: 1.63811 (A-MSE: 1.39067) avg lploss: 0.00000
==> test epoch 50 avg loss: 1.46534 (A-MSE: 1.23194) avg lploss: 0.00000
*** Best Val Loss: 1.63811 	 Best Test Loss: 1.46534 	 Best epoch 50
Validation loss decreased (1.858778 --> 1.638106).  Saving model ...
train epoch 51 avg loss: 1.31787 (A-MSE: 1.12421) avg lploss: 0.00000
train epoch 52 avg loss: 1.28201 (A-MSE: 1.10008) avg lploss: 0.00000
train epoch 53 avg loss: 1.23286 (A-MSE: 1.05367) avg lploss: 0.00000
train epoch 54 avg loss: 1.32855 (A-MSE: 1.13657) avg lploss: 0.00000
train epoch 55 avg loss: 1.22553 (A-MSE: 1.05380) avg lploss: 0.00000
==> val epoch 55 avg loss: 1.46313 (A-MSE: 1.22270) avg lploss: 0.00000
==> test epoch 55 avg loss: 1.30172 (A-MSE: 1.07681) avg lploss: 0.00000
*** Best Val Loss: 1.46313 	 Best Test Loss: 1.30172 	 Best epoch 55
Validation loss decreased (1.638106 --> 1.463129).  Saving model ...
train epoch 56 avg loss: 1.14107 (A-MSE: 0.97498) avg lploss: 0.00000
train epoch 57 avg loss: 1.12316 (A-MSE: 0.95892) avg lploss: 0.00000
train epoch 58 avg loss: 1.09667 (A-MSE: 0.94063) avg lploss: 0.00000
train epoch 59 avg loss: 1.02602 (A-MSE: 0.88386) avg lploss: 0.00000
train epoch 60 avg loss: 1.03699 (A-MSE: 0.88661) avg lploss: 0.00000
==> val epoch 60 avg loss: 1.22079 (A-MSE: 1.00555) avg lploss: 0.00000
==> test epoch 60 avg loss: 1.06369 (A-MSE: 0.86461) avg lploss: 0.00000
*** Best Val Loss: 1.22079 	 Best Test Loss: 1.06369 	 Best epoch 60
Validation loss decreased (1.463129 --> 1.220788).  Saving model ...
train epoch 61 avg loss: 0.94020 (A-MSE: 0.80387) avg lploss: 0.00000
train epoch 62 avg loss: 0.94284 (A-MSE: 0.80737) avg lploss: 0.00000
train epoch 63 avg loss: 1.14157 (A-MSE: 0.99141) avg lploss: 0.00000
train epoch 64 avg loss: 1.07571 (A-MSE: 0.92699) avg lploss: 0.00000
train epoch 65 avg loss: 0.95530 (A-MSE: 0.81669) avg lploss: 0.00000
==> val epoch 65 avg loss: 1.12188 (A-MSE: 0.94966) avg lploss: 0.00000
==> test epoch 65 avg loss: 0.98121 (A-MSE: 0.82523) avg lploss: 0.00000
*** Best Val Loss: 1.12188 	 Best Test Loss: 0.98121 	 Best epoch 65
Validation loss decreased (1.220788 --> 1.121884).  Saving model ...
train epoch 66 avg loss: 0.91414 (A-MSE: 0.78358) avg lploss: 0.00000
train epoch 67 avg loss: 0.87117 (A-MSE: 0.75021) avg lploss: 0.00000
train epoch 68 avg loss: 0.88268 (A-MSE: 0.75916) avg lploss: 0.00000
train epoch 69 avg loss: 0.88044 (A-MSE: 0.75590) avg lploss: 0.00000
train epoch 70 avg loss: 0.85497 (A-MSE: 0.73297) avg lploss: 0.00000
==> val epoch 70 avg loss: 1.09274 (A-MSE: 0.89827) avg lploss: 0.00000
==> test epoch 70 avg loss: 0.94286 (A-MSE: 0.76635) avg lploss: 0.00000
*** Best Val Loss: 1.09274 	 Best Test Loss: 0.94286 	 Best epoch 70
Validation loss decreased (1.121884 --> 1.092745).  Saving model ...
train epoch 71 avg loss: 0.87990 (A-MSE: 0.75908) avg lploss: 0.00000
train epoch 72 avg loss: 0.88524 (A-MSE: 0.76228) avg lploss: 0.00000
train epoch 73 avg loss: 0.86560 (A-MSE: 0.74521) avg lploss: 0.00000
train epoch 74 avg loss: 0.82027 (A-MSE: 0.70381) avg lploss: 0.00000
train epoch 75 avg loss: 0.79228 (A-MSE: 0.67830) avg lploss: 0.00000
==> val epoch 75 avg loss: 0.98082 (A-MSE: 0.81953) avg lploss: 0.00000
==> test epoch 75 avg loss: 0.84781 (A-MSE: 0.70323) avg lploss: 0.00000
*** Best Val Loss: 0.98082 	 Best Test Loss: 0.84781 	 Best epoch 75
Validation loss decreased (1.092745 --> 0.980823).  Saving model ...
train epoch 76 avg loss: 0.83708 (A-MSE: 0.72296) avg lploss: 0.00000
train epoch 77 avg loss: 0.87151 (A-MSE: 0.75926) avg lploss: 0.00000
train epoch 78 avg loss: 0.81741 (A-MSE: 0.70128) avg lploss: 0.00000
train epoch 79 avg loss: 0.80456 (A-MSE: 0.68770) avg lploss: 0.00000
train epoch 80 avg loss: 0.73752 (A-MSE: 0.63409) avg lploss: 0.00000
==> val epoch 80 avg loss: 1.00307 (A-MSE: 0.81791) avg lploss: 0.00000
==> test epoch 80 avg loss: 0.86835 (A-MSE: 0.69987) avg lploss: 0.00000
*** Best Val Loss: 0.98082 	 Best Test Loss: 0.84781 	 Best epoch 75
EarlyStopping counter: 1 out of 50
train epoch 81 avg loss: 0.78999 (A-MSE: 0.68000) avg lploss: 0.00000
train epoch 82 avg loss: 0.73445 (A-MSE: 0.62712) avg lploss: 0.00000
train epoch 83 avg loss: 0.73044 (A-MSE: 0.62972) avg lploss: 0.00000
train epoch 84 avg loss: 0.74057 (A-MSE: 0.63596) avg lploss: 0.00000
train epoch 85 avg loss: 0.72088 (A-MSE: 0.62363) avg lploss: 0.00000
==> val epoch 85 avg loss: 0.98519 (A-MSE: 0.79641) avg lploss: 0.00000
==> test epoch 85 avg loss: 0.84628 (A-MSE: 0.67484) avg lploss: 0.00000
*** Best Val Loss: 0.98082 	 Best Test Loss: 0.84781 	 Best epoch 75
EarlyStopping counter: 2 out of 50
train epoch 86 avg loss: 0.72866 (A-MSE: 0.62577) avg lploss: 0.00000
train epoch 87 avg loss: 0.71073 (A-MSE: 0.61148) avg lploss: 0.00000
train epoch 88 avg loss: 0.70940 (A-MSE: 0.60845) avg lploss: 0.00000
train epoch 89 avg loss: 0.68927 (A-MSE: 0.59160) avg lploss: 0.00000
train epoch 90 avg loss: 0.67950 (A-MSE: 0.58511) avg lploss: 0.00000
==> val epoch 90 avg loss: 0.83378 (A-MSE: 0.69799) avg lploss: 0.00000
==> test epoch 90 avg loss: 0.71635 (A-MSE: 0.59618) avg lploss: 0.00000
*** Best Val Loss: 0.83378 	 Best Test Loss: 0.71635 	 Best epoch 90
Validation loss decreased (0.980823 --> 0.833784).  Saving model ...
train epoch 91 avg loss: 0.69178 (A-MSE: 0.59608) avg lploss: 0.00000
train epoch 92 avg loss: 0.68069 (A-MSE: 0.58705) avg lploss: 0.00000
train epoch 93 avg loss: 0.68253 (A-MSE: 0.58749) avg lploss: 0.00000
train epoch 94 avg loss: 0.67797 (A-MSE: 0.58612) avg lploss: 0.00000
train epoch 95 avg loss: 0.67695 (A-MSE: 0.58309) avg lploss: 0.00000
==> val epoch 95 avg loss: 0.81513 (A-MSE: 0.68496) avg lploss: 0.00000
==> test epoch 95 avg loss: 0.70015 (A-MSE: 0.58587) avg lploss: 0.00000
*** Best Val Loss: 0.81513 	 Best Test Loss: 0.70015 	 Best epoch 95
Validation loss decreased (0.833784 --> 0.815133).  Saving model ...
train epoch 96 avg loss: 0.67797 (A-MSE: 0.58498) avg lploss: 0.00000
train epoch 97 avg loss: 0.69862 (A-MSE: 0.60444) avg lploss: 0.00000
train epoch 98 avg loss: 0.73091 (A-MSE: 0.63262) avg lploss: 0.00000
train epoch 99 avg loss: 0.69630 (A-MSE: 0.59971) avg lploss: 0.00000
train epoch 100 avg loss: 0.67308 (A-MSE: 0.58201) avg lploss: 0.00000
==> val epoch 100 avg loss: 0.85383 (A-MSE: 0.71053) avg lploss: 0.00000
==> test epoch 100 avg loss: 0.73905 (A-MSE: 0.61128) avg lploss: 0.00000
*** Best Val Loss: 0.81513 	 Best Test Loss: 0.70015 	 Best epoch 95
EarlyStopping counter: 1 out of 50
train epoch 101 avg loss: 0.68438 (A-MSE: 0.59444) avg lploss: 0.00000
train epoch 102 avg loss: 0.64383 (A-MSE: 0.55328) avg lploss: 0.00000
train epoch 103 avg loss: 0.66791 (A-MSE: 0.57820) avg lploss: 0.00000
train epoch 104 avg loss: 0.65361 (A-MSE: 0.56451) avg lploss: 0.00000
train epoch 105 avg loss: 0.64702 (A-MSE: 0.55852) avg lploss: 0.00000
==> val epoch 105 avg loss: 0.77848 (A-MSE: 0.66057) avg lploss: 0.00000
==> test epoch 105 avg loss: 0.67685 (A-MSE: 0.57280) avg lploss: 0.00000
*** Best Val Loss: 0.77848 	 Best Test Loss: 0.67685 	 Best epoch 105
Validation loss decreased (0.815133 --> 0.778481).  Saving model ...
train epoch 106 avg loss: 0.61790 (A-MSE: 0.53247) avg lploss: 0.00000
train epoch 107 avg loss: 0.62485 (A-MSE: 0.53982) avg lploss: 0.00000
train epoch 108 avg loss: 0.66391 (A-MSE: 0.57695) avg lploss: 0.00000
train epoch 109 avg loss: 0.62834 (A-MSE: 0.54209) avg lploss: 0.00000
train epoch 110 avg loss: 0.60922 (A-MSE: 0.52561) avg lploss: 0.00000
==> val epoch 110 avg loss: 0.72239 (A-MSE: 0.60597) avg lploss: 0.00000
==> test epoch 110 avg loss: 0.62764 (A-MSE: 0.52450) avg lploss: 0.00000
*** Best Val Loss: 0.72239 	 Best Test Loss: 0.62764 	 Best epoch 110
Validation loss decreased (0.778481 --> 0.722393).  Saving model ...
train epoch 111 avg loss: 0.60025 (A-MSE: 0.51493) avg lploss: 0.00000
train epoch 112 avg loss: 0.62395 (A-MSE: 0.54138) avg lploss: 0.00000
train epoch 113 avg loss: 0.63241 (A-MSE: 0.54869) avg lploss: 0.00000
train epoch 114 avg loss: 0.64169 (A-MSE: 0.55609) avg lploss: 0.00000
train epoch 115 avg loss: 0.67376 (A-MSE: 0.58764) avg lploss: 0.00000
==> val epoch 115 avg loss: 0.80742 (A-MSE: 0.66508) avg lploss: 0.00000
==> test epoch 115 avg loss: 0.70212 (A-MSE: 0.57409) avg lploss: 0.00000
*** Best Val Loss: 0.72239 	 Best Test Loss: 0.62764 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 0.65601 (A-MSE: 0.56557) avg lploss: 0.00000
train epoch 117 avg loss: 0.65354 (A-MSE: 0.56646) avg lploss: 0.00000
train epoch 118 avg loss: 0.59422 (A-MSE: 0.51134) avg lploss: 0.00000
train epoch 119 avg loss: 0.58875 (A-MSE: 0.50783) avg lploss: 0.00000
train epoch 120 avg loss: 0.57716 (A-MSE: 0.49934) avg lploss: 0.00000
==> val epoch 120 avg loss: 0.72625 (A-MSE: 0.61475) avg lploss: 0.00000
==> test epoch 120 avg loss: 0.61440 (A-MSE: 0.51745) avg lploss: 0.00000
*** Best Val Loss: 0.72239 	 Best Test Loss: 0.62764 	 Best epoch 110
EarlyStopping counter: 2 out of 50
train epoch 121 avg loss: 0.59537 (A-MSE: 0.51599) avg lploss: 0.00000
train epoch 122 avg loss: 0.60416 (A-MSE: 0.52163) avg lploss: 0.00000
train epoch 123 avg loss: 0.59366 (A-MSE: 0.51287) avg lploss: 0.00000
train epoch 124 avg loss: 0.62054 (A-MSE: 0.54141) avg lploss: 0.00000
train epoch 125 avg loss: 0.59822 (A-MSE: 0.51462) avg lploss: 0.00000
==> val epoch 125 avg loss: 0.70450 (A-MSE: 0.59220) avg lploss: 0.00000
==> test epoch 125 avg loss: 0.60764 (A-MSE: 0.50894) avg lploss: 0.00000
*** Best Val Loss: 0.70450 	 Best Test Loss: 0.60764 	 Best epoch 125
Validation loss decreased (0.722393 --> 0.704502).  Saving model ...
train epoch 126 avg loss: 0.57165 (A-MSE: 0.49681) avg lploss: 0.00000
train epoch 127 avg loss: 0.55950 (A-MSE: 0.48256) avg lploss: 0.00000
train epoch 128 avg loss: 0.55843 (A-MSE: 0.48336) avg lploss: 0.00000
train epoch 129 avg loss: 0.60989 (A-MSE: 0.52756) avg lploss: 0.00000
train epoch 130 avg loss: 0.60410 (A-MSE: 0.52412) avg lploss: 0.00000
==> val epoch 130 avg loss: 0.70256 (A-MSE: 0.59824) avg lploss: 0.00000
==> test epoch 130 avg loss: 0.59364 (A-MSE: 0.50438) avg lploss: 0.00000
*** Best Val Loss: 0.70256 	 Best Test Loss: 0.59364 	 Best epoch 130
Validation loss decreased (0.704502 --> 0.702565).  Saving model ...
train epoch 131 avg loss: 0.57572 (A-MSE: 0.49882) avg lploss: 0.00000
train epoch 132 avg loss: 0.55246 (A-MSE: 0.47825) avg lploss: 0.00000
train epoch 133 avg loss: 0.54183 (A-MSE: 0.46870) avg lploss: 0.00000
train epoch 134 avg loss: 0.58028 (A-MSE: 0.50220) avg lploss: 0.00000
train epoch 135 avg loss: 0.56362 (A-MSE: 0.49036) avg lploss: 0.00000
==> val epoch 135 avg loss: 0.70264 (A-MSE: 0.60497) avg lploss: 0.00000
==> test epoch 135 avg loss: 0.59817 (A-MSE: 0.51351) avg lploss: 0.00000
*** Best Val Loss: 0.70256 	 Best Test Loss: 0.59364 	 Best epoch 130
EarlyStopping counter: 1 out of 50
train epoch 136 avg loss: 0.54762 (A-MSE: 0.47312) avg lploss: 0.00000
train epoch 137 avg loss: 0.56600 (A-MSE: 0.49038) avg lploss: 0.00000
train epoch 138 avg loss: 0.54922 (A-MSE: 0.47511) avg lploss: 0.00000
train epoch 139 avg loss: 0.54591 (A-MSE: 0.47420) avg lploss: 0.00000
train epoch 140 avg loss: 0.59134 (A-MSE: 0.51410) avg lploss: 0.00000
==> val epoch 140 avg loss: 0.71177 (A-MSE: 0.61115) avg lploss: 0.00000
==> test epoch 140 avg loss: 0.62647 (A-MSE: 0.53807) avg lploss: 0.00000
*** Best Val Loss: 0.70256 	 Best Test Loss: 0.59364 	 Best epoch 130
EarlyStopping counter: 2 out of 50
train epoch 141 avg loss: 0.56049 (A-MSE: 0.48842) avg lploss: 0.00000
train epoch 142 avg loss: 0.55378 (A-MSE: 0.47898) avg lploss: 0.00000
train epoch 143 avg loss: 0.52616 (A-MSE: 0.45315) avg lploss: 0.00000
train epoch 144 avg loss: 0.50978 (A-MSE: 0.44301) avg lploss: 0.00000
train epoch 145 avg loss: 0.52878 (A-MSE: 0.45811) avg lploss: 0.00000
==> val epoch 145 avg loss: 0.61600 (A-MSE: 0.51772) avg lploss: 0.00000
==> test epoch 145 avg loss: 0.52175 (A-MSE: 0.43625) avg lploss: 0.00000
*** Best Val Loss: 0.61600 	 Best Test Loss: 0.52175 	 Best epoch 145
Validation loss decreased (0.702565 --> 0.616001).  Saving model ...
train epoch 146 avg loss: 0.52121 (A-MSE: 0.45215) avg lploss: 0.00000
train epoch 147 avg loss: 0.53931 (A-MSE: 0.46865) avg lploss: 0.00000
train epoch 148 avg loss: 0.51924 (A-MSE: 0.45222) avg lploss: 0.00000
train epoch 149 avg loss: 0.51425 (A-MSE: 0.44532) avg lploss: 0.00000
train epoch 150 avg loss: 0.51598 (A-MSE: 0.44944) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.65263 (A-MSE: 0.55390) avg lploss: 0.00000
==> test epoch 150 avg loss: 0.54689 (A-MSE: 0.46133) avg lploss: 0.00000
*** Best Val Loss: 0.61600 	 Best Test Loss: 0.52175 	 Best epoch 145
EarlyStopping counter: 1 out of 50
train epoch 151 avg loss: 0.52780 (A-MSE: 0.45816) avg lploss: 0.00000
train epoch 152 avg loss: 0.52603 (A-MSE: 0.45903) avg lploss: 0.00000
train epoch 153 avg loss: 0.49587 (A-MSE: 0.42907) avg lploss: 0.00000
train epoch 154 avg loss: 0.56072 (A-MSE: 0.49044) avg lploss: 0.00000
train epoch 155 avg loss: 0.53156 (A-MSE: 0.45954) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.63914 (A-MSE: 0.55250) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.53915 (A-MSE: 0.46562) avg lploss: 0.00000
*** Best Val Loss: 0.61600 	 Best Test Loss: 0.52175 	 Best epoch 145
EarlyStopping counter: 2 out of 50
train epoch 156 avg loss: 0.51513 (A-MSE: 0.44879) avg lploss: 0.00000
train epoch 157 avg loss: 0.50278 (A-MSE: 0.43756) avg lploss: 0.00000
train epoch 158 avg loss: 0.49735 (A-MSE: 0.43250) avg lploss: 0.00000
train epoch 159 avg loss: 0.50591 (A-MSE: 0.43955) avg lploss: 0.00000
train epoch 160 avg loss: 0.48823 (A-MSE: 0.42461) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.59840 (A-MSE: 0.51454) avg lploss: 0.00000
==> test epoch 160 avg loss: 0.52447 (A-MSE: 0.45186) avg lploss: 0.00000
*** Best Val Loss: 0.59840 	 Best Test Loss: 0.52447 	 Best epoch 160
Validation loss decreased (0.616001 --> 0.598403).  Saving model ...
train epoch 161 avg loss: 0.48911 (A-MSE: 0.42653) avg lploss: 0.00000
train epoch 162 avg loss: 0.48242 (A-MSE: 0.41910) avg lploss: 0.00000
train epoch 163 avg loss: 0.46840 (A-MSE: 0.40705) avg lploss: 0.00000
train epoch 164 avg loss: 0.47043 (A-MSE: 0.40955) avg lploss: 0.00000
train epoch 165 avg loss: 0.48187 (A-MSE: 0.41994) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.60277 (A-MSE: 0.50885) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.52827 (A-MSE: 0.44579) avg lploss: 0.00000
*** Best Val Loss: 0.59840 	 Best Test Loss: 0.52447 	 Best epoch 160
EarlyStopping counter: 1 out of 50
train epoch 166 avg loss: 0.48466 (A-MSE: 0.42258) avg lploss: 0.00000
train epoch 167 avg loss: 0.49544 (A-MSE: 0.43068) avg lploss: 0.00000
train epoch 168 avg loss: 0.49898 (A-MSE: 0.43550) avg lploss: 0.00000
train epoch 169 avg loss: 0.46416 (A-MSE: 0.40451) avg lploss: 0.00000
train epoch 170 avg loss: 0.46112 (A-MSE: 0.40277) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.59276 (A-MSE: 0.49947) avg lploss: 0.00000
==> test epoch 170 avg loss: 0.50349 (A-MSE: 0.42206) avg lploss: 0.00000
*** Best Val Loss: 0.59276 	 Best Test Loss: 0.50349 	 Best epoch 170
Validation loss decreased (0.598403 --> 0.592757).  Saving model ...
train epoch 171 avg loss: 0.46579 (A-MSE: 0.40573) avg lploss: 0.00000
train epoch 172 avg loss: 0.46415 (A-MSE: 0.40464) avg lploss: 0.00000
train epoch 173 avg loss: 0.45828 (A-MSE: 0.39842) avg lploss: 0.00000
train epoch 174 avg loss: 0.44385 (A-MSE: 0.38778) avg lploss: 0.00000
train epoch 175 avg loss: 0.48015 (A-MSE: 0.41970) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.58005 (A-MSE: 0.48335) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.49973 (A-MSE: 0.41464) avg lploss: 0.00000
*** Best Val Loss: 0.58005 	 Best Test Loss: 0.49973 	 Best epoch 175
Validation loss decreased (0.592757 --> 0.580047).  Saving model ...
train epoch 176 avg loss: 0.47389 (A-MSE: 0.41448) avg lploss: 0.00000
train epoch 177 avg loss: 0.50131 (A-MSE: 0.43706) avg lploss: 0.00000
train epoch 178 avg loss: 0.47178 (A-MSE: 0.41274) avg lploss: 0.00000
train epoch 179 avg loss: 0.46539 (A-MSE: 0.40525) avg lploss: 0.00000
train epoch 180 avg loss: 0.45294 (A-MSE: 0.39463) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.53424 (A-MSE: 0.45284) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.44686 (A-MSE: 0.37639) avg lploss: 0.00000
*** Best Val Loss: 0.53424 	 Best Test Loss: 0.44686 	 Best epoch 180
Validation loss decreased (0.580047 --> 0.534237).  Saving model ...
train epoch 181 avg loss: 0.42672 (A-MSE: 0.37273) avg lploss: 0.00000
train epoch 182 avg loss: 0.44769 (A-MSE: 0.39071) avg lploss: 0.00000
train epoch 183 avg loss: 0.44916 (A-MSE: 0.39385) avg lploss: 0.00000
train epoch 184 avg loss: 0.45133 (A-MSE: 0.39256) avg lploss: 0.00000
train epoch 185 avg loss: 0.43246 (A-MSE: 0.37835) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.56018 (A-MSE: 0.46907) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.46954 (A-MSE: 0.38984) avg lploss: 0.00000
*** Best Val Loss: 0.53424 	 Best Test Loss: 0.44686 	 Best epoch 180
EarlyStopping counter: 1 out of 50
train epoch 186 avg loss: 0.41895 (A-MSE: 0.36514) avg lploss: 0.00000
train epoch 187 avg loss: 0.45630 (A-MSE: 0.40048) avg lploss: 0.00000
train epoch 188 avg loss: 0.47201 (A-MSE: 0.41415) avg lploss: 0.00000
train epoch 189 avg loss: 0.43617 (A-MSE: 0.38024) avg lploss: 0.00000
train epoch 190 avg loss: 0.43994 (A-MSE: 0.38577) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.56963 (A-MSE: 0.47780) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.47704 (A-MSE: 0.39694) avg lploss: 0.00000
*** Best Val Loss: 0.53424 	 Best Test Loss: 0.44686 	 Best epoch 180
EarlyStopping counter: 2 out of 50
train epoch 191 avg loss: 0.43236 (A-MSE: 0.37910) avg lploss: 0.00000
train epoch 192 avg loss: 0.43014 (A-MSE: 0.37615) avg lploss: 0.00000
train epoch 193 avg loss: 0.46296 (A-MSE: 0.40551) avg lploss: 0.00000
train epoch 194 avg loss: 0.44365 (A-MSE: 0.38812) avg lploss: 0.00000
train epoch 195 avg loss: 0.44268 (A-MSE: 0.38872) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.53161 (A-MSE: 0.44898) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.46500 (A-MSE: 0.39261) avg lploss: 0.00000
*** Best Val Loss: 0.53161 	 Best Test Loss: 0.46500 	 Best epoch 195
Validation loss decreased (0.534237 --> 0.531605).  Saving model ...
train epoch 196 avg loss: 0.43199 (A-MSE: 0.37823) avg lploss: 0.00000
train epoch 197 avg loss: 0.41306 (A-MSE: 0.36287) avg lploss: 0.00000
train epoch 198 avg loss: 0.42105 (A-MSE: 0.36796) avg lploss: 0.00000
train epoch 199 avg loss: 0.41125 (A-MSE: 0.35916) avg lploss: 0.00000
train epoch 200 avg loss: 0.42996 (A-MSE: 0.37936) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.52877 (A-MSE: 0.45470) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.45405 (A-MSE: 0.38964) avg lploss: 0.00000
*** Best Val Loss: 0.52877 	 Best Test Loss: 0.45405 	 Best epoch 200
Validation loss decreased (0.531605 --> 0.528765).  Saving model ...
train epoch 201 avg loss: 0.43607 (A-MSE: 0.38233) avg lploss: 0.00000
train epoch 202 avg loss: 0.43051 (A-MSE: 0.37870) avg lploss: 0.00000
train epoch 203 avg loss: 0.44509 (A-MSE: 0.39154) avg lploss: 0.00000
train epoch 204 avg loss: 0.40568 (A-MSE: 0.35625) avg lploss: 0.00000
train epoch 205 avg loss: 0.41070 (A-MSE: 0.36198) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.57021 (A-MSE: 0.48718) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.47382 (A-MSE: 0.40180) avg lploss: 0.00000
*** Best Val Loss: 0.52877 	 Best Test Loss: 0.45405 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 0.40664 (A-MSE: 0.35710) avg lploss: 0.00000
train epoch 207 avg loss: 0.41507 (A-MSE: 0.36406) avg lploss: 0.00000
train epoch 208 avg loss: 0.39259 (A-MSE: 0.34491) avg lploss: 0.00000
train epoch 209 avg loss: 0.38847 (A-MSE: 0.34132) avg lploss: 0.00000
train epoch 210 avg loss: 0.39470 (A-MSE: 0.34658) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.46078 (A-MSE: 0.39904) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.39216 (A-MSE: 0.33952) avg lploss: 0.00000
*** Best Val Loss: 0.46078 	 Best Test Loss: 0.39216 	 Best epoch 210
Validation loss decreased (0.528765 --> 0.460780).  Saving model ...
train epoch 211 avg loss: 0.39509 (A-MSE: 0.34862) avg lploss: 0.00000
train epoch 212 avg loss: 0.37817 (A-MSE: 0.33285) avg lploss: 0.00000
train epoch 213 avg loss: 0.38079 (A-MSE: 0.33429) avg lploss: 0.00000
train epoch 214 avg loss: 0.37770 (A-MSE: 0.33362) avg lploss: 0.00000
train epoch 215 avg loss: 0.36873 (A-MSE: 0.32459) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.48310 (A-MSE: 0.41582) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.40432 (A-MSE: 0.34820) avg lploss: 0.00000
*** Best Val Loss: 0.46078 	 Best Test Loss: 0.39216 	 Best epoch 210
EarlyStopping counter: 1 out of 50
train epoch 216 avg loss: 0.37777 (A-MSE: 0.33207) avg lploss: 0.00000
train epoch 217 avg loss: 0.40066 (A-MSE: 0.35266) avg lploss: 0.00000
train epoch 218 avg loss: 0.39294 (A-MSE: 0.34801) avg lploss: 0.00000
train epoch 219 avg loss: 0.37759 (A-MSE: 0.33332) avg lploss: 0.00000
train epoch 220 avg loss: 0.35923 (A-MSE: 0.31641) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.43292 (A-MSE: 0.36919) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.36678 (A-MSE: 0.31277) avg lploss: 0.00000
*** Best Val Loss: 0.43292 	 Best Test Loss: 0.36678 	 Best epoch 220
Validation loss decreased (0.460780 --> 0.432916).  Saving model ...
train epoch 221 avg loss: 0.35452 (A-MSE: 0.31266) avg lploss: 0.00000
train epoch 222 avg loss: 0.39133 (A-MSE: 0.34663) avg lploss: 0.00000
train epoch 223 avg loss: 0.36987 (A-MSE: 0.32604) avg lploss: 0.00000
train epoch 224 avg loss: 0.35968 (A-MSE: 0.31841) avg lploss: 0.00000
train epoch 225 avg loss: 0.36824 (A-MSE: 0.32522) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.43965 (A-MSE: 0.38749) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.37501 (A-MSE: 0.33133) avg lploss: 0.00000
*** Best Val Loss: 0.43292 	 Best Test Loss: 0.36678 	 Best epoch 220
EarlyStopping counter: 1 out of 50
train epoch 226 avg loss: 0.37264 (A-MSE: 0.33075) avg lploss: 0.00000
train epoch 227 avg loss: 0.37044 (A-MSE: 0.32759) avg lploss: 0.00000
train epoch 228 avg loss: 0.35131 (A-MSE: 0.30843) avg lploss: 0.00000
train epoch 229 avg loss: 0.35639 (A-MSE: 0.31588) avg lploss: 0.00000
train epoch 230 avg loss: 0.35853 (A-MSE: 0.31770) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.43469 (A-MSE: 0.37837) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.36583 (A-MSE: 0.31839) avg lploss: 0.00000
*** Best Val Loss: 0.43292 	 Best Test Loss: 0.36678 	 Best epoch 220
EarlyStopping counter: 2 out of 50
train epoch 231 avg loss: 0.34705 (A-MSE: 0.30668) avg lploss: 0.00000
train epoch 232 avg loss: 0.34351 (A-MSE: 0.30450) avg lploss: 0.00000
train epoch 233 avg loss: 0.34300 (A-MSE: 0.30363) avg lploss: 0.00000
train epoch 234 avg loss: 0.35680 (A-MSE: 0.31596) avg lploss: 0.00000
train epoch 235 avg loss: 0.32266 (A-MSE: 0.28569) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.42185 (A-MSE: 0.36888) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.35476 (A-MSE: 0.30857) avg lploss: 0.00000
*** Best Val Loss: 0.42185 	 Best Test Loss: 0.35476 	 Best epoch 235
Validation loss decreased (0.432916 --> 0.421846).  Saving model ...
train epoch 236 avg loss: 0.33886 (A-MSE: 0.30005) avg lploss: 0.00000
train epoch 237 avg loss: 0.35459 (A-MSE: 0.31641) avg lploss: 0.00000
train epoch 238 avg loss: 0.34766 (A-MSE: 0.30714) avg lploss: 0.00000
train epoch 239 avg loss: 0.33751 (A-MSE: 0.29899) avg lploss: 0.00000
train epoch 240 avg loss: 0.32418 (A-MSE: 0.28700) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.42653 (A-MSE: 0.37283) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.34778 (A-MSE: 0.30398) avg lploss: 0.00000
*** Best Val Loss: 0.42185 	 Best Test Loss: 0.35476 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.33277 (A-MSE: 0.29693) avg lploss: 0.00000
train epoch 242 avg loss: 0.31232 (A-MSE: 0.27676) avg lploss: 0.00000
train epoch 243 avg loss: 0.33019 (A-MSE: 0.29453) avg lploss: 0.00000
train epoch 244 avg loss: 0.33039 (A-MSE: 0.29286) avg lploss: 0.00000
train epoch 245 avg loss: 0.32512 (A-MSE: 0.28939) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.41711 (A-MSE: 0.36318) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.35548 (A-MSE: 0.30811) avg lploss: 0.00000
*** Best Val Loss: 0.41711 	 Best Test Loss: 0.35548 	 Best epoch 245
Validation loss decreased (0.421846 --> 0.417111).  Saving model ...
train epoch 246 avg loss: 0.30653 (A-MSE: 0.27224) avg lploss: 0.00000
train epoch 247 avg loss: 0.29126 (A-MSE: 0.25934) avg lploss: 0.00000
train epoch 248 avg loss: 0.30211 (A-MSE: 0.26862) avg lploss: 0.00000
train epoch 249 avg loss: 0.30649 (A-MSE: 0.27435) avg lploss: 0.00000
train epoch 250 avg loss: 0.33414 (A-MSE: 0.29705) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.38721 (A-MSE: 0.32948) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.32407 (A-MSE: 0.27456) avg lploss: 0.00000
*** Best Val Loss: 0.38721 	 Best Test Loss: 0.32407 	 Best epoch 250
Validation loss decreased (0.417111 --> 0.387211).  Saving model ...
train epoch 251 avg loss: 0.29694 (A-MSE: 0.26483) avg lploss: 0.00000
train epoch 252 avg loss: 0.33590 (A-MSE: 0.29946) avg lploss: 0.00000
train epoch 253 avg loss: 0.31346 (A-MSE: 0.28012) avg lploss: 0.00000
train epoch 254 avg loss: 0.30044 (A-MSE: 0.26780) avg lploss: 0.00000
train epoch 255 avg loss: 0.28842 (A-MSE: 0.25749) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.39485 (A-MSE: 0.34353) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.33162 (A-MSE: 0.28869) avg lploss: 0.00000
*** Best Val Loss: 0.38721 	 Best Test Loss: 0.32407 	 Best epoch 250
EarlyStopping counter: 1 out of 50
train epoch 256 avg loss: 0.28879 (A-MSE: 0.25672) avg lploss: 0.00000
train epoch 257 avg loss: 0.28866 (A-MSE: 0.25674) avg lploss: 0.00000
train epoch 258 avg loss: 0.28238 (A-MSE: 0.25100) avg lploss: 0.00000
train epoch 259 avg loss: 0.27972 (A-MSE: 0.25083) avg lploss: 0.00000
train epoch 260 avg loss: 0.27608 (A-MSE: 0.24574) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.44572 (A-MSE: 0.38408) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.37264 (A-MSE: 0.32060) avg lploss: 0.00000
*** Best Val Loss: 0.38721 	 Best Test Loss: 0.32407 	 Best epoch 250
EarlyStopping counter: 2 out of 50
train epoch 261 avg loss: 0.31676 (A-MSE: 0.28455) avg lploss: 0.00000
train epoch 262 avg loss: 0.31635 (A-MSE: 0.28274) avg lploss: 0.00000
train epoch 263 avg loss: 0.27595 (A-MSE: 0.24533) avg lploss: 0.00000
train epoch 264 avg loss: 0.29666 (A-MSE: 0.26507) avg lploss: 0.00000
train epoch 265 avg loss: 0.26291 (A-MSE: 0.23429) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.31755 (A-MSE: 0.27658) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.25745 (A-MSE: 0.22450) avg lploss: 0.00000
*** Best Val Loss: 0.31755 	 Best Test Loss: 0.25745 	 Best epoch 265
Validation loss decreased (0.387211 --> 0.317552).  Saving model ...
train epoch 266 avg loss: 0.26421 (A-MSE: 0.23588) avg lploss: 0.00000
train epoch 267 avg loss: 0.25413 (A-MSE: 0.22682) avg lploss: 0.00000
train epoch 268 avg loss: 0.26271 (A-MSE: 0.23547) avg lploss: 0.00000
train epoch 269 avg loss: 0.28346 (A-MSE: 0.25313) avg lploss: 0.00000
train epoch 270 avg loss: 0.26353 (A-MSE: 0.23564) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.33481 (A-MSE: 0.29461) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.27932 (A-MSE: 0.24600) avg lploss: 0.00000
*** Best Val Loss: 0.31755 	 Best Test Loss: 0.25745 	 Best epoch 265
EarlyStopping counter: 1 out of 50
train epoch 271 avg loss: 0.35200 (A-MSE: 0.31573) avg lploss: 0.00000
train epoch 272 avg loss: 0.28870 (A-MSE: 0.25775) avg lploss: 0.00000
train epoch 273 avg loss: 0.26618 (A-MSE: 0.23785) avg lploss: 0.00000
train epoch 274 avg loss: 0.26132 (A-MSE: 0.23445) avg lploss: 0.00000
train epoch 275 avg loss: 0.27904 (A-MSE: 0.24984) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.33942 (A-MSE: 0.29894) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.29350 (A-MSE: 0.26015) avg lploss: 0.00000
*** Best Val Loss: 0.31755 	 Best Test Loss: 0.25745 	 Best epoch 265
EarlyStopping counter: 2 out of 50
train epoch 276 avg loss: 0.28057 (A-MSE: 0.25207) avg lploss: 0.00000
train epoch 277 avg loss: 0.27446 (A-MSE: 0.24431) avg lploss: 0.00000
train epoch 278 avg loss: 0.26782 (A-MSE: 0.23946) avg lploss: 0.00000
train epoch 279 avg loss: 0.27156 (A-MSE: 0.24382) avg lploss: 0.00000
train epoch 280 avg loss: 0.23326 (A-MSE: 0.20857) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.30367 (A-MSE: 0.26979) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.24612 (A-MSE: 0.21977) avg lploss: 0.00000
*** Best Val Loss: 0.30367 	 Best Test Loss: 0.24612 	 Best epoch 280
Validation loss decreased (0.317552 --> 0.303665).  Saving model ...
train epoch 281 avg loss: 0.22525 (A-MSE: 0.20290) avg lploss: 0.00000
train epoch 282 avg loss: 0.23949 (A-MSE: 0.21523) avg lploss: 0.00000
train epoch 283 avg loss: 0.24098 (A-MSE: 0.21705) avg lploss: 0.00000
train epoch 284 avg loss: 0.25060 (A-MSE: 0.22479) avg lploss: 0.00000
train epoch 285 avg loss: 0.24892 (A-MSE: 0.22409) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.34683 (A-MSE: 0.29875) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.28568 (A-MSE: 0.24670) avg lploss: 0.00000
*** Best Val Loss: 0.30367 	 Best Test Loss: 0.24612 	 Best epoch 280
EarlyStopping counter: 1 out of 50
train epoch 286 avg loss: 0.24195 (A-MSE: 0.21670) avg lploss: 0.00000
train epoch 287 avg loss: 0.22661 (A-MSE: 0.20380) avg lploss: 0.00000
train epoch 288 avg loss: 0.22607 (A-MSE: 0.20361) avg lploss: 0.00000
train epoch 289 avg loss: 0.23198 (A-MSE: 0.20836) avg lploss: 0.00000
train epoch 290 avg loss: 0.22950 (A-MSE: 0.20647) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.27310 (A-MSE: 0.23814) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.22673 (A-MSE: 0.19955) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
Validation loss decreased (0.303665 --> 0.273098).  Saving model ...
train epoch 291 avg loss: 0.23945 (A-MSE: 0.21571) avg lploss: 0.00000
train epoch 292 avg loss: 0.22683 (A-MSE: 0.20426) avg lploss: 0.00000
train epoch 293 avg loss: 0.22076 (A-MSE: 0.19797) avg lploss: 0.00000
train epoch 294 avg loss: 0.22276 (A-MSE: 0.20041) avg lploss: 0.00000
train epoch 295 avg loss: 0.26391 (A-MSE: 0.23769) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.35011 (A-MSE: 0.29865) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.29430 (A-MSE: 0.25200) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 0.26659 (A-MSE: 0.23865) avg lploss: 0.00000
train epoch 297 avg loss: 0.22354 (A-MSE: 0.20136) avg lploss: 0.00000
train epoch 298 avg loss: 0.23529 (A-MSE: 0.21152) avg lploss: 0.00000
train epoch 299 avg loss: 0.22429 (A-MSE: 0.20137) avg lploss: 0.00000
train epoch 300 avg loss: 0.22195 (A-MSE: 0.20050) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.30420 (A-MSE: 0.26360) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.24302 (A-MSE: 0.21158) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 0.21286 (A-MSE: 0.19029) avg lploss: 0.00000
train epoch 302 avg loss: 0.20182 (A-MSE: 0.18152) avg lploss: 0.00000
train epoch 303 avg loss: 0.22850 (A-MSE: 0.20552) avg lploss: 0.00000
train epoch 304 avg loss: 0.20168 (A-MSE: 0.18107) avg lploss: 0.00000
train epoch 305 avg loss: 0.23100 (A-MSE: 0.20754) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.27826 (A-MSE: 0.24043) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.22291 (A-MSE: 0.19490) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
EarlyStopping counter: 3 out of 50
train epoch 306 avg loss: 0.21087 (A-MSE: 0.19007) avg lploss: 0.00000
train epoch 307 avg loss: 0.21620 (A-MSE: 0.19454) avg lploss: 0.00000
train epoch 308 avg loss: 0.20854 (A-MSE: 0.18688) avg lploss: 0.00000
train epoch 309 avg loss: 0.22995 (A-MSE: 0.20714) avg lploss: 0.00000
train epoch 310 avg loss: 0.23751 (A-MSE: 0.21300) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.30022 (A-MSE: 0.25941) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.24962 (A-MSE: 0.21751) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
EarlyStopping counter: 4 out of 50
train epoch 311 avg loss: 0.22528 (A-MSE: 0.20326) avg lploss: 0.00000
train epoch 312 avg loss: 0.22441 (A-MSE: 0.20067) avg lploss: 0.00000
train epoch 313 avg loss: 0.24215 (A-MSE: 0.21682) avg lploss: 0.00000
train epoch 314 avg loss: 0.23626 (A-MSE: 0.21131) avg lploss: 0.00000
train epoch 315 avg loss: 0.22041 (A-MSE: 0.19846) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.27451 (A-MSE: 0.23894) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.21905 (A-MSE: 0.19142) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
EarlyStopping counter: 5 out of 50
train epoch 316 avg loss: 0.20969 (A-MSE: 0.18681) avg lploss: 0.00000
train epoch 317 avg loss: 0.20368 (A-MSE: 0.18111) avg lploss: 0.00000
train epoch 318 avg loss: 0.21024 (A-MSE: 0.18871) avg lploss: 0.00000
train epoch 319 avg loss: 0.23336 (A-MSE: 0.20878) avg lploss: 0.00000
train epoch 320 avg loss: 0.19124 (A-MSE: 0.16995) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.29206 (A-MSE: 0.25132) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.24042 (A-MSE: 0.20807) avg lploss: 0.00000
*** Best Val Loss: 0.27310 	 Best Test Loss: 0.22673 	 Best epoch 290
EarlyStopping counter: 6 out of 50
train epoch 321 avg loss: 0.19156 (A-MSE: 0.17085) avg lploss: 0.00000
train epoch 322 avg loss: 0.18023 (A-MSE: 0.16068) avg lploss: 0.00000
train epoch 323 avg loss: 0.18055 (A-MSE: 0.16034) avg lploss: 0.00000
train epoch 324 avg loss: 0.18199 (A-MSE: 0.16204) avg lploss: 0.00000
train epoch 325 avg loss: 0.18781 (A-MSE: 0.16669) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.24656 (A-MSE: 0.21434) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.20336 (A-MSE: 0.17832) avg lploss: 0.00000
*** Best Val Loss: 0.24656 	 Best Test Loss: 0.20336 	 Best epoch 325
Validation loss decreased (0.273098 --> 0.246558).  Saving model ...
train epoch 326 avg loss: 0.18833 (A-MSE: 0.16812) avg lploss: 0.00000
train epoch 327 avg loss: 0.18596 (A-MSE: 0.16514) avg lploss: 0.00000
train epoch 328 avg loss: 0.20502 (A-MSE: 0.18360) avg lploss: 0.00000
train epoch 329 avg loss: 0.18827 (A-MSE: 0.16687) avg lploss: 0.00000
train epoch 330 avg loss: 0.17263 (A-MSE: 0.15381) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.24315 (A-MSE: 0.20838) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.18879 (A-MSE: 0.16196) avg lploss: 0.00000
*** Best Val Loss: 0.24315 	 Best Test Loss: 0.18879 	 Best epoch 330
Validation loss decreased (0.246558 --> 0.243154).  Saving model ...
train epoch 331 avg loss: 0.19862 (A-MSE: 0.17671) avg lploss: 0.00000
train epoch 332 avg loss: 0.19648 (A-MSE: 0.17497) avg lploss: 0.00000
train epoch 333 avg loss: 0.19337 (A-MSE: 0.17169) avg lploss: 0.00000
train epoch 334 avg loss: 0.17802 (A-MSE: 0.15809) avg lploss: 0.00000
train epoch 335 avg loss: 0.18440 (A-MSE: 0.16394) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.24475 (A-MSE: 0.21020) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.20041 (A-MSE: 0.17411) avg lploss: 0.00000
*** Best Val Loss: 0.24315 	 Best Test Loss: 0.18879 	 Best epoch 330
EarlyStopping counter: 1 out of 50
train epoch 336 avg loss: 0.19531 (A-MSE: 0.17395) avg lploss: 0.00000
train epoch 337 avg loss: 0.20370 (A-MSE: 0.18036) avg lploss: 0.00000
train epoch 338 avg loss: 0.18287 (A-MSE: 0.16226) avg lploss: 0.00000
train epoch 339 avg loss: 0.19726 (A-MSE: 0.17552) avg lploss: 0.00000
train epoch 340 avg loss: 0.22267 (A-MSE: 0.19991) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.26761 (A-MSE: 0.23366) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.21867 (A-MSE: 0.19270) avg lploss: 0.00000
*** Best Val Loss: 0.24315 	 Best Test Loss: 0.18879 	 Best epoch 330
EarlyStopping counter: 2 out of 50
train epoch 341 avg loss: 0.19238 (A-MSE: 0.16990) avg lploss: 0.00000
train epoch 342 avg loss: 0.17976 (A-MSE: 0.15906) avg lploss: 0.00000
train epoch 343 avg loss: 0.17256 (A-MSE: 0.15247) avg lploss: 0.00000
train epoch 344 avg loss: 0.17743 (A-MSE: 0.15715) avg lploss: 0.00000
train epoch 345 avg loss: 0.17785 (A-MSE: 0.15766) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.33078 (A-MSE: 0.28196) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.27712 (A-MSE: 0.23659) avg lploss: 0.00000
*** Best Val Loss: 0.24315 	 Best Test Loss: 0.18879 	 Best epoch 330
EarlyStopping counter: 3 out of 50
train epoch 346 avg loss: 0.17914 (A-MSE: 0.15901) avg lploss: 0.00000
train epoch 347 avg loss: 0.17897 (A-MSE: 0.15841) avg lploss: 0.00000
train epoch 348 avg loss: 0.17521 (A-MSE: 0.15461) avg lploss: 0.00000
train epoch 349 avg loss: 0.19126 (A-MSE: 0.16822) avg lploss: 0.00000
train epoch 350 avg loss: 0.18019 (A-MSE: 0.15975) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.23031 (A-MSE: 0.19793) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.17807 (A-MSE: 0.15342) avg lploss: 0.00000
*** Best Val Loss: 0.23031 	 Best Test Loss: 0.17807 	 Best epoch 350
Validation loss decreased (0.243154 --> 0.230309).  Saving model ...
train epoch 351 avg loss: 0.17260 (A-MSE: 0.15150) avg lploss: 0.00000
train epoch 352 avg loss: 0.16511 (A-MSE: 0.14590) avg lploss: 0.00000
train epoch 353 avg loss: 0.16434 (A-MSE: 0.14502) avg lploss: 0.00000
train epoch 354 avg loss: 0.15958 (A-MSE: 0.14035) avg lploss: 0.00000
train epoch 355 avg loss: 0.19343 (A-MSE: 0.17125) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.30714 (A-MSE: 0.26087) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.25298 (A-MSE: 0.21627) avg lploss: 0.00000
*** Best Val Loss: 0.23031 	 Best Test Loss: 0.17807 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.17803 (A-MSE: 0.15699) avg lploss: 0.00000
train epoch 357 avg loss: 0.17003 (A-MSE: 0.15009) avg lploss: 0.00000
train epoch 358 avg loss: 0.18344 (A-MSE: 0.16156) avg lploss: 0.00000
train epoch 359 avg loss: 0.17069 (A-MSE: 0.15171) avg lploss: 0.00000
train epoch 360 avg loss: 0.17301 (A-MSE: 0.15193) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.22657 (A-MSE: 0.19426) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.17909 (A-MSE: 0.15434) avg lploss: 0.00000
*** Best Val Loss: 0.22657 	 Best Test Loss: 0.17909 	 Best epoch 360
Validation loss decreased (0.230309 --> 0.226566).  Saving model ...
train epoch 361 avg loss: 0.17589 (A-MSE: 0.15559) avg lploss: 0.00000
train epoch 362 avg loss: 0.15779 (A-MSE: 0.13896) avg lploss: 0.00000
train epoch 363 avg loss: 0.18788 (A-MSE: 0.16551) avg lploss: 0.00000
train epoch 364 avg loss: 0.17021 (A-MSE: 0.15063) avg lploss: 0.00000
train epoch 365 avg loss: 0.16170 (A-MSE: 0.14227) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.27988 (A-MSE: 0.24049) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.22785 (A-MSE: 0.19693) avg lploss: 0.00000
*** Best Val Loss: 0.22657 	 Best Test Loss: 0.17909 	 Best epoch 360
EarlyStopping counter: 1 out of 50
train epoch 366 avg loss: 0.15107 (A-MSE: 0.13278) avg lploss: 0.00000
train epoch 367 avg loss: 0.16010 (A-MSE: 0.14073) avg lploss: 0.00000
train epoch 368 avg loss: 0.16903 (A-MSE: 0.14988) avg lploss: 0.00000
train epoch 369 avg loss: 0.15559 (A-MSE: 0.13608) avg lploss: 0.00000
train epoch 370 avg loss: 0.15052 (A-MSE: 0.13276) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.25228 (A-MSE: 0.21342) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.20236 (A-MSE: 0.17109) avg lploss: 0.00000
*** Best Val Loss: 0.22657 	 Best Test Loss: 0.17909 	 Best epoch 360
EarlyStopping counter: 2 out of 50
train epoch 371 avg loss: 0.15956 (A-MSE: 0.14090) avg lploss: 0.00000
train epoch 372 avg loss: 0.16308 (A-MSE: 0.14382) avg lploss: 0.00000
train epoch 373 avg loss: 0.16932 (A-MSE: 0.14912) avg lploss: 0.00000
train epoch 374 avg loss: 0.14928 (A-MSE: 0.13097) avg lploss: 0.00000
train epoch 375 avg loss: 0.14520 (A-MSE: 0.12765) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.25439 (A-MSE: 0.21686) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.20429 (A-MSE: 0.17468) avg lploss: 0.00000
*** Best Val Loss: 0.22657 	 Best Test Loss: 0.17909 	 Best epoch 360
EarlyStopping counter: 3 out of 50
train epoch 376 avg loss: 0.15743 (A-MSE: 0.13849) avg lploss: 0.00000
train epoch 377 avg loss: 0.15469 (A-MSE: 0.13634) avg lploss: 0.00000
train epoch 378 avg loss: 0.15492 (A-MSE: 0.13563) avg lploss: 0.00000
train epoch 379 avg loss: 0.14959 (A-MSE: 0.13236) avg lploss: 0.00000
train epoch 380 avg loss: 0.17038 (A-MSE: 0.15002) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.21561 (A-MSE: 0.18544) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.16400 (A-MSE: 0.14119) avg lploss: 0.00000
*** Best Val Loss: 0.21561 	 Best Test Loss: 0.16400 	 Best epoch 380
Validation loss decreased (0.226566 --> 0.215607).  Saving model ...
train epoch 381 avg loss: 0.15475 (A-MSE: 0.13572) avg lploss: 0.00000
train epoch 382 avg loss: 0.15083 (A-MSE: 0.13255) avg lploss: 0.00000
train epoch 383 avg loss: 0.16728 (A-MSE: 0.14752) avg lploss: 0.00000
train epoch 384 avg loss: 0.17215 (A-MSE: 0.15202) avg lploss: 0.00000
train epoch 385 avg loss: 0.15951 (A-MSE: 0.14007) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.26455 (A-MSE: 0.22724) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.21909 (A-MSE: 0.18892) avg lploss: 0.00000
*** Best Val Loss: 0.21561 	 Best Test Loss: 0.16400 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 0.14535 (A-MSE: 0.12791) avg lploss: 0.00000
train epoch 387 avg loss: 0.13974 (A-MSE: 0.12237) avg lploss: 0.00000
train epoch 388 avg loss: 0.14022 (A-MSE: 0.12277) avg lploss: 0.00000
train epoch 389 avg loss: 0.14789 (A-MSE: 0.13036) avg lploss: 0.00000
train epoch 390 avg loss: 0.15738 (A-MSE: 0.13767) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.25107 (A-MSE: 0.21938) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.21866 (A-MSE: 0.19255) avg lploss: 0.00000
*** Best Val Loss: 0.21561 	 Best Test Loss: 0.16400 	 Best epoch 380
EarlyStopping counter: 2 out of 50
train epoch 391 avg loss: 0.18386 (A-MSE: 0.16345) avg lploss: 0.00000
train epoch 392 avg loss: 0.15437 (A-MSE: 0.13587) avg lploss: 0.00000
train epoch 393 avg loss: 0.14320 (A-MSE: 0.12627) avg lploss: 0.00000
train epoch 394 avg loss: 0.14938 (A-MSE: 0.13152) avg lploss: 0.00000
train epoch 395 avg loss: 0.15685 (A-MSE: 0.13700) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.20534 (A-MSE: 0.17702) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.16398 (A-MSE: 0.14132) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
Validation loss decreased (0.215607 --> 0.205343).  Saving model ...
train epoch 396 avg loss: 0.14946 (A-MSE: 0.13077) avg lploss: 0.00000
train epoch 397 avg loss: 0.14903 (A-MSE: 0.13136) avg lploss: 0.00000
train epoch 398 avg loss: 0.13943 (A-MSE: 0.12249) avg lploss: 0.00000
train epoch 399 avg loss: 0.13794 (A-MSE: 0.12106) avg lploss: 0.00000
train epoch 400 avg loss: 0.15599 (A-MSE: 0.13746) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.25209 (A-MSE: 0.21281) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.20815 (A-MSE: 0.17517) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 1 out of 50
train epoch 401 avg loss: 0.15767 (A-MSE: 0.13880) avg lploss: 0.00000
train epoch 402 avg loss: 0.14582 (A-MSE: 0.12805) avg lploss: 0.00000
train epoch 403 avg loss: 0.15796 (A-MSE: 0.13921) avg lploss: 0.00000
train epoch 404 avg loss: 0.14810 (A-MSE: 0.12950) avg lploss: 0.00000
train epoch 405 avg loss: 0.14643 (A-MSE: 0.12911) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.23754 (A-MSE: 0.21462) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.19220 (A-MSE: 0.16789) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 2 out of 50
train epoch 406 avg loss: 0.14795 (A-MSE: 0.12885) avg lploss: 0.00000
train epoch 407 avg loss: 0.15518 (A-MSE: 0.13747) avg lploss: 0.00000
train epoch 408 avg loss: 0.15985 (A-MSE: 0.14041) avg lploss: 0.00000
train epoch 409 avg loss: 0.14262 (A-MSE: 0.12515) avg lploss: 0.00000
train epoch 410 avg loss: 0.14051 (A-MSE: 0.12311) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.28135 (A-MSE: 0.34652) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.22257 (A-MSE: 0.19240) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 3 out of 50
train epoch 411 avg loss: 0.13314 (A-MSE: 0.11624) avg lploss: 0.00000
train epoch 412 avg loss: 0.12738 (A-MSE: 0.11170) avg lploss: 0.00000
train epoch 413 avg loss: 0.13449 (A-MSE: 0.11777) avg lploss: 0.00000
train epoch 414 avg loss: 0.12878 (A-MSE: 0.11341) avg lploss: 0.00000
train epoch 415 avg loss: 0.12751 (A-MSE: 0.11186) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.21892 (A-MSE: 0.26056) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.17109 (A-MSE: 0.14541) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 4 out of 50
train epoch 416 avg loss: 0.12675 (A-MSE: 0.11083) avg lploss: 0.00000
train epoch 417 avg loss: 0.12531 (A-MSE: 0.11052) avg lploss: 0.00000
train epoch 418 avg loss: 0.13528 (A-MSE: 0.11828) avg lploss: 0.00000
train epoch 419 avg loss: 0.12774 (A-MSE: 0.11239) avg lploss: 0.00000
train epoch 420 avg loss: 0.13038 (A-MSE: 0.11457) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.30012 (A-MSE: 0.34930) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.23100 (A-MSE: 0.19851) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 5 out of 50
train epoch 421 avg loss: 0.12995 (A-MSE: 0.11333) avg lploss: 0.00000
train epoch 422 avg loss: 0.14491 (A-MSE: 0.12787) avg lploss: 0.00000
train epoch 423 avg loss: 0.15212 (A-MSE: 0.13405) avg lploss: 0.00000
train epoch 424 avg loss: 0.13165 (A-MSE: 0.11560) avg lploss: 0.00000
train epoch 425 avg loss: 0.14812 (A-MSE: 0.13020) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.76017 (A-MSE: 0.48792) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.15927 (A-MSE: 0.13765) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 6 out of 50
train epoch 426 avg loss: 0.13642 (A-MSE: 0.12012) avg lploss: 0.00000
train epoch 427 avg loss: 0.13188 (A-MSE: 0.11560) avg lploss: 0.00000
train epoch 428 avg loss: 0.13758 (A-MSE: 0.12139) avg lploss: 0.00000
train epoch 429 avg loss: 0.13622 (A-MSE: 0.11879) avg lploss: 0.00000
train epoch 430 avg loss: 0.13714 (A-MSE: 0.12067) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.84318 (A-MSE: 0.52234) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.21753 (A-MSE: 0.19122) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 7 out of 50
train epoch 431 avg loss: 0.13629 (A-MSE: 0.11999) avg lploss: 0.00000
train epoch 432 avg loss: 0.13774 (A-MSE: 0.12114) avg lploss: 0.00000
train epoch 433 avg loss: 0.13654 (A-MSE: 0.12041) avg lploss: 0.00000
train epoch 434 avg loss: 0.13009 (A-MSE: 0.11403) avg lploss: 0.00000
train epoch 435 avg loss: 0.12558 (A-MSE: 0.11009) avg lploss: 0.00000
==> val epoch 435 avg loss: 1.01855 (A-MSE: 0.60996) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.17166 (A-MSE: 0.14422) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 8 out of 50
train epoch 436 avg loss: 0.13425 (A-MSE: 0.11724) avg lploss: 0.00000
train epoch 437 avg loss: 0.13995 (A-MSE: 0.12346) avg lploss: 0.00000
train epoch 438 avg loss: 0.12734 (A-MSE: 0.11158) avg lploss: 0.00000
train epoch 439 avg loss: 0.11833 (A-MSE: 0.10430) avg lploss: 0.00000
train epoch 440 avg loss: 0.12423 (A-MSE: 0.10940) avg lploss: 0.00000
==> val epoch 440 avg loss: 1.28389 (A-MSE: 0.65324) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.18146 (A-MSE: 0.15275) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 9 out of 50
train epoch 441 avg loss: 0.12971 (A-MSE: 0.11335) avg lploss: 0.00000
train epoch 442 avg loss: 0.12699 (A-MSE: 0.11138) avg lploss: 0.00000
train epoch 443 avg loss: 0.13306 (A-MSE: 0.11671) avg lploss: 0.00000
train epoch 444 avg loss: 0.13349 (A-MSE: 0.11688) avg lploss: 0.00000
train epoch 445 avg loss: 0.12940 (A-MSE: 0.11397) avg lploss: 0.00000
==> val epoch 445 avg loss: 1.43302 (A-MSE: 0.65852) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.14648 (A-MSE: 0.12579) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 10 out of 50
train epoch 446 avg loss: 0.13396 (A-MSE: 0.11794) avg lploss: 0.00000
train epoch 447 avg loss: 0.13477 (A-MSE: 0.11858) avg lploss: 0.00000
train epoch 448 avg loss: 0.12350 (A-MSE: 0.10765) avg lploss: 0.00000
train epoch 449 avg loss: 0.13356 (A-MSE: 0.11788) avg lploss: 0.00000
train epoch 450 avg loss: 0.13450 (A-MSE: 0.11811) avg lploss: 0.00000
==> val epoch 450 avg loss: 1.41923 (A-MSE: 0.67795) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.15264 (A-MSE: 0.13096) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 11 out of 50
train epoch 451 avg loss: 0.11891 (A-MSE: 0.10456) avg lploss: 0.00000
train epoch 452 avg loss: 0.12270 (A-MSE: 0.10780) avg lploss: 0.00000
train epoch 453 avg loss: 0.12180 (A-MSE: 0.10685) avg lploss: 0.00000
train epoch 454 avg loss: 0.12270 (A-MSE: 0.10787) avg lploss: 0.00000
train epoch 455 avg loss: 0.12723 (A-MSE: 0.11174) avg lploss: 0.00000
==> val epoch 455 avg loss: 1.42742 (A-MSE: 0.66685) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.15699 (A-MSE: 0.13547) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 12 out of 50
train epoch 456 avg loss: 0.11564 (A-MSE: 0.10107) avg lploss: 0.00000
train epoch 457 avg loss: 0.12194 (A-MSE: 0.10668) avg lploss: 0.00000
train epoch 458 avg loss: 0.12487 (A-MSE: 0.10976) avg lploss: 0.00000
train epoch 459 avg loss: 0.13106 (A-MSE: 0.11529) avg lploss: 0.00000
train epoch 460 avg loss: 0.13431 (A-MSE: 0.11832) avg lploss: 0.00000
==> val epoch 460 avg loss: 1.55852 (A-MSE: 0.71916) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.19358 (A-MSE: 0.16830) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 13 out of 50
train epoch 461 avg loss: 0.13431 (A-MSE: 0.11883) avg lploss: 0.00000
train epoch 462 avg loss: 0.12118 (A-MSE: 0.10569) avg lploss: 0.00000
train epoch 463 avg loss: 0.12764 (A-MSE: 0.11162) avg lploss: 0.00000
train epoch 464 avg loss: 0.11383 (A-MSE: 0.09999) avg lploss: 0.00000
train epoch 465 avg loss: 0.11895 (A-MSE: 0.10441) avg lploss: 0.00000
==> val epoch 465 avg loss: 1.39477 (A-MSE: 0.69147) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.15193 (A-MSE: 0.12949) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 14 out of 50
train epoch 466 avg loss: 0.12074 (A-MSE: 0.10654) avg lploss: 0.00000
train epoch 467 avg loss: 0.12403 (A-MSE: 0.10910) avg lploss: 0.00000
train epoch 468 avg loss: 0.11930 (A-MSE: 0.10471) avg lploss: 0.00000
train epoch 469 avg loss: 0.11490 (A-MSE: 0.10020) avg lploss: 0.00000
train epoch 470 avg loss: 0.13540 (A-MSE: 0.11963) avg lploss: 0.00000
==> val epoch 470 avg loss: 1.53772 (A-MSE: 0.90283) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.18817 (A-MSE: 0.16075) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 15 out of 50
train epoch 471 avg loss: 0.11979 (A-MSE: 0.10505) avg lploss: 0.00000
train epoch 472 avg loss: 0.11954 (A-MSE: 0.10524) avg lploss: 0.00000
train epoch 473 avg loss: 0.11401 (A-MSE: 0.09985) avg lploss: 0.00000
train epoch 474 avg loss: 0.12550 (A-MSE: 0.11027) avg lploss: 0.00000
train epoch 475 avg loss: 0.11881 (A-MSE: 0.10380) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.53902 (A-MSE: 0.99914) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.16453 (A-MSE: 0.14542) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 16 out of 50
train epoch 476 avg loss: 0.11946 (A-MSE: 0.10512) avg lploss: 0.00000
train epoch 477 avg loss: 0.11690 (A-MSE: 0.10318) avg lploss: 0.00000
train epoch 478 avg loss: 0.12039 (A-MSE: 0.10551) avg lploss: 0.00000
train epoch 479 avg loss: 0.11565 (A-MSE: 0.10159) avg lploss: 0.00000
train epoch 480 avg loss: 0.11286 (A-MSE: 0.09861) avg lploss: 0.00000
==> val epoch 480 avg loss: 1.48659 (A-MSE: 0.95338) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.14092 (A-MSE: 0.12260) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 17 out of 50
train epoch 481 avg loss: 0.10470 (A-MSE: 0.09193) avg lploss: 0.00000
train epoch 482 avg loss: 0.11151 (A-MSE: 0.09775) avg lploss: 0.00000
train epoch 483 avg loss: 0.10409 (A-MSE: 0.09143) avg lploss: 0.00000
train epoch 484 avg loss: 0.11031 (A-MSE: 0.09724) avg lploss: 0.00000
train epoch 485 avg loss: 0.10846 (A-MSE: 0.09503) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.55545 (A-MSE: 1.01634) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.16001 (A-MSE: 0.13923) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 18 out of 50
train epoch 486 avg loss: 0.10931 (A-MSE: 0.09522) avg lploss: 0.00000
train epoch 487 avg loss: 0.11156 (A-MSE: 0.09822) avg lploss: 0.00000
train epoch 488 avg loss: 0.11456 (A-MSE: 0.10097) avg lploss: 0.00000
train epoch 489 avg loss: 0.11881 (A-MSE: 0.10485) avg lploss: 0.00000
train epoch 490 avg loss: 0.11440 (A-MSE: 0.10057) avg lploss: 0.00000
==> val epoch 490 avg loss: 1.58416 (A-MSE: 1.02620) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.17554 (A-MSE: 0.14964) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 19 out of 50
train epoch 491 avg loss: 0.10772 (A-MSE: 0.09432) avg lploss: 0.00000
train epoch 492 avg loss: 0.10661 (A-MSE: 0.09346) avg lploss: 0.00000
train epoch 493 avg loss: 0.11490 (A-MSE: 0.10131) avg lploss: 0.00000
train epoch 494 avg loss: 0.11156 (A-MSE: 0.09839) avg lploss: 0.00000
train epoch 495 avg loss: 0.10922 (A-MSE: 0.09575) avg lploss: 0.00000
==> val epoch 495 avg loss: 1.48781 (A-MSE: 1.09031) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.15427 (A-MSE: 0.13145) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 20 out of 50
train epoch 496 avg loss: 0.11703 (A-MSE: 0.10262) avg lploss: 0.00000
train epoch 497 avg loss: 0.11638 (A-MSE: 0.10190) avg lploss: 0.00000
train epoch 498 avg loss: 0.12220 (A-MSE: 0.10794) avg lploss: 0.00000
train epoch 499 avg loss: 0.10912 (A-MSE: 0.09564) avg lploss: 0.00000
train epoch 500 avg loss: 0.11500 (A-MSE: 0.10121) avg lploss: 0.00000
==> val epoch 500 avg loss: 1.45617 (A-MSE: 1.15973) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.15224 (A-MSE: 0.13225) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 21 out of 50
train epoch 501 avg loss: 0.11510 (A-MSE: 0.10096) avg lploss: 0.00000
train epoch 502 avg loss: 0.11622 (A-MSE: 0.10187) avg lploss: 0.00000
train epoch 503 avg loss: 0.11425 (A-MSE: 0.10032) avg lploss: 0.00000
train epoch 504 avg loss: 0.10095 (A-MSE: 0.08793) avg lploss: 0.00000
train epoch 505 avg loss: 0.10791 (A-MSE: 0.09444) avg lploss: 0.00000
==> val epoch 505 avg loss: 1.47200 (A-MSE: 1.20202) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.17506 (A-MSE: 0.14786) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 22 out of 50
train epoch 506 avg loss: 0.10928 (A-MSE: 0.09620) avg lploss: 0.00000
train epoch 507 avg loss: 0.10866 (A-MSE: 0.09557) avg lploss: 0.00000
train epoch 508 avg loss: 0.11521 (A-MSE: 0.10164) avg lploss: 0.00000
train epoch 509 avg loss: 0.11511 (A-MSE: 0.10108) avg lploss: 0.00000
train epoch 510 avg loss: 0.10796 (A-MSE: 0.09411) avg lploss: 0.00000
==> val epoch 510 avg loss: 1.40047 (A-MSE: 1.33498) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.14749 (A-MSE: 0.12819) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 23 out of 50
train epoch 511 avg loss: 0.09765 (A-MSE: 0.08565) avg lploss: 0.00000
train epoch 512 avg loss: 0.12096 (A-MSE: 0.10685) avg lploss: 0.00000
train epoch 513 avg loss: 0.11591 (A-MSE: 0.10194) avg lploss: 0.00000
train epoch 514 avg loss: 0.12468 (A-MSE: 0.11062) avg lploss: 0.00000
train epoch 515 avg loss: 0.10428 (A-MSE: 0.09126) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.39819 (A-MSE: 1.31747) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.14313 (A-MSE: 0.12300) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 24 out of 50
train epoch 516 avg loss: 0.10074 (A-MSE: 0.08836) avg lploss: 0.00000
train epoch 517 avg loss: 0.10908 (A-MSE: 0.09699) avg lploss: 0.00000
train epoch 518 avg loss: 0.10195 (A-MSE: 0.08936) avg lploss: 0.00000
train epoch 519 avg loss: 0.10528 (A-MSE: 0.09257) avg lploss: 0.00000
train epoch 520 avg loss: 0.10225 (A-MSE: 0.08983) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.35385 (A-MSE: 1.53481) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.12851 (A-MSE: 0.10960) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 25 out of 50
train epoch 521 avg loss: 0.09824 (A-MSE: 0.08627) avg lploss: 0.00000
train epoch 522 avg loss: 0.09949 (A-MSE: 0.08703) avg lploss: 0.00000
train epoch 523 avg loss: 0.09820 (A-MSE: 0.08619) avg lploss: 0.00000
train epoch 524 avg loss: 0.09366 (A-MSE: 0.08191) avg lploss: 0.00000
train epoch 525 avg loss: 0.10430 (A-MSE: 0.09164) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.34626 (A-MSE: 1.63516) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.15079 (A-MSE: 0.13048) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 26 out of 50
train epoch 526 avg loss: 0.11447 (A-MSE: 0.10090) avg lploss: 0.00000
train epoch 527 avg loss: 0.12307 (A-MSE: 0.10859) avg lploss: 0.00000
train epoch 528 avg loss: 0.10499 (A-MSE: 0.09251) avg lploss: 0.00000
train epoch 529 avg loss: 0.10204 (A-MSE: 0.08939) avg lploss: 0.00000
train epoch 530 avg loss: 0.10723 (A-MSE: 0.09420) avg lploss: 0.00000
==> val epoch 530 avg loss: 1.34326 (A-MSE: 1.80939) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.13620 (A-MSE: 0.11680) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 27 out of 50
train epoch 531 avg loss: 0.11111 (A-MSE: 0.09788) avg lploss: 0.00000
train epoch 532 avg loss: 0.13399 (A-MSE: 0.11868) avg lploss: 0.00000
train epoch 533 avg loss: 0.13376 (A-MSE: 0.11907) avg lploss: 0.00000
train epoch 534 avg loss: 0.13999 (A-MSE: 0.12335) avg lploss: 0.00000
train epoch 535 avg loss: 0.12425 (A-MSE: 0.10975) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.50829 (A-MSE: 1.93153) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.15300 (A-MSE: 0.13469) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 28 out of 50
train epoch 536 avg loss: 0.11022 (A-MSE: 0.09653) avg lploss: 0.00000
train epoch 537 avg loss: 0.10238 (A-MSE: 0.08979) avg lploss: 0.00000
train epoch 538 avg loss: 0.10050 (A-MSE: 0.08772) avg lploss: 0.00000
train epoch 539 avg loss: 0.09823 (A-MSE: 0.08636) avg lploss: 0.00000
train epoch 540 avg loss: 0.10178 (A-MSE: 0.08914) avg lploss: 0.00000
==> val epoch 540 avg loss: 1.50910 (A-MSE: 1.98569) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.13892 (A-MSE: 0.11929) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 29 out of 50
train epoch 541 avg loss: 0.09622 (A-MSE: 0.08432) avg lploss: 0.00000
train epoch 542 avg loss: 0.10174 (A-MSE: 0.08908) avg lploss: 0.00000
train epoch 543 avg loss: 0.10874 (A-MSE: 0.09540) avg lploss: 0.00000
train epoch 544 avg loss: 0.11400 (A-MSE: 0.10097) avg lploss: 0.00000
train epoch 545 avg loss: 0.11779 (A-MSE: 0.10429) avg lploss: 0.00000
==> val epoch 545 avg loss: 1.87783 (A-MSE: 2.79968) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.16999 (A-MSE: 0.14530) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 30 out of 50
train epoch 546 avg loss: 0.11006 (A-MSE: 0.09594) avg lploss: 0.00000
train epoch 547 avg loss: 0.10507 (A-MSE: 0.09290) avg lploss: 0.00000
train epoch 548 avg loss: 0.09536 (A-MSE: 0.08363) avg lploss: 0.00000
train epoch 549 avg loss: 0.10175 (A-MSE: 0.08956) avg lploss: 0.00000
train epoch 550 avg loss: 0.09956 (A-MSE: 0.08730) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.83423 (A-MSE: 2.86865) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.17657 (A-MSE: 0.15504) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 31 out of 50
train epoch 551 avg loss: 0.09408 (A-MSE: 0.08229) avg lploss: 0.00000
train epoch 552 avg loss: 0.09476 (A-MSE: 0.08300) avg lploss: 0.00000
train epoch 553 avg loss: 0.09445 (A-MSE: 0.08326) avg lploss: 0.00000
train epoch 554 avg loss: 0.09344 (A-MSE: 0.08155) avg lploss: 0.00000
train epoch 555 avg loss: 0.10542 (A-MSE: 0.09327) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.55310 (A-MSE: 2.04072) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.15707 (A-MSE: 0.13734) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 32 out of 50
train epoch 556 avg loss: 0.10326 (A-MSE: 0.09069) avg lploss: 0.00000
train epoch 557 avg loss: 0.11824 (A-MSE: 0.10401) avg lploss: 0.00000
train epoch 558 avg loss: 0.10458 (A-MSE: 0.09153) avg lploss: 0.00000
train epoch 559 avg loss: 0.09636 (A-MSE: 0.08428) avg lploss: 0.00000
train epoch 560 avg loss: 0.10243 (A-MSE: 0.08994) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.60499 (A-MSE: 2.47180) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.12722 (A-MSE: 0.10937) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 33 out of 50
train epoch 561 avg loss: 0.09500 (A-MSE: 0.08374) avg lploss: 0.00000
train epoch 562 avg loss: 0.09681 (A-MSE: 0.08480) avg lploss: 0.00000
train epoch 563 avg loss: 0.09944 (A-MSE: 0.08782) avg lploss: 0.00000
train epoch 564 avg loss: 0.08738 (A-MSE: 0.07633) avg lploss: 0.00000
train epoch 565 avg loss: 0.08891 (A-MSE: 0.07735) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.57745 (A-MSE: 2.53993) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.13487 (A-MSE: 0.11884) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 34 out of 50
train epoch 566 avg loss: 0.09584 (A-MSE: 0.08418) avg lploss: 0.00000
train epoch 567 avg loss: 0.09075 (A-MSE: 0.07960) avg lploss: 0.00000
train epoch 568 avg loss: 0.09166 (A-MSE: 0.08047) avg lploss: 0.00000
train epoch 569 avg loss: 0.10437 (A-MSE: 0.09215) avg lploss: 0.00000
train epoch 570 avg loss: 0.09440 (A-MSE: 0.08283) avg lploss: 0.00000
==> val epoch 570 avg loss: 2.33773 (A-MSE: 3.34067) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.13770 (A-MSE: 0.11765) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 35 out of 50
train epoch 571 avg loss: 0.08964 (A-MSE: 0.07857) avg lploss: 0.00000
train epoch 572 avg loss: 0.08993 (A-MSE: 0.07856) avg lploss: 0.00000
train epoch 573 avg loss: 0.09554 (A-MSE: 0.08416) avg lploss: 0.00000
train epoch 574 avg loss: 0.09221 (A-MSE: 0.08148) avg lploss: 0.00000
train epoch 575 avg loss: 0.09170 (A-MSE: 0.07999) avg lploss: 0.00000
==> val epoch 575 avg loss: 2.40619 (A-MSE: 3.43182) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.14556 (A-MSE: 0.12694) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 36 out of 50
train epoch 576 avg loss: 0.10026 (A-MSE: 0.08852) avg lploss: 0.00000
train epoch 577 avg loss: 0.10570 (A-MSE: 0.09325) avg lploss: 0.00000
train epoch 578 avg loss: 0.09308 (A-MSE: 0.08197) avg lploss: 0.00000
train epoch 579 avg loss: 0.09009 (A-MSE: 0.07922) avg lploss: 0.00000
train epoch 580 avg loss: 0.08627 (A-MSE: 0.07539) avg lploss: 0.00000
==> val epoch 580 avg loss: 2.81199 (A-MSE: 3.76240) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.13540 (A-MSE: 0.11708) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 37 out of 50
train epoch 581 avg loss: 0.10008 (A-MSE: 0.08838) avg lploss: 0.00000
train epoch 582 avg loss: 0.09267 (A-MSE: 0.08079) avg lploss: 0.00000
train epoch 583 avg loss: 0.10023 (A-MSE: 0.08860) avg lploss: 0.00000
train epoch 584 avg loss: 0.09288 (A-MSE: 0.08150) avg lploss: 0.00000
train epoch 585 avg loss: 0.09822 (A-MSE: 0.08665) avg lploss: 0.00000
==> val epoch 585 avg loss: 2.76550 (A-MSE: 3.65312) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.13330 (A-MSE: 0.11563) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 38 out of 50
train epoch 586 avg loss: 0.09241 (A-MSE: 0.08119) avg lploss: 0.00000
train epoch 587 avg loss: 0.09302 (A-MSE: 0.08161) avg lploss: 0.00000
train epoch 588 avg loss: 0.09787 (A-MSE: 0.08578) avg lploss: 0.00000
train epoch 589 avg loss: 0.10618 (A-MSE: 0.09376) avg lploss: 0.00000
train epoch 590 avg loss: 0.09317 (A-MSE: 0.08130) avg lploss: 0.00000
==> val epoch 590 avg loss: 3.47109 (A-MSE: 4.32997) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.12195 (A-MSE: 0.10613) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 39 out of 50
train epoch 591 avg loss: 0.09335 (A-MSE: 0.08197) avg lploss: 0.00000
train epoch 592 avg loss: 0.09362 (A-MSE: 0.08224) avg lploss: 0.00000
train epoch 593 avg loss: 0.10035 (A-MSE: 0.08810) avg lploss: 0.00000
train epoch 594 avg loss: 0.10123 (A-MSE: 0.08914) avg lploss: 0.00000
train epoch 595 avg loss: 0.10269 (A-MSE: 0.09056) avg lploss: 0.00000
==> val epoch 595 avg loss: 3.76540 (A-MSE: 4.72850) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.13839 (A-MSE: 0.12049) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 40 out of 50
train epoch 596 avg loss: 0.09876 (A-MSE: 0.08656) avg lploss: 0.00000
train epoch 597 avg loss: 0.10461 (A-MSE: 0.09215) avg lploss: 0.00000
train epoch 598 avg loss: 0.10684 (A-MSE: 0.09329) avg lploss: 0.00000
train epoch 599 avg loss: 0.08936 (A-MSE: 0.07794) avg lploss: 0.00000
train epoch 600 avg loss: 0.08852 (A-MSE: 0.07783) avg lploss: 0.00000
==> val epoch 600 avg loss: 4.59165 (A-MSE: 5.26529) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.11431 (A-MSE: 0.09958) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 41 out of 50
train epoch 601 avg loss: 0.08728 (A-MSE: 0.07627) avg lploss: 0.00000
train epoch 602 avg loss: 0.08455 (A-MSE: 0.07430) avg lploss: 0.00000
train epoch 603 avg loss: 0.09142 (A-MSE: 0.08028) avg lploss: 0.00000
train epoch 604 avg loss: 0.09890 (A-MSE: 0.08789) avg lploss: 0.00000
train epoch 605 avg loss: 0.08774 (A-MSE: 0.07670) avg lploss: 0.00000
==> val epoch 605 avg loss: 4.06347 (A-MSE: 4.92746) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.13180 (A-MSE: 0.11153) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 42 out of 50
train epoch 606 avg loss: 0.09164 (A-MSE: 0.08030) avg lploss: 0.00000
train epoch 607 avg loss: 0.10255 (A-MSE: 0.09051) avg lploss: 0.00000
train epoch 608 avg loss: 0.09560 (A-MSE: 0.08362) avg lploss: 0.00000
train epoch 609 avg loss: 0.08972 (A-MSE: 0.07856) avg lploss: 0.00000
train epoch 610 avg loss: 0.08498 (A-MSE: 0.07437) avg lploss: 0.00000
==> val epoch 610 avg loss: 3.60036 (A-MSE: 4.78501) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.13218 (A-MSE: 0.11689) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 43 out of 50
train epoch 611 avg loss: 0.09459 (A-MSE: 0.08306) avg lploss: 0.00000
train epoch 612 avg loss: 0.08794 (A-MSE: 0.07716) avg lploss: 0.00000
train epoch 613 avg loss: 0.08476 (A-MSE: 0.07461) avg lploss: 0.00000
train epoch 614 avg loss: 0.08526 (A-MSE: 0.07513) avg lploss: 0.00000
train epoch 615 avg loss: 0.09152 (A-MSE: 0.08064) avg lploss: 0.00000
==> val epoch 615 avg loss: 4.50343 (A-MSE: 5.52075) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.17364 (A-MSE: 0.15176) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 44 out of 50
train epoch 616 avg loss: 0.09807 (A-MSE: 0.08617) avg lploss: 0.00000
train epoch 617 avg loss: 0.08827 (A-MSE: 0.07821) avg lploss: 0.00000
train epoch 618 avg loss: 0.09271 (A-MSE: 0.08145) avg lploss: 0.00000
train epoch 619 avg loss: 0.08930 (A-MSE: 0.07814) avg lploss: 0.00000
train epoch 620 avg loss: 0.08534 (A-MSE: 0.07464) avg lploss: 0.00000
==> val epoch 620 avg loss: 5.05085 (A-MSE: 5.84429) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.12465 (A-MSE: 0.10630) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 45 out of 50
train epoch 621 avg loss: 0.09176 (A-MSE: 0.08083) avg lploss: 0.00000
train epoch 622 avg loss: 0.09303 (A-MSE: 0.08209) avg lploss: 0.00000
train epoch 623 avg loss: 0.08633 (A-MSE: 0.07587) avg lploss: 0.00000
train epoch 624 avg loss: 0.08330 (A-MSE: 0.07290) avg lploss: 0.00000
train epoch 625 avg loss: 0.08973 (A-MSE: 0.07911) avg lploss: 0.00000
==> val epoch 625 avg loss: 6.37355 (A-MSE: 6.97944) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.12687 (A-MSE: 0.11027) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 46 out of 50
train epoch 626 avg loss: 0.08737 (A-MSE: 0.07715) avg lploss: 0.00000
train epoch 627 avg loss: 0.08606 (A-MSE: 0.07554) avg lploss: 0.00000
train epoch 628 avg loss: 0.08322 (A-MSE: 0.07250) avg lploss: 0.00000
train epoch 629 avg loss: 0.08514 (A-MSE: 0.07465) avg lploss: 0.00000
train epoch 630 avg loss: 0.09683 (A-MSE: 0.08573) avg lploss: 0.00000
==> val epoch 630 avg loss: 9.69110 (A-MSE: 9.13355) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.14757 (A-MSE: 0.12872) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 47 out of 50
train epoch 631 avg loss: 0.10213 (A-MSE: 0.08971) avg lploss: 0.00000
train epoch 632 avg loss: 0.08781 (A-MSE: 0.07733) avg lploss: 0.00000
train epoch 633 avg loss: 0.08763 (A-MSE: 0.07678) avg lploss: 0.00000
train epoch 634 avg loss: 0.09011 (A-MSE: 0.07908) avg lploss: 0.00000
train epoch 635 avg loss: 0.09009 (A-MSE: 0.07948) avg lploss: 0.00000
==> val epoch 635 avg loss: 7.20217 (A-MSE: 7.62860) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.14436 (A-MSE: 0.12729) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 48 out of 50
train epoch 636 avg loss: 0.08892 (A-MSE: 0.07809) avg lploss: 0.00000
train epoch 637 avg loss: 0.11061 (A-MSE: 0.09735) avg lploss: 0.00000
train epoch 638 avg loss: 0.11140 (A-MSE: 0.09928) avg lploss: 0.00000
train epoch 639 avg loss: 0.09408 (A-MSE: 0.08306) avg lploss: 0.00000
train epoch 640 avg loss: 0.08030 (A-MSE: 0.06991) avg lploss: 0.00000
==> val epoch 640 avg loss: 11.14266 (A-MSE: 10.06412) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.11609 (A-MSE: 0.10174) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 49 out of 50
train epoch 641 avg loss: 0.08988 (A-MSE: 0.07888) avg lploss: 0.00000
train epoch 642 avg loss: 0.08094 (A-MSE: 0.07082) avg lploss: 0.00000
train epoch 643 avg loss: 0.08181 (A-MSE: 0.07167) avg lploss: 0.00000
train epoch 644 avg loss: 0.08653 (A-MSE: 0.07649) avg lploss: 0.00000
train epoch 645 avg loss: 0.08744 (A-MSE: 0.07662) avg lploss: 0.00000
==> val epoch 645 avg loss: 12.02248 (A-MSE: 10.73057) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.11296 (A-MSE: 0.09829) avg lploss: 0.00000
*** Best Val Loss: 0.20534 	 Best Test Loss: 0.16398 	 Best epoch 395
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train_f_mse = 0.156850
best_lp = 0.000000
best_val_f_mse = 0.205343
best_test_f_mse = 0.163983
best_test_a_mse = 0.141318
best_epoch = 395
best_train_f_mse = 0.156850, best_lp = 0.000000, best_val_f_mse = 0.205343, best_test_f_mse = 0.163983, best_test_a_mse = 0.141318, best_epoch = 395
Job completed at Mon Dec  8 23:19:42 CET 2025
