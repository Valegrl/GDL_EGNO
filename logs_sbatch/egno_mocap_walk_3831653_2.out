Date              = Mon Dec  8 23:11:24 CET 2025
Hostname          = mel2154
Array Task ID     = 2
Running config: configs/mocap_walk_seed3.json
Namespace(batch_size=12, case='walk', config_by_file='configs/mocap_walk_seed3.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_walk_seed3', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=3, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 198 samples!
Got Split!
Got 600 samples!
Got Split!
Got 600 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_walk_seed3/saved_model.pth
train epoch 0 avg loss: 13.95817 (A-MSE: 12.47357) avg lploss: 0.00000
==> val epoch 0 avg loss: 12.96649 (A-MSE: 11.43375) avg lploss: 0.00000
==> test epoch 0 avg loss: 12.99583 (A-MSE: 11.46942) avg lploss: 0.00000
*** Best Val Loss: 12.96649 	 Best Test Loss: 12.99583 	 Best epoch 0
Validation loss decreased (inf --> 12.966490).  Saving model ...
train epoch 1 avg loss: 11.26886 (A-MSE: 9.92465) avg lploss: 0.00000
train epoch 2 avg loss: 9.33863 (A-MSE: 8.13164) avg lploss: 0.00000
train epoch 3 avg loss: 436.88356 (A-MSE: 769.09600) avg lploss: 0.00000
train epoch 4 avg loss: 8.35378 (A-MSE: 7.26158) avg lploss: 0.00000
train epoch 5 avg loss: 8.28754 (A-MSE: 7.22035) avg lploss: 0.00000
==> val epoch 5 avg loss: 8.58677 (A-MSE: 7.46601) avg lploss: 0.00000
==> test epoch 5 avg loss: 8.55754 (A-MSE: 7.44670) avg lploss: 0.00000
*** Best Val Loss: 8.58677 	 Best Test Loss: 8.55754 	 Best epoch 5
Validation loss decreased (12.966490 --> 8.586767).  Saving model ...
train epoch 6 avg loss: 8.08311 (A-MSE: 7.04430) avg lploss: 0.00000
train epoch 7 avg loss: 7.83509 (A-MSE: 6.81294) avg lploss: 0.00000
train epoch 8 avg loss: 7.51255 (A-MSE: 6.51622) avg lploss: 0.00000
train epoch 9 avg loss: 6.90232 (A-MSE: 5.96621) avg lploss: 0.00000
train epoch 10 avg loss: 6.37880 (A-MSE: 5.51077) avg lploss: 0.00000
==> val epoch 10 avg loss: 7.01158 (A-MSE: 6.00888) avg lploss: 0.00000
==> test epoch 10 avg loss: 6.88409 (A-MSE: 5.90335) avg lploss: 0.00000
*** Best Val Loss: 7.01158 	 Best Test Loss: 6.88409 	 Best epoch 10
Validation loss decreased (8.586767 --> 7.011576).  Saving model ...
train epoch 11 avg loss: 5.93211 (A-MSE: 5.10919) avg lploss: 0.00000
train epoch 12 avg loss: 5.20583 (A-MSE: 4.47997) avg lploss: 0.00000
train epoch 13 avg loss: 4.46991 (A-MSE: 3.84121) avg lploss: 0.00000
train epoch 14 avg loss: 3.84063 (A-MSE: 3.29583) avg lploss: 0.00000
train epoch 15 avg loss: 3.52722 (A-MSE: 3.02910) avg lploss: 0.00000
==> val epoch 15 avg loss: 3.59029 (A-MSE: 3.02927) avg lploss: 0.00000
==> test epoch 15 avg loss: 3.45533 (A-MSE: 2.90695) avg lploss: 0.00000
*** Best Val Loss: 3.59029 	 Best Test Loss: 3.45533 	 Best epoch 15
Validation loss decreased (7.011576 --> 3.590290).  Saving model ...
train epoch 16 avg loss: 3.06488 (A-MSE: 2.62197) avg lploss: 0.00000
train epoch 17 avg loss: 2.75507 (A-MSE: 2.35698) avg lploss: 0.00000
train epoch 18 avg loss: 2.65092 (A-MSE: 2.26535) avg lploss: 0.00000
train epoch 19 avg loss: 2.57554 (A-MSE: 2.20079) avg lploss: 0.00000
train epoch 20 avg loss: 2.39645 (A-MSE: 2.04757) avg lploss: 0.00000
==> val epoch 20 avg loss: 2.71377 (A-MSE: 2.25155) avg lploss: 0.00000
==> test epoch 20 avg loss: 2.57563 (A-MSE: 2.12586) avg lploss: 0.00000
*** Best Val Loss: 2.71377 	 Best Test Loss: 2.57563 	 Best epoch 20
Validation loss decreased (3.590290 --> 2.713775).  Saving model ...
train epoch 21 avg loss: 2.36289 (A-MSE: 2.01112) avg lploss: 0.00000
train epoch 22 avg loss: 2.33210 (A-MSE: 1.99939) avg lploss: 0.00000
train epoch 23 avg loss: 2.23055 (A-MSE: 1.90212) avg lploss: 0.00000
train epoch 24 avg loss: 2.13104 (A-MSE: 1.82706) avg lploss: 0.00000
train epoch 25 avg loss: 2.32474 (A-MSE: 2.00042) avg lploss: 0.00000
==> val epoch 25 avg loss: 3.49612 (A-MSE: 2.92769) avg lploss: 0.00000
==> test epoch 25 avg loss: 3.45996 (A-MSE: 2.89796) avg lploss: 0.00000
*** Best Val Loss: 2.71377 	 Best Test Loss: 2.57563 	 Best epoch 20
EarlyStopping counter: 1 out of 50
train epoch 26 avg loss: 2.47394 (A-MSE: 2.11882) avg lploss: 0.00000
train epoch 27 avg loss: 2.11250 (A-MSE: 1.79951) avg lploss: 0.00000
train epoch 28 avg loss: 2.00244 (A-MSE: 1.71739) avg lploss: 0.00000
train epoch 29 avg loss: 1.96943 (A-MSE: 1.68442) avg lploss: 0.00000
train epoch 30 avg loss: 1.97229 (A-MSE: 1.68790) avg lploss: 0.00000
==> val epoch 30 avg loss: 2.22995 (A-MSE: 1.85267) avg lploss: 0.00000
==> test epoch 30 avg loss: 2.11700 (A-MSE: 1.75318) avg lploss: 0.00000
*** Best Val Loss: 2.22995 	 Best Test Loss: 2.11700 	 Best epoch 30
Validation loss decreased (2.713775 --> 2.229953).  Saving model ...
train epoch 31 avg loss: 1.93119 (A-MSE: 1.65115) avg lploss: 0.00000
train epoch 32 avg loss: 1.96015 (A-MSE: 1.68016) avg lploss: 0.00000
train epoch 33 avg loss: 1.86497 (A-MSE: 1.59959) avg lploss: 0.00000
train epoch 34 avg loss: 1.83161 (A-MSE: 1.56000) avg lploss: 0.00000
train epoch 35 avg loss: 1.80265 (A-MSE: 1.54509) avg lploss: 0.00000
==> val epoch 35 avg loss: 1.96819 (A-MSE: 1.65858) avg lploss: 0.00000
==> test epoch 35 avg loss: 1.83032 (A-MSE: 1.53530) avg lploss: 0.00000
*** Best Val Loss: 1.96819 	 Best Test Loss: 1.83032 	 Best epoch 35
Validation loss decreased (2.229953 --> 1.968185).  Saving model ...
train epoch 36 avg loss: 1.76908 (A-MSE: 1.50970) avg lploss: 0.00000
train epoch 37 avg loss: 1.75999 (A-MSE: 1.50978) avg lploss: 0.00000
train epoch 38 avg loss: 1.73172 (A-MSE: 1.47926) avg lploss: 0.00000
train epoch 39 avg loss: 1.64314 (A-MSE: 1.40597) avg lploss: 0.00000
train epoch 40 avg loss: 1.66712 (A-MSE: 1.42057) avg lploss: 0.00000
==> val epoch 40 avg loss: 1.96691 (A-MSE: 1.63797) avg lploss: 0.00000
==> test epoch 40 avg loss: 1.85292 (A-MSE: 1.53837) avg lploss: 0.00000
*** Best Val Loss: 1.96691 	 Best Test Loss: 1.85292 	 Best epoch 40
Validation loss decreased (1.968185 --> 1.966912).  Saving model ...
train epoch 41 avg loss: 1.65314 (A-MSE: 1.40743) avg lploss: 0.00000
train epoch 42 avg loss: 1.51901 (A-MSE: 1.29446) avg lploss: 0.00000
train epoch 43 avg loss: 1.50747 (A-MSE: 1.28555) avg lploss: 0.00000
train epoch 44 avg loss: 1.52212 (A-MSE: 1.29609) avg lploss: 0.00000
train epoch 45 avg loss: 1.45052 (A-MSE: 1.24063) avg lploss: 0.00000
==> val epoch 45 avg loss: 1.68333 (A-MSE: 1.42047) avg lploss: 0.00000
==> test epoch 45 avg loss: 1.53968 (A-MSE: 1.29169) avg lploss: 0.00000
*** Best Val Loss: 1.68333 	 Best Test Loss: 1.53968 	 Best epoch 45
Validation loss decreased (1.966912 --> 1.683330).  Saving model ...
train epoch 46 avg loss: 1.41141 (A-MSE: 1.19824) avg lploss: 0.00000
train epoch 47 avg loss: 1.40420 (A-MSE: 1.19781) avg lploss: 0.00000
train epoch 48 avg loss: 1.40609 (A-MSE: 1.19942) avg lploss: 0.00000
train epoch 49 avg loss: 1.43659 (A-MSE: 1.22533) avg lploss: 0.00000
train epoch 50 avg loss: 1.34829 (A-MSE: 1.14972) avg lploss: 0.00000
==> val epoch 50 avg loss: 1.49149 (A-MSE: 1.24763) avg lploss: 0.00000
==> test epoch 50 avg loss: 1.36132 (A-MSE: 1.13341) avg lploss: 0.00000
*** Best Val Loss: 1.49149 	 Best Test Loss: 1.36132 	 Best epoch 50
Validation loss decreased (1.683330 --> 1.491493).  Saving model ...
train epoch 51 avg loss: 1.29044 (A-MSE: 1.09888) avg lploss: 0.00000
train epoch 52 avg loss: 1.33521 (A-MSE: 1.13293) avg lploss: 0.00000
train epoch 53 avg loss: 1.28297 (A-MSE: 1.09821) avg lploss: 0.00000
train epoch 54 avg loss: 1.21525 (A-MSE: 1.03815) avg lploss: 0.00000
train epoch 55 avg loss: 1.17114 (A-MSE: 0.99840) avg lploss: 0.00000
==> val epoch 55 avg loss: 1.35413 (A-MSE: 1.14120) avg lploss: 0.00000
==> test epoch 55 avg loss: 1.25749 (A-MSE: 1.05842) avg lploss: 0.00000
*** Best Val Loss: 1.35413 	 Best Test Loss: 1.25749 	 Best epoch 55
Validation loss decreased (1.491493 --> 1.354125).  Saving model ...
train epoch 56 avg loss: 1.27814 (A-MSE: 1.09007) avg lploss: 0.00000
train epoch 57 avg loss: 1.16496 (A-MSE: 0.99834) avg lploss: 0.00000
train epoch 58 avg loss: 1.16188 (A-MSE: 0.99231) avg lploss: 0.00000
train epoch 59 avg loss: 1.08331 (A-MSE: 0.92584) avg lploss: 0.00000
train epoch 60 avg loss: 1.07806 (A-MSE: 0.92325) avg lploss: 0.00000
==> val epoch 60 avg loss: 1.19672 (A-MSE: 1.01769) avg lploss: 0.00000
==> test epoch 60 avg loss: 1.08485 (A-MSE: 0.92015) avg lploss: 0.00000
*** Best Val Loss: 1.19672 	 Best Test Loss: 1.08485 	 Best epoch 60
Validation loss decreased (1.354125 --> 1.196717).  Saving model ...
train epoch 61 avg loss: 1.01039 (A-MSE: 0.86953) avg lploss: 0.00000
train epoch 62 avg loss: 1.04736 (A-MSE: 0.89852) avg lploss: 0.00000
train epoch 63 avg loss: 0.99080 (A-MSE: 0.84519) avg lploss: 0.00000
train epoch 64 avg loss: 1.00390 (A-MSE: 0.86300) avg lploss: 0.00000
train epoch 65 avg loss: 1.16596 (A-MSE: 1.00251) avg lploss: 0.00000
==> val epoch 65 avg loss: 1.26041 (A-MSE: 1.05766) avg lploss: 0.00000
==> test epoch 65 avg loss: 1.15736 (A-MSE: 0.96704) avg lploss: 0.00000
*** Best Val Loss: 1.19672 	 Best Test Loss: 1.08485 	 Best epoch 60
EarlyStopping counter: 1 out of 50
train epoch 66 avg loss: 1.00074 (A-MSE: 0.85858) avg lploss: 0.00000
train epoch 67 avg loss: 0.95085 (A-MSE: 0.81656) avg lploss: 0.00000
train epoch 68 avg loss: 0.88723 (A-MSE: 0.75950) avg lploss: 0.00000
train epoch 69 avg loss: 0.93428 (A-MSE: 0.80403) avg lploss: 0.00000
train epoch 70 avg loss: 0.88817 (A-MSE: 0.75878) avg lploss: 0.00000
==> val epoch 70 avg loss: 0.98311 (A-MSE: 0.83342) avg lploss: 0.00000
==> test epoch 70 avg loss: 0.91411 (A-MSE: 0.77573) avg lploss: 0.00000
*** Best Val Loss: 0.98311 	 Best Test Loss: 0.91411 	 Best epoch 70
Validation loss decreased (1.196717 --> 0.983114).  Saving model ...
train epoch 71 avg loss: 0.93448 (A-MSE: 0.80423) avg lploss: 0.00000
train epoch 72 avg loss: 0.86237 (A-MSE: 0.73893) avg lploss: 0.00000
train epoch 73 avg loss: 0.84505 (A-MSE: 0.72786) avg lploss: 0.00000
train epoch 74 avg loss: 0.85112 (A-MSE: 0.73021) avg lploss: 0.00000
train epoch 75 avg loss: 0.77736 (A-MSE: 0.66572) avg lploss: 0.00000
==> val epoch 75 avg loss: 0.91666 (A-MSE: 0.77243) avg lploss: 0.00000
==> test epoch 75 avg loss: 0.81363 (A-MSE: 0.68124) avg lploss: 0.00000
*** Best Val Loss: 0.91666 	 Best Test Loss: 0.81363 	 Best epoch 75
Validation loss decreased (0.983114 --> 0.916661).  Saving model ...
train epoch 76 avg loss: 0.81310 (A-MSE: 0.69774) avg lploss: 0.00000
train epoch 77 avg loss: 0.78894 (A-MSE: 0.67960) avg lploss: 0.00000
train epoch 78 avg loss: 0.75429 (A-MSE: 0.64737) avg lploss: 0.00000
train epoch 79 avg loss: 0.76617 (A-MSE: 0.66375) avg lploss: 0.00000
train epoch 80 avg loss: 0.75359 (A-MSE: 0.64600) avg lploss: 0.00000
==> val epoch 80 avg loss: 0.93126 (A-MSE: 0.79979) avg lploss: 0.00000
==> test epoch 80 avg loss: 0.83891 (A-MSE: 0.71841) avg lploss: 0.00000
*** Best Val Loss: 0.91666 	 Best Test Loss: 0.81363 	 Best epoch 75
EarlyStopping counter: 1 out of 50
train epoch 81 avg loss: 0.77345 (A-MSE: 0.66586) avg lploss: 0.00000
train epoch 82 avg loss: 0.75508 (A-MSE: 0.64964) avg lploss: 0.00000
train epoch 83 avg loss: 0.79572 (A-MSE: 0.68752) avg lploss: 0.00000
train epoch 84 avg loss: 0.76107 (A-MSE: 0.65462) avg lploss: 0.00000
train epoch 85 avg loss: 0.74237 (A-MSE: 0.64223) avg lploss: 0.00000
==> val epoch 85 avg loss: 0.84729 (A-MSE: 0.71944) avg lploss: 0.00000
==> test epoch 85 avg loss: 0.76322 (A-MSE: 0.64704) avg lploss: 0.00000
*** Best Val Loss: 0.84729 	 Best Test Loss: 0.76322 	 Best epoch 85
Validation loss decreased (0.916661 --> 0.847287).  Saving model ...
train epoch 86 avg loss: 0.70644 (A-MSE: 0.61138) avg lploss: 0.00000
train epoch 87 avg loss: 0.70163 (A-MSE: 0.60496) avg lploss: 0.00000
train epoch 88 avg loss: 0.68056 (A-MSE: 0.58416) avg lploss: 0.00000
train epoch 89 avg loss: 0.69921 (A-MSE: 0.60469) avg lploss: 0.00000
train epoch 90 avg loss: 0.65267 (A-MSE: 0.56665) avg lploss: 0.00000
==> val epoch 90 avg loss: 0.86508 (A-MSE: 0.71176) avg lploss: 0.00000
==> test epoch 90 avg loss: 0.78263 (A-MSE: 0.63924) avg lploss: 0.00000
*** Best Val Loss: 0.84729 	 Best Test Loss: 0.76322 	 Best epoch 85
EarlyStopping counter: 1 out of 50
train epoch 91 avg loss: 0.68064 (A-MSE: 0.58778) avg lploss: 0.00000
train epoch 92 avg loss: 0.64800 (A-MSE: 0.55922) avg lploss: 0.00000
train epoch 93 avg loss: 0.76000 (A-MSE: 0.65479) avg lploss: 0.00000
train epoch 94 avg loss: 0.68268 (A-MSE: 0.58983) avg lploss: 0.00000
train epoch 95 avg loss: 0.64817 (A-MSE: 0.56210) avg lploss: 0.00000
==> val epoch 95 avg loss: 0.73515 (A-MSE: 0.63440) avg lploss: 0.00000
==> test epoch 95 avg loss: 0.68273 (A-MSE: 0.59048) avg lploss: 0.00000
*** Best Val Loss: 0.73515 	 Best Test Loss: 0.68273 	 Best epoch 95
Validation loss decreased (0.847287 --> 0.735147).  Saving model ...
train epoch 96 avg loss: 0.63333 (A-MSE: 0.54997) avg lploss: 0.00000
train epoch 97 avg loss: 0.63056 (A-MSE: 0.54637) avg lploss: 0.00000
train epoch 98 avg loss: 0.69822 (A-MSE: 0.60501) avg lploss: 0.00000
train epoch 99 avg loss: 0.68420 (A-MSE: 0.59341) avg lploss: 0.00000
train epoch 100 avg loss: 0.67796 (A-MSE: 0.58625) avg lploss: 0.00000
==> val epoch 100 avg loss: 0.78851 (A-MSE: 0.65380) avg lploss: 0.00000
==> test epoch 100 avg loss: 0.73391 (A-MSE: 0.60832) avg lploss: 0.00000
*** Best Val Loss: 0.73515 	 Best Test Loss: 0.68273 	 Best epoch 95
EarlyStopping counter: 1 out of 50
train epoch 101 avg loss: 0.62759 (A-MSE: 0.54484) avg lploss: 0.00000
train epoch 102 avg loss: 0.59407 (A-MSE: 0.51535) avg lploss: 0.00000
train epoch 103 avg loss: 0.59102 (A-MSE: 0.51188) avg lploss: 0.00000
train epoch 104 avg loss: 0.60435 (A-MSE: 0.52747) avg lploss: 0.00000
train epoch 105 avg loss: 0.60114 (A-MSE: 0.52290) avg lploss: 0.00000
==> val epoch 105 avg loss: 0.76175 (A-MSE: 0.64295) avg lploss: 0.00000
==> test epoch 105 avg loss: 0.69738 (A-MSE: 0.58755) avg lploss: 0.00000
*** Best Val Loss: 0.73515 	 Best Test Loss: 0.68273 	 Best epoch 95
EarlyStopping counter: 2 out of 50
train epoch 106 avg loss: 0.58877 (A-MSE: 0.50863) avg lploss: 0.00000
train epoch 107 avg loss: 0.58223 (A-MSE: 0.50577) avg lploss: 0.00000
train epoch 108 avg loss: 0.56758 (A-MSE: 0.49472) avg lploss: 0.00000
train epoch 109 avg loss: 0.63325 (A-MSE: 0.55068) avg lploss: 0.00000
train epoch 110 avg loss: 0.62781 (A-MSE: 0.54295) avg lploss: 0.00000
==> val epoch 110 avg loss: 0.93793 (A-MSE: 0.77647) avg lploss: 0.00000
==> test epoch 110 avg loss: 0.85777 (A-MSE: 0.70782) avg lploss: 0.00000
*** Best Val Loss: 0.73515 	 Best Test Loss: 0.68273 	 Best epoch 95
EarlyStopping counter: 3 out of 50
train epoch 111 avg loss: 0.62100 (A-MSE: 0.53984) avg lploss: 0.00000
train epoch 112 avg loss: 0.54486 (A-MSE: 0.47357) avg lploss: 0.00000
train epoch 113 avg loss: 0.60182 (A-MSE: 0.52346) avg lploss: 0.00000
train epoch 114 avg loss: 0.57529 (A-MSE: 0.49828) avg lploss: 0.00000
train epoch 115 avg loss: 0.57804 (A-MSE: 0.50434) avg lploss: 0.00000
==> val epoch 115 avg loss: 0.72887 (A-MSE: 0.61942) avg lploss: 0.00000
==> test epoch 115 avg loss: 0.64352 (A-MSE: 0.54494) avg lploss: 0.00000
*** Best Val Loss: 0.72887 	 Best Test Loss: 0.64352 	 Best epoch 115
Validation loss decreased (0.735147 --> 0.728872).  Saving model ...
train epoch 116 avg loss: 0.57375 (A-MSE: 0.49888) avg lploss: 0.00000
train epoch 117 avg loss: 0.54435 (A-MSE: 0.47175) avg lploss: 0.00000
train epoch 118 avg loss: 0.54541 (A-MSE: 0.47695) avg lploss: 0.00000
train epoch 119 avg loss: 0.62405 (A-MSE: 0.54144) avg lploss: 0.00000
train epoch 120 avg loss: 0.55050 (A-MSE: 0.47961) avg lploss: 0.00000
==> val epoch 120 avg loss: 0.61376 (A-MSE: 0.52675) avg lploss: 0.00000
==> test epoch 120 avg loss: 0.57010 (A-MSE: 0.49046) avg lploss: 0.00000
*** Best Val Loss: 0.61376 	 Best Test Loss: 0.57010 	 Best epoch 120
Validation loss decreased (0.728872 --> 0.613760).  Saving model ...
train epoch 121 avg loss: 0.55942 (A-MSE: 0.48863) avg lploss: 0.00000
train epoch 122 avg loss: 0.56212 (A-MSE: 0.48789) avg lploss: 0.00000
train epoch 123 avg loss: 0.57425 (A-MSE: 0.50034) avg lploss: 0.00000
train epoch 124 avg loss: 0.50040 (A-MSE: 0.43720) avg lploss: 0.00000
train epoch 125 avg loss: 0.50581 (A-MSE: 0.44135) avg lploss: 0.00000
==> val epoch 125 avg loss: 0.68037 (A-MSE: 0.58334) avg lploss: 0.00000
==> test epoch 125 avg loss: 0.63109 (A-MSE: 0.54080) avg lploss: 0.00000
*** Best Val Loss: 0.61376 	 Best Test Loss: 0.57010 	 Best epoch 120
EarlyStopping counter: 1 out of 50
train epoch 126 avg loss: 0.57111 (A-MSE: 0.49642) avg lploss: 0.00000
train epoch 127 avg loss: 0.57821 (A-MSE: 0.50492) avg lploss: 0.00000
train epoch 128 avg loss: 0.53144 (A-MSE: 0.46475) avg lploss: 0.00000
train epoch 129 avg loss: 0.52595 (A-MSE: 0.45933) avg lploss: 0.00000
train epoch 130 avg loss: 0.50751 (A-MSE: 0.44355) avg lploss: 0.00000
==> val epoch 130 avg loss: 0.55773 (A-MSE: 0.48291) avg lploss: 0.00000
==> test epoch 130 avg loss: 0.50668 (A-MSE: 0.44006) avg lploss: 0.00000
*** Best Val Loss: 0.55773 	 Best Test Loss: 0.50668 	 Best epoch 130
Validation loss decreased (0.613760 --> 0.557733).  Saving model ...
train epoch 131 avg loss: 0.49904 (A-MSE: 0.43593) avg lploss: 0.00000
train epoch 132 avg loss: 0.55004 (A-MSE: 0.48058) avg lploss: 0.00000
train epoch 133 avg loss: 0.52516 (A-MSE: 0.46041) avg lploss: 0.00000
train epoch 134 avg loss: 0.48229 (A-MSE: 0.42221) avg lploss: 0.00000
train epoch 135 avg loss: 0.48313 (A-MSE: 0.42039) avg lploss: 0.00000
==> val epoch 135 avg loss: 0.62791 (A-MSE: 0.52893) avg lploss: 0.00000
==> test epoch 135 avg loss: 0.56826 (A-MSE: 0.47778) avg lploss: 0.00000
*** Best Val Loss: 0.55773 	 Best Test Loss: 0.50668 	 Best epoch 130
EarlyStopping counter: 1 out of 50
train epoch 136 avg loss: 0.49373 (A-MSE: 0.43061) avg lploss: 0.00000
train epoch 137 avg loss: 0.46523 (A-MSE: 0.40723) avg lploss: 0.00000
train epoch 138 avg loss: 0.47886 (A-MSE: 0.41764) avg lploss: 0.00000
train epoch 139 avg loss: 0.55272 (A-MSE: 0.48219) avg lploss: 0.00000
train epoch 140 avg loss: 0.53041 (A-MSE: 0.46214) avg lploss: 0.00000
==> val epoch 140 avg loss: 0.59439 (A-MSE: 0.50718) avg lploss: 0.00000
==> test epoch 140 avg loss: 0.55706 (A-MSE: 0.47549) avg lploss: 0.00000
*** Best Val Loss: 0.55773 	 Best Test Loss: 0.50668 	 Best epoch 130
EarlyStopping counter: 2 out of 50
train epoch 141 avg loss: 0.47211 (A-MSE: 0.41292) avg lploss: 0.00000
train epoch 142 avg loss: 0.53187 (A-MSE: 0.46625) avg lploss: 0.00000
train epoch 143 avg loss: 0.53907 (A-MSE: 0.46902) avg lploss: 0.00000
train epoch 144 avg loss: 0.52932 (A-MSE: 0.46271) avg lploss: 0.00000
train epoch 145 avg loss: 0.47490 (A-MSE: 0.41594) avg lploss: 0.00000
==> val epoch 145 avg loss: 0.61133 (A-MSE: 0.51224) avg lploss: 0.00000
==> test epoch 145 avg loss: 0.54866 (A-MSE: 0.45928) avg lploss: 0.00000
*** Best Val Loss: 0.55773 	 Best Test Loss: 0.50668 	 Best epoch 130
EarlyStopping counter: 3 out of 50
train epoch 146 avg loss: 0.50404 (A-MSE: 0.43961) avg lploss: 0.00000
train epoch 147 avg loss: 0.49623 (A-MSE: 0.43284) avg lploss: 0.00000
train epoch 148 avg loss: 0.48481 (A-MSE: 0.42341) avg lploss: 0.00000
train epoch 149 avg loss: 0.51257 (A-MSE: 0.44658) avg lploss: 0.00000
train epoch 150 avg loss: 0.49990 (A-MSE: 0.43732) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.61799 (A-MSE: 0.52684) avg lploss: 0.00000
==> test epoch 150 avg loss: 0.54289 (A-MSE: 0.46263) avg lploss: 0.00000
*** Best Val Loss: 0.55773 	 Best Test Loss: 0.50668 	 Best epoch 130
EarlyStopping counter: 4 out of 50
train epoch 151 avg loss: 0.54120 (A-MSE: 0.47466) avg lploss: 0.00000
train epoch 152 avg loss: 0.47273 (A-MSE: 0.41042) avg lploss: 0.00000
train epoch 153 avg loss: 0.49156 (A-MSE: 0.42979) avg lploss: 0.00000
train epoch 154 avg loss: 0.46901 (A-MSE: 0.40980) avg lploss: 0.00000
train epoch 155 avg loss: 0.46054 (A-MSE: 0.40272) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.55308 (A-MSE: 0.46960) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.48292 (A-MSE: 0.41033) avg lploss: 0.00000
*** Best Val Loss: 0.55308 	 Best Test Loss: 0.48292 	 Best epoch 155
Validation loss decreased (0.557733 --> 0.553080).  Saving model ...
train epoch 156 avg loss: 0.49123 (A-MSE: 0.43068) avg lploss: 0.00000
train epoch 157 avg loss: 0.50640 (A-MSE: 0.44064) avg lploss: 0.00000
train epoch 158 avg loss: 0.47121 (A-MSE: 0.41258) avg lploss: 0.00000
train epoch 159 avg loss: 0.43767 (A-MSE: 0.38148) avg lploss: 0.00000
train epoch 160 avg loss: 0.42654 (A-MSE: 0.37385) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.59892 (A-MSE: 0.50575) avg lploss: 0.00000
==> test epoch 160 avg loss: 0.52457 (A-MSE: 0.44388) avg lploss: 0.00000
*** Best Val Loss: 0.55308 	 Best Test Loss: 0.48292 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 0.46363 (A-MSE: 0.40636) avg lploss: 0.00000
train epoch 162 avg loss: 0.44088 (A-MSE: 0.38612) avg lploss: 0.00000
train epoch 163 avg loss: 0.45184 (A-MSE: 0.39473) avg lploss: 0.00000
train epoch 164 avg loss: 0.42415 (A-MSE: 0.37210) avg lploss: 0.00000
train epoch 165 avg loss: 0.41328 (A-MSE: 0.36198) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.52889 (A-MSE: 0.45886) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.46210 (A-MSE: 0.40070) avg lploss: 0.00000
*** Best Val Loss: 0.52889 	 Best Test Loss: 0.46210 	 Best epoch 165
Validation loss decreased (0.553080 --> 0.528889).  Saving model ...
train epoch 166 avg loss: 0.45764 (A-MSE: 0.39772) avg lploss: 0.00000
train epoch 167 avg loss: 0.42810 (A-MSE: 0.37481) avg lploss: 0.00000
train epoch 168 avg loss: 0.50449 (A-MSE: 0.44112) avg lploss: 0.00000
train epoch 169 avg loss: 0.49747 (A-MSE: 0.43701) avg lploss: 0.00000
train epoch 170 avg loss: 0.44338 (A-MSE: 0.38650) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.54792 (A-MSE: 0.47338) avg lploss: 0.00000
==> test epoch 170 avg loss: 0.47619 (A-MSE: 0.41213) avg lploss: 0.00000
*** Best Val Loss: 0.52889 	 Best Test Loss: 0.46210 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 0.44554 (A-MSE: 0.38991) avg lploss: 0.00000
train epoch 172 avg loss: 0.44531 (A-MSE: 0.38884) avg lploss: 0.00000
train epoch 173 avg loss: 0.44043 (A-MSE: 0.38439) avg lploss: 0.00000
train epoch 174 avg loss: 0.40683 (A-MSE: 0.35543) avg lploss: 0.00000
train epoch 175 avg loss: 0.46170 (A-MSE: 0.40518) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.51529 (A-MSE: 0.44175) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.45996 (A-MSE: 0.39629) avg lploss: 0.00000
*** Best Val Loss: 0.51529 	 Best Test Loss: 0.45996 	 Best epoch 175
Validation loss decreased (0.528889 --> 0.515285).  Saving model ...
train epoch 176 avg loss: 0.47726 (A-MSE: 0.41630) avg lploss: 0.00000
train epoch 177 avg loss: 0.42270 (A-MSE: 0.36954) avg lploss: 0.00000
train epoch 178 avg loss: 0.44229 (A-MSE: 0.38481) avg lploss: 0.00000
train epoch 179 avg loss: 0.46331 (A-MSE: 0.40307) avg lploss: 0.00000
train epoch 180 avg loss: 0.40516 (A-MSE: 0.35447) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.46298 (A-MSE: 0.39977) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.42733 (A-MSE: 0.36980) avg lploss: 0.00000
*** Best Val Loss: 0.46298 	 Best Test Loss: 0.42733 	 Best epoch 180
Validation loss decreased (0.515285 --> 0.462975).  Saving model ...
train epoch 181 avg loss: 0.41574 (A-MSE: 0.36278) avg lploss: 0.00000
train epoch 182 avg loss: 0.43469 (A-MSE: 0.38081) avg lploss: 0.00000
train epoch 183 avg loss: 0.42508 (A-MSE: 0.37175) avg lploss: 0.00000
train epoch 184 avg loss: 0.41335 (A-MSE: 0.36102) avg lploss: 0.00000
train epoch 185 avg loss: 0.40265 (A-MSE: 0.35237) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.47431 (A-MSE: 0.40891) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.41201 (A-MSE: 0.35495) avg lploss: 0.00000
*** Best Val Loss: 0.46298 	 Best Test Loss: 0.42733 	 Best epoch 180
EarlyStopping counter: 1 out of 50
train epoch 186 avg loss: 0.53573 (A-MSE: 0.46684) avg lploss: 0.00000
train epoch 187 avg loss: 0.47552 (A-MSE: 0.41336) avg lploss: 0.00000
train epoch 188 avg loss: 0.42690 (A-MSE: 0.37278) avg lploss: 0.00000
train epoch 189 avg loss: 0.46460 (A-MSE: 0.40577) avg lploss: 0.00000
train epoch 190 avg loss: 0.41416 (A-MSE: 0.36443) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.53003 (A-MSE: 0.45659) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.45845 (A-MSE: 0.39580) avg lploss: 0.00000
*** Best Val Loss: 0.46298 	 Best Test Loss: 0.42733 	 Best epoch 180
EarlyStopping counter: 2 out of 50
train epoch 191 avg loss: 0.39977 (A-MSE: 0.35003) avg lploss: 0.00000
train epoch 192 avg loss: 0.44408 (A-MSE: 0.38788) avg lploss: 0.00000
train epoch 193 avg loss: 0.40438 (A-MSE: 0.35357) avg lploss: 0.00000
train epoch 194 avg loss: 0.44104 (A-MSE: 0.38557) avg lploss: 0.00000
train epoch 195 avg loss: 0.53260 (A-MSE: 0.46396) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.56203 (A-MSE: 0.48350) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.50460 (A-MSE: 0.43256) avg lploss: 0.00000
*** Best Val Loss: 0.46298 	 Best Test Loss: 0.42733 	 Best epoch 180
EarlyStopping counter: 3 out of 50
train epoch 196 avg loss: 0.41987 (A-MSE: 0.36676) avg lploss: 0.00000
train epoch 197 avg loss: 0.47275 (A-MSE: 0.41370) avg lploss: 0.00000
train epoch 198 avg loss: 0.42412 (A-MSE: 0.37082) avg lploss: 0.00000
train epoch 199 avg loss: 0.39698 (A-MSE: 0.34638) avg lploss: 0.00000
train epoch 200 avg loss: 0.41478 (A-MSE: 0.36265) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.49246 (A-MSE: 0.41557) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.43954 (A-MSE: 0.37194) avg lploss: 0.00000
*** Best Val Loss: 0.46298 	 Best Test Loss: 0.42733 	 Best epoch 180
EarlyStopping counter: 4 out of 50
train epoch 201 avg loss: 0.40157 (A-MSE: 0.35141) avg lploss: 0.00000
train epoch 202 avg loss: 0.38841 (A-MSE: 0.33964) avg lploss: 0.00000
train epoch 203 avg loss: 0.35334 (A-MSE: 0.30831) avg lploss: 0.00000
train epoch 204 avg loss: 0.34879 (A-MSE: 0.30514) avg lploss: 0.00000
train epoch 205 avg loss: 0.41448 (A-MSE: 0.36195) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.52423 (A-MSE: 0.45273) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.46820 (A-MSE: 0.40413) avg lploss: 0.00000
*** Best Val Loss: 0.46298 	 Best Test Loss: 0.42733 	 Best epoch 180
EarlyStopping counter: 5 out of 50
train epoch 206 avg loss: 0.38688 (A-MSE: 0.33831) avg lploss: 0.00000
train epoch 207 avg loss: 0.42151 (A-MSE: 0.36457) avg lploss: 0.00000
train epoch 208 avg loss: 0.39778 (A-MSE: 0.34696) avg lploss: 0.00000
train epoch 209 avg loss: 0.43404 (A-MSE: 0.37903) avg lploss: 0.00000
train epoch 210 avg loss: 0.41891 (A-MSE: 0.36305) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.45930 (A-MSE: 0.39623) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.39037 (A-MSE: 0.33778) avg lploss: 0.00000
*** Best Val Loss: 0.45930 	 Best Test Loss: 0.39037 	 Best epoch 210
Validation loss decreased (0.462975 --> 0.459300).  Saving model ...
train epoch 211 avg loss: 0.42168 (A-MSE: 0.36759) avg lploss: 0.00000
train epoch 212 avg loss: 0.41853 (A-MSE: 0.36449) avg lploss: 0.00000
train epoch 213 avg loss: 0.40416 (A-MSE: 0.35247) avg lploss: 0.00000
train epoch 214 avg loss: 0.35478 (A-MSE: 0.30935) avg lploss: 0.00000
train epoch 215 avg loss: 0.37047 (A-MSE: 0.32496) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.53745 (A-MSE: 0.45832) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.46251 (A-MSE: 0.39459) avg lploss: 0.00000
*** Best Val Loss: 0.45930 	 Best Test Loss: 0.39037 	 Best epoch 210
EarlyStopping counter: 1 out of 50
train epoch 216 avg loss: 0.37197 (A-MSE: 0.32511) avg lploss: 0.00000
train epoch 217 avg loss: 0.40765 (A-MSE: 0.35603) avg lploss: 0.00000
train epoch 218 avg loss: 0.39197 (A-MSE: 0.34318) avg lploss: 0.00000
train epoch 219 avg loss: 0.39947 (A-MSE: 0.34935) avg lploss: 0.00000
train epoch 220 avg loss: 0.36650 (A-MSE: 0.32037) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.42577 (A-MSE: 0.36767) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.38683 (A-MSE: 0.33387) avg lploss: 0.00000
*** Best Val Loss: 0.42577 	 Best Test Loss: 0.38683 	 Best epoch 220
Validation loss decreased (0.459300 --> 0.425768).  Saving model ...
train epoch 221 avg loss: 0.35887 (A-MSE: 0.31367) avg lploss: 0.00000
train epoch 222 avg loss: 0.34514 (A-MSE: 0.30197) avg lploss: 0.00000
train epoch 223 avg loss: 0.36119 (A-MSE: 0.31700) avg lploss: 0.00000
train epoch 224 avg loss: 0.45323 (A-MSE: 0.39773) avg lploss: 0.00000
train epoch 225 avg loss: 0.41376 (A-MSE: 0.36326) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.52882 (A-MSE: 0.44452) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.45257 (A-MSE: 0.38155) avg lploss: 0.00000
*** Best Val Loss: 0.42577 	 Best Test Loss: 0.38683 	 Best epoch 220
EarlyStopping counter: 1 out of 50
train epoch 226 avg loss: 0.39514 (A-MSE: 0.34434) avg lploss: 0.00000
train epoch 227 avg loss: 0.36263 (A-MSE: 0.31296) avg lploss: 0.00000
train epoch 228 avg loss: 0.37236 (A-MSE: 0.32545) avg lploss: 0.00000
train epoch 229 avg loss: 0.36110 (A-MSE: 0.31505) avg lploss: 0.00000
train epoch 230 avg loss: 0.35582 (A-MSE: 0.31143) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.50202 (A-MSE: 0.42748) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.42213 (A-MSE: 0.35956) avg lploss: 0.00000
*** Best Val Loss: 0.42577 	 Best Test Loss: 0.38683 	 Best epoch 220
EarlyStopping counter: 2 out of 50
train epoch 231 avg loss: 0.36665 (A-MSE: 0.32016) avg lploss: 0.00000
train epoch 232 avg loss: 0.36869 (A-MSE: 0.32242) avg lploss: 0.00000
train epoch 233 avg loss: 0.41975 (A-MSE: 0.36534) avg lploss: 0.00000
train epoch 234 avg loss: 0.40893 (A-MSE: 0.35718) avg lploss: 0.00000
train epoch 235 avg loss: 0.39796 (A-MSE: 0.34389) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.39673 (A-MSE: 0.33889) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.34324 (A-MSE: 0.29412) avg lploss: 0.00000
*** Best Val Loss: 0.39673 	 Best Test Loss: 0.34324 	 Best epoch 235
Validation loss decreased (0.425768 --> 0.396731).  Saving model ...
train epoch 236 avg loss: 0.34103 (A-MSE: 0.29751) avg lploss: 0.00000
train epoch 237 avg loss: 0.32401 (A-MSE: 0.28275) avg lploss: 0.00000
train epoch 238 avg loss: 0.36082 (A-MSE: 0.31674) avg lploss: 0.00000
train epoch 239 avg loss: 0.40373 (A-MSE: 0.35183) avg lploss: 0.00000
train epoch 240 avg loss: 0.35393 (A-MSE: 0.30903) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.42769 (A-MSE: 0.36764) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.41604 (A-MSE: 0.35867) avg lploss: 0.00000
*** Best Val Loss: 0.39673 	 Best Test Loss: 0.34324 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.36255 (A-MSE: 0.31424) avg lploss: 0.00000
train epoch 242 avg loss: 0.36010 (A-MSE: 0.31356) avg lploss: 0.00000
train epoch 243 avg loss: 0.35980 (A-MSE: 0.31488) avg lploss: 0.00000
train epoch 244 avg loss: 0.33186 (A-MSE: 0.29008) avg lploss: 0.00000
train epoch 245 avg loss: 0.31766 (A-MSE: 0.27656) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.43744 (A-MSE: 0.37699) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.37302 (A-MSE: 0.32053) avg lploss: 0.00000
*** Best Val Loss: 0.39673 	 Best Test Loss: 0.34324 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.34712 (A-MSE: 0.29983) avg lploss: 0.00000
train epoch 247 avg loss: 0.34607 (A-MSE: 0.30238) avg lploss: 0.00000
train epoch 248 avg loss: 0.33153 (A-MSE: 0.29016) avg lploss: 0.00000
train epoch 249 avg loss: 0.33349 (A-MSE: 0.29290) avg lploss: 0.00000
train epoch 250 avg loss: 0.30977 (A-MSE: 0.27031) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.44484 (A-MSE: 0.37479) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.36577 (A-MSE: 0.30874) avg lploss: 0.00000
*** Best Val Loss: 0.39673 	 Best Test Loss: 0.34324 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 0.32260 (A-MSE: 0.28154) avg lploss: 0.00000
train epoch 252 avg loss: 0.31443 (A-MSE: 0.27565) avg lploss: 0.00000
train epoch 253 avg loss: 0.32416 (A-MSE: 0.28403) avg lploss: 0.00000
train epoch 254 avg loss: 0.34845 (A-MSE: 0.30444) avg lploss: 0.00000
train epoch 255 avg loss: 0.33450 (A-MSE: 0.29192) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.42654 (A-MSE: 0.37008) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.35434 (A-MSE: 0.30839) avg lploss: 0.00000
*** Best Val Loss: 0.39673 	 Best Test Loss: 0.34324 	 Best epoch 235
EarlyStopping counter: 4 out of 50
train epoch 256 avg loss: 0.29705 (A-MSE: 0.26088) avg lploss: 0.00000
train epoch 257 avg loss: 0.32930 (A-MSE: 0.28618) avg lploss: 0.00000
train epoch 258 avg loss: 0.33132 (A-MSE: 0.28897) avg lploss: 0.00000
train epoch 259 avg loss: 0.38478 (A-MSE: 0.33568) avg lploss: 0.00000
train epoch 260 avg loss: 0.33813 (A-MSE: 0.29596) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.41521 (A-MSE: 0.35751) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.34480 (A-MSE: 0.29715) avg lploss: 0.00000
*** Best Val Loss: 0.39673 	 Best Test Loss: 0.34324 	 Best epoch 235
EarlyStopping counter: 5 out of 50
train epoch 261 avg loss: 0.29019 (A-MSE: 0.25359) avg lploss: 0.00000
train epoch 262 avg loss: 0.31549 (A-MSE: 0.27491) avg lploss: 0.00000
train epoch 263 avg loss: 0.30503 (A-MSE: 0.26592) avg lploss: 0.00000
train epoch 264 avg loss: 0.35688 (A-MSE: 0.30992) avg lploss: 0.00000
train epoch 265 avg loss: 0.29951 (A-MSE: 0.26100) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.34112 (A-MSE: 0.29298) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.29943 (A-MSE: 0.25730) avg lploss: 0.00000
*** Best Val Loss: 0.34112 	 Best Test Loss: 0.29943 	 Best epoch 265
Validation loss decreased (0.396731 --> 0.341115).  Saving model ...
train epoch 266 avg loss: 0.30090 (A-MSE: 0.26354) avg lploss: 0.00000
train epoch 267 avg loss: 0.35637 (A-MSE: 0.31246) avg lploss: 0.00000
train epoch 268 avg loss: 0.29422 (A-MSE: 0.25605) avg lploss: 0.00000
train epoch 269 avg loss: 0.29588 (A-MSE: 0.25877) avg lploss: 0.00000
train epoch 270 avg loss: 0.31258 (A-MSE: 0.27363) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.38276 (A-MSE: 0.32467) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.33441 (A-MSE: 0.28358) avg lploss: 0.00000
*** Best Val Loss: 0.34112 	 Best Test Loss: 0.29943 	 Best epoch 265
EarlyStopping counter: 1 out of 50
train epoch 271 avg loss: 0.32657 (A-MSE: 0.28292) avg lploss: 0.00000
train epoch 272 avg loss: 0.29239 (A-MSE: 0.25649) avg lploss: 0.00000
train epoch 273 avg loss: 0.31325 (A-MSE: 0.27194) avg lploss: 0.00000
train epoch 274 avg loss: 0.34796 (A-MSE: 0.30333) avg lploss: 0.00000
train epoch 275 avg loss: 0.34104 (A-MSE: 0.29847) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.43618 (A-MSE: 0.38054) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.37087 (A-MSE: 0.32446) avg lploss: 0.00000
*** Best Val Loss: 0.34112 	 Best Test Loss: 0.29943 	 Best epoch 265
EarlyStopping counter: 2 out of 50
train epoch 276 avg loss: 0.30801 (A-MSE: 0.26894) avg lploss: 0.00000
train epoch 277 avg loss: 0.31692 (A-MSE: 0.27596) avg lploss: 0.00000
train epoch 278 avg loss: 0.31216 (A-MSE: 0.27237) avg lploss: 0.00000
train epoch 279 avg loss: 0.29917 (A-MSE: 0.26176) avg lploss: 0.00000
train epoch 280 avg loss: 0.28645 (A-MSE: 0.24923) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.36332 (A-MSE: 0.30880) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.30210 (A-MSE: 0.25702) avg lploss: 0.00000
*** Best Val Loss: 0.34112 	 Best Test Loss: 0.29943 	 Best epoch 265
EarlyStopping counter: 3 out of 50
train epoch 281 avg loss: 0.29752 (A-MSE: 0.25782) avg lploss: 0.00000
train epoch 282 avg loss: 0.30491 (A-MSE: 0.26603) avg lploss: 0.00000
train epoch 283 avg loss: 0.33613 (A-MSE: 0.29496) avg lploss: 0.00000
train epoch 284 avg loss: 0.30855 (A-MSE: 0.26834) avg lploss: 0.00000
train epoch 285 avg loss: 0.30346 (A-MSE: 0.26625) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.38326 (A-MSE: 0.33277) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.32056 (A-MSE: 0.27828) avg lploss: 0.00000
*** Best Val Loss: 0.34112 	 Best Test Loss: 0.29943 	 Best epoch 265
EarlyStopping counter: 4 out of 50
train epoch 286 avg loss: 0.26251 (A-MSE: 0.22960) avg lploss: 0.00000
train epoch 287 avg loss: 0.28076 (A-MSE: 0.24524) avg lploss: 0.00000
train epoch 288 avg loss: 0.25217 (A-MSE: 0.22108) avg lploss: 0.00000
train epoch 289 avg loss: 0.31280 (A-MSE: 0.27412) avg lploss: 0.00000
train epoch 290 avg loss: 0.28540 (A-MSE: 0.25028) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.32750 (A-MSE: 0.27779) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.28512 (A-MSE: 0.24254) avg lploss: 0.00000
*** Best Val Loss: 0.32750 	 Best Test Loss: 0.28512 	 Best epoch 290
Validation loss decreased (0.341115 --> 0.327503).  Saving model ...
train epoch 291 avg loss: 0.29330 (A-MSE: 0.25594) avg lploss: 0.00000
train epoch 292 avg loss: 0.26435 (A-MSE: 0.23029) avg lploss: 0.00000
train epoch 293 avg loss: 0.28156 (A-MSE: 0.24645) avg lploss: 0.00000
train epoch 294 avg loss: 0.37835 (A-MSE: 0.33221) avg lploss: 0.00000
train epoch 295 avg loss: 0.29935 (A-MSE: 0.26187) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.36156 (A-MSE: 0.31212) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.30684 (A-MSE: 0.26454) avg lploss: 0.00000
*** Best Val Loss: 0.32750 	 Best Test Loss: 0.28512 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 0.31826 (A-MSE: 0.27477) avg lploss: 0.00000
train epoch 297 avg loss: 0.29369 (A-MSE: 0.25714) avg lploss: 0.00000
train epoch 298 avg loss: 0.32465 (A-MSE: 0.28334) avg lploss: 0.00000
train epoch 299 avg loss: 0.33861 (A-MSE: 0.29699) avg lploss: 0.00000
train epoch 300 avg loss: 0.30130 (A-MSE: 0.26123) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.33817 (A-MSE: 0.28786) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.30785 (A-MSE: 0.26221) avg lploss: 0.00000
*** Best Val Loss: 0.32750 	 Best Test Loss: 0.28512 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 0.27853 (A-MSE: 0.24438) avg lploss: 0.00000
train epoch 302 avg loss: 0.30317 (A-MSE: 0.26503) avg lploss: 0.00000
train epoch 303 avg loss: 0.30845 (A-MSE: 0.26794) avg lploss: 0.00000
train epoch 304 avg loss: 0.30654 (A-MSE: 0.26571) avg lploss: 0.00000
train epoch 305 avg loss: 0.28400 (A-MSE: 0.24879) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.40164 (A-MSE: 0.34550) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.33768 (A-MSE: 0.29085) avg lploss: 0.00000
*** Best Val Loss: 0.32750 	 Best Test Loss: 0.28512 	 Best epoch 290
EarlyStopping counter: 3 out of 50
train epoch 306 avg loss: 0.27225 (A-MSE: 0.23767) avg lploss: 0.00000
train epoch 307 avg loss: 0.25713 (A-MSE: 0.22401) avg lploss: 0.00000
train epoch 308 avg loss: 0.26559 (A-MSE: 0.23251) avg lploss: 0.00000
train epoch 309 avg loss: 0.25332 (A-MSE: 0.22273) avg lploss: 0.00000
train epoch 310 avg loss: 0.29855 (A-MSE: 0.25934) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.30272 (A-MSE: 0.25943) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.25937 (A-MSE: 0.22247) avg lploss: 0.00000
*** Best Val Loss: 0.30272 	 Best Test Loss: 0.25937 	 Best epoch 310
Validation loss decreased (0.327503 --> 0.302724).  Saving model ...
train epoch 311 avg loss: 0.29241 (A-MSE: 0.25192) avg lploss: 0.00000
train epoch 312 avg loss: 0.27310 (A-MSE: 0.23672) avg lploss: 0.00000
train epoch 313 avg loss: 0.27028 (A-MSE: 0.23587) avg lploss: 0.00000
train epoch 314 avg loss: 0.27507 (A-MSE: 0.24023) avg lploss: 0.00000
train epoch 315 avg loss: 0.27755 (A-MSE: 0.24187) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.32102 (A-MSE: 0.27316) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.28635 (A-MSE: 0.24471) avg lploss: 0.00000
*** Best Val Loss: 0.30272 	 Best Test Loss: 0.25937 	 Best epoch 310
EarlyStopping counter: 1 out of 50
train epoch 316 avg loss: 0.28459 (A-MSE: 0.24817) avg lploss: 0.00000
train epoch 317 avg loss: 0.29451 (A-MSE: 0.25667) avg lploss: 0.00000
train epoch 318 avg loss: 0.27549 (A-MSE: 0.24027) avg lploss: 0.00000
train epoch 319 avg loss: 0.28053 (A-MSE: 0.24413) avg lploss: 0.00000
train epoch 320 avg loss: 0.24426 (A-MSE: 0.21321) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.29825 (A-MSE: 0.25321) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.27705 (A-MSE: 0.23517) avg lploss: 0.00000
*** Best Val Loss: 0.29825 	 Best Test Loss: 0.27705 	 Best epoch 320
Validation loss decreased (0.302724 --> 0.298250).  Saving model ...
train epoch 321 avg loss: 0.26106 (A-MSE: 0.22725) avg lploss: 0.00000
train epoch 322 avg loss: 0.26735 (A-MSE: 0.23441) avg lploss: 0.00000
train epoch 323 avg loss: 0.27894 (A-MSE: 0.24353) avg lploss: 0.00000
train epoch 324 avg loss: 0.28281 (A-MSE: 0.24610) avg lploss: 0.00000
train epoch 325 avg loss: 0.25230 (A-MSE: 0.22112) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.28260 (A-MSE: 0.24109) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.25756 (A-MSE: 0.21972) avg lploss: 0.00000
*** Best Val Loss: 0.28260 	 Best Test Loss: 0.25756 	 Best epoch 325
Validation loss decreased (0.298250 --> 0.282597).  Saving model ...
train epoch 326 avg loss: 0.24643 (A-MSE: 0.21508) avg lploss: 0.00000
train epoch 327 avg loss: 0.27329 (A-MSE: 0.23825) avg lploss: 0.00000
train epoch 328 avg loss: 0.28049 (A-MSE: 0.24614) avg lploss: 0.00000
train epoch 329 avg loss: 0.26979 (A-MSE: 0.23599) avg lploss: 0.00000
train epoch 330 avg loss: 0.27311 (A-MSE: 0.23852) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.37947 (A-MSE: 0.31945) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.31522 (A-MSE: 0.26536) avg lploss: 0.00000
*** Best Val Loss: 0.28260 	 Best Test Loss: 0.25756 	 Best epoch 325
EarlyStopping counter: 1 out of 50
train epoch 331 avg loss: 0.27850 (A-MSE: 0.24130) avg lploss: 0.00000
train epoch 332 avg loss: 0.26022 (A-MSE: 0.22667) avg lploss: 0.00000
train epoch 333 avg loss: 0.24837 (A-MSE: 0.21617) avg lploss: 0.00000
train epoch 334 avg loss: 0.24988 (A-MSE: 0.21867) avg lploss: 0.00000
train epoch 335 avg loss: 0.27464 (A-MSE: 0.23674) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.34312 (A-MSE: 0.28980) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.29501 (A-MSE: 0.24929) avg lploss: 0.00000
*** Best Val Loss: 0.28260 	 Best Test Loss: 0.25756 	 Best epoch 325
EarlyStopping counter: 2 out of 50
train epoch 336 avg loss: 0.30619 (A-MSE: 0.26783) avg lploss: 0.00000
train epoch 337 avg loss: 0.25205 (A-MSE: 0.21937) avg lploss: 0.00000
train epoch 338 avg loss: 0.26869 (A-MSE: 0.23477) avg lploss: 0.00000
train epoch 339 avg loss: 0.27947 (A-MSE: 0.24398) avg lploss: 0.00000
train epoch 340 avg loss: 0.24368 (A-MSE: 0.21257) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.29036 (A-MSE: 0.24894) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.23970 (A-MSE: 0.20522) avg lploss: 0.00000
*** Best Val Loss: 0.28260 	 Best Test Loss: 0.25756 	 Best epoch 325
EarlyStopping counter: 3 out of 50
train epoch 341 avg loss: 0.23137 (A-MSE: 0.20117) avg lploss: 0.00000
train epoch 342 avg loss: 0.22084 (A-MSE: 0.19299) avg lploss: 0.00000
train epoch 343 avg loss: 0.24779 (A-MSE: 0.21582) avg lploss: 0.00000
train epoch 344 avg loss: 0.24349 (A-MSE: 0.21290) avg lploss: 0.00000
train epoch 345 avg loss: 0.21700 (A-MSE: 0.18926) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.30553 (A-MSE: 0.25416) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.26218 (A-MSE: 0.21836) avg lploss: 0.00000
*** Best Val Loss: 0.28260 	 Best Test Loss: 0.25756 	 Best epoch 325
EarlyStopping counter: 4 out of 50
train epoch 346 avg loss: 0.26225 (A-MSE: 0.22565) avg lploss: 0.00000
train epoch 347 avg loss: 0.26436 (A-MSE: 0.23036) avg lploss: 0.00000
train epoch 348 avg loss: 0.23371 (A-MSE: 0.20360) avg lploss: 0.00000
train epoch 349 avg loss: 0.22706 (A-MSE: 0.19850) avg lploss: 0.00000
train epoch 350 avg loss: 0.22064 (A-MSE: 0.19281) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.31691 (A-MSE: 0.27013) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.26577 (A-MSE: 0.22642) avg lploss: 0.00000
*** Best Val Loss: 0.28260 	 Best Test Loss: 0.25756 	 Best epoch 325
EarlyStopping counter: 5 out of 50
train epoch 351 avg loss: 0.21669 (A-MSE: 0.18898) avg lploss: 0.00000
train epoch 352 avg loss: 0.22946 (A-MSE: 0.20042) avg lploss: 0.00000
train epoch 353 avg loss: 0.26469 (A-MSE: 0.22884) avg lploss: 0.00000
train epoch 354 avg loss: 0.27093 (A-MSE: 0.23384) avg lploss: 0.00000
train epoch 355 avg loss: 0.23653 (A-MSE: 0.20665) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.27797 (A-MSE: 0.23743) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.24641 (A-MSE: 0.21005) avg lploss: 0.00000
*** Best Val Loss: 0.27797 	 Best Test Loss: 0.24641 	 Best epoch 355
Validation loss decreased (0.282597 --> 0.277971).  Saving model ...
train epoch 356 avg loss: 0.21356 (A-MSE: 0.18668) avg lploss: 0.00000
train epoch 357 avg loss: 0.26305 (A-MSE: 0.22587) avg lploss: 0.00000
train epoch 358 avg loss: 0.26394 (A-MSE: 0.23094) avg lploss: 0.00000
train epoch 359 avg loss: 0.21503 (A-MSE: 0.18711) avg lploss: 0.00000
train epoch 360 avg loss: 0.20734 (A-MSE: 0.18030) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.25759 (A-MSE: 0.22066) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.22475 (A-MSE: 0.19276) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
Validation loss decreased (0.277971 --> 0.257587).  Saving model ...
train epoch 361 avg loss: 0.23084 (A-MSE: 0.20112) avg lploss: 0.00000
train epoch 362 avg loss: 0.23178 (A-MSE: 0.20220) avg lploss: 0.00000
train epoch 363 avg loss: 0.21855 (A-MSE: 0.18969) avg lploss: 0.00000
train epoch 364 avg loss: 0.25894 (A-MSE: 0.22405) avg lploss: 0.00000
train epoch 365 avg loss: 0.23168 (A-MSE: 0.20029) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.29289 (A-MSE: 0.24658) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.27240 (A-MSE: 0.23052) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
EarlyStopping counter: 1 out of 50
train epoch 366 avg loss: 0.25560 (A-MSE: 0.22342) avg lploss: 0.00000
train epoch 367 avg loss: 0.25822 (A-MSE: 0.22428) avg lploss: 0.00000
train epoch 368 avg loss: 0.24219 (A-MSE: 0.21183) avg lploss: 0.00000
train epoch 369 avg loss: 0.26221 (A-MSE: 0.22824) avg lploss: 0.00000
train epoch 370 avg loss: 0.32679 (A-MSE: 0.28621) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.34565 (A-MSE: 0.29312) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.31250 (A-MSE: 0.26661) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
EarlyStopping counter: 2 out of 50
train epoch 371 avg loss: 0.25154 (A-MSE: 0.21828) avg lploss: 0.00000
train epoch 372 avg loss: 0.24617 (A-MSE: 0.21434) avg lploss: 0.00000
train epoch 373 avg loss: 0.23215 (A-MSE: 0.20185) avg lploss: 0.00000
train epoch 374 avg loss: 0.21838 (A-MSE: 0.19005) avg lploss: 0.00000
train epoch 375 avg loss: 0.23462 (A-MSE: 0.20464) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.29521 (A-MSE: 0.25585) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.26370 (A-MSE: 0.22914) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
EarlyStopping counter: 3 out of 50
train epoch 376 avg loss: 0.23409 (A-MSE: 0.20323) avg lploss: 0.00000
train epoch 377 avg loss: 0.22110 (A-MSE: 0.19347) avg lploss: 0.00000
train epoch 378 avg loss: 0.20160 (A-MSE: 0.17560) avg lploss: 0.00000
train epoch 379 avg loss: 0.20381 (A-MSE: 0.17682) avg lploss: 0.00000
train epoch 380 avg loss: 0.20908 (A-MSE: 0.18308) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.27168 (A-MSE: 0.22972) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.23267 (A-MSE: 0.19654) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
EarlyStopping counter: 4 out of 50
train epoch 381 avg loss: 0.19700 (A-MSE: 0.17109) avg lploss: 0.00000
train epoch 382 avg loss: 0.20866 (A-MSE: 0.18153) avg lploss: 0.00000
train epoch 383 avg loss: 0.20016 (A-MSE: 0.17384) avg lploss: 0.00000
train epoch 384 avg loss: 0.20943 (A-MSE: 0.18198) avg lploss: 0.00000
train epoch 385 avg loss: 0.23012 (A-MSE: 0.19955) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.26368 (A-MSE: 0.22508) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.23653 (A-MSE: 0.20187) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
EarlyStopping counter: 5 out of 50
train epoch 386 avg loss: 0.21672 (A-MSE: 0.19004) avg lploss: 0.00000
train epoch 387 avg loss: 0.25041 (A-MSE: 0.21832) avg lploss: 0.00000
train epoch 388 avg loss: 0.23433 (A-MSE: 0.20195) avg lploss: 0.00000
train epoch 389 avg loss: 0.22228 (A-MSE: 0.19363) avg lploss: 0.00000
train epoch 390 avg loss: 0.21708 (A-MSE: 0.18972) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.28669 (A-MSE: 0.24174) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.26460 (A-MSE: 0.22402) avg lploss: 0.00000
*** Best Val Loss: 0.25759 	 Best Test Loss: 0.22475 	 Best epoch 360
EarlyStopping counter: 6 out of 50
train epoch 391 avg loss: 0.22791 (A-MSE: 0.19879) avg lploss: 0.00000
train epoch 392 avg loss: 0.20113 (A-MSE: 0.17477) avg lploss: 0.00000
train epoch 393 avg loss: 0.19157 (A-MSE: 0.16650) avg lploss: 0.00000
train epoch 394 avg loss: 0.18941 (A-MSE: 0.16351) avg lploss: 0.00000
train epoch 395 avg loss: 0.19321 (A-MSE: 0.16854) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.25015 (A-MSE: 0.21281) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.20581 (A-MSE: 0.17488) avg lploss: 0.00000
*** Best Val Loss: 0.25015 	 Best Test Loss: 0.20581 	 Best epoch 395
Validation loss decreased (0.257587 --> 0.250152).  Saving model ...
train epoch 396 avg loss: 0.17630 (A-MSE: 0.15363) avg lploss: 0.00000
train epoch 397 avg loss: 0.19183 (A-MSE: 0.16650) avg lploss: 0.00000
train epoch 398 avg loss: 0.19695 (A-MSE: 0.17083) avg lploss: 0.00000
train epoch 399 avg loss: 0.29168 (A-MSE: 0.25528) avg lploss: 0.00000
train epoch 400 avg loss: 0.26255 (A-MSE: 0.22947) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.31621 (A-MSE: 0.26898) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.27087 (A-MSE: 0.23177) avg lploss: 0.00000
*** Best Val Loss: 0.25015 	 Best Test Loss: 0.20581 	 Best epoch 395
EarlyStopping counter: 1 out of 50
train epoch 401 avg loss: 0.20522 (A-MSE: 0.17872) avg lploss: 0.00000
train epoch 402 avg loss: 0.20968 (A-MSE: 0.18235) avg lploss: 0.00000
train epoch 403 avg loss: 0.21406 (A-MSE: 0.18550) avg lploss: 0.00000
train epoch 404 avg loss: 0.22321 (A-MSE: 0.19377) avg lploss: 0.00000
train epoch 405 avg loss: 0.23116 (A-MSE: 0.20161) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.33183 (A-MSE: 0.28002) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.28733 (A-MSE: 0.24384) avg lploss: 0.00000
*** Best Val Loss: 0.25015 	 Best Test Loss: 0.20581 	 Best epoch 395
EarlyStopping counter: 2 out of 50
train epoch 406 avg loss: 0.21010 (A-MSE: 0.18255) avg lploss: 0.00000
train epoch 407 avg loss: 0.18413 (A-MSE: 0.15966) avg lploss: 0.00000
train epoch 408 avg loss: 0.20517 (A-MSE: 0.17895) avg lploss: 0.00000
train epoch 409 avg loss: 0.19233 (A-MSE: 0.16749) avg lploss: 0.00000
train epoch 410 avg loss: 0.19312 (A-MSE: 0.16808) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.31360 (A-MSE: 0.26083) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.26732 (A-MSE: 0.22203) avg lploss: 0.00000
*** Best Val Loss: 0.25015 	 Best Test Loss: 0.20581 	 Best epoch 395
EarlyStopping counter: 3 out of 50
train epoch 411 avg loss: 0.20744 (A-MSE: 0.17949) avg lploss: 0.00000
train epoch 412 avg loss: 0.23811 (A-MSE: 0.20795) avg lploss: 0.00000
train epoch 413 avg loss: 0.21122 (A-MSE: 0.18322) avg lploss: 0.00000
train epoch 414 avg loss: 0.23178 (A-MSE: 0.20281) avg lploss: 0.00000
train epoch 415 avg loss: 0.27802 (A-MSE: 0.24104) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.30668 (A-MSE: 0.25706) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.27617 (A-MSE: 0.23205) avg lploss: 0.00000
*** Best Val Loss: 0.25015 	 Best Test Loss: 0.20581 	 Best epoch 395
EarlyStopping counter: 4 out of 50
train epoch 416 avg loss: 0.26167 (A-MSE: 0.22827) avg lploss: 0.00000
train epoch 417 avg loss: 0.22472 (A-MSE: 0.19377) avg lploss: 0.00000
train epoch 418 avg loss: 0.20564 (A-MSE: 0.17870) avg lploss: 0.00000
train epoch 419 avg loss: 0.19306 (A-MSE: 0.16746) avg lploss: 0.00000
train epoch 420 avg loss: 0.18828 (A-MSE: 0.16407) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.23510 (A-MSE: 0.19875) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.19866 (A-MSE: 0.16773) avg lploss: 0.00000
*** Best Val Loss: 0.23510 	 Best Test Loss: 0.19866 	 Best epoch 420
Validation loss decreased (0.250152 --> 0.235100).  Saving model ...
train epoch 421 avg loss: 0.17307 (A-MSE: 0.14973) avg lploss: 0.00000
train epoch 422 avg loss: 0.19343 (A-MSE: 0.16718) avg lploss: 0.00000
train epoch 423 avg loss: 0.18256 (A-MSE: 0.15932) avg lploss: 0.00000
train epoch 424 avg loss: 0.17510 (A-MSE: 0.15197) avg lploss: 0.00000
train epoch 425 avg loss: 0.18327 (A-MSE: 0.15990) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.27186 (A-MSE: 0.23222) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.22449 (A-MSE: 0.19170) avg lploss: 0.00000
*** Best Val Loss: 0.23510 	 Best Test Loss: 0.19866 	 Best epoch 420
EarlyStopping counter: 1 out of 50
train epoch 426 avg loss: 0.18002 (A-MSE: 0.15679) avg lploss: 0.00000
train epoch 427 avg loss: 0.17516 (A-MSE: 0.15182) avg lploss: 0.00000
train epoch 428 avg loss: 0.15825 (A-MSE: 0.13722) avg lploss: 0.00000
train epoch 429 avg loss: 0.15801 (A-MSE: 0.13783) avg lploss: 0.00000
train epoch 430 avg loss: 0.18075 (A-MSE: 0.15682) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.22679 (A-MSE: 0.19409) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.18522 (A-MSE: 0.15888) avg lploss: 0.00000
*** Best Val Loss: 0.22679 	 Best Test Loss: 0.18522 	 Best epoch 430
Validation loss decreased (0.235100 --> 0.226792).  Saving model ...
train epoch 431 avg loss: 0.15590 (A-MSE: 0.13505) avg lploss: 0.00000
train epoch 432 avg loss: 0.16477 (A-MSE: 0.14339) avg lploss: 0.00000
train epoch 433 avg loss: 0.15905 (A-MSE: 0.13832) avg lploss: 0.00000
train epoch 434 avg loss: 0.15497 (A-MSE: 0.13459) avg lploss: 0.00000
train epoch 435 avg loss: 0.16303 (A-MSE: 0.14062) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.21494 (A-MSE: 0.18543) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.18588 (A-MSE: 0.16145) avg lploss: 0.00000
*** Best Val Loss: 0.21494 	 Best Test Loss: 0.18588 	 Best epoch 435
Validation loss decreased (0.226792 --> 0.214936).  Saving model ...
train epoch 436 avg loss: 0.17933 (A-MSE: 0.15578) avg lploss: 0.00000
train epoch 437 avg loss: 0.19567 (A-MSE: 0.17098) avg lploss: 0.00000
train epoch 438 avg loss: 0.19881 (A-MSE: 0.17386) avg lploss: 0.00000
train epoch 439 avg loss: 0.16063 (A-MSE: 0.13995) avg lploss: 0.00000
train epoch 440 avg loss: 0.16709 (A-MSE: 0.14539) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.24699 (A-MSE: 0.21000) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.21504 (A-MSE: 0.18234) avg lploss: 0.00000
*** Best Val Loss: 0.21494 	 Best Test Loss: 0.18588 	 Best epoch 435
EarlyStopping counter: 1 out of 50
train epoch 441 avg loss: 0.15044 (A-MSE: 0.13068) avg lploss: 0.00000
train epoch 442 avg loss: 0.16208 (A-MSE: 0.14061) avg lploss: 0.00000
train epoch 443 avg loss: 0.16377 (A-MSE: 0.14228) avg lploss: 0.00000
train epoch 444 avg loss: 0.15511 (A-MSE: 0.13441) avg lploss: 0.00000
train epoch 445 avg loss: 0.15482 (A-MSE: 0.13460) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.22934 (A-MSE: 0.19517) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.19215 (A-MSE: 0.16387) avg lploss: 0.00000
*** Best Val Loss: 0.21494 	 Best Test Loss: 0.18588 	 Best epoch 435
EarlyStopping counter: 2 out of 50
train epoch 446 avg loss: 0.14487 (A-MSE: 0.12593) avg lploss: 0.00000
train epoch 447 avg loss: 0.14096 (A-MSE: 0.12193) avg lploss: 0.00000
train epoch 448 avg loss: 0.15095 (A-MSE: 0.13007) avg lploss: 0.00000
train epoch 449 avg loss: 0.16892 (A-MSE: 0.14670) avg lploss: 0.00000
train epoch 450 avg loss: 0.16026 (A-MSE: 0.13959) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.28600 (A-MSE: 0.24595) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.24733 (A-MSE: 0.21348) avg lploss: 0.00000
*** Best Val Loss: 0.21494 	 Best Test Loss: 0.18588 	 Best epoch 435
EarlyStopping counter: 3 out of 50
train epoch 451 avg loss: 0.15687 (A-MSE: 0.13651) avg lploss: 0.00000
train epoch 452 avg loss: 0.14884 (A-MSE: 0.12868) avg lploss: 0.00000
train epoch 453 avg loss: 0.18551 (A-MSE: 0.16091) avg lploss: 0.00000
train epoch 454 avg loss: 0.14164 (A-MSE: 0.12278) avg lploss: 0.00000
train epoch 455 avg loss: 0.13567 (A-MSE: 0.11812) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.19605 (A-MSE: 0.16552) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.16639 (A-MSE: 0.14041) avg lploss: 0.00000
*** Best Val Loss: 0.19605 	 Best Test Loss: 0.16639 	 Best epoch 455
Validation loss decreased (0.214936 --> 0.196054).  Saving model ...
train epoch 456 avg loss: 0.12977 (A-MSE: 0.11306) avg lploss: 0.00000
train epoch 457 avg loss: 0.13780 (A-MSE: 0.12010) avg lploss: 0.00000
train epoch 458 avg loss: 0.16379 (A-MSE: 0.14306) avg lploss: 0.00000
train epoch 459 avg loss: 0.16356 (A-MSE: 0.14114) avg lploss: 0.00000
train epoch 460 avg loss: 0.16608 (A-MSE: 0.14460) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.35375 (A-MSE: 0.30811) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.31038 (A-MSE: 0.27115) avg lploss: 0.00000
*** Best Val Loss: 0.19605 	 Best Test Loss: 0.16639 	 Best epoch 455
EarlyStopping counter: 1 out of 50
train epoch 461 avg loss: 0.18915 (A-MSE: 0.16409) avg lploss: 0.00000
train epoch 462 avg loss: 0.15409 (A-MSE: 0.13399) avg lploss: 0.00000
train epoch 463 avg loss: 0.14427 (A-MSE: 0.12586) avg lploss: 0.00000
train epoch 464 avg loss: 0.14574 (A-MSE: 0.12656) avg lploss: 0.00000
train epoch 465 avg loss: 0.13851 (A-MSE: 0.12027) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.20873 (A-MSE: 0.17606) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.17242 (A-MSE: 0.14490) avg lploss: 0.00000
*** Best Val Loss: 0.19605 	 Best Test Loss: 0.16639 	 Best epoch 455
EarlyStopping counter: 2 out of 50
train epoch 466 avg loss: 0.12939 (A-MSE: 0.11251) avg lploss: 0.00000
train epoch 467 avg loss: 0.13594 (A-MSE: 0.11711) avg lploss: 0.00000
train epoch 468 avg loss: 0.16194 (A-MSE: 0.14190) avg lploss: 0.00000
train epoch 469 avg loss: 0.15545 (A-MSE: 0.13538) avg lploss: 0.00000
train epoch 470 avg loss: 0.14929 (A-MSE: 0.13006) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.18104 (A-MSE: 0.15362) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.15659 (A-MSE: 0.13270) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
Validation loss decreased (0.196054 --> 0.181036).  Saving model ...
train epoch 471 avg loss: 0.14455 (A-MSE: 0.12587) avg lploss: 0.00000
train epoch 472 avg loss: 0.13981 (A-MSE: 0.12109) avg lploss: 0.00000
train epoch 473 avg loss: 0.13444 (A-MSE: 0.11699) avg lploss: 0.00000
train epoch 474 avg loss: 0.13201 (A-MSE: 0.11479) avg lploss: 0.00000
train epoch 475 avg loss: 0.12215 (A-MSE: 0.10636) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.19876 (A-MSE: 0.16779) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.16424 (A-MSE: 0.13798) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 1 out of 50
train epoch 476 avg loss: 0.12089 (A-MSE: 0.10457) avg lploss: 0.00000
train epoch 477 avg loss: 0.13069 (A-MSE: 0.11377) avg lploss: 0.00000
train epoch 478 avg loss: 0.13345 (A-MSE: 0.11621) avg lploss: 0.00000
train epoch 479 avg loss: 0.21712 (A-MSE: 0.19150) avg lploss: 0.00000
train epoch 480 avg loss: 0.38838 (A-MSE: 0.34413) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.33913 (A-MSE: 0.29779) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.32401 (A-MSE: 0.28593) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 2 out of 50
train epoch 481 avg loss: 0.23137 (A-MSE: 0.20147) avg lploss: 0.00000
train epoch 482 avg loss: 0.16890 (A-MSE: 0.14683) avg lploss: 0.00000
train epoch 483 avg loss: 0.17889 (A-MSE: 0.15469) avg lploss: 0.00000
train epoch 484 avg loss: 0.14377 (A-MSE: 0.12492) avg lploss: 0.00000
train epoch 485 avg loss: 0.14760 (A-MSE: 0.12882) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.20396 (A-MSE: 0.17267) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.16748 (A-MSE: 0.14169) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 3 out of 50
train epoch 486 avg loss: 0.12590 (A-MSE: 0.10927) avg lploss: 0.00000
train epoch 487 avg loss: 0.13560 (A-MSE: 0.11744) avg lploss: 0.00000
train epoch 488 avg loss: 0.14419 (A-MSE: 0.12613) avg lploss: 0.00000
train epoch 489 avg loss: 0.18643 (A-MSE: 0.16051) avg lploss: 0.00000
train epoch 490 avg loss: 0.14768 (A-MSE: 0.12898) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.20444 (A-MSE: 0.17315) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.17469 (A-MSE: 0.14746) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 4 out of 50
train epoch 491 avg loss: 0.13325 (A-MSE: 0.11541) avg lploss: 0.00000
train epoch 492 avg loss: 0.12559 (A-MSE: 0.10888) avg lploss: 0.00000
train epoch 493 avg loss: 0.11895 (A-MSE: 0.10383) avg lploss: 0.00000
train epoch 494 avg loss: 0.14333 (A-MSE: 0.12375) avg lploss: 0.00000
train epoch 495 avg loss: 0.14726 (A-MSE: 0.12725) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.20078 (A-MSE: 0.17092) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.16504 (A-MSE: 0.13983) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 5 out of 50
train epoch 496 avg loss: 0.13290 (A-MSE: 0.11569) avg lploss: 0.00000
train epoch 497 avg loss: 0.13847 (A-MSE: 0.12094) avg lploss: 0.00000
train epoch 498 avg loss: 0.12306 (A-MSE: 0.10740) avg lploss: 0.00000
train epoch 499 avg loss: 0.11987 (A-MSE: 0.10534) avg lploss: 0.00000
train epoch 500 avg loss: 0.12405 (A-MSE: 0.10841) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.18913 (A-MSE: 0.16168) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.16315 (A-MSE: 0.13911) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 6 out of 50
train epoch 501 avg loss: 0.12443 (A-MSE: 0.10802) avg lploss: 0.00000
train epoch 502 avg loss: 0.12121 (A-MSE: 0.10544) avg lploss: 0.00000
train epoch 503 avg loss: 0.12304 (A-MSE: 0.10767) avg lploss: 0.00000
train epoch 504 avg loss: 0.11700 (A-MSE: 0.10190) avg lploss: 0.00000
train epoch 505 avg loss: 0.11562 (A-MSE: 0.10122) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.25112 (A-MSE: 0.21030) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.21404 (A-MSE: 0.17954) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 7 out of 50
train epoch 506 avg loss: 0.13344 (A-MSE: 0.11618) avg lploss: 0.00000
train epoch 507 avg loss: 0.13216 (A-MSE: 0.11609) avg lploss: 0.00000
train epoch 508 avg loss: 0.12453 (A-MSE: 0.10969) avg lploss: 0.00000
train epoch 509 avg loss: 0.11965 (A-MSE: 0.10410) avg lploss: 0.00000
train epoch 510 avg loss: 0.11283 (A-MSE: 0.09765) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.20314 (A-MSE: 0.17646) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.15679 (A-MSE: 0.13653) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 8 out of 50
train epoch 511 avg loss: 0.13429 (A-MSE: 0.11737) avg lploss: 0.00000
train epoch 512 avg loss: 0.11864 (A-MSE: 0.10417) avg lploss: 0.00000
train epoch 513 avg loss: 0.13886 (A-MSE: 0.12097) avg lploss: 0.00000
train epoch 514 avg loss: 0.14139 (A-MSE: 0.12329) avg lploss: 0.00000
train epoch 515 avg loss: 0.15016 (A-MSE: 0.13138) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.23301 (A-MSE: 0.19758) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.19740 (A-MSE: 0.16744) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 9 out of 50
train epoch 516 avg loss: 0.13193 (A-MSE: 0.11541) avg lploss: 0.00000
train epoch 517 avg loss: 0.12430 (A-MSE: 0.10860) avg lploss: 0.00000
train epoch 518 avg loss: 0.11199 (A-MSE: 0.09763) avg lploss: 0.00000
train epoch 519 avg loss: 0.11745 (A-MSE: 0.10272) avg lploss: 0.00000
train epoch 520 avg loss: 0.11328 (A-MSE: 0.09853) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.20227 (A-MSE: 0.17018) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.16635 (A-MSE: 0.13969) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 10 out of 50
train epoch 521 avg loss: 0.11354 (A-MSE: 0.09900) avg lploss: 0.00000
train epoch 522 avg loss: 0.11908 (A-MSE: 0.10464) avg lploss: 0.00000
train epoch 523 avg loss: 0.13650 (A-MSE: 0.12002) avg lploss: 0.00000
train epoch 524 avg loss: 0.15517 (A-MSE: 0.13604) avg lploss: 0.00000
train epoch 525 avg loss: 0.13912 (A-MSE: 0.12107) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.18661 (A-MSE: 0.15791) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.16478 (A-MSE: 0.13857) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 11 out of 50
train epoch 526 avg loss: 0.12128 (A-MSE: 0.10537) avg lploss: 0.00000
train epoch 527 avg loss: 0.11457 (A-MSE: 0.10000) avg lploss: 0.00000
train epoch 528 avg loss: 0.11144 (A-MSE: 0.09756) avg lploss: 0.00000
train epoch 529 avg loss: 0.14687 (A-MSE: 0.12645) avg lploss: 0.00000
train epoch 530 avg loss: 0.14209 (A-MSE: 0.12429) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.21678 (A-MSE: 0.18265) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.17165 (A-MSE: 0.14392) avg lploss: 0.00000
*** Best Val Loss: 0.18104 	 Best Test Loss: 0.15659 	 Best epoch 470
EarlyStopping counter: 12 out of 50
train epoch 531 avg loss: 0.12660 (A-MSE: 0.10991) avg lploss: 0.00000
train epoch 532 avg loss: 0.12523 (A-MSE: 0.10935) avg lploss: 0.00000
train epoch 533 avg loss: 0.11457 (A-MSE: 0.09987) avg lploss: 0.00000
train epoch 534 avg loss: 0.11605 (A-MSE: 0.10100) avg lploss: 0.00000
train epoch 535 avg loss: 0.11324 (A-MSE: 0.09849) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.16511 (A-MSE: 0.14233) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.13335 (A-MSE: 0.11465) avg lploss: 0.00000
*** Best Val Loss: 0.16511 	 Best Test Loss: 0.13335 	 Best epoch 535
Validation loss decreased (0.181036 --> 0.165110).  Saving model ...
train epoch 536 avg loss: 0.10708 (A-MSE: 0.09357) avg lploss: 0.00000
train epoch 537 avg loss: 0.11682 (A-MSE: 0.10078) avg lploss: 0.00000
train epoch 538 avg loss: 0.14118 (A-MSE: 0.12343) avg lploss: 0.00000
train epoch 539 avg loss: 0.12707 (A-MSE: 0.11040) avg lploss: 0.00000
train epoch 540 avg loss: 0.12397 (A-MSE: 0.10869) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.18773 (A-MSE: 0.15889) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.15022 (A-MSE: 0.12653) avg lploss: 0.00000
*** Best Val Loss: 0.16511 	 Best Test Loss: 0.13335 	 Best epoch 535
EarlyStopping counter: 1 out of 50
train epoch 541 avg loss: 0.10647 (A-MSE: 0.09268) avg lploss: 0.00000
train epoch 542 avg loss: 0.14376 (A-MSE: 0.12615) avg lploss: 0.00000
train epoch 543 avg loss: 0.12303 (A-MSE: 0.10740) avg lploss: 0.00000
train epoch 544 avg loss: 0.11498 (A-MSE: 0.10090) avg lploss: 0.00000
train epoch 545 avg loss: 0.12768 (A-MSE: 0.11142) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.19819 (A-MSE: 0.16932) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.16190 (A-MSE: 0.13758) avg lploss: 0.00000
*** Best Val Loss: 0.16511 	 Best Test Loss: 0.13335 	 Best epoch 535
EarlyStopping counter: 2 out of 50
train epoch 546 avg loss: 0.11322 (A-MSE: 0.09877) avg lploss: 0.00000
train epoch 547 avg loss: 0.12806 (A-MSE: 0.11148) avg lploss: 0.00000
train epoch 548 avg loss: 0.12399 (A-MSE: 0.10884) avg lploss: 0.00000
train epoch 549 avg loss: 0.11091 (A-MSE: 0.09702) avg lploss: 0.00000
train epoch 550 avg loss: 0.10441 (A-MSE: 0.09135) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.16896 (A-MSE: 0.14600) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.13151 (A-MSE: 0.11281) avg lploss: 0.00000
*** Best Val Loss: 0.16511 	 Best Test Loss: 0.13335 	 Best epoch 535
EarlyStopping counter: 3 out of 50
train epoch 551 avg loss: 0.09694 (A-MSE: 0.08448) avg lploss: 0.00000
train epoch 552 avg loss: 0.09721 (A-MSE: 0.08488) avg lploss: 0.00000
train epoch 553 avg loss: 0.10895 (A-MSE: 0.09477) avg lploss: 0.00000
train epoch 554 avg loss: 0.09958 (A-MSE: 0.08623) avg lploss: 0.00000
train epoch 555 avg loss: 0.10807 (A-MSE: 0.09458) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.16214 (A-MSE: 0.13957) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.12967 (A-MSE: 0.11131) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
Validation loss decreased (0.165110 --> 0.162145).  Saving model ...
train epoch 556 avg loss: 0.10514 (A-MSE: 0.09120) avg lploss: 0.00000
train epoch 557 avg loss: 0.10425 (A-MSE: 0.09127) avg lploss: 0.00000
train epoch 558 avg loss: 0.09667 (A-MSE: 0.08423) avg lploss: 0.00000
train epoch 559 avg loss: 0.10087 (A-MSE: 0.08769) avg lploss: 0.00000
train epoch 560 avg loss: 0.11188 (A-MSE: 0.09676) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.21080 (A-MSE: 0.17599) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.17782 (A-MSE: 0.14819) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 1 out of 50
train epoch 561 avg loss: 0.12657 (A-MSE: 0.10965) avg lploss: 0.00000
train epoch 562 avg loss: 0.12027 (A-MSE: 0.10452) avg lploss: 0.00000
train epoch 563 avg loss: 0.11332 (A-MSE: 0.09860) avg lploss: 0.00000
train epoch 564 avg loss: 0.17052 (A-MSE: 0.14672) avg lploss: 0.00000
train epoch 565 avg loss: 0.14404 (A-MSE: 0.12582) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.20608 (A-MSE: 0.17745) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.17159 (A-MSE: 0.14596) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 2 out of 50
train epoch 566 avg loss: 0.12178 (A-MSE: 0.10654) avg lploss: 0.00000
train epoch 567 avg loss: 0.11655 (A-MSE: 0.10188) avg lploss: 0.00000
train epoch 568 avg loss: 0.11880 (A-MSE: 0.10375) avg lploss: 0.00000
train epoch 569 avg loss: 0.12206 (A-MSE: 0.10652) avg lploss: 0.00000
train epoch 570 avg loss: 0.11714 (A-MSE: 0.10236) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.17534 (A-MSE: 0.15000) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.14705 (A-MSE: 0.12511) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 3 out of 50
train epoch 571 avg loss: 0.10796 (A-MSE: 0.09419) avg lploss: 0.00000
train epoch 572 avg loss: 0.10231 (A-MSE: 0.08924) avg lploss: 0.00000
train epoch 573 avg loss: 0.11801 (A-MSE: 0.10306) avg lploss: 0.00000
train epoch 574 avg loss: 0.12017 (A-MSE: 0.10507) avg lploss: 0.00000
train epoch 575 avg loss: 0.12271 (A-MSE: 0.10665) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.17191 (A-MSE: 0.14766) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.15068 (A-MSE: 0.12919) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 4 out of 50
train epoch 576 avg loss: 0.11708 (A-MSE: 0.10195) avg lploss: 0.00000
train epoch 577 avg loss: 0.11329 (A-MSE: 0.09931) avg lploss: 0.00000
train epoch 578 avg loss: 0.11767 (A-MSE: 0.10272) avg lploss: 0.00000
train epoch 579 avg loss: 0.12407 (A-MSE: 0.10869) avg lploss: 0.00000
train epoch 580 avg loss: 0.11981 (A-MSE: 0.10534) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.22129 (A-MSE: 0.19358) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.16987 (A-MSE: 0.14846) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 5 out of 50
train epoch 581 avg loss: 0.11357 (A-MSE: 0.09904) avg lploss: 0.00000
train epoch 582 avg loss: 0.11028 (A-MSE: 0.09601) avg lploss: 0.00000
train epoch 583 avg loss: 0.13357 (A-MSE: 0.11611) avg lploss: 0.00000
train epoch 584 avg loss: 0.11538 (A-MSE: 0.10002) avg lploss: 0.00000
train epoch 585 avg loss: 0.10213 (A-MSE: 0.08910) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.20912 (A-MSE: 0.17923) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.16974 (A-MSE: 0.14450) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 6 out of 50
train epoch 586 avg loss: 0.10265 (A-MSE: 0.09009) avg lploss: 0.00000
train epoch 587 avg loss: 0.12014 (A-MSE: 0.10485) avg lploss: 0.00000
train epoch 588 avg loss: 0.11727 (A-MSE: 0.10197) avg lploss: 0.00000
train epoch 589 avg loss: 0.09625 (A-MSE: 0.08427) avg lploss: 0.00000
train epoch 590 avg loss: 0.10084 (A-MSE: 0.08770) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.16520 (A-MSE: 0.14188) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.13216 (A-MSE: 0.11263) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 7 out of 50
train epoch 591 avg loss: 0.11088 (A-MSE: 0.09667) avg lploss: 0.00000
train epoch 592 avg loss: 0.11144 (A-MSE: 0.09685) avg lploss: 0.00000
train epoch 593 avg loss: 0.11194 (A-MSE: 0.09803) avg lploss: 0.00000
train epoch 594 avg loss: 0.09887 (A-MSE: 0.08657) avg lploss: 0.00000
train epoch 595 avg loss: 0.10493 (A-MSE: 0.09172) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.17339 (A-MSE: 0.14914) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.14289 (A-MSE: 0.12253) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 8 out of 50
train epoch 596 avg loss: 0.10280 (A-MSE: 0.08919) avg lploss: 0.00000
train epoch 597 avg loss: 0.10132 (A-MSE: 0.08894) avg lploss: 0.00000
train epoch 598 avg loss: 0.10167 (A-MSE: 0.08906) avg lploss: 0.00000
train epoch 599 avg loss: 0.13223 (A-MSE: 0.11553) avg lploss: 0.00000
train epoch 600 avg loss: 0.10888 (A-MSE: 0.09542) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.19192 (A-MSE: 0.16379) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.15591 (A-MSE: 0.13309) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 9 out of 50
train epoch 601 avg loss: 0.10733 (A-MSE: 0.09308) avg lploss: 0.00000
train epoch 602 avg loss: 0.10733 (A-MSE: 0.09436) avg lploss: 0.00000
train epoch 603 avg loss: 0.11368 (A-MSE: 0.09916) avg lploss: 0.00000
train epoch 604 avg loss: 0.11327 (A-MSE: 0.09872) avg lploss: 0.00000
train epoch 605 avg loss: 0.12651 (A-MSE: 0.10947) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.25070 (A-MSE: 0.21015) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.22305 (A-MSE: 0.18608) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 10 out of 50
train epoch 606 avg loss: 0.17360 (A-MSE: 0.15113) avg lploss: 0.00000
train epoch 607 avg loss: 0.14555 (A-MSE: 0.12754) avg lploss: 0.00000
train epoch 608 avg loss: 0.12759 (A-MSE: 0.11197) avg lploss: 0.00000
train epoch 609 avg loss: 0.15463 (A-MSE: 0.13559) avg lploss: 0.00000
train epoch 610 avg loss: 0.13284 (A-MSE: 0.11614) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.16969 (A-MSE: 0.14613) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.13838 (A-MSE: 0.11900) avg lploss: 0.00000
*** Best Val Loss: 0.16214 	 Best Test Loss: 0.12967 	 Best epoch 555
EarlyStopping counter: 11 out of 50
train epoch 611 avg loss: 0.11896 (A-MSE: 0.10323) avg lploss: 0.00000
train epoch 612 avg loss: 0.12261 (A-MSE: 0.10631) avg lploss: 0.00000
train epoch 613 avg loss: 0.11108 (A-MSE: 0.09724) avg lploss: 0.00000
train epoch 614 avg loss: 0.09992 (A-MSE: 0.08717) avg lploss: 0.00000
train epoch 615 avg loss: 0.09622 (A-MSE: 0.08380) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.14900 (A-MSE: 0.12638) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.12319 (A-MSE: 0.10442) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
Validation loss decreased (0.162145 --> 0.149003).  Saving model ...
train epoch 616 avg loss: 0.10093 (A-MSE: 0.08774) avg lploss: 0.00000
train epoch 617 avg loss: 0.10985 (A-MSE: 0.09572) avg lploss: 0.00000
train epoch 618 avg loss: 0.12198 (A-MSE: 0.10731) avg lploss: 0.00000
train epoch 619 avg loss: 0.11003 (A-MSE: 0.09466) avg lploss: 0.00000
train epoch 620 avg loss: 0.10711 (A-MSE: 0.09323) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.18434 (A-MSE: 0.15976) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.15277 (A-MSE: 0.13168) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.10685 (A-MSE: 0.09321) avg lploss: 0.00000
train epoch 622 avg loss: 0.10264 (A-MSE: 0.08921) avg lploss: 0.00000
train epoch 623 avg loss: 0.10278 (A-MSE: 0.08916) avg lploss: 0.00000
train epoch 624 avg loss: 0.09865 (A-MSE: 0.08525) avg lploss: 0.00000
train epoch 625 avg loss: 0.11919 (A-MSE: 0.10341) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.18566 (A-MSE: 0.15967) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.15709 (A-MSE: 0.13451) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.09695 (A-MSE: 0.08472) avg lploss: 0.00000
train epoch 627 avg loss: 0.10096 (A-MSE: 0.08806) avg lploss: 0.00000
train epoch 628 avg loss: 0.09404 (A-MSE: 0.08185) avg lploss: 0.00000
train epoch 629 avg loss: 0.09586 (A-MSE: 0.08399) avg lploss: 0.00000
train epoch 630 avg loss: 0.11071 (A-MSE: 0.09643) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.17792 (A-MSE: 0.15526) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.14883 (A-MSE: 0.12983) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 3 out of 50
train epoch 631 avg loss: 0.10180 (A-MSE: 0.08906) avg lploss: 0.00000
train epoch 632 avg loss: 0.09592 (A-MSE: 0.08414) avg lploss: 0.00000
train epoch 633 avg loss: 0.09806 (A-MSE: 0.08583) avg lploss: 0.00000
train epoch 634 avg loss: 0.09649 (A-MSE: 0.08394) avg lploss: 0.00000
train epoch 635 avg loss: 0.10958 (A-MSE: 0.09558) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.18591 (A-MSE: 0.15822) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.15021 (A-MSE: 0.12671) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 4 out of 50
train epoch 636 avg loss: 0.10215 (A-MSE: 0.08955) avg lploss: 0.00000
train epoch 637 avg loss: 0.09600 (A-MSE: 0.08330) avg lploss: 0.00000
train epoch 638 avg loss: 0.10521 (A-MSE: 0.09128) avg lploss: 0.00000
train epoch 639 avg loss: 0.09852 (A-MSE: 0.08563) avg lploss: 0.00000
train epoch 640 avg loss: 0.11352 (A-MSE: 0.09892) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.16910 (A-MSE: 0.14845) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.14505 (A-MSE: 0.12685) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 5 out of 50
train epoch 641 avg loss: 0.09640 (A-MSE: 0.08391) avg lploss: 0.00000
train epoch 642 avg loss: 1.29563 (A-MSE: 1.14870) avg lploss: 0.00000
train epoch 643 avg loss: 1.53944 (A-MSE: 1.33059) avg lploss: 0.00000
train epoch 644 avg loss: 0.86035 (A-MSE: 0.75953) avg lploss: 0.00000
train epoch 645 avg loss: 0.64565 (A-MSE: 0.56230) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.79654 (A-MSE: 0.66128) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.74472 (A-MSE: 0.62110) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 6 out of 50
train epoch 646 avg loss: 0.54930 (A-MSE: 0.48530) avg lploss: 0.00000
train epoch 647 avg loss: 0.36088 (A-MSE: 0.31647) avg lploss: 0.00000
train epoch 648 avg loss: 0.27784 (A-MSE: 0.24358) avg lploss: 0.00000
train epoch 649 avg loss: 0.23506 (A-MSE: 0.20541) avg lploss: 0.00000
train epoch 650 avg loss: 0.20481 (A-MSE: 0.17822) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.23653 (A-MSE: 0.20232) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.21521 (A-MSE: 0.18610) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 7 out of 50
train epoch 651 avg loss: 0.19112 (A-MSE: 0.16651) avg lploss: 0.00000
train epoch 652 avg loss: 0.22414 (A-MSE: 0.19638) avg lploss: 0.00000
train epoch 653 avg loss: 0.20649 (A-MSE: 0.18044) avg lploss: 0.00000
train epoch 654 avg loss: 0.17886 (A-MSE: 0.15509) avg lploss: 0.00000
train epoch 655 avg loss: 0.16609 (A-MSE: 0.14405) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.22688 (A-MSE: 0.19025) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.20689 (A-MSE: 0.17490) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 8 out of 50
train epoch 656 avg loss: 0.19193 (A-MSE: 0.16769) avg lploss: 0.00000
train epoch 657 avg loss: 0.16591 (A-MSE: 0.14498) avg lploss: 0.00000
train epoch 658 avg loss: 0.16632 (A-MSE: 0.14564) avg lploss: 0.00000
train epoch 659 avg loss: 0.14568 (A-MSE: 0.12675) avg lploss: 0.00000
train epoch 660 avg loss: 0.14736 (A-MSE: 0.12916) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.19557 (A-MSE: 0.16333) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.16548 (A-MSE: 0.13909) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 9 out of 50
train epoch 661 avg loss: 0.13467 (A-MSE: 0.11762) avg lploss: 0.00000
train epoch 662 avg loss: 0.13450 (A-MSE: 0.11674) avg lploss: 0.00000
train epoch 663 avg loss: 0.12342 (A-MSE: 0.10748) avg lploss: 0.00000
train epoch 664 avg loss: 0.12220 (A-MSE: 0.10666) avg lploss: 0.00000
train epoch 665 avg loss: 0.13137 (A-MSE: 0.11489) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.16525 (A-MSE: 0.13956) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.13304 (A-MSE: 0.11272) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 10 out of 50
train epoch 666 avg loss: 0.12596 (A-MSE: 0.10989) avg lploss: 0.00000
train epoch 667 avg loss: 0.13644 (A-MSE: 0.11904) avg lploss: 0.00000
train epoch 668 avg loss: 0.14664 (A-MSE: 0.12648) avg lploss: 0.00000
train epoch 669 avg loss: 0.14049 (A-MSE: 0.12361) avg lploss: 0.00000
train epoch 670 avg loss: 0.12633 (A-MSE: 0.10911) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.16800 (A-MSE: 0.14173) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.14061 (A-MSE: 0.11941) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 11 out of 50
train epoch 671 avg loss: 0.11499 (A-MSE: 0.09999) avg lploss: 0.00000
train epoch 672 avg loss: 0.12631 (A-MSE: 0.11063) avg lploss: 0.00000
train epoch 673 avg loss: 0.13984 (A-MSE: 0.12184) avg lploss: 0.00000
train epoch 674 avg loss: 0.12332 (A-MSE: 0.10742) avg lploss: 0.00000
train epoch 675 avg loss: 0.12120 (A-MSE: 0.10626) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.16376 (A-MSE: 0.13939) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.14400 (A-MSE: 0.12283) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 12 out of 50
train epoch 676 avg loss: 0.12078 (A-MSE: 0.10503) avg lploss: 0.00000
train epoch 677 avg loss: 0.12229 (A-MSE: 0.10692) avg lploss: 0.00000
train epoch 678 avg loss: 0.10751 (A-MSE: 0.09345) avg lploss: 0.00000
train epoch 679 avg loss: 0.09999 (A-MSE: 0.08672) avg lploss: 0.00000
train epoch 680 avg loss: 0.10919 (A-MSE: 0.09522) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.16848 (A-MSE: 0.14669) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.13576 (A-MSE: 0.11928) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 13 out of 50
train epoch 681 avg loss: 0.12380 (A-MSE: 0.10828) avg lploss: 0.00000
train epoch 682 avg loss: 0.10905 (A-MSE: 0.09513) avg lploss: 0.00000
train epoch 683 avg loss: 0.10356 (A-MSE: 0.09052) avg lploss: 0.00000
train epoch 684 avg loss: 0.10411 (A-MSE: 0.09121) avg lploss: 0.00000
train epoch 685 avg loss: 0.10126 (A-MSE: 0.08850) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.17428 (A-MSE: 0.14792) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.14533 (A-MSE: 0.12384) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 14 out of 50
train epoch 686 avg loss: 0.11069 (A-MSE: 0.09657) avg lploss: 0.00000
train epoch 687 avg loss: 0.10314 (A-MSE: 0.09009) avg lploss: 0.00000
train epoch 688 avg loss: 0.12269 (A-MSE: 0.10747) avg lploss: 0.00000
train epoch 689 avg loss: 0.11898 (A-MSE: 0.10398) avg lploss: 0.00000
train epoch 690 avg loss: 0.16225 (A-MSE: 0.14161) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.21848 (A-MSE: 0.18734) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.18453 (A-MSE: 0.15940) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 15 out of 50
train epoch 691 avg loss: 0.14330 (A-MSE: 0.12401) avg lploss: 0.00000
train epoch 692 avg loss: 0.11734 (A-MSE: 0.10212) avg lploss: 0.00000
train epoch 693 avg loss: 0.10451 (A-MSE: 0.09124) avg lploss: 0.00000
train epoch 694 avg loss: 0.12485 (A-MSE: 0.10937) avg lploss: 0.00000
train epoch 695 avg loss: 0.12169 (A-MSE: 0.10626) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.18715 (A-MSE: 0.15799) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.15338 (A-MSE: 0.12939) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 16 out of 50
train epoch 696 avg loss: 0.10767 (A-MSE: 0.09438) avg lploss: 0.00000
train epoch 697 avg loss: 0.10123 (A-MSE: 0.08823) avg lploss: 0.00000
train epoch 698 avg loss: 0.09917 (A-MSE: 0.08638) avg lploss: 0.00000
train epoch 699 avg loss: 0.09751 (A-MSE: 0.08506) avg lploss: 0.00000
train epoch 700 avg loss: 0.10011 (A-MSE: 0.08740) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.15227 (A-MSE: 0.12958) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.12355 (A-MSE: 0.10538) avg lploss: 0.00000
*** Best Val Loss: 0.14900 	 Best Test Loss: 0.12319 	 Best epoch 615
EarlyStopping counter: 17 out of 50
train epoch 701 avg loss: 0.09052 (A-MSE: 0.07931) avg lploss: 0.00000
train epoch 702 avg loss: 0.09690 (A-MSE: 0.08576) avg lploss: 0.00000
train epoch 703 avg loss: 0.10120 (A-MSE: 0.08866) avg lploss: 0.00000
train epoch 704 avg loss: 0.10809 (A-MSE: 0.09525) avg lploss: 0.00000
train epoch 705 avg loss: 0.11096 (A-MSE: 0.09661) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.14574 (A-MSE: 0.12713) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.11873 (A-MSE: 0.10387) avg lploss: 0.00000
*** Best Val Loss: 0.14574 	 Best Test Loss: 0.11873 	 Best epoch 705
Validation loss decreased (0.149003 --> 0.145745).  Saving model ...
train epoch 706 avg loss: 0.09965 (A-MSE: 0.08799) avg lploss: 0.00000
train epoch 707 avg loss: 0.09348 (A-MSE: 0.08138) avg lploss: 0.00000
train epoch 708 avg loss: 0.09098 (A-MSE: 0.07973) avg lploss: 0.00000
train epoch 709 avg loss: 0.08919 (A-MSE: 0.07794) avg lploss: 0.00000
train epoch 710 avg loss: 0.09938 (A-MSE: 0.08633) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.16097 (A-MSE: 0.13739) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.13012 (A-MSE: 0.11099) avg lploss: 0.00000
*** Best Val Loss: 0.14574 	 Best Test Loss: 0.11873 	 Best epoch 705
EarlyStopping counter: 1 out of 50
train epoch 711 avg loss: 0.09893 (A-MSE: 0.08649) avg lploss: 0.00000
train epoch 712 avg loss: 0.08650 (A-MSE: 0.07563) avg lploss: 0.00000
train epoch 713 avg loss: 0.09274 (A-MSE: 0.08138) avg lploss: 0.00000
train epoch 714 avg loss: 0.08927 (A-MSE: 0.07823) avg lploss: 0.00000
train epoch 715 avg loss: 0.09061 (A-MSE: 0.07936) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.16565 (A-MSE: 0.14170) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.13383 (A-MSE: 0.11463) avg lploss: 0.00000
*** Best Val Loss: 0.14574 	 Best Test Loss: 0.11873 	 Best epoch 705
EarlyStopping counter: 2 out of 50
train epoch 716 avg loss: 0.08517 (A-MSE: 0.07421) avg lploss: 0.00000
train epoch 717 avg loss: 0.08632 (A-MSE: 0.07563) avg lploss: 0.00000
train epoch 718 avg loss: 0.08551 (A-MSE: 0.07520) avg lploss: 0.00000
train epoch 719 avg loss: 0.09367 (A-MSE: 0.08201) avg lploss: 0.00000
train epoch 720 avg loss: 0.09490 (A-MSE: 0.08271) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.16948 (A-MSE: 0.14486) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.13823 (A-MSE: 0.11841) avg lploss: 0.00000
*** Best Val Loss: 0.14574 	 Best Test Loss: 0.11873 	 Best epoch 705
EarlyStopping counter: 3 out of 50
train epoch 721 avg loss: 0.09464 (A-MSE: 0.08246) avg lploss: 0.00000
train epoch 722 avg loss: 0.09710 (A-MSE: 0.08530) avg lploss: 0.00000
train epoch 723 avg loss: 0.09518 (A-MSE: 0.08402) avg lploss: 0.00000
train epoch 724 avg loss: 0.08904 (A-MSE: 0.07764) avg lploss: 0.00000
train epoch 725 avg loss: 0.08274 (A-MSE: 0.07222) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.14050 (A-MSE: 0.12020) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.11635 (A-MSE: 0.09926) avg lploss: 0.00000
*** Best Val Loss: 0.14050 	 Best Test Loss: 0.11635 	 Best epoch 725
Validation loss decreased (0.145745 --> 0.140502).  Saving model ...
train epoch 726 avg loss: 0.09966 (A-MSE: 0.08683) avg lploss: 0.00000
train epoch 727 avg loss: 0.08846 (A-MSE: 0.07772) avg lploss: 0.00000
train epoch 728 avg loss: 0.09997 (A-MSE: 0.08704) avg lploss: 0.00000
train epoch 729 avg loss: 0.09893 (A-MSE: 0.08704) avg lploss: 0.00000
train epoch 730 avg loss: 0.10173 (A-MSE: 0.08924) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.18341 (A-MSE: 0.15714) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.15388 (A-MSE: 0.13163) avg lploss: 0.00000
*** Best Val Loss: 0.14050 	 Best Test Loss: 0.11635 	 Best epoch 725
EarlyStopping counter: 1 out of 50
train epoch 731 avg loss: 0.09752 (A-MSE: 0.08531) avg lploss: 0.00000
train epoch 732 avg loss: 0.08347 (A-MSE: 0.07292) avg lploss: 0.00000
train epoch 733 avg loss: 0.08384 (A-MSE: 0.07327) avg lploss: 0.00000
train epoch 734 avg loss: 0.09549 (A-MSE: 0.08374) avg lploss: 0.00000
train epoch 735 avg loss: 0.08556 (A-MSE: 0.07436) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.14215 (A-MSE: 0.12200) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.11122 (A-MSE: 0.09520) avg lploss: 0.00000
*** Best Val Loss: 0.14050 	 Best Test Loss: 0.11635 	 Best epoch 725
EarlyStopping counter: 2 out of 50
train epoch 736 avg loss: 0.07936 (A-MSE: 0.06947) avg lploss: 0.00000
train epoch 737 avg loss: 0.07923 (A-MSE: 0.06978) avg lploss: 0.00000
train epoch 738 avg loss: 0.07919 (A-MSE: 0.06927) avg lploss: 0.00000
train epoch 739 avg loss: 0.08258 (A-MSE: 0.07202) avg lploss: 0.00000
train epoch 740 avg loss: 0.08024 (A-MSE: 0.07005) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.14909 (A-MSE: 0.12903) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.11667 (A-MSE: 0.10006) avg lploss: 0.00000
*** Best Val Loss: 0.14050 	 Best Test Loss: 0.11635 	 Best epoch 725
EarlyStopping counter: 3 out of 50
train epoch 741 avg loss: 0.08255 (A-MSE: 0.07205) avg lploss: 0.00000
train epoch 742 avg loss: 0.08519 (A-MSE: 0.07483) avg lploss: 0.00000
train epoch 743 avg loss: 0.08225 (A-MSE: 0.07188) avg lploss: 0.00000
train epoch 744 avg loss: 0.07792 (A-MSE: 0.06808) avg lploss: 0.00000
train epoch 745 avg loss: 0.08755 (A-MSE: 0.07617) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.18747 (A-MSE: 0.15963) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.15067 (A-MSE: 0.12750) avg lploss: 0.00000
*** Best Val Loss: 0.14050 	 Best Test Loss: 0.11635 	 Best epoch 725
EarlyStopping counter: 4 out of 50
train epoch 746 avg loss: 0.09313 (A-MSE: 0.08144) avg lploss: 0.00000
train epoch 747 avg loss: 0.09578 (A-MSE: 0.08390) avg lploss: 0.00000
train epoch 748 avg loss: 0.08198 (A-MSE: 0.07103) avg lploss: 0.00000
train epoch 749 avg loss: 0.07996 (A-MSE: 0.06980) avg lploss: 0.00000
train epoch 750 avg loss: 0.07811 (A-MSE: 0.06812) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.13949 (A-MSE: 0.12030) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.10548 (A-MSE: 0.09050) avg lploss: 0.00000
*** Best Val Loss: 0.13949 	 Best Test Loss: 0.10548 	 Best epoch 750
Validation loss decreased (0.140502 --> 0.139493).  Saving model ...
train epoch 751 avg loss: 0.08089 (A-MSE: 0.07068) avg lploss: 0.00000
train epoch 752 avg loss: 0.08912 (A-MSE: 0.07777) avg lploss: 0.00000
train epoch 753 avg loss: 0.07071 (A-MSE: 0.06231) avg lploss: 0.00000
train epoch 754 avg loss: 0.09496 (A-MSE: 0.08349) avg lploss: 0.00000
train epoch 755 avg loss: 0.08156 (A-MSE: 0.07081) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.13568 (A-MSE: 0.11918) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.11007 (A-MSE: 0.09660) avg lploss: 0.00000
*** Best Val Loss: 0.13568 	 Best Test Loss: 0.11007 	 Best epoch 755
Validation loss decreased (0.139493 --> 0.135683).  Saving model ...
train epoch 756 avg loss: 0.08082 (A-MSE: 0.07108) avg lploss: 0.00000
train epoch 757 avg loss: 0.09267 (A-MSE: 0.08086) avg lploss: 0.00000
train epoch 758 avg loss: 0.09023 (A-MSE: 0.07879) avg lploss: 0.00000
train epoch 759 avg loss: 0.09143 (A-MSE: 0.07966) avg lploss: 0.00000
train epoch 760 avg loss: 0.08924 (A-MSE: 0.07770) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.13700 (A-MSE: 0.11974) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.11139 (A-MSE: 0.09673) avg lploss: 0.00000
*** Best Val Loss: 0.13568 	 Best Test Loss: 0.11007 	 Best epoch 755
EarlyStopping counter: 1 out of 50
train epoch 761 avg loss: 0.10210 (A-MSE: 0.08968) avg lploss: 0.00000
train epoch 762 avg loss: 0.08574 (A-MSE: 0.07542) avg lploss: 0.00000
train epoch 763 avg loss: 0.07446 (A-MSE: 0.06530) avg lploss: 0.00000
train epoch 764 avg loss: 0.08153 (A-MSE: 0.07105) avg lploss: 0.00000
train epoch 765 avg loss: 0.08291 (A-MSE: 0.07232) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.13362 (A-MSE: 0.11670) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.09987 (A-MSE: 0.08653) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
Validation loss decreased (0.135683 --> 0.133619).  Saving model ...
train epoch 766 avg loss: 0.08622 (A-MSE: 0.07559) avg lploss: 0.00000
train epoch 767 avg loss: 0.09346 (A-MSE: 0.08167) avg lploss: 0.00000
train epoch 768 avg loss: 0.09694 (A-MSE: 0.08482) avg lploss: 0.00000
train epoch 769 avg loss: 0.08586 (A-MSE: 0.07542) avg lploss: 0.00000
train epoch 770 avg loss: 0.09287 (A-MSE: 0.08090) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.13905 (A-MSE: 0.11781) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.11555 (A-MSE: 0.09720) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 1 out of 50
train epoch 771 avg loss: 0.07579 (A-MSE: 0.06626) avg lploss: 0.00000
train epoch 772 avg loss: 0.07634 (A-MSE: 0.06720) avg lploss: 0.00000
train epoch 773 avg loss: 0.08895 (A-MSE: 0.07797) avg lploss: 0.00000
train epoch 774 avg loss: 0.09349 (A-MSE: 0.08150) avg lploss: 0.00000
train epoch 775 avg loss: 0.07771 (A-MSE: 0.06812) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.13614 (A-MSE: 0.11789) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.10392 (A-MSE: 0.08963) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 2 out of 50
train epoch 776 avg loss: 0.07776 (A-MSE: 0.06795) avg lploss: 0.00000
train epoch 777 avg loss: 0.07308 (A-MSE: 0.06427) avg lploss: 0.00000
train epoch 778 avg loss: 0.09618 (A-MSE: 0.08432) avg lploss: 0.00000
train epoch 779 avg loss: 0.09252 (A-MSE: 0.08110) avg lploss: 0.00000
train epoch 780 avg loss: 0.09003 (A-MSE: 0.07833) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.13964 (A-MSE: 0.12226) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.10680 (A-MSE: 0.09308) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 3 out of 50
train epoch 781 avg loss: 0.08448 (A-MSE: 0.07451) avg lploss: 0.00000
train epoch 782 avg loss: 0.08616 (A-MSE: 0.07508) avg lploss: 0.00000
train epoch 783 avg loss: 0.08315 (A-MSE: 0.07236) avg lploss: 0.00000
train epoch 784 avg loss: 0.07768 (A-MSE: 0.06789) avg lploss: 0.00000
train epoch 785 avg loss: 0.07379 (A-MSE: 0.06451) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.14034 (A-MSE: 0.12104) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.11416 (A-MSE: 0.09789) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 4 out of 50
train epoch 786 avg loss: 0.07594 (A-MSE: 0.06632) avg lploss: 0.00000
train epoch 787 avg loss: 0.08204 (A-MSE: 0.07190) avg lploss: 0.00000
train epoch 788 avg loss: 0.08044 (A-MSE: 0.07069) avg lploss: 0.00000
train epoch 789 avg loss: 0.07494 (A-MSE: 0.06562) avg lploss: 0.00000
train epoch 790 avg loss: 0.08529 (A-MSE: 0.07463) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.14453 (A-MSE: 0.12549) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.11750 (A-MSE: 0.10183) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 5 out of 50
train epoch 791 avg loss: 0.08770 (A-MSE: 0.07686) avg lploss: 0.00000
train epoch 792 avg loss: 0.08242 (A-MSE: 0.07212) avg lploss: 0.00000
train epoch 793 avg loss: 0.08399 (A-MSE: 0.07303) avg lploss: 0.00000
train epoch 794 avg loss: 0.09761 (A-MSE: 0.08562) avg lploss: 0.00000
train epoch 795 avg loss: 0.08598 (A-MSE: 0.07582) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.14213 (A-MSE: 0.12103) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.11110 (A-MSE: 0.09306) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 6 out of 50
train epoch 796 avg loss: 0.08023 (A-MSE: 0.07046) avg lploss: 0.00000
train epoch 797 avg loss: 0.07403 (A-MSE: 0.06499) avg lploss: 0.00000
train epoch 798 avg loss: 0.07700 (A-MSE: 0.06704) avg lploss: 0.00000
train epoch 799 avg loss: 0.07433 (A-MSE: 0.06566) avg lploss: 0.00000
train epoch 800 avg loss: 0.07900 (A-MSE: 0.06918) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.14133 (A-MSE: 0.12183) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.11436 (A-MSE: 0.09803) avg lploss: 0.00000
*** Best Val Loss: 0.13362 	 Best Test Loss: 0.09987 	 Best epoch 765
EarlyStopping counter: 7 out of 50
train epoch 801 avg loss: 0.07943 (A-MSE: 0.06981) avg lploss: 0.00000
train epoch 802 avg loss: 0.08145 (A-MSE: 0.07169) avg lploss: 0.00000
train epoch 803 avg loss: 0.08885 (A-MSE: 0.07809) avg lploss: 0.00000
train epoch 804 avg loss: 0.07696 (A-MSE: 0.06773) avg lploss: 0.00000
train epoch 805 avg loss: 0.07345 (A-MSE: 0.06491) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.12560 (A-MSE: 0.10991) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.09293 (A-MSE: 0.08039) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
Validation loss decreased (0.133619 --> 0.125600).  Saving model ...
train epoch 806 avg loss: 0.06932 (A-MSE: 0.06055) avg lploss: 0.00000
train epoch 807 avg loss: 0.06890 (A-MSE: 0.06032) avg lploss: 0.00000
train epoch 808 avg loss: 0.07735 (A-MSE: 0.06733) avg lploss: 0.00000
train epoch 809 avg loss: 0.06769 (A-MSE: 0.05945) avg lploss: 0.00000
train epoch 810 avg loss: 0.08875 (A-MSE: 0.07799) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.14728 (A-MSE: 0.12856) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.11525 (A-MSE: 0.10001) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 1 out of 50
train epoch 811 avg loss: 0.07949 (A-MSE: 0.06936) avg lploss: 0.00000
train epoch 812 avg loss: 0.06986 (A-MSE: 0.06105) avg lploss: 0.00000
train epoch 813 avg loss: 0.07332 (A-MSE: 0.06437) avg lploss: 0.00000
train epoch 814 avg loss: 0.07400 (A-MSE: 0.06485) avg lploss: 0.00000
train epoch 815 avg loss: 0.07820 (A-MSE: 0.06835) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.14406 (A-MSE: 0.12472) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.10880 (A-MSE: 0.09412) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 2 out of 50
train epoch 816 avg loss: 0.07509 (A-MSE: 0.06567) avg lploss: 0.00000
train epoch 817 avg loss: 0.07377 (A-MSE: 0.06484) avg lploss: 0.00000
train epoch 818 avg loss: 0.07722 (A-MSE: 0.06760) avg lploss: 0.00000
train epoch 819 avg loss: 0.07530 (A-MSE: 0.06644) avg lploss: 0.00000
train epoch 820 avg loss: 0.07328 (A-MSE: 0.06418) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.15732 (A-MSE: 0.13755) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.11963 (A-MSE: 0.10364) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 3 out of 50
train epoch 821 avg loss: 0.08108 (A-MSE: 0.07108) avg lploss: 0.00000
train epoch 822 avg loss: 0.09211 (A-MSE: 0.08112) avg lploss: 0.00000
train epoch 823 avg loss: 0.08282 (A-MSE: 0.07260) avg lploss: 0.00000
train epoch 824 avg loss: 0.09682 (A-MSE: 0.08504) avg lploss: 0.00000
train epoch 825 avg loss: 0.09037 (A-MSE: 0.07961) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.12833 (A-MSE: 0.11123) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.10019 (A-MSE: 0.08624) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 4 out of 50
train epoch 826 avg loss: 0.07937 (A-MSE: 0.06997) avg lploss: 0.00000
train epoch 827 avg loss: 0.07915 (A-MSE: 0.06899) avg lploss: 0.00000
train epoch 828 avg loss: 0.08113 (A-MSE: 0.07090) avg lploss: 0.00000
train epoch 829 avg loss: 0.08983 (A-MSE: 0.07835) avg lploss: 0.00000
train epoch 830 avg loss: 0.07827 (A-MSE: 0.06829) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.14388 (A-MSE: 0.12656) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.11454 (A-MSE: 0.10072) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 5 out of 50
train epoch 831 avg loss: 0.07912 (A-MSE: 0.06896) avg lploss: 0.00000
train epoch 832 avg loss: 0.06810 (A-MSE: 0.05967) avg lploss: 0.00000
train epoch 833 avg loss: 0.07739 (A-MSE: 0.06760) avg lploss: 0.00000
train epoch 834 avg loss: 0.07125 (A-MSE: 0.06243) avg lploss: 0.00000
train epoch 835 avg loss: 0.07704 (A-MSE: 0.06763) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.16849 (A-MSE: 0.14373) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.13680 (A-MSE: 0.11593) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 6 out of 50
train epoch 836 avg loss: 0.06672 (A-MSE: 0.05871) avg lploss: 0.00000
train epoch 837 avg loss: 0.06600 (A-MSE: 0.05758) avg lploss: 0.00000
train epoch 838 avg loss: 0.06350 (A-MSE: 0.05573) avg lploss: 0.00000
train epoch 839 avg loss: 0.06749 (A-MSE: 0.05903) avg lploss: 0.00000
train epoch 840 avg loss: 0.07926 (A-MSE: 0.06958) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.20427 (A-MSE: 0.17198) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.17361 (A-MSE: 0.14537) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 7 out of 50
train epoch 841 avg loss: 0.08436 (A-MSE: 0.07312) avg lploss: 0.00000
train epoch 842 avg loss: 0.07608 (A-MSE: 0.06715) avg lploss: 0.00000
train epoch 843 avg loss: 0.07008 (A-MSE: 0.06134) avg lploss: 0.00000
train epoch 844 avg loss: 0.06559 (A-MSE: 0.05754) avg lploss: 0.00000
train epoch 845 avg loss: 0.09653 (A-MSE: 0.08504) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.17368 (A-MSE: 0.15167) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.13883 (A-MSE: 0.12052) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 8 out of 50
train epoch 846 avg loss: 0.09282 (A-MSE: 0.08107) avg lploss: 0.00000
train epoch 847 avg loss: 0.07690 (A-MSE: 0.06726) avg lploss: 0.00000
train epoch 848 avg loss: 0.08132 (A-MSE: 0.07096) avg lploss: 0.00000
train epoch 849 avg loss: 0.07208 (A-MSE: 0.06332) avg lploss: 0.00000
train epoch 850 avg loss: 0.08164 (A-MSE: 0.07116) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.13161 (A-MSE: 0.11284) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.10071 (A-MSE: 0.08555) avg lploss: 0.00000
*** Best Val Loss: 0.12560 	 Best Test Loss: 0.09293 	 Best epoch 805
EarlyStopping counter: 9 out of 50
train epoch 851 avg loss: 0.06797 (A-MSE: 0.05935) avg lploss: 0.00000
train epoch 852 avg loss: 0.06792 (A-MSE: 0.05957) avg lploss: 0.00000
train epoch 853 avg loss: 0.07215 (A-MSE: 0.06312) avg lploss: 0.00000
train epoch 854 avg loss: 0.07166 (A-MSE: 0.06248) avg lploss: 0.00000
train epoch 855 avg loss: 0.07065 (A-MSE: 0.06208) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.11726 (A-MSE: 0.10273) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.09214 (A-MSE: 0.08078) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
Validation loss decreased (0.125600 --> 0.117255).  Saving model ...
train epoch 856 avg loss: 0.07431 (A-MSE: 0.06489) avg lploss: 0.00000
train epoch 857 avg loss: 0.07182 (A-MSE: 0.06280) avg lploss: 0.00000
train epoch 858 avg loss: 0.07471 (A-MSE: 0.06522) avg lploss: 0.00000
train epoch 859 avg loss: 0.07951 (A-MSE: 0.06948) avg lploss: 0.00000
train epoch 860 avg loss: 0.06638 (A-MSE: 0.05839) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.13239 (A-MSE: 0.11512) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.09932 (A-MSE: 0.08571) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 1 out of 50
train epoch 861 avg loss: 0.07698 (A-MSE: 0.06787) avg lploss: 0.00000
train epoch 862 avg loss: 0.07002 (A-MSE: 0.06114) avg lploss: 0.00000
train epoch 863 avg loss: 0.07297 (A-MSE: 0.06402) avg lploss: 0.00000
train epoch 864 avg loss: 0.06992 (A-MSE: 0.06142) avg lploss: 0.00000
train epoch 865 avg loss: 0.07558 (A-MSE: 0.06648) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.11899 (A-MSE: 0.10399) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.09248 (A-MSE: 0.07978) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 2 out of 50
train epoch 866 avg loss: 0.07000 (A-MSE: 0.06107) avg lploss: 0.00000
train epoch 867 avg loss: 0.06378 (A-MSE: 0.05559) avg lploss: 0.00000
train epoch 868 avg loss: 0.06549 (A-MSE: 0.05738) avg lploss: 0.00000
train epoch 869 avg loss: 0.06765 (A-MSE: 0.05953) avg lploss: 0.00000
train epoch 870 avg loss: 0.06463 (A-MSE: 0.05676) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.12352 (A-MSE: 0.10852) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.09317 (A-MSE: 0.08143) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 3 out of 50
train epoch 871 avg loss: 0.06351 (A-MSE: 0.05565) avg lploss: 0.00000
train epoch 872 avg loss: 0.07077 (A-MSE: 0.06192) avg lploss: 0.00000
train epoch 873 avg loss: 0.07512 (A-MSE: 0.06609) avg lploss: 0.00000
train epoch 874 avg loss: 0.08575 (A-MSE: 0.07548) avg lploss: 0.00000
train epoch 875 avg loss: 0.07947 (A-MSE: 0.06952) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.15410 (A-MSE: 0.13013) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.11923 (A-MSE: 0.09960) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 4 out of 50
train epoch 876 avg loss: 0.07151 (A-MSE: 0.06214) avg lploss: 0.00000
train epoch 877 avg loss: 0.07506 (A-MSE: 0.06582) avg lploss: 0.00000
train epoch 878 avg loss: 0.06880 (A-MSE: 0.06040) avg lploss: 0.00000
train epoch 879 avg loss: 0.06860 (A-MSE: 0.06024) avg lploss: 0.00000
train epoch 880 avg loss: 0.08111 (A-MSE: 0.07136) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.13983 (A-MSE: 0.11896) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.10950 (A-MSE: 0.09257) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 5 out of 50
train epoch 881 avg loss: 0.09061 (A-MSE: 0.07794) avg lploss: 0.00000
train epoch 882 avg loss: 0.07274 (A-MSE: 0.06352) avg lploss: 0.00000
train epoch 883 avg loss: 0.06544 (A-MSE: 0.05724) avg lploss: 0.00000
train epoch 884 avg loss: 0.06566 (A-MSE: 0.05751) avg lploss: 0.00000
train epoch 885 avg loss: 0.07585 (A-MSE: 0.06658) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.13063 (A-MSE: 0.11235) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.10315 (A-MSE: 0.08764) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 6 out of 50
train epoch 886 avg loss: 0.07310 (A-MSE: 0.06392) avg lploss: 0.00000
train epoch 887 avg loss: 0.07533 (A-MSE: 0.06542) avg lploss: 0.00000
train epoch 888 avg loss: 0.07582 (A-MSE: 0.06650) avg lploss: 0.00000
train epoch 889 avg loss: 0.07708 (A-MSE: 0.06757) avg lploss: 0.00000
train epoch 890 avg loss: 0.07262 (A-MSE: 0.06383) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.12260 (A-MSE: 0.10692) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.09280 (A-MSE: 0.08003) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 7 out of 50
train epoch 891 avg loss: 0.07105 (A-MSE: 0.06189) avg lploss: 0.00000
train epoch 892 avg loss: 0.06715 (A-MSE: 0.05883) avg lploss: 0.00000
train epoch 893 avg loss: 0.07631 (A-MSE: 0.06666) avg lploss: 0.00000
train epoch 894 avg loss: 0.06826 (A-MSE: 0.05975) avg lploss: 0.00000
train epoch 895 avg loss: 0.07046 (A-MSE: 0.06164) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.15048 (A-MSE: 0.12975) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.11963 (A-MSE: 0.10223) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 8 out of 50
train epoch 896 avg loss: 0.07091 (A-MSE: 0.06211) avg lploss: 0.00000
train epoch 897 avg loss: 0.07513 (A-MSE: 0.06562) avg lploss: 0.00000
train epoch 898 avg loss: 0.08184 (A-MSE: 0.07149) avg lploss: 0.00000
train epoch 899 avg loss: 0.07350 (A-MSE: 0.06417) avg lploss: 0.00000
train epoch 900 avg loss: 0.06901 (A-MSE: 0.06069) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.13251 (A-MSE: 0.11343) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.10414 (A-MSE: 0.08838) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 9 out of 50
train epoch 901 avg loss: 0.07350 (A-MSE: 0.06356) avg lploss: 0.00000
train epoch 902 avg loss: 0.06525 (A-MSE: 0.05721) avg lploss: 0.00000
train epoch 903 avg loss: 0.06264 (A-MSE: 0.05493) avg lploss: 0.00000
train epoch 904 avg loss: 0.06171 (A-MSE: 0.05424) avg lploss: 0.00000
train epoch 905 avg loss: 0.06240 (A-MSE: 0.05484) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.12757 (A-MSE: 0.11047) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.09614 (A-MSE: 0.08292) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 10 out of 50
train epoch 906 avg loss: 0.06943 (A-MSE: 0.06127) avg lploss: 0.00000
train epoch 907 avg loss: 0.06526 (A-MSE: 0.05690) avg lploss: 0.00000
train epoch 908 avg loss: 0.07129 (A-MSE: 0.06245) avg lploss: 0.00000
train epoch 909 avg loss: 0.07898 (A-MSE: 0.06950) avg lploss: 0.00000
train epoch 910 avg loss: 0.06957 (A-MSE: 0.06029) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.12071 (A-MSE: 0.10621) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.09253 (A-MSE: 0.08111) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 11 out of 50
train epoch 911 avg loss: 0.06566 (A-MSE: 0.05741) avg lploss: 0.00000
train epoch 912 avg loss: 0.07208 (A-MSE: 0.06320) avg lploss: 0.00000
train epoch 913 avg loss: 0.07067 (A-MSE: 0.06213) avg lploss: 0.00000
train epoch 914 avg loss: 0.07004 (A-MSE: 0.06092) avg lploss: 0.00000
train epoch 915 avg loss: 0.06848 (A-MSE: 0.05990) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.12744 (A-MSE: 0.11066) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.09478 (A-MSE: 0.08126) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 12 out of 50
train epoch 916 avg loss: 0.06894 (A-MSE: 0.05993) avg lploss: 0.00000
train epoch 917 avg loss: 0.06543 (A-MSE: 0.05747) avg lploss: 0.00000
train epoch 918 avg loss: 0.08639 (A-MSE: 0.07554) avg lploss: 0.00000
train epoch 919 avg loss: 0.07354 (A-MSE: 0.06451) avg lploss: 0.00000
train epoch 920 avg loss: 0.07778 (A-MSE: 0.06829) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.15796 (A-MSE: 0.13471) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.12770 (A-MSE: 0.10791) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 13 out of 50
train epoch 921 avg loss: 0.07292 (A-MSE: 0.06355) avg lploss: 0.00000
train epoch 922 avg loss: 0.06527 (A-MSE: 0.05755) avg lploss: 0.00000
train epoch 923 avg loss: 0.07573 (A-MSE: 0.06574) avg lploss: 0.00000
train epoch 924 avg loss: 0.07718 (A-MSE: 0.06777) avg lploss: 0.00000
train epoch 925 avg loss: 0.07856 (A-MSE: 0.06895) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.13674 (A-MSE: 0.11847) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.10755 (A-MSE: 0.09268) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 14 out of 50
train epoch 926 avg loss: 0.08594 (A-MSE: 0.07497) avg lploss: 0.00000
train epoch 927 avg loss: 0.07636 (A-MSE: 0.06645) avg lploss: 0.00000
train epoch 928 avg loss: 0.06978 (A-MSE: 0.06089) avg lploss: 0.00000
train epoch 929 avg loss: 0.05881 (A-MSE: 0.05136) avg lploss: 0.00000
train epoch 930 avg loss: 0.05834 (A-MSE: 0.05120) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.12988 (A-MSE: 0.11336) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.09501 (A-MSE: 0.08207) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 15 out of 50
train epoch 931 avg loss: 0.06880 (A-MSE: 0.06061) avg lploss: 0.00000
train epoch 932 avg loss: 0.06527 (A-MSE: 0.05733) avg lploss: 0.00000
train epoch 933 avg loss: 0.06101 (A-MSE: 0.05355) avg lploss: 0.00000
train epoch 934 avg loss: 0.06400 (A-MSE: 0.05607) avg lploss: 0.00000
train epoch 935 avg loss: 0.06080 (A-MSE: 0.05313) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.13239 (A-MSE: 0.11606) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.10658 (A-MSE: 0.09291) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 16 out of 50
train epoch 936 avg loss: 0.05928 (A-MSE: 0.05215) avg lploss: 0.00000
train epoch 937 avg loss: 0.07597 (A-MSE: 0.06628) avg lploss: 0.00000
train epoch 938 avg loss: 0.07930 (A-MSE: 0.06935) avg lploss: 0.00000
train epoch 939 avg loss: 0.07601 (A-MSE: 0.06669) avg lploss: 0.00000
train epoch 940 avg loss: 0.06438 (A-MSE: 0.05596) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.12681 (A-MSE: 0.11342) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.09355 (A-MSE: 0.08303) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 17 out of 50
train epoch 941 avg loss: 0.06605 (A-MSE: 0.05826) avg lploss: 0.00000
train epoch 942 avg loss: 0.07285 (A-MSE: 0.06383) avg lploss: 0.00000
train epoch 943 avg loss: 0.08051 (A-MSE: 0.07077) avg lploss: 0.00000
train epoch 944 avg loss: 0.07143 (A-MSE: 0.06255) avg lploss: 0.00000
train epoch 945 avg loss: 0.05989 (A-MSE: 0.05241) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.12226 (A-MSE: 0.10658) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.09367 (A-MSE: 0.08052) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 18 out of 50
train epoch 946 avg loss: 0.06205 (A-MSE: 0.05456) avg lploss: 0.00000
train epoch 947 avg loss: 0.07015 (A-MSE: 0.06165) avg lploss: 0.00000
train epoch 948 avg loss: 0.07338 (A-MSE: 0.06445) avg lploss: 0.00000
train epoch 949 avg loss: 0.06574 (A-MSE: 0.05761) avg lploss: 0.00000
train epoch 950 avg loss: 0.07369 (A-MSE: 0.06489) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.13784 (A-MSE: 0.12294) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.11129 (A-MSE: 0.09928) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 19 out of 50
train epoch 951 avg loss: 0.07453 (A-MSE: 0.06506) avg lploss: 0.00000
train epoch 952 avg loss: 0.07082 (A-MSE: 0.06217) avg lploss: 0.00000
train epoch 953 avg loss: 0.07081 (A-MSE: 0.06172) avg lploss: 0.00000
train epoch 954 avg loss: 0.07270 (A-MSE: 0.06419) avg lploss: 0.00000
train epoch 955 avg loss: 0.06964 (A-MSE: 0.06037) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.15405 (A-MSE: 0.13616) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.12392 (A-MSE: 0.10991) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 20 out of 50
train epoch 956 avg loss: 0.06766 (A-MSE: 0.05965) avg lploss: 0.00000
train epoch 957 avg loss: 0.07789 (A-MSE: 0.06785) avg lploss: 0.00000
train epoch 958 avg loss: 0.08117 (A-MSE: 0.07153) avg lploss: 0.00000
train epoch 959 avg loss: 0.06421 (A-MSE: 0.05637) avg lploss: 0.00000
train epoch 960 avg loss: 0.06792 (A-MSE: 0.05969) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.14221 (A-MSE: 0.12592) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.11497 (A-MSE: 0.10122) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 21 out of 50
train epoch 961 avg loss: 0.06799 (A-MSE: 0.05984) avg lploss: 0.00000
train epoch 962 avg loss: 0.07334 (A-MSE: 0.06328) avg lploss: 0.00000
train epoch 963 avg loss: 0.06458 (A-MSE: 0.05702) avg lploss: 0.00000
train epoch 964 avg loss: 0.06231 (A-MSE: 0.05446) avg lploss: 0.00000
train epoch 965 avg loss: 0.05781 (A-MSE: 0.05039) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.12815 (A-MSE: 0.11305) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.09837 (A-MSE: 0.08619) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 22 out of 50
train epoch 966 avg loss: 0.05641 (A-MSE: 0.04909) avg lploss: 0.00000
train epoch 967 avg loss: 0.05917 (A-MSE: 0.05229) avg lploss: 0.00000
train epoch 968 avg loss: 0.05775 (A-MSE: 0.05063) avg lploss: 0.00000
train epoch 969 avg loss: 0.06656 (A-MSE: 0.05851) avg lploss: 0.00000
train epoch 970 avg loss: 0.06502 (A-MSE: 0.05697) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.12352 (A-MSE: 0.10967) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.09550 (A-MSE: 0.08348) avg lploss: 0.00000
*** Best Val Loss: 0.11726 	 Best Test Loss: 0.09214 	 Best epoch 855
EarlyStopping counter: 23 out of 50
train epoch 971 avg loss: 0.06886 (A-MSE: 0.05996) avg lploss: 0.00000
train epoch 972 avg loss: 0.06470 (A-MSE: 0.05634) avg lploss: 0.00000
train epoch 973 avg loss: 0.07732 (A-MSE: 0.06738) avg lploss: 0.00000
train epoch 974 avg loss: 0.06987 (A-MSE: 0.06109) avg lploss: 0.00000
train epoch 975 avg loss: 0.06508 (A-MSE: 0.05743) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.11520 (A-MSE: 0.10009) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.08538 (A-MSE: 0.07337) avg lploss: 0.00000
*** Best Val Loss: 0.11520 	 Best Test Loss: 0.08538 	 Best epoch 975
Validation loss decreased (0.117255 --> 0.115202).  Saving model ...
train epoch 976 avg loss: 0.08032 (A-MSE: 0.06996) avg lploss: 0.00000
train epoch 977 avg loss: 0.08486 (A-MSE: 0.07448) avg lploss: 0.00000
train epoch 978 avg loss: 0.07973 (A-MSE: 0.06935) avg lploss: 0.00000
train epoch 979 avg loss: 0.07302 (A-MSE: 0.06389) avg lploss: 0.00000
train epoch 980 avg loss: 0.07148 (A-MSE: 0.06265) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.12239 (A-MSE: 0.10848) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.09532 (A-MSE: 0.08332) avg lploss: 0.00000
*** Best Val Loss: 0.11520 	 Best Test Loss: 0.08538 	 Best epoch 975
EarlyStopping counter: 1 out of 50
train epoch 981 avg loss: 0.07004 (A-MSE: 0.06188) avg lploss: 0.00000
train epoch 982 avg loss: 0.06878 (A-MSE: 0.06006) avg lploss: 0.00000
train epoch 983 avg loss: 0.05899 (A-MSE: 0.05165) avg lploss: 0.00000
train epoch 984 avg loss: 0.06574 (A-MSE: 0.05725) avg lploss: 0.00000
train epoch 985 avg loss: 0.07395 (A-MSE: 0.06470) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.12740 (A-MSE: 0.11254) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.09858 (A-MSE: 0.08560) avg lploss: 0.00000
*** Best Val Loss: 0.11520 	 Best Test Loss: 0.08538 	 Best epoch 975
EarlyStopping counter: 2 out of 50
train epoch 986 avg loss: 0.07482 (A-MSE: 0.06477) avg lploss: 0.00000
train epoch 987 avg loss: 0.06184 (A-MSE: 0.05412) avg lploss: 0.00000
train epoch 988 avg loss: 0.05663 (A-MSE: 0.04965) avg lploss: 0.00000
train epoch 989 avg loss: 0.05614 (A-MSE: 0.04870) avg lploss: 0.00000
train epoch 990 avg loss: 0.06693 (A-MSE: 0.05876) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.12730 (A-MSE: 0.11139) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.09642 (A-MSE: 0.08309) avg lploss: 0.00000
*** Best Val Loss: 0.11520 	 Best Test Loss: 0.08538 	 Best epoch 975
EarlyStopping counter: 3 out of 50
train epoch 991 avg loss: 0.07312 (A-MSE: 0.06368) avg lploss: 0.00000
train epoch 992 avg loss: 0.08256 (A-MSE: 0.07213) avg lploss: 0.00000
train epoch 993 avg loss: 0.07058 (A-MSE: 0.06164) avg lploss: 0.00000
train epoch 994 avg loss: 0.06921 (A-MSE: 0.05999) avg lploss: 0.00000
train epoch 995 avg loss: 0.06989 (A-MSE: 0.06139) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.12391 (A-MSE: 0.10802) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.09184 (A-MSE: 0.07898) avg lploss: 0.00000
*** Best Val Loss: 0.11520 	 Best Test Loss: 0.08538 	 Best epoch 975
EarlyStopping counter: 4 out of 50
train epoch 996 avg loss: 0.06338 (A-MSE: 0.05582) avg lploss: 0.00000
train epoch 997 avg loss: 0.06820 (A-MSE: 0.05979) avg lploss: 0.00000
train epoch 998 avg loss: 0.06007 (A-MSE: 0.05230) avg lploss: 0.00000
train epoch 999 avg loss: 0.05651 (A-MSE: 0.04896) avg lploss: 0.00000
train epoch 1000 avg loss: 0.05497 (A-MSE: 0.04779) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.11081 (A-MSE: 0.09766) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.07786 (A-MSE: 0.06768) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
Validation loss decreased (0.115202 --> 0.110808).  Saving model ...
train epoch 1001 avg loss: 0.05480 (A-MSE: 0.04822) avg lploss: 0.00000
train epoch 1002 avg loss: 0.05544 (A-MSE: 0.04849) avg lploss: 0.00000
train epoch 1003 avg loss: 0.05298 (A-MSE: 0.04635) avg lploss: 0.00000
train epoch 1004 avg loss: 0.07145 (A-MSE: 0.06236) avg lploss: 0.00000
train epoch 1005 avg loss: 0.06907 (A-MSE: 0.06089) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.11656 (A-MSE: 0.10305) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.08860 (A-MSE: 0.07685) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 1 out of 50
train epoch 1006 avg loss: 0.06794 (A-MSE: 0.05945) avg lploss: 0.00000
train epoch 1007 avg loss: 0.07171 (A-MSE: 0.06284) avg lploss: 0.00000
train epoch 1008 avg loss: 0.06232 (A-MSE: 0.05453) avg lploss: 0.00000
train epoch 1009 avg loss: 0.06045 (A-MSE: 0.05287) avg lploss: 0.00000
train epoch 1010 avg loss: 0.06125 (A-MSE: 0.05347) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.11882 (A-MSE: 0.10482) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.08721 (A-MSE: 0.07586) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 2 out of 50
train epoch 1011 avg loss: 0.05781 (A-MSE: 0.05055) avg lploss: 0.00000
train epoch 1012 avg loss: 0.05941 (A-MSE: 0.05178) avg lploss: 0.00000
train epoch 1013 avg loss: 0.05972 (A-MSE: 0.05226) avg lploss: 0.00000
train epoch 1014 avg loss: 0.05860 (A-MSE: 0.05144) avg lploss: 0.00000
train epoch 1015 avg loss: 0.06484 (A-MSE: 0.05686) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.11924 (A-MSE: 0.10517) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.09005 (A-MSE: 0.07802) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 3 out of 50
train epoch 1016 avg loss: 0.06452 (A-MSE: 0.05648) avg lploss: 0.00000
train epoch 1017 avg loss: 0.06024 (A-MSE: 0.05242) avg lploss: 0.00000
train epoch 1018 avg loss: 0.06079 (A-MSE: 0.05344) avg lploss: 0.00000
train epoch 1019 avg loss: 0.06469 (A-MSE: 0.05634) avg lploss: 0.00000
train epoch 1020 avg loss: 0.07864 (A-MSE: 0.06869) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.17542 (A-MSE: 0.14890) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.14188 (A-MSE: 0.12003) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 4 out of 50
train epoch 1021 avg loss: 0.07785 (A-MSE: 0.06786) avg lploss: 0.00000
train epoch 1022 avg loss: 0.07126 (A-MSE: 0.06249) avg lploss: 0.00000
train epoch 1023 avg loss: 0.06931 (A-MSE: 0.06060) avg lploss: 0.00000
train epoch 1024 avg loss: 0.06304 (A-MSE: 0.05493) avg lploss: 0.00000
train epoch 1025 avg loss: 0.06195 (A-MSE: 0.05432) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.13410 (A-MSE: 0.11525) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.10417 (A-MSE: 0.08830) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 5 out of 50
train epoch 1026 avg loss: 0.06098 (A-MSE: 0.05345) avg lploss: 0.00000
train epoch 1027 avg loss: 0.06194 (A-MSE: 0.05423) avg lploss: 0.00000
train epoch 1028 avg loss: 0.06038 (A-MSE: 0.05299) avg lploss: 0.00000
train epoch 1029 avg loss: 0.05832 (A-MSE: 0.05091) avg lploss: 0.00000
train epoch 1030 avg loss: 0.05843 (A-MSE: 0.05107) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.12703 (A-MSE: 0.10915) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.10226 (A-MSE: 0.08611) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 6 out of 50
train epoch 1031 avg loss: 0.05701 (A-MSE: 0.04956) avg lploss: 0.00000
train epoch 1032 avg loss: 0.05118 (A-MSE: 0.04476) avg lploss: 0.00000
train epoch 1033 avg loss: 0.06194 (A-MSE: 0.05447) avg lploss: 0.00000
train epoch 1034 avg loss: 0.06561 (A-MSE: 0.05720) avg lploss: 0.00000
train epoch 1035 avg loss: 0.08061 (A-MSE: 0.07073) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.13952 (A-MSE: 0.12529) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.10981 (A-MSE: 0.09767) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 7 out of 50
train epoch 1036 avg loss: 0.06420 (A-MSE: 0.05625) avg lploss: 0.00000
train epoch 1037 avg loss: 0.05908 (A-MSE: 0.05134) avg lploss: 0.00000
train epoch 1038 avg loss: 0.06408 (A-MSE: 0.05626) avg lploss: 0.00000
train epoch 1039 avg loss: 0.05868 (A-MSE: 0.05139) avg lploss: 0.00000
train epoch 1040 avg loss: 0.05990 (A-MSE: 0.05233) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.16752 (A-MSE: 0.15314) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.12514 (A-MSE: 0.11345) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 8 out of 50
train epoch 1041 avg loss: 0.07003 (A-MSE: 0.06136) avg lploss: 0.00000
train epoch 1042 avg loss: 0.07731 (A-MSE: 0.06824) avg lploss: 0.00000
train epoch 1043 avg loss: 0.06450 (A-MSE: 0.05629) avg lploss: 0.00000
train epoch 1044 avg loss: 0.06298 (A-MSE: 0.05541) avg lploss: 0.00000
train epoch 1045 avg loss: 0.06323 (A-MSE: 0.05529) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.12065 (A-MSE: 0.10515) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.08877 (A-MSE: 0.07799) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 9 out of 50
train epoch 1046 avg loss: 0.05578 (A-MSE: 0.04905) avg lploss: 0.00000
train epoch 1047 avg loss: 0.06153 (A-MSE: 0.05391) avg lploss: 0.00000
train epoch 1048 avg loss: 0.06542 (A-MSE: 0.05671) avg lploss: 0.00000
train epoch 1049 avg loss: 0.05686 (A-MSE: 0.04985) avg lploss: 0.00000
train epoch 1050 avg loss: 0.06020 (A-MSE: 0.05320) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.12344 (A-MSE: 0.10680) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.09557 (A-MSE: 0.08136) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 10 out of 50
train epoch 1051 avg loss: 0.06020 (A-MSE: 0.05270) avg lploss: 0.00000
train epoch 1052 avg loss: 0.06031 (A-MSE: 0.05267) avg lploss: 0.00000
train epoch 1053 avg loss: 0.05444 (A-MSE: 0.04781) avg lploss: 0.00000
train epoch 1054 avg loss: 0.06029 (A-MSE: 0.05286) avg lploss: 0.00000
train epoch 1055 avg loss: 0.05938 (A-MSE: 0.05192) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.12193 (A-MSE: 0.10621) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.09276 (A-MSE: 0.08018) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 11 out of 50
train epoch 1056 avg loss: 0.06328 (A-MSE: 0.05522) avg lploss: 0.00000
train epoch 1057 avg loss: 0.05228 (A-MSE: 0.04554) avg lploss: 0.00000
train epoch 1058 avg loss: 0.05383 (A-MSE: 0.04717) avg lploss: 0.00000
train epoch 1059 avg loss: 0.07497 (A-MSE: 0.06550) avg lploss: 0.00000
train epoch 1060 avg loss: 0.06692 (A-MSE: 0.05844) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.14483 (A-MSE: 0.12196) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.10699 (A-MSE: 0.08864) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 12 out of 50
train epoch 1061 avg loss: 0.05761 (A-MSE: 0.05022) avg lploss: 0.00000
train epoch 1062 avg loss: 0.05982 (A-MSE: 0.05235) avg lploss: 0.00000
train epoch 1063 avg loss: 0.05218 (A-MSE: 0.04518) avg lploss: 0.00000
train epoch 1064 avg loss: 0.06339 (A-MSE: 0.05536) avg lploss: 0.00000
train epoch 1065 avg loss: 0.05867 (A-MSE: 0.05146) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.12822 (A-MSE: 0.11297) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.10259 (A-MSE: 0.08828) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 13 out of 50
train epoch 1066 avg loss: 0.06582 (A-MSE: 0.05649) avg lploss: 0.00000
train epoch 1067 avg loss: 0.06388 (A-MSE: 0.05567) avg lploss: 0.00000
train epoch 1068 avg loss: 0.05719 (A-MSE: 0.05002) avg lploss: 0.00000
train epoch 1069 avg loss: 0.06594 (A-MSE: 0.05807) avg lploss: 0.00000
train epoch 1070 avg loss: 0.05687 (A-MSE: 0.04966) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.14979 (A-MSE: 0.13130) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.11110 (A-MSE: 0.09623) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 14 out of 50
train epoch 1071 avg loss: 0.05665 (A-MSE: 0.04950) avg lploss: 0.00000
train epoch 1072 avg loss: 0.05791 (A-MSE: 0.05047) avg lploss: 0.00000
train epoch 1073 avg loss: 0.05945 (A-MSE: 0.05212) avg lploss: 0.00000
train epoch 1074 avg loss: 0.05780 (A-MSE: 0.05053) avg lploss: 0.00000
train epoch 1075 avg loss: 0.05085 (A-MSE: 0.04415) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.12043 (A-MSE: 0.10524) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.08782 (A-MSE: 0.07624) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 15 out of 50
train epoch 1076 avg loss: 0.05468 (A-MSE: 0.04764) avg lploss: 0.00000
train epoch 1077 avg loss: 0.05647 (A-MSE: 0.04937) avg lploss: 0.00000
train epoch 1078 avg loss: 0.06619 (A-MSE: 0.05717) avg lploss: 0.00000
train epoch 1079 avg loss: 0.05832 (A-MSE: 0.05104) avg lploss: 0.00000
train epoch 1080 avg loss: 0.06509 (A-MSE: 0.05675) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.14462 (A-MSE: 0.12809) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.11364 (A-MSE: 0.09923) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 16 out of 50
train epoch 1081 avg loss: 0.06587 (A-MSE: 0.05762) avg lploss: 0.00000
train epoch 1082 avg loss: 0.06862 (A-MSE: 0.06005) avg lploss: 0.00000
train epoch 1083 avg loss: 0.06914 (A-MSE: 0.06099) avg lploss: 0.00000
train epoch 1084 avg loss: 0.06157 (A-MSE: 0.05411) avg lploss: 0.00000
train epoch 1085 avg loss: 0.06321 (A-MSE: 0.05529) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.12422 (A-MSE: 0.10828) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.09175 (A-MSE: 0.07886) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 17 out of 50
train epoch 1086 avg loss: 0.06161 (A-MSE: 0.05350) avg lploss: 0.00000
train epoch 1087 avg loss: 0.06993 (A-MSE: 0.06105) avg lploss: 0.00000
train epoch 1088 avg loss: 0.05700 (A-MSE: 0.04978) avg lploss: 0.00000
train epoch 1089 avg loss: 0.05384 (A-MSE: 0.04674) avg lploss: 0.00000
train epoch 1090 avg loss: 0.05708 (A-MSE: 0.04989) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.11545 (A-MSE: 0.10031) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.08651 (A-MSE: 0.07345) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 18 out of 50
train epoch 1091 avg loss: 0.05224 (A-MSE: 0.04578) avg lploss: 0.00000
train epoch 1092 avg loss: 0.05267 (A-MSE: 0.04584) avg lploss: 0.00000
train epoch 1093 avg loss: 0.06420 (A-MSE: 0.05599) avg lploss: 0.00000
train epoch 1094 avg loss: 0.05976 (A-MSE: 0.05193) avg lploss: 0.00000
train epoch 1095 avg loss: 0.05317 (A-MSE: 0.04625) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.14923 (A-MSE: 0.12861) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.11379 (A-MSE: 0.09615) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 19 out of 50
train epoch 1096 avg loss: 0.05969 (A-MSE: 0.05196) avg lploss: 0.00000
train epoch 1097 avg loss: 0.06622 (A-MSE: 0.05847) avg lploss: 0.00000
train epoch 1098 avg loss: 0.08449 (A-MSE: 0.07400) avg lploss: 0.00000
train epoch 1099 avg loss: 0.07147 (A-MSE: 0.06196) avg lploss: 0.00000
train epoch 1100 avg loss: 0.06208 (A-MSE: 0.05436) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.11546 (A-MSE: 0.10080) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.08497 (A-MSE: 0.07416) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 20 out of 50
train epoch 1101 avg loss: 0.06131 (A-MSE: 0.05363) avg lploss: 0.00000
train epoch 1102 avg loss: 0.06053 (A-MSE: 0.05292) avg lploss: 0.00000
train epoch 1103 avg loss: 0.05620 (A-MSE: 0.04919) avg lploss: 0.00000
train epoch 1104 avg loss: 0.05450 (A-MSE: 0.04726) avg lploss: 0.00000
train epoch 1105 avg loss: 0.04868 (A-MSE: 0.04247) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.12497 (A-MSE: 0.11005) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.08930 (A-MSE: 0.07754) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 21 out of 50
train epoch 1106 avg loss: 0.05642 (A-MSE: 0.04953) avg lploss: 0.00000
train epoch 1107 avg loss: 0.05741 (A-MSE: 0.05012) avg lploss: 0.00000
train epoch 1108 avg loss: 0.05645 (A-MSE: 0.04932) avg lploss: 0.00000
train epoch 1109 avg loss: 0.06033 (A-MSE: 0.05254) avg lploss: 0.00000
train epoch 1110 avg loss: 0.05630 (A-MSE: 0.04954) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.13422 (A-MSE: 0.11919) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.09951 (A-MSE: 0.08680) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 22 out of 50
train epoch 1111 avg loss: 0.05979 (A-MSE: 0.05203) avg lploss: 0.00000
train epoch 1112 avg loss: 0.06414 (A-MSE: 0.05597) avg lploss: 0.00000
train epoch 1113 avg loss: 0.05460 (A-MSE: 0.04772) avg lploss: 0.00000
train epoch 1114 avg loss: 0.05438 (A-MSE: 0.04778) avg lploss: 0.00000
train epoch 1115 avg loss: 0.05406 (A-MSE: 0.04727) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.13098 (A-MSE: 0.11543) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.10270 (A-MSE: 0.08965) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 23 out of 50
train epoch 1116 avg loss: 0.05154 (A-MSE: 0.04467) avg lploss: 0.00000
train epoch 1117 avg loss: 0.05185 (A-MSE: 0.04453) avg lploss: 0.00000
train epoch 1118 avg loss: 0.05396 (A-MSE: 0.04724) avg lploss: 0.00000
train epoch 1119 avg loss: 0.05630 (A-MSE: 0.04934) avg lploss: 0.00000
train epoch 1120 avg loss: 0.05769 (A-MSE: 0.05002) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.11771 (A-MSE: 0.10401) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.08919 (A-MSE: 0.07717) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 24 out of 50
train epoch 1121 avg loss: 0.06625 (A-MSE: 0.05776) avg lploss: 0.00000
train epoch 1122 avg loss: 0.06114 (A-MSE: 0.05367) avg lploss: 0.00000
train epoch 1123 avg loss: 0.06229 (A-MSE: 0.05470) avg lploss: 0.00000
train epoch 1124 avg loss: 0.05689 (A-MSE: 0.04955) avg lploss: 0.00000
train epoch 1125 avg loss: 0.04920 (A-MSE: 0.04277) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.11180 (A-MSE: 0.09867) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.08340 (A-MSE: 0.07171) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 25 out of 50
train epoch 1126 avg loss: 0.04586 (A-MSE: 0.04011) avg lploss: 0.00000
train epoch 1127 avg loss: 0.05148 (A-MSE: 0.04461) avg lploss: 0.00000
train epoch 1128 avg loss: 0.06438 (A-MSE: 0.05559) avg lploss: 0.00000
train epoch 1129 avg loss: 0.05513 (A-MSE: 0.04873) avg lploss: 0.00000
train epoch 1130 avg loss: 0.05545 (A-MSE: 0.04883) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.12566 (A-MSE: 0.11010) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.09920 (A-MSE: 0.08583) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 26 out of 50
train epoch 1131 avg loss: 0.05249 (A-MSE: 0.04570) avg lploss: 0.00000
train epoch 1132 avg loss: 0.05368 (A-MSE: 0.04708) avg lploss: 0.00000
train epoch 1133 avg loss: 0.06238 (A-MSE: 0.05474) avg lploss: 0.00000
train epoch 1134 avg loss: 0.05326 (A-MSE: 0.04660) avg lploss: 0.00000
train epoch 1135 avg loss: 0.04701 (A-MSE: 0.04096) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.11128 (A-MSE: 0.09887) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.07932 (A-MSE: 0.06958) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 27 out of 50
train epoch 1136 avg loss: 0.05524 (A-MSE: 0.04819) avg lploss: 0.00000
train epoch 1137 avg loss: 0.05909 (A-MSE: 0.05159) avg lploss: 0.00000
train epoch 1138 avg loss: 0.06378 (A-MSE: 0.05633) avg lploss: 0.00000
train epoch 1139 avg loss: 0.05806 (A-MSE: 0.05125) avg lploss: 0.00000
train epoch 1140 avg loss: 0.05525 (A-MSE: 0.04789) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.13142 (A-MSE: 0.11185) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.09505 (A-MSE: 0.08116) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 28 out of 50
train epoch 1141 avg loss: 0.05907 (A-MSE: 0.05150) avg lploss: 0.00000
train epoch 1142 avg loss: 0.05012 (A-MSE: 0.04379) avg lploss: 0.00000
train epoch 1143 avg loss: 0.04723 (A-MSE: 0.04103) avg lploss: 0.00000
train epoch 1144 avg loss: 0.05267 (A-MSE: 0.04608) avg lploss: 0.00000
train epoch 1145 avg loss: 0.05203 (A-MSE: 0.04555) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.11407 (A-MSE: 0.10194) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.08468 (A-MSE: 0.07488) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 29 out of 50
train epoch 1146 avg loss: 0.05048 (A-MSE: 0.04409) avg lploss: 0.00000
train epoch 1147 avg loss: 0.04879 (A-MSE: 0.04233) avg lploss: 0.00000
train epoch 1148 avg loss: 0.05075 (A-MSE: 0.04436) avg lploss: 0.00000
train epoch 1149 avg loss: 0.05060 (A-MSE: 0.04407) avg lploss: 0.00000
train epoch 1150 avg loss: 0.06132 (A-MSE: 0.05342) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.15109 (A-MSE: 0.13239) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.11726 (A-MSE: 0.10092) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 30 out of 50
train epoch 1151 avg loss: 0.05509 (A-MSE: 0.04814) avg lploss: 0.00000
train epoch 1152 avg loss: 0.05572 (A-MSE: 0.04822) avg lploss: 0.00000
train epoch 1153 avg loss: 0.05256 (A-MSE: 0.04611) avg lploss: 0.00000
train epoch 1154 avg loss: 0.04809 (A-MSE: 0.04173) avg lploss: 0.00000
train epoch 1155 avg loss: 0.05316 (A-MSE: 0.04643) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.12124 (A-MSE: 0.10830) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.08913 (A-MSE: 0.07854) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 31 out of 50
train epoch 1156 avg loss: 0.04521 (A-MSE: 0.03963) avg lploss: 0.00000
train epoch 1157 avg loss: 0.05965 (A-MSE: 0.05209) avg lploss: 0.00000
train epoch 1158 avg loss: 0.05392 (A-MSE: 0.04783) avg lploss: 0.00000
train epoch 1159 avg loss: 0.05600 (A-MSE: 0.04883) avg lploss: 0.00000
train epoch 1160 avg loss: 0.05919 (A-MSE: 0.05140) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.13162 (A-MSE: 0.11379) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.09837 (A-MSE: 0.08420) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 32 out of 50
train epoch 1161 avg loss: 0.05107 (A-MSE: 0.04484) avg lploss: 0.00000
train epoch 1162 avg loss: 0.05142 (A-MSE: 0.04473) avg lploss: 0.00000
train epoch 1163 avg loss: 0.04800 (A-MSE: 0.04151) avg lploss: 0.00000
train epoch 1164 avg loss: 0.05593 (A-MSE: 0.04857) avg lploss: 0.00000
train epoch 1165 avg loss: 0.05239 (A-MSE: 0.04559) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.11620 (A-MSE: 0.10325) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.08902 (A-MSE: 0.07753) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 33 out of 50
train epoch 1166 avg loss: 0.04639 (A-MSE: 0.04024) avg lploss: 0.00000
train epoch 1167 avg loss: 0.04873 (A-MSE: 0.04270) avg lploss: 0.00000
train epoch 1168 avg loss: 0.05161 (A-MSE: 0.04519) avg lploss: 0.00000
train epoch 1169 avg loss: 0.05829 (A-MSE: 0.05084) avg lploss: 0.00000
train epoch 1170 avg loss: 0.05819 (A-MSE: 0.05127) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.11965 (A-MSE: 0.10545) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.08912 (A-MSE: 0.07752) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 34 out of 50
train epoch 1171 avg loss: 0.05590 (A-MSE: 0.04885) avg lploss: 0.00000
train epoch 1172 avg loss: 0.06081 (A-MSE: 0.05278) avg lploss: 0.00000
train epoch 1173 avg loss: 0.05166 (A-MSE: 0.04526) avg lploss: 0.00000
train epoch 1174 avg loss: 0.05214 (A-MSE: 0.04517) avg lploss: 0.00000
train epoch 1175 avg loss: 0.05833 (A-MSE: 0.05123) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.11322 (A-MSE: 0.09985) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.08389 (A-MSE: 0.07255) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 35 out of 50
train epoch 1176 avg loss: 0.05137 (A-MSE: 0.04496) avg lploss: 0.00000
train epoch 1177 avg loss: 0.05200 (A-MSE: 0.04531) avg lploss: 0.00000
train epoch 1178 avg loss: 0.05451 (A-MSE: 0.04752) avg lploss: 0.00000
train epoch 1179 avg loss: 0.06280 (A-MSE: 0.05499) avg lploss: 0.00000
train epoch 1180 avg loss: 0.06075 (A-MSE: 0.05327) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.16596 (A-MSE: 0.14747) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.13380 (A-MSE: 0.11753) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 36 out of 50
train epoch 1181 avg loss: 0.06294 (A-MSE: 0.05549) avg lploss: 0.00000
train epoch 1182 avg loss: 0.05110 (A-MSE: 0.04453) avg lploss: 0.00000
train epoch 1183 avg loss: 0.05833 (A-MSE: 0.05073) avg lploss: 0.00000
train epoch 1184 avg loss: 0.05727 (A-MSE: 0.04972) avg lploss: 0.00000
train epoch 1185 avg loss: 0.04995 (A-MSE: 0.04354) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.12446 (A-MSE: 0.10814) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.09329 (A-MSE: 0.07994) avg lploss: 0.00000
*** Best Val Loss: 0.11081 	 Best Test Loss: 0.07786 	 Best epoch 1000
EarlyStopping counter: 37 out of 50
train epoch 1186 avg loss: 0.05394 (A-MSE: 0.04685) avg lploss: 0.00000
train epoch 1187 avg loss: 0.06619 (A-MSE: 0.05727) avg lploss: 0.00000
train epoch 1188 avg loss: 0.05358 (A-MSE: 0.04644) avg lploss: 0.00000
train epoch 1189 avg loss: 0.05126 (A-MSE: 0.04456) avg lploss: 0.00000
train epoch 1190 avg loss: 0.05005 (A-MSE: 0.04414) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.10983 (A-MSE: 0.09407) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.08515 (A-MSE: 0.07281) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
Validation loss decreased (0.110808 --> 0.109834).  Saving model ...
train epoch 1191 avg loss: 0.04864 (A-MSE: 0.04242) avg lploss: 0.00000
train epoch 1192 avg loss: 0.04862 (A-MSE: 0.04215) avg lploss: 0.00000
train epoch 1193 avg loss: 0.05099 (A-MSE: 0.04436) avg lploss: 0.00000
train epoch 1194 avg loss: 0.05799 (A-MSE: 0.05101) avg lploss: 0.00000
train epoch 1195 avg loss: 0.05203 (A-MSE: 0.04536) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.12991 (A-MSE: 0.11319) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.09645 (A-MSE: 0.08306) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 1 out of 50
train epoch 1196 avg loss: 0.06224 (A-MSE: 0.05409) avg lploss: 0.00000
train epoch 1197 avg loss: 0.06235 (A-MSE: 0.05464) avg lploss: 0.00000
train epoch 1198 avg loss: 0.05378 (A-MSE: 0.04687) avg lploss: 0.00000
train epoch 1199 avg loss: 0.04852 (A-MSE: 0.04224) avg lploss: 0.00000
train epoch 1200 avg loss: 0.04771 (A-MSE: 0.04148) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.12768 (A-MSE: 0.10969) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.09690 (A-MSE: 0.08256) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 2 out of 50
train epoch 1201 avg loss: 0.04979 (A-MSE: 0.04381) avg lploss: 0.00000
train epoch 1202 avg loss: 0.04570 (A-MSE: 0.03949) avg lploss: 0.00000
train epoch 1203 avg loss: 0.05207 (A-MSE: 0.04575) avg lploss: 0.00000
train epoch 1204 avg loss: 0.05249 (A-MSE: 0.04638) avg lploss: 0.00000
train epoch 1205 avg loss: 0.04862 (A-MSE: 0.04227) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.12795 (A-MSE: 0.11356) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.09600 (A-MSE: 0.08397) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 3 out of 50
train epoch 1206 avg loss: 0.05002 (A-MSE: 0.04358) avg lploss: 0.00000
train epoch 1207 avg loss: 0.05516 (A-MSE: 0.04820) avg lploss: 0.00000
train epoch 1208 avg loss: 0.05219 (A-MSE: 0.04547) avg lploss: 0.00000
train epoch 1209 avg loss: 0.05984 (A-MSE: 0.05177) avg lploss: 0.00000
train epoch 1210 avg loss: 0.05147 (A-MSE: 0.04481) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.12842 (A-MSE: 0.11194) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.08741 (A-MSE: 0.07552) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 4 out of 50
train epoch 1211 avg loss: 0.05360 (A-MSE: 0.04658) avg lploss: 0.00000
train epoch 1212 avg loss: 0.04867 (A-MSE: 0.04234) avg lploss: 0.00000
train epoch 1213 avg loss: 0.04849 (A-MSE: 0.04232) avg lploss: 0.00000
train epoch 1214 avg loss: 0.04483 (A-MSE: 0.03889) avg lploss: 0.00000
train epoch 1215 avg loss: 0.04583 (A-MSE: 0.04008) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.13007 (A-MSE: 0.11322) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.09697 (A-MSE: 0.08363) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 5 out of 50
train epoch 1216 avg loss: 0.05363 (A-MSE: 0.04690) avg lploss: 0.00000
train epoch 1217 avg loss: 0.05212 (A-MSE: 0.04574) avg lploss: 0.00000
train epoch 1218 avg loss: 0.05500 (A-MSE: 0.04811) avg lploss: 0.00000
train epoch 1219 avg loss: 0.05074 (A-MSE: 0.04437) avg lploss: 0.00000
train epoch 1220 avg loss: 0.04726 (A-MSE: 0.04089) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.11512 (A-MSE: 0.10074) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.08191 (A-MSE: 0.07089) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 6 out of 50
train epoch 1221 avg loss: 0.04516 (A-MSE: 0.03913) avg lploss: 0.00000
train epoch 1222 avg loss: 0.04531 (A-MSE: 0.03942) avg lploss: 0.00000
train epoch 1223 avg loss: 0.04338 (A-MSE: 0.03799) avg lploss: 0.00000
train epoch 1224 avg loss: 0.04365 (A-MSE: 0.03787) avg lploss: 0.00000
train epoch 1225 avg loss: 0.04730 (A-MSE: 0.04094) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.13361 (A-MSE: 0.11165) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.10001 (A-MSE: 0.08190) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 7 out of 50
train epoch 1226 avg loss: 0.04514 (A-MSE: 0.03922) avg lploss: 0.00000
train epoch 1227 avg loss: 0.04748 (A-MSE: 0.04154) avg lploss: 0.00000
train epoch 1228 avg loss: 0.05053 (A-MSE: 0.04455) avg lploss: 0.00000
train epoch 1229 avg loss: 0.05231 (A-MSE: 0.04566) avg lploss: 0.00000
train epoch 1230 avg loss: 0.06281 (A-MSE: 0.05427) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.15112 (A-MSE: 0.12802) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.10542 (A-MSE: 0.09003) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 8 out of 50
train epoch 1231 avg loss: 0.09088 (A-MSE: 0.07825) avg lploss: 0.00000
train epoch 1232 avg loss: 0.17880 (A-MSE: 0.15017) avg lploss: 0.00000
train epoch 1233 avg loss: 220732.33236 (A-MSE: 227768.94065) avg lploss: 0.00000
train epoch 1234 avg loss: 1221.89357 (A-MSE: 1194.34095) avg lploss: 0.00000
train epoch 1235 avg loss: 13.93960 (A-MSE: 12.78962) avg lploss: 0.00000
==> val epoch 1235 avg loss: 12.02032 (A-MSE: 10.64522) avg lploss: 0.00000
==> test epoch 1235 avg loss: 12.10675 (A-MSE: 10.74726) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 9 out of 50
train epoch 1236 avg loss: 8.78872 (A-MSE: 7.06628) avg lploss: 0.00000
train epoch 1237 avg loss: 5.03869 (A-MSE: 3.49773) avg lploss: 0.00000
train epoch 1238 avg loss: 3.83217 (A-MSE: 2.61497) avg lploss: 0.00000
train epoch 1239 avg loss: 3.19462 (A-MSE: 2.20645) avg lploss: 0.00000
train epoch 1240 avg loss: 2.73909 (A-MSE: 1.91273) avg lploss: 0.00000
==> val epoch 1240 avg loss: 2.88628 (A-MSE: 2.04955) avg lploss: 0.00000
==> test epoch 1240 avg loss: 2.73468 (A-MSE: 1.91839) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 10 out of 50
train epoch 1241 avg loss: 2.38717 (A-MSE: 1.68304) avg lploss: 0.00000
train epoch 1242 avg loss: 2.17081 (A-MSE: 1.52688) avg lploss: 0.00000
train epoch 1243 avg loss: 1.92031 (A-MSE: 1.35592) avg lploss: 0.00000
train epoch 1244 avg loss: 1.74067 (A-MSE: 1.21918) avg lploss: 0.00000
train epoch 1245 avg loss: 1.61908 (A-MSE: 1.15095) avg lploss: 0.00000
==> val epoch 1245 avg loss: 1.99093 (A-MSE: 1.40511) avg lploss: 0.00000
==> test epoch 1245 avg loss: 1.85523 (A-MSE: 1.28526) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 11 out of 50
train epoch 1246 avg loss: 1.54621 (A-MSE: 1.09944) avg lploss: 0.00000
train epoch 1247 avg loss: 1.40842 (A-MSE: 0.99407) avg lploss: 0.00000
train epoch 1248 avg loss: 1.28270 (A-MSE: 0.91398) avg lploss: 0.00000
train epoch 1249 avg loss: 1.19024 (A-MSE: 0.85150) avg lploss: 0.00000
train epoch 1250 avg loss: 1.10490 (A-MSE: 0.78673) avg lploss: 0.00000
==> val epoch 1250 avg loss: 1.33046 (A-MSE: 0.96146) avg lploss: 0.00000
==> test epoch 1250 avg loss: 1.21516 (A-MSE: 0.85315) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 12 out of 50
train epoch 1251 avg loss: 1.05104 (A-MSE: 0.76106) avg lploss: 0.00000
train epoch 1252 avg loss: 0.99832 (A-MSE: 0.73285) avg lploss: 0.00000
train epoch 1253 avg loss: 0.95686 (A-MSE: 0.69439) avg lploss: 0.00000
train epoch 1254 avg loss: 0.88713 (A-MSE: 0.65770) avg lploss: 0.00000
train epoch 1255 avg loss: 0.84069 (A-MSE: 0.62606) avg lploss: 0.00000
==> val epoch 1255 avg loss: 1.11437 (A-MSE: 0.81510) avg lploss: 0.00000
==> test epoch 1255 avg loss: 1.00968 (A-MSE: 0.72103) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 13 out of 50
train epoch 1256 avg loss: 0.84938 (A-MSE: 0.63934) avg lploss: 0.00000
train epoch 1257 avg loss: 0.81319 (A-MSE: 0.61091) avg lploss: 0.00000
train epoch 1258 avg loss: 0.77900 (A-MSE: 0.58215) avg lploss: 0.00000
train epoch 1259 avg loss: 0.74175 (A-MSE: 0.56615) avg lploss: 0.00000
train epoch 1260 avg loss: 0.73008 (A-MSE: 0.55236) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.92978 (A-MSE: 0.70972) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.83191 (A-MSE: 0.62200) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 14 out of 50
train epoch 1261 avg loss: 0.71477 (A-MSE: 0.54550) avg lploss: 0.00000
train epoch 1262 avg loss: 0.70621 (A-MSE: 0.54228) avg lploss: 0.00000
train epoch 1263 avg loss: 0.70841 (A-MSE: 0.53747) avg lploss: 0.00000
train epoch 1264 avg loss: 0.66829 (A-MSE: 0.51156) avg lploss: 0.00000
train epoch 1265 avg loss: 0.64536 (A-MSE: 0.49323) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.83889 (A-MSE: 0.64019) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.74826 (A-MSE: 0.55959) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 15 out of 50
train epoch 1266 avg loss: 0.63639 (A-MSE: 0.49300) avg lploss: 0.00000
train epoch 1267 avg loss: 0.63812 (A-MSE: 0.49360) avg lploss: 0.00000
train epoch 1268 avg loss: 0.61839 (A-MSE: 0.47787) avg lploss: 0.00000
train epoch 1269 avg loss: 0.61565 (A-MSE: 0.47516) avg lploss: 0.00000
train epoch 1270 avg loss: 0.60383 (A-MSE: 0.46698) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.76531 (A-MSE: 0.58328) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.68532 (A-MSE: 0.51118) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 16 out of 50
train epoch 1271 avg loss: 0.60083 (A-MSE: 0.46346) avg lploss: 0.00000
train epoch 1272 avg loss: 0.59220 (A-MSE: 0.46448) avg lploss: 0.00000
train epoch 1273 avg loss: 0.57456 (A-MSE: 0.44234) avg lploss: 0.00000
train epoch 1274 avg loss: 0.58096 (A-MSE: 0.44748) avg lploss: 0.00000
train epoch 1275 avg loss: 0.57067 (A-MSE: 0.44125) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.70870 (A-MSE: 0.54874) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.63516 (A-MSE: 0.48354) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 17 out of 50
train epoch 1276 avg loss: 0.55366 (A-MSE: 0.43008) avg lploss: 0.00000
train epoch 1277 avg loss: 0.54441 (A-MSE: 0.42042) avg lploss: 0.00000
train epoch 1278 avg loss: 0.55218 (A-MSE: 0.43015) avg lploss: 0.00000
train epoch 1279 avg loss: 0.54965 (A-MSE: 0.42649) avg lploss: 0.00000
train epoch 1280 avg loss: 0.54846 (A-MSE: 0.42997) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.71374 (A-MSE: 0.54987) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.63725 (A-MSE: 0.48097) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 18 out of 50
train epoch 1281 avg loss: 0.53818 (A-MSE: 0.41787) avg lploss: 0.00000
train epoch 1282 avg loss: 0.53190 (A-MSE: 0.41205) avg lploss: 0.00000
train epoch 1283 avg loss: 0.50928 (A-MSE: 0.39539) avg lploss: 0.00000
train epoch 1284 avg loss: 0.50942 (A-MSE: 0.39851) avg lploss: 0.00000
train epoch 1285 avg loss: 0.52606 (A-MSE: 0.41245) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.67084 (A-MSE: 0.52512) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.59951 (A-MSE: 0.45868) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 19 out of 50
train epoch 1286 avg loss: 0.51818 (A-MSE: 0.40387) avg lploss: 0.00000
train epoch 1287 avg loss: 0.50048 (A-MSE: 0.39017) avg lploss: 0.00000
train epoch 1288 avg loss: 0.50525 (A-MSE: 0.39314) avg lploss: 0.00000
train epoch 1289 avg loss: 0.47610 (A-MSE: 0.37153) avg lploss: 0.00000
train epoch 1290 avg loss: 0.48528 (A-MSE: 0.37868) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.70708 (A-MSE: 0.55011) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.63194 (A-MSE: 0.48227) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 20 out of 50
train epoch 1291 avg loss: 0.49906 (A-MSE: 0.39102) avg lploss: 0.00000
train epoch 1292 avg loss: 0.48339 (A-MSE: 0.37730) avg lploss: 0.00000
train epoch 1293 avg loss: 0.48589 (A-MSE: 0.37979) avg lploss: 0.00000
train epoch 1294 avg loss: 0.47917 (A-MSE: 0.37771) avg lploss: 0.00000
train epoch 1295 avg loss: 0.47770 (A-MSE: 0.37400) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.66137 (A-MSE: 0.51751) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.58737 (A-MSE: 0.45016) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 21 out of 50
train epoch 1296 avg loss: 0.47211 (A-MSE: 0.37382) avg lploss: 0.00000
train epoch 1297 avg loss: 0.46167 (A-MSE: 0.36186) avg lploss: 0.00000
train epoch 1298 avg loss: 0.44946 (A-MSE: 0.35184) avg lploss: 0.00000
train epoch 1299 avg loss: 0.44039 (A-MSE: 0.34414) avg lploss: 0.00000
train epoch 1300 avg loss: 0.44659 (A-MSE: 0.35171) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.61245 (A-MSE: 0.48141) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.54437 (A-MSE: 0.42053) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 22 out of 50
train epoch 1301 avg loss: 0.45751 (A-MSE: 0.36080) avg lploss: 0.00000
train epoch 1302 avg loss: 0.44311 (A-MSE: 0.34792) avg lploss: 0.00000
train epoch 1303 avg loss: 0.44381 (A-MSE: 0.34642) avg lploss: 0.00000
train epoch 1304 avg loss: 0.43719 (A-MSE: 0.34406) avg lploss: 0.00000
train epoch 1305 avg loss: 0.42546 (A-MSE: 0.33441) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.57938 (A-MSE: 0.45447) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.51625 (A-MSE: 0.39878) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 23 out of 50
train epoch 1306 avg loss: 0.42576 (A-MSE: 0.33535) avg lploss: 0.00000
train epoch 1307 avg loss: 0.41705 (A-MSE: 0.32744) avg lploss: 0.00000
train epoch 1308 avg loss: 0.41700 (A-MSE: 0.32927) avg lploss: 0.00000
train epoch 1309 avg loss: 0.41918 (A-MSE: 0.32892) avg lploss: 0.00000
train epoch 1310 avg loss: 0.41675 (A-MSE: 0.32843) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.60199 (A-MSE: 0.48279) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.53062 (A-MSE: 0.41886) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 24 out of 50
train epoch 1311 avg loss: 0.41686 (A-MSE: 0.32789) avg lploss: 0.00000
train epoch 1312 avg loss: 0.42323 (A-MSE: 0.33430) avg lploss: 0.00000
train epoch 1313 avg loss: 0.41377 (A-MSE: 0.32723) avg lploss: 0.00000
train epoch 1314 avg loss: 0.41130 (A-MSE: 0.32263) avg lploss: 0.00000
train epoch 1315 avg loss: 0.40695 (A-MSE: 0.32132) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.56527 (A-MSE: 0.44425) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.49832 (A-MSE: 0.38654) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 25 out of 50
train epoch 1316 avg loss: 0.39961 (A-MSE: 0.31734) avg lploss: 0.00000
train epoch 1317 avg loss: 0.39729 (A-MSE: 0.31256) avg lploss: 0.00000
train epoch 1318 avg loss: 0.39844 (A-MSE: 0.31765) avg lploss: 0.00000
train epoch 1319 avg loss: 0.39810 (A-MSE: 0.31803) avg lploss: 0.00000
train epoch 1320 avg loss: 0.40548 (A-MSE: 0.32042) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.53930 (A-MSE: 0.42227) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.48018 (A-MSE: 0.36989) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 26 out of 50
train epoch 1321 avg loss: 0.38865 (A-MSE: 0.30684) avg lploss: 0.00000
train epoch 1322 avg loss: 0.39793 (A-MSE: 0.31780) avg lploss: 0.00000
train epoch 1323 avg loss: 0.39400 (A-MSE: 0.31039) avg lploss: 0.00000
train epoch 1324 avg loss: 0.38409 (A-MSE: 0.30658) avg lploss: 0.00000
train epoch 1325 avg loss: 0.39391 (A-MSE: 0.31060) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.53587 (A-MSE: 0.42891) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.47215 (A-MSE: 0.37135) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 27 out of 50
train epoch 1326 avg loss: 0.38138 (A-MSE: 0.30202) avg lploss: 0.00000
train epoch 1327 avg loss: 0.38011 (A-MSE: 0.30337) avg lploss: 0.00000
train epoch 1328 avg loss: 0.36822 (A-MSE: 0.29023) avg lploss: 0.00000
train epoch 1329 avg loss: 0.36902 (A-MSE: 0.29286) avg lploss: 0.00000
train epoch 1330 avg loss: 0.36956 (A-MSE: 0.29157) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.50995 (A-MSE: 0.40066) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.44648 (A-MSE: 0.34511) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 28 out of 50
train epoch 1331 avg loss: 0.36998 (A-MSE: 0.29207) avg lploss: 0.00000
train epoch 1332 avg loss: 0.36765 (A-MSE: 0.29107) avg lploss: 0.00000
train epoch 1333 avg loss: 0.35744 (A-MSE: 0.28395) avg lploss: 0.00000
train epoch 1334 avg loss: 0.37403 (A-MSE: 0.29830) avg lploss: 0.00000
train epoch 1335 avg loss: 0.36568 (A-MSE: 0.29095) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.49863 (A-MSE: 0.39278) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.43527 (A-MSE: 0.33750) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 29 out of 50
train epoch 1336 avg loss: 0.36814 (A-MSE: 0.29262) avg lploss: 0.00000
train epoch 1337 avg loss: 0.36213 (A-MSE: 0.28997) avg lploss: 0.00000
train epoch 1338 avg loss: 0.34696 (A-MSE: 0.27482) avg lploss: 0.00000
train epoch 1339 avg loss: 0.36125 (A-MSE: 0.28795) avg lploss: 0.00000
train epoch 1340 avg loss: 0.35552 (A-MSE: 0.28349) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.53258 (A-MSE: 0.43787) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.46607 (A-MSE: 0.38050) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 30 out of 50
train epoch 1341 avg loss: 0.35778 (A-MSE: 0.28433) avg lploss: 0.00000
train epoch 1342 avg loss: 0.35059 (A-MSE: 0.28043) avg lploss: 0.00000
train epoch 1343 avg loss: 0.34394 (A-MSE: 0.27260) avg lploss: 0.00000
train epoch 1344 avg loss: 0.35104 (A-MSE: 0.27900) avg lploss: 0.00000
train epoch 1345 avg loss: 0.34564 (A-MSE: 0.27705) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.48228 (A-MSE: 0.37885) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.42182 (A-MSE: 0.32652) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 31 out of 50
train epoch 1346 avg loss: 0.34064 (A-MSE: 0.27088) avg lploss: 0.00000
train epoch 1347 avg loss: 0.33576 (A-MSE: 0.26665) avg lploss: 0.00000
train epoch 1348 avg loss: 0.35102 (A-MSE: 0.28318) avg lploss: 0.00000
train epoch 1349 avg loss: 0.34581 (A-MSE: 0.27920) avg lploss: 0.00000
train epoch 1350 avg loss: 0.33024 (A-MSE: 0.26494) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.47534 (A-MSE: 0.37847) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.41312 (A-MSE: 0.32321) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 32 out of 50
train epoch 1351 avg loss: 0.32862 (A-MSE: 0.26053) avg lploss: 0.00000
train epoch 1352 avg loss: 0.34330 (A-MSE: 0.27581) avg lploss: 0.00000
train epoch 1353 avg loss: 0.33822 (A-MSE: 0.27183) avg lploss: 0.00000
train epoch 1354 avg loss: 0.32899 (A-MSE: 0.26103) avg lploss: 0.00000
train epoch 1355 avg loss: 0.32656 (A-MSE: 0.25963) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.47036 (A-MSE: 0.37439) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.40841 (A-MSE: 0.32098) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 33 out of 50
train epoch 1356 avg loss: 0.32799 (A-MSE: 0.26116) avg lploss: 0.00000
train epoch 1357 avg loss: 0.33867 (A-MSE: 0.27187) avg lploss: 0.00000
train epoch 1358 avg loss: 0.32177 (A-MSE: 0.25600) avg lploss: 0.00000
train epoch 1359 avg loss: 0.32529 (A-MSE: 0.25975) avg lploss: 0.00000
train epoch 1360 avg loss: 0.31105 (A-MSE: 0.24684) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.45257 (A-MSE: 0.36386) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.39138 (A-MSE: 0.31119) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 34 out of 50
train epoch 1361 avg loss: 0.31253 (A-MSE: 0.24844) avg lploss: 0.00000
train epoch 1362 avg loss: 0.31994 (A-MSE: 0.25799) avg lploss: 0.00000
train epoch 1363 avg loss: 0.31416 (A-MSE: 0.25108) avg lploss: 0.00000
train epoch 1364 avg loss: 0.31906 (A-MSE: 0.25437) avg lploss: 0.00000
train epoch 1365 avg loss: 0.30958 (A-MSE: 0.24782) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.45249 (A-MSE: 0.35981) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.39306 (A-MSE: 0.30760) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 35 out of 50
train epoch 1366 avg loss: 0.30791 (A-MSE: 0.24635) avg lploss: 0.00000
train epoch 1367 avg loss: 0.31205 (A-MSE: 0.24843) avg lploss: 0.00000
train epoch 1368 avg loss: 0.31048 (A-MSE: 0.24942) avg lploss: 0.00000
train epoch 1369 avg loss: 0.30592 (A-MSE: 0.24494) avg lploss: 0.00000
train epoch 1370 avg loss: 0.30537 (A-MSE: 0.24526) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.43111 (A-MSE: 0.34811) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.37466 (A-MSE: 0.29905) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 36 out of 50
train epoch 1371 avg loss: 0.30969 (A-MSE: 0.24805) avg lploss: 0.00000
train epoch 1372 avg loss: 0.31099 (A-MSE: 0.25051) avg lploss: 0.00000
train epoch 1373 avg loss: 0.30900 (A-MSE: 0.24804) avg lploss: 0.00000
train epoch 1374 avg loss: 0.29585 (A-MSE: 0.23751) avg lploss: 0.00000
train epoch 1375 avg loss: 0.29951 (A-MSE: 0.23953) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.42736 (A-MSE: 0.34560) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.37140 (A-MSE: 0.29582) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 37 out of 50
train epoch 1376 avg loss: 0.30360 (A-MSE: 0.24432) avg lploss: 0.00000
train epoch 1377 avg loss: 0.30873 (A-MSE: 0.24900) avg lploss: 0.00000
train epoch 1378 avg loss: 0.29980 (A-MSE: 0.24090) avg lploss: 0.00000
train epoch 1379 avg loss: 0.29153 (A-MSE: 0.23507) avg lploss: 0.00000
train epoch 1380 avg loss: 0.30437 (A-MSE: 0.24645) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.42693 (A-MSE: 0.34538) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.37225 (A-MSE: 0.29784) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 38 out of 50
train epoch 1381 avg loss: 0.29375 (A-MSE: 0.23569) avg lploss: 0.00000
train epoch 1382 avg loss: 0.28864 (A-MSE: 0.23283) avg lploss: 0.00000
train epoch 1383 avg loss: 0.29867 (A-MSE: 0.24132) avg lploss: 0.00000
train epoch 1384 avg loss: 0.29662 (A-MSE: 0.23978) avg lploss: 0.00000
train epoch 1385 avg loss: 0.29446 (A-MSE: 0.23775) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.45090 (A-MSE: 0.37741) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.38811 (A-MSE: 0.32157) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 39 out of 50
train epoch 1386 avg loss: 0.28849 (A-MSE: 0.23359) avg lploss: 0.00000
train epoch 1387 avg loss: 0.28639 (A-MSE: 0.23017) avg lploss: 0.00000
train epoch 1388 avg loss: 0.29142 (A-MSE: 0.23662) avg lploss: 0.00000
train epoch 1389 avg loss: 0.28719 (A-MSE: 0.23076) avg lploss: 0.00000
train epoch 1390 avg loss: 0.29048 (A-MSE: 0.23400) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.42890 (A-MSE: 0.34893) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.37163 (A-MSE: 0.29826) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 40 out of 50
train epoch 1391 avg loss: 0.29994 (A-MSE: 0.24390) avg lploss: 0.00000
train epoch 1392 avg loss: 0.30208 (A-MSE: 0.24669) avg lploss: 0.00000
train epoch 1393 avg loss: 0.29170 (A-MSE: 0.23490) avg lploss: 0.00000
train epoch 1394 avg loss: 0.28305 (A-MSE: 0.22933) avg lploss: 0.00000
train epoch 1395 avg loss: 0.27588 (A-MSE: 0.22265) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.40196 (A-MSE: 0.33001) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.34635 (A-MSE: 0.27899) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 41 out of 50
train epoch 1396 avg loss: 0.27417 (A-MSE: 0.22246) avg lploss: 0.00000
train epoch 1397 avg loss: 0.28180 (A-MSE: 0.22831) avg lploss: 0.00000
train epoch 1398 avg loss: 0.26694 (A-MSE: 0.21387) avg lploss: 0.00000
train epoch 1399 avg loss: 0.27180 (A-MSE: 0.21921) avg lploss: 0.00000
train epoch 1400 avg loss: 0.26949 (A-MSE: 0.21848) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.38827 (A-MSE: 0.31521) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.33693 (A-MSE: 0.26882) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 42 out of 50
train epoch 1401 avg loss: 0.27602 (A-MSE: 0.22428) avg lploss: 0.00000
train epoch 1402 avg loss: 0.25957 (A-MSE: 0.21017) avg lploss: 0.00000
train epoch 1403 avg loss: 0.27539 (A-MSE: 0.22320) avg lploss: 0.00000
train epoch 1404 avg loss: 0.28995 (A-MSE: 0.23888) avg lploss: 0.00000
train epoch 1405 avg loss: 0.27958 (A-MSE: 0.22804) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.39089 (A-MSE: 0.32352) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.33669 (A-MSE: 0.27384) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 43 out of 50
train epoch 1406 avg loss: 0.26250 (A-MSE: 0.21125) avg lploss: 0.00000
train epoch 1407 avg loss: 0.25940 (A-MSE: 0.21068) avg lploss: 0.00000
train epoch 1408 avg loss: 0.27776 (A-MSE: 0.22901) avg lploss: 0.00000
train epoch 1409 avg loss: 0.26231 (A-MSE: 0.21372) avg lploss: 0.00000
train epoch 1410 avg loss: 0.25969 (A-MSE: 0.21033) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.38011 (A-MSE: 0.30887) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.32629 (A-MSE: 0.26069) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 44 out of 50
train epoch 1411 avg loss: 0.25471 (A-MSE: 0.20739) avg lploss: 0.00000
train epoch 1412 avg loss: 0.25225 (A-MSE: 0.20448) avg lploss: 0.00000
train epoch 1413 avg loss: 0.27309 (A-MSE: 0.22623) avg lploss: 0.00000
train epoch 1414 avg loss: 0.27352 (A-MSE: 0.22246) avg lploss: 0.00000
train epoch 1415 avg loss: 0.25728 (A-MSE: 0.21016) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.37147 (A-MSE: 0.30919) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.32189 (A-MSE: 0.26318) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 45 out of 50
train epoch 1416 avg loss: 0.25468 (A-MSE: 0.20815) avg lploss: 0.00000
train epoch 1417 avg loss: 0.28277 (A-MSE: 0.23393) avg lploss: 0.00000
train epoch 1418 avg loss: 0.27007 (A-MSE: 0.22089) avg lploss: 0.00000
train epoch 1419 avg loss: 0.26844 (A-MSE: 0.22086) avg lploss: 0.00000
train epoch 1420 avg loss: 0.24249 (A-MSE: 0.19937) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.37045 (A-MSE: 0.30866) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.31875 (A-MSE: 0.26271) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 46 out of 50
train epoch 1421 avg loss: 0.24931 (A-MSE: 0.20309) avg lploss: 0.00000
train epoch 1422 avg loss: 0.24730 (A-MSE: 0.20169) avg lploss: 0.00000
train epoch 1423 avg loss: 0.25556 (A-MSE: 0.20869) avg lploss: 0.00000
train epoch 1424 avg loss: 0.24889 (A-MSE: 0.20439) avg lploss: 0.00000
train epoch 1425 avg loss: 0.26353 (A-MSE: 0.21716) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.36950 (A-MSE: 0.30927) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.32115 (A-MSE: 0.26516) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 47 out of 50
train epoch 1426 avg loss: 0.24329 (A-MSE: 0.20020) avg lploss: 0.00000
train epoch 1427 avg loss: 0.24170 (A-MSE: 0.19781) avg lploss: 0.00000
train epoch 1428 avg loss: 0.22932 (A-MSE: 0.18745) avg lploss: 0.00000
train epoch 1429 avg loss: 0.24829 (A-MSE: 0.20423) avg lploss: 0.00000
train epoch 1430 avg loss: 0.23562 (A-MSE: 0.19310) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.36285 (A-MSE: 0.30267) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.30954 (A-MSE: 0.25413) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 48 out of 50
train epoch 1431 avg loss: 0.24221 (A-MSE: 0.19913) avg lploss: 0.00000
train epoch 1432 avg loss: 0.23232 (A-MSE: 0.19092) avg lploss: 0.00000
train epoch 1433 avg loss: 0.23665 (A-MSE: 0.19378) avg lploss: 0.00000
train epoch 1434 avg loss: 0.24263 (A-MSE: 0.19942) avg lploss: 0.00000
train epoch 1435 avg loss: 0.24770 (A-MSE: 0.20374) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.34992 (A-MSE: 0.29295) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.30141 (A-MSE: 0.24822) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 49 out of 50
train epoch 1436 avg loss: 0.23194 (A-MSE: 0.19264) avg lploss: 0.00000
train epoch 1437 avg loss: 0.23435 (A-MSE: 0.19313) avg lploss: 0.00000
train epoch 1438 avg loss: 0.24739 (A-MSE: 0.20382) avg lploss: 0.00000
train epoch 1439 avg loss: 0.24680 (A-MSE: 0.20443) avg lploss: 0.00000
train epoch 1440 avg loss: 0.24294 (A-MSE: 0.20118) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.34439 (A-MSE: 0.28983) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.29936 (A-MSE: 0.24697) avg lploss: 0.00000
*** Best Val Loss: 0.10983 	 Best Test Loss: 0.08515 	 Best epoch 1190
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train_f_mse = 0.050047
best_lp = 0.000000
best_val_f_mse = 0.109834
best_test_f_mse = 0.085149
best_test_a_mse = 0.072807
best_epoch = 1190
best_train_f_mse = 0.050047, best_lp = 0.000000, best_val_f_mse = 0.109834, best_test_f_mse = 0.085149, best_test_a_mse = 0.072807, best_epoch = 1190
Job completed at Mon Dec  8 23:29:32 CET 2025
