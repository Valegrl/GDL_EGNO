Date              = Sat Dec  6 08:06:12 CET 2025
Hostname          = mel2193
Array Task ID     = 1
Running config: configs/mocap_walk_seed2.json
Namespace(batch_size=12, case='walk', config_by_file='configs/mocap_walk_seed2.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_walk_seed2', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='/project/scratch/p200981/egno/logs/mocap', pooling_layer=3, seed=2, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 198 samples!
Got Split!
Got 600 samples!
Got Split!
Got 600 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to /project/scratch/p200981/egno/logs/mocap/mocap_walk_seed2/saved_model.pth
train epoch 0 avg loss: 13.35772 (A-MSE: 11.88214) avg lploss: 0.00000
==> val epoch 0 avg loss: 12.58261 (A-MSE: 11.08052) avg lploss: 0.00000
==> test epoch 0 avg loss: 12.63115 (A-MSE: 11.13428) avg lploss: 0.00000
*** Best Val Loss: 12.58261 	 Best Test Loss: 12.63115 	 Best epoch 0
Validation loss decreased (inf --> 12.582611).  Saving model ...
train epoch 1 avg loss: 11.37927 (A-MSE: 10.00164) avg lploss: 0.00000
train epoch 2 avg loss: 11.58761 (A-MSE: 10.27022) avg lploss: 0.00000
train epoch 3 avg loss: 10.75694 (A-MSE: 9.38968) avg lploss: 0.00000
train epoch 4 avg loss: 10.56399 (A-MSE: 9.18604) avg lploss: 0.00000
train epoch 5 avg loss: 9.91820 (A-MSE: 8.60952) avg lploss: 0.00000
==> val epoch 5 avg loss: 10.00291 (A-MSE: 8.67637) avg lploss: 0.00000
==> test epoch 5 avg loss: 9.96237 (A-MSE: 8.63813) avg lploss: 0.00000
*** Best Val Loss: 10.00291 	 Best Test Loss: 9.96237 	 Best epoch 5
Validation loss decreased (12.582611 --> 10.002906).  Saving model ...
train epoch 6 avg loss: 8.09596 (A-MSE: 6.99040) avg lploss: 0.00000
train epoch 7 avg loss: 6.19214 (A-MSE: 5.33927) avg lploss: 0.00000
train epoch 8 avg loss: 5.18334 (A-MSE: 4.45214) avg lploss: 0.00000
train epoch 9 avg loss: 5.18274 (A-MSE: 4.46611) avg lploss: 0.00000
train epoch 10 avg loss: 4.15558 (A-MSE: 3.58067) avg lploss: 0.00000
==> val epoch 10 avg loss: 4.06435 (A-MSE: 3.46172) avg lploss: 0.00000
==> test epoch 10 avg loss: 3.99284 (A-MSE: 3.39955) avg lploss: 0.00000
*** Best Val Loss: 4.06435 	 Best Test Loss: 3.99284 	 Best epoch 10
Validation loss decreased (10.002906 --> 4.064350).  Saving model ...
train epoch 11 avg loss: 3.24427 (A-MSE: 2.78103) avg lploss: 0.00000
train epoch 12 avg loss: 3.18518 (A-MSE: 2.74390) avg lploss: 0.00000
train epoch 13 avg loss: 2.46852 (A-MSE: 2.12813) avg lploss: 0.00000
train epoch 14 avg loss: 1.64879 (A-MSE: 1.43678) avg lploss: 0.00000
train epoch 15 avg loss: 1.40895 (A-MSE: 1.21021) avg lploss: 0.00000
==> val epoch 15 avg loss: 1.46597 (A-MSE: 1.26188) avg lploss: 0.00000
==> test epoch 15 avg loss: 1.36192 (A-MSE: 1.16880) avg lploss: 0.00000
*** Best Val Loss: 1.46597 	 Best Test Loss: 1.36192 	 Best epoch 15
Validation loss decreased (4.064350 --> 1.465969).  Saving model ...
train epoch 16 avg loss: 1.13429 (A-MSE: 0.98632) avg lploss: 0.00000
train epoch 17 avg loss: 1.00218 (A-MSE: 0.86456) avg lploss: 0.00000
train epoch 18 avg loss: 0.90959 (A-MSE: 0.78870) avg lploss: 0.00000
train epoch 19 avg loss: 0.84612 (A-MSE: 0.73337) avg lploss: 0.00000
train epoch 20 avg loss: 0.75678 (A-MSE: 0.65568) avg lploss: 0.00000
==> val epoch 20 avg loss: 0.89378 (A-MSE: 0.73928) avg lploss: 0.00000
==> test epoch 20 avg loss: 0.81941 (A-MSE: 0.67448) avg lploss: 0.00000
*** Best Val Loss: 0.89378 	 Best Test Loss: 0.81941 	 Best epoch 20
Validation loss decreased (1.465969 --> 0.893783).  Saving model ...
train epoch 21 avg loss: 0.72175 (A-MSE: 0.62836) avg lploss: 0.00000
train epoch 22 avg loss: 0.88604 (A-MSE: 0.77287) avg lploss: 0.00000
train epoch 23 avg loss: 0.70875 (A-MSE: 0.61522) avg lploss: 0.00000
train epoch 24 avg loss: 0.64290 (A-MSE: 0.56211) avg lploss: 0.00000
train epoch 25 avg loss: 0.61341 (A-MSE: 0.53680) avg lploss: 0.00000
==> val epoch 25 avg loss: 0.66536 (A-MSE: 0.57134) avg lploss: 0.00000
==> test epoch 25 avg loss: 0.59969 (A-MSE: 0.51171) avg lploss: 0.00000
*** Best Val Loss: 0.66536 	 Best Test Loss: 0.59969 	 Best epoch 25
Validation loss decreased (0.893783 --> 0.665361).  Saving model ...
train epoch 26 avg loss: 0.58317 (A-MSE: 0.51093) avg lploss: 0.00000
train epoch 27 avg loss: 0.56776 (A-MSE: 0.50081) avg lploss: 0.00000
train epoch 28 avg loss: 0.54560 (A-MSE: 0.47912) avg lploss: 0.00000
train epoch 29 avg loss: 0.56289 (A-MSE: 0.49604) avg lploss: 0.00000
train epoch 30 avg loss: 0.54485 (A-MSE: 0.47976) avg lploss: 0.00000
==> val epoch 30 avg loss: 0.62600 (A-MSE: 0.56699) avg lploss: 0.00000
==> test epoch 30 avg loss: 0.54518 (A-MSE: 0.49150) avg lploss: 0.00000
*** Best Val Loss: 0.62600 	 Best Test Loss: 0.54518 	 Best epoch 30
Validation loss decreased (0.665361 --> 0.625997).  Saving model ...
train epoch 31 avg loss: 0.54129 (A-MSE: 0.47657) avg lploss: 0.00000
train epoch 32 avg loss: 0.47931 (A-MSE: 0.42140) avg lploss: 0.00000
train epoch 33 avg loss: 0.44834 (A-MSE: 0.39850) avg lploss: 0.00000
train epoch 34 avg loss: 0.44073 (A-MSE: 0.39240) avg lploss: 0.00000
train epoch 35 avg loss: 0.44240 (A-MSE: 0.39365) avg lploss: 0.00000
==> val epoch 35 avg loss: 0.52701 (A-MSE: 0.44785) avg lploss: 0.00000
==> test epoch 35 avg loss: 0.49153 (A-MSE: 0.41586) avg lploss: 0.00000
*** Best Val Loss: 0.52701 	 Best Test Loss: 0.49153 	 Best epoch 35
Validation loss decreased (0.625997 --> 0.527011).  Saving model ...
train epoch 36 avg loss: 0.44874 (A-MSE: 0.39984) avg lploss: 0.00000
train epoch 37 avg loss: 0.43436 (A-MSE: 0.38677) avg lploss: 0.00000
train epoch 38 avg loss: 0.40666 (A-MSE: 0.36133) avg lploss: 0.00000
train epoch 39 avg loss: 0.40093 (A-MSE: 0.35782) avg lploss: 0.00000
train epoch 40 avg loss: 0.45782 (A-MSE: 0.40935) avg lploss: 0.00000
==> val epoch 40 avg loss: 0.57144 (A-MSE: 0.50076) avg lploss: 0.00000
==> test epoch 40 avg loss: 0.51308 (A-MSE: 0.44642) avg lploss: 0.00000
*** Best Val Loss: 0.52701 	 Best Test Loss: 0.49153 	 Best epoch 35
EarlyStopping counter: 1 out of 50
train epoch 41 avg loss: 0.42632 (A-MSE: 0.37960) avg lploss: 0.00000
train epoch 42 avg loss: 0.38407 (A-MSE: 0.34194) avg lploss: 0.00000
train epoch 43 avg loss: 0.36315 (A-MSE: 0.32279) avg lploss: 0.00000
train epoch 44 avg loss: 0.40854 (A-MSE: 0.36335) avg lploss: 0.00000
train epoch 45 avg loss: 0.40676 (A-MSE: 0.36104) avg lploss: 0.00000
==> val epoch 45 avg loss: 0.48862 (A-MSE: 0.41663) avg lploss: 0.00000
==> test epoch 45 avg loss: 0.44894 (A-MSE: 0.38084) avg lploss: 0.00000
*** Best Val Loss: 0.48862 	 Best Test Loss: 0.44894 	 Best epoch 45
Validation loss decreased (0.527011 --> 0.488622).  Saving model ...
train epoch 46 avg loss: 0.36394 (A-MSE: 0.32511) avg lploss: 0.00000
train epoch 47 avg loss: 0.37821 (A-MSE: 0.33472) avg lploss: 0.00000
train epoch 48 avg loss: 0.37354 (A-MSE: 0.33350) avg lploss: 0.00000
train epoch 49 avg loss: 0.33886 (A-MSE: 0.30446) avg lploss: 0.00000
train epoch 50 avg loss: 0.37782 (A-MSE: 0.33557) avg lploss: 0.00000
==> val epoch 50 avg loss: 0.38385 (A-MSE: 0.33881) avg lploss: 0.00000
==> test epoch 50 avg loss: 0.33195 (A-MSE: 0.29094) avg lploss: 0.00000
*** Best Val Loss: 0.38385 	 Best Test Loss: 0.33195 	 Best epoch 50
Validation loss decreased (0.488622 --> 0.383853).  Saving model ...
train epoch 51 avg loss: 0.35495 (A-MSE: 0.31690) avg lploss: 0.00000
train epoch 52 avg loss: 0.41069 (A-MSE: 0.36468) avg lploss: 0.00000
train epoch 53 avg loss: 0.38015 (A-MSE: 0.33760) avg lploss: 0.00000
train epoch 54 avg loss: 0.33019 (A-MSE: 0.29505) avg lploss: 0.00000
train epoch 55 avg loss: 0.33719 (A-MSE: 0.30083) avg lploss: 0.00000
==> val epoch 55 avg loss: 0.50033 (A-MSE: 0.43664) avg lploss: 0.00000
==> test epoch 55 avg loss: 0.43148 (A-MSE: 0.37509) avg lploss: 0.00000
*** Best Val Loss: 0.38385 	 Best Test Loss: 0.33195 	 Best epoch 50
EarlyStopping counter: 1 out of 50
train epoch 56 avg loss: 0.30970 (A-MSE: 0.27742) avg lploss: 0.00000
train epoch 57 avg loss: 0.30009 (A-MSE: 0.26689) avg lploss: 0.00000
train epoch 58 avg loss: 0.31886 (A-MSE: 0.28461) avg lploss: 0.00000
train epoch 59 avg loss: 0.30899 (A-MSE: 0.27446) avg lploss: 0.00000
train epoch 60 avg loss: 0.29187 (A-MSE: 0.25879) avg lploss: 0.00000
==> val epoch 60 avg loss: 0.35787 (A-MSE: 0.31558) avg lploss: 0.00000
==> test epoch 60 avg loss: 0.30141 (A-MSE: 0.26537) avg lploss: 0.00000
*** Best Val Loss: 0.35787 	 Best Test Loss: 0.30141 	 Best epoch 60
Validation loss decreased (0.383853 --> 0.357874).  Saving model ...
train epoch 61 avg loss: 0.31360 (A-MSE: 0.27938) avg lploss: 0.00000
train epoch 62 avg loss: 0.30802 (A-MSE: 0.27350) avg lploss: 0.00000
train epoch 63 avg loss: 0.25988 (A-MSE: 0.23225) avg lploss: 0.00000
train epoch 64 avg loss: 0.24127 (A-MSE: 0.21560) avg lploss: 0.00000
train epoch 65 avg loss: 0.27700 (A-MSE: 0.24647) avg lploss: 0.00000
==> val epoch 65 avg loss: 0.33005 (A-MSE: 0.29097) avg lploss: 0.00000
==> test epoch 65 avg loss: 0.27826 (A-MSE: 0.24613) avg lploss: 0.00000
*** Best Val Loss: 0.33005 	 Best Test Loss: 0.27826 	 Best epoch 65
Validation loss decreased (0.357874 --> 0.330049).  Saving model ...
train epoch 66 avg loss: 0.23969 (A-MSE: 0.21355) avg lploss: 0.00000
train epoch 67 avg loss: 0.25968 (A-MSE: 0.23070) avg lploss: 0.00000
train epoch 68 avg loss: 0.26467 (A-MSE: 0.23527) avg lploss: 0.00000
train epoch 69 avg loss: 0.27078 (A-MSE: 0.24093) avg lploss: 0.00000
train epoch 70 avg loss: 0.26767 (A-MSE: 0.23931) avg lploss: 0.00000
==> val epoch 70 avg loss: 0.29724 (A-MSE: 0.26525) avg lploss: 0.00000
==> test epoch 70 avg loss: 0.24555 (A-MSE: 0.21892) avg lploss: 0.00000
*** Best Val Loss: 0.29724 	 Best Test Loss: 0.24555 	 Best epoch 70
Validation loss decreased (0.330049 --> 0.297240).  Saving model ...
train epoch 71 avg loss: 0.26604 (A-MSE: 0.23663) avg lploss: 0.00000
train epoch 72 avg loss: 0.27073 (A-MSE: 0.24186) avg lploss: 0.00000
train epoch 73 avg loss: 0.32282 (A-MSE: 0.28446) avg lploss: 0.00000
train epoch 74 avg loss: 0.26754 (A-MSE: 0.23786) avg lploss: 0.00000
train epoch 75 avg loss: 0.24810 (A-MSE: 0.22145) avg lploss: 0.00000
==> val epoch 75 avg loss: 0.29542 (A-MSE: 0.26233) avg lploss: 0.00000
==> test epoch 75 avg loss: 0.24648 (A-MSE: 0.21916) avg lploss: 0.00000
*** Best Val Loss: 0.29542 	 Best Test Loss: 0.24648 	 Best epoch 75
Validation loss decreased (0.297240 --> 0.295420).  Saving model ...
train epoch 76 avg loss: 0.27744 (A-MSE: 0.24925) avg lploss: 0.00000
train epoch 77 avg loss: 0.27898 (A-MSE: 0.24858) avg lploss: 0.00000
train epoch 78 avg loss: 0.30257 (A-MSE: 0.26953) avg lploss: 0.00000
train epoch 79 avg loss: 0.26733 (A-MSE: 0.23914) avg lploss: 0.00000
train epoch 80 avg loss: 0.22410 (A-MSE: 0.20027) avg lploss: 0.00000
==> val epoch 80 avg loss: 0.28232 (A-MSE: 0.24876) avg lploss: 0.00000
==> test epoch 80 avg loss: 0.23336 (A-MSE: 0.20488) avg lploss: 0.00000
*** Best Val Loss: 0.28232 	 Best Test Loss: 0.23336 	 Best epoch 80
Validation loss decreased (0.295420 --> 0.282320).  Saving model ...
train epoch 81 avg loss: 0.22993 (A-MSE: 0.20495) avg lploss: 0.00000
train epoch 82 avg loss: 0.23789 (A-MSE: 0.21257) avg lploss: 0.00000
train epoch 83 avg loss: 0.23300 (A-MSE: 0.20711) avg lploss: 0.00000
train epoch 84 avg loss: 0.22851 (A-MSE: 0.20370) avg lploss: 0.00000
train epoch 85 avg loss: 0.28809 (A-MSE: 0.25589) avg lploss: 0.00000
==> val epoch 85 avg loss: 0.30994 (A-MSE: 0.27219) avg lploss: 0.00000
==> test epoch 85 avg loss: 0.26942 (A-MSE: 0.23625) avg lploss: 0.00000
*** Best Val Loss: 0.28232 	 Best Test Loss: 0.23336 	 Best epoch 80
EarlyStopping counter: 1 out of 50
train epoch 86 avg loss: 0.24683 (A-MSE: 0.22053) avg lploss: 0.00000
train epoch 87 avg loss: 0.27063 (A-MSE: 0.23983) avg lploss: 0.00000
train epoch 88 avg loss: 0.27005 (A-MSE: 0.24137) avg lploss: 0.00000
train epoch 89 avg loss: 0.24523 (A-MSE: 0.21771) avg lploss: 0.00000
train epoch 90 avg loss: 0.19864 (A-MSE: 0.17697) avg lploss: 0.00000
==> val epoch 90 avg loss: 0.25876 (A-MSE: 0.22759) avg lploss: 0.00000
==> test epoch 90 avg loss: 0.21072 (A-MSE: 0.18533) avg lploss: 0.00000
*** Best Val Loss: 0.25876 	 Best Test Loss: 0.21072 	 Best epoch 90
Validation loss decreased (0.282320 --> 0.258758).  Saving model ...
train epoch 91 avg loss: 0.18983 (A-MSE: 0.16950) avg lploss: 0.00000
train epoch 92 avg loss: 0.21122 (A-MSE: 0.18904) avg lploss: 0.00000
train epoch 93 avg loss: 0.25572 (A-MSE: 0.22748) avg lploss: 0.00000
train epoch 94 avg loss: 0.19499 (A-MSE: 0.17399) avg lploss: 0.00000
train epoch 95 avg loss: 0.21263 (A-MSE: 0.19023) avg lploss: 0.00000
==> val epoch 95 avg loss: 0.23560 (A-MSE: 0.20832) avg lploss: 0.00000
==> test epoch 95 avg loss: 0.19013 (A-MSE: 0.16700) avg lploss: 0.00000
*** Best Val Loss: 0.23560 	 Best Test Loss: 0.19013 	 Best epoch 95
Validation loss decreased (0.258758 --> 0.235604).  Saving model ...
train epoch 96 avg loss: 0.18758 (A-MSE: 0.16741) avg lploss: 0.00000
train epoch 97 avg loss: 0.16561 (A-MSE: 0.14857) avg lploss: 0.00000
train epoch 98 avg loss: 0.19861 (A-MSE: 0.17667) avg lploss: 0.00000
train epoch 99 avg loss: 0.22540 (A-MSE: 0.20073) avg lploss: 0.00000
train epoch 100 avg loss: 0.22105 (A-MSE: 0.19639) avg lploss: 0.00000
==> val epoch 100 avg loss: 0.24949 (A-MSE: 0.22325) avg lploss: 0.00000
==> test epoch 100 avg loss: 0.21570 (A-MSE: 0.19294) avg lploss: 0.00000
*** Best Val Loss: 0.23560 	 Best Test Loss: 0.19013 	 Best epoch 95
EarlyStopping counter: 1 out of 50
train epoch 101 avg loss: 0.19163 (A-MSE: 0.17101) avg lploss: 0.00000
train epoch 102 avg loss: 0.19656 (A-MSE: 0.17467) avg lploss: 0.00000
train epoch 103 avg loss: 0.19609 (A-MSE: 0.17446) avg lploss: 0.00000
train epoch 104 avg loss: 0.19465 (A-MSE: 0.17372) avg lploss: 0.00000
train epoch 105 avg loss: 0.18116 (A-MSE: 0.16183) avg lploss: 0.00000
==> val epoch 105 avg loss: 0.20096 (A-MSE: 0.17675) avg lploss: 0.00000
==> test epoch 105 avg loss: 0.16725 (A-MSE: 0.14635) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
Validation loss decreased (0.235604 --> 0.200962).  Saving model ...
train epoch 106 avg loss: 0.20344 (A-MSE: 0.18009) avg lploss: 0.00000
train epoch 107 avg loss: 0.21170 (A-MSE: 0.18832) avg lploss: 0.00000
train epoch 108 avg loss: 0.19511 (A-MSE: 0.17332) avg lploss: 0.00000
train epoch 109 avg loss: 0.20359 (A-MSE: 0.18095) avg lploss: 0.00000
train epoch 110 avg loss: 0.20557 (A-MSE: 0.18216) avg lploss: 0.00000
==> val epoch 110 avg loss: 0.25776 (A-MSE: 0.23153) avg lploss: 0.00000
==> test epoch 110 avg loss: 0.21396 (A-MSE: 0.19082) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 0.19274 (A-MSE: 0.17244) avg lploss: 0.00000
train epoch 112 avg loss: 0.17483 (A-MSE: 0.15548) avg lploss: 0.00000
train epoch 113 avg loss: 0.16893 (A-MSE: 0.15055) avg lploss: 0.00000
train epoch 114 avg loss: 0.17647 (A-MSE: 0.15637) avg lploss: 0.00000
train epoch 115 avg loss: 0.19229 (A-MSE: 0.17231) avg lploss: 0.00000
==> val epoch 115 avg loss: 0.31189 (A-MSE: 0.28168) avg lploss: 0.00000
==> test epoch 115 avg loss: 0.25999 (A-MSE: 0.23411) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 2 out of 50
train epoch 116 avg loss: 0.18511 (A-MSE: 0.16407) avg lploss: 0.00000
train epoch 117 avg loss: 0.21264 (A-MSE: 0.19032) avg lploss: 0.00000
train epoch 118 avg loss: 0.18261 (A-MSE: 0.16250) avg lploss: 0.00000
train epoch 119 avg loss: 0.15187 (A-MSE: 0.13548) avg lploss: 0.00000
train epoch 120 avg loss: 0.19169 (A-MSE: 0.16981) avg lploss: 0.00000
==> val epoch 120 avg loss: 0.23950 (A-MSE: 0.21408) avg lploss: 0.00000
==> test epoch 120 avg loss: 0.19358 (A-MSE: 0.17134) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 3 out of 50
train epoch 121 avg loss: 0.19397 (A-MSE: 0.17304) avg lploss: 0.00000
train epoch 122 avg loss: 0.20801 (A-MSE: 0.18392) avg lploss: 0.00000
train epoch 123 avg loss: 0.16863 (A-MSE: 0.15069) avg lploss: 0.00000
train epoch 124 avg loss: 0.14897 (A-MSE: 0.13319) avg lploss: 0.00000
train epoch 125 avg loss: 0.15751 (A-MSE: 0.13883) avg lploss: 0.00000
==> val epoch 125 avg loss: 0.26875 (A-MSE: 0.24748) avg lploss: 0.00000
==> test epoch 125 avg loss: 0.22215 (A-MSE: 0.20301) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 4 out of 50
train epoch 126 avg loss: 0.18645 (A-MSE: 0.16633) avg lploss: 0.00000
train epoch 127 avg loss: 0.18257 (A-MSE: 0.16281) avg lploss: 0.00000
train epoch 128 avg loss: 0.18509 (A-MSE: 0.16338) avg lploss: 0.00000
train epoch 129 avg loss: 0.19061 (A-MSE: 0.17024) avg lploss: 0.00000
train epoch 130 avg loss: 0.15762 (A-MSE: 0.13989) avg lploss: 0.00000
==> val epoch 130 avg loss: 0.22985 (A-MSE: 0.20386) avg lploss: 0.00000
==> test epoch 130 avg loss: 0.17096 (A-MSE: 0.15049) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 5 out of 50
train epoch 131 avg loss: 0.18984 (A-MSE: 0.16854) avg lploss: 0.00000
train epoch 132 avg loss: 0.17035 (A-MSE: 0.15124) avg lploss: 0.00000
train epoch 133 avg loss: 0.15998 (A-MSE: 0.14235) avg lploss: 0.00000
train epoch 134 avg loss: 0.15053 (A-MSE: 0.13377) avg lploss: 0.00000
train epoch 135 avg loss: 0.17714 (A-MSE: 0.15720) avg lploss: 0.00000
==> val epoch 135 avg loss: 0.24119 (A-MSE: 0.21101) avg lploss: 0.00000
==> test epoch 135 avg loss: 0.19946 (A-MSE: 0.17428) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 6 out of 50
train epoch 136 avg loss: 0.16300 (A-MSE: 0.14574) avg lploss: 0.00000
train epoch 137 avg loss: 0.15530 (A-MSE: 0.13770) avg lploss: 0.00000
train epoch 138 avg loss: 0.16914 (A-MSE: 0.15092) avg lploss: 0.00000
train epoch 139 avg loss: 0.16331 (A-MSE: 0.14434) avg lploss: 0.00000
train epoch 140 avg loss: 0.15468 (A-MSE: 0.13702) avg lploss: 0.00000
==> val epoch 140 avg loss: 0.22470 (A-MSE: 0.19342) avg lploss: 0.00000
==> test epoch 140 avg loss: 0.17946 (A-MSE: 0.15326) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 7 out of 50
train epoch 141 avg loss: 0.13882 (A-MSE: 0.12346) avg lploss: 0.00000
train epoch 142 avg loss: 0.17600 (A-MSE: 0.15640) avg lploss: 0.00000
train epoch 143 avg loss: 0.18425 (A-MSE: 0.16348) avg lploss: 0.00000
train epoch 144 avg loss: 0.16704 (A-MSE: 0.14844) avg lploss: 0.00000
train epoch 145 avg loss: 0.16856 (A-MSE: 0.14852) avg lploss: 0.00000
==> val epoch 145 avg loss: 0.23505 (A-MSE: 0.20731) avg lploss: 0.00000
==> test epoch 145 avg loss: 0.19408 (A-MSE: 0.17120) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 8 out of 50
train epoch 146 avg loss: 0.17055 (A-MSE: 0.15139) avg lploss: 0.00000
train epoch 147 avg loss: 0.16631 (A-MSE: 0.14692) avg lploss: 0.00000
train epoch 148 avg loss: 0.19463 (A-MSE: 0.17274) avg lploss: 0.00000
train epoch 149 avg loss: 0.15378 (A-MSE: 0.13611) avg lploss: 0.00000
train epoch 150 avg loss: 0.18875 (A-MSE: 0.16841) avg lploss: 0.00000
==> val epoch 150 avg loss: 0.25589 (A-MSE: 0.22609) avg lploss: 0.00000
==> test epoch 150 avg loss: 0.20528 (A-MSE: 0.18134) avg lploss: 0.00000
*** Best Val Loss: 0.20096 	 Best Test Loss: 0.16725 	 Best epoch 105
EarlyStopping counter: 9 out of 50
train epoch 151 avg loss: 0.15254 (A-MSE: 0.13536) avg lploss: 0.00000
train epoch 152 avg loss: 0.15228 (A-MSE: 0.13527) avg lploss: 0.00000
train epoch 153 avg loss: 0.14872 (A-MSE: 0.13197) avg lploss: 0.00000
train epoch 154 avg loss: 0.15008 (A-MSE: 0.13270) avg lploss: 0.00000
train epoch 155 avg loss: 0.14300 (A-MSE: 0.12653) avg lploss: 0.00000
==> val epoch 155 avg loss: 0.18567 (A-MSE: 0.16273) avg lploss: 0.00000
==> test epoch 155 avg loss: 0.14177 (A-MSE: 0.12500) avg lploss: 0.00000
*** Best Val Loss: 0.18567 	 Best Test Loss: 0.14177 	 Best epoch 155
Validation loss decreased (0.200962 --> 0.185675).  Saving model ...
train epoch 156 avg loss: 0.14758 (A-MSE: 0.13060) avg lploss: 0.00000
train epoch 157 avg loss: 0.15596 (A-MSE: 0.13873) avg lploss: 0.00000
train epoch 158 avg loss: 0.17427 (A-MSE: 0.15509) avg lploss: 0.00000
train epoch 159 avg loss: 0.13913 (A-MSE: 0.12357) avg lploss: 0.00000
train epoch 160 avg loss: 0.13617 (A-MSE: 0.12087) avg lploss: 0.00000
==> val epoch 160 avg loss: 0.20278 (A-MSE: 0.17751) avg lploss: 0.00000
==> test epoch 160 avg loss: 0.16379 (A-MSE: 0.14417) avg lploss: 0.00000
*** Best Val Loss: 0.18567 	 Best Test Loss: 0.14177 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 0.15058 (A-MSE: 0.13339) avg lploss: 0.00000
train epoch 162 avg loss: 0.14875 (A-MSE: 0.13173) avg lploss: 0.00000
train epoch 163 avg loss: 0.14300 (A-MSE: 0.12688) avg lploss: 0.00000
train epoch 164 avg loss: 0.12697 (A-MSE: 0.11222) avg lploss: 0.00000
train epoch 165 avg loss: 0.14274 (A-MSE: 0.12567) avg lploss: 0.00000
==> val epoch 165 avg loss: 0.18070 (A-MSE: 0.15924) avg lploss: 0.00000
==> test epoch 165 avg loss: 0.14158 (A-MSE: 0.12473) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
Validation loss decreased (0.185675 --> 0.180696).  Saving model ...
train epoch 166 avg loss: 0.14359 (A-MSE: 0.12772) avg lploss: 0.00000
train epoch 167 avg loss: 0.14412 (A-MSE: 0.12728) avg lploss: 0.00000
train epoch 168 avg loss: 0.14238 (A-MSE: 0.12610) avg lploss: 0.00000
train epoch 169 avg loss: 0.16102 (A-MSE: 0.14359) avg lploss: 0.00000
train epoch 170 avg loss: 0.14737 (A-MSE: 0.13102) avg lploss: 0.00000
==> val epoch 170 avg loss: 0.20947 (A-MSE: 0.18324) avg lploss: 0.00000
==> test epoch 170 avg loss: 0.17373 (A-MSE: 0.15293) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 0.14689 (A-MSE: 0.13069) avg lploss: 0.00000
train epoch 172 avg loss: 0.17616 (A-MSE: 0.15489) avg lploss: 0.00000
train epoch 173 avg loss: 0.14785 (A-MSE: 0.13131) avg lploss: 0.00000
train epoch 174 avg loss: 0.14634 (A-MSE: 0.12848) avg lploss: 0.00000
train epoch 175 avg loss: 0.13818 (A-MSE: 0.12259) avg lploss: 0.00000
==> val epoch 175 avg loss: 0.18211 (A-MSE: 0.15896) avg lploss: 0.00000
==> test epoch 175 avg loss: 0.14008 (A-MSE: 0.12243) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 2 out of 50
train epoch 176 avg loss: 0.13840 (A-MSE: 0.12282) avg lploss: 0.00000
train epoch 177 avg loss: 0.13414 (A-MSE: 0.11954) avg lploss: 0.00000
train epoch 178 avg loss: 0.14976 (A-MSE: 0.13271) avg lploss: 0.00000
train epoch 179 avg loss: 0.14306 (A-MSE: 0.12567) avg lploss: 0.00000
train epoch 180 avg loss: 0.14744 (A-MSE: 0.13040) avg lploss: 0.00000
==> val epoch 180 avg loss: 0.19155 (A-MSE: 0.16585) avg lploss: 0.00000
==> test epoch 180 avg loss: 0.16480 (A-MSE: 0.14316) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 3 out of 50
train epoch 181 avg loss: 0.13594 (A-MSE: 0.12039) avg lploss: 0.00000
train epoch 182 avg loss: 0.14109 (A-MSE: 0.12437) avg lploss: 0.00000
train epoch 183 avg loss: 0.17806 (A-MSE: 0.15674) avg lploss: 0.00000
train epoch 184 avg loss: 0.16957 (A-MSE: 0.15092) avg lploss: 0.00000
train epoch 185 avg loss: 0.14985 (A-MSE: 0.13279) avg lploss: 0.00000
==> val epoch 185 avg loss: 0.20221 (A-MSE: 0.17852) avg lploss: 0.00000
==> test epoch 185 avg loss: 0.17306 (A-MSE: 0.15349) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 4 out of 50
train epoch 186 avg loss: 0.14372 (A-MSE: 0.12646) avg lploss: 0.00000
train epoch 187 avg loss: 0.13918 (A-MSE: 0.12325) avg lploss: 0.00000
train epoch 188 avg loss: 0.12749 (A-MSE: 0.11237) avg lploss: 0.00000
train epoch 189 avg loss: 0.13425 (A-MSE: 0.11893) avg lploss: 0.00000
train epoch 190 avg loss: 0.16219 (A-MSE: 0.14402) avg lploss: 0.00000
==> val epoch 190 avg loss: 0.23604 (A-MSE: 0.20499) avg lploss: 0.00000
==> test epoch 190 avg loss: 0.19478 (A-MSE: 0.16817) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 5 out of 50
train epoch 191 avg loss: 0.15953 (A-MSE: 0.13997) avg lploss: 0.00000
train epoch 192 avg loss: 0.14312 (A-MSE: 0.12524) avg lploss: 0.00000
train epoch 193 avg loss: 0.13308 (A-MSE: 0.11756) avg lploss: 0.00000
train epoch 194 avg loss: 0.12726 (A-MSE: 0.11172) avg lploss: 0.00000
train epoch 195 avg loss: 0.14151 (A-MSE: 0.12559) avg lploss: 0.00000
==> val epoch 195 avg loss: 0.19110 (A-MSE: 0.16462) avg lploss: 0.00000
==> test epoch 195 avg loss: 0.15973 (A-MSE: 0.13674) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 6 out of 50
train epoch 196 avg loss: 0.14800 (A-MSE: 0.13159) avg lploss: 0.00000
train epoch 197 avg loss: 0.13905 (A-MSE: 0.12292) avg lploss: 0.00000
train epoch 198 avg loss: 0.14685 (A-MSE: 0.13067) avg lploss: 0.00000
train epoch 199 avg loss: 0.16640 (A-MSE: 0.14823) avg lploss: 0.00000
train epoch 200 avg loss: 0.12835 (A-MSE: 0.11312) avg lploss: 0.00000
==> val epoch 200 avg loss: 0.23666 (A-MSE: 0.21025) avg lploss: 0.00000
==> test epoch 200 avg loss: 0.20942 (A-MSE: 0.18816) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 7 out of 50
train epoch 201 avg loss: 0.17581 (A-MSE: 0.15619) avg lploss: 0.00000
train epoch 202 avg loss: 0.12744 (A-MSE: 0.11185) avg lploss: 0.00000
train epoch 203 avg loss: 0.12762 (A-MSE: 0.11254) avg lploss: 0.00000
train epoch 204 avg loss: 0.12911 (A-MSE: 0.11375) avg lploss: 0.00000
train epoch 205 avg loss: 0.13632 (A-MSE: 0.12144) avg lploss: 0.00000
==> val epoch 205 avg loss: 0.23277 (A-MSE: 0.20428) avg lploss: 0.00000
==> test epoch 205 avg loss: 0.19224 (A-MSE: 0.16860) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 8 out of 50
train epoch 206 avg loss: 0.12388 (A-MSE: 0.10910) avg lploss: 0.00000
train epoch 207 avg loss: 0.12218 (A-MSE: 0.10773) avg lploss: 0.00000
train epoch 208 avg loss: 0.11589 (A-MSE: 0.10240) avg lploss: 0.00000
train epoch 209 avg loss: 0.11179 (A-MSE: 0.09871) avg lploss: 0.00000
train epoch 210 avg loss: 0.11389 (A-MSE: 0.09952) avg lploss: 0.00000
==> val epoch 210 avg loss: 0.18618 (A-MSE: 0.16308) avg lploss: 0.00000
==> test epoch 210 avg loss: 0.15409 (A-MSE: 0.13497) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 9 out of 50
train epoch 211 avg loss: 0.11449 (A-MSE: 0.10111) avg lploss: 0.00000
train epoch 212 avg loss: 0.11193 (A-MSE: 0.09813) avg lploss: 0.00000
train epoch 213 avg loss: 0.10708 (A-MSE: 0.09401) avg lploss: 0.00000
train epoch 214 avg loss: 0.12737 (A-MSE: 0.11271) avg lploss: 0.00000
train epoch 215 avg loss: 0.13685 (A-MSE: 0.12074) avg lploss: 0.00000
==> val epoch 215 avg loss: 0.23747 (A-MSE: 0.19987) avg lploss: 0.00000
==> test epoch 215 avg loss: 0.20056 (A-MSE: 0.16688) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 10 out of 50
train epoch 216 avg loss: 0.12363 (A-MSE: 0.10884) avg lploss: 0.00000
train epoch 217 avg loss: 0.12099 (A-MSE: 0.10647) avg lploss: 0.00000
train epoch 218 avg loss: 0.11391 (A-MSE: 0.10065) avg lploss: 0.00000
train epoch 219 avg loss: 0.12362 (A-MSE: 0.10856) avg lploss: 0.00000
train epoch 220 avg loss: 0.12254 (A-MSE: 0.10808) avg lploss: 0.00000
==> val epoch 220 avg loss: 0.22075 (A-MSE: 0.19792) avg lploss: 0.00000
==> test epoch 220 avg loss: 0.18017 (A-MSE: 0.16139) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 11 out of 50
train epoch 221 avg loss: 0.12482 (A-MSE: 0.11073) avg lploss: 0.00000
train epoch 222 avg loss: 0.11988 (A-MSE: 0.10621) avg lploss: 0.00000
train epoch 223 avg loss: 0.11028 (A-MSE: 0.09789) avg lploss: 0.00000
train epoch 224 avg loss: 0.11777 (A-MSE: 0.10407) avg lploss: 0.00000
train epoch 225 avg loss: 0.11725 (A-MSE: 0.10362) avg lploss: 0.00000
==> val epoch 225 avg loss: 0.20578 (A-MSE: 0.17856) avg lploss: 0.00000
==> test epoch 225 avg loss: 0.17176 (A-MSE: 0.14835) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 12 out of 50
train epoch 226 avg loss: 0.11669 (A-MSE: 0.10334) avg lploss: 0.00000
train epoch 227 avg loss: 0.10206 (A-MSE: 0.08980) avg lploss: 0.00000
train epoch 228 avg loss: 0.12760 (A-MSE: 0.11263) avg lploss: 0.00000
train epoch 229 avg loss: 0.12521 (A-MSE: 0.11003) avg lploss: 0.00000
train epoch 230 avg loss: 0.11819 (A-MSE: 0.10350) avg lploss: 0.00000
==> val epoch 230 avg loss: 0.24408 (A-MSE: 0.20781) avg lploss: 0.00000
==> test epoch 230 avg loss: 0.20792 (A-MSE: 0.17613) avg lploss: 0.00000
*** Best Val Loss: 0.18070 	 Best Test Loss: 0.14158 	 Best epoch 165
EarlyStopping counter: 13 out of 50
train epoch 231 avg loss: 0.12813 (A-MSE: 0.11218) avg lploss: 0.00000
train epoch 232 avg loss: 0.12676 (A-MSE: 0.11269) avg lploss: 0.00000
train epoch 233 avg loss: 0.11767 (A-MSE: 0.10359) avg lploss: 0.00000
train epoch 234 avg loss: 0.11198 (A-MSE: 0.09883) avg lploss: 0.00000
train epoch 235 avg loss: 0.10871 (A-MSE: 0.09536) avg lploss: 0.00000
==> val epoch 235 avg loss: 0.16021 (A-MSE: 0.14151) avg lploss: 0.00000
==> test epoch 235 avg loss: 0.12469 (A-MSE: 0.10874) avg lploss: 0.00000
*** Best Val Loss: 0.16021 	 Best Test Loss: 0.12469 	 Best epoch 235
Validation loss decreased (0.180696 --> 0.160214).  Saving model ...
train epoch 236 avg loss: 0.10900 (A-MSE: 0.09614) avg lploss: 0.00000
train epoch 237 avg loss: 0.10689 (A-MSE: 0.09459) avg lploss: 0.00000
train epoch 238 avg loss: 0.11001 (A-MSE: 0.09632) avg lploss: 0.00000
train epoch 239 avg loss: 0.12076 (A-MSE: 0.10660) avg lploss: 0.00000
train epoch 240 avg loss: 0.11146 (A-MSE: 0.09894) avg lploss: 0.00000
==> val epoch 240 avg loss: 0.16409 (A-MSE: 0.14298) avg lploss: 0.00000
==> test epoch 240 avg loss: 0.12643 (A-MSE: 0.10943) avg lploss: 0.00000
*** Best Val Loss: 0.16021 	 Best Test Loss: 0.12469 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.11411 (A-MSE: 0.10110) avg lploss: 0.00000
train epoch 242 avg loss: 0.11580 (A-MSE: 0.10150) avg lploss: 0.00000
train epoch 243 avg loss: 0.10199 (A-MSE: 0.09067) avg lploss: 0.00000
train epoch 244 avg loss: 0.10259 (A-MSE: 0.09035) avg lploss: 0.00000
train epoch 245 avg loss: 0.10274 (A-MSE: 0.09024) avg lploss: 0.00000
==> val epoch 245 avg loss: 0.16369 (A-MSE: 0.14569) avg lploss: 0.00000
==> test epoch 245 avg loss: 0.13192 (A-MSE: 0.11714) avg lploss: 0.00000
*** Best Val Loss: 0.16021 	 Best Test Loss: 0.12469 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.09750 (A-MSE: 0.08635) avg lploss: 0.00000
train epoch 247 avg loss: 0.12927 (A-MSE: 0.11321) avg lploss: 0.00000
train epoch 248 avg loss: 0.12298 (A-MSE: 0.10825) avg lploss: 0.00000
train epoch 249 avg loss: 0.10922 (A-MSE: 0.09628) avg lploss: 0.00000
train epoch 250 avg loss: 0.11840 (A-MSE: 0.10392) avg lploss: 0.00000
==> val epoch 250 avg loss: 0.25094 (A-MSE: 0.22006) avg lploss: 0.00000
==> test epoch 250 avg loss: 0.21454 (A-MSE: 0.18877) avg lploss: 0.00000
*** Best Val Loss: 0.16021 	 Best Test Loss: 0.12469 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 0.11146 (A-MSE: 0.09823) avg lploss: 0.00000
train epoch 252 avg loss: 0.12594 (A-MSE: 0.11205) avg lploss: 0.00000
train epoch 253 avg loss: 0.11878 (A-MSE: 0.10503) avg lploss: 0.00000
train epoch 254 avg loss: 0.11281 (A-MSE: 0.09990) avg lploss: 0.00000
train epoch 255 avg loss: 0.12265 (A-MSE: 0.10810) avg lploss: 0.00000
==> val epoch 255 avg loss: 0.15276 (A-MSE: 0.13588) avg lploss: 0.00000
==> test epoch 255 avg loss: 0.12224 (A-MSE: 0.10845) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
Validation loss decreased (0.160214 --> 0.152760).  Saving model ...
train epoch 256 avg loss: 0.12901 (A-MSE: 0.11347) avg lploss: 0.00000
train epoch 257 avg loss: 0.15257 (A-MSE: 0.13379) avg lploss: 0.00000
train epoch 258 avg loss: 0.11737 (A-MSE: 0.10425) avg lploss: 0.00000
train epoch 259 avg loss: 0.10721 (A-MSE: 0.09385) avg lploss: 0.00000
train epoch 260 avg loss: 0.09537 (A-MSE: 0.08405) avg lploss: 0.00000
==> val epoch 260 avg loss: 0.18521 (A-MSE: 0.16136) avg lploss: 0.00000
==> test epoch 260 avg loss: 0.14774 (A-MSE: 0.12800) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 1 out of 50
train epoch 261 avg loss: 0.10122 (A-MSE: 0.08905) avg lploss: 0.00000
train epoch 262 avg loss: 0.11204 (A-MSE: 0.09820) avg lploss: 0.00000
train epoch 263 avg loss: 0.11191 (A-MSE: 0.09772) avg lploss: 0.00000
train epoch 264 avg loss: 0.10823 (A-MSE: 0.09553) avg lploss: 0.00000
train epoch 265 avg loss: 0.12106 (A-MSE: 0.10648) avg lploss: 0.00000
==> val epoch 265 avg loss: 0.18294 (A-MSE: 0.16192) avg lploss: 0.00000
==> test epoch 265 avg loss: 0.13491 (A-MSE: 0.11844) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 2 out of 50
train epoch 266 avg loss: 0.11775 (A-MSE: 0.10332) avg lploss: 0.00000
train epoch 267 avg loss: 0.10001 (A-MSE: 0.08846) avg lploss: 0.00000
train epoch 268 avg loss: 0.09543 (A-MSE: 0.08449) avg lploss: 0.00000
train epoch 269 avg loss: 0.10509 (A-MSE: 0.09213) avg lploss: 0.00000
train epoch 270 avg loss: 0.11147 (A-MSE: 0.09883) avg lploss: 0.00000
==> val epoch 270 avg loss: 0.17308 (A-MSE: 0.14900) avg lploss: 0.00000
==> test epoch 270 avg loss: 0.14486 (A-MSE: 0.12336) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 3 out of 50
train epoch 271 avg loss: 0.11610 (A-MSE: 0.10284) avg lploss: 0.00000
train epoch 272 avg loss: 0.10526 (A-MSE: 0.09295) avg lploss: 0.00000
train epoch 273 avg loss: 0.10861 (A-MSE: 0.09573) avg lploss: 0.00000
train epoch 274 avg loss: 0.08915 (A-MSE: 0.07852) avg lploss: 0.00000
train epoch 275 avg loss: 0.09876 (A-MSE: 0.08735) avg lploss: 0.00000
==> val epoch 275 avg loss: 0.15818 (A-MSE: 0.13625) avg lploss: 0.00000
==> test epoch 275 avg loss: 0.12397 (A-MSE: 0.10662) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 4 out of 50
train epoch 276 avg loss: 0.09871 (A-MSE: 0.08727) avg lploss: 0.00000
train epoch 277 avg loss: 0.11303 (A-MSE: 0.10065) avg lploss: 0.00000
train epoch 278 avg loss: 0.11905 (A-MSE: 0.10459) avg lploss: 0.00000
train epoch 279 avg loss: 0.10789 (A-MSE: 0.09513) avg lploss: 0.00000
train epoch 280 avg loss: 0.10998 (A-MSE: 0.09689) avg lploss: 0.00000
==> val epoch 280 avg loss: 0.16045 (A-MSE: 0.14108) avg lploss: 0.00000
==> test epoch 280 avg loss: 0.13394 (A-MSE: 0.11794) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 5 out of 50
train epoch 281 avg loss: 0.11076 (A-MSE: 0.09747) avg lploss: 0.00000
train epoch 282 avg loss: 0.09866 (A-MSE: 0.08663) avg lploss: 0.00000
train epoch 283 avg loss: 0.09885 (A-MSE: 0.08728) avg lploss: 0.00000
train epoch 284 avg loss: 0.10695 (A-MSE: 0.09441) avg lploss: 0.00000
train epoch 285 avg loss: 0.11026 (A-MSE: 0.09779) avg lploss: 0.00000
==> val epoch 285 avg loss: 0.16602 (A-MSE: 0.14141) avg lploss: 0.00000
==> test epoch 285 avg loss: 0.12768 (A-MSE: 0.10723) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 6 out of 50
train epoch 286 avg loss: 0.09687 (A-MSE: 0.08522) avg lploss: 0.00000
train epoch 287 avg loss: 0.09835 (A-MSE: 0.08641) avg lploss: 0.00000
train epoch 288 avg loss: 0.12698 (A-MSE: 0.11193) avg lploss: 0.00000
train epoch 289 avg loss: 0.12051 (A-MSE: 0.10503) avg lploss: 0.00000
train epoch 290 avg loss: 0.11400 (A-MSE: 0.10100) avg lploss: 0.00000
==> val epoch 290 avg loss: 0.15800 (A-MSE: 0.13974) avg lploss: 0.00000
==> test epoch 290 avg loss: 0.12410 (A-MSE: 0.11034) avg lploss: 0.00000
*** Best Val Loss: 0.15276 	 Best Test Loss: 0.12224 	 Best epoch 255
EarlyStopping counter: 7 out of 50
train epoch 291 avg loss: 0.12406 (A-MSE: 0.10972) avg lploss: 0.00000
train epoch 292 avg loss: 0.09879 (A-MSE: 0.08707) avg lploss: 0.00000
train epoch 293 avg loss: 0.09085 (A-MSE: 0.07926) avg lploss: 0.00000
train epoch 294 avg loss: 0.08604 (A-MSE: 0.07564) avg lploss: 0.00000
train epoch 295 avg loss: 0.08408 (A-MSE: 0.07430) avg lploss: 0.00000
==> val epoch 295 avg loss: 0.15079 (A-MSE: 0.13006) avg lploss: 0.00000
==> test epoch 295 avg loss: 0.11305 (A-MSE: 0.09650) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
Validation loss decreased (0.152760 --> 0.150794).  Saving model ...
train epoch 296 avg loss: 0.09905 (A-MSE: 0.08702) avg lploss: 0.00000
train epoch 297 avg loss: 0.09083 (A-MSE: 0.07960) avg lploss: 0.00000
train epoch 298 avg loss: 0.09294 (A-MSE: 0.08183) avg lploss: 0.00000
train epoch 299 avg loss: 0.12970 (A-MSE: 0.11256) avg lploss: 0.00000
train epoch 300 avg loss: 0.12147 (A-MSE: 0.10806) avg lploss: 0.00000
==> val epoch 300 avg loss: 0.19594 (A-MSE: 0.17418) avg lploss: 0.00000
==> test epoch 300 avg loss: 0.16199 (A-MSE: 0.14385) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 1 out of 50
train epoch 301 avg loss: 0.11218 (A-MSE: 0.09883) avg lploss: 0.00000
train epoch 302 avg loss: 0.10605 (A-MSE: 0.09311) avg lploss: 0.00000
train epoch 303 avg loss: 0.09151 (A-MSE: 0.08094) avg lploss: 0.00000
train epoch 304 avg loss: 0.09565 (A-MSE: 0.08457) avg lploss: 0.00000
train epoch 305 avg loss: 0.10031 (A-MSE: 0.08813) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.16487 (A-MSE: 0.14428) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.12712 (A-MSE: 0.11052) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 2 out of 50
train epoch 306 avg loss: 0.09959 (A-MSE: 0.08739) avg lploss: 0.00000
train epoch 307 avg loss: 0.10390 (A-MSE: 0.09147) avg lploss: 0.00000
train epoch 308 avg loss: 0.10217 (A-MSE: 0.08995) avg lploss: 0.00000
train epoch 309 avg loss: 0.10296 (A-MSE: 0.09138) avg lploss: 0.00000
train epoch 310 avg loss: 0.14197 (A-MSE: 0.12390) avg lploss: 0.00000
==> val epoch 310 avg loss: 0.24579 (A-MSE: 0.21642) avg lploss: 0.00000
==> test epoch 310 avg loss: 0.21585 (A-MSE: 0.19035) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 3 out of 50
train epoch 311 avg loss: 0.12972 (A-MSE: 0.11446) avg lploss: 0.00000
train epoch 312 avg loss: 0.14632 (A-MSE: 0.12811) avg lploss: 0.00000
train epoch 313 avg loss: 0.11540 (A-MSE: 0.10139) avg lploss: 0.00000
train epoch 314 avg loss: 0.10958 (A-MSE: 0.09702) avg lploss: 0.00000
train epoch 315 avg loss: 0.09838 (A-MSE: 0.08632) avg lploss: 0.00000
==> val epoch 315 avg loss: 0.18412 (A-MSE: 0.16550) avg lploss: 0.00000
==> test epoch 315 avg loss: 0.14739 (A-MSE: 0.13444) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 4 out of 50
train epoch 316 avg loss: 0.09584 (A-MSE: 0.08518) avg lploss: 0.00000
train epoch 317 avg loss: 0.08527 (A-MSE: 0.07466) avg lploss: 0.00000
train epoch 318 avg loss: 0.09035 (A-MSE: 0.07950) avg lploss: 0.00000
train epoch 319 avg loss: 0.08459 (A-MSE: 0.07472) avg lploss: 0.00000
train epoch 320 avg loss: 0.08661 (A-MSE: 0.07632) avg lploss: 0.00000
==> val epoch 320 avg loss: 0.15731 (A-MSE: 0.13676) avg lploss: 0.00000
==> test epoch 320 avg loss: 0.12577 (A-MSE: 0.10938) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 5 out of 50
train epoch 321 avg loss: 0.08244 (A-MSE: 0.07261) avg lploss: 0.00000
train epoch 322 avg loss: 0.08132 (A-MSE: 0.07168) avg lploss: 0.00000
train epoch 323 avg loss: 0.08335 (A-MSE: 0.07369) avg lploss: 0.00000
train epoch 324 avg loss: 0.10164 (A-MSE: 0.08880) avg lploss: 0.00000
train epoch 325 avg loss: 0.11349 (A-MSE: 0.10046) avg lploss: 0.00000
==> val epoch 325 avg loss: 0.15527 (A-MSE: 0.13450) avg lploss: 0.00000
==> test epoch 325 avg loss: 0.12447 (A-MSE: 0.10690) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 6 out of 50
train epoch 326 avg loss: 0.12885 (A-MSE: 0.11274) avg lploss: 0.00000
train epoch 327 avg loss: 0.11082 (A-MSE: 0.09901) avg lploss: 0.00000
train epoch 328 avg loss: 0.08900 (A-MSE: 0.07819) avg lploss: 0.00000
train epoch 329 avg loss: 0.08442 (A-MSE: 0.07404) avg lploss: 0.00000
train epoch 330 avg loss: 0.08457 (A-MSE: 0.07471) avg lploss: 0.00000
==> val epoch 330 avg loss: 0.15726 (A-MSE: 0.13928) avg lploss: 0.00000
==> test epoch 330 avg loss: 0.12142 (A-MSE: 0.10831) avg lploss: 0.00000
*** Best Val Loss: 0.15079 	 Best Test Loss: 0.11305 	 Best epoch 295
EarlyStopping counter: 7 out of 50
train epoch 331 avg loss: 0.08078 (A-MSE: 0.07185) avg lploss: 0.00000
train epoch 332 avg loss: 0.08442 (A-MSE: 0.07476) avg lploss: 0.00000
train epoch 333 avg loss: 0.07485 (A-MSE: 0.06575) avg lploss: 0.00000
train epoch 334 avg loss: 0.09785 (A-MSE: 0.08678) avg lploss: 0.00000
train epoch 335 avg loss: 0.09560 (A-MSE: 0.08475) avg lploss: 0.00000
==> val epoch 335 avg loss: 0.14878 (A-MSE: 0.13282) avg lploss: 0.00000
==> test epoch 335 avg loss: 0.10773 (A-MSE: 0.09572) avg lploss: 0.00000
*** Best Val Loss: 0.14878 	 Best Test Loss: 0.10773 	 Best epoch 335
Validation loss decreased (0.150794 --> 0.148780).  Saving model ...
train epoch 336 avg loss: 0.08850 (A-MSE: 0.07764) avg lploss: 0.00000
train epoch 337 avg loss: 0.10043 (A-MSE: 0.08825) avg lploss: 0.00000
train epoch 338 avg loss: 0.09030 (A-MSE: 0.07947) avg lploss: 0.00000
train epoch 339 avg loss: 0.09308 (A-MSE: 0.08255) avg lploss: 0.00000
train epoch 340 avg loss: 0.09536 (A-MSE: 0.08342) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.14944 (A-MSE: 0.13393) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.11513 (A-MSE: 0.10383) avg lploss: 0.00000
*** Best Val Loss: 0.14878 	 Best Test Loss: 0.10773 	 Best epoch 335
EarlyStopping counter: 1 out of 50
train epoch 341 avg loss: 0.09898 (A-MSE: 0.08714) avg lploss: 0.00000
train epoch 342 avg loss: 0.12869 (A-MSE: 0.11302) avg lploss: 0.00000
train epoch 343 avg loss: 0.12055 (A-MSE: 0.10717) avg lploss: 0.00000
train epoch 344 avg loss: 0.10589 (A-MSE: 0.09319) avg lploss: 0.00000
train epoch 345 avg loss: 0.10943 (A-MSE: 0.09649) avg lploss: 0.00000
==> val epoch 345 avg loss: 0.14719 (A-MSE: 0.12902) avg lploss: 0.00000
==> test epoch 345 avg loss: 0.11003 (A-MSE: 0.09662) avg lploss: 0.00000
*** Best Val Loss: 0.14719 	 Best Test Loss: 0.11003 	 Best epoch 345
Validation loss decreased (0.148780 --> 0.147186).  Saving model ...
train epoch 346 avg loss: 0.09377 (A-MSE: 0.08288) avg lploss: 0.00000
train epoch 347 avg loss: 0.08758 (A-MSE: 0.07718) avg lploss: 0.00000
train epoch 348 avg loss: 0.08629 (A-MSE: 0.07645) avg lploss: 0.00000
train epoch 349 avg loss: 0.09051 (A-MSE: 0.07972) avg lploss: 0.00000
train epoch 350 avg loss: 0.08047 (A-MSE: 0.07063) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.14416 (A-MSE: 0.12686) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.11322 (A-MSE: 0.09973) avg lploss: 0.00000
*** Best Val Loss: 0.14416 	 Best Test Loss: 0.11322 	 Best epoch 350
Validation loss decreased (0.147186 --> 0.144163).  Saving model ...
train epoch 351 avg loss: 0.08025 (A-MSE: 0.07050) avg lploss: 0.00000
train epoch 352 avg loss: 0.08861 (A-MSE: 0.07851) avg lploss: 0.00000
train epoch 353 avg loss: 0.09447 (A-MSE: 0.08276) avg lploss: 0.00000
train epoch 354 avg loss: 0.08244 (A-MSE: 0.07302) avg lploss: 0.00000
train epoch 355 avg loss: 0.10458 (A-MSE: 0.09272) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.14522 (A-MSE: 0.12842) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.10844 (A-MSE: 0.09724) avg lploss: 0.00000
*** Best Val Loss: 0.14416 	 Best Test Loss: 0.11322 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.09657 (A-MSE: 0.08427) avg lploss: 0.00000
train epoch 357 avg loss: 0.08321 (A-MSE: 0.07363) avg lploss: 0.00000
train epoch 358 avg loss: 0.07778 (A-MSE: 0.06784) avg lploss: 0.00000
train epoch 359 avg loss: 0.10380 (A-MSE: 0.09214) avg lploss: 0.00000
train epoch 360 avg loss: 0.10772 (A-MSE: 0.09575) avg lploss: 0.00000
==> val epoch 360 avg loss: 0.13695 (A-MSE: 0.12021) avg lploss: 0.00000
==> test epoch 360 avg loss: 0.10630 (A-MSE: 0.09427) avg lploss: 0.00000
*** Best Val Loss: 0.13695 	 Best Test Loss: 0.10630 	 Best epoch 360
Validation loss decreased (0.144163 --> 0.136952).  Saving model ...
train epoch 361 avg loss: 0.08275 (A-MSE: 0.07247) avg lploss: 0.00000
train epoch 362 avg loss: 0.08775 (A-MSE: 0.07723) avg lploss: 0.00000
train epoch 363 avg loss: 0.07824 (A-MSE: 0.06978) avg lploss: 0.00000
train epoch 364 avg loss: 0.08428 (A-MSE: 0.07378) avg lploss: 0.00000
train epoch 365 avg loss: 0.08572 (A-MSE: 0.07563) avg lploss: 0.00000
==> val epoch 365 avg loss: 0.12714 (A-MSE: 0.11119) avg lploss: 0.00000
==> test epoch 365 avg loss: 0.09762 (A-MSE: 0.08648) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
Validation loss decreased (0.136952 --> 0.127140).  Saving model ...
train epoch 366 avg loss: 0.08765 (A-MSE: 0.07777) avg lploss: 0.00000
train epoch 367 avg loss: 0.08502 (A-MSE: 0.07520) avg lploss: 0.00000
train epoch 368 avg loss: 0.09477 (A-MSE: 0.08382) avg lploss: 0.00000
train epoch 369 avg loss: 0.08854 (A-MSE: 0.07869) avg lploss: 0.00000
train epoch 370 avg loss: 0.11022 (A-MSE: 0.09553) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.16255 (A-MSE: 0.14118) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.13269 (A-MSE: 0.11595) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 1 out of 50
train epoch 371 avg loss: 0.09213 (A-MSE: 0.08168) avg lploss: 0.00000
train epoch 372 avg loss: 0.08339 (A-MSE: 0.07318) avg lploss: 0.00000
train epoch 373 avg loss: 0.07806 (A-MSE: 0.06892) avg lploss: 0.00000
train epoch 374 avg loss: 0.07888 (A-MSE: 0.06924) avg lploss: 0.00000
train epoch 375 avg loss: 0.12261 (A-MSE: 0.10791) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.16116 (A-MSE: 0.13593) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.13002 (A-MSE: 0.10914) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 2 out of 50
train epoch 376 avg loss: 0.09429 (A-MSE: 0.08273) avg lploss: 0.00000
train epoch 377 avg loss: 0.08565 (A-MSE: 0.07573) avg lploss: 0.00000
train epoch 378 avg loss: 0.07901 (A-MSE: 0.07007) avg lploss: 0.00000
train epoch 379 avg loss: 0.08591 (A-MSE: 0.07582) avg lploss: 0.00000
train epoch 380 avg loss: 0.07477 (A-MSE: 0.06593) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.13838 (A-MSE: 0.12447) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.10654 (A-MSE: 0.09647) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 3 out of 50
train epoch 381 avg loss: 0.07872 (A-MSE: 0.06978) avg lploss: 0.00000
train epoch 382 avg loss: 0.09402 (A-MSE: 0.08319) avg lploss: 0.00000
train epoch 383 avg loss: 0.08581 (A-MSE: 0.07550) avg lploss: 0.00000
train epoch 384 avg loss: 0.08694 (A-MSE: 0.07760) avg lploss: 0.00000
train epoch 385 avg loss: 0.08891 (A-MSE: 0.07725) avg lploss: 0.00000
==> val epoch 385 avg loss: 0.13739 (A-MSE: 0.12177) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.10063 (A-MSE: 0.08897) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 4 out of 50
train epoch 386 avg loss: 0.09398 (A-MSE: 0.08223) avg lploss: 0.00000
train epoch 387 avg loss: 0.07982 (A-MSE: 0.07053) avg lploss: 0.00000
train epoch 388 avg loss: 0.08426 (A-MSE: 0.07447) avg lploss: 0.00000
train epoch 389 avg loss: 0.08061 (A-MSE: 0.07134) avg lploss: 0.00000
train epoch 390 avg loss: 0.08557 (A-MSE: 0.07602) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.14776 (A-MSE: 0.13163) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.11532 (A-MSE: 0.10315) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 5 out of 50
train epoch 391 avg loss: 0.07541 (A-MSE: 0.06700) avg lploss: 0.00000
train epoch 392 avg loss: 0.07630 (A-MSE: 0.06642) avg lploss: 0.00000
train epoch 393 avg loss: 0.07691 (A-MSE: 0.06800) avg lploss: 0.00000
train epoch 394 avg loss: 0.07867 (A-MSE: 0.06960) avg lploss: 0.00000
train epoch 395 avg loss: 0.08069 (A-MSE: 0.07130) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.20178 (A-MSE: 0.17287) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.16584 (A-MSE: 0.14151) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 6 out of 50
train epoch 396 avg loss: 0.07099 (A-MSE: 0.06263) avg lploss: 0.00000
train epoch 397 avg loss: 0.06783 (A-MSE: 0.06003) avg lploss: 0.00000
train epoch 398 avg loss: 0.08019 (A-MSE: 0.07131) avg lploss: 0.00000
train epoch 399 avg loss: 0.08402 (A-MSE: 0.07458) avg lploss: 0.00000
train epoch 400 avg loss: 0.10352 (A-MSE: 0.09138) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.15667 (A-MSE: 0.13631) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.12567 (A-MSE: 0.10920) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 7 out of 50
train epoch 401 avg loss: 0.10041 (A-MSE: 0.08850) avg lploss: 0.00000
train epoch 402 avg loss: 0.10109 (A-MSE: 0.08959) avg lploss: 0.00000
train epoch 403 avg loss: 13.87461 (A-MSE: 14.04836) avg lploss: 0.00000
train epoch 404 avg loss: 11.43519 (A-MSE: 10.02591) avg lploss: 0.00000
train epoch 405 avg loss: 9.41371 (A-MSE: 8.29452) avg lploss: 0.00000
==> val epoch 405 avg loss: 8.08535 (A-MSE: 7.10221) avg lploss: 0.00000
==> test epoch 405 avg loss: 8.04807 (A-MSE: 7.08624) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 8 out of 50
train epoch 406 avg loss: 5.53119 (A-MSE: 4.87769) avg lploss: 0.00000
train epoch 407 avg loss: 2.75332 (A-MSE: 2.33193) avg lploss: 0.00000
train epoch 408 avg loss: 1.64159 (A-MSE: 1.33823) avg lploss: 0.00000
train epoch 409 avg loss: 1.12732 (A-MSE: 0.93172) avg lploss: 0.00000
train epoch 410 avg loss: 0.87435 (A-MSE: 0.73978) avg lploss: 0.00000
==> val epoch 410 avg loss: 1.03103 (A-MSE: 0.85925) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.93884 (A-MSE: 0.77595) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 9 out of 50
train epoch 411 avg loss: 0.75340 (A-MSE: 0.63915) avg lploss: 0.00000
train epoch 412 avg loss: 0.70346 (A-MSE: 0.59328) avg lploss: 0.00000
train epoch 413 avg loss: 0.64341 (A-MSE: 0.54260) avg lploss: 0.00000
train epoch 414 avg loss: 0.58107 (A-MSE: 0.48861) avg lploss: 0.00000
train epoch 415 avg loss: 0.56699 (A-MSE: 0.48221) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.74124 (A-MSE: 0.63404) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.67525 (A-MSE: 0.57506) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 10 out of 50
train epoch 416 avg loss: 0.52533 (A-MSE: 0.44529) avg lploss: 0.00000
train epoch 417 avg loss: 0.51541 (A-MSE: 0.43610) avg lploss: 0.00000
train epoch 418 avg loss: 0.47893 (A-MSE: 0.40968) avg lploss: 0.00000
train epoch 419 avg loss: 0.48213 (A-MSE: 0.41193) avg lploss: 0.00000
train epoch 420 avg loss: 0.45302 (A-MSE: 0.38568) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.59132 (A-MSE: 0.50925) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.51634 (A-MSE: 0.44093) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 11 out of 50
train epoch 421 avg loss: 0.42546 (A-MSE: 0.36312) avg lploss: 0.00000
train epoch 422 avg loss: 0.43116 (A-MSE: 0.36994) avg lploss: 0.00000
train epoch 423 avg loss: 0.42515 (A-MSE: 0.36534) avg lploss: 0.00000
train epoch 424 avg loss: 0.41690 (A-MSE: 0.35850) avg lploss: 0.00000
train epoch 425 avg loss: 0.40617 (A-MSE: 0.34795) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.55997 (A-MSE: 0.48482) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.48892 (A-MSE: 0.41787) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 12 out of 50
train epoch 426 avg loss: 0.40620 (A-MSE: 0.35074) avg lploss: 0.00000
train epoch 427 avg loss: 0.38691 (A-MSE: 0.33082) avg lploss: 0.00000
train epoch 428 avg loss: 0.35709 (A-MSE: 0.30693) avg lploss: 0.00000
train epoch 429 avg loss: 0.36636 (A-MSE: 0.31442) avg lploss: 0.00000
train epoch 430 avg loss: 0.38095 (A-MSE: 0.32852) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.61382 (A-MSE: 0.53350) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.53183 (A-MSE: 0.45396) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 13 out of 50
train epoch 431 avg loss: 0.40504 (A-MSE: 0.34857) avg lploss: 0.00000
train epoch 432 avg loss: 0.33748 (A-MSE: 0.28964) avg lploss: 0.00000
train epoch 433 avg loss: 0.32872 (A-MSE: 0.28415) avg lploss: 0.00000
train epoch 434 avg loss: 0.35018 (A-MSE: 0.30086) avg lploss: 0.00000
train epoch 435 avg loss: 0.31871 (A-MSE: 0.27481) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.51838 (A-MSE: 0.45482) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.43954 (A-MSE: 0.37960) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 14 out of 50
train epoch 436 avg loss: 0.35392 (A-MSE: 0.30407) avg lploss: 0.00000
train epoch 437 avg loss: 0.32976 (A-MSE: 0.28248) avg lploss: 0.00000
train epoch 438 avg loss: 0.31059 (A-MSE: 0.26777) avg lploss: 0.00000
train epoch 439 avg loss: 0.31683 (A-MSE: 0.27413) avg lploss: 0.00000
train epoch 440 avg loss: 0.29909 (A-MSE: 0.25759) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.48759 (A-MSE: 0.43021) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.40920 (A-MSE: 0.35440) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 15 out of 50
train epoch 441 avg loss: 0.30671 (A-MSE: 0.26450) avg lploss: 0.00000
train epoch 442 avg loss: 0.32583 (A-MSE: 0.28027) avg lploss: 0.00000
train epoch 443 avg loss: 0.32167 (A-MSE: 0.27699) avg lploss: 0.00000
train epoch 444 avg loss: 0.28718 (A-MSE: 0.24709) avg lploss: 0.00000
train epoch 445 avg loss: 0.28048 (A-MSE: 0.24202) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.48016 (A-MSE: 0.42102) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.40819 (A-MSE: 0.35150) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 16 out of 50
train epoch 446 avg loss: 0.27659 (A-MSE: 0.23865) avg lploss: 0.00000
train epoch 447 avg loss: 0.34581 (A-MSE: 0.29747) avg lploss: 0.00000
train epoch 448 avg loss: 0.30185 (A-MSE: 0.26031) avg lploss: 0.00000
train epoch 449 avg loss: 0.28615 (A-MSE: 0.24643) avg lploss: 0.00000
train epoch 450 avg loss: 0.29188 (A-MSE: 0.25224) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.49186 (A-MSE: 0.42840) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.42545 (A-MSE: 0.36631) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 17 out of 50
train epoch 451 avg loss: 0.28434 (A-MSE: 0.24558) avg lploss: 0.00000
train epoch 452 avg loss: 0.27087 (A-MSE: 0.23314) avg lploss: 0.00000
train epoch 453 avg loss: 0.26865 (A-MSE: 0.23153) avg lploss: 0.00000
train epoch 454 avg loss: 0.32350 (A-MSE: 0.27745) avg lploss: 0.00000
train epoch 455 avg loss: 0.29351 (A-MSE: 0.25231) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.42165 (A-MSE: 0.37241) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.36338 (A-MSE: 0.31670) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 18 out of 50
train epoch 456 avg loss: 0.26107 (A-MSE: 0.22685) avg lploss: 0.00000
train epoch 457 avg loss: 0.26306 (A-MSE: 0.22580) avg lploss: 0.00000
train epoch 458 avg loss: 0.25957 (A-MSE: 0.22451) avg lploss: 0.00000
train epoch 459 avg loss: 0.26391 (A-MSE: 0.22809) avg lploss: 0.00000
train epoch 460 avg loss: 0.25056 (A-MSE: 0.21515) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.46548 (A-MSE: 0.40382) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.40345 (A-MSE: 0.34600) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 19 out of 50
train epoch 461 avg loss: 0.25757 (A-MSE: 0.22166) avg lploss: 0.00000
train epoch 462 avg loss: 0.24960 (A-MSE: 0.21511) avg lploss: 0.00000
train epoch 463 avg loss: 0.24204 (A-MSE: 0.20879) avg lploss: 0.00000
train epoch 464 avg loss: 0.25364 (A-MSE: 0.21828) avg lploss: 0.00000
train epoch 465 avg loss: 0.25158 (A-MSE: 0.21643) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.41128 (A-MSE: 0.36373) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.35525 (A-MSE: 0.30927) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 20 out of 50
train epoch 466 avg loss: 0.25078 (A-MSE: 0.21703) avg lploss: 0.00000
train epoch 467 avg loss: 0.26649 (A-MSE: 0.23017) avg lploss: 0.00000
train epoch 468 avg loss: 0.26135 (A-MSE: 0.22478) avg lploss: 0.00000
train epoch 469 avg loss: 0.24047 (A-MSE: 0.20728) avg lploss: 0.00000
train epoch 470 avg loss: 0.23454 (A-MSE: 0.20232) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.39729 (A-MSE: 0.34429) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.33743 (A-MSE: 0.28794) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 21 out of 50
train epoch 471 avg loss: 0.23030 (A-MSE: 0.19805) avg lploss: 0.00000
train epoch 472 avg loss: 0.22200 (A-MSE: 0.19127) avg lploss: 0.00000
train epoch 473 avg loss: 0.22788 (A-MSE: 0.19701) avg lploss: 0.00000
train epoch 474 avg loss: 0.22846 (A-MSE: 0.19748) avg lploss: 0.00000
train epoch 475 avg loss: 0.22972 (A-MSE: 0.19722) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.37397 (A-MSE: 0.32715) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.31298 (A-MSE: 0.27039) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 22 out of 50
train epoch 476 avg loss: 0.21397 (A-MSE: 0.18525) avg lploss: 0.00000
train epoch 477 avg loss: 0.24124 (A-MSE: 0.20738) avg lploss: 0.00000
train epoch 478 avg loss: 0.22688 (A-MSE: 0.19536) avg lploss: 0.00000
train epoch 479 avg loss: 0.22655 (A-MSE: 0.19456) avg lploss: 0.00000
train epoch 480 avg loss: 0.24041 (A-MSE: 0.20597) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.42029 (A-MSE: 0.36085) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.35878 (A-MSE: 0.30427) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 23 out of 50
train epoch 481 avg loss: 0.23757 (A-MSE: 0.20390) avg lploss: 0.00000
train epoch 482 avg loss: 0.22143 (A-MSE: 0.19024) avg lploss: 0.00000
train epoch 483 avg loss: 0.22268 (A-MSE: 0.19196) avg lploss: 0.00000
train epoch 484 avg loss: 0.22211 (A-MSE: 0.19075) avg lploss: 0.00000
train epoch 485 avg loss: 0.24148 (A-MSE: 0.20707) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.40462 (A-MSE: 0.35314) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.33987 (A-MSE: 0.29417) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 24 out of 50
train epoch 486 avg loss: 0.22475 (A-MSE: 0.19366) avg lploss: 0.00000
train epoch 487 avg loss: 0.22440 (A-MSE: 0.19217) avg lploss: 0.00000
train epoch 488 avg loss: 0.21505 (A-MSE: 0.18422) avg lploss: 0.00000
train epoch 489 avg loss: 0.21527 (A-MSE: 0.18529) avg lploss: 0.00000
train epoch 490 avg loss: 0.20348 (A-MSE: 0.17549) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.36157 (A-MSE: 0.31514) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.30388 (A-MSE: 0.26075) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 25 out of 50
train epoch 491 avg loss: 0.20044 (A-MSE: 0.17226) avg lploss: 0.00000
train epoch 492 avg loss: 0.21073 (A-MSE: 0.18147) avg lploss: 0.00000
train epoch 493 avg loss: 0.21326 (A-MSE: 0.18324) avg lploss: 0.00000
train epoch 494 avg loss: 0.18613 (A-MSE: 0.16060) avg lploss: 0.00000
train epoch 495 avg loss: 0.20061 (A-MSE: 0.17235) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.35410 (A-MSE: 0.30696) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.29989 (A-MSE: 0.25708) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 26 out of 50
train epoch 496 avg loss: 0.20733 (A-MSE: 0.17772) avg lploss: 0.00000
train epoch 497 avg loss: 0.21492 (A-MSE: 0.18359) avg lploss: 0.00000
train epoch 498 avg loss: 0.21119 (A-MSE: 0.18061) avg lploss: 0.00000
train epoch 499 avg loss: 0.23113 (A-MSE: 0.19694) avg lploss: 0.00000
train epoch 500 avg loss: 0.23781 (A-MSE: 0.20384) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.38860 (A-MSE: 0.33655) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.34297 (A-MSE: 0.29150) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 27 out of 50
train epoch 501 avg loss: 0.22523 (A-MSE: 0.19372) avg lploss: 0.00000
train epoch 502 avg loss: 0.21087 (A-MSE: 0.18010) avg lploss: 0.00000
train epoch 503 avg loss: 0.19458 (A-MSE: 0.16787) avg lploss: 0.00000
train epoch 504 avg loss: 0.18773 (A-MSE: 0.16214) avg lploss: 0.00000
train epoch 505 avg loss: 0.19923 (A-MSE: 0.17152) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.35608 (A-MSE: 0.30996) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.29423 (A-MSE: 0.25418) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 28 out of 50
train epoch 506 avg loss: 0.18562 (A-MSE: 0.15959) avg lploss: 0.00000
train epoch 507 avg loss: 0.18335 (A-MSE: 0.15845) avg lploss: 0.00000
train epoch 508 avg loss: 0.18643 (A-MSE: 0.16077) avg lploss: 0.00000
train epoch 509 avg loss: 0.19670 (A-MSE: 0.16931) avg lploss: 0.00000
train epoch 510 avg loss: 0.19499 (A-MSE: 0.16694) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.34941 (A-MSE: 0.30370) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.30162 (A-MSE: 0.25818) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 29 out of 50
train epoch 511 avg loss: 0.21085 (A-MSE: 0.18172) avg lploss: 0.00000
train epoch 512 avg loss: 0.19067 (A-MSE: 0.16487) avg lploss: 0.00000
train epoch 513 avg loss: 0.18495 (A-MSE: 0.16018) avg lploss: 0.00000
train epoch 514 avg loss: 0.17661 (A-MSE: 0.15156) avg lploss: 0.00000
train epoch 515 avg loss: 0.17857 (A-MSE: 0.15440) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.32318 (A-MSE: 0.28227) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.26489 (A-MSE: 0.22987) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 30 out of 50
train epoch 516 avg loss: 0.17510 (A-MSE: 0.15119) avg lploss: 0.00000
train epoch 517 avg loss: 0.17354 (A-MSE: 0.14898) avg lploss: 0.00000
train epoch 518 avg loss: 0.16985 (A-MSE: 0.14603) avg lploss: 0.00000
train epoch 519 avg loss: 0.17930 (A-MSE: 0.15455) avg lploss: 0.00000
train epoch 520 avg loss: 0.18526 (A-MSE: 0.15955) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.33062 (A-MSE: 0.28660) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.27949 (A-MSE: 0.23849) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 31 out of 50
train epoch 521 avg loss: 0.18566 (A-MSE: 0.15922) avg lploss: 0.00000
train epoch 522 avg loss: 0.17306 (A-MSE: 0.14953) avg lploss: 0.00000
train epoch 523 avg loss: 0.18601 (A-MSE: 0.16005) avg lploss: 0.00000
train epoch 524 avg loss: 0.18138 (A-MSE: 0.15637) avg lploss: 0.00000
train epoch 525 avg loss: 0.17351 (A-MSE: 0.14918) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.31619 (A-MSE: 0.27551) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.25780 (A-MSE: 0.22325) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 32 out of 50
train epoch 526 avg loss: 0.17249 (A-MSE: 0.14831) avg lploss: 0.00000
train epoch 527 avg loss: 0.17109 (A-MSE: 0.14740) avg lploss: 0.00000
train epoch 528 avg loss: 0.16800 (A-MSE: 0.14452) avg lploss: 0.00000
train epoch 529 avg loss: 0.16912 (A-MSE: 0.14648) avg lploss: 0.00000
train epoch 530 avg loss: 0.18070 (A-MSE: 0.15469) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.34532 (A-MSE: 0.30016) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.28042 (A-MSE: 0.24170) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 33 out of 50
train epoch 531 avg loss: 0.17560 (A-MSE: 0.15240) avg lploss: 0.00000
train epoch 532 avg loss: 0.17502 (A-MSE: 0.15063) avg lploss: 0.00000
train epoch 533 avg loss: 0.17819 (A-MSE: 0.15348) avg lploss: 0.00000
train epoch 534 avg loss: 0.20604 (A-MSE: 0.17692) avg lploss: 0.00000
train epoch 535 avg loss: 0.19030 (A-MSE: 0.16307) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.32128 (A-MSE: 0.28044) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.26432 (A-MSE: 0.22933) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 34 out of 50
train epoch 536 avg loss: 0.16536 (A-MSE: 0.14224) avg lploss: 0.00000
train epoch 537 avg loss: 0.18529 (A-MSE: 0.15992) avg lploss: 0.00000
train epoch 538 avg loss: 0.17094 (A-MSE: 0.14771) avg lploss: 0.00000
train epoch 539 avg loss: 0.16930 (A-MSE: 0.14634) avg lploss: 0.00000
train epoch 540 avg loss: 0.15653 (A-MSE: 0.13503) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.32199 (A-MSE: 0.27854) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.25847 (A-MSE: 0.22213) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 35 out of 50
train epoch 541 avg loss: 0.15269 (A-MSE: 0.13140) avg lploss: 0.00000
train epoch 542 avg loss: 0.15979 (A-MSE: 0.13730) avg lploss: 0.00000
train epoch 543 avg loss: 0.15998 (A-MSE: 0.13792) avg lploss: 0.00000
train epoch 544 avg loss: 0.19281 (A-MSE: 0.16723) avg lploss: 0.00000
train epoch 545 avg loss: 0.17827 (A-MSE: 0.15462) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.32283 (A-MSE: 0.28033) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.26040 (A-MSE: 0.22436) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 36 out of 50
train epoch 546 avg loss: 0.17291 (A-MSE: 0.14958) avg lploss: 0.00000
train epoch 547 avg loss: 0.16755 (A-MSE: 0.14510) avg lploss: 0.00000
train epoch 548 avg loss: 0.19621 (A-MSE: 0.16896) avg lploss: 0.00000
train epoch 549 avg loss: 0.17609 (A-MSE: 0.15200) avg lploss: 0.00000
train epoch 550 avg loss: 0.18361 (A-MSE: 0.15795) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.33631 (A-MSE: 0.29038) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.27932 (A-MSE: 0.23879) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 37 out of 50
train epoch 551 avg loss: 0.19133 (A-MSE: 0.16514) avg lploss: 0.00000
train epoch 552 avg loss: 0.18319 (A-MSE: 0.15829) avg lploss: 0.00000
train epoch 553 avg loss: 0.20788 (A-MSE: 0.17805) avg lploss: 0.00000
train epoch 554 avg loss: 0.16628 (A-MSE: 0.14278) avg lploss: 0.00000
train epoch 555 avg loss: 0.15508 (A-MSE: 0.13367) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.31574 (A-MSE: 0.27215) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.25650 (A-MSE: 0.21991) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 38 out of 50
train epoch 556 avg loss: 0.15831 (A-MSE: 0.13602) avg lploss: 0.00000
train epoch 557 avg loss: 0.15901 (A-MSE: 0.13644) avg lploss: 0.00000
train epoch 558 avg loss: 0.16103 (A-MSE: 0.13925) avg lploss: 0.00000
train epoch 559 avg loss: 0.17335 (A-MSE: 0.15002) avg lploss: 0.00000
train epoch 560 avg loss: 0.17224 (A-MSE: 0.14896) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.30747 (A-MSE: 0.26879) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.25399 (A-MSE: 0.21957) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 39 out of 50
train epoch 561 avg loss: 0.16257 (A-MSE: 0.13999) avg lploss: 0.00000
train epoch 562 avg loss: 0.17300 (A-MSE: 0.14891) avg lploss: 0.00000
train epoch 563 avg loss: 0.16080 (A-MSE: 0.13971) avg lploss: 0.00000
train epoch 564 avg loss: 0.17023 (A-MSE: 0.14656) avg lploss: 0.00000
train epoch 565 avg loss: 0.15997 (A-MSE: 0.13863) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.29575 (A-MSE: 0.25892) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.24292 (A-MSE: 0.21004) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 40 out of 50
train epoch 566 avg loss: 0.15338 (A-MSE: 0.13209) avg lploss: 0.00000
train epoch 567 avg loss: 0.17192 (A-MSE: 0.14762) avg lploss: 0.00000
train epoch 568 avg loss: 0.16093 (A-MSE: 0.13906) avg lploss: 0.00000
train epoch 569 avg loss: 0.15502 (A-MSE: 0.13484) avg lploss: 0.00000
train epoch 570 avg loss: 0.14350 (A-MSE: 0.12490) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.28895 (A-MSE: 0.25125) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.23141 (A-MSE: 0.20017) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 41 out of 50
train epoch 571 avg loss: 0.14945 (A-MSE: 0.12994) avg lploss: 0.00000
train epoch 572 avg loss: 0.17104 (A-MSE: 0.14653) avg lploss: 0.00000
train epoch 573 avg loss: 0.17026 (A-MSE: 0.14705) avg lploss: 0.00000
train epoch 574 avg loss: 0.15837 (A-MSE: 0.13735) avg lploss: 0.00000
train epoch 575 avg loss: 0.14561 (A-MSE: 0.12639) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.29067 (A-MSE: 0.25351) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.23401 (A-MSE: 0.20280) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 42 out of 50
train epoch 576 avg loss: 0.14092 (A-MSE: 0.12254) avg lploss: 0.00000
train epoch 577 avg loss: 0.14946 (A-MSE: 0.13016) avg lploss: 0.00000
train epoch 578 avg loss: 0.14253 (A-MSE: 0.12474) avg lploss: 0.00000
train epoch 579 avg loss: 0.14862 (A-MSE: 0.12883) avg lploss: 0.00000
train epoch 580 avg loss: 0.14410 (A-MSE: 0.12499) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.28626 (A-MSE: 0.24898) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.22874 (A-MSE: 0.19793) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 43 out of 50
train epoch 581 avg loss: 0.14364 (A-MSE: 0.12525) avg lploss: 0.00000
train epoch 582 avg loss: 0.13513 (A-MSE: 0.11786) avg lploss: 0.00000
train epoch 583 avg loss: 0.14101 (A-MSE: 0.12329) avg lploss: 0.00000
train epoch 584 avg loss: 0.14323 (A-MSE: 0.12512) avg lploss: 0.00000
train epoch 585 avg loss: 0.13873 (A-MSE: 0.12096) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.29485 (A-MSE: 0.25623) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.23629 (A-MSE: 0.20421) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 44 out of 50
train epoch 586 avg loss: 0.14340 (A-MSE: 0.12505) avg lploss: 0.00000
train epoch 587 avg loss: 0.13370 (A-MSE: 0.11657) avg lploss: 0.00000
train epoch 588 avg loss: 0.13096 (A-MSE: 0.11404) avg lploss: 0.00000
train epoch 589 avg loss: 0.14088 (A-MSE: 0.12225) avg lploss: 0.00000
train epoch 590 avg loss: 0.14543 (A-MSE: 0.12565) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.28209 (A-MSE: 0.24993) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.22756 (A-MSE: 0.20124) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 45 out of 50
train epoch 591 avg loss: 0.15210 (A-MSE: 0.13193) avg lploss: 0.00000
train epoch 592 avg loss: 0.13338 (A-MSE: 0.11646) avg lploss: 0.00000
train epoch 593 avg loss: 0.14252 (A-MSE: 0.12368) avg lploss: 0.00000
train epoch 594 avg loss: 0.12518 (A-MSE: 0.10969) avg lploss: 0.00000
train epoch 595 avg loss: 0.12630 (A-MSE: 0.11043) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.28445 (A-MSE: 0.24669) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.22048 (A-MSE: 0.19029) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 46 out of 50
train epoch 596 avg loss: 0.13734 (A-MSE: 0.12074) avg lploss: 0.00000
train epoch 597 avg loss: 0.14516 (A-MSE: 0.12716) avg lploss: 0.00000
train epoch 598 avg loss: 0.14224 (A-MSE: 0.12388) avg lploss: 0.00000
train epoch 599 avg loss: 0.13521 (A-MSE: 0.11835) avg lploss: 0.00000
train epoch 600 avg loss: 0.13324 (A-MSE: 0.11549) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.28594 (A-MSE: 0.24907) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.23730 (A-MSE: 0.20552) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 47 out of 50
train epoch 601 avg loss: 0.13278 (A-MSE: 0.11580) avg lploss: 0.00000
train epoch 602 avg loss: 0.12756 (A-MSE: 0.11235) avg lploss: 0.00000
train epoch 603 avg loss: 0.12943 (A-MSE: 0.11266) avg lploss: 0.00000
train epoch 604 avg loss: 0.13402 (A-MSE: 0.11618) avg lploss: 0.00000
train epoch 605 avg loss: 0.15249 (A-MSE: 0.13124) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.29277 (A-MSE: 0.25844) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.23787 (A-MSE: 0.20981) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 48 out of 50
train epoch 606 avg loss: 0.13793 (A-MSE: 0.12042) avg lploss: 0.00000
train epoch 607 avg loss: 0.14578 (A-MSE: 0.12648) avg lploss: 0.00000
train epoch 608 avg loss: 0.14337 (A-MSE: 0.12616) avg lploss: 0.00000
train epoch 609 avg loss: 0.13722 (A-MSE: 0.12015) avg lploss: 0.00000
train epoch 610 avg loss: 0.13076 (A-MSE: 0.11487) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.28728 (A-MSE: 0.25136) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.23391 (A-MSE: 0.20416) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 49 out of 50
train epoch 611 avg loss: 0.12593 (A-MSE: 0.11028) avg lploss: 0.00000
train epoch 612 avg loss: 0.13887 (A-MSE: 0.12038) avg lploss: 0.00000
train epoch 613 avg loss: 0.14559 (A-MSE: 0.12697) avg lploss: 0.00000
train epoch 614 avg loss: 0.13504 (A-MSE: 0.11874) avg lploss: 0.00000
train epoch 615 avg loss: 0.13173 (A-MSE: 0.11492) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.26723 (A-MSE: 0.23594) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.21215 (A-MSE: 0.18765) avg lploss: 0.00000
*** Best Val Loss: 0.12714 	 Best Test Loss: 0.09762 	 Best epoch 365
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.085723
best_lp = 0.000000
best_val = 0.127140
best_test = 0.097616
best_epoch = 365
best_train = 0.085723, best_lp = 0.000000, best_val = 0.127140, best_test = 0.097616, best_epoch = 365
Job completed at Sat Dec  6 08:14:02 CET 2025
