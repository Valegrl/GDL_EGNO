Running Mocap-Run with num_modes=1 for seed 1
Job ID: 3831009, Array Task ID: 1
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes1_seed1.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes1_seed1', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=1, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=1, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes1_seed1/saved_model.pth
train epoch 0 avg loss: 287.03307 (A-MSE: 301.65508) avg lploss: 0.00000
==> val epoch 0 avg loss: 92.18912 (A-MSE: 83.70558) avg lploss: 0.00000
==> test epoch 0 avg loss: 106.47704 (A-MSE: 98.91542) avg lploss: 0.00000
*** Best Val Loss: 92.18912 	 Best Test Loss: 106.47704 	 Best epoch 0
Validation loss decreased (inf --> 92.189123).  Saving model ...
train epoch 1 avg loss: 73.29844 (A-MSE: 64.35777) avg lploss: 0.00000
train epoch 2 avg loss: 84.89084 (A-MSE: 72.84563) avg lploss: 0.00000
train epoch 3 avg loss: 77.46941 (A-MSE: 67.64680) avg lploss: 0.00000
train epoch 4 avg loss: 76.06753 (A-MSE: 66.42809) avg lploss: 0.00000
train epoch 5 avg loss: 72.64579 (A-MSE: 63.52506) avg lploss: 0.00000
==> val epoch 5 avg loss: 71.63014 (A-MSE: 62.43964) avg lploss: 0.00000
==> test epoch 5 avg loss: 67.92637 (A-MSE: 59.22813) avg lploss: 0.00000
*** Best Val Loss: 71.63014 	 Best Test Loss: 67.92637 	 Best epoch 5
Validation loss decreased (92.189123 --> 71.630140).  Saving model ...
train epoch 6 avg loss: 68.88630 (A-MSE: 60.07704) avg lploss: 0.00000
train epoch 7 avg loss: 62.92087 (A-MSE: 54.60197) avg lploss: 0.00000
train epoch 8 avg loss: 52.28806 (A-MSE: 45.07251) avg lploss: 0.00000
train epoch 9 avg loss: 41.42454 (A-MSE: 35.62227) avg lploss: 0.00000
train epoch 10 avg loss: 33.71711 (A-MSE: 28.90338) avg lploss: 0.00000
==> val epoch 10 avg loss: 30.77507 (A-MSE: 26.24973) avg lploss: 0.00000
==> test epoch 10 avg loss: 29.31635 (A-MSE: 24.99109) avg lploss: 0.00000
*** Best Val Loss: 30.77507 	 Best Test Loss: 29.31635 	 Best epoch 10
Validation loss decreased (71.630140 --> 30.775069).  Saving model ...
train epoch 11 avg loss: 29.96739 (A-MSE: 25.71056) avg lploss: 0.00000
train epoch 12 avg loss: 26.29004 (A-MSE: 22.55733) avg lploss: 0.00000
train epoch 13 avg loss: 24.56307 (A-MSE: 21.11397) avg lploss: 0.00000
train epoch 14 avg loss: 22.62166 (A-MSE: 19.35189) avg lploss: 0.00000
train epoch 15 avg loss: 21.19013 (A-MSE: 18.19883) avg lploss: 0.00000
==> val epoch 15 avg loss: 19.86111 (A-MSE: 17.01320) avg lploss: 0.00000
==> test epoch 15 avg loss: 18.66930 (A-MSE: 15.90071) avg lploss: 0.00000
*** Best Val Loss: 19.86111 	 Best Test Loss: 18.66930 	 Best epoch 15
Validation loss decreased (30.775069 --> 19.861113).  Saving model ...
train epoch 16 avg loss: 20.55058 (A-MSE: 17.71093) avg lploss: 0.00000
train epoch 17 avg loss: 19.36432 (A-MSE: 16.57198) avg lploss: 0.00000
train epoch 18 avg loss: 18.91516 (A-MSE: 16.31377) avg lploss: 0.00000
train epoch 19 avg loss: 18.26672 (A-MSE: 15.64037) avg lploss: 0.00000
train epoch 20 avg loss: 17.42255 (A-MSE: 14.95624) avg lploss: 0.00000
==> val epoch 20 avg loss: 16.26190 (A-MSE: 13.96099) avg lploss: 0.00000
==> test epoch 20 avg loss: 15.45183 (A-MSE: 13.21143) avg lploss: 0.00000
*** Best Val Loss: 16.26190 	 Best Test Loss: 15.45183 	 Best epoch 20
Validation loss decreased (19.861113 --> 16.261903).  Saving model ...
train epoch 21 avg loss: 16.80587 (A-MSE: 14.45244) avg lploss: 0.00000
train epoch 22 avg loss: 15.85966 (A-MSE: 13.56248) avg lploss: 0.00000
train epoch 23 avg loss: 15.14760 (A-MSE: 13.00831) avg lploss: 0.00000
train epoch 24 avg loss: 14.96915 (A-MSE: 12.85501) avg lploss: 0.00000
train epoch 25 avg loss: 13.87873 (A-MSE: 11.94055) avg lploss: 0.00000
==> val epoch 25 avg loss: 13.01893 (A-MSE: 11.29053) avg lploss: 0.00000
==> test epoch 25 avg loss: 12.28603 (A-MSE: 10.61866) avg lploss: 0.00000
*** Best Val Loss: 13.01893 	 Best Test Loss: 12.28603 	 Best epoch 25
Validation loss decreased (16.261903 --> 13.018933).  Saving model ...
train epoch 26 avg loss: 13.44070 (A-MSE: 11.60441) avg lploss: 0.00000
train epoch 27 avg loss: 12.97825 (A-MSE: 11.15417) avg lploss: 0.00000
train epoch 28 avg loss: 12.64287 (A-MSE: 10.87288) avg lploss: 0.00000
train epoch 29 avg loss: 12.08946 (A-MSE: 10.42777) avg lploss: 0.00000
train epoch 30 avg loss: 12.47813 (A-MSE: 10.78041) avg lploss: 0.00000
==> val epoch 30 avg loss: 11.53787 (A-MSE: 9.99292) avg lploss: 0.00000
==> test epoch 30 avg loss: 11.01910 (A-MSE: 9.56406) avg lploss: 0.00000
*** Best Val Loss: 11.53787 	 Best Test Loss: 11.01910 	 Best epoch 30
Validation loss decreased (13.018933 --> 11.537873).  Saving model ...
train epoch 31 avg loss: 12.15764 (A-MSE: 10.47996) avg lploss: 0.00000
train epoch 32 avg loss: 11.73806 (A-MSE: 10.11406) avg lploss: 0.00000
train epoch 33 avg loss: 11.25459 (A-MSE: 9.70184) avg lploss: 0.00000
train epoch 34 avg loss: 11.10424 (A-MSE: 9.58121) avg lploss: 0.00000
train epoch 35 avg loss: 11.02338 (A-MSE: 9.52245) avg lploss: 0.00000
==> val epoch 35 avg loss: 10.59298 (A-MSE: 8.84426) avg lploss: 0.00000
==> test epoch 35 avg loss: 9.98883 (A-MSE: 8.35035) avg lploss: 0.00000
*** Best Val Loss: 10.59298 	 Best Test Loss: 9.98883 	 Best epoch 35
Validation loss decreased (11.537873 --> 10.592979).  Saving model ...
train epoch 36 avg loss: 10.46588 (A-MSE: 9.03007) avg lploss: 0.00000
train epoch 37 avg loss: 10.06399 (A-MSE: 8.70084) avg lploss: 0.00000
train epoch 38 avg loss: 9.68777 (A-MSE: 8.37032) avg lploss: 0.00000
train epoch 39 avg loss: 9.53078 (A-MSE: 8.23743) avg lploss: 0.00000
train epoch 40 avg loss: 9.99541 (A-MSE: 8.64606) avg lploss: 0.00000
==> val epoch 40 avg loss: 9.72404 (A-MSE: 8.27354) avg lploss: 0.00000
==> test epoch 40 avg loss: 9.24158 (A-MSE: 7.90212) avg lploss: 0.00000
*** Best Val Loss: 9.72404 	 Best Test Loss: 9.24158 	 Best epoch 40
Validation loss decreased (10.592979 --> 9.724038).  Saving model ...
train epoch 41 avg loss: 9.35275 (A-MSE: 8.07831) avg lploss: 0.00000
train epoch 42 avg loss: 8.86771 (A-MSE: 7.68446) avg lploss: 0.00000
train epoch 43 avg loss: 8.87270 (A-MSE: 7.66414) avg lploss: 0.00000
train epoch 44 avg loss: 8.57432 (A-MSE: 7.44767) avg lploss: 0.00000
train epoch 45 avg loss: 8.14987 (A-MSE: 7.04801) avg lploss: 0.00000
==> val epoch 45 avg loss: 8.64500 (A-MSE: 7.27673) avg lploss: 0.00000
==> test epoch 45 avg loss: 8.43017 (A-MSE: 7.15113) avg lploss: 0.00000
*** Best Val Loss: 8.64500 	 Best Test Loss: 8.43017 	 Best epoch 45
Validation loss decreased (9.724038 --> 8.644997).  Saving model ...
train epoch 46 avg loss: 8.25369 (A-MSE: 7.15439) avg lploss: 0.00000
train epoch 47 avg loss: 8.22286 (A-MSE: 7.13982) avg lploss: 0.00000
train epoch 48 avg loss: 7.91691 (A-MSE: 6.83916) avg lploss: 0.00000
train epoch 49 avg loss: 7.49274 (A-MSE: 6.48889) avg lploss: 0.00000
train epoch 50 avg loss: 7.76110 (A-MSE: 6.73057) avg lploss: 0.00000
==> val epoch 50 avg loss: 8.00530 (A-MSE: 6.85339) avg lploss: 0.00000
==> test epoch 50 avg loss: 7.65824 (A-MSE: 6.59749) avg lploss: 0.00000
*** Best Val Loss: 8.00530 	 Best Test Loss: 7.65824 	 Best epoch 50
Validation loss decreased (8.644997 --> 8.005299).  Saving model ...
train epoch 51 avg loss: 7.77835 (A-MSE: 6.73166) avg lploss: 0.00000
train epoch 52 avg loss: 7.18511 (A-MSE: 6.21311) avg lploss: 0.00000
train epoch 53 avg loss: 6.76136 (A-MSE: 5.86426) avg lploss: 0.00000
train epoch 54 avg loss: 7.14124 (A-MSE: 6.19385) avg lploss: 0.00000
train epoch 55 avg loss: 7.57547 (A-MSE: 6.56859) avg lploss: 0.00000
==> val epoch 55 avg loss: 7.39369 (A-MSE: 6.21059) avg lploss: 0.00000
==> test epoch 55 avg loss: 7.12356 (A-MSE: 6.03219) avg lploss: 0.00000
*** Best Val Loss: 7.39369 	 Best Test Loss: 7.12356 	 Best epoch 55
Validation loss decreased (8.005299 --> 7.393690).  Saving model ...
train epoch 56 avg loss: 6.52896 (A-MSE: 5.66791) avg lploss: 0.00000
train epoch 57 avg loss: 6.35732 (A-MSE: 5.48972) avg lploss: 0.00000
train epoch 58 avg loss: 6.50284 (A-MSE: 5.62648) avg lploss: 0.00000
train epoch 59 avg loss: 6.35645 (A-MSE: 5.48494) avg lploss: 0.00000
train epoch 60 avg loss: 6.04702 (A-MSE: 5.21039) avg lploss: 0.00000
==> val epoch 60 avg loss: 6.42761 (A-MSE: 5.83880) avg lploss: 0.00000
==> test epoch 60 avg loss: 6.26145 (A-MSE: 5.75331) avg lploss: 0.00000
*** Best Val Loss: 6.42761 	 Best Test Loss: 6.26145 	 Best epoch 60
Validation loss decreased (7.393690 --> 6.427614).  Saving model ...
train epoch 61 avg loss: 5.56934 (A-MSE: 4.85102) avg lploss: 0.00000
train epoch 62 avg loss: 5.31845 (A-MSE: 4.56635) avg lploss: 0.00000
train epoch 63 avg loss: 5.31274 (A-MSE: 4.59943) avg lploss: 0.00000
train epoch 64 avg loss: 5.78821 (A-MSE: 4.99558) avg lploss: 0.00000
train epoch 65 avg loss: 5.86726 (A-MSE: 5.08308) avg lploss: 0.00000
==> val epoch 65 avg loss: 6.24232 (A-MSE: 5.42242) avg lploss: 0.00000
==> test epoch 65 avg loss: 5.98345 (A-MSE: 5.23970) avg lploss: 0.00000
*** Best Val Loss: 6.24232 	 Best Test Loss: 5.98345 	 Best epoch 65
Validation loss decreased (6.427614 --> 6.242319).  Saving model ...
train epoch 66 avg loss: 5.34390 (A-MSE: 4.61578) avg lploss: 0.00000
train epoch 67 avg loss: 5.14860 (A-MSE: 4.44752) avg lploss: 0.00000
train epoch 68 avg loss: 4.91654 (A-MSE: 4.27316) avg lploss: 0.00000
train epoch 69 avg loss: 4.73460 (A-MSE: 4.06070) avg lploss: 0.00000
train epoch 70 avg loss: 4.74440 (A-MSE: 4.08730) avg lploss: 0.00000
==> val epoch 70 avg loss: 5.08749 (A-MSE: 4.21560) avg lploss: 0.00000
==> test epoch 70 avg loss: 5.15552 (A-MSE: 4.35737) avg lploss: 0.00000
*** Best Val Loss: 5.08749 	 Best Test Loss: 5.15552 	 Best epoch 70
Validation loss decreased (6.242319 --> 5.087488).  Saving model ...
train epoch 71 avg loss: 4.49357 (A-MSE: 3.88727) avg lploss: 0.00000
train epoch 72 avg loss: 4.65307 (A-MSE: 4.01424) avg lploss: 0.00000
train epoch 73 avg loss: 5.00258 (A-MSE: 4.33007) avg lploss: 0.00000
train epoch 74 avg loss: 4.56492 (A-MSE: 3.94826) avg lploss: 0.00000
train epoch 75 avg loss: 4.45831 (A-MSE: 3.84499) avg lploss: 0.00000
==> val epoch 75 avg loss: 4.90669 (A-MSE: 4.16419) avg lploss: 0.00000
==> test epoch 75 avg loss: 4.87628 (A-MSE: 4.22755) avg lploss: 0.00000
*** Best Val Loss: 4.90669 	 Best Test Loss: 4.87628 	 Best epoch 75
Validation loss decreased (5.087488 --> 4.906690).  Saving model ...
train epoch 76 avg loss: 4.37046 (A-MSE: 3.79919) avg lploss: 0.00000
train epoch 77 avg loss: 4.18080 (A-MSE: 3.58469) avg lploss: 0.00000
train epoch 78 avg loss: 4.25551 (A-MSE: 3.68231) avg lploss: 0.00000
train epoch 79 avg loss: 3.84947 (A-MSE: 3.30289) avg lploss: 0.00000
train epoch 80 avg loss: 3.99864 (A-MSE: 3.44521) avg lploss: 0.00000
==> val epoch 80 avg loss: 4.39644 (A-MSE: 3.76365) avg lploss: 0.00000
==> test epoch 80 avg loss: 4.46345 (A-MSE: 3.91122) avg lploss: 0.00000
*** Best Val Loss: 4.39644 	 Best Test Loss: 4.46345 	 Best epoch 80
Validation loss decreased (4.906690 --> 4.396443).  Saving model ...
train epoch 81 avg loss: 3.64423 (A-MSE: 3.14630) avg lploss: 0.00000
train epoch 82 avg loss: 4.03479 (A-MSE: 3.52256) avg lploss: 0.00000
train epoch 83 avg loss: 4.00939 (A-MSE: 3.43050) avg lploss: 0.00000
train epoch 84 avg loss: 3.94422 (A-MSE: 3.42182) avg lploss: 0.00000
train epoch 85 avg loss: 3.77257 (A-MSE: 3.25636) avg lploss: 0.00000
==> val epoch 85 avg loss: 3.97882 (A-MSE: 3.40166) avg lploss: 0.00000
==> test epoch 85 avg loss: 4.05266 (A-MSE: 3.54817) avg lploss: 0.00000
*** Best Val Loss: 3.97882 	 Best Test Loss: 4.05266 	 Best epoch 85
Validation loss decreased (4.396443 --> 3.978822).  Saving model ...
train epoch 86 avg loss: 3.21931 (A-MSE: 2.77504) avg lploss: 0.00000
train epoch 87 avg loss: 3.26235 (A-MSE: 2.81150) avg lploss: 0.00000
train epoch 88 avg loss: 3.24181 (A-MSE: 2.82093) avg lploss: 0.00000
train epoch 89 avg loss: 3.53937 (A-MSE: 3.05140) avg lploss: 0.00000
train epoch 90 avg loss: 3.25795 (A-MSE: 2.80227) avg lploss: 0.00000
==> val epoch 90 avg loss: 4.12687 (A-MSE: 3.55498) avg lploss: 0.00000
==> test epoch 90 avg loss: 4.19974 (A-MSE: 3.70399) avg lploss: 0.00000
*** Best Val Loss: 3.97882 	 Best Test Loss: 4.05266 	 Best epoch 85
EarlyStopping counter: 1 out of 50
train epoch 91 avg loss: 3.25410 (A-MSE: 2.80836) avg lploss: 0.00000
train epoch 92 avg loss: 3.26812 (A-MSE: 2.82563) avg lploss: 0.00000
train epoch 93 avg loss: 3.11246 (A-MSE: 2.67494) avg lploss: 0.00000
train epoch 94 avg loss: 3.06468 (A-MSE: 2.65346) avg lploss: 0.00000
train epoch 95 avg loss: 2.89643 (A-MSE: 2.49252) avg lploss: 0.00000
==> val epoch 95 avg loss: 4.02105 (A-MSE: 3.46860) avg lploss: 0.00000
==> test epoch 95 avg loss: 4.17373 (A-MSE: 3.69053) avg lploss: 0.00000
*** Best Val Loss: 3.97882 	 Best Test Loss: 4.05266 	 Best epoch 85
EarlyStopping counter: 2 out of 50
train epoch 96 avg loss: 3.01145 (A-MSE: 2.59205) avg lploss: 0.00000
train epoch 97 avg loss: 2.95581 (A-MSE: 2.54466) avg lploss: 0.00000
train epoch 98 avg loss: 3.08665 (A-MSE: 2.67103) avg lploss: 0.00000
train epoch 99 avg loss: 2.80597 (A-MSE: 2.40603) avg lploss: 0.00000
train epoch 100 avg loss: 2.89158 (A-MSE: 2.49818) avg lploss: 0.00000
==> val epoch 100 avg loss: 3.29443 (A-MSE: 2.84457) avg lploss: 0.00000
==> test epoch 100 avg loss: 3.36975 (A-MSE: 2.97658) avg lploss: 0.00000
*** Best Val Loss: 3.29443 	 Best Test Loss: 3.36975 	 Best epoch 100
Validation loss decreased (3.978822 --> 3.294429).  Saving model ...
train epoch 101 avg loss: 2.85141 (A-MSE: 2.44534) avg lploss: 0.00000
train epoch 102 avg loss: 2.85418 (A-MSE: 2.47681) avg lploss: 0.00000
train epoch 103 avg loss: 2.68619 (A-MSE: 2.29816) avg lploss: 0.00000
train epoch 104 avg loss: 2.60994 (A-MSE: 2.25671) avg lploss: 0.00000
train epoch 105 avg loss: 2.57173 (A-MSE: 2.20172) avg lploss: 0.00000
==> val epoch 105 avg loss: 3.23144 (A-MSE: 2.79566) avg lploss: 0.00000
==> test epoch 105 avg loss: 3.41752 (A-MSE: 3.02738) avg lploss: 0.00000
*** Best Val Loss: 3.23144 	 Best Test Loss: 3.41752 	 Best epoch 105
Validation loss decreased (3.294429 --> 3.231439).  Saving model ...
train epoch 106 avg loss: 2.70601 (A-MSE: 2.33352) avg lploss: 0.00000
train epoch 107 avg loss: 2.78885 (A-MSE: 2.41143) avg lploss: 0.00000
train epoch 108 avg loss: 2.74586 (A-MSE: 2.35892) avg lploss: 0.00000
train epoch 109 avg loss: 2.48471 (A-MSE: 2.13452) avg lploss: 0.00000
train epoch 110 avg loss: 2.57339 (A-MSE: 2.23109) avg lploss: 0.00000
==> val epoch 110 avg loss: 3.21720 (A-MSE: 2.74081) avg lploss: 0.00000
==> test epoch 110 avg loss: 3.41879 (A-MSE: 2.97561) avg lploss: 0.00000
*** Best Val Loss: 3.21720 	 Best Test Loss: 3.41879 	 Best epoch 110
Validation loss decreased (3.231439 --> 3.217200).  Saving model ...
train epoch 111 avg loss: 2.60977 (A-MSE: 2.23443) avg lploss: 0.00000
train epoch 112 avg loss: 2.59393 (A-MSE: 2.23180) avg lploss: 0.00000
train epoch 113 avg loss: 2.98428 (A-MSE: 2.58320) avg lploss: 0.00000
train epoch 114 avg loss: 2.63259 (A-MSE: 2.28254) avg lploss: 0.00000
train epoch 115 avg loss: 2.43632 (A-MSE: 2.08478) avg lploss: 0.00000
==> val epoch 115 avg loss: 2.72208 (A-MSE: 2.31586) avg lploss: 0.00000
==> test epoch 115 avg loss: 2.89571 (A-MSE: 2.51155) avg lploss: 0.00000
*** Best Val Loss: 2.72208 	 Best Test Loss: 2.89571 	 Best epoch 115
Validation loss decreased (3.217200 --> 2.722085).  Saving model ...
train epoch 116 avg loss: 2.37661 (A-MSE: 2.04335) avg lploss: 0.00000
train epoch 117 avg loss: 2.46934 (A-MSE: 2.11474) avg lploss: 0.00000
train epoch 118 avg loss: 2.53660 (A-MSE: 2.19780) avg lploss: 0.00000
train epoch 119 avg loss: 2.52274 (A-MSE: 2.18416) avg lploss: 0.00000
train epoch 120 avg loss: 2.45893 (A-MSE: 2.10275) avg lploss: 0.00000
==> val epoch 120 avg loss: 2.84548 (A-MSE: 2.47174) avg lploss: 0.00000
==> test epoch 120 avg loss: 2.87763 (A-MSE: 2.55299) avg lploss: 0.00000
*** Best Val Loss: 2.72208 	 Best Test Loss: 2.89571 	 Best epoch 115
EarlyStopping counter: 1 out of 50
train epoch 121 avg loss: 2.23005 (A-MSE: 1.92577) avg lploss: 0.00000
train epoch 122 avg loss: 2.25861 (A-MSE: 1.92183) avg lploss: 0.00000
train epoch 123 avg loss: 2.36124 (A-MSE: 2.05698) avg lploss: 0.00000
train epoch 124 avg loss: 2.22518 (A-MSE: 1.89974) avg lploss: 0.00000
train epoch 125 avg loss: 2.07339 (A-MSE: 1.78659) avg lploss: 0.00000
==> val epoch 125 avg loss: 2.90694 (A-MSE: 2.52298) avg lploss: 0.00000
==> test epoch 125 avg loss: 2.87628 (A-MSE: 2.53535) avg lploss: 0.00000
*** Best Val Loss: 2.72208 	 Best Test Loss: 2.89571 	 Best epoch 115
EarlyStopping counter: 2 out of 50
train epoch 126 avg loss: 2.20383 (A-MSE: 1.88893) avg lploss: 0.00000
train epoch 127 avg loss: 2.08584 (A-MSE: 1.79097) avg lploss: 0.00000
train epoch 128 avg loss: 2.05355 (A-MSE: 1.77400) avg lploss: 0.00000
train epoch 129 avg loss: 2.16374 (A-MSE: 1.84505) avg lploss: 0.00000
train epoch 130 avg loss: 1.96531 (A-MSE: 1.68146) avg lploss: 0.00000
==> val epoch 130 avg loss: 2.56449 (A-MSE: 2.25090) avg lploss: 0.00000
==> test epoch 130 avg loss: 2.50734 (A-MSE: 2.23662) avg lploss: 0.00000
*** Best Val Loss: 2.56449 	 Best Test Loss: 2.50734 	 Best epoch 130
Validation loss decreased (2.722085 --> 2.564491).  Saving model ...
train epoch 131 avg loss: 2.06478 (A-MSE: 1.77313) avg lploss: 0.00000
train epoch 132 avg loss: 2.05436 (A-MSE: 1.77065) avg lploss: 0.00000
train epoch 133 avg loss: 2.06520 (A-MSE: 1.75480) avg lploss: 0.00000
train epoch 134 avg loss: 1.93345 (A-MSE: 1.66109) avg lploss: 0.00000
train epoch 135 avg loss: 1.87941 (A-MSE: 1.60280) avg lploss: 0.00000
==> val epoch 135 avg loss: 2.29231 (A-MSE: 1.96270) avg lploss: 0.00000
==> test epoch 135 avg loss: 2.26038 (A-MSE: 1.96372) avg lploss: 0.00000
*** Best Val Loss: 2.29231 	 Best Test Loss: 2.26038 	 Best epoch 135
Validation loss decreased (2.564491 --> 2.292308).  Saving model ...
train epoch 136 avg loss: 2.04672 (A-MSE: 1.77039) avg lploss: 0.00000
train epoch 137 avg loss: 2.01211 (A-MSE: 1.72397) avg lploss: 0.00000
train epoch 138 avg loss: 1.85571 (A-MSE: 1.59227) avg lploss: 0.00000
train epoch 139 avg loss: 1.84364 (A-MSE: 1.58286) avg lploss: 0.00000
train epoch 140 avg loss: 1.97797 (A-MSE: 1.69541) avg lploss: 0.00000
==> val epoch 140 avg loss: 2.12983 (A-MSE: 1.79958) avg lploss: 0.00000
==> test epoch 140 avg loss: 2.23680 (A-MSE: 1.92783) avg lploss: 0.00000
*** Best Val Loss: 2.12983 	 Best Test Loss: 2.23680 	 Best epoch 140
Validation loss decreased (2.292308 --> 2.129825).  Saving model ...
train epoch 141 avg loss: 1.72723 (A-MSE: 1.48239) avg lploss: 0.00000
train epoch 142 avg loss: 1.75742 (A-MSE: 1.50609) avg lploss: 0.00000
train epoch 143 avg loss: 1.99552 (A-MSE: 1.72158) avg lploss: 0.00000
train epoch 144 avg loss: 1.81287 (A-MSE: 1.54416) avg lploss: 0.00000
train epoch 145 avg loss: 2.00554 (A-MSE: 1.73464) avg lploss: 0.00000
==> val epoch 145 avg loss: 2.14771 (A-MSE: 1.88506) avg lploss: 0.00000
==> test epoch 145 avg loss: 2.28005 (A-MSE: 2.02754) avg lploss: 0.00000
*** Best Val Loss: 2.12983 	 Best Test Loss: 2.23680 	 Best epoch 140
EarlyStopping counter: 1 out of 50
train epoch 146 avg loss: 2.04247 (A-MSE: 1.76608) avg lploss: 0.00000
train epoch 147 avg loss: 1.99993 (A-MSE: 1.71917) avg lploss: 0.00000
train epoch 148 avg loss: 1.92872 (A-MSE: 1.65952) avg lploss: 0.00000
train epoch 149 avg loss: 1.71314 (A-MSE: 1.46942) avg lploss: 0.00000
train epoch 150 avg loss: 1.71409 (A-MSE: 1.46291) avg lploss: 0.00000
==> val epoch 150 avg loss: 2.03168 (A-MSE: 1.80309) avg lploss: 0.00000
==> test epoch 150 avg loss: 1.99471 (A-MSE: 1.78644) avg lploss: 0.00000
*** Best Val Loss: 2.03168 	 Best Test Loss: 1.99471 	 Best epoch 150
Validation loss decreased (2.129825 --> 2.031679).  Saving model ...
train epoch 151 avg loss: 1.59830 (A-MSE: 1.37531) avg lploss: 0.00000
train epoch 152 avg loss: 1.68616 (A-MSE: 1.44303) avg lploss: 0.00000
train epoch 153 avg loss: 1.63360 (A-MSE: 1.40797) avg lploss: 0.00000
train epoch 154 avg loss: 1.50558 (A-MSE: 1.30390) avg lploss: 0.00000
train epoch 155 avg loss: 1.53320 (A-MSE: 1.30759) avg lploss: 0.00000
==> val epoch 155 avg loss: 1.73652 (A-MSE: 1.51978) avg lploss: 0.00000
==> test epoch 155 avg loss: 1.83381 (A-MSE: 1.62978) avg lploss: 0.00000
*** Best Val Loss: 1.73652 	 Best Test Loss: 1.83381 	 Best epoch 155
Validation loss decreased (2.031679 --> 1.736518).  Saving model ...
train epoch 156 avg loss: 1.58244 (A-MSE: 1.35655) avg lploss: 0.00000
train epoch 157 avg loss: 1.56881 (A-MSE: 1.34933) avg lploss: 0.00000
train epoch 158 avg loss: 1.61569 (A-MSE: 1.38427) avg lploss: 0.00000
train epoch 159 avg loss: 1.62192 (A-MSE: 1.40878) avg lploss: 0.00000
train epoch 160 avg loss: 1.55678 (A-MSE: 1.34819) avg lploss: 0.00000
==> val epoch 160 avg loss: 1.81226 (A-MSE: 1.57754) avg lploss: 0.00000
==> test epoch 160 avg loss: 1.80169 (A-MSE: 1.60452) avg lploss: 0.00000
*** Best Val Loss: 1.73652 	 Best Test Loss: 1.83381 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 1.54441 (A-MSE: 1.33327) avg lploss: 0.00000
train epoch 162 avg loss: 1.68107 (A-MSE: 1.45104) avg lploss: 0.00000
train epoch 163 avg loss: 1.53848 (A-MSE: 1.33071) avg lploss: 0.00000
train epoch 164 avg loss: 1.41775 (A-MSE: 1.21347) avg lploss: 0.00000
train epoch 165 avg loss: 1.33031 (A-MSE: 1.13477) avg lploss: 0.00000
==> val epoch 165 avg loss: 1.65977 (A-MSE: 1.45479) avg lploss: 0.00000
==> test epoch 165 avg loss: 1.65183 (A-MSE: 1.48519) avg lploss: 0.00000
*** Best Val Loss: 1.65977 	 Best Test Loss: 1.65183 	 Best epoch 165
Validation loss decreased (1.736518 --> 1.659773).  Saving model ...
train epoch 166 avg loss: 1.36095 (A-MSE: 1.16889) avg lploss: 0.00000
train epoch 167 avg loss: 1.32691 (A-MSE: 1.15331) avg lploss: 0.00000
train epoch 168 avg loss: 1.39842 (A-MSE: 1.20916) avg lploss: 0.00000
train epoch 169 avg loss: 1.50512 (A-MSE: 1.29807) avg lploss: 0.00000
train epoch 170 avg loss: 1.51552 (A-MSE: 1.31077) avg lploss: 0.00000
==> val epoch 170 avg loss: 1.92247 (A-MSE: 1.68156) avg lploss: 0.00000
==> test epoch 170 avg loss: 1.83772 (A-MSE: 1.64919) avg lploss: 0.00000
*** Best Val Loss: 1.65977 	 Best Test Loss: 1.65183 	 Best epoch 165
EarlyStopping counter: 1 out of 50
train epoch 171 avg loss: 1.45375 (A-MSE: 1.26751) avg lploss: 0.00000
train epoch 172 avg loss: 1.50926 (A-MSE: 1.30493) avg lploss: 0.00000
train epoch 173 avg loss: 1.42148 (A-MSE: 1.23910) avg lploss: 0.00000
train epoch 174 avg loss: 1.39687 (A-MSE: 1.22327) avg lploss: 0.00000
train epoch 175 avg loss: 1.43982 (A-MSE: 1.23776) avg lploss: 0.00000
==> val epoch 175 avg loss: 1.90214 (A-MSE: 1.62625) avg lploss: 0.00000
==> test epoch 175 avg loss: 1.76044 (A-MSE: 1.53569) avg lploss: 0.00000
*** Best Val Loss: 1.65977 	 Best Test Loss: 1.65183 	 Best epoch 165
EarlyStopping counter: 2 out of 50
train epoch 176 avg loss: 1.64109 (A-MSE: 1.42735) avg lploss: 0.00000
train epoch 177 avg loss: 1.39903 (A-MSE: 1.21448) avg lploss: 0.00000
train epoch 178 avg loss: 1.30795 (A-MSE: 1.13382) avg lploss: 0.00000
train epoch 179 avg loss: 1.46813 (A-MSE: 1.27745) avg lploss: 0.00000
train epoch 180 avg loss: 1.40883 (A-MSE: 1.22088) avg lploss: 0.00000
==> val epoch 180 avg loss: 1.84009 (A-MSE: 1.62040) avg lploss: 0.00000
==> test epoch 180 avg loss: 1.81822 (A-MSE: 1.61928) avg lploss: 0.00000
*** Best Val Loss: 1.65977 	 Best Test Loss: 1.65183 	 Best epoch 165
EarlyStopping counter: 3 out of 50
train epoch 181 avg loss: 1.35017 (A-MSE: 1.17286) avg lploss: 0.00000
train epoch 182 avg loss: 1.29328 (A-MSE: 1.11850) avg lploss: 0.00000
train epoch 183 avg loss: 1.27232 (A-MSE: 1.11167) avg lploss: 0.00000
train epoch 184 avg loss: 1.41796 (A-MSE: 1.23077) avg lploss: 0.00000
train epoch 185 avg loss: 1.34521 (A-MSE: 1.17086) avg lploss: 0.00000
==> val epoch 185 avg loss: 1.68140 (A-MSE: 1.44527) avg lploss: 0.00000
==> test epoch 185 avg loss: 1.64707 (A-MSE: 1.44284) avg lploss: 0.00000
*** Best Val Loss: 1.65977 	 Best Test Loss: 1.65183 	 Best epoch 165
EarlyStopping counter: 4 out of 50
train epoch 186 avg loss: 1.23355 (A-MSE: 1.06466) avg lploss: 0.00000
train epoch 187 avg loss: 1.24196 (A-MSE: 1.07121) avg lploss: 0.00000
train epoch 188 avg loss: 1.33198 (A-MSE: 1.16000) avg lploss: 0.00000
train epoch 189 avg loss: 1.33172 (A-MSE: 1.16385) avg lploss: 0.00000
train epoch 190 avg loss: 1.32661 (A-MSE: 1.15743) avg lploss: 0.00000
==> val epoch 190 avg loss: 1.53856 (A-MSE: 1.34141) avg lploss: 0.00000
==> test epoch 190 avg loss: 1.56250 (A-MSE: 1.38306) avg lploss: 0.00000
*** Best Val Loss: 1.53856 	 Best Test Loss: 1.56250 	 Best epoch 190
Validation loss decreased (1.659773 --> 1.538565).  Saving model ...
train epoch 191 avg loss: 1.22309 (A-MSE: 1.05301) avg lploss: 0.00000
train epoch 192 avg loss: 1.12407 (A-MSE: 0.97921) avg lploss: 0.00000
train epoch 193 avg loss: 1.19580 (A-MSE: 1.03466) avg lploss: 0.00000
train epoch 194 avg loss: 1.45266 (A-MSE: 1.26839) avg lploss: 0.00000
train epoch 195 avg loss: 1.28900 (A-MSE: 1.12863) avg lploss: 0.00000
==> val epoch 195 avg loss: 1.64205 (A-MSE: 1.43752) avg lploss: 0.00000
==> test epoch 195 avg loss: 1.63602 (A-MSE: 1.47016) avg lploss: 0.00000
*** Best Val Loss: 1.53856 	 Best Test Loss: 1.56250 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 1.15471 (A-MSE: 1.00307) avg lploss: 0.00000
train epoch 197 avg loss: 1.15924 (A-MSE: 0.99718) avg lploss: 0.00000
train epoch 198 avg loss: 1.22798 (A-MSE: 1.07705) avg lploss: 0.00000
train epoch 199 avg loss: 1.32052 (A-MSE: 1.15285) avg lploss: 0.00000
train epoch 200 avg loss: 1.21940 (A-MSE: 1.06585) avg lploss: 0.00000
==> val epoch 200 avg loss: 1.58233 (A-MSE: 1.38704) avg lploss: 0.00000
==> test epoch 200 avg loss: 1.44964 (A-MSE: 1.30537) avg lploss: 0.00000
*** Best Val Loss: 1.53856 	 Best Test Loss: 1.56250 	 Best epoch 190
EarlyStopping counter: 2 out of 50
train epoch 201 avg loss: 1.11502 (A-MSE: 0.96299) avg lploss: 0.00000
train epoch 202 avg loss: 1.03784 (A-MSE: 0.91028) avg lploss: 0.00000
train epoch 203 avg loss: 1.20397 (A-MSE: 1.03967) avg lploss: 0.00000
train epoch 204 avg loss: 1.08936 (A-MSE: 0.95536) avg lploss: 0.00000
train epoch 205 avg loss: 1.13891 (A-MSE: 0.99123) avg lploss: 0.00000
==> val epoch 205 avg loss: 1.49937 (A-MSE: 1.39232) avg lploss: 0.00000
==> test epoch 205 avg loss: 1.72151 (A-MSE: 1.60814) avg lploss: 0.00000
*** Best Val Loss: 1.49937 	 Best Test Loss: 1.72151 	 Best epoch 205
Validation loss decreased (1.538565 --> 1.499370).  Saving model ...
train epoch 206 avg loss: 1.15027 (A-MSE: 1.00530) avg lploss: 0.00000
train epoch 207 avg loss: 1.04375 (A-MSE: 0.91123) avg lploss: 0.00000
train epoch 208 avg loss: 1.11926 (A-MSE: 0.97792) avg lploss: 0.00000
train epoch 209 avg loss: 1.21923 (A-MSE: 1.06707) avg lploss: 0.00000
train epoch 210 avg loss: 1.09785 (A-MSE: 0.96318) avg lploss: 0.00000
==> val epoch 210 avg loss: 1.70034 (A-MSE: 1.47518) avg lploss: 0.00000
==> test epoch 210 avg loss: 1.61735 (A-MSE: 1.45510) avg lploss: 0.00000
*** Best Val Loss: 1.49937 	 Best Test Loss: 1.72151 	 Best epoch 205
EarlyStopping counter: 1 out of 50
train epoch 211 avg loss: 1.06823 (A-MSE: 0.93560) avg lploss: 0.00000
train epoch 212 avg loss: 1.11439 (A-MSE: 0.97532) avg lploss: 0.00000
train epoch 213 avg loss: 1.06731 (A-MSE: 0.93668) avg lploss: 0.00000
train epoch 214 avg loss: 1.10820 (A-MSE: 0.96644) avg lploss: 0.00000
train epoch 215 avg loss: 1.17347 (A-MSE: 1.03036) avg lploss: 0.00000
==> val epoch 215 avg loss: 2.05356 (A-MSE: 1.76292) avg lploss: 0.00000
==> test epoch 215 avg loss: 1.83545 (A-MSE: 1.63167) avg lploss: 0.00000
*** Best Val Loss: 1.49937 	 Best Test Loss: 1.72151 	 Best epoch 205
EarlyStopping counter: 2 out of 50
train epoch 216 avg loss: 1.18898 (A-MSE: 1.04223) avg lploss: 0.00000
train epoch 217 avg loss: 1.04690 (A-MSE: 0.90870) avg lploss: 0.00000
train epoch 218 avg loss: 1.17762 (A-MSE: 1.03385) avg lploss: 0.00000
train epoch 219 avg loss: 1.02893 (A-MSE: 0.90484) avg lploss: 0.00000
train epoch 220 avg loss: 0.99708 (A-MSE: 0.86687) avg lploss: 0.00000
==> val epoch 220 avg loss: 1.40084 (A-MSE: 1.25488) avg lploss: 0.00000
==> test epoch 220 avg loss: 1.44101 (A-MSE: 1.33004) avg lploss: 0.00000
*** Best Val Loss: 1.40084 	 Best Test Loss: 1.44101 	 Best epoch 220
Validation loss decreased (1.499370 --> 1.400836).  Saving model ...
train epoch 221 avg loss: 1.05928 (A-MSE: 0.91896) avg lploss: 0.00000
train epoch 222 avg loss: 0.98830 (A-MSE: 0.86633) avg lploss: 0.00000
train epoch 223 avg loss: 0.95125 (A-MSE: 0.83543) avg lploss: 0.00000
train epoch 224 avg loss: 0.97955 (A-MSE: 0.85966) avg lploss: 0.00000
train epoch 225 avg loss: 1.04257 (A-MSE: 0.91239) avg lploss: 0.00000
==> val epoch 225 avg loss: 1.38192 (A-MSE: 1.20477) avg lploss: 0.00000
==> test epoch 225 avg loss: 1.40390 (A-MSE: 1.24471) avg lploss: 0.00000
*** Best Val Loss: 1.38192 	 Best Test Loss: 1.40390 	 Best epoch 225
Validation loss decreased (1.400836 --> 1.381925).  Saving model ...
train epoch 226 avg loss: 0.94511 (A-MSE: 0.83137) avg lploss: 0.00000
train epoch 227 avg loss: 0.99431 (A-MSE: 0.87701) avg lploss: 0.00000
train epoch 228 avg loss: 0.99742 (A-MSE: 0.86739) avg lploss: 0.00000
train epoch 229 avg loss: 0.99613 (A-MSE: 0.87815) avg lploss: 0.00000
train epoch 230 avg loss: 0.97946 (A-MSE: 0.85722) avg lploss: 0.00000
==> val epoch 230 avg loss: 1.35068 (A-MSE: 1.18039) avg lploss: 0.00000
==> test epoch 230 avg loss: 1.35083 (A-MSE: 1.21632) avg lploss: 0.00000
*** Best Val Loss: 1.35068 	 Best Test Loss: 1.35083 	 Best epoch 230
Validation loss decreased (1.381925 --> 1.350683).  Saving model ...
train epoch 231 avg loss: 1.01266 (A-MSE: 0.88322) avg lploss: 0.00000
train epoch 232 avg loss: 1.09915 (A-MSE: 0.96865) avg lploss: 0.00000
train epoch 233 avg loss: 1.01185 (A-MSE: 0.88179) avg lploss: 0.00000
train epoch 234 avg loss: 1.03569 (A-MSE: 0.90747) avg lploss: 0.00000
train epoch 235 avg loss: 0.91273 (A-MSE: 0.80123) avg lploss: 0.00000
==> val epoch 235 avg loss: 1.22784 (A-MSE: 1.08407) avg lploss: 0.00000
==> test epoch 235 avg loss: 1.21742 (A-MSE: 1.12178) avg lploss: 0.00000
*** Best Val Loss: 1.22784 	 Best Test Loss: 1.21742 	 Best epoch 235
Validation loss decreased (1.350683 --> 1.227836).  Saving model ...
train epoch 236 avg loss: 0.87330 (A-MSE: 0.76655) avg lploss: 0.00000
train epoch 237 avg loss: 0.92824 (A-MSE: 0.81318) avg lploss: 0.00000
train epoch 238 avg loss: 0.88126 (A-MSE: 0.77541) avg lploss: 0.00000
train epoch 239 avg loss: 0.84910 (A-MSE: 0.73891) avg lploss: 0.00000
train epoch 240 avg loss: 0.97232 (A-MSE: 0.85296) avg lploss: 0.00000
==> val epoch 240 avg loss: 1.63243 (A-MSE: 1.43712) avg lploss: 0.00000
==> test epoch 240 avg loss: 1.45135 (A-MSE: 1.32789) avg lploss: 0.00000
*** Best Val Loss: 1.22784 	 Best Test Loss: 1.21742 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 0.96048 (A-MSE: 0.85082) avg lploss: 0.00000
train epoch 242 avg loss: 0.93940 (A-MSE: 0.81290) avg lploss: 0.00000
train epoch 243 avg loss: 0.91461 (A-MSE: 0.81232) avg lploss: 0.00000
train epoch 244 avg loss: 1.05701 (A-MSE: 0.94138) avg lploss: 0.00000
train epoch 245 avg loss: 1.01198 (A-MSE: 0.88671) avg lploss: 0.00000
==> val epoch 245 avg loss: 1.45762 (A-MSE: 1.27726) avg lploss: 0.00000
==> test epoch 245 avg loss: 1.48473 (A-MSE: 1.33803) avg lploss: 0.00000
*** Best Val Loss: 1.22784 	 Best Test Loss: 1.21742 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 0.90081 (A-MSE: 0.78916) avg lploss: 0.00000
train epoch 247 avg loss: 0.93685 (A-MSE: 0.82082) avg lploss: 0.00000
train epoch 248 avg loss: 0.95049 (A-MSE: 0.83888) avg lploss: 0.00000
train epoch 249 avg loss: 0.83510 (A-MSE: 0.73235) avg lploss: 0.00000
train epoch 250 avg loss: 0.84156 (A-MSE: 0.73879) avg lploss: 0.00000
==> val epoch 250 avg loss: 1.28669 (A-MSE: 1.13270) avg lploss: 0.00000
==> test epoch 250 avg loss: 1.20043 (A-MSE: 1.10387) avg lploss: 0.00000
*** Best Val Loss: 1.22784 	 Best Test Loss: 1.21742 	 Best epoch 235
EarlyStopping counter: 3 out of 50
train epoch 251 avg loss: 1.05495 (A-MSE: 0.94301) avg lploss: 0.00000
train epoch 252 avg loss: 0.92653 (A-MSE: 0.81072) avg lploss: 0.00000
train epoch 253 avg loss: 0.85538 (A-MSE: 0.74892) avg lploss: 0.00000
train epoch 254 avg loss: 0.83061 (A-MSE: 0.73097) avg lploss: 0.00000
train epoch 255 avg loss: 0.89497 (A-MSE: 0.78377) avg lploss: 0.00000
==> val epoch 255 avg loss: 1.38110 (A-MSE: 1.26027) avg lploss: 0.00000
==> test epoch 255 avg loss: 1.30424 (A-MSE: 1.23511) avg lploss: 0.00000
*** Best Val Loss: 1.22784 	 Best Test Loss: 1.21742 	 Best epoch 235
EarlyStopping counter: 4 out of 50
train epoch 256 avg loss: 0.84096 (A-MSE: 0.73652) avg lploss: 0.00000
train epoch 257 avg loss: 0.91800 (A-MSE: 0.81348) avg lploss: 0.00000
train epoch 258 avg loss: 0.86371 (A-MSE: 0.75894) avg lploss: 0.00000
train epoch 259 avg loss: 0.82982 (A-MSE: 0.72617) avg lploss: 0.00000
train epoch 260 avg loss: 0.79903 (A-MSE: 0.70267) avg lploss: 0.00000
==> val epoch 260 avg loss: 1.33269 (A-MSE: 1.17074) avg lploss: 0.00000
==> test epoch 260 avg loss: 1.24359 (A-MSE: 1.14333) avg lploss: 0.00000
*** Best Val Loss: 1.22784 	 Best Test Loss: 1.21742 	 Best epoch 235
EarlyStopping counter: 5 out of 50
train epoch 261 avg loss: 0.80399 (A-MSE: 0.70822) avg lploss: 0.00000
train epoch 262 avg loss: 0.80009 (A-MSE: 0.70691) avg lploss: 0.00000
train epoch 263 avg loss: 0.78279 (A-MSE: 0.68397) avg lploss: 0.00000
train epoch 264 avg loss: 0.77308 (A-MSE: 0.68029) avg lploss: 0.00000
train epoch 265 avg loss: 0.75071 (A-MSE: 0.65714) avg lploss: 0.00000
==> val epoch 265 avg loss: 1.17039 (A-MSE: 1.04568) avg lploss: 0.00000
==> test epoch 265 avg loss: 1.11444 (A-MSE: 1.03343) avg lploss: 0.00000
*** Best Val Loss: 1.17039 	 Best Test Loss: 1.11444 	 Best epoch 265
Validation loss decreased (1.227836 --> 1.170392).  Saving model ...
train epoch 266 avg loss: 0.77696 (A-MSE: 0.68029) avg lploss: 0.00000
train epoch 267 avg loss: 0.93267 (A-MSE: 0.81689) avg lploss: 0.00000
train epoch 268 avg loss: 0.81486 (A-MSE: 0.72564) avg lploss: 0.00000
train epoch 269 avg loss: 0.75026 (A-MSE: 0.66075) avg lploss: 0.00000
train epoch 270 avg loss: 0.77012 (A-MSE: 0.67477) avg lploss: 0.00000
==> val epoch 270 avg loss: 1.31425 (A-MSE: 1.16800) avg lploss: 0.00000
==> test epoch 270 avg loss: 1.24425 (A-MSE: 1.15223) avg lploss: 0.00000
*** Best Val Loss: 1.17039 	 Best Test Loss: 1.11444 	 Best epoch 265
EarlyStopping counter: 1 out of 50
train epoch 271 avg loss: 0.86759 (A-MSE: 0.76030) avg lploss: 0.00000
train epoch 272 avg loss: 0.86021 (A-MSE: 0.76476) avg lploss: 0.00000
train epoch 273 avg loss: 0.87269 (A-MSE: 0.77201) avg lploss: 0.00000
train epoch 274 avg loss: 0.79296 (A-MSE: 0.69164) avg lploss: 0.00000
train epoch 275 avg loss: 0.88584 (A-MSE: 0.78386) avg lploss: 0.00000
==> val epoch 275 avg loss: 1.54415 (A-MSE: 1.33939) avg lploss: 0.00000
==> test epoch 275 avg loss: 1.41401 (A-MSE: 1.27524) avg lploss: 0.00000
*** Best Val Loss: 1.17039 	 Best Test Loss: 1.11444 	 Best epoch 265
EarlyStopping counter: 2 out of 50
train epoch 276 avg loss: 0.91725 (A-MSE: 0.80002) avg lploss: 0.00000
train epoch 277 avg loss: 0.86021 (A-MSE: 0.75382) avg lploss: 0.00000
train epoch 278 avg loss: 0.73923 (A-MSE: 0.64741) avg lploss: 0.00000
train epoch 279 avg loss: 0.74278 (A-MSE: 0.64884) avg lploss: 0.00000
train epoch 280 avg loss: 0.77354 (A-MSE: 0.67686) avg lploss: 0.00000
==> val epoch 280 avg loss: 1.22947 (A-MSE: 1.09142) avg lploss: 0.00000
==> test epoch 280 avg loss: 1.14804 (A-MSE: 1.05657) avg lploss: 0.00000
*** Best Val Loss: 1.17039 	 Best Test Loss: 1.11444 	 Best epoch 265
EarlyStopping counter: 3 out of 50
train epoch 281 avg loss: 0.76150 (A-MSE: 0.66833) avg lploss: 0.00000
train epoch 282 avg loss: 0.73043 (A-MSE: 0.64462) avg lploss: 0.00000
train epoch 283 avg loss: 0.76552 (A-MSE: 0.66805) avg lploss: 0.00000
train epoch 284 avg loss: 0.77463 (A-MSE: 0.68293) avg lploss: 0.00000
train epoch 285 avg loss: 0.71556 (A-MSE: 0.62514) avg lploss: 0.00000
==> val epoch 285 avg loss: 1.05561 (A-MSE: 0.93513) avg lploss: 0.00000
==> test epoch 285 avg loss: 1.05206 (A-MSE: 0.96673) avg lploss: 0.00000
*** Best Val Loss: 1.05561 	 Best Test Loss: 1.05206 	 Best epoch 285
Validation loss decreased (1.170392 --> 1.055605).  Saving model ...
train epoch 286 avg loss: 0.73525 (A-MSE: 0.64402) avg lploss: 0.00000
train epoch 287 avg loss: 0.85221 (A-MSE: 0.75047) avg lploss: 0.00000
train epoch 288 avg loss: 0.76270 (A-MSE: 0.67287) avg lploss: 0.00000
train epoch 289 avg loss: 0.68018 (A-MSE: 0.59602) avg lploss: 0.00000
train epoch 290 avg loss: 0.69352 (A-MSE: 0.60735) avg lploss: 0.00000
==> val epoch 290 avg loss: 1.01158 (A-MSE: 0.88846) avg lploss: 0.00000
==> test epoch 290 avg loss: 1.00699 (A-MSE: 0.92189) avg lploss: 0.00000
*** Best Val Loss: 1.01158 	 Best Test Loss: 1.00699 	 Best epoch 290
Validation loss decreased (1.055605 --> 1.011583).  Saving model ...
train epoch 291 avg loss: 0.71033 (A-MSE: 0.62537) avg lploss: 0.00000
train epoch 292 avg loss: 0.98107 (A-MSE: 0.86192) avg lploss: 0.00000
train epoch 293 avg loss: 0.93270 (A-MSE: 0.83137) avg lploss: 0.00000
train epoch 294 avg loss: 0.78257 (A-MSE: 0.69006) avg lploss: 0.00000
train epoch 295 avg loss: 0.71650 (A-MSE: 0.62802) avg lploss: 0.00000
==> val epoch 295 avg loss: 1.21683 (A-MSE: 1.04932) avg lploss: 0.00000
==> test epoch 295 avg loss: 1.13232 (A-MSE: 1.02988) avg lploss: 0.00000
*** Best Val Loss: 1.01158 	 Best Test Loss: 1.00699 	 Best epoch 290
EarlyStopping counter: 1 out of 50
train epoch 296 avg loss: 0.71549 (A-MSE: 0.62562) avg lploss: 0.00000
train epoch 297 avg loss: 0.69325 (A-MSE: 0.61302) avg lploss: 0.00000
train epoch 298 avg loss: 0.71068 (A-MSE: 0.61961) avg lploss: 0.00000
train epoch 299 avg loss: 0.79308 (A-MSE: 0.70149) avg lploss: 0.00000
train epoch 300 avg loss: 0.77175 (A-MSE: 0.68121) avg lploss: 0.00000
==> val epoch 300 avg loss: 1.17251 (A-MSE: 1.01218) avg lploss: 0.00000
==> test epoch 300 avg loss: 1.16217 (A-MSE: 1.04527) avg lploss: 0.00000
*** Best Val Loss: 1.01158 	 Best Test Loss: 1.00699 	 Best epoch 290
EarlyStopping counter: 2 out of 50
train epoch 301 avg loss: 0.76758 (A-MSE: 0.67211) avg lploss: 0.00000
train epoch 302 avg loss: 0.71274 (A-MSE: 0.62531) avg lploss: 0.00000
train epoch 303 avg loss: 0.72556 (A-MSE: 0.64200) avg lploss: 0.00000
train epoch 304 avg loss: 0.81124 (A-MSE: 0.71272) avg lploss: 0.00000
train epoch 305 avg loss: 0.70663 (A-MSE: 0.62097) avg lploss: 0.00000
==> val epoch 305 avg loss: 0.98767 (A-MSE: 0.88113) avg lploss: 0.00000
==> test epoch 305 avg loss: 0.99056 (A-MSE: 0.92677) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
Validation loss decreased (1.011583 --> 0.987666).  Saving model ...
train epoch 306 avg loss: 0.65923 (A-MSE: 0.57872) avg lploss: 0.00000
train epoch 307 avg loss: 0.59903 (A-MSE: 0.52256) avg lploss: 0.00000
train epoch 308 avg loss: 0.66387 (A-MSE: 0.58266) avg lploss: 0.00000
train epoch 309 avg loss: 0.61393 (A-MSE: 0.53977) avg lploss: 0.00000
train epoch 310 avg loss: 0.66260 (A-MSE: 0.58092) avg lploss: 0.00000
==> val epoch 310 avg loss: 1.14938 (A-MSE: 1.05196) avg lploss: 0.00000
==> test epoch 310 avg loss: 1.12290 (A-MSE: 1.07878) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
EarlyStopping counter: 1 out of 50
train epoch 311 avg loss: 0.67731 (A-MSE: 0.60195) avg lploss: 0.00000
train epoch 312 avg loss: 0.82326 (A-MSE: 0.71932) avg lploss: 0.00000
train epoch 313 avg loss: 0.63446 (A-MSE: 0.56100) avg lploss: 0.00000
train epoch 314 avg loss: 0.62323 (A-MSE: 0.54859) avg lploss: 0.00000
train epoch 315 avg loss: 0.67017 (A-MSE: 0.58686) avg lploss: 0.00000
==> val epoch 315 avg loss: 1.08474 (A-MSE: 0.95811) avg lploss: 0.00000
==> test epoch 315 avg loss: 1.06656 (A-MSE: 0.98840) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
EarlyStopping counter: 2 out of 50
train epoch 316 avg loss: 0.63152 (A-MSE: 0.55501) avg lploss: 0.00000
train epoch 317 avg loss: 0.74904 (A-MSE: 0.65884) avg lploss: 0.00000
train epoch 318 avg loss: 0.78579 (A-MSE: 0.68977) avg lploss: 0.00000
train epoch 319 avg loss: 0.77822 (A-MSE: 0.69256) avg lploss: 0.00000
train epoch 320 avg loss: 0.70444 (A-MSE: 0.62399) avg lploss: 0.00000
==> val epoch 320 avg loss: 1.21188 (A-MSE: 1.07862) avg lploss: 0.00000
==> test epoch 320 avg loss: 1.17974 (A-MSE: 1.09744) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
EarlyStopping counter: 3 out of 50
train epoch 321 avg loss: 0.62781 (A-MSE: 0.55330) avg lploss: 0.00000
train epoch 322 avg loss: 0.60964 (A-MSE: 0.53609) avg lploss: 0.00000
train epoch 323 avg loss: 0.59890 (A-MSE: 0.52619) avg lploss: 0.00000
train epoch 324 avg loss: 0.68044 (A-MSE: 0.60207) avg lploss: 0.00000
train epoch 325 avg loss: 0.76495 (A-MSE: 0.67716) avg lploss: 0.00000
==> val epoch 325 avg loss: 1.19164 (A-MSE: 1.02121) avg lploss: 0.00000
==> test epoch 325 avg loss: 1.07762 (A-MSE: 0.96772) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
EarlyStopping counter: 4 out of 50
train epoch 326 avg loss: 0.68369 (A-MSE: 0.59834) avg lploss: 0.00000
train epoch 327 avg loss: 0.62410 (A-MSE: 0.54688) avg lploss: 0.00000
train epoch 328 avg loss: 0.67874 (A-MSE: 0.59799) avg lploss: 0.00000
train epoch 329 avg loss: 0.79584 (A-MSE: 0.70075) avg lploss: 0.00000
train epoch 330 avg loss: 0.71619 (A-MSE: 0.63634) avg lploss: 0.00000
==> val epoch 330 avg loss: 1.18739 (A-MSE: 1.05051) avg lploss: 0.00000
==> test epoch 330 avg loss: 1.09255 (A-MSE: 1.01076) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
EarlyStopping counter: 5 out of 50
train epoch 331 avg loss: 0.66859 (A-MSE: 0.58290) avg lploss: 0.00000
train epoch 332 avg loss: 0.60354 (A-MSE: 0.53417) avg lploss: 0.00000
train epoch 333 avg loss: 0.62012 (A-MSE: 0.54530) avg lploss: 0.00000
train epoch 334 avg loss: 0.60961 (A-MSE: 0.53921) avg lploss: 0.00000
train epoch 335 avg loss: 0.67870 (A-MSE: 0.59366) avg lploss: 0.00000
==> val epoch 335 avg loss: 1.01076 (A-MSE: 0.90582) avg lploss: 0.00000
==> test epoch 335 avg loss: 1.03632 (A-MSE: 0.96448) avg lploss: 0.00000
*** Best Val Loss: 0.98767 	 Best Test Loss: 0.99056 	 Best epoch 305
EarlyStopping counter: 6 out of 50
train epoch 336 avg loss: 0.77940 (A-MSE: 0.68582) avg lploss: 0.00000
train epoch 337 avg loss: 0.67797 (A-MSE: 0.59947) avg lploss: 0.00000
train epoch 338 avg loss: 0.59961 (A-MSE: 0.52623) avg lploss: 0.00000
train epoch 339 avg loss: 0.64993 (A-MSE: 0.57443) avg lploss: 0.00000
train epoch 340 avg loss: 0.58673 (A-MSE: 0.51704) avg lploss: 0.00000
==> val epoch 340 avg loss: 0.89796 (A-MSE: 0.78339) avg lploss: 0.00000
==> test epoch 340 avg loss: 0.91986 (A-MSE: 0.83448) avg lploss: 0.00000
*** Best Val Loss: 0.89796 	 Best Test Loss: 0.91986 	 Best epoch 340
Validation loss decreased (0.987666 --> 0.897963).  Saving model ...
train epoch 341 avg loss: 0.57663 (A-MSE: 0.50636) avg lploss: 0.00000
train epoch 342 avg loss: 0.61185 (A-MSE: 0.53935) avg lploss: 0.00000
train epoch 343 avg loss: 0.59710 (A-MSE: 0.52493) avg lploss: 0.00000
train epoch 344 avg loss: 0.62281 (A-MSE: 0.55099) avg lploss: 0.00000
train epoch 345 avg loss: 0.62997 (A-MSE: 0.55671) avg lploss: 0.00000
==> val epoch 345 avg loss: 1.03305 (A-MSE: 0.91229) avg lploss: 0.00000
==> test epoch 345 avg loss: 1.02699 (A-MSE: 0.94188) avg lploss: 0.00000
*** Best Val Loss: 0.89796 	 Best Test Loss: 0.91986 	 Best epoch 340
EarlyStopping counter: 1 out of 50
train epoch 346 avg loss: 0.59783 (A-MSE: 0.52875) avg lploss: 0.00000
train epoch 347 avg loss: 0.57461 (A-MSE: 0.49904) avg lploss: 0.00000
train epoch 348 avg loss: 0.55466 (A-MSE: 0.48954) avg lploss: 0.00000
train epoch 349 avg loss: 0.56616 (A-MSE: 0.49646) avg lploss: 0.00000
train epoch 350 avg loss: 0.55897 (A-MSE: 0.48733) avg lploss: 0.00000
==> val epoch 350 avg loss: 0.85744 (A-MSE: 0.78183) avg lploss: 0.00000
==> test epoch 350 avg loss: 0.87590 (A-MSE: 0.83360) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
Validation loss decreased (0.897963 --> 0.857439).  Saving model ...
train epoch 351 avg loss: 0.58303 (A-MSE: 0.51604) avg lploss: 0.00000
train epoch 352 avg loss: 0.72006 (A-MSE: 0.63959) avg lploss: 0.00000
train epoch 353 avg loss: 0.70257 (A-MSE: 0.61507) avg lploss: 0.00000
train epoch 354 avg loss: 0.59769 (A-MSE: 0.52846) avg lploss: 0.00000
train epoch 355 avg loss: 0.65647 (A-MSE: 0.57314) avg lploss: 0.00000
==> val epoch 355 avg loss: 0.86002 (A-MSE: 0.76357) avg lploss: 0.00000
==> test epoch 355 avg loss: 0.84686 (A-MSE: 0.79248) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 0.56812 (A-MSE: 0.49875) avg lploss: 0.00000
train epoch 357 avg loss: 0.54633 (A-MSE: 0.48426) avg lploss: 0.00000
train epoch 358 avg loss: 0.54229 (A-MSE: 0.47597) avg lploss: 0.00000
train epoch 359 avg loss: 0.55820 (A-MSE: 0.48917) avg lploss: 0.00000
train epoch 360 avg loss: 0.77129 (A-MSE: 0.67896) avg lploss: 0.00000
==> val epoch 360 avg loss: 1.62486 (A-MSE: 1.45303) avg lploss: 0.00000
==> test epoch 360 avg loss: 1.58929 (A-MSE: 1.49157) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 2 out of 50
train epoch 361 avg loss: 0.65223 (A-MSE: 0.57781) avg lploss: 0.00000
train epoch 362 avg loss: 0.57416 (A-MSE: 0.50543) avg lploss: 0.00000
train epoch 363 avg loss: 0.51553 (A-MSE: 0.45575) avg lploss: 0.00000
train epoch 364 avg loss: 0.53636 (A-MSE: 0.47651) avg lploss: 0.00000
train epoch 365 avg loss: 0.53059 (A-MSE: 0.46357) avg lploss: 0.00000
==> val epoch 365 avg loss: 1.06663 (A-MSE: 0.94242) avg lploss: 0.00000
==> test epoch 365 avg loss: 1.06203 (A-MSE: 0.98726) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 3 out of 50
train epoch 366 avg loss: 0.58155 (A-MSE: 0.51556) avg lploss: 0.00000
train epoch 367 avg loss: 0.56875 (A-MSE: 0.50068) avg lploss: 0.00000
train epoch 368 avg loss: 0.65603 (A-MSE: 0.57546) avg lploss: 0.00000
train epoch 369 avg loss: 0.59527 (A-MSE: 0.52377) avg lploss: 0.00000
train epoch 370 avg loss: 0.61809 (A-MSE: 0.55059) avg lploss: 0.00000
==> val epoch 370 avg loss: 0.95419 (A-MSE: 0.83400) avg lploss: 0.00000
==> test epoch 370 avg loss: 0.98305 (A-MSE: 0.90195) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 4 out of 50
train epoch 371 avg loss: 0.67384 (A-MSE: 0.59257) avg lploss: 0.00000
train epoch 372 avg loss: 0.65703 (A-MSE: 0.57648) avg lploss: 0.00000
train epoch 373 avg loss: 0.61056 (A-MSE: 0.53526) avg lploss: 0.00000
train epoch 374 avg loss: 0.52972 (A-MSE: 0.46711) avg lploss: 0.00000
train epoch 375 avg loss: 0.53210 (A-MSE: 0.46705) avg lploss: 0.00000
==> val epoch 375 avg loss: 0.88862 (A-MSE: 0.82107) avg lploss: 0.00000
==> test epoch 375 avg loss: 0.89599 (A-MSE: 0.87071) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 5 out of 50
train epoch 376 avg loss: 0.59015 (A-MSE: 0.52435) avg lploss: 0.00000
train epoch 377 avg loss: 0.57384 (A-MSE: 0.50840) avg lploss: 0.00000
train epoch 378 avg loss: 0.56384 (A-MSE: 0.49785) avg lploss: 0.00000
train epoch 379 avg loss: 0.59368 (A-MSE: 0.51945) avg lploss: 0.00000
train epoch 380 avg loss: 0.56523 (A-MSE: 0.49872) avg lploss: 0.00000
==> val epoch 380 avg loss: 0.93689 (A-MSE: 0.85270) avg lploss: 0.00000
==> test epoch 380 avg loss: 0.91028 (A-MSE: 0.87562) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 6 out of 50
train epoch 381 avg loss: 0.49389 (A-MSE: 0.43499) avg lploss: 0.00000
train epoch 382 avg loss: 0.50925 (A-MSE: 0.44870) avg lploss: 0.00000
train epoch 383 avg loss: 0.52016 (A-MSE: 0.45876) avg lploss: 0.00000
train epoch 384 avg loss: 0.51571 (A-MSE: 0.45530) avg lploss: 0.00000
train epoch 385 avg loss: 0.57341 (A-MSE: 0.50410) avg lploss: 0.00000
==> val epoch 385 avg loss: 1.01905 (A-MSE: 0.89950) avg lploss: 0.00000
==> test epoch 385 avg loss: 0.97900 (A-MSE: 0.91765) avg lploss: 0.00000
*** Best Val Loss: 0.85744 	 Best Test Loss: 0.87590 	 Best epoch 350
EarlyStopping counter: 7 out of 50
train epoch 386 avg loss: 0.52996 (A-MSE: 0.46913) avg lploss: 0.00000
train epoch 387 avg loss: 0.53320 (A-MSE: 0.46959) avg lploss: 0.00000
train epoch 388 avg loss: 0.51985 (A-MSE: 0.45988) avg lploss: 0.00000
train epoch 389 avg loss: 0.50047 (A-MSE: 0.43916) avg lploss: 0.00000
train epoch 390 avg loss: 0.48936 (A-MSE: 0.43146) avg lploss: 0.00000
==> val epoch 390 avg loss: 0.77479 (A-MSE: 0.68660) avg lploss: 0.00000
==> test epoch 390 avg loss: 0.84067 (A-MSE: 0.77335) avg lploss: 0.00000
*** Best Val Loss: 0.77479 	 Best Test Loss: 0.84067 	 Best epoch 390
Validation loss decreased (0.857439 --> 0.774787).  Saving model ...
train epoch 391 avg loss: 0.52260 (A-MSE: 0.46249) avg lploss: 0.00000
train epoch 392 avg loss: 0.54951 (A-MSE: 0.47910) avg lploss: 0.00000
train epoch 393 avg loss: 0.44591 (A-MSE: 0.39226) avg lploss: 0.00000
train epoch 394 avg loss: 0.47849 (A-MSE: 0.42392) avg lploss: 0.00000
train epoch 395 avg loss: 0.50924 (A-MSE: 0.44957) avg lploss: 0.00000
==> val epoch 395 avg loss: 0.71133 (A-MSE: 0.63434) avg lploss: 0.00000
==> test epoch 395 avg loss: 0.76409 (A-MSE: 0.71522) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
Validation loss decreased (0.774787 --> 0.711333).  Saving model ...
train epoch 396 avg loss: 0.51410 (A-MSE: 0.45428) avg lploss: 0.00000
train epoch 397 avg loss: 0.45593 (A-MSE: 0.40157) avg lploss: 0.00000
train epoch 398 avg loss: 0.51069 (A-MSE: 0.44557) avg lploss: 0.00000
train epoch 399 avg loss: 0.46159 (A-MSE: 0.40826) avg lploss: 0.00000
train epoch 400 avg loss: 0.46485 (A-MSE: 0.41220) avg lploss: 0.00000
==> val epoch 400 avg loss: 0.82010 (A-MSE: 0.72629) avg lploss: 0.00000
==> test epoch 400 avg loss: 0.81367 (A-MSE: 0.76679) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 1 out of 50
train epoch 401 avg loss: 0.50117 (A-MSE: 0.43738) avg lploss: 0.00000
train epoch 402 avg loss: 0.50137 (A-MSE: 0.44258) avg lploss: 0.00000
train epoch 403 avg loss: 0.49119 (A-MSE: 0.43153) avg lploss: 0.00000
train epoch 404 avg loss: 0.50957 (A-MSE: 0.44671) avg lploss: 0.00000
train epoch 405 avg loss: 0.51386 (A-MSE: 0.45614) avg lploss: 0.00000
==> val epoch 405 avg loss: 0.85478 (A-MSE: 0.78327) avg lploss: 0.00000
==> test epoch 405 avg loss: 0.89934 (A-MSE: 0.86267) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 2 out of 50
train epoch 406 avg loss: 0.48258 (A-MSE: 0.42599) avg lploss: 0.00000
train epoch 407 avg loss: 0.44182 (A-MSE: 0.38897) avg lploss: 0.00000
train epoch 408 avg loss: 0.46776 (A-MSE: 0.40969) avg lploss: 0.00000
train epoch 409 avg loss: 0.47539 (A-MSE: 0.41843) avg lploss: 0.00000
train epoch 410 avg loss: 0.48876 (A-MSE: 0.42859) avg lploss: 0.00000
==> val epoch 410 avg loss: 0.90456 (A-MSE: 0.81511) avg lploss: 0.00000
==> test epoch 410 avg loss: 0.90099 (A-MSE: 0.85192) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 3 out of 50
train epoch 411 avg loss: 0.49550 (A-MSE: 0.43598) avg lploss: 0.00000
train epoch 412 avg loss: 0.51078 (A-MSE: 0.45622) avg lploss: 0.00000
train epoch 413 avg loss: 0.50098 (A-MSE: 0.43764) avg lploss: 0.00000
train epoch 414 avg loss: 0.54934 (A-MSE: 0.48856) avg lploss: 0.00000
train epoch 415 avg loss: 0.51353 (A-MSE: 0.44880) avg lploss: 0.00000
==> val epoch 415 avg loss: 0.77117 (A-MSE: 0.68758) avg lploss: 0.00000
==> test epoch 415 avg loss: 0.83072 (A-MSE: 0.77710) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 4 out of 50
train epoch 416 avg loss: 0.52577 (A-MSE: 0.46376) avg lploss: 0.00000
train epoch 417 avg loss: 0.49038 (A-MSE: 0.43718) avg lploss: 0.00000
train epoch 418 avg loss: 0.43407 (A-MSE: 0.37892) avg lploss: 0.00000
train epoch 419 avg loss: 0.48803 (A-MSE: 0.43084) avg lploss: 0.00000
train epoch 420 avg loss: 0.48940 (A-MSE: 0.42887) avg lploss: 0.00000
==> val epoch 420 avg loss: 0.84070 (A-MSE: 0.74654) avg lploss: 0.00000
==> test epoch 420 avg loss: 0.88869 (A-MSE: 0.83031) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 5 out of 50
train epoch 421 avg loss: 0.51578 (A-MSE: 0.45424) avg lploss: 0.00000
train epoch 422 avg loss: 0.48452 (A-MSE: 0.43064) avg lploss: 0.00000
train epoch 423 avg loss: 0.47007 (A-MSE: 0.40645) avg lploss: 0.00000
train epoch 424 avg loss: 0.47571 (A-MSE: 0.42144) avg lploss: 0.00000
train epoch 425 avg loss: 0.51972 (A-MSE: 0.45434) avg lploss: 0.00000
==> val epoch 425 avg loss: 0.75894 (A-MSE: 0.67755) avg lploss: 0.00000
==> test epoch 425 avg loss: 0.81032 (A-MSE: 0.75983) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 6 out of 50
train epoch 426 avg loss: 0.50285 (A-MSE: 0.44681) avg lploss: 0.00000
train epoch 427 avg loss: 0.45465 (A-MSE: 0.40475) avg lploss: 0.00000
train epoch 428 avg loss: 0.47701 (A-MSE: 0.41732) avg lploss: 0.00000
train epoch 429 avg loss: 0.49238 (A-MSE: 0.43952) avg lploss: 0.00000
train epoch 430 avg loss: 0.50487 (A-MSE: 0.44588) avg lploss: 0.00000
==> val epoch 430 avg loss: 0.83546 (A-MSE: 0.73360) avg lploss: 0.00000
==> test epoch 430 avg loss: 0.89059 (A-MSE: 0.82847) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 7 out of 50
train epoch 431 avg loss: 0.47783 (A-MSE: 0.41945) avg lploss: 0.00000
train epoch 432 avg loss: 0.47562 (A-MSE: 0.42171) avg lploss: 0.00000
train epoch 433 avg loss: 0.46190 (A-MSE: 0.40884) avg lploss: 0.00000
train epoch 434 avg loss: 0.43553 (A-MSE: 0.38274) avg lploss: 0.00000
train epoch 435 avg loss: 0.45216 (A-MSE: 0.39743) avg lploss: 0.00000
==> val epoch 435 avg loss: 0.82592 (A-MSE: 0.72729) avg lploss: 0.00000
==> test epoch 435 avg loss: 0.81329 (A-MSE: 0.77201) avg lploss: 0.00000
*** Best Val Loss: 0.71133 	 Best Test Loss: 0.76409 	 Best epoch 395
EarlyStopping counter: 8 out of 50
train epoch 436 avg loss: 0.45252 (A-MSE: 0.40234) avg lploss: 0.00000
train epoch 437 avg loss: 0.45012 (A-MSE: 0.39545) avg lploss: 0.00000
train epoch 438 avg loss: 0.48363 (A-MSE: 0.42643) avg lploss: 0.00000
train epoch 439 avg loss: 0.46867 (A-MSE: 0.40836) avg lploss: 0.00000
train epoch 440 avg loss: 0.43512 (A-MSE: 0.38677) avg lploss: 0.00000
==> val epoch 440 avg loss: 0.70877 (A-MSE: 0.64235) avg lploss: 0.00000
==> test epoch 440 avg loss: 0.75180 (A-MSE: 0.71592) avg lploss: 0.00000
*** Best Val Loss: 0.70877 	 Best Test Loss: 0.75180 	 Best epoch 440
Validation loss decreased (0.711333 --> 0.708768).  Saving model ...
train epoch 441 avg loss: 0.43398 (A-MSE: 0.38007) avg lploss: 0.00000
train epoch 442 avg loss: 0.42688 (A-MSE: 0.37986) avg lploss: 0.00000
train epoch 443 avg loss: 0.52081 (A-MSE: 0.45786) avg lploss: 0.00000
train epoch 444 avg loss: 0.60228 (A-MSE: 0.52869) avg lploss: 0.00000
train epoch 445 avg loss: 0.53890 (A-MSE: 0.47822) avg lploss: 0.00000
==> val epoch 445 avg loss: 0.88550 (A-MSE: 0.77940) avg lploss: 0.00000
==> test epoch 445 avg loss: 0.85933 (A-MSE: 0.80391) avg lploss: 0.00000
*** Best Val Loss: 0.70877 	 Best Test Loss: 0.75180 	 Best epoch 440
EarlyStopping counter: 1 out of 50
train epoch 446 avg loss: 0.48876 (A-MSE: 0.43505) avg lploss: 0.00000
train epoch 447 avg loss: 0.42626 (A-MSE: 0.37782) avg lploss: 0.00000
train epoch 448 avg loss: 0.42149 (A-MSE: 0.37189) avg lploss: 0.00000
train epoch 449 avg loss: 0.43385 (A-MSE: 0.38093) avg lploss: 0.00000
train epoch 450 avg loss: 0.45086 (A-MSE: 0.39651) avg lploss: 0.00000
==> val epoch 450 avg loss: 0.67754 (A-MSE: 0.61558) avg lploss: 0.00000
==> test epoch 450 avg loss: 0.73328 (A-MSE: 0.70227) avg lploss: 0.00000
*** Best Val Loss: 0.67754 	 Best Test Loss: 0.73328 	 Best epoch 450
Validation loss decreased (0.708768 --> 0.677540).  Saving model ...
train epoch 451 avg loss: 0.45052 (A-MSE: 0.40024) avg lploss: 0.00000
train epoch 452 avg loss: 0.40340 (A-MSE: 0.36067) avg lploss: 0.00000
train epoch 453 avg loss: 0.40891 (A-MSE: 0.36097) avg lploss: 0.00000
train epoch 454 avg loss: 0.41639 (A-MSE: 0.36887) avg lploss: 0.00000
train epoch 455 avg loss: 0.42731 (A-MSE: 0.37397) avg lploss: 0.00000
==> val epoch 455 avg loss: 0.62669 (A-MSE: 0.55893) avg lploss: 0.00000
==> test epoch 455 avg loss: 0.70080 (A-MSE: 0.64803) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
Validation loss decreased (0.677540 --> 0.626692).  Saving model ...
train epoch 456 avg loss: 0.43228 (A-MSE: 0.38586) avg lploss: 0.00000
train epoch 457 avg loss: 0.43892 (A-MSE: 0.38321) avg lploss: 0.00000
train epoch 458 avg loss: 0.43161 (A-MSE: 0.38522) avg lploss: 0.00000
train epoch 459 avg loss: 0.42480 (A-MSE: 0.37420) avg lploss: 0.00000
train epoch 460 avg loss: 0.40480 (A-MSE: 0.35726) avg lploss: 0.00000
==> val epoch 460 avg loss: 0.68664 (A-MSE: 0.59474) avg lploss: 0.00000
==> test epoch 460 avg loss: 0.74959 (A-MSE: 0.67624) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 1 out of 50
train epoch 461 avg loss: 0.43797 (A-MSE: 0.38734) avg lploss: 0.00000
train epoch 462 avg loss: 0.41118 (A-MSE: 0.36480) avg lploss: 0.00000
train epoch 463 avg loss: 0.41408 (A-MSE: 0.36309) avg lploss: 0.00000
train epoch 464 avg loss: 0.47167 (A-MSE: 0.41985) avg lploss: 0.00000
train epoch 465 avg loss: 0.37231 (A-MSE: 0.32948) avg lploss: 0.00000
==> val epoch 465 avg loss: 0.63733 (A-MSE: 0.55539) avg lploss: 0.00000
==> test epoch 465 avg loss: 0.70800 (A-MSE: 0.64343) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 2 out of 50
train epoch 466 avg loss: 0.41787 (A-MSE: 0.36971) avg lploss: 0.00000
train epoch 467 avg loss: 0.44129 (A-MSE: 0.39090) avg lploss: 0.00000
train epoch 468 avg loss: 0.56385 (A-MSE: 0.49993) avg lploss: 0.00000
train epoch 469 avg loss: 0.44815 (A-MSE: 0.39452) avg lploss: 0.00000
train epoch 470 avg loss: 0.44252 (A-MSE: 0.38973) avg lploss: 0.00000
==> val epoch 470 avg loss: 0.94347 (A-MSE: 0.80851) avg lploss: 0.00000
==> test epoch 470 avg loss: 0.85848 (A-MSE: 0.79287) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 3 out of 50
train epoch 471 avg loss: 0.46247 (A-MSE: 0.41035) avg lploss: 0.00000
train epoch 472 avg loss: 0.42365 (A-MSE: 0.37301) avg lploss: 0.00000
train epoch 473 avg loss: 0.49692 (A-MSE: 0.43807) avg lploss: 0.00000
train epoch 474 avg loss: 0.45449 (A-MSE: 0.39579) avg lploss: 0.00000
train epoch 475 avg loss: 0.43695 (A-MSE: 0.39210) avg lploss: 0.00000
==> val epoch 475 avg loss: 0.73583 (A-MSE: 0.65927) avg lploss: 0.00000
==> test epoch 475 avg loss: 0.76890 (A-MSE: 0.72529) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 4 out of 50
train epoch 476 avg loss: 0.42186 (A-MSE: 0.37203) avg lploss: 0.00000
train epoch 477 avg loss: 0.46329 (A-MSE: 0.40895) avg lploss: 0.00000
train epoch 478 avg loss: 0.42540 (A-MSE: 0.37766) avg lploss: 0.00000
train epoch 479 avg loss: 0.38929 (A-MSE: 0.34345) avg lploss: 0.00000
train epoch 480 avg loss: 0.41969 (A-MSE: 0.37217) avg lploss: 0.00000
==> val epoch 480 avg loss: 0.82445 (A-MSE: 0.70167) avg lploss: 0.00000
==> test epoch 480 avg loss: 0.80191 (A-MSE: 0.72012) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 5 out of 50
train epoch 481 avg loss: 0.41384 (A-MSE: 0.35983) avg lploss: 0.00000
train epoch 482 avg loss: 0.39326 (A-MSE: 0.34960) avg lploss: 0.00000
train epoch 483 avg loss: 0.37425 (A-MSE: 0.33291) avg lploss: 0.00000
train epoch 484 avg loss: 0.39192 (A-MSE: 0.34794) avg lploss: 0.00000
train epoch 485 avg loss: 0.41012 (A-MSE: 0.35967) avg lploss: 0.00000
==> val epoch 485 avg loss: 0.64246 (A-MSE: 0.58388) avg lploss: 0.00000
==> test epoch 485 avg loss: 0.70078 (A-MSE: 0.66728) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 6 out of 50
train epoch 486 avg loss: 0.40780 (A-MSE: 0.36267) avg lploss: 0.00000
train epoch 487 avg loss: 0.41352 (A-MSE: 0.36692) avg lploss: 0.00000
train epoch 488 avg loss: 0.46120 (A-MSE: 0.40317) avg lploss: 0.00000
train epoch 489 avg loss: 0.41196 (A-MSE: 0.36347) avg lploss: 0.00000
train epoch 490 avg loss: 0.40817 (A-MSE: 0.36017) avg lploss: 0.00000
==> val epoch 490 avg loss: 0.68663 (A-MSE: 0.58676) avg lploss: 0.00000
==> test epoch 490 avg loss: 0.69425 (A-MSE: 0.63240) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 7 out of 50
train epoch 491 avg loss: 0.37803 (A-MSE: 0.33309) avg lploss: 0.00000
train epoch 492 avg loss: 0.34831 (A-MSE: 0.30579) avg lploss: 0.00000
train epoch 493 avg loss: 0.33720 (A-MSE: 0.30023) avg lploss: 0.00000
train epoch 494 avg loss: 0.44533 (A-MSE: 0.39310) avg lploss: 0.00000
train epoch 495 avg loss: 0.49097 (A-MSE: 0.43125) avg lploss: 0.00000
==> val epoch 495 avg loss: 0.81217 (A-MSE: 0.75845) avg lploss: 0.00000
==> test epoch 495 avg loss: 0.87948 (A-MSE: 0.86887) avg lploss: 0.00000
*** Best Val Loss: 0.62669 	 Best Test Loss: 0.70080 	 Best epoch 455
EarlyStopping counter: 8 out of 50
train epoch 496 avg loss: 0.48540 (A-MSE: 0.43181) avg lploss: 0.00000
train epoch 497 avg loss: 0.42802 (A-MSE: 0.37570) avg lploss: 0.00000
train epoch 498 avg loss: 0.41269 (A-MSE: 0.36737) avg lploss: 0.00000
train epoch 499 avg loss: 0.41896 (A-MSE: 0.37151) avg lploss: 0.00000
train epoch 500 avg loss: 0.40363 (A-MSE: 0.35415) avg lploss: 0.00000
==> val epoch 500 avg loss: 0.61751 (A-MSE: 0.53885) avg lploss: 0.00000
==> test epoch 500 avg loss: 0.64927 (A-MSE: 0.59810) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
Validation loss decreased (0.626692 --> 0.617507).  Saving model ...
train epoch 501 avg loss: 0.35275 (A-MSE: 0.31172) avg lploss: 0.00000
train epoch 502 avg loss: 0.34906 (A-MSE: 0.30746) avg lploss: 0.00000
train epoch 503 avg loss: 0.36224 (A-MSE: 0.31836) avg lploss: 0.00000
train epoch 504 avg loss: 0.36808 (A-MSE: 0.32682) avg lploss: 0.00000
train epoch 505 avg loss: 0.35214 (A-MSE: 0.31257) avg lploss: 0.00000
==> val epoch 505 avg loss: 0.68266 (A-MSE: 0.59655) avg lploss: 0.00000
==> test epoch 505 avg loss: 0.69827 (A-MSE: 0.64987) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
EarlyStopping counter: 1 out of 50
train epoch 506 avg loss: 0.40083 (A-MSE: 0.35424) avg lploss: 0.00000
train epoch 507 avg loss: 0.36653 (A-MSE: 0.32297) avg lploss: 0.00000
train epoch 508 avg loss: 0.36379 (A-MSE: 0.32119) avg lploss: 0.00000
train epoch 509 avg loss: 0.41524 (A-MSE: 0.36820) avg lploss: 0.00000
train epoch 510 avg loss: 0.37263 (A-MSE: 0.32888) avg lploss: 0.00000
==> val epoch 510 avg loss: 0.72824 (A-MSE: 0.62674) avg lploss: 0.00000
==> test epoch 510 avg loss: 0.77689 (A-MSE: 0.69449) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
EarlyStopping counter: 2 out of 50
train epoch 511 avg loss: 0.40652 (A-MSE: 0.35636) avg lploss: 0.00000
train epoch 512 avg loss: 0.43256 (A-MSE: 0.38342) avg lploss: 0.00000
train epoch 513 avg loss: 0.43401 (A-MSE: 0.38020) avg lploss: 0.00000
train epoch 514 avg loss: 0.42102 (A-MSE: 0.37936) avg lploss: 0.00000
train epoch 515 avg loss: 0.39081 (A-MSE: 0.34505) avg lploss: 0.00000
==> val epoch 515 avg loss: 0.74068 (A-MSE: 0.63727) avg lploss: 0.00000
==> test epoch 515 avg loss: 0.71000 (A-MSE: 0.66290) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
EarlyStopping counter: 3 out of 50
train epoch 516 avg loss: 0.38517 (A-MSE: 0.33824) avg lploss: 0.00000
train epoch 517 avg loss: 0.42235 (A-MSE: 0.36977) avg lploss: 0.00000
train epoch 518 avg loss: 0.39201 (A-MSE: 0.34843) avg lploss: 0.00000
train epoch 519 avg loss: 0.38589 (A-MSE: 0.34121) avg lploss: 0.00000
train epoch 520 avg loss: 0.43258 (A-MSE: 0.38177) avg lploss: 0.00000
==> val epoch 520 avg loss: 0.64929 (A-MSE: 0.56620) avg lploss: 0.00000
==> test epoch 520 avg loss: 0.66802 (A-MSE: 0.62147) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
EarlyStopping counter: 4 out of 50
train epoch 521 avg loss: 0.38811 (A-MSE: 0.34266) avg lploss: 0.00000
train epoch 522 avg loss: 0.37611 (A-MSE: 0.33380) avg lploss: 0.00000
train epoch 523 avg loss: 0.38492 (A-MSE: 0.34061) avg lploss: 0.00000
train epoch 524 avg loss: 0.44369 (A-MSE: 0.39369) avg lploss: 0.00000
train epoch 525 avg loss: 0.40558 (A-MSE: 0.36180) avg lploss: 0.00000
==> val epoch 525 avg loss: 0.69388 (A-MSE: 0.60092) avg lploss: 0.00000
==> test epoch 525 avg loss: 0.73284 (A-MSE: 0.67675) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
EarlyStopping counter: 5 out of 50
train epoch 526 avg loss: 0.37652 (A-MSE: 0.33360) avg lploss: 0.00000
train epoch 527 avg loss: 0.38672 (A-MSE: 0.34427) avg lploss: 0.00000
train epoch 528 avg loss: 0.35917 (A-MSE: 0.31696) avg lploss: 0.00000
train epoch 529 avg loss: 0.33352 (A-MSE: 0.29093) avg lploss: 0.00000
train epoch 530 avg loss: 0.38432 (A-MSE: 0.33836) avg lploss: 0.00000
==> val epoch 530 avg loss: 0.76607 (A-MSE: 0.68872) avg lploss: 0.00000
==> test epoch 530 avg loss: 0.74885 (A-MSE: 0.72461) avg lploss: 0.00000
*** Best Val Loss: 0.61751 	 Best Test Loss: 0.64927 	 Best epoch 500
EarlyStopping counter: 6 out of 50
train epoch 531 avg loss: 0.36085 (A-MSE: 0.32151) avg lploss: 0.00000
train epoch 532 avg loss: 0.36695 (A-MSE: 0.32244) avg lploss: 0.00000
train epoch 533 avg loss: 0.39943 (A-MSE: 0.35144) avg lploss: 0.00000
train epoch 534 avg loss: 0.34401 (A-MSE: 0.30363) avg lploss: 0.00000
train epoch 535 avg loss: 0.37462 (A-MSE: 0.33232) avg lploss: 0.00000
==> val epoch 535 avg loss: 0.59936 (A-MSE: 0.53429) avg lploss: 0.00000
==> test epoch 535 avg loss: 0.66023 (A-MSE: 0.61046) avg lploss: 0.00000
*** Best Val Loss: 0.59936 	 Best Test Loss: 0.66023 	 Best epoch 535
Validation loss decreased (0.617507 --> 0.599359).  Saving model ...
train epoch 536 avg loss: 0.36702 (A-MSE: 0.32422) avg lploss: 0.00000
train epoch 537 avg loss: 0.37485 (A-MSE: 0.32999) avg lploss: 0.00000
train epoch 538 avg loss: 0.35789 (A-MSE: 0.31512) avg lploss: 0.00000
train epoch 539 avg loss: 0.37461 (A-MSE: 0.32948) avg lploss: 0.00000
train epoch 540 avg loss: 0.33622 (A-MSE: 0.29681) avg lploss: 0.00000
==> val epoch 540 avg loss: 0.92287 (A-MSE: 0.77120) avg lploss: 0.00000
==> test epoch 540 avg loss: 0.87484 (A-MSE: 0.77238) avg lploss: 0.00000
*** Best Val Loss: 0.59936 	 Best Test Loss: 0.66023 	 Best epoch 535
EarlyStopping counter: 1 out of 50
train epoch 541 avg loss: 0.40397 (A-MSE: 0.35612) avg lploss: 0.00000
train epoch 542 avg loss: 0.33680 (A-MSE: 0.29984) avg lploss: 0.00000
train epoch 543 avg loss: 0.39557 (A-MSE: 0.35374) avg lploss: 0.00000
train epoch 544 avg loss: 0.38540 (A-MSE: 0.33809) avg lploss: 0.00000
train epoch 545 avg loss: 0.33104 (A-MSE: 0.29331) avg lploss: 0.00000
==> val epoch 545 avg loss: 0.66051 (A-MSE: 0.57520) avg lploss: 0.00000
==> test epoch 545 avg loss: 0.68320 (A-MSE: 0.63491) avg lploss: 0.00000
*** Best Val Loss: 0.59936 	 Best Test Loss: 0.66023 	 Best epoch 535
EarlyStopping counter: 2 out of 50
train epoch 546 avg loss: 0.34191 (A-MSE: 0.30043) avg lploss: 0.00000
train epoch 547 avg loss: 0.31600 (A-MSE: 0.27786) avg lploss: 0.00000
train epoch 548 avg loss: 0.31114 (A-MSE: 0.27574) avg lploss: 0.00000
train epoch 549 avg loss: 0.35808 (A-MSE: 0.31603) avg lploss: 0.00000
train epoch 550 avg loss: 0.32659 (A-MSE: 0.29326) avg lploss: 0.00000
==> val epoch 550 avg loss: 0.71193 (A-MSE: 0.63486) avg lploss: 0.00000
==> test epoch 550 avg loss: 0.68086 (A-MSE: 0.65066) avg lploss: 0.00000
*** Best Val Loss: 0.59936 	 Best Test Loss: 0.66023 	 Best epoch 535
EarlyStopping counter: 3 out of 50
train epoch 551 avg loss: 0.35934 (A-MSE: 0.31843) avg lploss: 0.00000
train epoch 552 avg loss: 0.32034 (A-MSE: 0.28325) avg lploss: 0.00000
train epoch 553 avg loss: 0.36064 (A-MSE: 0.31947) avg lploss: 0.00000
train epoch 554 avg loss: 0.35077 (A-MSE: 0.30901) avg lploss: 0.00000
train epoch 555 avg loss: 0.35746 (A-MSE: 0.31450) avg lploss: 0.00000
==> val epoch 555 avg loss: 0.62798 (A-MSE: 0.54642) avg lploss: 0.00000
==> test epoch 555 avg loss: 0.68594 (A-MSE: 0.63766) avg lploss: 0.00000
*** Best Val Loss: 0.59936 	 Best Test Loss: 0.66023 	 Best epoch 535
EarlyStopping counter: 4 out of 50
train epoch 556 avg loss: 0.39278 (A-MSE: 0.35055) avg lploss: 0.00000
train epoch 557 avg loss: 0.38009 (A-MSE: 0.33801) avg lploss: 0.00000
train epoch 558 avg loss: 0.39614 (A-MSE: 0.35130) avg lploss: 0.00000
train epoch 559 avg loss: 0.32231 (A-MSE: 0.28365) avg lploss: 0.00000
train epoch 560 avg loss: 0.30661 (A-MSE: 0.27080) avg lploss: 0.00000
==> val epoch 560 avg loss: 0.54771 (A-MSE: 0.47782) avg lploss: 0.00000
==> test epoch 560 avg loss: 0.58615 (A-MSE: 0.53612) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
Validation loss decreased (0.599359 --> 0.547713).  Saving model ...
train epoch 561 avg loss: 0.30504 (A-MSE: 0.26886) avg lploss: 0.00000
train epoch 562 avg loss: 0.32005 (A-MSE: 0.28243) avg lploss: 0.00000
train epoch 563 avg loss: 0.39004 (A-MSE: 0.34505) avg lploss: 0.00000
train epoch 564 avg loss: 0.34969 (A-MSE: 0.31036) avg lploss: 0.00000
train epoch 565 avg loss: 0.33871 (A-MSE: 0.29972) avg lploss: 0.00000
==> val epoch 565 avg loss: 0.69672 (A-MSE: 0.60525) avg lploss: 0.00000
==> test epoch 565 avg loss: 0.68026 (A-MSE: 0.63274) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 1 out of 50
train epoch 566 avg loss: 0.35262 (A-MSE: 0.30943) avg lploss: 0.00000
train epoch 567 avg loss: 0.35927 (A-MSE: 0.32081) avg lploss: 0.00000
train epoch 568 avg loss: 0.36309 (A-MSE: 0.31954) avg lploss: 0.00000
train epoch 569 avg loss: 0.40196 (A-MSE: 0.35343) avg lploss: 0.00000
train epoch 570 avg loss: 0.31277 (A-MSE: 0.27986) avg lploss: 0.00000
==> val epoch 570 avg loss: 0.63130 (A-MSE: 0.56277) avg lploss: 0.00000
==> test epoch 570 avg loss: 0.65643 (A-MSE: 0.62295) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 2 out of 50
train epoch 571 avg loss: 0.33984 (A-MSE: 0.30068) avg lploss: 0.00000
train epoch 572 avg loss: 0.33585 (A-MSE: 0.29626) avg lploss: 0.00000
train epoch 573 avg loss: 0.33182 (A-MSE: 0.29386) avg lploss: 0.00000
train epoch 574 avg loss: 0.34028 (A-MSE: 0.29978) avg lploss: 0.00000
train epoch 575 avg loss: 0.31648 (A-MSE: 0.27961) avg lploss: 0.00000
==> val epoch 575 avg loss: 0.60224 (A-MSE: 0.52780) avg lploss: 0.00000
==> test epoch 575 avg loss: 0.62857 (A-MSE: 0.58803) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 3 out of 50
train epoch 576 avg loss: 0.34399 (A-MSE: 0.30434) avg lploss: 0.00000
train epoch 577 avg loss: 0.27977 (A-MSE: 0.24821) avg lploss: 0.00000
train epoch 578 avg loss: 0.29761 (A-MSE: 0.26217) avg lploss: 0.00000
train epoch 579 avg loss: 0.29956 (A-MSE: 0.26438) avg lploss: 0.00000
train epoch 580 avg loss: 0.28388 (A-MSE: 0.24923) avg lploss: 0.00000
==> val epoch 580 avg loss: 0.62327 (A-MSE: 0.55127) avg lploss: 0.00000
==> test epoch 580 avg loss: 0.60681 (A-MSE: 0.58361) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 4 out of 50
train epoch 581 avg loss: 0.29948 (A-MSE: 0.26478) avg lploss: 0.00000
train epoch 582 avg loss: 0.30893 (A-MSE: 0.27143) avg lploss: 0.00000
train epoch 583 avg loss: 0.35851 (A-MSE: 0.31295) avg lploss: 0.00000
train epoch 584 avg loss: 0.33483 (A-MSE: 0.29600) avg lploss: 0.00000
train epoch 585 avg loss: 0.36112 (A-MSE: 0.32301) avg lploss: 0.00000
==> val epoch 585 avg loss: 0.61632 (A-MSE: 0.53297) avg lploss: 0.00000
==> test epoch 585 avg loss: 0.63690 (A-MSE: 0.58288) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 5 out of 50
train epoch 586 avg loss: 0.38992 (A-MSE: 0.34342) avg lploss: 0.00000
train epoch 587 avg loss: 0.31010 (A-MSE: 0.27185) avg lploss: 0.00000
train epoch 588 avg loss: 0.32182 (A-MSE: 0.28718) avg lploss: 0.00000
train epoch 589 avg loss: 0.38802 (A-MSE: 0.34185) avg lploss: 0.00000
train epoch 590 avg loss: 0.32864 (A-MSE: 0.29255) avg lploss: 0.00000
==> val epoch 590 avg loss: 0.62309 (A-MSE: 0.54322) avg lploss: 0.00000
==> test epoch 590 avg loss: 0.63589 (A-MSE: 0.59315) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 6 out of 50
train epoch 591 avg loss: 0.32663 (A-MSE: 0.28586) avg lploss: 0.00000
train epoch 592 avg loss: 0.33376 (A-MSE: 0.29628) avg lploss: 0.00000
train epoch 593 avg loss: 0.34047 (A-MSE: 0.30212) avg lploss: 0.00000
train epoch 594 avg loss: 0.33522 (A-MSE: 0.29565) avg lploss: 0.00000
train epoch 595 avg loss: 0.34240 (A-MSE: 0.30066) avg lploss: 0.00000
==> val epoch 595 avg loss: 0.62343 (A-MSE: 0.54262) avg lploss: 0.00000
==> test epoch 595 avg loss: 0.64423 (A-MSE: 0.59545) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 7 out of 50
train epoch 596 avg loss: 0.31656 (A-MSE: 0.27917) avg lploss: 0.00000
train epoch 597 avg loss: 0.47135 (A-MSE: 0.41703) avg lploss: 0.00000
train epoch 598 avg loss: 0.38282 (A-MSE: 0.33881) avg lploss: 0.00000
train epoch 599 avg loss: 0.39747 (A-MSE: 0.35108) avg lploss: 0.00000
train epoch 600 avg loss: 0.36054 (A-MSE: 0.31780) avg lploss: 0.00000
==> val epoch 600 avg loss: 0.62230 (A-MSE: 0.53630) avg lploss: 0.00000
==> test epoch 600 avg loss: 0.61623 (A-MSE: 0.57049) avg lploss: 0.00000
*** Best Val Loss: 0.54771 	 Best Test Loss: 0.58615 	 Best epoch 560
EarlyStopping counter: 8 out of 50
train epoch 601 avg loss: 0.32247 (A-MSE: 0.28354) avg lploss: 0.00000
train epoch 602 avg loss: 0.31208 (A-MSE: 0.27681) avg lploss: 0.00000
train epoch 603 avg loss: 0.31467 (A-MSE: 0.27784) avg lploss: 0.00000
train epoch 604 avg loss: 0.30122 (A-MSE: 0.26603) avg lploss: 0.00000
train epoch 605 avg loss: 0.28635 (A-MSE: 0.25427) avg lploss: 0.00000
==> val epoch 605 avg loss: 0.54754 (A-MSE: 0.47677) avg lploss: 0.00000
==> test epoch 605 avg loss: 0.58460 (A-MSE: 0.54741) avg lploss: 0.00000
*** Best Val Loss: 0.54754 	 Best Test Loss: 0.58460 	 Best epoch 605
Validation loss decreased (0.547713 --> 0.547537).  Saving model ...
train epoch 606 avg loss: 0.33797 (A-MSE: 0.29680) avg lploss: 0.00000
train epoch 607 avg loss: 0.32397 (A-MSE: 0.28568) avg lploss: 0.00000
train epoch 608 avg loss: 0.29211 (A-MSE: 0.25868) avg lploss: 0.00000
train epoch 609 avg loss: 0.30823 (A-MSE: 0.26997) avg lploss: 0.00000
train epoch 610 avg loss: 0.26932 (A-MSE: 0.23705) avg lploss: 0.00000
==> val epoch 610 avg loss: 0.62733 (A-MSE: 0.53906) avg lploss: 0.00000
==> test epoch 610 avg loss: 0.62198 (A-MSE: 0.57522) avg lploss: 0.00000
*** Best Val Loss: 0.54754 	 Best Test Loss: 0.58460 	 Best epoch 605
EarlyStopping counter: 1 out of 50
train epoch 611 avg loss: 0.28590 (A-MSE: 0.25425) avg lploss: 0.00000
train epoch 612 avg loss: 0.31430 (A-MSE: 0.27986) avg lploss: 0.00000
train epoch 613 avg loss: 0.31668 (A-MSE: 0.27713) avg lploss: 0.00000
train epoch 614 avg loss: 0.31392 (A-MSE: 0.27847) avg lploss: 0.00000
train epoch 615 avg loss: 0.31491 (A-MSE: 0.27673) avg lploss: 0.00000
==> val epoch 615 avg loss: 0.61181 (A-MSE: 0.52196) avg lploss: 0.00000
==> test epoch 615 avg loss: 0.60404 (A-MSE: 0.54483) avg lploss: 0.00000
*** Best Val Loss: 0.54754 	 Best Test Loss: 0.58460 	 Best epoch 605
EarlyStopping counter: 2 out of 50
train epoch 616 avg loss: 0.30144 (A-MSE: 0.26763) avg lploss: 0.00000
train epoch 617 avg loss: 0.27671 (A-MSE: 0.24390) avg lploss: 0.00000
train epoch 618 avg loss: 0.27117 (A-MSE: 0.23954) avg lploss: 0.00000
train epoch 619 avg loss: 0.30430 (A-MSE: 0.26682) avg lploss: 0.00000
train epoch 620 avg loss: 0.30905 (A-MSE: 0.27409) avg lploss: 0.00000
==> val epoch 620 avg loss: 0.59329 (A-MSE: 0.52213) avg lploss: 0.00000
==> test epoch 620 avg loss: 0.60176 (A-MSE: 0.56433) avg lploss: 0.00000
*** Best Val Loss: 0.54754 	 Best Test Loss: 0.58460 	 Best epoch 605
EarlyStopping counter: 3 out of 50
train epoch 621 avg loss: 0.30857 (A-MSE: 0.27264) avg lploss: 0.00000
train epoch 622 avg loss: 0.29010 (A-MSE: 0.25769) avg lploss: 0.00000
train epoch 623 avg loss: 0.34324 (A-MSE: 0.30454) avg lploss: 0.00000
train epoch 624 avg loss: 0.32217 (A-MSE: 0.28399) avg lploss: 0.00000
train epoch 625 avg loss: 0.34575 (A-MSE: 0.30452) avg lploss: 0.00000
==> val epoch 625 avg loss: 0.66833 (A-MSE: 0.57460) avg lploss: 0.00000
==> test epoch 625 avg loss: 0.63583 (A-MSE: 0.58012) avg lploss: 0.00000
*** Best Val Loss: 0.54754 	 Best Test Loss: 0.58460 	 Best epoch 605
EarlyStopping counter: 4 out of 50
train epoch 626 avg loss: 0.28682 (A-MSE: 0.25199) avg lploss: 0.00000
train epoch 627 avg loss: 0.26903 (A-MSE: 0.23821) avg lploss: 0.00000
train epoch 628 avg loss: 0.25708 (A-MSE: 0.22457) avg lploss: 0.00000
train epoch 629 avg loss: 0.28615 (A-MSE: 0.25389) avg lploss: 0.00000
train epoch 630 avg loss: 0.32576 (A-MSE: 0.28926) avg lploss: 0.00000
==> val epoch 630 avg loss: 0.50613 (A-MSE: 0.44938) avg lploss: 0.00000
==> test epoch 630 avg loss: 0.57699 (A-MSE: 0.53958) avg lploss: 0.00000
*** Best Val Loss: 0.50613 	 Best Test Loss: 0.57699 	 Best epoch 630
Validation loss decreased (0.547537 --> 0.506134).  Saving model ...
train epoch 631 avg loss: 0.30617 (A-MSE: 0.27039) avg lploss: 0.00000
train epoch 632 avg loss: 0.30753 (A-MSE: 0.27433) avg lploss: 0.00000
train epoch 633 avg loss: 0.31394 (A-MSE: 0.27671) avg lploss: 0.00000
train epoch 634 avg loss: 0.28564 (A-MSE: 0.25194) avg lploss: 0.00000
train epoch 635 avg loss: 0.34067 (A-MSE: 0.30493) avg lploss: 0.00000
==> val epoch 635 avg loss: 0.61241 (A-MSE: 0.53311) avg lploss: 0.00000
==> test epoch 635 avg loss: 0.61154 (A-MSE: 0.56831) avg lploss: 0.00000
*** Best Val Loss: 0.50613 	 Best Test Loss: 0.57699 	 Best epoch 630
EarlyStopping counter: 1 out of 50
train epoch 636 avg loss: 0.34774 (A-MSE: 0.30644) avg lploss: 0.00000
train epoch 637 avg loss: 0.32057 (A-MSE: 0.28456) avg lploss: 0.00000
train epoch 638 avg loss: 0.27792 (A-MSE: 0.24514) avg lploss: 0.00000
train epoch 639 avg loss: 0.33478 (A-MSE: 0.29452) avg lploss: 0.00000
train epoch 640 avg loss: 0.43495 (A-MSE: 0.38296) avg lploss: 0.00000
==> val epoch 640 avg loss: 0.67081 (A-MSE: 0.59142) avg lploss: 0.00000
==> test epoch 640 avg loss: 0.68617 (A-MSE: 0.64525) avg lploss: 0.00000
*** Best Val Loss: 0.50613 	 Best Test Loss: 0.57699 	 Best epoch 630
EarlyStopping counter: 2 out of 50
train epoch 641 avg loss: 0.35983 (A-MSE: 0.31891) avg lploss: 0.00000
train epoch 642 avg loss: 0.31694 (A-MSE: 0.27974) avg lploss: 0.00000
train epoch 643 avg loss: 0.30485 (A-MSE: 0.27027) avg lploss: 0.00000
train epoch 644 avg loss: 0.28017 (A-MSE: 0.24873) avg lploss: 0.00000
train epoch 645 avg loss: 0.32355 (A-MSE: 0.28498) avg lploss: 0.00000
==> val epoch 645 avg loss: 0.56789 (A-MSE: 0.48166) avg lploss: 0.00000
==> test epoch 645 avg loss: 0.56261 (A-MSE: 0.51301) avg lploss: 0.00000
*** Best Val Loss: 0.50613 	 Best Test Loss: 0.57699 	 Best epoch 630
EarlyStopping counter: 3 out of 50
train epoch 646 avg loss: 0.31597 (A-MSE: 0.27916) avg lploss: 0.00000
train epoch 647 avg loss: 0.28185 (A-MSE: 0.25021) avg lploss: 0.00000
train epoch 648 avg loss: 0.28849 (A-MSE: 0.25250) avg lploss: 0.00000
train epoch 649 avg loss: 0.29420 (A-MSE: 0.26025) avg lploss: 0.00000
train epoch 650 avg loss: 0.26510 (A-MSE: 0.23398) avg lploss: 0.00000
==> val epoch 650 avg loss: 0.50373 (A-MSE: 0.44048) avg lploss: 0.00000
==> test epoch 650 avg loss: 0.53530 (A-MSE: 0.49744) avg lploss: 0.00000
*** Best Val Loss: 0.50373 	 Best Test Loss: 0.53530 	 Best epoch 650
Validation loss decreased (0.506134 --> 0.503729).  Saving model ...
train epoch 651 avg loss: 0.30406 (A-MSE: 0.27076) avg lploss: 0.00000
train epoch 652 avg loss: 0.28556 (A-MSE: 0.25246) avg lploss: 0.00000
train epoch 653 avg loss: 0.25888 (A-MSE: 0.22751) avg lploss: 0.00000
train epoch 654 avg loss: 0.27644 (A-MSE: 0.24489) avg lploss: 0.00000
train epoch 655 avg loss: 0.28168 (A-MSE: 0.25025) avg lploss: 0.00000
==> val epoch 655 avg loss: 0.65377 (A-MSE: 0.57264) avg lploss: 0.00000
==> test epoch 655 avg loss: 0.67811 (A-MSE: 0.62826) avg lploss: 0.00000
*** Best Val Loss: 0.50373 	 Best Test Loss: 0.53530 	 Best epoch 650
EarlyStopping counter: 1 out of 50
train epoch 656 avg loss: 0.37869 (A-MSE: 0.33646) avg lploss: 0.00000
train epoch 657 avg loss: 0.31226 (A-MSE: 0.27712) avg lploss: 0.00000
train epoch 658 avg loss: 0.30059 (A-MSE: 0.26462) avg lploss: 0.00000
train epoch 659 avg loss: 0.28849 (A-MSE: 0.25371) avg lploss: 0.00000
train epoch 660 avg loss: 0.30552 (A-MSE: 0.26932) avg lploss: 0.00000
==> val epoch 660 avg loss: 0.48871 (A-MSE: 0.43178) avg lploss: 0.00000
==> test epoch 660 avg loss: 0.50129 (A-MSE: 0.46756) avg lploss: 0.00000
*** Best Val Loss: 0.48871 	 Best Test Loss: 0.50129 	 Best epoch 660
Validation loss decreased (0.503729 --> 0.488713).  Saving model ...
train epoch 661 avg loss: 0.27943 (A-MSE: 0.24731) avg lploss: 0.00000
train epoch 662 avg loss: 0.25258 (A-MSE: 0.22359) avg lploss: 0.00000
train epoch 663 avg loss: 0.25480 (A-MSE: 0.22464) avg lploss: 0.00000
train epoch 664 avg loss: 0.24477 (A-MSE: 0.21475) avg lploss: 0.00000
train epoch 665 avg loss: 0.27854 (A-MSE: 0.24613) avg lploss: 0.00000
==> val epoch 665 avg loss: 0.66089 (A-MSE: 0.56709) avg lploss: 0.00000
==> test epoch 665 avg loss: 0.61520 (A-MSE: 0.56381) avg lploss: 0.00000
*** Best Val Loss: 0.48871 	 Best Test Loss: 0.50129 	 Best epoch 660
EarlyStopping counter: 1 out of 50
train epoch 666 avg loss: 0.30319 (A-MSE: 0.26672) avg lploss: 0.00000
train epoch 667 avg loss: 0.30566 (A-MSE: 0.26976) avg lploss: 0.00000
train epoch 668 avg loss: 0.33012 (A-MSE: 0.29360) avg lploss: 0.00000
train epoch 669 avg loss: 0.31329 (A-MSE: 0.27521) avg lploss: 0.00000
train epoch 670 avg loss: 0.29801 (A-MSE: 0.26470) avg lploss: 0.00000
==> val epoch 670 avg loss: 0.53068 (A-MSE: 0.46845) avg lploss: 0.00000
==> test epoch 670 avg loss: 0.54987 (A-MSE: 0.51459) avg lploss: 0.00000
*** Best Val Loss: 0.48871 	 Best Test Loss: 0.50129 	 Best epoch 660
EarlyStopping counter: 2 out of 50
train epoch 671 avg loss: 0.30341 (A-MSE: 0.26908) avg lploss: 0.00000
train epoch 672 avg loss: 0.33084 (A-MSE: 0.29034) avg lploss: 0.00000
train epoch 673 avg loss: 0.28770 (A-MSE: 0.25573) avg lploss: 0.00000
train epoch 674 avg loss: 0.27841 (A-MSE: 0.24373) avg lploss: 0.00000
train epoch 675 avg loss: 0.30957 (A-MSE: 0.27556) avg lploss: 0.00000
==> val epoch 675 avg loss: 0.51788 (A-MSE: 0.45333) avg lploss: 0.00000
==> test epoch 675 avg loss: 0.54255 (A-MSE: 0.50370) avg lploss: 0.00000
*** Best Val Loss: 0.48871 	 Best Test Loss: 0.50129 	 Best epoch 660
EarlyStopping counter: 3 out of 50
train epoch 676 avg loss: 0.25151 (A-MSE: 0.22146) avg lploss: 0.00000
train epoch 677 avg loss: 0.28010 (A-MSE: 0.24749) avg lploss: 0.00000
train epoch 678 avg loss: 0.25901 (A-MSE: 0.22815) avg lploss: 0.00000
train epoch 679 avg loss: 0.23826 (A-MSE: 0.21096) avg lploss: 0.00000
train epoch 680 avg loss: 0.25886 (A-MSE: 0.22737) avg lploss: 0.00000
==> val epoch 680 avg loss: 0.46139 (A-MSE: 0.40390) avg lploss: 0.00000
==> test epoch 680 avg loss: 0.49052 (A-MSE: 0.44622) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
Validation loss decreased (0.488713 --> 0.461390).  Saving model ...
train epoch 681 avg loss: 0.24729 (A-MSE: 0.21988) avg lploss: 0.00000
train epoch 682 avg loss: 0.25492 (A-MSE: 0.22595) avg lploss: 0.00000
train epoch 683 avg loss: 0.25942 (A-MSE: 0.22984) avg lploss: 0.00000
train epoch 684 avg loss: 0.24419 (A-MSE: 0.21495) avg lploss: 0.00000
train epoch 685 avg loss: 0.23354 (A-MSE: 0.20517) avg lploss: 0.00000
==> val epoch 685 avg loss: 0.51562 (A-MSE: 0.44608) avg lploss: 0.00000
==> test epoch 685 avg loss: 0.50591 (A-MSE: 0.46476) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 1 out of 50
train epoch 686 avg loss: 0.23158 (A-MSE: 0.20448) avg lploss: 0.00000
train epoch 687 avg loss: 0.27504 (A-MSE: 0.24234) avg lploss: 0.00000
train epoch 688 avg loss: 0.27298 (A-MSE: 0.24169) avg lploss: 0.00000
train epoch 689 avg loss: 0.25804 (A-MSE: 0.22663) avg lploss: 0.00000
train epoch 690 avg loss: 0.29766 (A-MSE: 0.26344) avg lploss: 0.00000
==> val epoch 690 avg loss: 0.56413 (A-MSE: 0.50745) avg lploss: 0.00000
==> test epoch 690 avg loss: 0.59776 (A-MSE: 0.56823) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 2 out of 50
train epoch 691 avg loss: 0.28393 (A-MSE: 0.25170) avg lploss: 0.00000
train epoch 692 avg loss: 0.28636 (A-MSE: 0.24957) avg lploss: 0.00000
train epoch 693 avg loss: 0.26368 (A-MSE: 0.23384) avg lploss: 0.00000
train epoch 694 avg loss: 0.29107 (A-MSE: 0.25489) avg lploss: 0.00000
train epoch 695 avg loss: 0.26290 (A-MSE: 0.23411) avg lploss: 0.00000
==> val epoch 695 avg loss: 0.46279 (A-MSE: 0.41178) avg lploss: 0.00000
==> test epoch 695 avg loss: 0.53975 (A-MSE: 0.50453) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 3 out of 50
train epoch 696 avg loss: 0.28652 (A-MSE: 0.25214) avg lploss: 0.00000
train epoch 697 avg loss: 0.27148 (A-MSE: 0.24033) avg lploss: 0.00000
train epoch 698 avg loss: 0.28030 (A-MSE: 0.24811) avg lploss: 0.00000
train epoch 699 avg loss: 0.26055 (A-MSE: 0.23089) avg lploss: 0.00000
train epoch 700 avg loss: 0.24468 (A-MSE: 0.21456) avg lploss: 0.00000
==> val epoch 700 avg loss: 0.52791 (A-MSE: 0.47035) avg lploss: 0.00000
==> test epoch 700 avg loss: 0.56882 (A-MSE: 0.53189) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 4 out of 50
train epoch 701 avg loss: 0.25449 (A-MSE: 0.22577) avg lploss: 0.00000
train epoch 702 avg loss: 0.25573 (A-MSE: 0.22590) avg lploss: 0.00000
train epoch 703 avg loss: 0.26512 (A-MSE: 0.23095) avg lploss: 0.00000
train epoch 704 avg loss: 0.28356 (A-MSE: 0.25057) avg lploss: 0.00000
train epoch 705 avg loss: 0.28120 (A-MSE: 0.24888) avg lploss: 0.00000
==> val epoch 705 avg loss: 0.53816 (A-MSE: 0.46298) avg lploss: 0.00000
==> test epoch 705 avg loss: 0.54307 (A-MSE: 0.49953) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 5 out of 50
train epoch 706 avg loss: 0.26694 (A-MSE: 0.23353) avg lploss: 0.00000
train epoch 707 avg loss: 0.29296 (A-MSE: 0.25703) avg lploss: 0.00000
train epoch 708 avg loss: 0.25171 (A-MSE: 0.22246) avg lploss: 0.00000
train epoch 709 avg loss: 0.26131 (A-MSE: 0.22952) avg lploss: 0.00000
train epoch 710 avg loss: 0.24876 (A-MSE: 0.22277) avg lploss: 0.00000
==> val epoch 710 avg loss: 0.48594 (A-MSE: 0.42239) avg lploss: 0.00000
==> test epoch 710 avg loss: 0.55226 (A-MSE: 0.49797) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 6 out of 50
train epoch 711 avg loss: 0.25718 (A-MSE: 0.22793) avg lploss: 0.00000
train epoch 712 avg loss: 0.22884 (A-MSE: 0.20270) avg lploss: 0.00000
train epoch 713 avg loss: 0.26496 (A-MSE: 0.23572) avg lploss: 0.00000
train epoch 714 avg loss: 0.24465 (A-MSE: 0.21635) avg lploss: 0.00000
train epoch 715 avg loss: 0.23684 (A-MSE: 0.20864) avg lploss: 0.00000
==> val epoch 715 avg loss: 0.51569 (A-MSE: 0.44428) avg lploss: 0.00000
==> test epoch 715 avg loss: 0.50955 (A-MSE: 0.46741) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 7 out of 50
train epoch 716 avg loss: 0.28978 (A-MSE: 0.25486) avg lploss: 0.00000
train epoch 717 avg loss: 0.27160 (A-MSE: 0.23976) avg lploss: 0.00000
train epoch 718 avg loss: 0.23439 (A-MSE: 0.20755) avg lploss: 0.00000
train epoch 719 avg loss: 0.22079 (A-MSE: 0.19519) avg lploss: 0.00000
train epoch 720 avg loss: 0.21124 (A-MSE: 0.18663) avg lploss: 0.00000
==> val epoch 720 avg loss: 0.51729 (A-MSE: 0.44698) avg lploss: 0.00000
==> test epoch 720 avg loss: 0.50661 (A-MSE: 0.46759) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 8 out of 50
train epoch 721 avg loss: 0.23196 (A-MSE: 0.20454) avg lploss: 0.00000
train epoch 722 avg loss: 0.23015 (A-MSE: 0.20378) avg lploss: 0.00000
train epoch 723 avg loss: 0.22884 (A-MSE: 0.20227) avg lploss: 0.00000
train epoch 724 avg loss: 0.24100 (A-MSE: 0.21356) avg lploss: 0.00000
train epoch 725 avg loss: 0.22435 (A-MSE: 0.19687) avg lploss: 0.00000
==> val epoch 725 avg loss: 0.53451 (A-MSE: 0.47222) avg lploss: 0.00000
==> test epoch 725 avg loss: 0.53659 (A-MSE: 0.50385) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 9 out of 50
train epoch 726 avg loss: 0.24740 (A-MSE: 0.21894) avg lploss: 0.00000
train epoch 727 avg loss: 0.29540 (A-MSE: 0.25871) avg lploss: 0.00000
train epoch 728 avg loss: 0.26736 (A-MSE: 0.23564) avg lploss: 0.00000
train epoch 729 avg loss: 0.23468 (A-MSE: 0.20725) avg lploss: 0.00000
train epoch 730 avg loss: 0.23980 (A-MSE: 0.21037) avg lploss: 0.00000
==> val epoch 730 avg loss: 0.48937 (A-MSE: 0.41850) avg lploss: 0.00000
==> test epoch 730 avg loss: 0.49447 (A-MSE: 0.44816) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 10 out of 50
train epoch 731 avg loss: 0.22093 (A-MSE: 0.19567) avg lploss: 0.00000
train epoch 732 avg loss: 0.21454 (A-MSE: 0.18956) avg lploss: 0.00000
train epoch 733 avg loss: 0.23072 (A-MSE: 0.20245) avg lploss: 0.00000
train epoch 734 avg loss: 0.23414 (A-MSE: 0.20773) avg lploss: 0.00000
train epoch 735 avg loss: 0.22526 (A-MSE: 0.19983) avg lploss: 0.00000
==> val epoch 735 avg loss: 0.50972 (A-MSE: 0.43530) avg lploss: 0.00000
==> test epoch 735 avg loss: 0.52132 (A-MSE: 0.47183) avg lploss: 0.00000
*** Best Val Loss: 0.46139 	 Best Test Loss: 0.49052 	 Best epoch 680
EarlyStopping counter: 11 out of 50
train epoch 736 avg loss: 0.24653 (A-MSE: 0.21753) avg lploss: 0.00000
train epoch 737 avg loss: 0.25245 (A-MSE: 0.22449) avg lploss: 0.00000
train epoch 738 avg loss: 0.22021 (A-MSE: 0.19371) avg lploss: 0.00000
train epoch 739 avg loss: 0.22291 (A-MSE: 0.19831) avg lploss: 0.00000
train epoch 740 avg loss: 0.23258 (A-MSE: 0.20578) avg lploss: 0.00000
==> val epoch 740 avg loss: 0.43874 (A-MSE: 0.38467) avg lploss: 0.00000
==> test epoch 740 avg loss: 0.47446 (A-MSE: 0.44030) avg lploss: 0.00000
*** Best Val Loss: 0.43874 	 Best Test Loss: 0.47446 	 Best epoch 740
Validation loss decreased (0.461390 --> 0.438742).  Saving model ...
train epoch 741 avg loss: 0.28077 (A-MSE: 0.24646) avg lploss: 0.00000
train epoch 742 avg loss: 0.27410 (A-MSE: 0.24232) avg lploss: 0.00000
train epoch 743 avg loss: 0.25103 (A-MSE: 0.22103) avg lploss: 0.00000
train epoch 744 avg loss: 0.22273 (A-MSE: 0.19648) avg lploss: 0.00000
train epoch 745 avg loss: 0.22443 (A-MSE: 0.19753) avg lploss: 0.00000
==> val epoch 745 avg loss: 0.56667 (A-MSE: 0.47847) avg lploss: 0.00000
==> test epoch 745 avg loss: 0.54885 (A-MSE: 0.49417) avg lploss: 0.00000
*** Best Val Loss: 0.43874 	 Best Test Loss: 0.47446 	 Best epoch 740
EarlyStopping counter: 1 out of 50
train epoch 746 avg loss: 0.21230 (A-MSE: 0.18784) avg lploss: 0.00000
train epoch 747 avg loss: 0.21509 (A-MSE: 0.19142) avg lploss: 0.00000
train epoch 748 avg loss: 0.20214 (A-MSE: 0.17726) avg lploss: 0.00000
train epoch 749 avg loss: 0.20165 (A-MSE: 0.17834) avg lploss: 0.00000
train epoch 750 avg loss: 0.23643 (A-MSE: 0.20849) avg lploss: 0.00000
==> val epoch 750 avg loss: 0.46820 (A-MSE: 0.40532) avg lploss: 0.00000
==> test epoch 750 avg loss: 0.48312 (A-MSE: 0.44047) avg lploss: 0.00000
*** Best Val Loss: 0.43874 	 Best Test Loss: 0.47446 	 Best epoch 740
EarlyStopping counter: 2 out of 50
train epoch 751 avg loss: 0.24180 (A-MSE: 0.21218) avg lploss: 0.00000
train epoch 752 avg loss: 0.24515 (A-MSE: 0.21803) avg lploss: 0.00000
train epoch 753 avg loss: 0.28134 (A-MSE: 0.25097) avg lploss: 0.00000
train epoch 754 avg loss: 0.26176 (A-MSE: 0.23129) avg lploss: 0.00000
train epoch 755 avg loss: 0.23698 (A-MSE: 0.20913) avg lploss: 0.00000
==> val epoch 755 avg loss: 0.47731 (A-MSE: 0.43209) avg lploss: 0.00000
==> test epoch 755 avg loss: 0.51561 (A-MSE: 0.48476) avg lploss: 0.00000
*** Best Val Loss: 0.43874 	 Best Test Loss: 0.47446 	 Best epoch 740
EarlyStopping counter: 3 out of 50
train epoch 756 avg loss: 0.23376 (A-MSE: 0.20713) avg lploss: 0.00000
train epoch 757 avg loss: 0.27855 (A-MSE: 0.24558) avg lploss: 0.00000
train epoch 758 avg loss: 0.28677 (A-MSE: 0.25633) avg lploss: 0.00000
train epoch 759 avg loss: 0.25283 (A-MSE: 0.22183) avg lploss: 0.00000
train epoch 760 avg loss: 0.22835 (A-MSE: 0.20191) avg lploss: 0.00000
==> val epoch 760 avg loss: 0.43997 (A-MSE: 0.38995) avg lploss: 0.00000
==> test epoch 760 avg loss: 0.46320 (A-MSE: 0.43235) avg lploss: 0.00000
*** Best Val Loss: 0.43874 	 Best Test Loss: 0.47446 	 Best epoch 740
EarlyStopping counter: 4 out of 50
train epoch 761 avg loss: 0.21082 (A-MSE: 0.18726) avg lploss: 0.00000
train epoch 762 avg loss: 0.22976 (A-MSE: 0.20255) avg lploss: 0.00000
train epoch 763 avg loss: 0.22752 (A-MSE: 0.20071) avg lploss: 0.00000
train epoch 764 avg loss: 0.23821 (A-MSE: 0.21215) avg lploss: 0.00000
train epoch 765 avg loss: 0.23715 (A-MSE: 0.20937) avg lploss: 0.00000
==> val epoch 765 avg loss: 0.42642 (A-MSE: 0.37531) avg lploss: 0.00000
==> test epoch 765 avg loss: 0.49224 (A-MSE: 0.45136) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
Validation loss decreased (0.438742 --> 0.426417).  Saving model ...
train epoch 766 avg loss: 0.24676 (A-MSE: 0.21766) avg lploss: 0.00000
train epoch 767 avg loss: 0.22240 (A-MSE: 0.19641) avg lploss: 0.00000
train epoch 768 avg loss: 0.21574 (A-MSE: 0.19160) avg lploss: 0.00000
train epoch 769 avg loss: 0.24703 (A-MSE: 0.21717) avg lploss: 0.00000
train epoch 770 avg loss: 0.23816 (A-MSE: 0.21173) avg lploss: 0.00000
==> val epoch 770 avg loss: 0.48612 (A-MSE: 0.42764) avg lploss: 0.00000
==> test epoch 770 avg loss: 0.55674 (A-MSE: 0.50795) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 1 out of 50
train epoch 771 avg loss: 0.25837 (A-MSE: 0.22608) avg lploss: 0.00000
train epoch 772 avg loss: 0.23414 (A-MSE: 0.20780) avg lploss: 0.00000
train epoch 773 avg loss: 0.25138 (A-MSE: 0.22086) avg lploss: 0.00000
train epoch 774 avg loss: 0.24889 (A-MSE: 0.21821) avg lploss: 0.00000
train epoch 775 avg loss: 0.25072 (A-MSE: 0.22079) avg lploss: 0.00000
==> val epoch 775 avg loss: 0.46148 (A-MSE: 0.40979) avg lploss: 0.00000
==> test epoch 775 avg loss: 0.48346 (A-MSE: 0.44738) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 2 out of 50
train epoch 776 avg loss: 0.21506 (A-MSE: 0.19244) avg lploss: 0.00000
train epoch 777 avg loss: 0.25911 (A-MSE: 0.22746) avg lploss: 0.00000
train epoch 778 avg loss: 0.24263 (A-MSE: 0.21639) avg lploss: 0.00000
train epoch 779 avg loss: 0.19469 (A-MSE: 0.17242) avg lploss: 0.00000
train epoch 780 avg loss: 0.21434 (A-MSE: 0.18821) avg lploss: 0.00000
==> val epoch 780 avg loss: 0.51981 (A-MSE: 0.45244) avg lploss: 0.00000
==> test epoch 780 avg loss: 0.51568 (A-MSE: 0.47040) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 3 out of 50
train epoch 781 avg loss: 0.20374 (A-MSE: 0.18152) avg lploss: 0.00000
train epoch 782 avg loss: 0.21191 (A-MSE: 0.18639) avg lploss: 0.00000
train epoch 783 avg loss: 0.19290 (A-MSE: 0.17171) avg lploss: 0.00000
train epoch 784 avg loss: 0.22904 (A-MSE: 0.20263) avg lploss: 0.00000
train epoch 785 avg loss: 0.25098 (A-MSE: 0.22305) avg lploss: 0.00000
==> val epoch 785 avg loss: 0.52343 (A-MSE: 0.46588) avg lploss: 0.00000
==> test epoch 785 avg loss: 0.55547 (A-MSE: 0.51270) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 4 out of 50
train epoch 786 avg loss: 0.25955 (A-MSE: 0.22827) avg lploss: 0.00000
train epoch 787 avg loss: 0.24128 (A-MSE: 0.21278) avg lploss: 0.00000
train epoch 788 avg loss: 0.26469 (A-MSE: 0.23236) avg lploss: 0.00000
train epoch 789 avg loss: 0.22506 (A-MSE: 0.20055) avg lploss: 0.00000
train epoch 790 avg loss: 0.24191 (A-MSE: 0.21447) avg lploss: 0.00000
==> val epoch 790 avg loss: 0.45017 (A-MSE: 0.39804) avg lploss: 0.00000
==> test epoch 790 avg loss: 0.47363 (A-MSE: 0.44211) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 5 out of 50
train epoch 791 avg loss: 0.25231 (A-MSE: 0.22315) avg lploss: 0.00000
train epoch 792 avg loss: 0.24401 (A-MSE: 0.21587) avg lploss: 0.00000
train epoch 793 avg loss: 0.24415 (A-MSE: 0.21548) avg lploss: 0.00000
train epoch 794 avg loss: 0.25097 (A-MSE: 0.22527) avg lploss: 0.00000
train epoch 795 avg loss: 0.23463 (A-MSE: 0.20459) avg lploss: 0.00000
==> val epoch 795 avg loss: 0.53299 (A-MSE: 0.45432) avg lploss: 0.00000
==> test epoch 795 avg loss: 0.56973 (A-MSE: 0.51347) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 6 out of 50
train epoch 796 avg loss: 0.22456 (A-MSE: 0.19883) avg lploss: 0.00000
train epoch 797 avg loss: 0.20518 (A-MSE: 0.18152) avg lploss: 0.00000
train epoch 798 avg loss: 0.22588 (A-MSE: 0.19947) avg lploss: 0.00000
train epoch 799 avg loss: 0.22520 (A-MSE: 0.19928) avg lploss: 0.00000
train epoch 800 avg loss: 0.22332 (A-MSE: 0.19710) avg lploss: 0.00000
==> val epoch 800 avg loss: 0.61552 (A-MSE: 0.51465) avg lploss: 0.00000
==> test epoch 800 avg loss: 0.59125 (A-MSE: 0.52924) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 7 out of 50
train epoch 801 avg loss: 0.27988 (A-MSE: 0.24947) avg lploss: 0.00000
train epoch 802 avg loss: 0.29568 (A-MSE: 0.25844) avg lploss: 0.00000
train epoch 803 avg loss: 0.27897 (A-MSE: 0.24655) avg lploss: 0.00000
train epoch 804 avg loss: 0.22998 (A-MSE: 0.20247) avg lploss: 0.00000
train epoch 805 avg loss: 0.21611 (A-MSE: 0.19155) avg lploss: 0.00000
==> val epoch 805 avg loss: 0.45025 (A-MSE: 0.40597) avg lploss: 0.00000
==> test epoch 805 avg loss: 0.48990 (A-MSE: 0.46541) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 8 out of 50
train epoch 806 avg loss: 0.19696 (A-MSE: 0.17377) avg lploss: 0.00000
train epoch 807 avg loss: 0.22707 (A-MSE: 0.20172) avg lploss: 0.00000
train epoch 808 avg loss: 0.24793 (A-MSE: 0.22093) avg lploss: 0.00000
train epoch 809 avg loss: 0.27317 (A-MSE: 0.24278) avg lploss: 0.00000
train epoch 810 avg loss: 0.22297 (A-MSE: 0.19663) avg lploss: 0.00000
==> val epoch 810 avg loss: 0.44257 (A-MSE: 0.37887) avg lploss: 0.00000
==> test epoch 810 avg loss: 0.46395 (A-MSE: 0.41742) avg lploss: 0.00000
*** Best Val Loss: 0.42642 	 Best Test Loss: 0.49224 	 Best epoch 765
EarlyStopping counter: 9 out of 50
train epoch 811 avg loss: 0.19968 (A-MSE: 0.17456) avg lploss: 0.00000
train epoch 812 avg loss: 0.19691 (A-MSE: 0.17331) avg lploss: 0.00000
train epoch 813 avg loss: 0.20893 (A-MSE: 0.18557) avg lploss: 0.00000
train epoch 814 avg loss: 0.20588 (A-MSE: 0.18246) avg lploss: 0.00000
train epoch 815 avg loss: 0.22189 (A-MSE: 0.19449) avg lploss: 0.00000
==> val epoch 815 avg loss: 0.41396 (A-MSE: 0.35541) avg lploss: 0.00000
==> test epoch 815 avg loss: 0.45289 (A-MSE: 0.40940) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
Validation loss decreased (0.426417 --> 0.413964).  Saving model ...
train epoch 816 avg loss: 0.21034 (A-MSE: 0.18442) avg lploss: 0.00000
train epoch 817 avg loss: 0.19778 (A-MSE: 0.17468) avg lploss: 0.00000
train epoch 818 avg loss: 0.19761 (A-MSE: 0.17572) avg lploss: 0.00000
train epoch 819 avg loss: 0.22001 (A-MSE: 0.19342) avg lploss: 0.00000
train epoch 820 avg loss: 0.21178 (A-MSE: 0.18729) avg lploss: 0.00000
==> val epoch 820 avg loss: 0.49614 (A-MSE: 0.43259) avg lploss: 0.00000
==> test epoch 820 avg loss: 0.50587 (A-MSE: 0.46964) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 1 out of 50
train epoch 821 avg loss: 0.23303 (A-MSE: 0.20599) avg lploss: 0.00000
train epoch 822 avg loss: 0.22828 (A-MSE: 0.20102) avg lploss: 0.00000
train epoch 823 avg loss: 0.21869 (A-MSE: 0.19283) avg lploss: 0.00000
train epoch 824 avg loss: 0.20551 (A-MSE: 0.18175) avg lploss: 0.00000
train epoch 825 avg loss: 0.20992 (A-MSE: 0.18468) avg lploss: 0.00000
==> val epoch 825 avg loss: 0.60250 (A-MSE: 0.52897) avg lploss: 0.00000
==> test epoch 825 avg loss: 0.58893 (A-MSE: 0.54765) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 2 out of 50
train epoch 826 avg loss: 0.24287 (A-MSE: 0.21490) avg lploss: 0.00000
train epoch 827 avg loss: 0.20707 (A-MSE: 0.17994) avg lploss: 0.00000
train epoch 828 avg loss: 0.18320 (A-MSE: 0.16187) avg lploss: 0.00000
train epoch 829 avg loss: 0.16713 (A-MSE: 0.14719) avg lploss: 0.00000
train epoch 830 avg loss: 0.18549 (A-MSE: 0.16494) avg lploss: 0.00000
==> val epoch 830 avg loss: 0.44698 (A-MSE: 0.39563) avg lploss: 0.00000
==> test epoch 830 avg loss: 0.45417 (A-MSE: 0.42837) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 3 out of 50
train epoch 831 avg loss: 0.18832 (A-MSE: 0.16602) avg lploss: 0.00000
train epoch 832 avg loss: 0.22109 (A-MSE: 0.19360) avg lploss: 0.00000
train epoch 833 avg loss: 0.21895 (A-MSE: 0.19437) avg lploss: 0.00000
train epoch 834 avg loss: 0.24216 (A-MSE: 0.21256) avg lploss: 0.00000
train epoch 835 avg loss: 0.22246 (A-MSE: 0.19675) avg lploss: 0.00000
==> val epoch 835 avg loss: 0.42616 (A-MSE: 0.38504) avg lploss: 0.00000
==> test epoch 835 avg loss: 0.45653 (A-MSE: 0.43220) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 4 out of 50
train epoch 836 avg loss: 0.19207 (A-MSE: 0.16698) avg lploss: 0.00000
train epoch 837 avg loss: 0.19416 (A-MSE: 0.17109) avg lploss: 0.00000
train epoch 838 avg loss: 0.19245 (A-MSE: 0.16961) avg lploss: 0.00000
train epoch 839 avg loss: 0.18310 (A-MSE: 0.15990) avg lploss: 0.00000
train epoch 840 avg loss: 0.19993 (A-MSE: 0.17654) avg lploss: 0.00000
==> val epoch 840 avg loss: 0.46563 (A-MSE: 0.40339) avg lploss: 0.00000
==> test epoch 840 avg loss: 0.47212 (A-MSE: 0.42808) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 5 out of 50
train epoch 841 avg loss: 0.22317 (A-MSE: 0.19924) avg lploss: 0.00000
train epoch 842 avg loss: 0.28648 (A-MSE: 0.24888) avg lploss: 0.00000
train epoch 843 avg loss: 0.29339 (A-MSE: 0.26065) avg lploss: 0.00000
train epoch 844 avg loss: 0.25259 (A-MSE: 0.22216) avg lploss: 0.00000
train epoch 845 avg loss: 0.26171 (A-MSE: 0.22842) avg lploss: 0.00000
==> val epoch 845 avg loss: 0.57883 (A-MSE: 0.51965) avg lploss: 0.00000
==> test epoch 845 avg loss: 0.59308 (A-MSE: 0.56045) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 6 out of 50
train epoch 846 avg loss: 0.25055 (A-MSE: 0.22319) avg lploss: 0.00000
train epoch 847 avg loss: 0.20744 (A-MSE: 0.18258) avg lploss: 0.00000
train epoch 848 avg loss: 0.20446 (A-MSE: 0.17990) avg lploss: 0.00000
train epoch 849 avg loss: 0.19633 (A-MSE: 0.17261) avg lploss: 0.00000
train epoch 850 avg loss: 0.17539 (A-MSE: 0.15717) avg lploss: 0.00000
==> val epoch 850 avg loss: 0.47324 (A-MSE: 0.41078) avg lploss: 0.00000
==> test epoch 850 avg loss: 0.46466 (A-MSE: 0.42174) avg lploss: 0.00000
*** Best Val Loss: 0.41396 	 Best Test Loss: 0.45289 	 Best epoch 815
EarlyStopping counter: 7 out of 50
train epoch 851 avg loss: 0.17598 (A-MSE: 0.15462) avg lploss: 0.00000
train epoch 852 avg loss: 0.18086 (A-MSE: 0.16036) avg lploss: 0.00000
train epoch 853 avg loss: 0.17319 (A-MSE: 0.15252) avg lploss: 0.00000
train epoch 854 avg loss: 0.18730 (A-MSE: 0.16708) avg lploss: 0.00000
train epoch 855 avg loss: 0.19459 (A-MSE: 0.17098) avg lploss: 0.00000
==> val epoch 855 avg loss: 0.38864 (A-MSE: 0.34314) avg lploss: 0.00000
==> test epoch 855 avg loss: 0.41166 (A-MSE: 0.38176) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
Validation loss decreased (0.413964 --> 0.388640).  Saving model ...
train epoch 856 avg loss: 0.21784 (A-MSE: 0.19345) avg lploss: 0.00000
train epoch 857 avg loss: 0.18649 (A-MSE: 0.16369) avg lploss: 0.00000
train epoch 858 avg loss: 0.22262 (A-MSE: 0.19353) avg lploss: 0.00000
train epoch 859 avg loss: 0.20808 (A-MSE: 0.18431) avg lploss: 0.00000
train epoch 860 avg loss: 0.19566 (A-MSE: 0.17342) avg lploss: 0.00000
==> val epoch 860 avg loss: 0.42582 (A-MSE: 0.36123) avg lploss: 0.00000
==> test epoch 860 avg loss: 0.40558 (A-MSE: 0.36450) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
EarlyStopping counter: 1 out of 50
train epoch 861 avg loss: 0.18935 (A-MSE: 0.16763) avg lploss: 0.00000
train epoch 862 avg loss: 0.18437 (A-MSE: 0.16275) avg lploss: 0.00000
train epoch 863 avg loss: 0.19418 (A-MSE: 0.17184) avg lploss: 0.00000
train epoch 864 avg loss: 0.24589 (A-MSE: 0.21663) avg lploss: 0.00000
train epoch 865 avg loss: 0.24624 (A-MSE: 0.21984) avg lploss: 0.00000
==> val epoch 865 avg loss: 0.49146 (A-MSE: 0.44117) avg lploss: 0.00000
==> test epoch 865 avg loss: 0.47778 (A-MSE: 0.44644) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
EarlyStopping counter: 2 out of 50
train epoch 866 avg loss: 0.20914 (A-MSE: 0.18480) avg lploss: 0.00000
train epoch 867 avg loss: 0.20358 (A-MSE: 0.17892) avg lploss: 0.00000
train epoch 868 avg loss: 0.19395 (A-MSE: 0.17167) avg lploss: 0.00000
train epoch 869 avg loss: 0.19850 (A-MSE: 0.17454) avg lploss: 0.00000
train epoch 870 avg loss: 0.19495 (A-MSE: 0.17266) avg lploss: 0.00000
==> val epoch 870 avg loss: 0.49783 (A-MSE: 0.44198) avg lploss: 0.00000
==> test epoch 870 avg loss: 0.53053 (A-MSE: 0.48635) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
EarlyStopping counter: 3 out of 50
train epoch 871 avg loss: 0.23097 (A-MSE: 0.20614) avg lploss: 0.00000
train epoch 872 avg loss: 0.21613 (A-MSE: 0.19388) avg lploss: 0.00000
train epoch 873 avg loss: 0.20489 (A-MSE: 0.18109) avg lploss: 0.00000
train epoch 874 avg loss: 0.19903 (A-MSE: 0.17625) avg lploss: 0.00000
train epoch 875 avg loss: 0.17270 (A-MSE: 0.15247) avg lploss: 0.00000
==> val epoch 875 avg loss: 0.38865 (A-MSE: 0.33498) avg lploss: 0.00000
==> test epoch 875 avg loss: 0.43482 (A-MSE: 0.39479) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
EarlyStopping counter: 4 out of 50
train epoch 876 avg loss: 0.18008 (A-MSE: 0.15780) avg lploss: 0.00000
train epoch 877 avg loss: 0.20821 (A-MSE: 0.18340) avg lploss: 0.00000
train epoch 878 avg loss: 0.18007 (A-MSE: 0.15806) avg lploss: 0.00000
train epoch 879 avg loss: 0.16497 (A-MSE: 0.14491) avg lploss: 0.00000
train epoch 880 avg loss: 0.18059 (A-MSE: 0.15975) avg lploss: 0.00000
==> val epoch 880 avg loss: 0.39409 (A-MSE: 0.34310) avg lploss: 0.00000
==> test epoch 880 avg loss: 0.42397 (A-MSE: 0.38586) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
EarlyStopping counter: 5 out of 50
train epoch 881 avg loss: 0.18938 (A-MSE: 0.16678) avg lploss: 0.00000
train epoch 882 avg loss: 0.17906 (A-MSE: 0.15723) avg lploss: 0.00000
train epoch 883 avg loss: 0.18179 (A-MSE: 0.16074) avg lploss: 0.00000
train epoch 884 avg loss: 0.16668 (A-MSE: 0.14732) avg lploss: 0.00000
train epoch 885 avg loss: 0.18844 (A-MSE: 0.16441) avg lploss: 0.00000
==> val epoch 885 avg loss: 0.47142 (A-MSE: 0.40960) avg lploss: 0.00000
==> test epoch 885 avg loss: 0.49546 (A-MSE: 0.44648) avg lploss: 0.00000
*** Best Val Loss: 0.38864 	 Best Test Loss: 0.41166 	 Best epoch 855
EarlyStopping counter: 6 out of 50
train epoch 886 avg loss: 0.20570 (A-MSE: 0.18167) avg lploss: 0.00000
train epoch 887 avg loss: 0.19794 (A-MSE: 0.17400) avg lploss: 0.00000
train epoch 888 avg loss: 0.16224 (A-MSE: 0.14539) avg lploss: 0.00000
train epoch 889 avg loss: 0.16243 (A-MSE: 0.14285) avg lploss: 0.00000
train epoch 890 avg loss: 0.16665 (A-MSE: 0.14628) avg lploss: 0.00000
==> val epoch 890 avg loss: 0.38117 (A-MSE: 0.33779) avg lploss: 0.00000
==> test epoch 890 avg loss: 0.39697 (A-MSE: 0.36686) avg lploss: 0.00000
*** Best Val Loss: 0.38117 	 Best Test Loss: 0.39697 	 Best epoch 890
Validation loss decreased (0.388640 --> 0.381166).  Saving model ...
train epoch 891 avg loss: 0.18363 (A-MSE: 0.16289) avg lploss: 0.00000
train epoch 892 avg loss: 0.18214 (A-MSE: 0.16009) avg lploss: 0.00000
train epoch 893 avg loss: 0.17885 (A-MSE: 0.15730) avg lploss: 0.00000
train epoch 894 avg loss: 0.17606 (A-MSE: 0.15508) avg lploss: 0.00000
train epoch 895 avg loss: 0.16011 (A-MSE: 0.14167) avg lploss: 0.00000
==> val epoch 895 avg loss: 0.46041 (A-MSE: 0.40121) avg lploss: 0.00000
==> test epoch 895 avg loss: 0.46264 (A-MSE: 0.42255) avg lploss: 0.00000
*** Best Val Loss: 0.38117 	 Best Test Loss: 0.39697 	 Best epoch 890
EarlyStopping counter: 1 out of 50
train epoch 896 avg loss: 0.17661 (A-MSE: 0.15559) avg lploss: 0.00000
train epoch 897 avg loss: 0.16140 (A-MSE: 0.14433) avg lploss: 0.00000
train epoch 898 avg loss: 0.17922 (A-MSE: 0.15801) avg lploss: 0.00000
train epoch 899 avg loss: 0.17649 (A-MSE: 0.15618) avg lploss: 0.00000
train epoch 900 avg loss: 0.17568 (A-MSE: 0.15601) avg lploss: 0.00000
==> val epoch 900 avg loss: 0.41470 (A-MSE: 0.36575) avg lploss: 0.00000
==> test epoch 900 avg loss: 0.43305 (A-MSE: 0.39897) avg lploss: 0.00000
*** Best Val Loss: 0.38117 	 Best Test Loss: 0.39697 	 Best epoch 890
EarlyStopping counter: 2 out of 50
train epoch 901 avg loss: 0.17731 (A-MSE: 0.15726) avg lploss: 0.00000
train epoch 902 avg loss: 0.16927 (A-MSE: 0.14963) avg lploss: 0.00000
train epoch 903 avg loss: 0.16698 (A-MSE: 0.14609) avg lploss: 0.00000
train epoch 904 avg loss: 0.17830 (A-MSE: 0.15875) avg lploss: 0.00000
train epoch 905 avg loss: 0.17483 (A-MSE: 0.15483) avg lploss: 0.00000
==> val epoch 905 avg loss: 0.42715 (A-MSE: 0.37127) avg lploss: 0.00000
==> test epoch 905 avg loss: 0.43509 (A-MSE: 0.38867) avg lploss: 0.00000
*** Best Val Loss: 0.38117 	 Best Test Loss: 0.39697 	 Best epoch 890
EarlyStopping counter: 3 out of 50
train epoch 906 avg loss: 0.17265 (A-MSE: 0.15287) avg lploss: 0.00000
train epoch 907 avg loss: 0.20725 (A-MSE: 0.18285) avg lploss: 0.00000
train epoch 908 avg loss: 0.23590 (A-MSE: 0.20863) avg lploss: 0.00000
train epoch 909 avg loss: 0.19038 (A-MSE: 0.16808) avg lploss: 0.00000
train epoch 910 avg loss: 0.16312 (A-MSE: 0.14521) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.42944 (A-MSE: 0.38353) avg lploss: 0.00000
==> test epoch 910 avg loss: 0.46224 (A-MSE: 0.43038) avg lploss: 0.00000
*** Best Val Loss: 0.38117 	 Best Test Loss: 0.39697 	 Best epoch 890
EarlyStopping counter: 4 out of 50
train epoch 911 avg loss: 0.17949 (A-MSE: 0.15889) avg lploss: 0.00000
train epoch 912 avg loss: 0.17642 (A-MSE: 0.15674) avg lploss: 0.00000
train epoch 913 avg loss: 0.16660 (A-MSE: 0.14789) avg lploss: 0.00000
train epoch 914 avg loss: 0.16827 (A-MSE: 0.14801) avg lploss: 0.00000
train epoch 915 avg loss: 0.15694 (A-MSE: 0.13898) avg lploss: 0.00000
==> val epoch 915 avg loss: 0.36808 (A-MSE: 0.32529) avg lploss: 0.00000
==> test epoch 915 avg loss: 0.40725 (A-MSE: 0.37599) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
Validation loss decreased (0.381166 --> 0.368082).  Saving model ...
train epoch 916 avg loss: 0.18373 (A-MSE: 0.16232) avg lploss: 0.00000
train epoch 917 avg loss: 0.19233 (A-MSE: 0.16855) avg lploss: 0.00000
train epoch 918 avg loss: 0.19204 (A-MSE: 0.16983) avg lploss: 0.00000
train epoch 919 avg loss: 0.17781 (A-MSE: 0.15662) avg lploss: 0.00000
train epoch 920 avg loss: 0.15390 (A-MSE: 0.13552) avg lploss: 0.00000
==> val epoch 920 avg loss: 0.41159 (A-MSE: 0.36183) avg lploss: 0.00000
==> test epoch 920 avg loss: 0.43296 (A-MSE: 0.39245) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 1 out of 50
train epoch 921 avg loss: 0.16853 (A-MSE: 0.14806) avg lploss: 0.00000
train epoch 922 avg loss: 0.17138 (A-MSE: 0.15040) avg lploss: 0.00000
train epoch 923 avg loss: 0.17065 (A-MSE: 0.15148) avg lploss: 0.00000
train epoch 924 avg loss: 0.16005 (A-MSE: 0.14119) avg lploss: 0.00000
train epoch 925 avg loss: 0.14774 (A-MSE: 0.13034) avg lploss: 0.00000
==> val epoch 925 avg loss: 0.38159 (A-MSE: 0.33533) avg lploss: 0.00000
==> test epoch 925 avg loss: 0.41197 (A-MSE: 0.37341) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 2 out of 50
train epoch 926 avg loss: 0.14357 (A-MSE: 0.12745) avg lploss: 0.00000
train epoch 927 avg loss: 0.17029 (A-MSE: 0.15200) avg lploss: 0.00000
train epoch 928 avg loss: 0.18899 (A-MSE: 0.16563) avg lploss: 0.00000
train epoch 929 avg loss: 0.19227 (A-MSE: 0.16936) avg lploss: 0.00000
train epoch 930 avg loss: 0.22727 (A-MSE: 0.19973) avg lploss: 0.00000
==> val epoch 930 avg loss: 0.49004 (A-MSE: 0.42899) avg lploss: 0.00000
==> test epoch 930 avg loss: 0.50914 (A-MSE: 0.46784) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 3 out of 50
train epoch 931 avg loss: 0.23059 (A-MSE: 0.20194) avg lploss: 0.00000
train epoch 932 avg loss: 0.19270 (A-MSE: 0.17046) avg lploss: 0.00000
train epoch 933 avg loss: 0.17741 (A-MSE: 0.15546) avg lploss: 0.00000
train epoch 934 avg loss: 0.17368 (A-MSE: 0.15294) avg lploss: 0.00000
train epoch 935 avg loss: 0.17544 (A-MSE: 0.15559) avg lploss: 0.00000
==> val epoch 935 avg loss: 0.38193 (A-MSE: 0.33231) avg lploss: 0.00000
==> test epoch 935 avg loss: 0.41149 (A-MSE: 0.37381) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 4 out of 50
train epoch 936 avg loss: 0.15759 (A-MSE: 0.13917) avg lploss: 0.00000
train epoch 937 avg loss: 0.16742 (A-MSE: 0.15010) avg lploss: 0.00000
train epoch 938 avg loss: 0.18233 (A-MSE: 0.15928) avg lploss: 0.00000
train epoch 939 avg loss: 0.20344 (A-MSE: 0.18074) avg lploss: 0.00000
train epoch 940 avg loss: 0.17395 (A-MSE: 0.15445) avg lploss: 0.00000
==> val epoch 940 avg loss: 0.38604 (A-MSE: 0.34921) avg lploss: 0.00000
==> test epoch 940 avg loss: 0.42957 (A-MSE: 0.40591) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 5 out of 50
train epoch 941 avg loss: 0.16827 (A-MSE: 0.14996) avg lploss: 0.00000
train epoch 942 avg loss: 0.18916 (A-MSE: 0.16580) avg lploss: 0.00000
train epoch 943 avg loss: 0.21274 (A-MSE: 0.18805) avg lploss: 0.00000
train epoch 944 avg loss: 0.17553 (A-MSE: 0.15373) avg lploss: 0.00000
train epoch 945 avg loss: 0.16417 (A-MSE: 0.14505) avg lploss: 0.00000
==> val epoch 945 avg loss: 0.49922 (A-MSE: 0.43676) avg lploss: 0.00000
==> test epoch 945 avg loss: 0.45298 (A-MSE: 0.41249) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 6 out of 50
train epoch 946 avg loss: 0.16413 (A-MSE: 0.14378) avg lploss: 0.00000
train epoch 947 avg loss: 0.16377 (A-MSE: 0.14524) avg lploss: 0.00000
train epoch 948 avg loss: 0.15616 (A-MSE: 0.13932) avg lploss: 0.00000
train epoch 949 avg loss: 0.18135 (A-MSE: 0.16037) avg lploss: 0.00000
train epoch 950 avg loss: 0.17685 (A-MSE: 0.15725) avg lploss: 0.00000
==> val epoch 950 avg loss: 0.45522 (A-MSE: 0.39066) avg lploss: 0.00000
==> test epoch 950 avg loss: 0.47928 (A-MSE: 0.42893) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 7 out of 50
train epoch 951 avg loss: 0.18300 (A-MSE: 0.16025) avg lploss: 0.00000
train epoch 952 avg loss: 0.16273 (A-MSE: 0.14340) avg lploss: 0.00000
train epoch 953 avg loss: 0.16154 (A-MSE: 0.14391) avg lploss: 0.00000
train epoch 954 avg loss: 0.15863 (A-MSE: 0.13955) avg lploss: 0.00000
train epoch 955 avg loss: 0.15896 (A-MSE: 0.14085) avg lploss: 0.00000
==> val epoch 955 avg loss: 0.40082 (A-MSE: 0.35462) avg lploss: 0.00000
==> test epoch 955 avg loss: 0.43645 (A-MSE: 0.40272) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 8 out of 50
train epoch 956 avg loss: 0.16059 (A-MSE: 0.14279) avg lploss: 0.00000
train epoch 957 avg loss: 0.16843 (A-MSE: 0.14884) avg lploss: 0.00000
train epoch 958 avg loss: 0.14673 (A-MSE: 0.13097) avg lploss: 0.00000
train epoch 959 avg loss: 0.15166 (A-MSE: 0.13393) avg lploss: 0.00000
train epoch 960 avg loss: 0.16404 (A-MSE: 0.14534) avg lploss: 0.00000
==> val epoch 960 avg loss: 0.39842 (A-MSE: 0.35199) avg lploss: 0.00000
==> test epoch 960 avg loss: 0.44900 (A-MSE: 0.40776) avg lploss: 0.00000
*** Best Val Loss: 0.36808 	 Best Test Loss: 0.40725 	 Best epoch 915
EarlyStopping counter: 9 out of 50
train epoch 961 avg loss: 0.16248 (A-MSE: 0.14412) avg lploss: 0.00000
train epoch 962 avg loss: 0.14882 (A-MSE: 0.13111) avg lploss: 0.00000
train epoch 963 avg loss: 0.16322 (A-MSE: 0.14456) avg lploss: 0.00000
train epoch 964 avg loss: 0.16878 (A-MSE: 0.14839) avg lploss: 0.00000
train epoch 965 avg loss: 0.15339 (A-MSE: 0.13532) avg lploss: 0.00000
==> val epoch 965 avg loss: 0.36246 (A-MSE: 0.32219) avg lploss: 0.00000
==> test epoch 965 avg loss: 0.42288 (A-MSE: 0.38546) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
Validation loss decreased (0.368082 --> 0.362463).  Saving model ...
train epoch 966 avg loss: 0.19238 (A-MSE: 0.17111) avg lploss: 0.00000
train epoch 967 avg loss: 0.18046 (A-MSE: 0.15975) avg lploss: 0.00000
train epoch 968 avg loss: 0.16586 (A-MSE: 0.14675) avg lploss: 0.00000
train epoch 969 avg loss: 0.17408 (A-MSE: 0.15266) avg lploss: 0.00000
train epoch 970 avg loss: 0.18467 (A-MSE: 0.16370) avg lploss: 0.00000
==> val epoch 970 avg loss: 0.41856 (A-MSE: 0.38811) avg lploss: 0.00000
==> test epoch 970 avg loss: 0.43083 (A-MSE: 0.41011) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 1 out of 50
train epoch 971 avg loss: 0.18590 (A-MSE: 0.16425) avg lploss: 0.00000
train epoch 972 avg loss: 0.17633 (A-MSE: 0.15527) avg lploss: 0.00000
train epoch 973 avg loss: 0.19153 (A-MSE: 0.17086) avg lploss: 0.00000
train epoch 974 avg loss: 0.19690 (A-MSE: 0.17240) avg lploss: 0.00000
train epoch 975 avg loss: 0.15999 (A-MSE: 0.14154) avg lploss: 0.00000
==> val epoch 975 avg loss: 0.43019 (A-MSE: 0.36659) avg lploss: 0.00000
==> test epoch 975 avg loss: 0.45326 (A-MSE: 0.40665) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 2 out of 50
train epoch 976 avg loss: 0.17409 (A-MSE: 0.15349) avg lploss: 0.00000
train epoch 977 avg loss: 0.20764 (A-MSE: 0.18276) avg lploss: 0.00000
train epoch 978 avg loss: 0.22264 (A-MSE: 0.19616) avg lploss: 0.00000
train epoch 979 avg loss: 0.18365 (A-MSE: 0.16286) avg lploss: 0.00000
train epoch 980 avg loss: 0.15138 (A-MSE: 0.13213) avg lploss: 0.00000
==> val epoch 980 avg loss: 0.37448 (A-MSE: 0.32142) avg lploss: 0.00000
==> test epoch 980 avg loss: 0.40358 (A-MSE: 0.36425) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 3 out of 50
train epoch 981 avg loss: 0.14080 (A-MSE: 0.12382) avg lploss: 0.00000
train epoch 982 avg loss: 0.13600 (A-MSE: 0.12118) avg lploss: 0.00000
train epoch 983 avg loss: 0.15634 (A-MSE: 0.13875) avg lploss: 0.00000
train epoch 984 avg loss: 0.15289 (A-MSE: 0.13498) avg lploss: 0.00000
train epoch 985 avg loss: 0.14847 (A-MSE: 0.13137) avg lploss: 0.00000
==> val epoch 985 avg loss: 0.38895 (A-MSE: 0.34348) avg lploss: 0.00000
==> test epoch 985 avg loss: 0.39824 (A-MSE: 0.36470) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 4 out of 50
train epoch 986 avg loss: 0.16064 (A-MSE: 0.14202) avg lploss: 0.00000
train epoch 987 avg loss: 0.18410 (A-MSE: 0.16358) avg lploss: 0.00000
train epoch 988 avg loss: 0.18374 (A-MSE: 0.16210) avg lploss: 0.00000
train epoch 989 avg loss: 0.18234 (A-MSE: 0.16095) avg lploss: 0.00000
train epoch 990 avg loss: 0.16118 (A-MSE: 0.14278) avg lploss: 0.00000
==> val epoch 990 avg loss: 0.46829 (A-MSE: 0.42433) avg lploss: 0.00000
==> test epoch 990 avg loss: 0.45353 (A-MSE: 0.42604) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 5 out of 50
train epoch 991 avg loss: 0.16229 (A-MSE: 0.14424) avg lploss: 0.00000
train epoch 992 avg loss: 0.17393 (A-MSE: 0.15394) avg lploss: 0.00000
train epoch 993 avg loss: 0.18603 (A-MSE: 0.16477) avg lploss: 0.00000
train epoch 994 avg loss: 0.17153 (A-MSE: 0.15204) avg lploss: 0.00000
train epoch 995 avg loss: 0.17182 (A-MSE: 0.15214) avg lploss: 0.00000
==> val epoch 995 avg loss: 0.48698 (A-MSE: 0.43270) avg lploss: 0.00000
==> test epoch 995 avg loss: 0.48089 (A-MSE: 0.44473) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 6 out of 50
train epoch 996 avg loss: 0.17531 (A-MSE: 0.15395) avg lploss: 0.00000
train epoch 997 avg loss: 0.20541 (A-MSE: 0.18055) avg lploss: 0.00000
train epoch 998 avg loss: 0.16178 (A-MSE: 0.14289) avg lploss: 0.00000
train epoch 999 avg loss: 0.14413 (A-MSE: 0.12607) avg lploss: 0.00000
train epoch 1000 avg loss: 0.15239 (A-MSE: 0.13553) avg lploss: 0.00000
==> val epoch 1000 avg loss: 0.38897 (A-MSE: 0.34220) avg lploss: 0.00000
==> test epoch 1000 avg loss: 0.41940 (A-MSE: 0.38028) avg lploss: 0.00000
*** Best Val Loss: 0.36246 	 Best Test Loss: 0.42288 	 Best epoch 965
EarlyStopping counter: 7 out of 50
train epoch 1001 avg loss: 0.18730 (A-MSE: 0.16635) avg lploss: 0.00000
train epoch 1002 avg loss: 0.17478 (A-MSE: 0.15383) avg lploss: 0.00000
train epoch 1003 avg loss: 0.17869 (A-MSE: 0.15736) avg lploss: 0.00000
train epoch 1004 avg loss: 0.15882 (A-MSE: 0.14248) avg lploss: 0.00000
train epoch 1005 avg loss: 0.15817 (A-MSE: 0.13971) avg lploss: 0.00000
==> val epoch 1005 avg loss: 0.36123 (A-MSE: 0.31470) avg lploss: 0.00000
==> test epoch 1005 avg loss: 0.38947 (A-MSE: 0.34908) avg lploss: 0.00000
*** Best Val Loss: 0.36123 	 Best Test Loss: 0.38947 	 Best epoch 1005
Validation loss decreased (0.362463 --> 0.361227).  Saving model ...
train epoch 1006 avg loss: 0.14055 (A-MSE: 0.12455) avg lploss: 0.00000
train epoch 1007 avg loss: 0.13856 (A-MSE: 0.12224) avg lploss: 0.00000
train epoch 1008 avg loss: 0.12448 (A-MSE: 0.10990) avg lploss: 0.00000
train epoch 1009 avg loss: 0.14892 (A-MSE: 0.13268) avg lploss: 0.00000
train epoch 1010 avg loss: 0.15905 (A-MSE: 0.14100) avg lploss: 0.00000
==> val epoch 1010 avg loss: 0.39611 (A-MSE: 0.34243) avg lploss: 0.00000
==> test epoch 1010 avg loss: 0.42949 (A-MSE: 0.38803) avg lploss: 0.00000
*** Best Val Loss: 0.36123 	 Best Test Loss: 0.38947 	 Best epoch 1005
EarlyStopping counter: 1 out of 50
train epoch 1011 avg loss: 0.14074 (A-MSE: 0.12493) avg lploss: 0.00000
train epoch 1012 avg loss: 0.16043 (A-MSE: 0.14293) avg lploss: 0.00000
train epoch 1013 avg loss: 0.16003 (A-MSE: 0.14243) avg lploss: 0.00000
train epoch 1014 avg loss: 0.16177 (A-MSE: 0.14282) avg lploss: 0.00000
train epoch 1015 avg loss: 0.16811 (A-MSE: 0.14817) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.34874 (A-MSE: 0.31068) avg lploss: 0.00000
==> test epoch 1015 avg loss: 0.39886 (A-MSE: 0.36913) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
Validation loss decreased (0.361227 --> 0.348741).  Saving model ...
train epoch 1016 avg loss: 0.14048 (A-MSE: 0.12390) avg lploss: 0.00000
train epoch 1017 avg loss: 0.14664 (A-MSE: 0.12893) avg lploss: 0.00000
train epoch 1018 avg loss: 0.15294 (A-MSE: 0.13445) avg lploss: 0.00000
train epoch 1019 avg loss: 0.14694 (A-MSE: 0.13121) avg lploss: 0.00000
train epoch 1020 avg loss: 0.16318 (A-MSE: 0.14708) avg lploss: 0.00000
==> val epoch 1020 avg loss: 0.38886 (A-MSE: 0.34128) avg lploss: 0.00000
==> test epoch 1020 avg loss: 0.40531 (A-MSE: 0.36665) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 1 out of 50
train epoch 1021 avg loss: 0.18269 (A-MSE: 0.16206) avg lploss: 0.00000
train epoch 1022 avg loss: 0.17973 (A-MSE: 0.15964) avg lploss: 0.00000
train epoch 1023 avg loss: 0.15262 (A-MSE: 0.13316) avg lploss: 0.00000
train epoch 1024 avg loss: 0.14182 (A-MSE: 0.12488) avg lploss: 0.00000
train epoch 1025 avg loss: 0.14172 (A-MSE: 0.12470) avg lploss: 0.00000
==> val epoch 1025 avg loss: 0.38826 (A-MSE: 0.33265) avg lploss: 0.00000
==> test epoch 1025 avg loss: 0.40224 (A-MSE: 0.35961) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 2 out of 50
train epoch 1026 avg loss: 0.12519 (A-MSE: 0.11068) avg lploss: 0.00000
train epoch 1027 avg loss: 0.12092 (A-MSE: 0.10785) avg lploss: 0.00000
train epoch 1028 avg loss: 0.11758 (A-MSE: 0.10381) avg lploss: 0.00000
train epoch 1029 avg loss: 0.13512 (A-MSE: 0.11921) avg lploss: 0.00000
train epoch 1030 avg loss: 0.15425 (A-MSE: 0.13644) avg lploss: 0.00000
==> val epoch 1030 avg loss: 0.42557 (A-MSE: 0.37131) avg lploss: 0.00000
==> test epoch 1030 avg loss: 0.42714 (A-MSE: 0.38213) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 3 out of 50
train epoch 1031 avg loss: 0.14757 (A-MSE: 0.13128) avg lploss: 0.00000
train epoch 1032 avg loss: 0.17282 (A-MSE: 0.15271) avg lploss: 0.00000
train epoch 1033 avg loss: 0.14956 (A-MSE: 0.13307) avg lploss: 0.00000
train epoch 1034 avg loss: 0.15605 (A-MSE: 0.13858) avg lploss: 0.00000
train epoch 1035 avg loss: 0.14824 (A-MSE: 0.13053) avg lploss: 0.00000
==> val epoch 1035 avg loss: 0.37642 (A-MSE: 0.32721) avg lploss: 0.00000
==> test epoch 1035 avg loss: 0.40257 (A-MSE: 0.36366) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 4 out of 50
train epoch 1036 avg loss: 0.14089 (A-MSE: 0.12501) avg lploss: 0.00000
train epoch 1037 avg loss: 0.13152 (A-MSE: 0.11649) avg lploss: 0.00000
train epoch 1038 avg loss: 0.12839 (A-MSE: 0.11261) avg lploss: 0.00000
train epoch 1039 avg loss: 0.12811 (A-MSE: 0.11396) avg lploss: 0.00000
train epoch 1040 avg loss: 0.17035 (A-MSE: 0.15007) avg lploss: 0.00000
==> val epoch 1040 avg loss: 0.43916 (A-MSE: 0.36905) avg lploss: 0.00000
==> test epoch 1040 avg loss: 0.46006 (A-MSE: 0.40626) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 5 out of 50
train epoch 1041 avg loss: 0.15953 (A-MSE: 0.14073) avg lploss: 0.00000
train epoch 1042 avg loss: 0.13771 (A-MSE: 0.12210) avg lploss: 0.00000
train epoch 1043 avg loss: 0.13939 (A-MSE: 0.12397) avg lploss: 0.00000
train epoch 1044 avg loss: 0.14203 (A-MSE: 0.12557) avg lploss: 0.00000
train epoch 1045 avg loss: 0.14535 (A-MSE: 0.12862) avg lploss: 0.00000
==> val epoch 1045 avg loss: 0.39844 (A-MSE: 0.34481) avg lploss: 0.00000
==> test epoch 1045 avg loss: 0.42053 (A-MSE: 0.37679) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 6 out of 50
train epoch 1046 avg loss: 0.13576 (A-MSE: 0.11960) avg lploss: 0.00000
train epoch 1047 avg loss: 0.13659 (A-MSE: 0.12203) avg lploss: 0.00000
train epoch 1048 avg loss: 0.17209 (A-MSE: 0.15177) avg lploss: 0.00000
train epoch 1049 avg loss: 0.15525 (A-MSE: 0.13873) avg lploss: 0.00000
train epoch 1050 avg loss: 0.21089 (A-MSE: 0.18572) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.53660 (A-MSE: 0.47023) avg lploss: 0.00000
==> test epoch 1050 avg loss: 0.57260 (A-MSE: 0.51220) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 7 out of 50
train epoch 1051 avg loss: 0.22974 (A-MSE: 0.20496) avg lploss: 0.00000
train epoch 1052 avg loss: 0.20521 (A-MSE: 0.18164) avg lploss: 0.00000
train epoch 1053 avg loss: 0.16084 (A-MSE: 0.14144) avg lploss: 0.00000
train epoch 1054 avg loss: 0.13828 (A-MSE: 0.12286) avg lploss: 0.00000
train epoch 1055 avg loss: 0.13108 (A-MSE: 0.11633) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.37299 (A-MSE: 0.32734) avg lploss: 0.00000
==> test epoch 1055 avg loss: 0.39652 (A-MSE: 0.35986) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 8 out of 50
train epoch 1056 avg loss: 0.14038 (A-MSE: 0.12372) avg lploss: 0.00000
train epoch 1057 avg loss: 0.12495 (A-MSE: 0.11082) avg lploss: 0.00000
train epoch 1058 avg loss: 0.12860 (A-MSE: 0.11376) avg lploss: 0.00000
train epoch 1059 avg loss: 0.14652 (A-MSE: 0.12865) avg lploss: 0.00000
train epoch 1060 avg loss: 0.16402 (A-MSE: 0.14268) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.36665 (A-MSE: 0.32091) avg lploss: 0.00000
==> test epoch 1060 avg loss: 0.39155 (A-MSE: 0.35542) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 9 out of 50
train epoch 1061 avg loss: 0.14597 (A-MSE: 0.12924) avg lploss: 0.00000
train epoch 1062 avg loss: 0.12878 (A-MSE: 0.11502) avg lploss: 0.00000
train epoch 1063 avg loss: 0.11820 (A-MSE: 0.10484) avg lploss: 0.00000
train epoch 1064 avg loss: 0.12815 (A-MSE: 0.11231) avg lploss: 0.00000
train epoch 1065 avg loss: 0.11787 (A-MSE: 0.10525) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.35823 (A-MSE: 0.31996) avg lploss: 0.00000
==> test epoch 1065 avg loss: 0.38936 (A-MSE: 0.35908) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 10 out of 50
train epoch 1066 avg loss: 0.12569 (A-MSE: 0.11182) avg lploss: 0.00000
train epoch 1067 avg loss: 0.14328 (A-MSE: 0.12745) avg lploss: 0.00000
train epoch 1068 avg loss: 0.14062 (A-MSE: 0.12399) avg lploss: 0.00000
train epoch 1069 avg loss: 0.12712 (A-MSE: 0.11113) avg lploss: 0.00000
train epoch 1070 avg loss: 0.12814 (A-MSE: 0.11327) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.37647 (A-MSE: 0.32908) avg lploss: 0.00000
==> test epoch 1070 avg loss: 0.39877 (A-MSE: 0.35955) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 11 out of 50
train epoch 1071 avg loss: 0.13703 (A-MSE: 0.12092) avg lploss: 0.00000
train epoch 1072 avg loss: 0.15981 (A-MSE: 0.14157) avg lploss: 0.00000
train epoch 1073 avg loss: 0.12774 (A-MSE: 0.11252) avg lploss: 0.00000
train epoch 1074 avg loss: 0.13422 (A-MSE: 0.11822) avg lploss: 0.00000
train epoch 1075 avg loss: 0.13464 (A-MSE: 0.11855) avg lploss: 0.00000
==> val epoch 1075 avg loss: 0.40296 (A-MSE: 0.34310) avg lploss: 0.00000
==> test epoch 1075 avg loss: 0.41666 (A-MSE: 0.37051) avg lploss: 0.00000
*** Best Val Loss: 0.34874 	 Best Test Loss: 0.39886 	 Best epoch 1015
EarlyStopping counter: 12 out of 50
train epoch 1076 avg loss: 0.12547 (A-MSE: 0.11084) avg lploss: 0.00000
train epoch 1077 avg loss: 0.16141 (A-MSE: 0.14280) avg lploss: 0.00000
train epoch 1078 avg loss: 0.17669 (A-MSE: 0.15704) avg lploss: 0.00000
train epoch 1079 avg loss: 0.16460 (A-MSE: 0.14714) avg lploss: 0.00000
train epoch 1080 avg loss: 0.14484 (A-MSE: 0.12823) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.34615 (A-MSE: 0.30817) avg lploss: 0.00000
==> test epoch 1080 avg loss: 0.37016 (A-MSE: 0.33652) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.37016 	 Best epoch 1080
Validation loss decreased (0.348741 --> 0.346153).  Saving model ...
train epoch 1081 avg loss: 0.12507 (A-MSE: 0.11016) avg lploss: 0.00000
train epoch 1082 avg loss: 0.13190 (A-MSE: 0.11645) avg lploss: 0.00000
train epoch 1083 avg loss: 0.12954 (A-MSE: 0.11479) avg lploss: 0.00000
train epoch 1084 avg loss: 0.13266 (A-MSE: 0.11740) avg lploss: 0.00000
train epoch 1085 avg loss: 0.12994 (A-MSE: 0.11634) avg lploss: 0.00000
==> val epoch 1085 avg loss: 0.36562 (A-MSE: 0.32536) avg lploss: 0.00000
==> test epoch 1085 avg loss: 0.42873 (A-MSE: 0.39068) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.37016 	 Best epoch 1080
EarlyStopping counter: 1 out of 50
train epoch 1086 avg loss: 0.14008 (A-MSE: 0.12252) avg lploss: 0.00000
train epoch 1087 avg loss: 0.13398 (A-MSE: 0.11975) avg lploss: 0.00000
train epoch 1088 avg loss: 0.12014 (A-MSE: 0.10562) avg lploss: 0.00000
train epoch 1089 avg loss: 0.12203 (A-MSE: 0.10817) avg lploss: 0.00000
train epoch 1090 avg loss: 0.13093 (A-MSE: 0.11614) avg lploss: 0.00000
==> val epoch 1090 avg loss: 0.42506 (A-MSE: 0.36278) avg lploss: 0.00000
==> test epoch 1090 avg loss: 0.43293 (A-MSE: 0.38361) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.37016 	 Best epoch 1080
EarlyStopping counter: 2 out of 50
train epoch 1091 avg loss: 0.13621 (A-MSE: 0.12066) avg lploss: 0.00000
train epoch 1092 avg loss: 0.17206 (A-MSE: 0.15348) avg lploss: 0.00000
train epoch 1093 avg loss: 0.16858 (A-MSE: 0.15089) avg lploss: 0.00000
train epoch 1094 avg loss: 0.15594 (A-MSE: 0.13662) avg lploss: 0.00000
train epoch 1095 avg loss: 0.13557 (A-MSE: 0.12099) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.37838 (A-MSE: 0.32767) avg lploss: 0.00000
==> test epoch 1095 avg loss: 0.40329 (A-MSE: 0.36135) avg lploss: 0.00000
*** Best Val Loss: 0.34615 	 Best Test Loss: 0.37016 	 Best epoch 1080
EarlyStopping counter: 3 out of 50
train epoch 1096 avg loss: 0.13767 (A-MSE: 0.12168) avg lploss: 0.00000
train epoch 1097 avg loss: 0.14873 (A-MSE: 0.13120) avg lploss: 0.00000
train epoch 1098 avg loss: 0.14921 (A-MSE: 0.13197) avg lploss: 0.00000
train epoch 1099 avg loss: 0.14563 (A-MSE: 0.12888) avg lploss: 0.00000
train epoch 1100 avg loss: 0.12420 (A-MSE: 0.11038) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.34092 (A-MSE: 0.30069) avg lploss: 0.00000
==> test epoch 1100 avg loss: 0.37624 (A-MSE: 0.34057) avg lploss: 0.00000
*** Best Val Loss: 0.34092 	 Best Test Loss: 0.37624 	 Best epoch 1100
Validation loss decreased (0.346153 --> 0.340925).  Saving model ...
train epoch 1101 avg loss: 0.11720 (A-MSE: 0.10401) avg lploss: 0.00000
train epoch 1102 avg loss: 0.11321 (A-MSE: 0.10004) avg lploss: 0.00000
train epoch 1103 avg loss: 0.15016 (A-MSE: 0.13098) avg lploss: 0.00000
train epoch 1104 avg loss: 0.15419 (A-MSE: 0.13810) avg lploss: 0.00000
train epoch 1105 avg loss: 0.16234 (A-MSE: 0.14292) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.41412 (A-MSE: 0.36344) avg lploss: 0.00000
==> test epoch 1105 avg loss: 0.45702 (A-MSE: 0.41431) avg lploss: 0.00000
*** Best Val Loss: 0.34092 	 Best Test Loss: 0.37624 	 Best epoch 1100
EarlyStopping counter: 1 out of 50
train epoch 1106 avg loss: 0.14436 (A-MSE: 0.12872) avg lploss: 0.00000
train epoch 1107 avg loss: 0.13639 (A-MSE: 0.12167) avg lploss: 0.00000
train epoch 1108 avg loss: 0.11449 (A-MSE: 0.10183) avg lploss: 0.00000
train epoch 1109 avg loss: 0.12048 (A-MSE: 0.10644) avg lploss: 0.00000
train epoch 1110 avg loss: 0.14654 (A-MSE: 0.12904) avg lploss: 0.00000
==> val epoch 1110 avg loss: 0.44308 (A-MSE: 0.38728) avg lploss: 0.00000
==> test epoch 1110 avg loss: 0.43535 (A-MSE: 0.39309) avg lploss: 0.00000
*** Best Val Loss: 0.34092 	 Best Test Loss: 0.37624 	 Best epoch 1100
EarlyStopping counter: 2 out of 50
train epoch 1111 avg loss: 0.15253 (A-MSE: 0.13526) avg lploss: 0.00000
train epoch 1112 avg loss: 0.14137 (A-MSE: 0.12451) avg lploss: 0.00000
train epoch 1113 avg loss: 0.15022 (A-MSE: 0.13316) avg lploss: 0.00000
train epoch 1114 avg loss: 0.14579 (A-MSE: 0.12961) avg lploss: 0.00000
train epoch 1115 avg loss: 0.14475 (A-MSE: 0.12648) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.38213 (A-MSE: 0.34062) avg lploss: 0.00000
==> test epoch 1115 avg loss: 0.41828 (A-MSE: 0.37733) avg lploss: 0.00000
*** Best Val Loss: 0.34092 	 Best Test Loss: 0.37624 	 Best epoch 1100
EarlyStopping counter: 3 out of 50
train epoch 1116 avg loss: 0.13198 (A-MSE: 0.11648) avg lploss: 0.00000
train epoch 1117 avg loss: 0.12433 (A-MSE: 0.10975) avg lploss: 0.00000
train epoch 1118 avg loss: 0.15229 (A-MSE: 0.13566) avg lploss: 0.00000
train epoch 1119 avg loss: 0.14422 (A-MSE: 0.12697) avg lploss: 0.00000
train epoch 1120 avg loss: 0.13098 (A-MSE: 0.11635) avg lploss: 0.00000
==> val epoch 1120 avg loss: 0.33053 (A-MSE: 0.29492) avg lploss: 0.00000
==> test epoch 1120 avg loss: 0.36873 (A-MSE: 0.33723) avg lploss: 0.00000
*** Best Val Loss: 0.33053 	 Best Test Loss: 0.36873 	 Best epoch 1120
Validation loss decreased (0.340925 --> 0.330526).  Saving model ...
train epoch 1121 avg loss: 0.13018 (A-MSE: 0.11570) avg lploss: 0.00000
train epoch 1122 avg loss: 0.13464 (A-MSE: 0.11894) avg lploss: 0.00000
train epoch 1123 avg loss: 0.13758 (A-MSE: 0.12165) avg lploss: 0.00000
train epoch 1124 avg loss: 0.14169 (A-MSE: 0.12433) avg lploss: 0.00000
train epoch 1125 avg loss: 0.15524 (A-MSE: 0.13585) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.37752 (A-MSE: 0.33442) avg lploss: 0.00000
==> test epoch 1125 avg loss: 0.38775 (A-MSE: 0.35127) avg lploss: 0.00000
*** Best Val Loss: 0.33053 	 Best Test Loss: 0.36873 	 Best epoch 1120
EarlyStopping counter: 1 out of 50
train epoch 1126 avg loss: 0.14290 (A-MSE: 0.12724) avg lploss: 0.00000
train epoch 1127 avg loss: 0.11680 (A-MSE: 0.10308) avg lploss: 0.00000
train epoch 1128 avg loss: 0.12129 (A-MSE: 0.10724) avg lploss: 0.00000
train epoch 1129 avg loss: 0.16603 (A-MSE: 0.14913) avg lploss: 0.00000
train epoch 1130 avg loss: 0.15524 (A-MSE: 0.13683) avg lploss: 0.00000
==> val epoch 1130 avg loss: 0.34572 (A-MSE: 0.30042) avg lploss: 0.00000
==> test epoch 1130 avg loss: 0.40731 (A-MSE: 0.36869) avg lploss: 0.00000
*** Best Val Loss: 0.33053 	 Best Test Loss: 0.36873 	 Best epoch 1120
EarlyStopping counter: 2 out of 50
train epoch 1131 avg loss: 0.18243 (A-MSE: 0.16039) avg lploss: 0.00000
train epoch 1132 avg loss: 0.18438 (A-MSE: 0.16190) avg lploss: 0.00000
train epoch 1133 avg loss: 0.17031 (A-MSE: 0.15163) avg lploss: 0.00000
train epoch 1134 avg loss: 0.15604 (A-MSE: 0.13885) avg lploss: 0.00000
train epoch 1135 avg loss: 0.13836 (A-MSE: 0.12372) avg lploss: 0.00000
==> val epoch 1135 avg loss: 0.32694 (A-MSE: 0.28767) avg lploss: 0.00000
==> test epoch 1135 avg loss: 0.36657 (A-MSE: 0.33222) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
Validation loss decreased (0.330526 --> 0.326935).  Saving model ...
train epoch 1136 avg loss: 0.12691 (A-MSE: 0.11196) avg lploss: 0.00000
train epoch 1137 avg loss: 0.10623 (A-MSE: 0.09350) avg lploss: 0.00000
train epoch 1138 avg loss: 0.10871 (A-MSE: 0.09562) avg lploss: 0.00000
train epoch 1139 avg loss: 0.12352 (A-MSE: 0.10913) avg lploss: 0.00000
train epoch 1140 avg loss: 0.12954 (A-MSE: 0.11467) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.37243 (A-MSE: 0.33057) avg lploss: 0.00000
==> test epoch 1140 avg loss: 0.40263 (A-MSE: 0.37045) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 1 out of 50
train epoch 1141 avg loss: 0.12199 (A-MSE: 0.10772) avg lploss: 0.00000
train epoch 1142 avg loss: 0.10662 (A-MSE: 0.09450) avg lploss: 0.00000
train epoch 1143 avg loss: 0.16563 (A-MSE: 0.14581) avg lploss: 0.00000
train epoch 1144 avg loss: 0.16710 (A-MSE: 0.14804) avg lploss: 0.00000
train epoch 1145 avg loss: 0.15921 (A-MSE: 0.14230) avg lploss: 0.00000
==> val epoch 1145 avg loss: 0.38457 (A-MSE: 0.33781) avg lploss: 0.00000
==> test epoch 1145 avg loss: 0.45386 (A-MSE: 0.40772) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 2 out of 50
train epoch 1146 avg loss: 0.14578 (A-MSE: 0.12935) avg lploss: 0.00000
train epoch 1147 avg loss: 0.16131 (A-MSE: 0.14257) avg lploss: 0.00000
train epoch 1148 avg loss: 0.13374 (A-MSE: 0.11853) avg lploss: 0.00000
train epoch 1149 avg loss: 0.12881 (A-MSE: 0.11315) avg lploss: 0.00000
train epoch 1150 avg loss: 0.13421 (A-MSE: 0.11877) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.37990 (A-MSE: 0.32576) avg lploss: 0.00000
==> test epoch 1150 avg loss: 0.39323 (A-MSE: 0.35023) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 3 out of 50
train epoch 1151 avg loss: 0.12644 (A-MSE: 0.11187) avg lploss: 0.00000
train epoch 1152 avg loss: 0.12713 (A-MSE: 0.11070) avg lploss: 0.00000
train epoch 1153 avg loss: 0.12324 (A-MSE: 0.10883) avg lploss: 0.00000
train epoch 1154 avg loss: 0.13727 (A-MSE: 0.12029) avg lploss: 0.00000
train epoch 1155 avg loss: 0.14601 (A-MSE: 0.12883) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.46912 (A-MSE: 0.39051) avg lploss: 0.00000
==> test epoch 1155 avg loss: 0.46147 (A-MSE: 0.39870) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 4 out of 50
train epoch 1156 avg loss: 0.15861 (A-MSE: 0.13993) avg lploss: 0.00000
train epoch 1157 avg loss: 0.13320 (A-MSE: 0.11745) avg lploss: 0.00000
train epoch 1158 avg loss: 0.12346 (A-MSE: 0.11037) avg lploss: 0.00000
train epoch 1159 avg loss: 0.10816 (A-MSE: 0.09594) avg lploss: 0.00000
train epoch 1160 avg loss: 0.11690 (A-MSE: 0.10336) avg lploss: 0.00000
==> val epoch 1160 avg loss: 0.37001 (A-MSE: 0.32560) avg lploss: 0.00000
==> test epoch 1160 avg loss: 0.38636 (A-MSE: 0.35271) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 5 out of 50
train epoch 1161 avg loss: 0.12067 (A-MSE: 0.10667) avg lploss: 0.00000
train epoch 1162 avg loss: 0.12684 (A-MSE: 0.11251) avg lploss: 0.00000
train epoch 1163 avg loss: 0.12244 (A-MSE: 0.10825) avg lploss: 0.00000
train epoch 1164 avg loss: 0.11165 (A-MSE: 0.09919) avg lploss: 0.00000
train epoch 1165 avg loss: 0.12265 (A-MSE: 0.10777) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.44158 (A-MSE: 0.37798) avg lploss: 0.00000
==> test epoch 1165 avg loss: 0.43373 (A-MSE: 0.38448) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 6 out of 50
train epoch 1166 avg loss: 0.13399 (A-MSE: 0.11812) avg lploss: 0.00000
train epoch 1167 avg loss: 0.12437 (A-MSE: 0.10985) avg lploss: 0.00000
train epoch 1168 avg loss: 0.13774 (A-MSE: 0.12101) avg lploss: 0.00000
train epoch 1169 avg loss: 0.11828 (A-MSE: 0.10539) avg lploss: 0.00000
train epoch 1170 avg loss: 0.11761 (A-MSE: 0.10399) avg lploss: 0.00000
==> val epoch 1170 avg loss: 0.36821 (A-MSE: 0.32371) avg lploss: 0.00000
==> test epoch 1170 avg loss: 0.40411 (A-MSE: 0.36348) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 7 out of 50
train epoch 1171 avg loss: 0.11213 (A-MSE: 0.09973) avg lploss: 0.00000
train epoch 1172 avg loss: 0.11619 (A-MSE: 0.10256) avg lploss: 0.00000
train epoch 1173 avg loss: 0.10342 (A-MSE: 0.09180) avg lploss: 0.00000
train epoch 1174 avg loss: 0.10860 (A-MSE: 0.09712) avg lploss: 0.00000
train epoch 1175 avg loss: 0.15231 (A-MSE: 0.13541) avg lploss: 0.00000
==> val epoch 1175 avg loss: 0.49879 (A-MSE: 0.44448) avg lploss: 0.00000
==> test epoch 1175 avg loss: 0.51851 (A-MSE: 0.47709) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 8 out of 50
train epoch 1176 avg loss: 0.21932 (A-MSE: 0.19408) avg lploss: 0.00000
train epoch 1177 avg loss: 0.14727 (A-MSE: 0.12894) avg lploss: 0.00000
train epoch 1178 avg loss: 0.15825 (A-MSE: 0.13880) avg lploss: 0.00000
train epoch 1179 avg loss: 0.14388 (A-MSE: 0.12635) avg lploss: 0.00000
train epoch 1180 avg loss: 0.12871 (A-MSE: 0.11396) avg lploss: 0.00000
==> val epoch 1180 avg loss: 0.33910 (A-MSE: 0.30304) avg lploss: 0.00000
==> test epoch 1180 avg loss: 0.37756 (A-MSE: 0.34224) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 9 out of 50
train epoch 1181 avg loss: 0.11596 (A-MSE: 0.10221) avg lploss: 0.00000
train epoch 1182 avg loss: 0.11382 (A-MSE: 0.10077) avg lploss: 0.00000
train epoch 1183 avg loss: 0.11733 (A-MSE: 0.10299) avg lploss: 0.00000
train epoch 1184 avg loss: 0.13657 (A-MSE: 0.12074) avg lploss: 0.00000
train epoch 1185 avg loss: 0.11807 (A-MSE: 0.10502) avg lploss: 0.00000
==> val epoch 1185 avg loss: 0.45719 (A-MSE: 0.39109) avg lploss: 0.00000
==> test epoch 1185 avg loss: 0.43786 (A-MSE: 0.38393) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 10 out of 50
train epoch 1186 avg loss: 0.12226 (A-MSE: 0.10772) avg lploss: 0.00000
train epoch 1187 avg loss: 0.10763 (A-MSE: 0.09576) avg lploss: 0.00000
train epoch 1188 avg loss: 0.09996 (A-MSE: 0.08890) avg lploss: 0.00000
train epoch 1189 avg loss: 0.10675 (A-MSE: 0.09539) avg lploss: 0.00000
train epoch 1190 avg loss: 0.11048 (A-MSE: 0.09722) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.32757 (A-MSE: 0.29024) avg lploss: 0.00000
==> test epoch 1190 avg loss: 0.36226 (A-MSE: 0.32749) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 11 out of 50
train epoch 1191 avg loss: 0.10451 (A-MSE: 0.09162) avg lploss: 0.00000
train epoch 1192 avg loss: 0.10888 (A-MSE: 0.09556) avg lploss: 0.00000
train epoch 1193 avg loss: 0.10926 (A-MSE: 0.09681) avg lploss: 0.00000
train epoch 1194 avg loss: 0.09904 (A-MSE: 0.08835) avg lploss: 0.00000
train epoch 1195 avg loss: 0.11339 (A-MSE: 0.10018) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.42135 (A-MSE: 0.37092) avg lploss: 0.00000
==> test epoch 1195 avg loss: 0.43604 (A-MSE: 0.39185) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 12 out of 50
train epoch 1196 avg loss: 0.13456 (A-MSE: 0.11890) avg lploss: 0.00000
train epoch 1197 avg loss: 0.12094 (A-MSE: 0.10721) avg lploss: 0.00000
train epoch 1198 avg loss: 0.11136 (A-MSE: 0.09875) avg lploss: 0.00000
train epoch 1199 avg loss: 0.11625 (A-MSE: 0.10351) avg lploss: 0.00000
train epoch 1200 avg loss: 0.10227 (A-MSE: 0.09079) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.38224 (A-MSE: 0.34240) avg lploss: 0.00000
==> test epoch 1200 avg loss: 0.40385 (A-MSE: 0.36943) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 13 out of 50
train epoch 1201 avg loss: 0.11531 (A-MSE: 0.10133) avg lploss: 0.00000
train epoch 1202 avg loss: 0.12543 (A-MSE: 0.11138) avg lploss: 0.00000
train epoch 1203 avg loss: 0.11483 (A-MSE: 0.10177) avg lploss: 0.00000
train epoch 1204 avg loss: 0.10658 (A-MSE: 0.09356) avg lploss: 0.00000
train epoch 1205 avg loss: 0.11702 (A-MSE: 0.10245) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.38250 (A-MSE: 0.33148) avg lploss: 0.00000
==> test epoch 1205 avg loss: 0.38599 (A-MSE: 0.34465) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 14 out of 50
train epoch 1206 avg loss: 0.12043 (A-MSE: 0.10685) avg lploss: 0.00000
train epoch 1207 avg loss: 0.10360 (A-MSE: 0.09202) avg lploss: 0.00000
train epoch 1208 avg loss: 0.10243 (A-MSE: 0.09019) avg lploss: 0.00000
train epoch 1209 avg loss: 0.10119 (A-MSE: 0.08990) avg lploss: 0.00000
train epoch 1210 avg loss: 0.10731 (A-MSE: 0.09468) avg lploss: 0.00000
==> val epoch 1210 avg loss: 0.38653 (A-MSE: 0.34278) avg lploss: 0.00000
==> test epoch 1210 avg loss: 0.44107 (A-MSE: 0.39960) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 15 out of 50
train epoch 1211 avg loss: 0.11317 (A-MSE: 0.10064) avg lploss: 0.00000
train epoch 1212 avg loss: 0.10823 (A-MSE: 0.09635) avg lploss: 0.00000
train epoch 1213 avg loss: 0.10452 (A-MSE: 0.09276) avg lploss: 0.00000
train epoch 1214 avg loss: 0.11400 (A-MSE: 0.10046) avg lploss: 0.00000
train epoch 1215 avg loss: 0.11716 (A-MSE: 0.10333) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.40501 (A-MSE: 0.36402) avg lploss: 0.00000
==> test epoch 1215 avg loss: 0.40897 (A-MSE: 0.37509) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 16 out of 50
train epoch 1216 avg loss: 0.12998 (A-MSE: 0.11441) avg lploss: 0.00000
train epoch 1217 avg loss: 0.10562 (A-MSE: 0.09377) avg lploss: 0.00000
train epoch 1218 avg loss: 0.12845 (A-MSE: 0.11348) avg lploss: 0.00000
train epoch 1219 avg loss: 0.11304 (A-MSE: 0.10029) avg lploss: 0.00000
train epoch 1220 avg loss: 0.11031 (A-MSE: 0.09742) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.34173 (A-MSE: 0.30343) avg lploss: 0.00000
==> test epoch 1220 avg loss: 0.35327 (A-MSE: 0.32182) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 17 out of 50
train epoch 1221 avg loss: 0.08711 (A-MSE: 0.07743) avg lploss: 0.00000
train epoch 1222 avg loss: 0.09157 (A-MSE: 0.08140) avg lploss: 0.00000
train epoch 1223 avg loss: 0.11305 (A-MSE: 0.10007) avg lploss: 0.00000
train epoch 1224 avg loss: 0.11296 (A-MSE: 0.10079) avg lploss: 0.00000
train epoch 1225 avg loss: 0.10656 (A-MSE: 0.09483) avg lploss: 0.00000
==> val epoch 1225 avg loss: 0.35853 (A-MSE: 0.31157) avg lploss: 0.00000
==> test epoch 1225 avg loss: 0.40741 (A-MSE: 0.36331) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 18 out of 50
train epoch 1226 avg loss: 0.10340 (A-MSE: 0.09111) avg lploss: 0.00000
train epoch 1227 avg loss: 0.10630 (A-MSE: 0.09484) avg lploss: 0.00000
train epoch 1228 avg loss: 0.10328 (A-MSE: 0.09130) avg lploss: 0.00000
train epoch 1229 avg loss: 0.12009 (A-MSE: 0.10697) avg lploss: 0.00000
train epoch 1230 avg loss: 0.11363 (A-MSE: 0.10048) avg lploss: 0.00000
==> val epoch 1230 avg loss: 0.38645 (A-MSE: 0.33495) avg lploss: 0.00000
==> test epoch 1230 avg loss: 0.42069 (A-MSE: 0.37462) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 19 out of 50
train epoch 1231 avg loss: 0.13294 (A-MSE: 0.11548) avg lploss: 0.00000
train epoch 1232 avg loss: 0.12780 (A-MSE: 0.11166) avg lploss: 0.00000
train epoch 1233 avg loss: 0.12655 (A-MSE: 0.11332) avg lploss: 0.00000
train epoch 1234 avg loss: 0.13756 (A-MSE: 0.12237) avg lploss: 0.00000
train epoch 1235 avg loss: 0.12977 (A-MSE: 0.11366) avg lploss: 0.00000
==> val epoch 1235 avg loss: 0.34459 (A-MSE: 0.30156) avg lploss: 0.00000
==> test epoch 1235 avg loss: 0.38928 (A-MSE: 0.34782) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 20 out of 50
train epoch 1236 avg loss: 0.12476 (A-MSE: 0.10969) avg lploss: 0.00000
train epoch 1237 avg loss: 0.11989 (A-MSE: 0.10565) avg lploss: 0.00000
train epoch 1238 avg loss: 0.11787 (A-MSE: 0.10511) avg lploss: 0.00000
train epoch 1239 avg loss: 0.11967 (A-MSE: 0.10671) avg lploss: 0.00000
train epoch 1240 avg loss: 0.15128 (A-MSE: 0.13289) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.33609 (A-MSE: 0.29691) avg lploss: 0.00000
==> test epoch 1240 avg loss: 0.42390 (A-MSE: 0.37784) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 21 out of 50
train epoch 1241 avg loss: 0.12598 (A-MSE: 0.11174) avg lploss: 0.00000
train epoch 1242 avg loss: 0.09287 (A-MSE: 0.08223) avg lploss: 0.00000
train epoch 1243 avg loss: 0.09064 (A-MSE: 0.08039) avg lploss: 0.00000
train epoch 1244 avg loss: 0.10726 (A-MSE: 0.09485) avg lploss: 0.00000
train epoch 1245 avg loss: 0.10866 (A-MSE: 0.09538) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.34566 (A-MSE: 0.30463) avg lploss: 0.00000
==> test epoch 1245 avg loss: 0.40847 (A-MSE: 0.36557) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 22 out of 50
train epoch 1246 avg loss: 0.11669 (A-MSE: 0.10296) avg lploss: 0.00000
train epoch 1247 avg loss: 0.11507 (A-MSE: 0.10168) avg lploss: 0.00000
train epoch 1248 avg loss: 0.12630 (A-MSE: 0.11164) avg lploss: 0.00000
train epoch 1249 avg loss: 0.12341 (A-MSE: 0.10878) avg lploss: 0.00000
train epoch 1250 avg loss: 0.11578 (A-MSE: 0.10163) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.34906 (A-MSE: 0.30400) avg lploss: 0.00000
==> test epoch 1250 avg loss: 0.39261 (A-MSE: 0.35206) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 23 out of 50
train epoch 1251 avg loss: 0.10668 (A-MSE: 0.09368) avg lploss: 0.00000
train epoch 1252 avg loss: 0.10857 (A-MSE: 0.09689) avg lploss: 0.00000
train epoch 1253 avg loss: 0.12880 (A-MSE: 0.11549) avg lploss: 0.00000
train epoch 1254 avg loss: 0.13084 (A-MSE: 0.11572) avg lploss: 0.00000
train epoch 1255 avg loss: 0.12128 (A-MSE: 0.10614) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.37389 (A-MSE: 0.32980) avg lploss: 0.00000
==> test epoch 1255 avg loss: 0.42061 (A-MSE: 0.38391) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 24 out of 50
train epoch 1256 avg loss: 0.12817 (A-MSE: 0.11420) avg lploss: 0.00000
train epoch 1257 avg loss: 0.12957 (A-MSE: 0.11391) avg lploss: 0.00000
train epoch 1258 avg loss: 0.11196 (A-MSE: 0.09787) avg lploss: 0.00000
train epoch 1259 avg loss: 0.12266 (A-MSE: 0.10815) avg lploss: 0.00000
train epoch 1260 avg loss: 0.11103 (A-MSE: 0.09771) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.35119 (A-MSE: 0.30947) avg lploss: 0.00000
==> test epoch 1260 avg loss: 0.38471 (A-MSE: 0.35144) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 25 out of 50
train epoch 1261 avg loss: 0.10959 (A-MSE: 0.09757) avg lploss: 0.00000
train epoch 1262 avg loss: 0.10080 (A-MSE: 0.08849) avg lploss: 0.00000
train epoch 1263 avg loss: 0.08955 (A-MSE: 0.07931) avg lploss: 0.00000
train epoch 1264 avg loss: 0.09308 (A-MSE: 0.08213) avg lploss: 0.00000
train epoch 1265 avg loss: 0.09561 (A-MSE: 0.08446) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.35207 (A-MSE: 0.30797) avg lploss: 0.00000
==> test epoch 1265 avg loss: 0.37548 (A-MSE: 0.33839) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 26 out of 50
train epoch 1266 avg loss: 0.10333 (A-MSE: 0.09129) avg lploss: 0.00000
train epoch 1267 avg loss: 0.10235 (A-MSE: 0.09068) avg lploss: 0.00000
train epoch 1268 avg loss: 0.11359 (A-MSE: 0.10027) avg lploss: 0.00000
train epoch 1269 avg loss: 0.11064 (A-MSE: 0.09832) avg lploss: 0.00000
train epoch 1270 avg loss: 0.12263 (A-MSE: 0.10778) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.45430 (A-MSE: 0.41119) avg lploss: 0.00000
==> test epoch 1270 avg loss: 0.47528 (A-MSE: 0.43484) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 27 out of 50
train epoch 1271 avg loss: 0.10172 (A-MSE: 0.09011) avg lploss: 0.00000
train epoch 1272 avg loss: 0.10618 (A-MSE: 0.09384) avg lploss: 0.00000
train epoch 1273 avg loss: 0.10757 (A-MSE: 0.09610) avg lploss: 0.00000
train epoch 1274 avg loss: 0.10010 (A-MSE: 0.08841) avg lploss: 0.00000
train epoch 1275 avg loss: 0.09266 (A-MSE: 0.08136) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.35263 (A-MSE: 0.30721) avg lploss: 0.00000
==> test epoch 1275 avg loss: 0.38580 (A-MSE: 0.34659) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 28 out of 50
train epoch 1276 avg loss: 0.10559 (A-MSE: 0.09440) avg lploss: 0.00000
train epoch 1277 avg loss: 0.12609 (A-MSE: 0.11074) avg lploss: 0.00000
train epoch 1278 avg loss: 0.12511 (A-MSE: 0.11069) avg lploss: 0.00000
train epoch 1279 avg loss: 0.12716 (A-MSE: 0.11345) avg lploss: 0.00000
train epoch 1280 avg loss: 0.13578 (A-MSE: 0.11884) avg lploss: 0.00000
==> val epoch 1280 avg loss: 0.38910 (A-MSE: 0.33807) avg lploss: 0.00000
==> test epoch 1280 avg loss: 0.41286 (A-MSE: 0.37256) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 29 out of 50
train epoch 1281 avg loss: 0.13931 (A-MSE: 0.12077) avg lploss: 0.00000
train epoch 1282 avg loss: 0.13097 (A-MSE: 0.11716) avg lploss: 0.00000
train epoch 1283 avg loss: 0.10444 (A-MSE: 0.09200) avg lploss: 0.00000
train epoch 1284 avg loss: 0.09196 (A-MSE: 0.08145) avg lploss: 0.00000
train epoch 1285 avg loss: 0.09448 (A-MSE: 0.08267) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.38096 (A-MSE: 0.34009) avg lploss: 0.00000
==> test epoch 1285 avg loss: 0.41195 (A-MSE: 0.37349) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 30 out of 50
train epoch 1286 avg loss: 0.10121 (A-MSE: 0.08953) avg lploss: 0.00000
train epoch 1287 avg loss: 0.10130 (A-MSE: 0.08835) avg lploss: 0.00000
train epoch 1288 avg loss: 0.10191 (A-MSE: 0.09070) avg lploss: 0.00000
train epoch 1289 avg loss: 0.10444 (A-MSE: 0.09317) avg lploss: 0.00000
train epoch 1290 avg loss: 0.10218 (A-MSE: 0.08889) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.39587 (A-MSE: 0.34750) avg lploss: 0.00000
==> test epoch 1290 avg loss: 0.41323 (A-MSE: 0.37137) avg lploss: 0.00000
*** Best Val Loss: 0.32694 	 Best Test Loss: 0.36657 	 Best epoch 1135
EarlyStopping counter: 31 out of 50
train epoch 1291 avg loss: 0.13003 (A-MSE: 0.11369) avg lploss: 0.00000
train epoch 1292 avg loss: 0.11388 (A-MSE: 0.10056) avg lploss: 0.00000
train epoch 1293 avg loss: 0.11514 (A-MSE: 0.10261) avg lploss: 0.00000
train epoch 1294 avg loss: 0.10718 (A-MSE: 0.09543) avg lploss: 0.00000
train epoch 1295 avg loss: 0.09504 (A-MSE: 0.08421) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.32572 (A-MSE: 0.29001) avg lploss: 0.00000
==> test epoch 1295 avg loss: 0.34904 (A-MSE: 0.31554) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
Validation loss decreased (0.326935 --> 0.325724).  Saving model ...
train epoch 1296 avg loss: 0.10190 (A-MSE: 0.08982) avg lploss: 0.00000
train epoch 1297 avg loss: 0.09359 (A-MSE: 0.08259) avg lploss: 0.00000
train epoch 1298 avg loss: 0.10293 (A-MSE: 0.09007) avg lploss: 0.00000
train epoch 1299 avg loss: 0.13122 (A-MSE: 0.11674) avg lploss: 0.00000
train epoch 1300 avg loss: 0.11791 (A-MSE: 0.10467) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.33935 (A-MSE: 0.30022) avg lploss: 0.00000
==> test epoch 1300 avg loss: 0.38358 (A-MSE: 0.34389) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
EarlyStopping counter: 1 out of 50
train epoch 1301 avg loss: 0.10809 (A-MSE: 0.09659) avg lploss: 0.00000
train epoch 1302 avg loss: 0.09492 (A-MSE: 0.08365) avg lploss: 0.00000
train epoch 1303 avg loss: 0.10294 (A-MSE: 0.09196) avg lploss: 0.00000
train epoch 1304 avg loss: 0.12206 (A-MSE: 0.10732) avg lploss: 0.00000
train epoch 1305 avg loss: 0.11668 (A-MSE: 0.10427) avg lploss: 0.00000
==> val epoch 1305 avg loss: 0.41473 (A-MSE: 0.36070) avg lploss: 0.00000
==> test epoch 1305 avg loss: 0.47342 (A-MSE: 0.42092) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
EarlyStopping counter: 2 out of 50
train epoch 1306 avg loss: 0.10706 (A-MSE: 0.09371) avg lploss: 0.00000
train epoch 1307 avg loss: 0.09757 (A-MSE: 0.08619) avg lploss: 0.00000
train epoch 1308 avg loss: 0.08970 (A-MSE: 0.07871) avg lploss: 0.00000
train epoch 1309 avg loss: 0.09758 (A-MSE: 0.08696) avg lploss: 0.00000
train epoch 1310 avg loss: 0.09739 (A-MSE: 0.08582) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.39891 (A-MSE: 0.35143) avg lploss: 0.00000
==> test epoch 1310 avg loss: 0.43390 (A-MSE: 0.39005) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
EarlyStopping counter: 3 out of 50
train epoch 1311 avg loss: 0.11168 (A-MSE: 0.09883) avg lploss: 0.00000
train epoch 1312 avg loss: 0.11908 (A-MSE: 0.10638) avg lploss: 0.00000
train epoch 1313 avg loss: 0.11553 (A-MSE: 0.10315) avg lploss: 0.00000
train epoch 1314 avg loss: 0.11088 (A-MSE: 0.09704) avg lploss: 0.00000
train epoch 1315 avg loss: 0.10575 (A-MSE: 0.09424) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.34401 (A-MSE: 0.30367) avg lploss: 0.00000
==> test epoch 1315 avg loss: 0.38684 (A-MSE: 0.34341) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
EarlyStopping counter: 4 out of 50
train epoch 1316 avg loss: 0.10796 (A-MSE: 0.09511) avg lploss: 0.00000
train epoch 1317 avg loss: 0.09490 (A-MSE: 0.08430) avg lploss: 0.00000
train epoch 1318 avg loss: 0.10738 (A-MSE: 0.09596) avg lploss: 0.00000
train epoch 1319 avg loss: 0.11742 (A-MSE: 0.10286) avg lploss: 0.00000
train epoch 1320 avg loss: 0.09704 (A-MSE: 0.08586) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.39704 (A-MSE: 0.34352) avg lploss: 0.00000
==> test epoch 1320 avg loss: 0.41609 (A-MSE: 0.37257) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
EarlyStopping counter: 5 out of 50
train epoch 1321 avg loss: 0.09027 (A-MSE: 0.07969) avg lploss: 0.00000
train epoch 1322 avg loss: 0.09637 (A-MSE: 0.08421) avg lploss: 0.00000
train epoch 1323 avg loss: 0.10803 (A-MSE: 0.09458) avg lploss: 0.00000
train epoch 1324 avg loss: 0.12534 (A-MSE: 0.11223) avg lploss: 0.00000
train epoch 1325 avg loss: 0.11703 (A-MSE: 0.10421) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.36019 (A-MSE: 0.31805) avg lploss: 0.00000
==> test epoch 1325 avg loss: 0.38980 (A-MSE: 0.35272) avg lploss: 0.00000
*** Best Val Loss: 0.32572 	 Best Test Loss: 0.34904 	 Best epoch 1295
EarlyStopping counter: 6 out of 50
train epoch 1326 avg loss: 0.12084 (A-MSE: 0.10687) avg lploss: 0.00000
train epoch 1327 avg loss: 0.10454 (A-MSE: 0.09163) avg lploss: 0.00000
train epoch 1328 avg loss: 0.10060 (A-MSE: 0.08808) avg lploss: 0.00000
train epoch 1329 avg loss: 0.08760 (A-MSE: 0.07737) avg lploss: 0.00000
train epoch 1330 avg loss: 0.08883 (A-MSE: 0.07802) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.31161 (A-MSE: 0.27528) avg lploss: 0.00000
==> test epoch 1330 avg loss: 0.39037 (A-MSE: 0.35146) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
Validation loss decreased (0.325724 --> 0.311608).  Saving model ...
train epoch 1331 avg loss: 0.08551 (A-MSE: 0.07517) avg lploss: 0.00000
train epoch 1332 avg loss: 0.08187 (A-MSE: 0.07218) avg lploss: 0.00000
train epoch 1333 avg loss: 0.09181 (A-MSE: 0.08118) avg lploss: 0.00000
train epoch 1334 avg loss: 0.07781 (A-MSE: 0.06881) avg lploss: 0.00000
train epoch 1335 avg loss: 0.08534 (A-MSE: 0.07591) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.37569 (A-MSE: 0.33288) avg lploss: 0.00000
==> test epoch 1335 avg loss: 0.42346 (A-MSE: 0.38166) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 1 out of 50
train epoch 1336 avg loss: 0.08222 (A-MSE: 0.07249) avg lploss: 0.00000
train epoch 1337 avg loss: 0.07950 (A-MSE: 0.07065) avg lploss: 0.00000
train epoch 1338 avg loss: 0.08218 (A-MSE: 0.07212) avg lploss: 0.00000
train epoch 1339 avg loss: 0.08368 (A-MSE: 0.07426) avg lploss: 0.00000
train epoch 1340 avg loss: 0.08723 (A-MSE: 0.07760) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.38474 (A-MSE: 0.33744) avg lploss: 0.00000
==> test epoch 1340 avg loss: 0.39803 (A-MSE: 0.35527) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 2 out of 50
train epoch 1341 avg loss: 0.09678 (A-MSE: 0.08581) avg lploss: 0.00000
train epoch 1342 avg loss: 0.09093 (A-MSE: 0.07918) avg lploss: 0.00000
train epoch 1343 avg loss: 0.08444 (A-MSE: 0.07457) avg lploss: 0.00000
train epoch 1344 avg loss: 0.08670 (A-MSE: 0.07657) avg lploss: 0.00000
train epoch 1345 avg loss: 0.09885 (A-MSE: 0.08796) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.41703 (A-MSE: 0.37119) avg lploss: 0.00000
==> test epoch 1345 avg loss: 0.45853 (A-MSE: 0.41397) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 3 out of 50
train epoch 1346 avg loss: 0.09805 (A-MSE: 0.08797) avg lploss: 0.00000
train epoch 1347 avg loss: 0.08429 (A-MSE: 0.07496) avg lploss: 0.00000
train epoch 1348 avg loss: 0.09474 (A-MSE: 0.08352) avg lploss: 0.00000
train epoch 1349 avg loss: 0.10449 (A-MSE: 0.09271) avg lploss: 0.00000
train epoch 1350 avg loss: 0.11719 (A-MSE: 0.10183) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.36904 (A-MSE: 0.33243) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.39900 (A-MSE: 0.36334) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 4 out of 50
train epoch 1351 avg loss: 0.10571 (A-MSE: 0.09448) avg lploss: 0.00000
train epoch 1352 avg loss: 0.11485 (A-MSE: 0.10119) avg lploss: 0.00000
train epoch 1353 avg loss: 0.11552 (A-MSE: 0.10192) avg lploss: 0.00000
train epoch 1354 avg loss: 0.08953 (A-MSE: 0.07956) avg lploss: 0.00000
train epoch 1355 avg loss: 0.08326 (A-MSE: 0.07319) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.35213 (A-MSE: 0.31711) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.39030 (A-MSE: 0.35653) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 5 out of 50
train epoch 1356 avg loss: 0.07855 (A-MSE: 0.06926) avg lploss: 0.00000
train epoch 1357 avg loss: 0.08592 (A-MSE: 0.07584) avg lploss: 0.00000
train epoch 1358 avg loss: 0.08054 (A-MSE: 0.07095) avg lploss: 0.00000
train epoch 1359 avg loss: 0.08655 (A-MSE: 0.07696) avg lploss: 0.00000
train epoch 1360 avg loss: 0.09517 (A-MSE: 0.08392) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.38044 (A-MSE: 0.33147) avg lploss: 0.00000
==> test epoch 1360 avg loss: 0.42396 (A-MSE: 0.38082) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 6 out of 50
train epoch 1361 avg loss: 0.10077 (A-MSE: 0.08979) avg lploss: 0.00000
train epoch 1362 avg loss: 0.09053 (A-MSE: 0.08074) avg lploss: 0.00000
train epoch 1363 avg loss: 0.10403 (A-MSE: 0.09149) avg lploss: 0.00000
train epoch 1364 avg loss: 0.11175 (A-MSE: 0.09886) avg lploss: 0.00000
train epoch 1365 avg loss: 0.11983 (A-MSE: 0.10447) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.41779 (A-MSE: 0.37321) avg lploss: 0.00000
==> test epoch 1365 avg loss: 0.44401 (A-MSE: 0.40858) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 7 out of 50
train epoch 1366 avg loss: 0.10224 (A-MSE: 0.09170) avg lploss: 0.00000
train epoch 1367 avg loss: 0.11027 (A-MSE: 0.09720) avg lploss: 0.00000
train epoch 1368 avg loss: 0.09782 (A-MSE: 0.08654) avg lploss: 0.00000
train epoch 1369 avg loss: 0.09294 (A-MSE: 0.08147) avg lploss: 0.00000
train epoch 1370 avg loss: 0.08890 (A-MSE: 0.07855) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.34874 (A-MSE: 0.31353) avg lploss: 0.00000
==> test epoch 1370 avg loss: 0.37728 (A-MSE: 0.34155) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 8 out of 50
train epoch 1371 avg loss: 0.08048 (A-MSE: 0.07065) avg lploss: 0.00000
train epoch 1372 avg loss: 0.09185 (A-MSE: 0.08124) avg lploss: 0.00000
train epoch 1373 avg loss: 0.09378 (A-MSE: 0.08276) avg lploss: 0.00000
train epoch 1374 avg loss: 0.09823 (A-MSE: 0.08736) avg lploss: 0.00000
train epoch 1375 avg loss: 0.08871 (A-MSE: 0.07882) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.37578 (A-MSE: 0.32720) avg lploss: 0.00000
==> test epoch 1375 avg loss: 0.40704 (A-MSE: 0.36370) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 9 out of 50
train epoch 1376 avg loss: 0.07068 (A-MSE: 0.06217) avg lploss: 0.00000
train epoch 1377 avg loss: 0.07687 (A-MSE: 0.06827) avg lploss: 0.00000
train epoch 1378 avg loss: 0.09891 (A-MSE: 0.08755) avg lploss: 0.00000
train epoch 1379 avg loss: 0.14358 (A-MSE: 0.12501) avg lploss: 0.00000
train epoch 1380 avg loss: 0.13906 (A-MSE: 0.12537) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.37602 (A-MSE: 0.34000) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.42756 (A-MSE: 0.38923) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 10 out of 50
train epoch 1381 avg loss: 0.12445 (A-MSE: 0.11009) avg lploss: 0.00000
train epoch 1382 avg loss: 0.09247 (A-MSE: 0.08191) avg lploss: 0.00000
train epoch 1383 avg loss: 0.08826 (A-MSE: 0.07762) avg lploss: 0.00000
train epoch 1384 avg loss: 0.09143 (A-MSE: 0.08067) avg lploss: 0.00000
train epoch 1385 avg loss: 0.09134 (A-MSE: 0.07923) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.38651 (A-MSE: 0.34279) avg lploss: 0.00000
==> test epoch 1385 avg loss: 0.42243 (A-MSE: 0.38165) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 11 out of 50
train epoch 1386 avg loss: 0.07825 (A-MSE: 0.06864) avg lploss: 0.00000
train epoch 1387 avg loss: 0.07985 (A-MSE: 0.07095) avg lploss: 0.00000
train epoch 1388 avg loss: 0.07792 (A-MSE: 0.06889) avg lploss: 0.00000
train epoch 1389 avg loss: 0.08202 (A-MSE: 0.07255) avg lploss: 0.00000
train epoch 1390 avg loss: 0.07734 (A-MSE: 0.06839) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.37062 (A-MSE: 0.31821) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.40636 (A-MSE: 0.36113) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 12 out of 50
train epoch 1391 avg loss: 0.08106 (A-MSE: 0.07113) avg lploss: 0.00000
train epoch 1392 avg loss: 0.07459 (A-MSE: 0.06620) avg lploss: 0.00000
train epoch 1393 avg loss: 0.08947 (A-MSE: 0.07913) avg lploss: 0.00000
train epoch 1394 avg loss: 0.08485 (A-MSE: 0.07569) avg lploss: 0.00000
train epoch 1395 avg loss: 0.08128 (A-MSE: 0.07111) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.39595 (A-MSE: 0.35669) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.43697 (A-MSE: 0.39948) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 13 out of 50
train epoch 1396 avg loss: 0.07722 (A-MSE: 0.06914) avg lploss: 0.00000
train epoch 1397 avg loss: 0.07119 (A-MSE: 0.06320) avg lploss: 0.00000
train epoch 1398 avg loss: 0.08562 (A-MSE: 0.07518) avg lploss: 0.00000
train epoch 1399 avg loss: 0.07442 (A-MSE: 0.06625) avg lploss: 0.00000
train epoch 1400 avg loss: 0.08115 (A-MSE: 0.07099) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.39213 (A-MSE: 0.35120) avg lploss: 0.00000
==> test epoch 1400 avg loss: 0.42328 (A-MSE: 0.38432) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 14 out of 50
train epoch 1401 avg loss: 0.08116 (A-MSE: 0.07171) avg lploss: 0.00000
train epoch 1402 avg loss: 0.08320 (A-MSE: 0.07421) avg lploss: 0.00000
train epoch 1403 avg loss: 0.07914 (A-MSE: 0.06875) avg lploss: 0.00000
train epoch 1404 avg loss: 0.07915 (A-MSE: 0.06989) avg lploss: 0.00000
train epoch 1405 avg loss: 0.09124 (A-MSE: 0.08040) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.32309 (A-MSE: 0.29194) avg lploss: 0.00000
==> test epoch 1405 avg loss: 0.38818 (A-MSE: 0.35624) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 15 out of 50
train epoch 1406 avg loss: 0.08352 (A-MSE: 0.07399) avg lploss: 0.00000
train epoch 1407 avg loss: 0.08492 (A-MSE: 0.07479) avg lploss: 0.00000
train epoch 1408 avg loss: 0.07922 (A-MSE: 0.07066) avg lploss: 0.00000
train epoch 1409 avg loss: 0.07056 (A-MSE: 0.06245) avg lploss: 0.00000
train epoch 1410 avg loss: 0.08626 (A-MSE: 0.07615) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.35429 (A-MSE: 0.31570) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.37219 (A-MSE: 0.33934) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 16 out of 50
train epoch 1411 avg loss: 0.07865 (A-MSE: 0.06982) avg lploss: 0.00000
train epoch 1412 avg loss: 0.07838 (A-MSE: 0.06929) avg lploss: 0.00000
train epoch 1413 avg loss: 0.08724 (A-MSE: 0.07726) avg lploss: 0.00000
train epoch 1414 avg loss: 0.08794 (A-MSE: 0.07758) avg lploss: 0.00000
train epoch 1415 avg loss: 0.07618 (A-MSE: 0.06685) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.32179 (A-MSE: 0.27974) avg lploss: 0.00000
==> test epoch 1415 avg loss: 0.36558 (A-MSE: 0.33173) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 17 out of 50
train epoch 1416 avg loss: 0.07462 (A-MSE: 0.06605) avg lploss: 0.00000
train epoch 1417 avg loss: 0.07630 (A-MSE: 0.06763) avg lploss: 0.00000
train epoch 1418 avg loss: 0.07975 (A-MSE: 0.07012) avg lploss: 0.00000
train epoch 1419 avg loss: 0.08448 (A-MSE: 0.07509) avg lploss: 0.00000
train epoch 1420 avg loss: 0.08237 (A-MSE: 0.07307) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.36655 (A-MSE: 0.32470) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.40731 (A-MSE: 0.36423) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 18 out of 50
train epoch 1421 avg loss: 0.09982 (A-MSE: 0.08738) avg lploss: 0.00000
train epoch 1422 avg loss: 0.10160 (A-MSE: 0.08938) avg lploss: 0.00000
train epoch 1423 avg loss: 0.08992 (A-MSE: 0.07930) avg lploss: 0.00000
train epoch 1424 avg loss: 0.10467 (A-MSE: 0.09103) avg lploss: 0.00000
train epoch 1425 avg loss: 0.10467 (A-MSE: 0.09175) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.35660 (A-MSE: 0.31461) avg lploss: 0.00000
==> test epoch 1425 avg loss: 0.41793 (A-MSE: 0.37507) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 19 out of 50
train epoch 1426 avg loss: 0.10676 (A-MSE: 0.09469) avg lploss: 0.00000
train epoch 1427 avg loss: 0.09618 (A-MSE: 0.08586) avg lploss: 0.00000
train epoch 1428 avg loss: 0.08801 (A-MSE: 0.07686) avg lploss: 0.00000
train epoch 1429 avg loss: 0.08101 (A-MSE: 0.07156) avg lploss: 0.00000
train epoch 1430 avg loss: 0.07139 (A-MSE: 0.06235) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.36802 (A-MSE: 0.32900) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.40836 (A-MSE: 0.36858) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 20 out of 50
train epoch 1431 avg loss: 0.08327 (A-MSE: 0.07320) avg lploss: 0.00000
train epoch 1432 avg loss: 0.06906 (A-MSE: 0.06176) avg lploss: 0.00000
train epoch 1433 avg loss: 0.06772 (A-MSE: 0.06003) avg lploss: 0.00000
train epoch 1434 avg loss: 0.06431 (A-MSE: 0.05720) avg lploss: 0.00000
train epoch 1435 avg loss: 0.06165 (A-MSE: 0.05395) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.34926 (A-MSE: 0.30505) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.39303 (A-MSE: 0.35125) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 21 out of 50
train epoch 1436 avg loss: 0.06765 (A-MSE: 0.05925) avg lploss: 0.00000
train epoch 1437 avg loss: 0.07124 (A-MSE: 0.06271) avg lploss: 0.00000
train epoch 1438 avg loss: 0.07121 (A-MSE: 0.06267) avg lploss: 0.00000
train epoch 1439 avg loss: 0.08337 (A-MSE: 0.07389) avg lploss: 0.00000
train epoch 1440 avg loss: 0.07993 (A-MSE: 0.07062) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.39446 (A-MSE: 0.34925) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.42664 (A-MSE: 0.38581) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 22 out of 50
train epoch 1441 avg loss: 0.08944 (A-MSE: 0.07824) avg lploss: 0.00000
train epoch 1442 avg loss: 0.08999 (A-MSE: 0.07932) avg lploss: 0.00000
train epoch 1443 avg loss: 0.07479 (A-MSE: 0.06632) avg lploss: 0.00000
train epoch 1444 avg loss: 0.07693 (A-MSE: 0.06783) avg lploss: 0.00000
train epoch 1445 avg loss: 0.09614 (A-MSE: 0.08555) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.40330 (A-MSE: 0.35794) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.47582 (A-MSE: 0.43073) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 23 out of 50
train epoch 1446 avg loss: 0.11107 (A-MSE: 0.09850) avg lploss: 0.00000
train epoch 1447 avg loss: 0.10764 (A-MSE: 0.09589) avg lploss: 0.00000
train epoch 1448 avg loss: 0.09124 (A-MSE: 0.07968) avg lploss: 0.00000
train epoch 1449 avg loss: 0.10336 (A-MSE: 0.09148) avg lploss: 0.00000
train epoch 1450 avg loss: 0.10520 (A-MSE: 0.09247) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.34548 (A-MSE: 0.30337) avg lploss: 0.00000
==> test epoch 1450 avg loss: 0.39393 (A-MSE: 0.35443) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 24 out of 50
train epoch 1451 avg loss: 0.09467 (A-MSE: 0.08411) avg lploss: 0.00000
train epoch 1452 avg loss: 0.09315 (A-MSE: 0.08204) avg lploss: 0.00000
train epoch 1453 avg loss: 0.07691 (A-MSE: 0.06859) avg lploss: 0.00000
train epoch 1454 avg loss: 0.07388 (A-MSE: 0.06561) avg lploss: 0.00000
train epoch 1455 avg loss: 0.08928 (A-MSE: 0.07876) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.32477 (A-MSE: 0.29221) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.37923 (A-MSE: 0.34642) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 25 out of 50
train epoch 1456 avg loss: 0.08135 (A-MSE: 0.07233) avg lploss: 0.00000
train epoch 1457 avg loss: 0.06903 (A-MSE: 0.06033) avg lploss: 0.00000
train epoch 1458 avg loss: 0.06719 (A-MSE: 0.05944) avg lploss: 0.00000
train epoch 1459 avg loss: 0.06987 (A-MSE: 0.06215) avg lploss: 0.00000
train epoch 1460 avg loss: 0.07846 (A-MSE: 0.06866) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.35988 (A-MSE: 0.32445) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.39453 (A-MSE: 0.36341) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 26 out of 50
train epoch 1461 avg loss: 0.09459 (A-MSE: 0.08431) avg lploss: 0.00000
train epoch 1462 avg loss: 0.09211 (A-MSE: 0.08135) avg lploss: 0.00000
train epoch 1463 avg loss: 0.07716 (A-MSE: 0.06738) avg lploss: 0.00000
train epoch 1464 avg loss: 0.06937 (A-MSE: 0.06145) avg lploss: 0.00000
train epoch 1465 avg loss: 0.06351 (A-MSE: 0.05578) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.33786 (A-MSE: 0.30608) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.37514 (A-MSE: 0.34664) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 27 out of 50
train epoch 1466 avg loss: 0.07532 (A-MSE: 0.06598) avg lploss: 0.00000
train epoch 1467 avg loss: 0.09065 (A-MSE: 0.07943) avg lploss: 0.00000
train epoch 1468 avg loss: 0.08736 (A-MSE: 0.07666) avg lploss: 0.00000
train epoch 1469 avg loss: 0.08386 (A-MSE: 0.07346) avg lploss: 0.00000
train epoch 1470 avg loss: 0.07362 (A-MSE: 0.06502) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.34638 (A-MSE: 0.30999) avg lploss: 0.00000
==> test epoch 1470 avg loss: 0.40402 (A-MSE: 0.36660) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 28 out of 50
train epoch 1471 avg loss: 0.07098 (A-MSE: 0.06278) avg lploss: 0.00000
train epoch 1472 avg loss: 0.07242 (A-MSE: 0.06342) avg lploss: 0.00000
train epoch 1473 avg loss: 0.10562 (A-MSE: 0.09316) avg lploss: 0.00000
train epoch 1474 avg loss: 0.12383 (A-MSE: 0.10990) avg lploss: 0.00000
train epoch 1475 avg loss: 0.08622 (A-MSE: 0.07696) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.38045 (A-MSE: 0.32777) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.41034 (A-MSE: 0.36543) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 29 out of 50
train epoch 1476 avg loss: 0.07906 (A-MSE: 0.06946) avg lploss: 0.00000
train epoch 1477 avg loss: 0.09558 (A-MSE: 0.08399) avg lploss: 0.00000
train epoch 1478 avg loss: 0.07648 (A-MSE: 0.06838) avg lploss: 0.00000
train epoch 1479 avg loss: 0.07502 (A-MSE: 0.06615) avg lploss: 0.00000
train epoch 1480 avg loss: 0.07610 (A-MSE: 0.06718) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.32405 (A-MSE: 0.28625) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.37268 (A-MSE: 0.33787) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 30 out of 50
train epoch 1481 avg loss: 0.07447 (A-MSE: 0.06570) avg lploss: 0.00000
train epoch 1482 avg loss: 0.06780 (A-MSE: 0.05996) avg lploss: 0.00000
train epoch 1483 avg loss: 0.06212 (A-MSE: 0.05483) avg lploss: 0.00000
train epoch 1484 avg loss: 0.06847 (A-MSE: 0.06083) avg lploss: 0.00000
train epoch 1485 avg loss: 0.07810 (A-MSE: 0.06927) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.35986 (A-MSE: 0.31803) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.40067 (A-MSE: 0.36185) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 31 out of 50
train epoch 1486 avg loss: 0.07516 (A-MSE: 0.06587) avg lploss: 0.00000
train epoch 1487 avg loss: 0.07736 (A-MSE: 0.06749) avg lploss: 0.00000
train epoch 1488 avg loss: 0.07245 (A-MSE: 0.06409) avg lploss: 0.00000
train epoch 1489 avg loss: 0.06981 (A-MSE: 0.06172) avg lploss: 0.00000
train epoch 1490 avg loss: 0.06931 (A-MSE: 0.06072) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.37077 (A-MSE: 0.33041) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.41024 (A-MSE: 0.37342) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 32 out of 50
train epoch 1491 avg loss: 0.06062 (A-MSE: 0.05408) avg lploss: 0.00000
train epoch 1492 avg loss: 0.05723 (A-MSE: 0.05041) avg lploss: 0.00000
train epoch 1493 avg loss: 0.06057 (A-MSE: 0.05408) avg lploss: 0.00000
train epoch 1494 avg loss: 0.06979 (A-MSE: 0.06201) avg lploss: 0.00000
train epoch 1495 avg loss: 0.07483 (A-MSE: 0.06621) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.35779 (A-MSE: 0.31519) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.40058 (A-MSE: 0.36004) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 33 out of 50
train epoch 1496 avg loss: 0.08071 (A-MSE: 0.07237) avg lploss: 0.00000
train epoch 1497 avg loss: 0.08499 (A-MSE: 0.07483) avg lploss: 0.00000
train epoch 1498 avg loss: 0.06592 (A-MSE: 0.05845) avg lploss: 0.00000
train epoch 1499 avg loss: 0.07373 (A-MSE: 0.06486) avg lploss: 0.00000
train epoch 1500 avg loss: 0.08454 (A-MSE: 0.07433) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.40949 (A-MSE: 0.36772) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.42035 (A-MSE: 0.37858) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 34 out of 50
train epoch 1501 avg loss: 0.09054 (A-MSE: 0.08007) avg lploss: 0.00000
train epoch 1502 avg loss: 0.07699 (A-MSE: 0.06906) avg lploss: 0.00000
train epoch 1503 avg loss: 0.07692 (A-MSE: 0.06825) avg lploss: 0.00000
train epoch 1504 avg loss: 0.07872 (A-MSE: 0.06945) avg lploss: 0.00000
train epoch 1505 avg loss: 0.08209 (A-MSE: 0.07226) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.34770 (A-MSE: 0.30521) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.37975 (A-MSE: 0.34189) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 35 out of 50
train epoch 1506 avg loss: 0.07749 (A-MSE: 0.06778) avg lploss: 0.00000
train epoch 1507 avg loss: 0.07613 (A-MSE: 0.06755) avg lploss: 0.00000
train epoch 1508 avg loss: 0.06831 (A-MSE: 0.05997) avg lploss: 0.00000
train epoch 1509 avg loss: 0.06802 (A-MSE: 0.06035) avg lploss: 0.00000
train epoch 1510 avg loss: 0.06906 (A-MSE: 0.06143) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.36509 (A-MSE: 0.32216) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.40338 (A-MSE: 0.36265) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 36 out of 50
train epoch 1511 avg loss: 0.07275 (A-MSE: 0.06338) avg lploss: 0.00000
train epoch 1512 avg loss: 0.06878 (A-MSE: 0.06027) avg lploss: 0.00000
train epoch 1513 avg loss: 0.07023 (A-MSE: 0.06200) avg lploss: 0.00000
train epoch 1514 avg loss: 0.06990 (A-MSE: 0.06195) avg lploss: 0.00000
train epoch 1515 avg loss: 0.07136 (A-MSE: 0.06255) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.38211 (A-MSE: 0.34020) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.40013 (A-MSE: 0.36487) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 37 out of 50
train epoch 1516 avg loss: 0.07031 (A-MSE: 0.06268) avg lploss: 0.00000
train epoch 1517 avg loss: 0.06327 (A-MSE: 0.05637) avg lploss: 0.00000
train epoch 1518 avg loss: 0.07440 (A-MSE: 0.06563) avg lploss: 0.00000
train epoch 1519 avg loss: 0.07538 (A-MSE: 0.06623) avg lploss: 0.00000
train epoch 1520 avg loss: 0.06678 (A-MSE: 0.05898) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.33070 (A-MSE: 0.29665) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.39128 (A-MSE: 0.35517) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 38 out of 50
train epoch 1521 avg loss: 0.06393 (A-MSE: 0.05650) avg lploss: 0.00000
train epoch 1522 avg loss: 0.05529 (A-MSE: 0.04852) avg lploss: 0.00000
train epoch 1523 avg loss: 0.06034 (A-MSE: 0.05276) avg lploss: 0.00000
train epoch 1524 avg loss: 0.05903 (A-MSE: 0.05172) avg lploss: 0.00000
train epoch 1525 avg loss: 0.05804 (A-MSE: 0.05121) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.33216 (A-MSE: 0.29689) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.37149 (A-MSE: 0.33550) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 39 out of 50
train epoch 1526 avg loss: 0.06053 (A-MSE: 0.05371) avg lploss: 0.00000
train epoch 1527 avg loss: 0.06530 (A-MSE: 0.05790) avg lploss: 0.00000
train epoch 1528 avg loss: 0.06682 (A-MSE: 0.05940) avg lploss: 0.00000
train epoch 1529 avg loss: 0.06906 (A-MSE: 0.06089) avg lploss: 0.00000
train epoch 1530 avg loss: 0.05829 (A-MSE: 0.05198) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.36044 (A-MSE: 0.31682) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.38549 (A-MSE: 0.34633) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 40 out of 50
train epoch 1531 avg loss: 0.06302 (A-MSE: 0.05558) avg lploss: 0.00000
train epoch 1532 avg loss: 0.05878 (A-MSE: 0.05160) avg lploss: 0.00000
train epoch 1533 avg loss: 0.07118 (A-MSE: 0.06258) avg lploss: 0.00000
train epoch 1534 avg loss: 0.06556 (A-MSE: 0.05811) avg lploss: 0.00000
train epoch 1535 avg loss: 0.07683 (A-MSE: 0.06771) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.33092 (A-MSE: 0.29577) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.37327 (A-MSE: 0.33879) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 41 out of 50
train epoch 1536 avg loss: 0.08319 (A-MSE: 0.07291) avg lploss: 0.00000
train epoch 1537 avg loss: 0.07097 (A-MSE: 0.06314) avg lploss: 0.00000
train epoch 1538 avg loss: 0.06382 (A-MSE: 0.05627) avg lploss: 0.00000
train epoch 1539 avg loss: 0.06143 (A-MSE: 0.05424) avg lploss: 0.00000
train epoch 1540 avg loss: 0.06987 (A-MSE: 0.06174) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.37464 (A-MSE: 0.33492) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.42020 (A-MSE: 0.38612) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 42 out of 50
train epoch 1541 avg loss: 0.06986 (A-MSE: 0.06134) avg lploss: 0.00000
train epoch 1542 avg loss: 0.07966 (A-MSE: 0.07139) avg lploss: 0.00000
train epoch 1543 avg loss: 0.07260 (A-MSE: 0.06438) avg lploss: 0.00000
train epoch 1544 avg loss: 0.07309 (A-MSE: 0.06392) avg lploss: 0.00000
train epoch 1545 avg loss: 0.07315 (A-MSE: 0.06566) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.35397 (A-MSE: 0.31407) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.40631 (A-MSE: 0.36817) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 43 out of 50
train epoch 1546 avg loss: 0.06029 (A-MSE: 0.05285) avg lploss: 0.00000
train epoch 1547 avg loss: 0.06697 (A-MSE: 0.05941) avg lploss: 0.00000
train epoch 1548 avg loss: 0.07799 (A-MSE: 0.06908) avg lploss: 0.00000
train epoch 1549 avg loss: 0.07639 (A-MSE: 0.06790) avg lploss: 0.00000
train epoch 1550 avg loss: 0.06986 (A-MSE: 0.06230) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.31458 (A-MSE: 0.28075) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.37556 (A-MSE: 0.33985) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 44 out of 50
train epoch 1551 avg loss: 0.08545 (A-MSE: 0.07440) avg lploss: 0.00000
train epoch 1552 avg loss: 0.07511 (A-MSE: 0.06700) avg lploss: 0.00000
train epoch 1553 avg loss: 0.07161 (A-MSE: 0.06292) avg lploss: 0.00000
train epoch 1554 avg loss: 0.06022 (A-MSE: 0.05284) avg lploss: 0.00000
train epoch 1555 avg loss: 0.05915 (A-MSE: 0.05166) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.35351 (A-MSE: 0.31133) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.40164 (A-MSE: 0.36142) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 45 out of 50
train epoch 1556 avg loss: 0.06912 (A-MSE: 0.06073) avg lploss: 0.00000
train epoch 1557 avg loss: 0.08231 (A-MSE: 0.07244) avg lploss: 0.00000
train epoch 1558 avg loss: 0.08562 (A-MSE: 0.07572) avg lploss: 0.00000
train epoch 1559 avg loss: 0.09234 (A-MSE: 0.08180) avg lploss: 0.00000
train epoch 1560 avg loss: 0.09709 (A-MSE: 0.08496) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.40419 (A-MSE: 0.35786) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.42644 (A-MSE: 0.38641) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 46 out of 50
train epoch 1561 avg loss: 0.06762 (A-MSE: 0.05960) avg lploss: 0.00000
train epoch 1562 avg loss: 0.06305 (A-MSE: 0.05590) avg lploss: 0.00000
train epoch 1563 avg loss: 0.06313 (A-MSE: 0.05514) avg lploss: 0.00000
train epoch 1564 avg loss: 0.06033 (A-MSE: 0.05305) avg lploss: 0.00000
train epoch 1565 avg loss: 0.06675 (A-MSE: 0.05863) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.38316 (A-MSE: 0.34129) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.44418 (A-MSE: 0.40371) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 47 out of 50
train epoch 1566 avg loss: 0.08840 (A-MSE: 0.07831) avg lploss: 0.00000
train epoch 1567 avg loss: 0.08663 (A-MSE: 0.07652) avg lploss: 0.00000
train epoch 1568 avg loss: 0.08452 (A-MSE: 0.07412) avg lploss: 0.00000
train epoch 1569 avg loss: 0.08419 (A-MSE: 0.07450) avg lploss: 0.00000
train epoch 1570 avg loss: 0.07673 (A-MSE: 0.06810) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.34830 (A-MSE: 0.30724) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.38699 (A-MSE: 0.35127) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 48 out of 50
train epoch 1571 avg loss: 0.06916 (A-MSE: 0.06049) avg lploss: 0.00000
train epoch 1572 avg loss: 0.08314 (A-MSE: 0.07345) avg lploss: 0.00000
train epoch 1573 avg loss: 0.07160 (A-MSE: 0.06329) avg lploss: 0.00000
train epoch 1574 avg loss: 0.06408 (A-MSE: 0.05693) avg lploss: 0.00000
train epoch 1575 avg loss: 0.06442 (A-MSE: 0.05672) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.33271 (A-MSE: 0.29357) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.39022 (A-MSE: 0.34901) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 49 out of 50
train epoch 1576 avg loss: 0.06379 (A-MSE: 0.05611) avg lploss: 0.00000
train epoch 1577 avg loss: 0.05786 (A-MSE: 0.05120) avg lploss: 0.00000
train epoch 1578 avg loss: 0.07027 (A-MSE: 0.06312) avg lploss: 0.00000
train epoch 1579 avg loss: 0.06741 (A-MSE: 0.05930) avg lploss: 0.00000
train epoch 1580 avg loss: 0.05933 (A-MSE: 0.05282) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.33651 (A-MSE: 0.29745) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.39108 (A-MSE: 0.35352) avg lploss: 0.00000
*** Best Val Loss: 0.31161 	 Best Test Loss: 0.39037 	 Best epoch 1330
EarlyStopping counter: 50 out of 50
Early Stopping.
best_train = 0.088834
best_lp = 0.000000
best_val = 0.311608
best_test = 0.390373
best_epoch = 1330
best_train = 0.088834, best_lp = 0.000000, best_val = 0.311608, best_test = 0.390373, best_epoch = 1330
Training completed for seed 1 with num_modes=1
