Date              = Mon Dec  8 23:11:23 CET 2025
Hostname          = mel2090
Array Task ID     = 2
Running config: configs/mocap_run_seed3.json
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_seed3.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_seed3', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=2, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=3, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_seed3/saved_model.pth
train epoch 0 avg loss: 104.63646 (A-MSE: 93.62543) avg lploss: 0.00000
==> val epoch 0 avg loss: 79.62976 (A-MSE: 69.28223) avg lploss: 0.00000
==> test epoch 0 avg loss: 76.18145 (A-MSE: 66.32553) avg lploss: 0.00000
*** Best Val Loss: 79.62976 	 Best Test Loss: 76.18145 	 Best epoch 0
Validation loss decreased (inf --> 79.629763).  Saving model ...
train epoch 1 avg loss: 75.96438 (A-MSE: 66.05545) avg lploss: 0.00000
train epoch 2 avg loss: 60.33927 (A-MSE: 52.37185) avg lploss: 0.00000
train epoch 3 avg loss: 39.46319 (A-MSE: 34.15988) avg lploss: 0.00000
train epoch 4 avg loss: 23.95367 (A-MSE: 21.09367) avg lploss: 0.00000
train epoch 5 avg loss: 17.00783 (A-MSE: 14.95307) avg lploss: 0.00000
==> val epoch 5 avg loss: 14.62888 (A-MSE: 12.79416) avg lploss: 0.00000
==> test epoch 5 avg loss: 14.11103 (A-MSE: 12.34363) avg lploss: 0.00000
*** Best Val Loss: 14.62888 	 Best Test Loss: 14.11103 	 Best epoch 5
Validation loss decreased (79.629763 --> 14.628880).  Saving model ...
train epoch 6 avg loss: 14.34075 (A-MSE: 12.55820) avg lploss: 0.00000
train epoch 7 avg loss: 12.09428 (A-MSE: 10.62535) avg lploss: 0.00000
train epoch 8 avg loss: 10.27368 (A-MSE: 9.01160) avg lploss: 0.00000
train epoch 9 avg loss: 9.11456 (A-MSE: 7.96671) avg lploss: 0.00000
train epoch 10 avg loss: 8.38196 (A-MSE: 7.33693) avg lploss: 0.00000
==> val epoch 10 avg loss: 7.67324 (A-MSE: 6.64227) avg lploss: 0.00000
==> test epoch 10 avg loss: 7.56493 (A-MSE: 6.54956) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
Validation loss decreased (14.628880 --> 7.673237).  Saving model ...
train epoch 11 avg loss: 7.73999 (A-MSE: 6.76778) avg lploss: 0.00000
train epoch 12 avg loss: 7.11729 (A-MSE: 6.22616) avg lploss: 0.00000
train epoch 13 avg loss: 1719510574.93374 (A-MSE: 1694546877.61603) avg lploss: 0.00000
train epoch 14 avg loss: 73379.69838 (A-MSE: 76553.64356) avg lploss: 0.00000
train epoch 15 avg loss: 1615.07335 (A-MSE: 1647.53157) avg lploss: 0.00000
==> val epoch 15 avg loss: 1651.11170 (A-MSE: 1682.66506) avg lploss: 0.00000
==> test epoch 15 avg loss: 1660.31318 (A-MSE: 1674.13619) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 1 out of 50
train epoch 16 avg loss: 1680.75790 (A-MSE: 1667.27760) avg lploss: 0.00000
train epoch 17 avg loss: 1647.60835 (A-MSE: 1632.88042) avg lploss: 0.00000
train epoch 18 avg loss: 1553.87663 (A-MSE: 1536.55824) avg lploss: 0.00000
train epoch 19 avg loss: 1336.16924 (A-MSE: 1324.55573) avg lploss: 0.00000
train epoch 20 avg loss: 1367.92854 (A-MSE: 1355.13400) avg lploss: 0.00000
==> val epoch 20 avg loss: 1345.06715 (A-MSE: 1316.27408) avg lploss: 0.00000
==> test epoch 20 avg loss: 1380.68546 (A-MSE: 1344.53541) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 2 out of 50
train epoch 21 avg loss: 2133.49429 (A-MSE: 2170.38093) avg lploss: 0.00000
train epoch 22 avg loss: 440.35536 (A-MSE: 458.03108) avg lploss: 0.00000
train epoch 23 avg loss: 49.79206 (A-MSE: 45.88090) avg lploss: 0.00000
train epoch 24 avg loss: 37.54516 (A-MSE: 30.62600) avg lploss: 0.00000
train epoch 25 avg loss: 31.82408 (A-MSE: 25.35368) avg lploss: 0.00000
==> val epoch 25 avg loss: 29.24386 (A-MSE: 23.04264) avg lploss: 0.00000
==> test epoch 25 avg loss: 28.18565 (A-MSE: 22.27180) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 3 out of 50
train epoch 26 avg loss: 27.34899 (A-MSE: 21.89955) avg lploss: 0.00000
train epoch 27 avg loss: 24.37283 (A-MSE: 19.63734) avg lploss: 0.00000
train epoch 28 avg loss: 22.35645 (A-MSE: 17.96904) avg lploss: 0.00000
train epoch 29 avg loss: 21.12233 (A-MSE: 17.04953) avg lploss: 0.00000
train epoch 30 avg loss: 20.18149 (A-MSE: 16.27147) avg lploss: 0.00000
==> val epoch 30 avg loss: 19.31940 (A-MSE: 15.33642) avg lploss: 0.00000
==> test epoch 30 avg loss: 18.33199 (A-MSE: 14.55125) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 4 out of 50
train epoch 31 avg loss: 19.42050 (A-MSE: 15.60657) avg lploss: 0.00000
train epoch 32 avg loss: 18.39093 (A-MSE: 14.69172) avg lploss: 0.00000
train epoch 33 avg loss: 17.84912 (A-MSE: 14.34728) avg lploss: 0.00000
train epoch 34 avg loss: 17.24971 (A-MSE: 13.93530) avg lploss: 0.00000
train epoch 35 avg loss: 16.97558 (A-MSE: 13.64077) avg lploss: 0.00000
==> val epoch 35 avg loss: 15.96034 (A-MSE: 12.67286) avg lploss: 0.00000
==> test epoch 35 avg loss: 15.17631 (A-MSE: 12.03391) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 5 out of 50
train epoch 36 avg loss: 16.31034 (A-MSE: 13.12593) avg lploss: 0.00000
train epoch 37 avg loss: 15.63010 (A-MSE: 12.59740) avg lploss: 0.00000
train epoch 38 avg loss: 15.23168 (A-MSE: 12.19189) avg lploss: 0.00000
train epoch 39 avg loss: 14.85503 (A-MSE: 11.96973) avg lploss: 0.00000
train epoch 40 avg loss: 14.50750 (A-MSE: 11.67720) avg lploss: 0.00000
==> val epoch 40 avg loss: 14.12382 (A-MSE: 11.16538) avg lploss: 0.00000
==> test epoch 40 avg loss: 13.38601 (A-MSE: 10.57051) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 6 out of 50
train epoch 41 avg loss: 14.34312 (A-MSE: 11.50269) avg lploss: 0.00000
train epoch 42 avg loss: 13.73957 (A-MSE: 11.02890) avg lploss: 0.00000
train epoch 43 avg loss: 13.71228 (A-MSE: 11.06201) avg lploss: 0.00000
train epoch 44 avg loss: 13.80233 (A-MSE: 11.06216) avg lploss: 0.00000
train epoch 45 avg loss: 13.11760 (A-MSE: 10.47664) avg lploss: 0.00000
==> val epoch 45 avg loss: 12.73056 (A-MSE: 10.13451) avg lploss: 0.00000
==> test epoch 45 avg loss: 12.18759 (A-MSE: 9.69329) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 7 out of 50
train epoch 46 avg loss: 12.82402 (A-MSE: 10.28963) avg lploss: 0.00000
train epoch 47 avg loss: 12.80499 (A-MSE: 10.29010) avg lploss: 0.00000
train epoch 48 avg loss: 12.70009 (A-MSE: 10.15012) avg lploss: 0.00000
train epoch 49 avg loss: 12.45495 (A-MSE: 10.05023) avg lploss: 0.00000
train epoch 50 avg loss: 12.32306 (A-MSE: 9.87532) avg lploss: 0.00000
==> val epoch 50 avg loss: 11.71694 (A-MSE: 9.37656) avg lploss: 0.00000
==> test epoch 50 avg loss: 11.15473 (A-MSE: 8.93002) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 8 out of 50
train epoch 51 avg loss: 11.99414 (A-MSE: 9.64161) avg lploss: 0.00000
train epoch 52 avg loss: 11.95421 (A-MSE: 9.64389) avg lploss: 0.00000
train epoch 53 avg loss: 11.74802 (A-MSE: 9.42025) avg lploss: 0.00000
train epoch 54 avg loss: 11.57635 (A-MSE: 9.32940) avg lploss: 0.00000
train epoch 55 avg loss: 11.68307 (A-MSE: 9.39648) avg lploss: 0.00000
==> val epoch 55 avg loss: 11.37531 (A-MSE: 8.98658) avg lploss: 0.00000
==> test epoch 55 avg loss: 10.86038 (A-MSE: 8.57089) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 9 out of 50
train epoch 56 avg loss: 11.33594 (A-MSE: 9.08291) avg lploss: 0.00000
train epoch 57 avg loss: 11.38791 (A-MSE: 9.19548) avg lploss: 0.00000
train epoch 58 avg loss: 11.36136 (A-MSE: 9.16098) avg lploss: 0.00000
train epoch 59 avg loss: 11.20732 (A-MSE: 9.01530) avg lploss: 0.00000
train epoch 60 avg loss: 10.99013 (A-MSE: 8.83178) avg lploss: 0.00000
==> val epoch 60 avg loss: 10.81200 (A-MSE: 8.44859) avg lploss: 0.00000
==> test epoch 60 avg loss: 10.49854 (A-MSE: 8.21118) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 10 out of 50
train epoch 61 avg loss: 10.89993 (A-MSE: 8.77641) avg lploss: 0.00000
train epoch 62 avg loss: 10.89802 (A-MSE: 8.80259) avg lploss: 0.00000
train epoch 63 avg loss: 10.64350 (A-MSE: 8.53624) avg lploss: 0.00000
train epoch 64 avg loss: 10.84947 (A-MSE: 8.73933) avg lploss: 0.00000
train epoch 65 avg loss: 10.58889 (A-MSE: 8.53362) avg lploss: 0.00000
==> val epoch 65 avg loss: 9.97187 (A-MSE: 7.95878) avg lploss: 0.00000
==> test epoch 65 avg loss: 9.63320 (A-MSE: 7.69660) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 11 out of 50
train epoch 66 avg loss: 10.38771 (A-MSE: 8.37185) avg lploss: 0.00000
train epoch 67 avg loss: 10.19633 (A-MSE: 8.18289) avg lploss: 0.00000
train epoch 68 avg loss: 10.11714 (A-MSE: 8.14673) avg lploss: 0.00000
train epoch 69 avg loss: 9.97984 (A-MSE: 8.01692) avg lploss: 0.00000
train epoch 70 avg loss: 9.82520 (A-MSE: 7.89421) avg lploss: 0.00000
==> val epoch 70 avg loss: 9.85970 (A-MSE: 7.94995) avg lploss: 0.00000
==> test epoch 70 avg loss: 9.77771 (A-MSE: 7.91266) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 12 out of 50
train epoch 71 avg loss: 9.87340 (A-MSE: 7.96955) avg lploss: 0.00000
train epoch 72 avg loss: 9.92996 (A-MSE: 8.00090) avg lploss: 0.00000
train epoch 73 avg loss: 9.56965 (A-MSE: 7.67752) avg lploss: 0.00000
train epoch 74 avg loss: 9.70145 (A-MSE: 7.83706) avg lploss: 0.00000
train epoch 75 avg loss: 9.52793 (A-MSE: 7.70228) avg lploss: 0.00000
==> val epoch 75 avg loss: 9.38523 (A-MSE: 7.28216) avg lploss: 0.00000
==> test epoch 75 avg loss: 9.12078 (A-MSE: 7.10494) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 13 out of 50
train epoch 76 avg loss: 9.49916 (A-MSE: 7.62275) avg lploss: 0.00000
train epoch 77 avg loss: 9.35512 (A-MSE: 7.51142) avg lploss: 0.00000
train epoch 78 avg loss: 9.32577 (A-MSE: 7.51723) avg lploss: 0.00000
train epoch 79 avg loss: 9.44502 (A-MSE: 7.61035) avg lploss: 0.00000
train epoch 80 avg loss: 8.92856 (A-MSE: 7.16268) avg lploss: 0.00000
==> val epoch 80 avg loss: 8.93396 (A-MSE: 6.99623) avg lploss: 0.00000
==> test epoch 80 avg loss: 8.70310 (A-MSE: 6.84643) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 14 out of 50
train epoch 81 avg loss: 8.84060 (A-MSE: 7.09224) avg lploss: 0.00000
train epoch 82 avg loss: 8.82918 (A-MSE: 7.12348) avg lploss: 0.00000
train epoch 83 avg loss: 8.81845 (A-MSE: 7.08374) avg lploss: 0.00000
train epoch 84 avg loss: 8.96507 (A-MSE: 7.25538) avg lploss: 0.00000
train epoch 85 avg loss: 8.55612 (A-MSE: 6.84301) avg lploss: 0.00000
==> val epoch 85 avg loss: 8.17588 (A-MSE: 6.55651) avg lploss: 0.00000
==> test epoch 85 avg loss: 8.19466 (A-MSE: 6.61383) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 15 out of 50
train epoch 86 avg loss: 8.59347 (A-MSE: 6.92930) avg lploss: 0.00000
train epoch 87 avg loss: 8.40767 (A-MSE: 6.73261) avg lploss: 0.00000
train epoch 88 avg loss: 8.29430 (A-MSE: 6.66091) avg lploss: 0.00000
train epoch 89 avg loss: 8.61388 (A-MSE: 6.99050) avg lploss: 0.00000
train epoch 90 avg loss: 8.31963 (A-MSE: 6.69778) avg lploss: 0.00000
==> val epoch 90 avg loss: 8.48632 (A-MSE: 6.53903) avg lploss: 0.00000
==> test epoch 90 avg loss: 8.35427 (A-MSE: 6.48364) avg lploss: 0.00000
*** Best Val Loss: 7.67324 	 Best Test Loss: 7.56493 	 Best epoch 10
EarlyStopping counter: 16 out of 50
train epoch 91 avg loss: 8.12882 (A-MSE: 6.51459) avg lploss: 0.00000
train epoch 92 avg loss: 8.18638 (A-MSE: 6.57310) avg lploss: 0.00000
train epoch 93 avg loss: 7.92125 (A-MSE: 6.36574) avg lploss: 0.00000
train epoch 94 avg loss: 7.82798 (A-MSE: 6.26624) avg lploss: 0.00000
train epoch 95 avg loss: 7.86042 (A-MSE: 6.34143) avg lploss: 0.00000
==> val epoch 95 avg loss: 7.44104 (A-MSE: 5.88414) avg lploss: 0.00000
==> test epoch 95 avg loss: 7.55625 (A-MSE: 6.04531) avg lploss: 0.00000
*** Best Val Loss: 7.44104 	 Best Test Loss: 7.55625 	 Best epoch 95
Validation loss decreased (7.673237 --> 7.441041).  Saving model ...
train epoch 96 avg loss: 7.72475 (A-MSE: 6.20923) avg lploss: 0.00000
train epoch 97 avg loss: 7.71088 (A-MSE: 6.19193) avg lploss: 0.00000
train epoch 98 avg loss: 7.67332 (A-MSE: 6.19014) avg lploss: 0.00000
train epoch 99 avg loss: 7.58718 (A-MSE: 6.03523) avg lploss: 0.00000
train epoch 100 avg loss: 7.40926 (A-MSE: 5.97155) avg lploss: 0.00000
==> val epoch 100 avg loss: 7.17847 (A-MSE: 5.60679) avg lploss: 0.00000
==> test epoch 100 avg loss: 7.22586 (A-MSE: 5.69944) avg lploss: 0.00000
*** Best Val Loss: 7.17847 	 Best Test Loss: 7.22586 	 Best epoch 100
Validation loss decreased (7.441041 --> 7.178466).  Saving model ...
train epoch 101 avg loss: 7.37508 (A-MSE: 5.95034) avg lploss: 0.00000
train epoch 102 avg loss: 7.37602 (A-MSE: 5.93130) avg lploss: 0.00000
train epoch 103 avg loss: 7.26681 (A-MSE: 5.81481) avg lploss: 0.00000
train epoch 104 avg loss: 7.10564 (A-MSE: 5.69221) avg lploss: 0.00000
train epoch 105 avg loss: 7.21299 (A-MSE: 5.81212) avg lploss: 0.00000
==> val epoch 105 avg loss: 7.17148 (A-MSE: 5.78175) avg lploss: 0.00000
==> test epoch 105 avg loss: 7.34835 (A-MSE: 5.97179) avg lploss: 0.00000
*** Best Val Loss: 7.17148 	 Best Test Loss: 7.34835 	 Best epoch 105
Validation loss decreased (7.178466 --> 7.171481).  Saving model ...
train epoch 106 avg loss: 7.14520 (A-MSE: 5.74423) avg lploss: 0.00000
train epoch 107 avg loss: 7.11798 (A-MSE: 5.73391) avg lploss: 0.00000
train epoch 108 avg loss: 7.04764 (A-MSE: 5.66871) avg lploss: 0.00000
train epoch 109 avg loss: 7.06427 (A-MSE: 5.66789) avg lploss: 0.00000
train epoch 110 avg loss: 6.92571 (A-MSE: 5.56337) avg lploss: 0.00000
==> val epoch 110 avg loss: 6.73298 (A-MSE: 5.41173) avg lploss: 0.00000
==> test epoch 110 avg loss: 6.95244 (A-MSE: 5.65077) avg lploss: 0.00000
*** Best Val Loss: 6.73298 	 Best Test Loss: 6.95244 	 Best epoch 110
Validation loss decreased (7.171481 --> 6.732979).  Saving model ...
train epoch 111 avg loss: 6.74626 (A-MSE: 5.40324) avg lploss: 0.00000
train epoch 112 avg loss: 6.68129 (A-MSE: 5.35796) avg lploss: 0.00000
train epoch 113 avg loss: 6.74421 (A-MSE: 5.41403) avg lploss: 0.00000
train epoch 114 avg loss: 6.94028 (A-MSE: 5.58541) avg lploss: 0.00000
train epoch 115 avg loss: 6.65007 (A-MSE: 5.33590) avg lploss: 0.00000
==> val epoch 115 avg loss: 6.92267 (A-MSE: 5.37552) avg lploss: 0.00000
==> test epoch 115 avg loss: 7.08716 (A-MSE: 5.59301) avg lploss: 0.00000
*** Best Val Loss: 6.73298 	 Best Test Loss: 6.95244 	 Best epoch 110
EarlyStopping counter: 1 out of 50
train epoch 116 avg loss: 6.57548 (A-MSE: 5.25677) avg lploss: 0.00000
train epoch 117 avg loss: 6.66365 (A-MSE: 5.34310) avg lploss: 0.00000
train epoch 118 avg loss: 6.47982 (A-MSE: 5.18091) avg lploss: 0.00000
train epoch 119 avg loss: 6.25141 (A-MSE: 4.98649) avg lploss: 0.00000
train epoch 120 avg loss: 6.42352 (A-MSE: 5.17634) avg lploss: 0.00000
==> val epoch 120 avg loss: 6.75181 (A-MSE: 5.18854) avg lploss: 0.00000
==> test epoch 120 avg loss: 6.81987 (A-MSE: 5.30430) avg lploss: 0.00000
*** Best Val Loss: 6.73298 	 Best Test Loss: 6.95244 	 Best epoch 110
EarlyStopping counter: 2 out of 50
train epoch 121 avg loss: 6.35932 (A-MSE: 5.09188) avg lploss: 0.00000
train epoch 122 avg loss: 6.27665 (A-MSE: 5.01395) avg lploss: 0.00000
train epoch 123 avg loss: 6.11409 (A-MSE: 4.90063) avg lploss: 0.00000
train epoch 124 avg loss: 6.02327 (A-MSE: 4.81988) avg lploss: 0.00000
train epoch 125 avg loss: 5.89601 (A-MSE: 4.72132) avg lploss: 0.00000
==> val epoch 125 avg loss: 6.51579 (A-MSE: 5.02266) avg lploss: 0.00000
==> test epoch 125 avg loss: 6.76758 (A-MSE: 5.29515) avg lploss: 0.00000
*** Best Val Loss: 6.51579 	 Best Test Loss: 6.76758 	 Best epoch 125
Validation loss decreased (6.732979 --> 6.515794).  Saving model ...
train epoch 126 avg loss: 5.96599 (A-MSE: 4.76203) avg lploss: 0.00000
train epoch 127 avg loss: 6.07560 (A-MSE: 4.90274) avg lploss: 0.00000
train epoch 128 avg loss: 6.00578 (A-MSE: 4.76168) avg lploss: 0.00000
train epoch 129 avg loss: 6.04270 (A-MSE: 4.85204) avg lploss: 0.00000
train epoch 130 avg loss: 6.01876 (A-MSE: 4.84276) avg lploss: 0.00000
==> val epoch 130 avg loss: 6.38748 (A-MSE: 4.90412) avg lploss: 0.00000
==> test epoch 130 avg loss: 6.57901 (A-MSE: 5.13337) avg lploss: 0.00000
*** Best Val Loss: 6.38748 	 Best Test Loss: 6.57901 	 Best epoch 130
Validation loss decreased (6.515794 --> 6.387478).  Saving model ...
train epoch 131 avg loss: 5.98507 (A-MSE: 4.82748) avg lploss: 0.00000
train epoch 132 avg loss: 5.76555 (A-MSE: 4.58989) avg lploss: 0.00000
train epoch 133 avg loss: 5.66300 (A-MSE: 4.50131) avg lploss: 0.00000
train epoch 134 avg loss: 5.72180 (A-MSE: 4.61486) avg lploss: 0.00000
train epoch 135 avg loss: 5.53521 (A-MSE: 4.39520) avg lploss: 0.00000
==> val epoch 135 avg loss: 5.67655 (A-MSE: 4.45665) avg lploss: 0.00000
==> test epoch 135 avg loss: 5.96739 (A-MSE: 4.75647) avg lploss: 0.00000
*** Best Val Loss: 5.67655 	 Best Test Loss: 5.96739 	 Best epoch 135
Validation loss decreased (6.387478 --> 5.676548).  Saving model ...
train epoch 136 avg loss: 5.60967 (A-MSE: 4.49425) avg lploss: 0.00000
train epoch 137 avg loss: 5.54046 (A-MSE: 4.45415) avg lploss: 0.00000
train epoch 138 avg loss: 5.79052 (A-MSE: 4.71638) avg lploss: 0.00000
train epoch 139 avg loss: 5.54478 (A-MSE: 4.38831) avg lploss: 0.00000
train epoch 140 avg loss: 5.40506 (A-MSE: 4.33137) avg lploss: 0.00000
==> val epoch 140 avg loss: 5.44911 (A-MSE: 4.28125) avg lploss: 0.00000
==> test epoch 140 avg loss: 5.82748 (A-MSE: 4.67083) avg lploss: 0.00000
*** Best Val Loss: 5.44911 	 Best Test Loss: 5.82748 	 Best epoch 140
Validation loss decreased (5.676548 --> 5.449114).  Saving model ...
train epoch 141 avg loss: 5.17809 (A-MSE: 4.10181) avg lploss: 0.00000
train epoch 142 avg loss: 5.15777 (A-MSE: 4.13641) avg lploss: 0.00000
train epoch 143 avg loss: 4.98910 (A-MSE: 3.99105) avg lploss: 0.00000
train epoch 144 avg loss: 5.30873 (A-MSE: 4.29812) avg lploss: 0.00000
train epoch 145 avg loss: 5.05077 (A-MSE: 4.01742) avg lploss: 0.00000
==> val epoch 145 avg loss: 5.37175 (A-MSE: 4.15067) avg lploss: 0.00000
==> test epoch 145 avg loss: 5.69247 (A-MSE: 4.50175) avg lploss: 0.00000
*** Best Val Loss: 5.37175 	 Best Test Loss: 5.69247 	 Best epoch 145
Validation loss decreased (5.449114 --> 5.371753).  Saving model ...
train epoch 146 avg loss: 4.74110 (A-MSE: 3.76706) avg lploss: 0.00000
train epoch 147 avg loss: 4.70274 (A-MSE: 3.76974) avg lploss: 0.00000
train epoch 148 avg loss: 4.72221 (A-MSE: 3.79631) avg lploss: 0.00000
train epoch 149 avg loss: 4.84589 (A-MSE: 3.93183) avg lploss: 0.00000
train epoch 150 avg loss: 4.70998 (A-MSE: 3.77944) avg lploss: 0.00000
==> val epoch 150 avg loss: 4.65982 (A-MSE: 3.69366) avg lploss: 0.00000
==> test epoch 150 avg loss: 4.99502 (A-MSE: 4.03732) avg lploss: 0.00000
*** Best Val Loss: 4.65982 	 Best Test Loss: 4.99502 	 Best epoch 150
Validation loss decreased (5.371753 --> 4.659817).  Saving model ...
train epoch 151 avg loss: 5.13739 (A-MSE: 4.17230) avg lploss: 0.00000
train epoch 152 avg loss: 5.15471 (A-MSE: 4.17160) avg lploss: 0.00000
train epoch 153 avg loss: 4.69639 (A-MSE: 3.80941) avg lploss: 0.00000
train epoch 154 avg loss: 4.66769 (A-MSE: 3.71889) avg lploss: 0.00000
train epoch 155 avg loss: 4.62688 (A-MSE: 3.74128) avg lploss: 0.00000
==> val epoch 155 avg loss: 5.29915 (A-MSE: 4.04304) avg lploss: 0.00000
==> test epoch 155 avg loss: 5.67039 (A-MSE: 4.41994) avg lploss: 0.00000
*** Best Val Loss: 4.65982 	 Best Test Loss: 4.99502 	 Best epoch 150
EarlyStopping counter: 1 out of 50
train epoch 156 avg loss: 4.52372 (A-MSE: 3.59833) avg lploss: 0.00000
train epoch 157 avg loss: 4.34889 (A-MSE: 3.50461) avg lploss: 0.00000
train epoch 158 avg loss: 4.54962 (A-MSE: 3.65007) avg lploss: 0.00000
train epoch 159 avg loss: 4.49422 (A-MSE: 3.62032) avg lploss: 0.00000
train epoch 160 avg loss: 4.40500 (A-MSE: 3.52465) avg lploss: 0.00000
==> val epoch 160 avg loss: 4.85015 (A-MSE: 3.74305) avg lploss: 0.00000
==> test epoch 160 avg loss: 5.20823 (A-MSE: 4.10790) avg lploss: 0.00000
*** Best Val Loss: 4.65982 	 Best Test Loss: 4.99502 	 Best epoch 150
EarlyStopping counter: 2 out of 50
train epoch 161 avg loss: 4.42397 (A-MSE: 3.53655) avg lploss: 0.00000
train epoch 162 avg loss: 4.26145 (A-MSE: 3.44609) avg lploss: 0.00000
train epoch 163 avg loss: 4.33216 (A-MSE: 3.46417) avg lploss: 0.00000
train epoch 164 avg loss: 4.39329 (A-MSE: 3.58073) avg lploss: 0.00000
train epoch 165 avg loss: 4.61526 (A-MSE: 3.68570) avg lploss: 0.00000
==> val epoch 165 avg loss: 4.80040 (A-MSE: 3.67804) avg lploss: 0.00000
==> test epoch 165 avg loss: 5.16722 (A-MSE: 4.07259) avg lploss: 0.00000
*** Best Val Loss: 4.65982 	 Best Test Loss: 4.99502 	 Best epoch 150
EarlyStopping counter: 3 out of 50
train epoch 166 avg loss: 4.15929 (A-MSE: 3.32295) avg lploss: 0.00000
train epoch 167 avg loss: 4.22115 (A-MSE: 3.39152) avg lploss: 0.00000
train epoch 168 avg loss: 4.31774 (A-MSE: 3.48494) avg lploss: 0.00000
train epoch 169 avg loss: 4.20225 (A-MSE: 3.37193) avg lploss: 0.00000
train epoch 170 avg loss: 4.46940 (A-MSE: 3.59763) avg lploss: 0.00000
==> val epoch 170 avg loss: 4.73025 (A-MSE: 3.57257) avg lploss: 0.00000
==> test epoch 170 avg loss: 5.13384 (A-MSE: 3.98700) avg lploss: 0.00000
*** Best Val Loss: 4.65982 	 Best Test Loss: 4.99502 	 Best epoch 150
EarlyStopping counter: 4 out of 50
train epoch 171 avg loss: 4.19108 (A-MSE: 3.32188) avg lploss: 0.00000
train epoch 172 avg loss: 4.08845 (A-MSE: 3.30185) avg lploss: 0.00000
train epoch 173 avg loss: 4.02903 (A-MSE: 3.18373) avg lploss: 0.00000
train epoch 174 avg loss: 3.98113 (A-MSE: 3.20391) avg lploss: 0.00000
train epoch 175 avg loss: 3.93134 (A-MSE: 3.13325) avg lploss: 0.00000
==> val epoch 175 avg loss: 4.59517 (A-MSE: 3.57780) avg lploss: 0.00000
==> test epoch 175 avg loss: 5.04205 (A-MSE: 4.05121) avg lploss: 0.00000
*** Best Val Loss: 4.59517 	 Best Test Loss: 5.04205 	 Best epoch 175
Validation loss decreased (4.659817 --> 4.595170).  Saving model ...
train epoch 176 avg loss: 4.03709 (A-MSE: 3.22670) avg lploss: 0.00000
train epoch 177 avg loss: 4.22500 (A-MSE: 3.40514) avg lploss: 0.00000
train epoch 178 avg loss: 3.96677 (A-MSE: 3.21331) avg lploss: 0.00000
train epoch 179 avg loss: 4.02093 (A-MSE: 3.20136) avg lploss: 0.00000
train epoch 180 avg loss: 4.00682 (A-MSE: 3.22043) avg lploss: 0.00000
==> val epoch 180 avg loss: 4.50713 (A-MSE: 3.53020) avg lploss: 0.00000
==> test epoch 180 avg loss: 5.00943 (A-MSE: 4.05334) avg lploss: 0.00000
*** Best Val Loss: 4.50713 	 Best Test Loss: 5.00943 	 Best epoch 180
Validation loss decreased (4.595170 --> 4.507131).  Saving model ...
train epoch 181 avg loss: 3.91476 (A-MSE: 3.12337) avg lploss: 0.00000
train epoch 182 avg loss: 3.88237 (A-MSE: 3.09426) avg lploss: 0.00000
train epoch 183 avg loss: 3.76341 (A-MSE: 3.02645) avg lploss: 0.00000
train epoch 184 avg loss: 3.80896 (A-MSE: 3.00970) avg lploss: 0.00000
train epoch 185 avg loss: 3.81283 (A-MSE: 3.04302) avg lploss: 0.00000
==> val epoch 185 avg loss: 4.40647 (A-MSE: 3.35588) avg lploss: 0.00000
==> test epoch 185 avg loss: 4.82724 (A-MSE: 3.80150) avg lploss: 0.00000
*** Best Val Loss: 4.40647 	 Best Test Loss: 4.82724 	 Best epoch 185
Validation loss decreased (4.507131 --> 4.406469).  Saving model ...
train epoch 186 avg loss: 3.90183 (A-MSE: 3.11295) avg lploss: 0.00000
train epoch 187 avg loss: 4.04773 (A-MSE: 3.27793) avg lploss: 0.00000
train epoch 188 avg loss: 3.98578 (A-MSE: 3.20196) avg lploss: 0.00000
train epoch 189 avg loss: 3.73954 (A-MSE: 3.00062) avg lploss: 0.00000
train epoch 190 avg loss: 3.78959 (A-MSE: 2.99645) avg lploss: 0.00000
==> val epoch 190 avg loss: 4.39136 (A-MSE: 3.39126) avg lploss: 0.00000
==> test epoch 190 avg loss: 4.77142 (A-MSE: 3.77566) avg lploss: 0.00000
*** Best Val Loss: 4.39136 	 Best Test Loss: 4.77142 	 Best epoch 190
Validation loss decreased (4.406469 --> 4.391356).  Saving model ...
train epoch 191 avg loss: 3.97614 (A-MSE: 3.20931) avg lploss: 0.00000
train epoch 192 avg loss: 4.14733 (A-MSE: 3.34761) avg lploss: 0.00000
train epoch 193 avg loss: 3.75333 (A-MSE: 3.00665) avg lploss: 0.00000
train epoch 194 avg loss: 3.60794 (A-MSE: 2.85050) avg lploss: 0.00000
train epoch 195 avg loss: 3.76791 (A-MSE: 3.02379) avg lploss: 0.00000
==> val epoch 195 avg loss: 4.27245 (A-MSE: 3.32226) avg lploss: 0.00000
==> test epoch 195 avg loss: 4.70360 (A-MSE: 3.75653) avg lploss: 0.00000
*** Best Val Loss: 4.27245 	 Best Test Loss: 4.70360 	 Best epoch 195
Validation loss decreased (4.391356 --> 4.272447).  Saving model ...
train epoch 196 avg loss: 3.64450 (A-MSE: 2.90260) avg lploss: 0.00000
train epoch 197 avg loss: 3.57632 (A-MSE: 2.84365) avg lploss: 0.00000
train epoch 198 avg loss: 3.50104 (A-MSE: 2.80342) avg lploss: 0.00000
train epoch 199 avg loss: 3.51188 (A-MSE: 2.82347) avg lploss: 0.00000
train epoch 200 avg loss: 3.63127 (A-MSE: 2.89014) avg lploss: 0.00000
==> val epoch 200 avg loss: 4.47515 (A-MSE: 3.55632) avg lploss: 0.00000
==> test epoch 200 avg loss: 4.98700 (A-MSE: 4.07605) avg lploss: 0.00000
*** Best Val Loss: 4.27245 	 Best Test Loss: 4.70360 	 Best epoch 195
EarlyStopping counter: 1 out of 50
train epoch 201 avg loss: 3.62820 (A-MSE: 2.90505) avg lploss: 0.00000
train epoch 202 avg loss: 3.89779 (A-MSE: 3.13501) avg lploss: 0.00000
train epoch 203 avg loss: 3.75353 (A-MSE: 2.98940) avg lploss: 0.00000
train epoch 204 avg loss: 3.92838 (A-MSE: 3.18585) avg lploss: 0.00000
train epoch 205 avg loss: 3.71532 (A-MSE: 2.96227) avg lploss: 0.00000
==> val epoch 205 avg loss: 4.24962 (A-MSE: 3.25318) avg lploss: 0.00000
==> test epoch 205 avg loss: 4.67875 (A-MSE: 3.68692) avg lploss: 0.00000
*** Best Val Loss: 4.24962 	 Best Test Loss: 4.67875 	 Best epoch 205
Validation loss decreased (4.272447 --> 4.249616).  Saving model ...
train epoch 206 avg loss: 3.56198 (A-MSE: 2.86296) avg lploss: 0.00000
train epoch 207 avg loss: 3.55396 (A-MSE: 2.80934) avg lploss: 0.00000
train epoch 208 avg loss: 3.67431 (A-MSE: 2.97407) avg lploss: 0.00000
train epoch 209 avg loss: 3.57537 (A-MSE: 2.84968) avg lploss: 0.00000
train epoch 210 avg loss: 3.62276 (A-MSE: 2.88073) avg lploss: 0.00000
==> val epoch 210 avg loss: 3.91578 (A-MSE: 3.10073) avg lploss: 0.00000
==> test epoch 210 avg loss: 4.44193 (A-MSE: 3.62146) avg lploss: 0.00000
*** Best Val Loss: 3.91578 	 Best Test Loss: 4.44193 	 Best epoch 210
Validation loss decreased (4.249616 --> 3.915783).  Saving model ...
train epoch 211 avg loss: 3.40531 (A-MSE: 2.72001) avg lploss: 0.00000
train epoch 212 avg loss: 3.44898 (A-MSE: 2.73841) avg lploss: 0.00000
train epoch 213 avg loss: 3.38128 (A-MSE: 2.69679) avg lploss: 0.00000
train epoch 214 avg loss: 3.34200 (A-MSE: 2.66679) avg lploss: 0.00000
train epoch 215 avg loss: 3.27637 (A-MSE: 2.58247) avg lploss: 0.00000
==> val epoch 215 avg loss: 4.21748 (A-MSE: 3.43139) avg lploss: 0.00000
==> test epoch 215 avg loss: 4.79330 (A-MSE: 4.02688) avg lploss: 0.00000
*** Best Val Loss: 3.91578 	 Best Test Loss: 4.44193 	 Best epoch 210
EarlyStopping counter: 1 out of 50
train epoch 216 avg loss: 3.50101 (A-MSE: 2.81143) avg lploss: 0.00000
train epoch 217 avg loss: 3.41204 (A-MSE: 2.70045) avg lploss: 0.00000
train epoch 218 avg loss: 3.31692 (A-MSE: 2.70149) avg lploss: 0.00000
train epoch 219 avg loss: 3.46210 (A-MSE: 2.76841) avg lploss: 0.00000
train epoch 220 avg loss: 3.47734 (A-MSE: 2.75663) avg lploss: 0.00000
==> val epoch 220 avg loss: 3.91046 (A-MSE: 2.98267) avg lploss: 0.00000
==> test epoch 220 avg loss: 4.40987 (A-MSE: 3.50038) avg lploss: 0.00000
*** Best Val Loss: 3.91046 	 Best Test Loss: 4.40987 	 Best epoch 220
Validation loss decreased (3.915783 --> 3.910464).  Saving model ...
train epoch 221 avg loss: 3.30340 (A-MSE: 2.62207) avg lploss: 0.00000
train epoch 222 avg loss: 3.47141 (A-MSE: 2.76828) avg lploss: 0.00000
train epoch 223 avg loss: 3.46376 (A-MSE: 2.78748) avg lploss: 0.00000
train epoch 224 avg loss: 3.37002 (A-MSE: 2.68729) avg lploss: 0.00000
train epoch 225 avg loss: 3.24914 (A-MSE: 2.55208) avg lploss: 0.00000
==> val epoch 225 avg loss: 3.69888 (A-MSE: 2.90387) avg lploss: 0.00000
==> test epoch 225 avg loss: 4.18099 (A-MSE: 3.39819) avg lploss: 0.00000
*** Best Val Loss: 3.69888 	 Best Test Loss: 4.18099 	 Best epoch 225
Validation loss decreased (3.910464 --> 3.698885).  Saving model ...
train epoch 226 avg loss: 3.15902 (A-MSE: 2.54995) avg lploss: 0.00000
train epoch 227 avg loss: 3.26646 (A-MSE: 2.55894) avg lploss: 0.00000
train epoch 228 avg loss: 3.16512 (A-MSE: 2.53165) avg lploss: 0.00000
train epoch 229 avg loss: 3.08870 (A-MSE: 2.44931) avg lploss: 0.00000
train epoch 230 avg loss: 3.07273 (A-MSE: 2.43898) avg lploss: 0.00000
==> val epoch 230 avg loss: 3.68574 (A-MSE: 2.87295) avg lploss: 0.00000
==> test epoch 230 avg loss: 4.21135 (A-MSE: 3.40969) avg lploss: 0.00000
*** Best Val Loss: 3.68574 	 Best Test Loss: 4.21135 	 Best epoch 230
Validation loss decreased (3.698885 --> 3.685740).  Saving model ...
train epoch 231 avg loss: 3.10101 (A-MSE: 2.44681) avg lploss: 0.00000
train epoch 232 avg loss: 3.16997 (A-MSE: 2.55110) avg lploss: 0.00000
train epoch 233 avg loss: 3.13564 (A-MSE: 2.47381) avg lploss: 0.00000
train epoch 234 avg loss: 3.16051 (A-MSE: 2.51457) avg lploss: 0.00000
train epoch 235 avg loss: 3.38514 (A-MSE: 2.71800) avg lploss: 0.00000
==> val epoch 235 avg loss: 3.98175 (A-MSE: 3.01571) avg lploss: 0.00000
==> test epoch 235 avg loss: 4.49580 (A-MSE: 3.52214) avg lploss: 0.00000
*** Best Val Loss: 3.68574 	 Best Test Loss: 4.21135 	 Best epoch 230
EarlyStopping counter: 1 out of 50
train epoch 236 avg loss: 3.18882 (A-MSE: 2.57004) avg lploss: 0.00000
train epoch 237 avg loss: 3.24950 (A-MSE: 2.55554) avg lploss: 0.00000
train epoch 238 avg loss: 3.29229 (A-MSE: 2.63804) avg lploss: 0.00000
train epoch 239 avg loss: 3.09063 (A-MSE: 2.45522) avg lploss: 0.00000
train epoch 240 avg loss: 3.27172 (A-MSE: 2.60474) avg lploss: 0.00000
==> val epoch 240 avg loss: 4.06491 (A-MSE: 3.25440) avg lploss: 0.00000
==> test epoch 240 avg loss: 4.56340 (A-MSE: 3.75239) avg lploss: 0.00000
*** Best Val Loss: 3.68574 	 Best Test Loss: 4.21135 	 Best epoch 230
EarlyStopping counter: 2 out of 50
train epoch 241 avg loss: 3.41774 (A-MSE: 2.75654) avg lploss: 0.00000
train epoch 242 avg loss: 3.39072 (A-MSE: 2.74948) avg lploss: 0.00000
train epoch 243 avg loss: 3.25067 (A-MSE: 2.57123) avg lploss: 0.00000
train epoch 244 avg loss: 3.17134 (A-MSE: 2.53547) avg lploss: 0.00000
train epoch 245 avg loss: 3.03534 (A-MSE: 2.40165) avg lploss: 0.00000
==> val epoch 245 avg loss: 3.82021 (A-MSE: 2.91869) avg lploss: 0.00000
==> test epoch 245 avg loss: 4.31049 (A-MSE: 3.41115) avg lploss: 0.00000
*** Best Val Loss: 3.68574 	 Best Test Loss: 4.21135 	 Best epoch 230
EarlyStopping counter: 3 out of 50
train epoch 246 avg loss: 3.07770 (A-MSE: 2.44792) avg lploss: 0.00000
train epoch 247 avg loss: 3.04024 (A-MSE: 2.40396) avg lploss: 0.00000
train epoch 248 avg loss: 2.98700 (A-MSE: 2.36979) avg lploss: 0.00000
train epoch 249 avg loss: 2.99836 (A-MSE: 2.37786) avg lploss: 0.00000
train epoch 250 avg loss: 2.93275 (A-MSE: 2.30852) avg lploss: 0.00000
==> val epoch 250 avg loss: 3.78203 (A-MSE: 2.98429) avg lploss: 0.00000
==> test epoch 250 avg loss: 4.38699 (A-MSE: 3.59520) avg lploss: 0.00000
*** Best Val Loss: 3.68574 	 Best Test Loss: 4.21135 	 Best epoch 230
EarlyStopping counter: 4 out of 50
train epoch 251 avg loss: 3.05117 (A-MSE: 2.44258) avg lploss: 0.00000
train epoch 252 avg loss: 2.94294 (A-MSE: 2.34000) avg lploss: 0.00000
train epoch 253 avg loss: 2.96289 (A-MSE: 2.35398) avg lploss: 0.00000
train epoch 254 avg loss: 2.95809 (A-MSE: 2.32931) avg lploss: 0.00000
train epoch 255 avg loss: 2.90060 (A-MSE: 2.31318) avg lploss: 0.00000
==> val epoch 255 avg loss: 3.56192 (A-MSE: 2.71986) avg lploss: 0.00000
==> test epoch 255 avg loss: 4.16269 (A-MSE: 3.30820) avg lploss: 0.00000
*** Best Val Loss: 3.56192 	 Best Test Loss: 4.16269 	 Best epoch 255
Validation loss decreased (3.685740 --> 3.561924).  Saving model ...
train epoch 256 avg loss: 2.81744 (A-MSE: 2.22723) avg lploss: 0.00000
train epoch 257 avg loss: 3.09552 (A-MSE: 2.50244) avg lploss: 0.00000
train epoch 258 avg loss: 3.00831 (A-MSE: 2.40563) avg lploss: 0.00000
train epoch 259 avg loss: 2.97856 (A-MSE: 2.34972) avg lploss: 0.00000
train epoch 260 avg loss: 2.85862 (A-MSE: 2.27614) avg lploss: 0.00000
==> val epoch 260 avg loss: 3.49425 (A-MSE: 2.69066) avg lploss: 0.00000
==> test epoch 260 avg loss: 4.04228 (A-MSE: 3.21808) avg lploss: 0.00000
*** Best Val Loss: 3.49425 	 Best Test Loss: 4.04228 	 Best epoch 260
Validation loss decreased (3.561924 --> 3.494247).  Saving model ...
train epoch 261 avg loss: 2.85195 (A-MSE: 2.23633) avg lploss: 0.00000
train epoch 262 avg loss: 2.87716 (A-MSE: 2.31516) avg lploss: 0.00000
train epoch 263 avg loss: 2.99885 (A-MSE: 2.40683) avg lploss: 0.00000
train epoch 264 avg loss: 3.01127 (A-MSE: 2.40863) avg lploss: 0.00000
train epoch 265 avg loss: 3.11636 (A-MSE: 2.47802) avg lploss: 0.00000
==> val epoch 265 avg loss: 3.48001 (A-MSE: 2.79822) avg lploss: 0.00000
==> test epoch 265 avg loss: 4.07138 (A-MSE: 3.37080) avg lploss: 0.00000
*** Best Val Loss: 3.48001 	 Best Test Loss: 4.07138 	 Best epoch 265
Validation loss decreased (3.494247 --> 3.480007).  Saving model ...
train epoch 266 avg loss: 2.80944 (A-MSE: 2.23050) avg lploss: 0.00000
train epoch 267 avg loss: 2.77933 (A-MSE: 2.19589) avg lploss: 0.00000
train epoch 268 avg loss: 2.79342 (A-MSE: 2.23534) avg lploss: 0.00000
train epoch 269 avg loss: 2.68581 (A-MSE: 2.12157) avg lploss: 0.00000
train epoch 270 avg loss: 2.91227 (A-MSE: 2.32011) avg lploss: 0.00000
==> val epoch 270 avg loss: 3.87918 (A-MSE: 3.13932) avg lploss: 0.00000
==> test epoch 270 avg loss: 4.48891 (A-MSE: 3.72794) avg lploss: 0.00000
*** Best Val Loss: 3.48001 	 Best Test Loss: 4.07138 	 Best epoch 265
EarlyStopping counter: 1 out of 50
train epoch 271 avg loss: 2.90090 (A-MSE: 2.31425) avg lploss: 0.00000
train epoch 272 avg loss: 2.84825 (A-MSE: 2.24336) avg lploss: 0.00000
train epoch 273 avg loss: 2.72942 (A-MSE: 2.18467) avg lploss: 0.00000
train epoch 274 avg loss: 2.85675 (A-MSE: 2.25781) avg lploss: 0.00000
train epoch 275 avg loss: 2.96811 (A-MSE: 2.41358) avg lploss: 0.00000
==> val epoch 275 avg loss: 3.42694 (A-MSE: 2.58874) avg lploss: 0.00000
==> test epoch 275 avg loss: 3.99298 (A-MSE: 3.13669) avg lploss: 0.00000
*** Best Val Loss: 3.42694 	 Best Test Loss: 3.99298 	 Best epoch 275
Validation loss decreased (3.480007 --> 3.426936).  Saving model ...
train epoch 276 avg loss: 2.79064 (A-MSE: 2.21135) avg lploss: 0.00000
train epoch 277 avg loss: 2.83053 (A-MSE: 2.25539) avg lploss: 0.00000
train epoch 278 avg loss: 2.59992 (A-MSE: 2.05992) avg lploss: 0.00000
train epoch 279 avg loss: 2.62348 (A-MSE: 2.07842) avg lploss: 0.00000
train epoch 280 avg loss: 2.61937 (A-MSE: 2.06103) avg lploss: 0.00000
==> val epoch 280 avg loss: 3.19233 (A-MSE: 2.41369) avg lploss: 0.00000
==> test epoch 280 avg loss: 3.68829 (A-MSE: 2.89397) avg lploss: 0.00000
*** Best Val Loss: 3.19233 	 Best Test Loss: 3.68829 	 Best epoch 280
Validation loss decreased (3.426936 --> 3.192330).  Saving model ...
train epoch 281 avg loss: 2.66617 (A-MSE: 2.14208) avg lploss: 0.00000
train epoch 282 avg loss: 2.73540 (A-MSE: 2.18626) avg lploss: 0.00000
train epoch 283 avg loss: 2.73073 (A-MSE: 2.18853) avg lploss: 0.00000
train epoch 284 avg loss: 2.67821 (A-MSE: 2.09700) avg lploss: 0.00000
train epoch 285 avg loss: 2.60938 (A-MSE: 2.07756) avg lploss: 0.00000
==> val epoch 285 avg loss: 3.13578 (A-MSE: 2.57500) avg lploss: 0.00000
==> test epoch 285 avg loss: 3.63765 (A-MSE: 3.04831) avg lploss: 0.00000
*** Best Val Loss: 3.13578 	 Best Test Loss: 3.63765 	 Best epoch 285
Validation loss decreased (3.192330 --> 3.135775).  Saving model ...
train epoch 286 avg loss: 2.67946 (A-MSE: 2.16793) avg lploss: 0.00000
train epoch 287 avg loss: 2.65872 (A-MSE: 2.09733) avg lploss: 0.00000
train epoch 288 avg loss: 2.61108 (A-MSE: 2.08296) avg lploss: 0.00000
train epoch 289 avg loss: 2.50747 (A-MSE: 1.97543) avg lploss: 0.00000
train epoch 290 avg loss: 2.49619 (A-MSE: 2.01553) avg lploss: 0.00000
==> val epoch 290 avg loss: 3.60945 (A-MSE: 2.67905) avg lploss: 0.00000
==> test epoch 290 avg loss: 4.08421 (A-MSE: 3.14193) avg lploss: 0.00000
*** Best Val Loss: 3.13578 	 Best Test Loss: 3.63765 	 Best epoch 285
EarlyStopping counter: 1 out of 50
train epoch 291 avg loss: 2.55278 (A-MSE: 2.00834) avg lploss: 0.00000
train epoch 292 avg loss: 2.47540 (A-MSE: 1.97183) avg lploss: 0.00000
train epoch 293 avg loss: 2.54485 (A-MSE: 1.99523) avg lploss: 0.00000
train epoch 294 avg loss: 2.39443 (A-MSE: 1.91740) avg lploss: 0.00000
train epoch 295 avg loss: 2.52893 (A-MSE: 2.00956) avg lploss: 0.00000
==> val epoch 295 avg loss: 3.18663 (A-MSE: 2.42904) avg lploss: 0.00000
==> test epoch 295 avg loss: 3.70037 (A-MSE: 2.91700) avg lploss: 0.00000
*** Best Val Loss: 3.13578 	 Best Test Loss: 3.63765 	 Best epoch 285
EarlyStopping counter: 2 out of 50
train epoch 296 avg loss: 2.58681 (A-MSE: 2.06785) avg lploss: 0.00000
train epoch 297 avg loss: 2.69681 (A-MSE: 2.18444) avg lploss: 0.00000
train epoch 298 avg loss: 2.67301 (A-MSE: 2.15566) avg lploss: 0.00000
train epoch 299 avg loss: 2.56745 (A-MSE: 2.03107) avg lploss: 0.00000
train epoch 300 avg loss: 2.51557 (A-MSE: 2.00902) avg lploss: 0.00000
==> val epoch 300 avg loss: 3.25997 (A-MSE: 2.47689) avg lploss: 0.00000
==> test epoch 300 avg loss: 3.70633 (A-MSE: 2.91569) avg lploss: 0.00000
*** Best Val Loss: 3.13578 	 Best Test Loss: 3.63765 	 Best epoch 285
EarlyStopping counter: 3 out of 50
train epoch 301 avg loss: 2.66232 (A-MSE: 2.13126) avg lploss: 0.00000
train epoch 302 avg loss: 2.48483 (A-MSE: 1.99458) avg lploss: 0.00000
train epoch 303 avg loss: 2.46547 (A-MSE: 1.95081) avg lploss: 0.00000
train epoch 304 avg loss: 2.53531 (A-MSE: 2.03741) avg lploss: 0.00000
train epoch 305 avg loss: 2.39763 (A-MSE: 1.90698) avg lploss: 0.00000
==> val epoch 305 avg loss: 2.87735 (A-MSE: 2.23059) avg lploss: 0.00000
==> test epoch 305 avg loss: 3.37151 (A-MSE: 2.70122) avg lploss: 0.00000
*** Best Val Loss: 2.87735 	 Best Test Loss: 3.37151 	 Best epoch 305
Validation loss decreased (3.135775 --> 2.877355).  Saving model ...
train epoch 306 avg loss: 2.37685 (A-MSE: 1.90722) avg lploss: 0.00000
train epoch 307 avg loss: 2.34476 (A-MSE: 1.86227) avg lploss: 0.00000
train epoch 308 avg loss: 2.38105 (A-MSE: 1.90363) avg lploss: 0.00000
train epoch 309 avg loss: 2.41107 (A-MSE: 1.92252) avg lploss: 0.00000
train epoch 310 avg loss: 2.37560 (A-MSE: 1.89171) avg lploss: 0.00000
==> val epoch 310 avg loss: 2.99870 (A-MSE: 2.33938) avg lploss: 0.00000
==> test epoch 310 avg loss: 3.53028 (A-MSE: 2.83382) avg lploss: 0.00000
*** Best Val Loss: 2.87735 	 Best Test Loss: 3.37151 	 Best epoch 305
EarlyStopping counter: 1 out of 50
train epoch 311 avg loss: 2.38209 (A-MSE: 1.92197) avg lploss: 0.00000
train epoch 312 avg loss: 2.57630 (A-MSE: 2.07139) avg lploss: 0.00000
train epoch 313 avg loss: 2.45267 (A-MSE: 1.98939) avg lploss: 0.00000
train epoch 314 avg loss: 2.33281 (A-MSE: 1.83863) avg lploss: 0.00000
train epoch 315 avg loss: 2.26901 (A-MSE: 1.80970) avg lploss: 0.00000
==> val epoch 315 avg loss: 2.78191 (A-MSE: 2.13102) avg lploss: 0.00000
==> test epoch 315 avg loss: 3.26594 (A-MSE: 2.59212) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
Validation loss decreased (2.877355 --> 2.781908).  Saving model ...
train epoch 316 avg loss: 2.30458 (A-MSE: 1.83961) avg lploss: 0.00000
train epoch 317 avg loss: 2.21083 (A-MSE: 1.76077) avg lploss: 0.00000
train epoch 318 avg loss: 2.20334 (A-MSE: 1.78949) avg lploss: 0.00000
train epoch 319 avg loss: 2.37964 (A-MSE: 1.91713) avg lploss: 0.00000
train epoch 320 avg loss: 2.39006 (A-MSE: 1.90180) avg lploss: 0.00000
==> val epoch 320 avg loss: 2.89681 (A-MSE: 2.26031) avg lploss: 0.00000
==> test epoch 320 avg loss: 3.42059 (A-MSE: 2.75127) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
EarlyStopping counter: 1 out of 50
train epoch 321 avg loss: 2.25964 (A-MSE: 1.80757) avg lploss: 0.00000
train epoch 322 avg loss: 2.13282 (A-MSE: 1.70083) avg lploss: 0.00000
train epoch 323 avg loss: 2.11048 (A-MSE: 1.69107) avg lploss: 0.00000
train epoch 324 avg loss: 2.10940 (A-MSE: 1.69516) avg lploss: 0.00000
train epoch 325 avg loss: 2.29080 (A-MSE: 1.83464) avg lploss: 0.00000
==> val epoch 325 avg loss: 3.03406 (A-MSE: 2.40230) avg lploss: 0.00000
==> test epoch 325 avg loss: 3.51636 (A-MSE: 2.85847) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
EarlyStopping counter: 2 out of 50
train epoch 326 avg loss: 2.35436 (A-MSE: 1.91108) avg lploss: 0.00000
train epoch 327 avg loss: 2.18877 (A-MSE: 1.75517) avg lploss: 0.00000
train epoch 328 avg loss: 2.24493 (A-MSE: 1.80271) avg lploss: 0.00000
train epoch 329 avg loss: 2.21314 (A-MSE: 1.79156) avg lploss: 0.00000
train epoch 330 avg loss: 2.16154 (A-MSE: 1.74466) avg lploss: 0.00000
==> val epoch 330 avg loss: 2.95320 (A-MSE: 2.30586) avg lploss: 0.00000
==> test epoch 330 avg loss: 3.43007 (A-MSE: 2.73725) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
EarlyStopping counter: 3 out of 50
train epoch 331 avg loss: 2.23603 (A-MSE: 1.80750) avg lploss: 0.00000
train epoch 332 avg loss: 2.28200 (A-MSE: 1.84948) avg lploss: 0.00000
train epoch 333 avg loss: 2.23601 (A-MSE: 1.80454) avg lploss: 0.00000
train epoch 334 avg loss: 2.16152 (A-MSE: 1.74586) avg lploss: 0.00000
train epoch 335 avg loss: 2.19118 (A-MSE: 1.77117) avg lploss: 0.00000
==> val epoch 335 avg loss: 2.90438 (A-MSE: 2.20264) avg lploss: 0.00000
==> test epoch 335 avg loss: 3.35370 (A-MSE: 2.63708) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
EarlyStopping counter: 4 out of 50
train epoch 336 avg loss: 2.20575 (A-MSE: 1.77995) avg lploss: 0.00000
train epoch 337 avg loss: 2.22412 (A-MSE: 1.79471) avg lploss: 0.00000
train epoch 338 avg loss: 2.06522 (A-MSE: 1.65799) avg lploss: 0.00000
train epoch 339 avg loss: 2.01175 (A-MSE: 1.62903) avg lploss: 0.00000
train epoch 340 avg loss: 1.99007 (A-MSE: 1.59978) avg lploss: 0.00000
==> val epoch 340 avg loss: 2.83388 (A-MSE: 2.18637) avg lploss: 0.00000
==> test epoch 340 avg loss: 3.32377 (A-MSE: 2.64676) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
EarlyStopping counter: 5 out of 50
train epoch 341 avg loss: 2.05335 (A-MSE: 1.65527) avg lploss: 0.00000
train epoch 342 avg loss: 2.16313 (A-MSE: 1.75130) avg lploss: 0.00000
train epoch 343 avg loss: 2.07504 (A-MSE: 1.69227) avg lploss: 0.00000
train epoch 344 avg loss: 2.09341 (A-MSE: 1.70227) avg lploss: 0.00000
train epoch 345 avg loss: 2.13880 (A-MSE: 1.73013) avg lploss: 0.00000
==> val epoch 345 avg loss: 2.90340 (A-MSE: 2.34007) avg lploss: 0.00000
==> test epoch 345 avg loss: 3.30754 (A-MSE: 2.71608) avg lploss: 0.00000
*** Best Val Loss: 2.78191 	 Best Test Loss: 3.26594 	 Best epoch 315
EarlyStopping counter: 6 out of 50
train epoch 346 avg loss: 2.29080 (A-MSE: 1.88960) avg lploss: 0.00000
train epoch 347 avg loss: 2.29182 (A-MSE: 1.85950) avg lploss: 0.00000
train epoch 348 avg loss: 2.19293 (A-MSE: 1.79560) avg lploss: 0.00000
train epoch 349 avg loss: 2.06061 (A-MSE: 1.67789) avg lploss: 0.00000
train epoch 350 avg loss: 2.01421 (A-MSE: 1.63245) avg lploss: 0.00000
==> val epoch 350 avg loss: 2.56991 (A-MSE: 1.95967) avg lploss: 0.00000
==> test epoch 350 avg loss: 3.01076 (A-MSE: 2.38568) avg lploss: 0.00000
*** Best Val Loss: 2.56991 	 Best Test Loss: 3.01076 	 Best epoch 350
Validation loss decreased (2.781908 --> 2.569915).  Saving model ...
train epoch 351 avg loss: 1.95559 (A-MSE: 1.58442) avg lploss: 0.00000
train epoch 352 avg loss: 1.89853 (A-MSE: 1.51634) avg lploss: 0.00000
train epoch 353 avg loss: 1.84742 (A-MSE: 1.49692) avg lploss: 0.00000
train epoch 354 avg loss: 1.88788 (A-MSE: 1.52993) avg lploss: 0.00000
train epoch 355 avg loss: 1.92630 (A-MSE: 1.55877) avg lploss: 0.00000
==> val epoch 355 avg loss: 2.51599 (A-MSE: 2.07501) avg lploss: 0.00000
==> test epoch 355 avg loss: 2.94549 (A-MSE: 2.46845) avg lploss: 0.00000
*** Best Val Loss: 2.51599 	 Best Test Loss: 2.94549 	 Best epoch 355
Validation loss decreased (2.569915 --> 2.515994).  Saving model ...
train epoch 356 avg loss: 1.87401 (A-MSE: 1.53574) avg lploss: 0.00000
train epoch 357 avg loss: 1.85882 (A-MSE: 1.49902) avg lploss: 0.00000
train epoch 358 avg loss: 1.81234 (A-MSE: 1.48045) avg lploss: 0.00000
train epoch 359 avg loss: 1.95720 (A-MSE: 1.60971) avg lploss: 0.00000
train epoch 360 avg loss: 1.82241 (A-MSE: 1.47820) avg lploss: 0.00000
==> val epoch 360 avg loss: 2.57623 (A-MSE: 1.99872) avg lploss: 0.00000
==> test epoch 360 avg loss: 3.06220 (A-MSE: 2.45287) avg lploss: 0.00000
*** Best Val Loss: 2.51599 	 Best Test Loss: 2.94549 	 Best epoch 355
EarlyStopping counter: 1 out of 50
train epoch 361 avg loss: 1.78385 (A-MSE: 1.43657) avg lploss: 0.00000
train epoch 362 avg loss: 1.87889 (A-MSE: 1.54566) avg lploss: 0.00000
train epoch 363 avg loss: 1.94362 (A-MSE: 1.58532) avg lploss: 0.00000
train epoch 364 avg loss: 1.90637 (A-MSE: 1.56778) avg lploss: 0.00000
train epoch 365 avg loss: 1.89029 (A-MSE: 1.52937) avg lploss: 0.00000
==> val epoch 365 avg loss: 2.50676 (A-MSE: 2.02857) avg lploss: 0.00000
==> test epoch 365 avg loss: 2.98421 (A-MSE: 2.47243) avg lploss: 0.00000
*** Best Val Loss: 2.50676 	 Best Test Loss: 2.98421 	 Best epoch 365
Validation loss decreased (2.515994 --> 2.506756).  Saving model ...
train epoch 366 avg loss: 1.73865 (A-MSE: 1.43837) avg lploss: 0.00000
train epoch 367 avg loss: 1.78503 (A-MSE: 1.46046) avg lploss: 0.00000
train epoch 368 avg loss: 1.81122 (A-MSE: 1.47033) avg lploss: 0.00000
train epoch 369 avg loss: 1.72220 (A-MSE: 1.40538) avg lploss: 0.00000
train epoch 370 avg loss: 1.71618 (A-MSE: 1.41172) avg lploss: 0.00000
==> val epoch 370 avg loss: 2.50445 (A-MSE: 1.94046) avg lploss: 0.00000
==> test epoch 370 avg loss: 2.94461 (A-MSE: 2.35533) avg lploss: 0.00000
*** Best Val Loss: 2.50445 	 Best Test Loss: 2.94461 	 Best epoch 370
Validation loss decreased (2.506756 --> 2.504448).  Saving model ...
train epoch 371 avg loss: 1.71776 (A-MSE: 1.40867) avg lploss: 0.00000
train epoch 372 avg loss: 1.69097 (A-MSE: 1.37938) avg lploss: 0.00000
train epoch 373 avg loss: 1.72322 (A-MSE: 1.40775) avg lploss: 0.00000
train epoch 374 avg loss: 1.70528 (A-MSE: 1.40118) avg lploss: 0.00000
train epoch 375 avg loss: 1.71229 (A-MSE: 1.41045) avg lploss: 0.00000
==> val epoch 375 avg loss: 2.37993 (A-MSE: 1.90547) avg lploss: 0.00000
==> test epoch 375 avg loss: 2.80429 (A-MSE: 2.31320) avg lploss: 0.00000
*** Best Val Loss: 2.37993 	 Best Test Loss: 2.80429 	 Best epoch 375
Validation loss decreased (2.504448 --> 2.379927).  Saving model ...
train epoch 376 avg loss: 1.75363 (A-MSE: 1.43649) avg lploss: 0.00000
train epoch 377 avg loss: 1.73643 (A-MSE: 1.43237) avg lploss: 0.00000
train epoch 378 avg loss: 1.69611 (A-MSE: 1.39369) avg lploss: 0.00000
train epoch 379 avg loss: 1.66785 (A-MSE: 1.36803) avg lploss: 0.00000
train epoch 380 avg loss: 1.71246 (A-MSE: 1.41586) avg lploss: 0.00000
==> val epoch 380 avg loss: 2.25904 (A-MSE: 1.82585) avg lploss: 0.00000
==> test epoch 380 avg loss: 2.67018 (A-MSE: 2.20869) avg lploss: 0.00000
*** Best Val Loss: 2.25904 	 Best Test Loss: 2.67018 	 Best epoch 380
Validation loss decreased (2.379927 --> 2.259035).  Saving model ...
train epoch 381 avg loss: 1.63601 (A-MSE: 1.35856) avg lploss: 0.00000
train epoch 382 avg loss: 1.71710 (A-MSE: 1.40020) avg lploss: 0.00000
train epoch 383 avg loss: 1.70486 (A-MSE: 1.40731) avg lploss: 0.00000
train epoch 384 avg loss: 1.72672 (A-MSE: 1.43211) avg lploss: 0.00000
train epoch 385 avg loss: 1.65245 (A-MSE: 1.36399) avg lploss: 0.00000
==> val epoch 385 avg loss: 2.31884 (A-MSE: 1.81362) avg lploss: 0.00000
==> test epoch 385 avg loss: 2.70079 (A-MSE: 2.18368) avg lploss: 0.00000
*** Best Val Loss: 2.25904 	 Best Test Loss: 2.67018 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 1.66520 (A-MSE: 1.36717) avg lploss: 0.00000
train epoch 387 avg loss: 1.74914 (A-MSE: 1.45198) avg lploss: 0.00000
train epoch 388 avg loss: 1.75710 (A-MSE: 1.45251) avg lploss: 0.00000
train epoch 389 avg loss: 1.73088 (A-MSE: 1.42696) avg lploss: 0.00000
train epoch 390 avg loss: 1.72065 (A-MSE: 1.42883) avg lploss: 0.00000
==> val epoch 390 avg loss: 2.06665 (A-MSE: 1.72105) avg lploss: 0.00000
==> test epoch 390 avg loss: 2.43780 (A-MSE: 2.06653) avg lploss: 0.00000
*** Best Val Loss: 2.06665 	 Best Test Loss: 2.43780 	 Best epoch 390
Validation loss decreased (2.259035 --> 2.066645).  Saving model ...
train epoch 391 avg loss: 1.63435 (A-MSE: 1.34296) avg lploss: 0.00000
train epoch 392 avg loss: 1.62102 (A-MSE: 1.35089) avg lploss: 0.00000
train epoch 393 avg loss: 1.67159 (A-MSE: 1.36571) avg lploss: 0.00000
train epoch 394 avg loss: 1.65040 (A-MSE: 1.35313) avg lploss: 0.00000
train epoch 395 avg loss: 1.77305 (A-MSE: 1.47002) avg lploss: 0.00000
==> val epoch 395 avg loss: 2.15041 (A-MSE: 1.75120) avg lploss: 0.00000
==> test epoch 395 avg loss: 2.55362 (A-MSE: 2.12966) avg lploss: 0.00000
*** Best Val Loss: 2.06665 	 Best Test Loss: 2.43780 	 Best epoch 390
EarlyStopping counter: 1 out of 50
train epoch 396 avg loss: 1.56885 (A-MSE: 1.30743) avg lploss: 0.00000
train epoch 397 avg loss: 1.55996 (A-MSE: 1.28610) avg lploss: 0.00000
train epoch 398 avg loss: 1.63207 (A-MSE: 1.33435) avg lploss: 0.00000
train epoch 399 avg loss: 1.66782 (A-MSE: 1.38751) avg lploss: 0.00000
train epoch 400 avg loss: 1.65858 (A-MSE: 1.39405) avg lploss: 0.00000
==> val epoch 400 avg loss: 2.64092 (A-MSE: 2.04246) avg lploss: 0.00000
==> test epoch 400 avg loss: 3.07493 (A-MSE: 2.44454) avg lploss: 0.00000
*** Best Val Loss: 2.06665 	 Best Test Loss: 2.43780 	 Best epoch 390
EarlyStopping counter: 2 out of 50
train epoch 401 avg loss: 1.58281 (A-MSE: 1.30271) avg lploss: 0.00000
train epoch 402 avg loss: 1.56731 (A-MSE: 1.29557) avg lploss: 0.00000
train epoch 403 avg loss: 1.56748 (A-MSE: 1.30161) avg lploss: 0.00000
train epoch 404 avg loss: 1.52888 (A-MSE: 1.25947) avg lploss: 0.00000
train epoch 405 avg loss: 1.52124 (A-MSE: 1.25791) avg lploss: 0.00000
==> val epoch 405 avg loss: 2.09740 (A-MSE: 1.68017) avg lploss: 0.00000
==> test epoch 405 avg loss: 2.51201 (A-MSE: 2.07041) avg lploss: 0.00000
*** Best Val Loss: 2.06665 	 Best Test Loss: 2.43780 	 Best epoch 390
EarlyStopping counter: 3 out of 50
train epoch 406 avg loss: 1.58304 (A-MSE: 1.31411) avg lploss: 0.00000
train epoch 407 avg loss: 1.55860 (A-MSE: 1.29712) avg lploss: 0.00000
train epoch 408 avg loss: 1.54572 (A-MSE: 1.27575) avg lploss: 0.00000
train epoch 409 avg loss: 1.59357 (A-MSE: 1.33671) avg lploss: 0.00000
train epoch 410 avg loss: 1.50435 (A-MSE: 1.24751) avg lploss: 0.00000
==> val epoch 410 avg loss: 2.05865 (A-MSE: 1.65128) avg lploss: 0.00000
==> test epoch 410 avg loss: 2.40631 (A-MSE: 1.98343) avg lploss: 0.00000
*** Best Val Loss: 2.05865 	 Best Test Loss: 2.40631 	 Best epoch 410
Validation loss decreased (2.066645 --> 2.058651).  Saving model ...
train epoch 411 avg loss: 1.48439 (A-MSE: 1.23020) avg lploss: 0.00000
train epoch 412 avg loss: 1.51536 (A-MSE: 1.26393) avg lploss: 0.00000
train epoch 413 avg loss: 1.55675 (A-MSE: 1.29093) avg lploss: 0.00000
train epoch 414 avg loss: 1.66394 (A-MSE: 1.38286) avg lploss: 0.00000
train epoch 415 avg loss: 1.72177 (A-MSE: 1.44075) avg lploss: 0.00000
==> val epoch 415 avg loss: 2.04504 (A-MSE: 1.68104) avg lploss: 0.00000
==> test epoch 415 avg loss: 2.43549 (A-MSE: 2.04420) avg lploss: 0.00000
*** Best Val Loss: 2.04504 	 Best Test Loss: 2.43549 	 Best epoch 415
Validation loss decreased (2.058651 --> 2.045039).  Saving model ...
train epoch 416 avg loss: 1.51827 (A-MSE: 1.26714) avg lploss: 0.00000
train epoch 417 avg loss: 1.58474 (A-MSE: 1.31558) avg lploss: 0.00000
train epoch 418 avg loss: 1.56926 (A-MSE: 1.30699) avg lploss: 0.00000
train epoch 419 avg loss: 1.56525 (A-MSE: 1.30590) avg lploss: 0.00000
train epoch 420 avg loss: 1.59395 (A-MSE: 1.33092) avg lploss: 0.00000
==> val epoch 420 avg loss: 2.16244 (A-MSE: 1.68939) avg lploss: 0.00000
==> test epoch 420 avg loss: 2.54003 (A-MSE: 2.05170) avg lploss: 0.00000
*** Best Val Loss: 2.04504 	 Best Test Loss: 2.43549 	 Best epoch 415
EarlyStopping counter: 1 out of 50
train epoch 421 avg loss: 1.49459 (A-MSE: 1.23645) avg lploss: 0.00000
train epoch 422 avg loss: 1.44339 (A-MSE: 1.20173) avg lploss: 0.00000
train epoch 423 avg loss: 1.48807 (A-MSE: 1.24089) avg lploss: 0.00000
train epoch 424 avg loss: 1.48764 (A-MSE: 1.23598) avg lploss: 0.00000
train epoch 425 avg loss: 1.43291 (A-MSE: 1.18228) avg lploss: 0.00000
==> val epoch 425 avg loss: 1.95098 (A-MSE: 1.61515) avg lploss: 0.00000
==> test epoch 425 avg loss: 2.35570 (A-MSE: 1.98980) avg lploss: 0.00000
*** Best Val Loss: 1.95098 	 Best Test Loss: 2.35570 	 Best epoch 425
Validation loss decreased (2.045039 --> 1.950976).  Saving model ...
train epoch 426 avg loss: 1.44245 (A-MSE: 1.21617) avg lploss: 0.00000
train epoch 427 avg loss: 1.60103 (A-MSE: 1.33274) avg lploss: 0.00000
train epoch 428 avg loss: 1.52685 (A-MSE: 1.28168) avg lploss: 0.00000
train epoch 429 avg loss: 1.38668 (A-MSE: 1.15085) avg lploss: 0.00000
train epoch 430 avg loss: 1.38784 (A-MSE: 1.15217) avg lploss: 0.00000
==> val epoch 430 avg loss: 2.07503 (A-MSE: 1.72236) avg lploss: 0.00000
==> test epoch 430 avg loss: 2.46721 (A-MSE: 2.09155) avg lploss: 0.00000
*** Best Val Loss: 1.95098 	 Best Test Loss: 2.35570 	 Best epoch 425
EarlyStopping counter: 1 out of 50
train epoch 431 avg loss: 1.47768 (A-MSE: 1.23321) avg lploss: 0.00000
train epoch 432 avg loss: 1.53792 (A-MSE: 1.30425) avg lploss: 0.00000
train epoch 433 avg loss: 1.46227 (A-MSE: 1.19794) avg lploss: 0.00000
train epoch 434 avg loss: 1.50952 (A-MSE: 1.29004) avg lploss: 0.00000
train epoch 435 avg loss: 1.55018 (A-MSE: 1.27954) avg lploss: 0.00000
==> val epoch 435 avg loss: 2.16950 (A-MSE: 1.76991) avg lploss: 0.00000
==> test epoch 435 avg loss: 2.59786 (A-MSE: 2.15931) avg lploss: 0.00000
*** Best Val Loss: 1.95098 	 Best Test Loss: 2.35570 	 Best epoch 425
EarlyStopping counter: 2 out of 50
train epoch 436 avg loss: 1.42440 (A-MSE: 1.20196) avg lploss: 0.00000
train epoch 437 avg loss: 1.42512 (A-MSE: 1.18028) avg lploss: 0.00000
train epoch 438 avg loss: 1.38335 (A-MSE: 1.15613) avg lploss: 0.00000
train epoch 439 avg loss: 1.41508 (A-MSE: 1.19174) avg lploss: 0.00000
train epoch 440 avg loss: 1.56114 (A-MSE: 1.29908) avg lploss: 0.00000
==> val epoch 440 avg loss: 1.90658 (A-MSE: 1.59094) avg lploss: 0.00000
==> test epoch 440 avg loss: 2.20297 (A-MSE: 1.87101) avg lploss: 0.00000
*** Best Val Loss: 1.90658 	 Best Test Loss: 2.20297 	 Best epoch 440
Validation loss decreased (1.950976 --> 1.906582).  Saving model ...
train epoch 441 avg loss: 1.49931 (A-MSE: 1.26133) avg lploss: 0.00000
train epoch 442 avg loss: 1.44662 (A-MSE: 1.20295) avg lploss: 0.00000
train epoch 443 avg loss: 1.50375 (A-MSE: 1.27868) avg lploss: 0.00000
train epoch 444 avg loss: 1.37746 (A-MSE: 1.13750) avg lploss: 0.00000
train epoch 445 avg loss: 1.40777 (A-MSE: 1.16869) avg lploss: 0.00000
==> val epoch 445 avg loss: 2.09539 (A-MSE: 1.70701) avg lploss: 0.00000
==> test epoch 445 avg loss: 2.45841 (A-MSE: 2.04437) avg lploss: 0.00000
*** Best Val Loss: 1.90658 	 Best Test Loss: 2.20297 	 Best epoch 440
EarlyStopping counter: 1 out of 50
train epoch 446 avg loss: 1.39174 (A-MSE: 1.16153) avg lploss: 0.00000
train epoch 447 avg loss: 1.41601 (A-MSE: 1.18259) avg lploss: 0.00000
train epoch 448 avg loss: 1.32398 (A-MSE: 1.10940) avg lploss: 0.00000
train epoch 449 avg loss: 1.37118 (A-MSE: 1.15108) avg lploss: 0.00000
train epoch 450 avg loss: 1.34104 (A-MSE: 1.12124) avg lploss: 0.00000
==> val epoch 450 avg loss: 2.24337 (A-MSE: 1.84417) avg lploss: 0.00000
==> test epoch 450 avg loss: 2.67206 (A-MSE: 2.22814) avg lploss: 0.00000
*** Best Val Loss: 1.90658 	 Best Test Loss: 2.20297 	 Best epoch 440
EarlyStopping counter: 2 out of 50
train epoch 451 avg loss: 1.28716 (A-MSE: 1.07264) avg lploss: 0.00000
train epoch 452 avg loss: 1.33966 (A-MSE: 1.12278) avg lploss: 0.00000
train epoch 453 avg loss: 1.37707 (A-MSE: 1.15368) avg lploss: 0.00000
train epoch 454 avg loss: 1.42799 (A-MSE: 1.19376) avg lploss: 0.00000
train epoch 455 avg loss: 1.33240 (A-MSE: 1.12346) avg lploss: 0.00000
==> val epoch 455 avg loss: 1.85204 (A-MSE: 1.52936) avg lploss: 0.00000
==> test epoch 455 avg loss: 2.16571 (A-MSE: 1.81661) avg lploss: 0.00000
*** Best Val Loss: 1.85204 	 Best Test Loss: 2.16571 	 Best epoch 455
Validation loss decreased (1.906582 --> 1.852036).  Saving model ...
train epoch 456 avg loss: 1.31750 (A-MSE: 1.09632) avg lploss: 0.00000
train epoch 457 avg loss: 1.29145 (A-MSE: 1.08565) avg lploss: 0.00000
train epoch 458 avg loss: 1.34538 (A-MSE: 1.12349) avg lploss: 0.00000
train epoch 459 avg loss: 1.36109 (A-MSE: 1.15242) avg lploss: 0.00000
train epoch 460 avg loss: 1.39619 (A-MSE: 1.16660) avg lploss: 0.00000
==> val epoch 460 avg loss: 1.92488 (A-MSE: 1.60224) avg lploss: 0.00000
==> test epoch 460 avg loss: 2.29862 (A-MSE: 1.95137) avg lploss: 0.00000
*** Best Val Loss: 1.85204 	 Best Test Loss: 2.16571 	 Best epoch 455
EarlyStopping counter: 1 out of 50
train epoch 461 avg loss: 1.39363 (A-MSE: 1.17635) avg lploss: 0.00000
train epoch 462 avg loss: 1.41492 (A-MSE: 1.19295) avg lploss: 0.00000
train epoch 463 avg loss: 1.33892 (A-MSE: 1.10889) avg lploss: 0.00000
train epoch 464 avg loss: 1.33392 (A-MSE: 1.11994) avg lploss: 0.00000
train epoch 465 avg loss: 1.25902 (A-MSE: 1.05573) avg lploss: 0.00000
==> val epoch 465 avg loss: 2.02331 (A-MSE: 1.68051) avg lploss: 0.00000
==> test epoch 465 avg loss: 2.33078 (A-MSE: 1.96594) avg lploss: 0.00000
*** Best Val Loss: 1.85204 	 Best Test Loss: 2.16571 	 Best epoch 455
EarlyStopping counter: 2 out of 50
train epoch 466 avg loss: 1.33451 (A-MSE: 1.13994) avg lploss: 0.00000
train epoch 467 avg loss: 1.36760 (A-MSE: 1.13209) avg lploss: 0.00000
train epoch 468 avg loss: 1.48049 (A-MSE: 1.24903) avg lploss: 0.00000
train epoch 469 avg loss: 1.46874 (A-MSE: 1.24091) avg lploss: 0.00000
train epoch 470 avg loss: 1.34935 (A-MSE: 1.11064) avg lploss: 0.00000
==> val epoch 470 avg loss: 1.88513 (A-MSE: 1.56242) avg lploss: 0.00000
==> test epoch 470 avg loss: 2.25973 (A-MSE: 1.89949) avg lploss: 0.00000
*** Best Val Loss: 1.85204 	 Best Test Loss: 2.16571 	 Best epoch 455
EarlyStopping counter: 3 out of 50
train epoch 471 avg loss: 1.30977 (A-MSE: 1.11444) avg lploss: 0.00000
train epoch 472 avg loss: 1.24662 (A-MSE: 1.03494) avg lploss: 0.00000
train epoch 473 avg loss: 1.19919 (A-MSE: 1.00639) avg lploss: 0.00000
train epoch 474 avg loss: 1.26069 (A-MSE: 1.06039) avg lploss: 0.00000
train epoch 475 avg loss: 1.34827 (A-MSE: 1.13474) avg lploss: 0.00000
==> val epoch 475 avg loss: 2.03312 (A-MSE: 1.63780) avg lploss: 0.00000
==> test epoch 475 avg loss: 2.33089 (A-MSE: 1.91521) avg lploss: 0.00000
*** Best Val Loss: 1.85204 	 Best Test Loss: 2.16571 	 Best epoch 455
EarlyStopping counter: 4 out of 50
train epoch 476 avg loss: 1.31514 (A-MSE: 1.11157) avg lploss: 0.00000
train epoch 477 avg loss: 1.35791 (A-MSE: 1.14633) avg lploss: 0.00000
train epoch 478 avg loss: 1.26162 (A-MSE: 1.05349) avg lploss: 0.00000
train epoch 479 avg loss: 1.24970 (A-MSE: 1.04352) avg lploss: 0.00000
train epoch 480 avg loss: 1.22355 (A-MSE: 1.02830) avg lploss: 0.00000
==> val epoch 480 avg loss: 2.00848 (A-MSE: 1.60118) avg lploss: 0.00000
==> test epoch 480 avg loss: 2.29982 (A-MSE: 1.87124) avg lploss: 0.00000
*** Best Val Loss: 1.85204 	 Best Test Loss: 2.16571 	 Best epoch 455
EarlyStopping counter: 5 out of 50
train epoch 481 avg loss: 1.22573 (A-MSE: 1.02426) avg lploss: 0.00000
train epoch 482 avg loss: 1.20324 (A-MSE: 1.01630) avg lploss: 0.00000
train epoch 483 avg loss: 1.24546 (A-MSE: 1.05459) avg lploss: 0.00000
train epoch 484 avg loss: 1.21025 (A-MSE: 1.01393) avg lploss: 0.00000
train epoch 485 avg loss: 1.19667 (A-MSE: 1.00399) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.69908 (A-MSE: 1.46533) avg lploss: 0.00000
==> test epoch 485 avg loss: 2.01872 (A-MSE: 1.75189) avg lploss: 0.00000
*** Best Val Loss: 1.69908 	 Best Test Loss: 2.01872 	 Best epoch 485
Validation loss decreased (1.852036 --> 1.699080).  Saving model ...
train epoch 486 avg loss: 1.24283 (A-MSE: 1.04230) avg lploss: 0.00000
train epoch 487 avg loss: 1.19246 (A-MSE: 1.00564) avg lploss: 0.00000
train epoch 488 avg loss: 1.25095 (A-MSE: 1.05722) avg lploss: 0.00000
train epoch 489 avg loss: 1.26787 (A-MSE: 1.07473) avg lploss: 0.00000
train epoch 490 avg loss: 1.24030 (A-MSE: 1.04019) avg lploss: 0.00000
==> val epoch 490 avg loss: 1.92227 (A-MSE: 1.58934) avg lploss: 0.00000
==> test epoch 490 avg loss: 2.23817 (A-MSE: 1.88533) avg lploss: 0.00000
*** Best Val Loss: 1.69908 	 Best Test Loss: 2.01872 	 Best epoch 485
EarlyStopping counter: 1 out of 50
train epoch 491 avg loss: 1.25287 (A-MSE: 1.05949) avg lploss: 0.00000
train epoch 492 avg loss: 1.16933 (A-MSE: 0.98829) avg lploss: 0.00000
train epoch 493 avg loss: 1.15541 (A-MSE: 0.96507) avg lploss: 0.00000
train epoch 494 avg loss: 1.17254 (A-MSE: 0.98089) avg lploss: 0.00000
train epoch 495 avg loss: 1.15861 (A-MSE: 0.98342) avg lploss: 0.00000
==> val epoch 495 avg loss: 2.03902 (A-MSE: 1.65712) avg lploss: 0.00000
==> test epoch 495 avg loss: 2.33711 (A-MSE: 1.93014) avg lploss: 0.00000
*** Best Val Loss: 1.69908 	 Best Test Loss: 2.01872 	 Best epoch 485
EarlyStopping counter: 2 out of 50
train epoch 496 avg loss: 1.26319 (A-MSE: 1.06728) avg lploss: 0.00000
train epoch 497 avg loss: 1.22989 (A-MSE: 1.03997) avg lploss: 0.00000
train epoch 498 avg loss: 1.15444 (A-MSE: 0.97693) avg lploss: 0.00000
train epoch 499 avg loss: 1.30510 (A-MSE: 1.10735) avg lploss: 0.00000
train epoch 500 avg loss: 1.31270 (A-MSE: 1.09206) avg lploss: 0.00000
==> val epoch 500 avg loss: 1.67266 (A-MSE: 1.45242) avg lploss: 0.00000
==> test epoch 500 avg loss: 2.00106 (A-MSE: 1.73704) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
Validation loss decreased (1.699080 --> 1.672662).  Saving model ...
train epoch 501 avg loss: 1.19573 (A-MSE: 1.01351) avg lploss: 0.00000
train epoch 502 avg loss: 1.20652 (A-MSE: 1.02328) avg lploss: 0.00000
train epoch 503 avg loss: 1.19198 (A-MSE: 1.00129) avg lploss: 0.00000
train epoch 504 avg loss: 1.19630 (A-MSE: 1.01235) avg lploss: 0.00000
train epoch 505 avg loss: 1.15850 (A-MSE: 0.96837) avg lploss: 0.00000
==> val epoch 505 avg loss: 2.14846 (A-MSE: 1.74865) avg lploss: 0.00000
==> test epoch 505 avg loss: 2.55907 (A-MSE: 2.12505) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 1 out of 50
train epoch 506 avg loss: 1.19188 (A-MSE: 1.01243) avg lploss: 0.00000
train epoch 507 avg loss: 1.17684 (A-MSE: 0.98596) avg lploss: 0.00000
train epoch 508 avg loss: 1.10278 (A-MSE: 0.92429) avg lploss: 0.00000
train epoch 509 avg loss: 1.13880 (A-MSE: 0.95679) avg lploss: 0.00000
train epoch 510 avg loss: 1.11915 (A-MSE: 0.95385) avg lploss: 0.00000
==> val epoch 510 avg loss: 2.12043 (A-MSE: 1.77766) avg lploss: 0.00000
==> test epoch 510 avg loss: 2.44612 (A-MSE: 2.08080) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 2 out of 50
train epoch 511 avg loss: 1.20219 (A-MSE: 1.02048) avg lploss: 0.00000
train epoch 512 avg loss: 1.18231 (A-MSE: 0.99062) avg lploss: 0.00000
train epoch 513 avg loss: 1.16662 (A-MSE: 0.98818) avg lploss: 0.00000
train epoch 514 avg loss: 1.15177 (A-MSE: 0.97122) avg lploss: 0.00000
train epoch 515 avg loss: 1.18505 (A-MSE: 0.99387) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.94991 (A-MSE: 1.56685) avg lploss: 0.00000
==> test epoch 515 avg loss: 2.31187 (A-MSE: 1.90167) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 3 out of 50
train epoch 516 avg loss: 1.12016 (A-MSE: 0.94978) avg lploss: 0.00000
train epoch 517 avg loss: 1.11054 (A-MSE: 0.94309) avg lploss: 0.00000
train epoch 518 avg loss: 1.12922 (A-MSE: 0.95363) avg lploss: 0.00000
train epoch 519 avg loss: 1.21656 (A-MSE: 1.01448) avg lploss: 0.00000
train epoch 520 avg loss: 1.24739 (A-MSE: 1.07583) avg lploss: 0.00000
==> val epoch 520 avg loss: 2.28218 (A-MSE: 1.73119) avg lploss: 0.00000
==> test epoch 520 avg loss: 2.61697 (A-MSE: 2.05550) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 4 out of 50
train epoch 521 avg loss: 1.24350 (A-MSE: 1.02861) avg lploss: 0.00000
train epoch 522 avg loss: 1.22373 (A-MSE: 1.03983) avg lploss: 0.00000
train epoch 523 avg loss: 1.17575 (A-MSE: 0.97962) avg lploss: 0.00000
train epoch 524 avg loss: 1.23562 (A-MSE: 1.05607) avg lploss: 0.00000
train epoch 525 avg loss: 1.19674 (A-MSE: 1.00751) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.89541 (A-MSE: 1.50197) avg lploss: 0.00000
==> test epoch 525 avg loss: 2.31798 (A-MSE: 1.89365) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 5 out of 50
train epoch 526 avg loss: 1.29861 (A-MSE: 1.10133) avg lploss: 0.00000
train epoch 527 avg loss: 1.17138 (A-MSE: 0.98734) avg lploss: 0.00000
train epoch 528 avg loss: 1.13296 (A-MSE: 0.96331) avg lploss: 0.00000
train epoch 529 avg loss: 1.09370 (A-MSE: 0.91801) avg lploss: 0.00000
train epoch 530 avg loss: 1.07738 (A-MSE: 0.91471) avg lploss: 0.00000
==> val epoch 530 avg loss: 2.02607 (A-MSE: 1.61539) avg lploss: 0.00000
==> test epoch 530 avg loss: 2.34139 (A-MSE: 1.91346) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 6 out of 50
train epoch 531 avg loss: 1.08669 (A-MSE: 0.90648) avg lploss: 0.00000
train epoch 532 avg loss: 1.24956 (A-MSE: 1.05979) avg lploss: 0.00000
train epoch 533 avg loss: 1.15228 (A-MSE: 0.98254) avg lploss: 0.00000
train epoch 534 avg loss: 1.18749 (A-MSE: 0.99645) avg lploss: 0.00000
train epoch 535 avg loss: 1.05470 (A-MSE: 0.88438) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.81612 (A-MSE: 1.52846) avg lploss: 0.00000
==> test epoch 535 avg loss: 2.21061 (A-MSE: 1.88058) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 7 out of 50
train epoch 536 avg loss: 1.07346 (A-MSE: 0.91536) avg lploss: 0.00000
train epoch 537 avg loss: 1.12526 (A-MSE: 0.94227) avg lploss: 0.00000
train epoch 538 avg loss: 1.14115 (A-MSE: 0.95857) avg lploss: 0.00000
train epoch 539 avg loss: 1.09100 (A-MSE: 0.92928) avg lploss: 0.00000
train epoch 540 avg loss: 1.07221 (A-MSE: 0.89723) avg lploss: 0.00000
==> val epoch 540 avg loss: 1.89724 (A-MSE: 1.60524) avg lploss: 0.00000
==> test epoch 540 avg loss: 2.17561 (A-MSE: 1.87411) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 8 out of 50
train epoch 541 avg loss: 1.07506 (A-MSE: 0.91827) avg lploss: 0.00000
train epoch 542 avg loss: 1.10581 (A-MSE: 0.91898) avg lploss: 0.00000
train epoch 543 avg loss: 1.08527 (A-MSE: 0.91863) avg lploss: 0.00000
train epoch 544 avg loss: 1.16578 (A-MSE: 0.98845) avg lploss: 0.00000
train epoch 545 avg loss: 1.04478 (A-MSE: 0.88400) avg lploss: 0.00000
==> val epoch 545 avg loss: 1.76383 (A-MSE: 1.41653) avg lploss: 0.00000
==> test epoch 545 avg loss: 2.09781 (A-MSE: 1.72633) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 9 out of 50
train epoch 546 avg loss: 1.03865 (A-MSE: 0.87497) avg lploss: 0.00000
train epoch 547 avg loss: 1.01016 (A-MSE: 0.85823) avg lploss: 0.00000
train epoch 548 avg loss: 1.05618 (A-MSE: 0.89171) avg lploss: 0.00000
train epoch 549 avg loss: 1.09110 (A-MSE: 0.92222) avg lploss: 0.00000
train epoch 550 avg loss: 1.11239 (A-MSE: 0.94012) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.88515 (A-MSE: 1.54540) avg lploss: 0.00000
==> test epoch 550 avg loss: 2.25412 (A-MSE: 1.87576) avg lploss: 0.00000
*** Best Val Loss: 1.67266 	 Best Test Loss: 2.00106 	 Best epoch 500
EarlyStopping counter: 10 out of 50
train epoch 551 avg loss: 1.07828 (A-MSE: 0.91581) avg lploss: 0.00000
train epoch 552 avg loss: 1.07563 (A-MSE: 0.89881) avg lploss: 0.00000
train epoch 553 avg loss: 1.14400 (A-MSE: 0.96403) avg lploss: 0.00000
train epoch 554 avg loss: 1.04923 (A-MSE: 0.88767) avg lploss: 0.00000
train epoch 555 avg loss: 1.05425 (A-MSE: 0.88805) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.66246 (A-MSE: 1.47406) avg lploss: 0.00000
==> test epoch 555 avg loss: 1.96129 (A-MSE: 1.74837) avg lploss: 0.00000
*** Best Val Loss: 1.66246 	 Best Test Loss: 1.96129 	 Best epoch 555
Validation loss decreased (1.672662 --> 1.662463).  Saving model ...
train epoch 556 avg loss: 1.03084 (A-MSE: 0.87379) avg lploss: 0.00000
train epoch 557 avg loss: 1.02064 (A-MSE: 0.86369) avg lploss: 0.00000
train epoch 558 avg loss: 1.16073 (A-MSE: 0.98116) avg lploss: 0.00000
train epoch 559 avg loss: 1.18089 (A-MSE: 0.99355) avg lploss: 0.00000
train epoch 560 avg loss: 1.06870 (A-MSE: 0.89189) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.71143 (A-MSE: 1.46371) avg lploss: 0.00000
==> test epoch 560 avg loss: 1.97710 (A-MSE: 1.70190) avg lploss: 0.00000
*** Best Val Loss: 1.66246 	 Best Test Loss: 1.96129 	 Best epoch 555
EarlyStopping counter: 1 out of 50
train epoch 561 avg loss: 1.07986 (A-MSE: 0.92693) avg lploss: 0.00000
train epoch 562 avg loss: 1.05459 (A-MSE: 0.88896) avg lploss: 0.00000
train epoch 563 avg loss: 1.05879 (A-MSE: 0.88897) avg lploss: 0.00000
train epoch 564 avg loss: 1.06308 (A-MSE: 0.89669) avg lploss: 0.00000
train epoch 565 avg loss: 1.02185 (A-MSE: 0.85970) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.65580 (A-MSE: 1.41275) avg lploss: 0.00000
==> test epoch 565 avg loss: 1.92838 (A-MSE: 1.65976) avg lploss: 0.00000
*** Best Val Loss: 1.65580 	 Best Test Loss: 1.92838 	 Best epoch 565
Validation loss decreased (1.662463 --> 1.655798).  Saving model ...
train epoch 566 avg loss: 0.99325 (A-MSE: 0.84704) avg lploss: 0.00000
train epoch 567 avg loss: 1.02811 (A-MSE: 0.86549) avg lploss: 0.00000
train epoch 568 avg loss: 1.02146 (A-MSE: 0.85547) avg lploss: 0.00000
train epoch 569 avg loss: 0.99471 (A-MSE: 0.84122) avg lploss: 0.00000
train epoch 570 avg loss: 1.08110 (A-MSE: 0.91612) avg lploss: 0.00000
==> val epoch 570 avg loss: 2.02091 (A-MSE: 1.71316) avg lploss: 0.00000
==> test epoch 570 avg loss: 2.36974 (A-MSE: 2.05059) avg lploss: 0.00000
*** Best Val Loss: 1.65580 	 Best Test Loss: 1.92838 	 Best epoch 565
EarlyStopping counter: 1 out of 50
train epoch 571 avg loss: 1.12617 (A-MSE: 0.95464) avg lploss: 0.00000
train epoch 572 avg loss: 1.15994 (A-MSE: 0.98904) avg lploss: 0.00000
train epoch 573 avg loss: 1.05702 (A-MSE: 0.89572) avg lploss: 0.00000
train epoch 574 avg loss: 0.97344 (A-MSE: 0.81562) avg lploss: 0.00000
train epoch 575 avg loss: 1.00302 (A-MSE: 0.85082) avg lploss: 0.00000
==> val epoch 575 avg loss: 1.99048 (A-MSE: 1.57711) avg lploss: 0.00000
==> test epoch 575 avg loss: 2.29359 (A-MSE: 1.86455) avg lploss: 0.00000
*** Best Val Loss: 1.65580 	 Best Test Loss: 1.92838 	 Best epoch 565
EarlyStopping counter: 2 out of 50
train epoch 576 avg loss: 1.04375 (A-MSE: 0.88251) avg lploss: 0.00000
train epoch 577 avg loss: 1.07195 (A-MSE: 0.91628) avg lploss: 0.00000
train epoch 578 avg loss: 1.00754 (A-MSE: 0.84904) avg lploss: 0.00000
train epoch 579 avg loss: 0.99591 (A-MSE: 0.83917) avg lploss: 0.00000
train epoch 580 avg loss: 1.00487 (A-MSE: 0.86468) avg lploss: 0.00000
==> val epoch 580 avg loss: 2.29986 (A-MSE: 1.81181) avg lploss: 0.00000
==> test epoch 580 avg loss: 2.57456 (A-MSE: 2.07931) avg lploss: 0.00000
*** Best Val Loss: 1.65580 	 Best Test Loss: 1.92838 	 Best epoch 565
EarlyStopping counter: 3 out of 50
train epoch 581 avg loss: 1.10604 (A-MSE: 0.93502) avg lploss: 0.00000
train epoch 582 avg loss: 1.01651 (A-MSE: 0.85044) avg lploss: 0.00000
train epoch 583 avg loss: 0.99688 (A-MSE: 0.84614) avg lploss: 0.00000
train epoch 584 avg loss: 0.97100 (A-MSE: 0.82787) avg lploss: 0.00000
train epoch 585 avg loss: 0.99155 (A-MSE: 0.83334) avg lploss: 0.00000
==> val epoch 585 avg loss: 1.46297 (A-MSE: 1.27876) avg lploss: 0.00000
==> test epoch 585 avg loss: 1.78341 (A-MSE: 1.56770) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
Validation loss decreased (1.655798 --> 1.462973).  Saving model ...
train epoch 586 avg loss: 1.00733 (A-MSE: 0.85658) avg lploss: 0.00000
train epoch 587 avg loss: 0.97607 (A-MSE: 0.82043) avg lploss: 0.00000
train epoch 588 avg loss: 1.06218 (A-MSE: 0.90515) avg lploss: 0.00000
train epoch 589 avg loss: 0.93543 (A-MSE: 0.79170) avg lploss: 0.00000
train epoch 590 avg loss: 0.94809 (A-MSE: 0.80024) avg lploss: 0.00000
==> val epoch 590 avg loss: 1.96737 (A-MSE: 1.59382) avg lploss: 0.00000
==> test epoch 590 avg loss: 2.33352 (A-MSE: 1.93878) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 1 out of 50
train epoch 591 avg loss: 0.98364 (A-MSE: 0.82140) avg lploss: 0.00000
train epoch 592 avg loss: 0.91894 (A-MSE: 0.78663) avg lploss: 0.00000
train epoch 593 avg loss: 0.99089 (A-MSE: 0.84188) avg lploss: 0.00000
train epoch 594 avg loss: 0.94410 (A-MSE: 0.79696) avg lploss: 0.00000
train epoch 595 avg loss: 0.96109 (A-MSE: 0.80809) avg lploss: 0.00000
==> val epoch 595 avg loss: 1.56062 (A-MSE: 1.34631) avg lploss: 0.00000
==> test epoch 595 avg loss: 1.94518 (A-MSE: 1.69583) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 2 out of 50
train epoch 596 avg loss: 0.98767 (A-MSE: 0.83222) avg lploss: 0.00000
train epoch 597 avg loss: 0.98981 (A-MSE: 0.84795) avg lploss: 0.00000
train epoch 598 avg loss: 0.98975 (A-MSE: 0.82853) avg lploss: 0.00000
train epoch 599 avg loss: 0.94618 (A-MSE: 0.79872) avg lploss: 0.00000
train epoch 600 avg loss: 0.95683 (A-MSE: 0.80935) avg lploss: 0.00000
==> val epoch 600 avg loss: 1.79836 (A-MSE: 1.46513) avg lploss: 0.00000
==> test epoch 600 avg loss: 2.07165 (A-MSE: 1.71099) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 3 out of 50
train epoch 601 avg loss: 0.91858 (A-MSE: 0.77597) avg lploss: 0.00000
train epoch 602 avg loss: 0.92064 (A-MSE: 0.77580) avg lploss: 0.00000
train epoch 603 avg loss: 1.01068 (A-MSE: 0.85972) avg lploss: 0.00000
train epoch 604 avg loss: 1.01938 (A-MSE: 0.87080) avg lploss: 0.00000
train epoch 605 avg loss: 0.95792 (A-MSE: 0.79869) avg lploss: 0.00000
==> val epoch 605 avg loss: 1.78774 (A-MSE: 1.43913) avg lploss: 0.00000
==> test epoch 605 avg loss: 2.12044 (A-MSE: 1.75786) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 4 out of 50
train epoch 606 avg loss: 0.98226 (A-MSE: 0.83833) avg lploss: 0.00000
train epoch 607 avg loss: 0.96477 (A-MSE: 0.81182) avg lploss: 0.00000
train epoch 608 avg loss: 1.01495 (A-MSE: 0.85947) avg lploss: 0.00000
train epoch 609 avg loss: 0.98614 (A-MSE: 0.83265) avg lploss: 0.00000
train epoch 610 avg loss: 0.92238 (A-MSE: 0.77633) avg lploss: 0.00000
==> val epoch 610 avg loss: 1.77433 (A-MSE: 1.47700) avg lploss: 0.00000
==> test epoch 610 avg loss: 2.02837 (A-MSE: 1.71081) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 5 out of 50
train epoch 611 avg loss: 0.92646 (A-MSE: 0.78761) avg lploss: 0.00000
train epoch 612 avg loss: 0.95055 (A-MSE: 0.80535) avg lploss: 0.00000
train epoch 613 avg loss: 0.95433 (A-MSE: 0.80628) avg lploss: 0.00000
train epoch 614 avg loss: 0.88677 (A-MSE: 0.74920) avg lploss: 0.00000
train epoch 615 avg loss: 0.97604 (A-MSE: 0.83509) avg lploss: 0.00000
==> val epoch 615 avg loss: 1.71974 (A-MSE: 1.39947) avg lploss: 0.00000
==> test epoch 615 avg loss: 2.00555 (A-MSE: 1.67088) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 6 out of 50
train epoch 616 avg loss: 1.05396 (A-MSE: 0.87838) avg lploss: 0.00000
train epoch 617 avg loss: 0.94435 (A-MSE: 0.80260) avg lploss: 0.00000
train epoch 618 avg loss: 1.02902 (A-MSE: 0.87351) avg lploss: 0.00000
train epoch 619 avg loss: 0.96157 (A-MSE: 0.81068) avg lploss: 0.00000
train epoch 620 avg loss: 0.99185 (A-MSE: 0.84612) avg lploss: 0.00000
==> val epoch 620 avg loss: 2.02451 (A-MSE: 1.63352) avg lploss: 0.00000
==> test epoch 620 avg loss: 2.32124 (A-MSE: 1.90559) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 7 out of 50
train epoch 621 avg loss: 0.91880 (A-MSE: 0.77143) avg lploss: 0.00000
train epoch 622 avg loss: 0.88306 (A-MSE: 0.75334) avg lploss: 0.00000
train epoch 623 avg loss: 0.92413 (A-MSE: 0.78318) avg lploss: 0.00000
train epoch 624 avg loss: 0.89529 (A-MSE: 0.76187) avg lploss: 0.00000
train epoch 625 avg loss: 0.94906 (A-MSE: 0.79706) avg lploss: 0.00000
==> val epoch 625 avg loss: 1.68339 (A-MSE: 1.40141) avg lploss: 0.00000
==> test epoch 625 avg loss: 1.94488 (A-MSE: 1.65094) avg lploss: 0.00000
*** Best Val Loss: 1.46297 	 Best Test Loss: 1.78341 	 Best epoch 585
EarlyStopping counter: 8 out of 50
train epoch 626 avg loss: 1.04908 (A-MSE: 0.89685) avg lploss: 0.00000
train epoch 627 avg loss: 0.98720 (A-MSE: 0.83552) avg lploss: 0.00000
train epoch 628 avg loss: 0.95690 (A-MSE: 0.81068) avg lploss: 0.00000
train epoch 629 avg loss: 0.91660 (A-MSE: 0.78681) avg lploss: 0.00000
train epoch 630 avg loss: 0.90229 (A-MSE: 0.75949) avg lploss: 0.00000
==> val epoch 630 avg loss: 1.31328 (A-MSE: 1.12862) avg lploss: 0.00000
==> test epoch 630 avg loss: 1.63750 (A-MSE: 1.42004) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
Validation loss decreased (1.462973 --> 1.313283).  Saving model ...
train epoch 631 avg loss: 0.88525 (A-MSE: 0.74376) avg lploss: 0.00000
train epoch 632 avg loss: 0.96677 (A-MSE: 0.82001) avg lploss: 0.00000
train epoch 633 avg loss: 0.92368 (A-MSE: 0.79134) avg lploss: 0.00000
train epoch 634 avg loss: 0.91453 (A-MSE: 0.77256) avg lploss: 0.00000
train epoch 635 avg loss: 0.91988 (A-MSE: 0.78004) avg lploss: 0.00000
==> val epoch 635 avg loss: 1.46313 (A-MSE: 1.22823) avg lploss: 0.00000
==> test epoch 635 avg loss: 1.76003 (A-MSE: 1.50066) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 1 out of 50
train epoch 636 avg loss: 0.94081 (A-MSE: 0.80130) avg lploss: 0.00000
train epoch 637 avg loss: 0.85941 (A-MSE: 0.73146) avg lploss: 0.00000
train epoch 638 avg loss: 0.98073 (A-MSE: 0.82815) avg lploss: 0.00000
train epoch 639 avg loss: 0.97144 (A-MSE: 0.82061) avg lploss: 0.00000
train epoch 640 avg loss: 0.91777 (A-MSE: 0.78749) avg lploss: 0.00000
==> val epoch 640 avg loss: 1.60173 (A-MSE: 1.33126) avg lploss: 0.00000
==> test epoch 640 avg loss: 1.91740 (A-MSE: 1.63352) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 2 out of 50
train epoch 641 avg loss: 0.96713 (A-MSE: 0.82020) avg lploss: 0.00000
train epoch 642 avg loss: 0.87991 (A-MSE: 0.74305) avg lploss: 0.00000
train epoch 643 avg loss: 0.84735 (A-MSE: 0.72266) avg lploss: 0.00000
train epoch 644 avg loss: 0.92516 (A-MSE: 0.78452) avg lploss: 0.00000
train epoch 645 avg loss: 0.88627 (A-MSE: 0.74535) avg lploss: 0.00000
==> val epoch 645 avg loss: 1.41203 (A-MSE: 1.21011) avg lploss: 0.00000
==> test epoch 645 avg loss: 1.74418 (A-MSE: 1.51023) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 3 out of 50
train epoch 646 avg loss: 0.97356 (A-MSE: 0.82678) avg lploss: 0.00000
train epoch 647 avg loss: 0.89232 (A-MSE: 0.76661) avg lploss: 0.00000
train epoch 648 avg loss: 0.97695 (A-MSE: 0.82852) avg lploss: 0.00000
train epoch 649 avg loss: 0.99792 (A-MSE: 0.84504) avg lploss: 0.00000
train epoch 650 avg loss: 0.87271 (A-MSE: 0.73811) avg lploss: 0.00000
==> val epoch 650 avg loss: 1.49273 (A-MSE: 1.24895) avg lploss: 0.00000
==> test epoch 650 avg loss: 1.79126 (A-MSE: 1.52396) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 4 out of 50
train epoch 651 avg loss: 0.90229 (A-MSE: 0.75759) avg lploss: 0.00000
train epoch 652 avg loss: 0.89124 (A-MSE: 0.76684) avg lploss: 0.00000
train epoch 653 avg loss: 0.88045 (A-MSE: 0.73366) avg lploss: 0.00000
train epoch 654 avg loss: 0.84698 (A-MSE: 0.71355) avg lploss: 0.00000
train epoch 655 avg loss: 0.88039 (A-MSE: 0.74794) avg lploss: 0.00000
==> val epoch 655 avg loss: 1.40638 (A-MSE: 1.24448) avg lploss: 0.00000
==> test epoch 655 avg loss: 1.71445 (A-MSE: 1.52516) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 5 out of 50
train epoch 656 avg loss: 0.92311 (A-MSE: 0.78669) avg lploss: 0.00000
train epoch 657 avg loss: 0.96735 (A-MSE: 0.82583) avg lploss: 0.00000
train epoch 658 avg loss: 0.97512 (A-MSE: 0.82655) avg lploss: 0.00000
train epoch 659 avg loss: 1.00408 (A-MSE: 0.85498) avg lploss: 0.00000
train epoch 660 avg loss: 0.89573 (A-MSE: 0.75159) avg lploss: 0.00000
==> val epoch 660 avg loss: 1.42697 (A-MSE: 1.21669) avg lploss: 0.00000
==> test epoch 660 avg loss: 1.69468 (A-MSE: 1.46723) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 6 out of 50
train epoch 661 avg loss: 0.89640 (A-MSE: 0.76879) avg lploss: 0.00000
train epoch 662 avg loss: 0.86767 (A-MSE: 0.73394) avg lploss: 0.00000
train epoch 663 avg loss: 0.86633 (A-MSE: 0.73902) avg lploss: 0.00000
train epoch 664 avg loss: 0.85762 (A-MSE: 0.72497) avg lploss: 0.00000
train epoch 665 avg loss: 0.84749 (A-MSE: 0.71457) avg lploss: 0.00000
==> val epoch 665 avg loss: 1.81947 (A-MSE: 1.49628) avg lploss: 0.00000
==> test epoch 665 avg loss: 2.10239 (A-MSE: 1.75804) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 7 out of 50
train epoch 666 avg loss: 0.89206 (A-MSE: 0.74675) avg lploss: 0.00000
train epoch 667 avg loss: 0.91436 (A-MSE: 0.78167) avg lploss: 0.00000
train epoch 668 avg loss: 0.84499 (A-MSE: 0.72548) avg lploss: 0.00000
train epoch 669 avg loss: 0.88289 (A-MSE: 0.74829) avg lploss: 0.00000
train epoch 670 avg loss: 0.84411 (A-MSE: 0.72061) avg lploss: 0.00000
==> val epoch 670 avg loss: 1.47836 (A-MSE: 1.24431) avg lploss: 0.00000
==> test epoch 670 avg loss: 1.76056 (A-MSE: 1.49056) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 8 out of 50
train epoch 671 avg loss: 0.85045 (A-MSE: 0.72221) avg lploss: 0.00000
train epoch 672 avg loss: 0.91323 (A-MSE: 0.77688) avg lploss: 0.00000
train epoch 673 avg loss: 0.85776 (A-MSE: 0.72816) avg lploss: 0.00000
train epoch 674 avg loss: 0.93225 (A-MSE: 0.79420) avg lploss: 0.00000
train epoch 675 avg loss: 0.88032 (A-MSE: 0.75025) avg lploss: 0.00000
==> val epoch 675 avg loss: 1.53401 (A-MSE: 1.28510) avg lploss: 0.00000
==> test epoch 675 avg loss: 1.84262 (A-MSE: 1.57166) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 9 out of 50
train epoch 676 avg loss: 0.81440 (A-MSE: 0.68962) avg lploss: 0.00000
train epoch 677 avg loss: 0.83955 (A-MSE: 0.71315) avg lploss: 0.00000
train epoch 678 avg loss: 0.91654 (A-MSE: 0.78247) avg lploss: 0.00000
train epoch 679 avg loss: 0.84484 (A-MSE: 0.71744) avg lploss: 0.00000
train epoch 680 avg loss: 0.84903 (A-MSE: 0.71776) avg lploss: 0.00000
==> val epoch 680 avg loss: 1.34659 (A-MSE: 1.16784) avg lploss: 0.00000
==> test epoch 680 avg loss: 1.68322 (A-MSE: 1.46644) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 10 out of 50
train epoch 681 avg loss: 0.82086 (A-MSE: 0.69787) avg lploss: 0.00000
train epoch 682 avg loss: 0.87574 (A-MSE: 0.75366) avg lploss: 0.00000
train epoch 683 avg loss: 0.82839 (A-MSE: 0.70685) avg lploss: 0.00000
train epoch 684 avg loss: 0.86429 (A-MSE: 0.73355) avg lploss: 0.00000
train epoch 685 avg loss: 0.88816 (A-MSE: 0.75236) avg lploss: 0.00000
==> val epoch 685 avg loss: 1.36895 (A-MSE: 1.18653) avg lploss: 0.00000
==> test epoch 685 avg loss: 1.63811 (A-MSE: 1.43067) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 11 out of 50
train epoch 686 avg loss: 0.84391 (A-MSE: 0.72165) avg lploss: 0.00000
train epoch 687 avg loss: 0.77810 (A-MSE: 0.66038) avg lploss: 0.00000
train epoch 688 avg loss: 0.88366 (A-MSE: 0.75562) avg lploss: 0.00000
train epoch 689 avg loss: 0.80530 (A-MSE: 0.68118) avg lploss: 0.00000
train epoch 690 avg loss: 0.78395 (A-MSE: 0.66229) avg lploss: 0.00000
==> val epoch 690 avg loss: 1.50280 (A-MSE: 1.22234) avg lploss: 0.00000
==> test epoch 690 avg loss: 1.80739 (A-MSE: 1.49996) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 12 out of 50
train epoch 691 avg loss: 0.75983 (A-MSE: 0.64671) avg lploss: 0.00000
train epoch 692 avg loss: 0.83057 (A-MSE: 0.70621) avg lploss: 0.00000
train epoch 693 avg loss: 0.80885 (A-MSE: 0.68902) avg lploss: 0.00000
train epoch 694 avg loss: 0.77993 (A-MSE: 0.67189) avg lploss: 0.00000
train epoch 695 avg loss: 0.76692 (A-MSE: 0.64874) avg lploss: 0.00000
==> val epoch 695 avg loss: 1.64817 (A-MSE: 1.37585) avg lploss: 0.00000
==> test epoch 695 avg loss: 1.96459 (A-MSE: 1.67050) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 13 out of 50
train epoch 696 avg loss: 0.79879 (A-MSE: 0.68377) avg lploss: 0.00000
train epoch 697 avg loss: 0.78213 (A-MSE: 0.66125) avg lploss: 0.00000
train epoch 698 avg loss: 0.85495 (A-MSE: 0.71791) avg lploss: 0.00000
train epoch 699 avg loss: 0.84640 (A-MSE: 0.72539) avg lploss: 0.00000
train epoch 700 avg loss: 0.77893 (A-MSE: 0.66074) avg lploss: 0.00000
==> val epoch 700 avg loss: 1.44677 (A-MSE: 1.20326) avg lploss: 0.00000
==> test epoch 700 avg loss: 1.74144 (A-MSE: 1.47812) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 14 out of 50
train epoch 701 avg loss: 0.76445 (A-MSE: 0.64616) avg lploss: 0.00000
train epoch 702 avg loss: 0.79437 (A-MSE: 0.68435) avg lploss: 0.00000
train epoch 703 avg loss: 0.79775 (A-MSE: 0.67648) avg lploss: 0.00000
train epoch 704 avg loss: 0.75104 (A-MSE: 0.64594) avg lploss: 0.00000
train epoch 705 avg loss: 0.79008 (A-MSE: 0.66637) avg lploss: 0.00000
==> val epoch 705 avg loss: 1.41452 (A-MSE: 1.18278) avg lploss: 0.00000
==> test epoch 705 avg loss: 1.75509 (A-MSE: 1.49428) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 15 out of 50
train epoch 706 avg loss: 0.82763 (A-MSE: 0.71153) avg lploss: 0.00000
train epoch 707 avg loss: 0.86985 (A-MSE: 0.74619) avg lploss: 0.00000
train epoch 708 avg loss: 0.82006 (A-MSE: 0.69184) avg lploss: 0.00000
train epoch 709 avg loss: 0.78064 (A-MSE: 0.67119) avg lploss: 0.00000
train epoch 710 avg loss: 0.93134 (A-MSE: 0.79548) avg lploss: 0.00000
==> val epoch 710 avg loss: 1.80651 (A-MSE: 1.44553) avg lploss: 0.00000
==> test epoch 710 avg loss: 2.09743 (A-MSE: 1.71200) avg lploss: 0.00000
*** Best Val Loss: 1.31328 	 Best Test Loss: 1.63750 	 Best epoch 630
EarlyStopping counter: 16 out of 50
train epoch 711 avg loss: 0.82093 (A-MSE: 0.69376) avg lploss: 0.00000
train epoch 712 avg loss: 0.75197 (A-MSE: 0.64122) avg lploss: 0.00000
train epoch 713 avg loss: 0.83855 (A-MSE: 0.71306) avg lploss: 0.00000
train epoch 714 avg loss: 0.79847 (A-MSE: 0.68127) avg lploss: 0.00000
train epoch 715 avg loss: 0.78128 (A-MSE: 0.66521) avg lploss: 0.00000
==> val epoch 715 avg loss: 1.27730 (A-MSE: 1.05849) avg lploss: 0.00000
==> test epoch 715 avg loss: 1.54936 (A-MSE: 1.30818) avg lploss: 0.00000
*** Best Val Loss: 1.27730 	 Best Test Loss: 1.54936 	 Best epoch 715
Validation loss decreased (1.313283 --> 1.277297).  Saving model ...
train epoch 716 avg loss: 0.75719 (A-MSE: 0.64701) avg lploss: 0.00000
train epoch 717 avg loss: 0.80207 (A-MSE: 0.68874) avg lploss: 0.00000
train epoch 718 avg loss: 0.82947 (A-MSE: 0.70595) avg lploss: 0.00000
train epoch 719 avg loss: 0.78271 (A-MSE: 0.66444) avg lploss: 0.00000
train epoch 720 avg loss: 0.73879 (A-MSE: 0.62675) avg lploss: 0.00000
==> val epoch 720 avg loss: 1.47833 (A-MSE: 1.23688) avg lploss: 0.00000
==> test epoch 720 avg loss: 1.80437 (A-MSE: 1.53441) avg lploss: 0.00000
*** Best Val Loss: 1.27730 	 Best Test Loss: 1.54936 	 Best epoch 715
EarlyStopping counter: 1 out of 50
train epoch 721 avg loss: 0.81311 (A-MSE: 0.69183) avg lploss: 0.00000
train epoch 722 avg loss: 0.79468 (A-MSE: 0.68244) avg lploss: 0.00000
train epoch 723 avg loss: 0.77207 (A-MSE: 0.65750) avg lploss: 0.00000
train epoch 724 avg loss: 0.74335 (A-MSE: 0.63032) avg lploss: 0.00000
train epoch 725 avg loss: 0.77022 (A-MSE: 0.65550) avg lploss: 0.00000
==> val epoch 725 avg loss: 1.26384 (A-MSE: 1.10074) avg lploss: 0.00000
==> test epoch 725 avg loss: 1.51181 (A-MSE: 1.32115) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
Validation loss decreased (1.277297 --> 1.263841).  Saving model ...
train epoch 726 avg loss: 0.73612 (A-MSE: 0.63006) avg lploss: 0.00000
train epoch 727 avg loss: 0.73320 (A-MSE: 0.62882) avg lploss: 0.00000
train epoch 728 avg loss: 0.73893 (A-MSE: 0.62640) avg lploss: 0.00000
train epoch 729 avg loss: 0.74855 (A-MSE: 0.64175) avg lploss: 0.00000
train epoch 730 avg loss: 0.75421 (A-MSE: 0.64242) avg lploss: 0.00000
==> val epoch 730 avg loss: 1.66128 (A-MSE: 1.36885) avg lploss: 0.00000
==> test epoch 730 avg loss: 1.87205 (A-MSE: 1.56276) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 1 out of 50
train epoch 731 avg loss: 0.85834 (A-MSE: 0.72772) avg lploss: 0.00000
train epoch 732 avg loss: 0.77620 (A-MSE: 0.66301) avg lploss: 0.00000
train epoch 733 avg loss: 0.73540 (A-MSE: 0.62854) avg lploss: 0.00000
train epoch 734 avg loss: 0.72224 (A-MSE: 0.62781) avg lploss: 0.00000
train epoch 735 avg loss: 0.79196 (A-MSE: 0.67134) avg lploss: 0.00000
==> val epoch 735 avg loss: 1.62302 (A-MSE: 1.40328) avg lploss: 0.00000
==> test epoch 735 avg loss: 1.99215 (A-MSE: 1.73797) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 2 out of 50
train epoch 736 avg loss: 0.77085 (A-MSE: 0.65966) avg lploss: 0.00000
train epoch 737 avg loss: 0.73789 (A-MSE: 0.62581) avg lploss: 0.00000
train epoch 738 avg loss: 0.81578 (A-MSE: 0.69801) avg lploss: 0.00000
train epoch 739 avg loss: 0.84641 (A-MSE: 0.72300) avg lploss: 0.00000
train epoch 740 avg loss: 0.76058 (A-MSE: 0.64332) avg lploss: 0.00000
==> val epoch 740 avg loss: 1.36101 (A-MSE: 1.13730) avg lploss: 0.00000
==> test epoch 740 avg loss: 1.67918 (A-MSE: 1.42099) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 3 out of 50
train epoch 741 avg loss: 0.76019 (A-MSE: 0.64978) avg lploss: 0.00000
train epoch 742 avg loss: 0.80594 (A-MSE: 0.69325) avg lploss: 0.00000
train epoch 743 avg loss: 0.82170 (A-MSE: 0.70365) avg lploss: 0.00000
train epoch 744 avg loss: 0.90592 (A-MSE: 0.77343) avg lploss: 0.00000
train epoch 745 avg loss: 0.75619 (A-MSE: 0.64419) avg lploss: 0.00000
==> val epoch 745 avg loss: 1.37611 (A-MSE: 1.16124) avg lploss: 0.00000
==> test epoch 745 avg loss: 1.69875 (A-MSE: 1.45505) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 4 out of 50
train epoch 746 avg loss: 0.82407 (A-MSE: 0.70912) avg lploss: 0.00000
train epoch 747 avg loss: 0.75833 (A-MSE: 0.63990) avg lploss: 0.00000
train epoch 748 avg loss: 0.77062 (A-MSE: 0.65766) avg lploss: 0.00000
train epoch 749 avg loss: 0.79012 (A-MSE: 0.67370) avg lploss: 0.00000
train epoch 750 avg loss: 0.80051 (A-MSE: 0.68258) avg lploss: 0.00000
==> val epoch 750 avg loss: 1.38698 (A-MSE: 1.18984) avg lploss: 0.00000
==> test epoch 750 avg loss: 1.64545 (A-MSE: 1.43073) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 5 out of 50
train epoch 751 avg loss: 0.81608 (A-MSE: 0.69974) avg lploss: 0.00000
train epoch 752 avg loss: 0.76586 (A-MSE: 0.65059) avg lploss: 0.00000
train epoch 753 avg loss: 0.73259 (A-MSE: 0.62713) avg lploss: 0.00000
train epoch 754 avg loss: 0.66787 (A-MSE: 0.57544) avg lploss: 0.00000
train epoch 755 avg loss: 0.71113 (A-MSE: 0.60481) avg lploss: 0.00000
==> val epoch 755 avg loss: 1.60020 (A-MSE: 1.37093) avg lploss: 0.00000
==> test epoch 755 avg loss: 1.89118 (A-MSE: 1.63594) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 6 out of 50
train epoch 756 avg loss: 0.74090 (A-MSE: 0.63282) avg lploss: 0.00000
train epoch 757 avg loss: 0.78681 (A-MSE: 0.68082) avg lploss: 0.00000
train epoch 758 avg loss: 0.71819 (A-MSE: 0.61250) avg lploss: 0.00000
train epoch 759 avg loss: 0.74244 (A-MSE: 0.64223) avg lploss: 0.00000
train epoch 760 avg loss: 0.77634 (A-MSE: 0.66286) avg lploss: 0.00000
==> val epoch 760 avg loss: 1.34269 (A-MSE: 1.12775) avg lploss: 0.00000
==> test epoch 760 avg loss: 1.57000 (A-MSE: 1.33690) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 7 out of 50
train epoch 761 avg loss: 0.76255 (A-MSE: 0.64520) avg lploss: 0.00000
train epoch 762 avg loss: 0.75105 (A-MSE: 0.64382) avg lploss: 0.00000
train epoch 763 avg loss: 0.72463 (A-MSE: 0.62009) avg lploss: 0.00000
train epoch 764 avg loss: 0.73050 (A-MSE: 0.62571) avg lploss: 0.00000
train epoch 765 avg loss: 0.67715 (A-MSE: 0.57939) avg lploss: 0.00000
==> val epoch 765 avg loss: 1.50258 (A-MSE: 1.23842) avg lploss: 0.00000
==> test epoch 765 avg loss: 1.72967 (A-MSE: 1.44863) avg lploss: 0.00000
*** Best Val Loss: 1.26384 	 Best Test Loss: 1.51181 	 Best epoch 725
EarlyStopping counter: 8 out of 50
train epoch 766 avg loss: 0.70937 (A-MSE: 0.60222) avg lploss: 0.00000
train epoch 767 avg loss: 0.69740 (A-MSE: 0.59542) avg lploss: 0.00000
train epoch 768 avg loss: 0.69650 (A-MSE: 0.59257) avg lploss: 0.00000
train epoch 769 avg loss: 0.74004 (A-MSE: 0.63616) avg lploss: 0.00000
train epoch 770 avg loss: 0.75440 (A-MSE: 0.63930) avg lploss: 0.00000
==> val epoch 770 avg loss: 1.07678 (A-MSE: 0.95391) avg lploss: 0.00000
==> test epoch 770 avg loss: 1.37178 (A-MSE: 1.22576) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
Validation loss decreased (1.263841 --> 1.076784).  Saving model ...
train epoch 771 avg loss: 0.75912 (A-MSE: 0.65401) avg lploss: 0.00000
train epoch 772 avg loss: 0.71444 (A-MSE: 0.60478) avg lploss: 0.00000
train epoch 773 avg loss: 0.77308 (A-MSE: 0.66266) avg lploss: 0.00000
train epoch 774 avg loss: 0.74295 (A-MSE: 0.63427) avg lploss: 0.00000
train epoch 775 avg loss: 0.71092 (A-MSE: 0.60836) avg lploss: 0.00000
==> val epoch 775 avg loss: 1.37293 (A-MSE: 1.16343) avg lploss: 0.00000
==> test epoch 775 avg loss: 1.68385 (A-MSE: 1.45449) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 1 out of 50
train epoch 776 avg loss: 0.70766 (A-MSE: 0.60595) avg lploss: 0.00000
train epoch 777 avg loss: 0.71419 (A-MSE: 0.61714) avg lploss: 0.00000
train epoch 778 avg loss: 0.78434 (A-MSE: 0.66725) avg lploss: 0.00000
train epoch 779 avg loss: 0.75204 (A-MSE: 0.64039) avg lploss: 0.00000
train epoch 780 avg loss: 0.73484 (A-MSE: 0.63468) avg lploss: 0.00000
==> val epoch 780 avg loss: 1.17909 (A-MSE: 1.01881) avg lploss: 0.00000
==> test epoch 780 avg loss: 1.44350 (A-MSE: 1.25931) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 2 out of 50
train epoch 781 avg loss: 0.71183 (A-MSE: 0.60583) avg lploss: 0.00000
train epoch 782 avg loss: 0.66030 (A-MSE: 0.57106) avg lploss: 0.00000
train epoch 783 avg loss: 0.65620 (A-MSE: 0.55795) avg lploss: 0.00000
train epoch 784 avg loss: 0.67387 (A-MSE: 0.57767) avg lploss: 0.00000
train epoch 785 avg loss: 0.71755 (A-MSE: 0.61403) avg lploss: 0.00000
==> val epoch 785 avg loss: 1.45941 (A-MSE: 1.21422) avg lploss: 0.00000
==> test epoch 785 avg loss: 1.74149 (A-MSE: 1.47917) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 3 out of 50
train epoch 786 avg loss: 0.67396 (A-MSE: 0.57123) avg lploss: 0.00000
train epoch 787 avg loss: 0.65139 (A-MSE: 0.55514) avg lploss: 0.00000
train epoch 788 avg loss: 0.65629 (A-MSE: 0.56247) avg lploss: 0.00000
train epoch 789 avg loss: 0.71772 (A-MSE: 0.61633) avg lploss: 0.00000
train epoch 790 avg loss: 0.72151 (A-MSE: 0.61706) avg lploss: 0.00000
==> val epoch 790 avg loss: 1.35246 (A-MSE: 1.14482) avg lploss: 0.00000
==> test epoch 790 avg loss: 1.62727 (A-MSE: 1.40054) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 4 out of 50
train epoch 791 avg loss: 0.67424 (A-MSE: 0.58150) avg lploss: 0.00000
train epoch 792 avg loss: 0.79135 (A-MSE: 0.68069) avg lploss: 0.00000
train epoch 793 avg loss: 0.74377 (A-MSE: 0.63596) avg lploss: 0.00000
train epoch 794 avg loss: 0.69684 (A-MSE: 0.59209) avg lploss: 0.00000
train epoch 795 avg loss: 0.67454 (A-MSE: 0.57726) avg lploss: 0.00000
==> val epoch 795 avg loss: 1.11547 (A-MSE: 0.98394) avg lploss: 0.00000
==> test epoch 795 avg loss: 1.38457 (A-MSE: 1.23654) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 5 out of 50
train epoch 796 avg loss: 0.64475 (A-MSE: 0.55169) avg lploss: 0.00000
train epoch 797 avg loss: 0.64585 (A-MSE: 0.54978) avg lploss: 0.00000
train epoch 798 avg loss: 0.64212 (A-MSE: 0.54483) avg lploss: 0.00000
train epoch 799 avg loss: 0.63479 (A-MSE: 0.55035) avg lploss: 0.00000
train epoch 800 avg loss: 0.63912 (A-MSE: 0.55212) avg lploss: 0.00000
==> val epoch 800 avg loss: 1.26122 (A-MSE: 1.06226) avg lploss: 0.00000
==> test epoch 800 avg loss: 1.53813 (A-MSE: 1.31464) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 6 out of 50
train epoch 801 avg loss: 0.68844 (A-MSE: 0.59233) avg lploss: 0.00000
train epoch 802 avg loss: 0.67509 (A-MSE: 0.57567) avg lploss: 0.00000
train epoch 803 avg loss: 0.65790 (A-MSE: 0.56120) avg lploss: 0.00000
train epoch 804 avg loss: 0.67251 (A-MSE: 0.57911) avg lploss: 0.00000
train epoch 805 avg loss: 0.63621 (A-MSE: 0.55064) avg lploss: 0.00000
==> val epoch 805 avg loss: 1.26706 (A-MSE: 1.08342) avg lploss: 0.00000
==> test epoch 805 avg loss: 1.54516 (A-MSE: 1.33362) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 7 out of 50
train epoch 806 avg loss: 0.61266 (A-MSE: 0.52570) avg lploss: 0.00000
train epoch 807 avg loss: 0.63928 (A-MSE: 0.54976) avg lploss: 0.00000
train epoch 808 avg loss: 0.71442 (A-MSE: 0.61633) avg lploss: 0.00000
train epoch 809 avg loss: 0.73211 (A-MSE: 0.62529) avg lploss: 0.00000
train epoch 810 avg loss: 0.72102 (A-MSE: 0.61989) avg lploss: 0.00000
==> val epoch 810 avg loss: 1.41496 (A-MSE: 1.16134) avg lploss: 0.00000
==> test epoch 810 avg loss: 1.67686 (A-MSE: 1.40487) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 8 out of 50
train epoch 811 avg loss: 0.71675 (A-MSE: 0.61525) avg lploss: 0.00000
train epoch 812 avg loss: 0.66882 (A-MSE: 0.56973) avg lploss: 0.00000
train epoch 813 avg loss: 0.61141 (A-MSE: 0.52005) avg lploss: 0.00000
train epoch 814 avg loss: 0.62686 (A-MSE: 0.54262) avg lploss: 0.00000
train epoch 815 avg loss: 0.64438 (A-MSE: 0.55228) avg lploss: 0.00000
==> val epoch 815 avg loss: 1.33136 (A-MSE: 1.12570) avg lploss: 0.00000
==> test epoch 815 avg loss: 1.62550 (A-MSE: 1.38931) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 9 out of 50
train epoch 816 avg loss: 0.62500 (A-MSE: 0.53738) avg lploss: 0.00000
train epoch 817 avg loss: 0.64481 (A-MSE: 0.55342) avg lploss: 0.00000
train epoch 818 avg loss: 0.66775 (A-MSE: 0.57358) avg lploss: 0.00000
train epoch 819 avg loss: 0.63884 (A-MSE: 0.54887) avg lploss: 0.00000
train epoch 820 avg loss: 0.62894 (A-MSE: 0.53865) avg lploss: 0.00000
==> val epoch 820 avg loss: 1.22017 (A-MSE: 1.04685) avg lploss: 0.00000
==> test epoch 820 avg loss: 1.46238 (A-MSE: 1.26472) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 10 out of 50
train epoch 821 avg loss: 0.68251 (A-MSE: 0.58833) avg lploss: 0.00000
train epoch 822 avg loss: 0.68131 (A-MSE: 0.58899) avg lploss: 0.00000
train epoch 823 avg loss: 0.74541 (A-MSE: 0.64166) avg lploss: 0.00000
train epoch 824 avg loss: 0.67650 (A-MSE: 0.57941) avg lploss: 0.00000
train epoch 825 avg loss: 0.67280 (A-MSE: 0.57623) avg lploss: 0.00000
==> val epoch 825 avg loss: 1.37929 (A-MSE: 1.15993) avg lploss: 0.00000
==> test epoch 825 avg loss: 1.71747 (A-MSE: 1.46937) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 11 out of 50
train epoch 826 avg loss: 0.68893 (A-MSE: 0.59377) avg lploss: 0.00000
train epoch 827 avg loss: 0.71833 (A-MSE: 0.61651) avg lploss: 0.00000
train epoch 828 avg loss: 0.64342 (A-MSE: 0.55157) avg lploss: 0.00000
train epoch 829 avg loss: 0.62865 (A-MSE: 0.53626) avg lploss: 0.00000
train epoch 830 avg loss: 0.60162 (A-MSE: 0.51712) avg lploss: 0.00000
==> val epoch 830 avg loss: 1.10161 (A-MSE: 0.97842) avg lploss: 0.00000
==> test epoch 830 avg loss: 1.41993 (A-MSE: 1.26907) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 12 out of 50
train epoch 831 avg loss: 0.69550 (A-MSE: 0.59704) avg lploss: 0.00000
train epoch 832 avg loss: 0.71853 (A-MSE: 0.61577) avg lploss: 0.00000
train epoch 833 avg loss: 0.60136 (A-MSE: 0.51839) avg lploss: 0.00000
train epoch 834 avg loss: 0.65797 (A-MSE: 0.56132) avg lploss: 0.00000
train epoch 835 avg loss: 0.66692 (A-MSE: 0.57300) avg lploss: 0.00000
==> val epoch 835 avg loss: 1.19595 (A-MSE: 1.04370) avg lploss: 0.00000
==> test epoch 835 avg loss: 1.51147 (A-MSE: 1.33348) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 13 out of 50
train epoch 836 avg loss: 0.66929 (A-MSE: 0.57257) avg lploss: 0.00000
train epoch 837 avg loss: 0.61489 (A-MSE: 0.52661) avg lploss: 0.00000
train epoch 838 avg loss: 0.65027 (A-MSE: 0.55365) avg lploss: 0.00000
train epoch 839 avg loss: 0.60856 (A-MSE: 0.51942) avg lploss: 0.00000
train epoch 840 avg loss: 0.59561 (A-MSE: 0.51377) avg lploss: 0.00000
==> val epoch 840 avg loss: 1.12968 (A-MSE: 0.97379) avg lploss: 0.00000
==> test epoch 840 avg loss: 1.41210 (A-MSE: 1.23219) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 14 out of 50
train epoch 841 avg loss: 0.61255 (A-MSE: 0.52552) avg lploss: 0.00000
train epoch 842 avg loss: 0.59401 (A-MSE: 0.50729) avg lploss: 0.00000
train epoch 843 avg loss: 0.60737 (A-MSE: 0.52648) avg lploss: 0.00000
train epoch 844 avg loss: 0.64666 (A-MSE: 0.56093) avg lploss: 0.00000
train epoch 845 avg loss: 0.64030 (A-MSE: 0.54798) avg lploss: 0.00000
==> val epoch 845 avg loss: 1.15426 (A-MSE: 0.99260) avg lploss: 0.00000
==> test epoch 845 avg loss: 1.41449 (A-MSE: 1.23248) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 15 out of 50
train epoch 846 avg loss: 0.63738 (A-MSE: 0.54547) avg lploss: 0.00000
train epoch 847 avg loss: 0.64956 (A-MSE: 0.55752) avg lploss: 0.00000
train epoch 848 avg loss: 0.66594 (A-MSE: 0.56834) avg lploss: 0.00000
train epoch 849 avg loss: 0.67403 (A-MSE: 0.58723) avg lploss: 0.00000
train epoch 850 avg loss: 0.62989 (A-MSE: 0.53889) avg lploss: 0.00000
==> val epoch 850 avg loss: 1.23311 (A-MSE: 1.06558) avg lploss: 0.00000
==> test epoch 850 avg loss: 1.51078 (A-MSE: 1.31325) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 16 out of 50
train epoch 851 avg loss: 0.60461 (A-MSE: 0.52237) avg lploss: 0.00000
train epoch 852 avg loss: 0.63507 (A-MSE: 0.54680) avg lploss: 0.00000
train epoch 853 avg loss: 0.62650 (A-MSE: 0.53556) avg lploss: 0.00000
train epoch 854 avg loss: 0.57985 (A-MSE: 0.50038) avg lploss: 0.00000
train epoch 855 avg loss: 0.56279 (A-MSE: 0.48612) avg lploss: 0.00000
==> val epoch 855 avg loss: 1.45884 (A-MSE: 1.21803) avg lploss: 0.00000
==> test epoch 855 avg loss: 1.67540 (A-MSE: 1.42570) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 17 out of 50
train epoch 856 avg loss: 0.61642 (A-MSE: 0.52901) avg lploss: 0.00000
train epoch 857 avg loss: 0.58775 (A-MSE: 0.50234) avg lploss: 0.00000
train epoch 858 avg loss: 0.58433 (A-MSE: 0.50352) avg lploss: 0.00000
train epoch 859 avg loss: 0.55694 (A-MSE: 0.48394) avg lploss: 0.00000
train epoch 860 avg loss: 0.61776 (A-MSE: 0.53422) avg lploss: 0.00000
==> val epoch 860 avg loss: 1.20835 (A-MSE: 1.03527) avg lploss: 0.00000
==> test epoch 860 avg loss: 1.49656 (A-MSE: 1.29297) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 18 out of 50
train epoch 861 avg loss: 0.58005 (A-MSE: 0.49536) avg lploss: 0.00000
train epoch 862 avg loss: 0.60970 (A-MSE: 0.52177) avg lploss: 0.00000
train epoch 863 avg loss: 0.58215 (A-MSE: 0.49912) avg lploss: 0.00000
train epoch 864 avg loss: 0.61837 (A-MSE: 0.53459) avg lploss: 0.00000
train epoch 865 avg loss: 0.61678 (A-MSE: 0.52723) avg lploss: 0.00000
==> val epoch 865 avg loss: 1.28228 (A-MSE: 1.08527) avg lploss: 0.00000
==> test epoch 865 avg loss: 1.50687 (A-MSE: 1.29068) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 19 out of 50
train epoch 866 avg loss: 0.59344 (A-MSE: 0.51117) avg lploss: 0.00000
train epoch 867 avg loss: 0.56837 (A-MSE: 0.49033) avg lploss: 0.00000
train epoch 868 avg loss: 0.61437 (A-MSE: 0.53260) avg lploss: 0.00000
train epoch 869 avg loss: 0.65859 (A-MSE: 0.57069) avg lploss: 0.00000
train epoch 870 avg loss: 0.61345 (A-MSE: 0.52658) avg lploss: 0.00000
==> val epoch 870 avg loss: 1.37920 (A-MSE: 1.17659) avg lploss: 0.00000
==> test epoch 870 avg loss: 1.59973 (A-MSE: 1.38807) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 20 out of 50
train epoch 871 avg loss: 0.60054 (A-MSE: 0.51680) avg lploss: 0.00000
train epoch 872 avg loss: 0.65636 (A-MSE: 0.55971) avg lploss: 0.00000
train epoch 873 avg loss: 0.61471 (A-MSE: 0.52749) avg lploss: 0.00000
train epoch 874 avg loss: 0.61614 (A-MSE: 0.53426) avg lploss: 0.00000
train epoch 875 avg loss: 0.65023 (A-MSE: 0.56281) avg lploss: 0.00000
==> val epoch 875 avg loss: 1.28980 (A-MSE: 1.10881) avg lploss: 0.00000
==> test epoch 875 avg loss: 1.55527 (A-MSE: 1.35933) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 21 out of 50
train epoch 876 avg loss: 0.59888 (A-MSE: 0.51674) avg lploss: 0.00000
train epoch 877 avg loss: 0.59431 (A-MSE: 0.51255) avg lploss: 0.00000
train epoch 878 avg loss: 0.61857 (A-MSE: 0.53471) avg lploss: 0.00000
train epoch 879 avg loss: 0.60195 (A-MSE: 0.52078) avg lploss: 0.00000
train epoch 880 avg loss: 0.58598 (A-MSE: 0.50414) avg lploss: 0.00000
==> val epoch 880 avg loss: 1.22112 (A-MSE: 1.05186) avg lploss: 0.00000
==> test epoch 880 avg loss: 1.52741 (A-MSE: 1.32348) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 22 out of 50
train epoch 881 avg loss: 0.59721 (A-MSE: 0.52001) avg lploss: 0.00000
train epoch 882 avg loss: 0.60645 (A-MSE: 0.52121) avg lploss: 0.00000
train epoch 883 avg loss: 0.58860 (A-MSE: 0.50294) avg lploss: 0.00000
train epoch 884 avg loss: 0.57959 (A-MSE: 0.49812) avg lploss: 0.00000
train epoch 885 avg loss: 0.58436 (A-MSE: 0.50557) avg lploss: 0.00000
==> val epoch 885 avg loss: 1.22093 (A-MSE: 1.03720) avg lploss: 0.00000
==> test epoch 885 avg loss: 1.51021 (A-MSE: 1.30305) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 23 out of 50
train epoch 886 avg loss: 0.56851 (A-MSE: 0.49167) avg lploss: 0.00000
train epoch 887 avg loss: 0.61106 (A-MSE: 0.52551) avg lploss: 0.00000
train epoch 888 avg loss: 0.60324 (A-MSE: 0.51791) avg lploss: 0.00000
train epoch 889 avg loss: 0.54097 (A-MSE: 0.46543) avg lploss: 0.00000
train epoch 890 avg loss: 0.57016 (A-MSE: 0.48796) avg lploss: 0.00000
==> val epoch 890 avg loss: 1.14939 (A-MSE: 1.00193) avg lploss: 0.00000
==> test epoch 890 avg loss: 1.44224 (A-MSE: 1.26604) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 24 out of 50
train epoch 891 avg loss: 0.61363 (A-MSE: 0.52929) avg lploss: 0.00000
train epoch 892 avg loss: 0.62140 (A-MSE: 0.52918) avg lploss: 0.00000
train epoch 893 avg loss: 0.59293 (A-MSE: 0.51433) avg lploss: 0.00000
train epoch 894 avg loss: 0.55054 (A-MSE: 0.47174) avg lploss: 0.00000
train epoch 895 avg loss: 0.57387 (A-MSE: 0.49502) avg lploss: 0.00000
==> val epoch 895 avg loss: 1.27726 (A-MSE: 1.08401) avg lploss: 0.00000
==> test epoch 895 avg loss: 1.58143 (A-MSE: 1.36689) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 25 out of 50
train epoch 896 avg loss: 0.59586 (A-MSE: 0.51476) avg lploss: 0.00000
train epoch 897 avg loss: 0.59442 (A-MSE: 0.51391) avg lploss: 0.00000
train epoch 898 avg loss: 0.59691 (A-MSE: 0.51725) avg lploss: 0.00000
train epoch 899 avg loss: 0.60766 (A-MSE: 0.52189) avg lploss: 0.00000
train epoch 900 avg loss: 0.64994 (A-MSE: 0.56393) avg lploss: 0.00000
==> val epoch 900 avg loss: 1.32303 (A-MSE: 1.11799) avg lploss: 0.00000
==> test epoch 900 avg loss: 1.57520 (A-MSE: 1.35702) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 26 out of 50
train epoch 901 avg loss: 0.58604 (A-MSE: 0.50542) avg lploss: 0.00000
train epoch 902 avg loss: 0.53956 (A-MSE: 0.46361) avg lploss: 0.00000
train epoch 903 avg loss: 0.55903 (A-MSE: 0.48342) avg lploss: 0.00000
train epoch 904 avg loss: 0.55534 (A-MSE: 0.47644) avg lploss: 0.00000
train epoch 905 avg loss: 0.55380 (A-MSE: 0.47943) avg lploss: 0.00000
==> val epoch 905 avg loss: 1.16591 (A-MSE: 0.97475) avg lploss: 0.00000
==> test epoch 905 avg loss: 1.33000 (A-MSE: 1.13321) avg lploss: 0.00000
*** Best Val Loss: 1.07678 	 Best Test Loss: 1.37178 	 Best epoch 770
EarlyStopping counter: 27 out of 50
train epoch 906 avg loss: 0.57457 (A-MSE: 0.49680) avg lploss: 0.00000
train epoch 907 avg loss: 0.52187 (A-MSE: 0.44917) avg lploss: 0.00000
train epoch 908 avg loss: 0.54704 (A-MSE: 0.46906) avg lploss: 0.00000
train epoch 909 avg loss: 0.61609 (A-MSE: 0.53364) avg lploss: 0.00000
train epoch 910 avg loss: 0.56392 (A-MSE: 0.48685) avg lploss: 0.00000
==> val epoch 910 avg loss: 0.97842 (A-MSE: 0.84000) avg lploss: 0.00000
==> test epoch 910 avg loss: 1.26169 (A-MSE: 1.09728) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
Validation loss decreased (1.076784 --> 0.978415).  Saving model ...
train epoch 911 avg loss: 0.57405 (A-MSE: 0.49722) avg lploss: 0.00000
train epoch 912 avg loss: 0.65180 (A-MSE: 0.55857) avg lploss: 0.00000
train epoch 913 avg loss: 0.68690 (A-MSE: 0.59210) avg lploss: 0.00000
train epoch 914 avg loss: 0.59873 (A-MSE: 0.52018) avg lploss: 0.00000
train epoch 915 avg loss: 0.57986 (A-MSE: 0.49652) avg lploss: 0.00000
==> val epoch 915 avg loss: 1.14187 (A-MSE: 0.95892) avg lploss: 0.00000
==> test epoch 915 avg loss: 1.43473 (A-MSE: 1.22572) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 1 out of 50
train epoch 916 avg loss: 0.56740 (A-MSE: 0.49015) avg lploss: 0.00000
train epoch 917 avg loss: 0.54328 (A-MSE: 0.47064) avg lploss: 0.00000
train epoch 918 avg loss: 0.60421 (A-MSE: 0.51817) avg lploss: 0.00000
train epoch 919 avg loss: 0.62705 (A-MSE: 0.54265) avg lploss: 0.00000
train epoch 920 avg loss: 0.60948 (A-MSE: 0.52175) avg lploss: 0.00000
==> val epoch 920 avg loss: 1.02546 (A-MSE: 0.88179) avg lploss: 0.00000
==> test epoch 920 avg loss: 1.23837 (A-MSE: 1.07433) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 2 out of 50
train epoch 921 avg loss: 0.56283 (A-MSE: 0.48535) avg lploss: 0.00000
train epoch 922 avg loss: 0.59581 (A-MSE: 0.51432) avg lploss: 0.00000
train epoch 923 avg loss: 0.58556 (A-MSE: 0.50446) avg lploss: 0.00000
train epoch 924 avg loss: 0.54118 (A-MSE: 0.46646) avg lploss: 0.00000
train epoch 925 avg loss: 0.53175 (A-MSE: 0.46014) avg lploss: 0.00000
==> val epoch 925 avg loss: 1.29666 (A-MSE: 1.08887) avg lploss: 0.00000
==> test epoch 925 avg loss: 1.49848 (A-MSE: 1.27340) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 3 out of 50
train epoch 926 avg loss: 0.52877 (A-MSE: 0.45500) avg lploss: 0.00000
train epoch 927 avg loss: 0.56416 (A-MSE: 0.48780) avg lploss: 0.00000
train epoch 928 avg loss: 0.59078 (A-MSE: 0.51022) avg lploss: 0.00000
train epoch 929 avg loss: 0.65518 (A-MSE: 0.56620) avg lploss: 0.00000
train epoch 930 avg loss: 0.62897 (A-MSE: 0.53794) avg lploss: 0.00000
==> val epoch 930 avg loss: 1.18570 (A-MSE: 1.01925) avg lploss: 0.00000
==> test epoch 930 avg loss: 1.41516 (A-MSE: 1.22723) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 4 out of 50
train epoch 931 avg loss: 0.57199 (A-MSE: 0.49304) avg lploss: 0.00000
train epoch 932 avg loss: 0.59193 (A-MSE: 0.51147) avg lploss: 0.00000
train epoch 933 avg loss: 0.54403 (A-MSE: 0.46630) avg lploss: 0.00000
train epoch 934 avg loss: 0.56224 (A-MSE: 0.48807) avg lploss: 0.00000
train epoch 935 avg loss: 0.64443 (A-MSE: 0.56108) avg lploss: 0.00000
==> val epoch 935 avg loss: 1.24560 (A-MSE: 1.07611) avg lploss: 0.00000
==> test epoch 935 avg loss: 1.50880 (A-MSE: 1.33004) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 5 out of 50
train epoch 936 avg loss: 0.58359 (A-MSE: 0.50269) avg lploss: 0.00000
train epoch 937 avg loss: 0.66691 (A-MSE: 0.57853) avg lploss: 0.00000
train epoch 938 avg loss: 0.58919 (A-MSE: 0.50753) avg lploss: 0.00000
train epoch 939 avg loss: 0.56276 (A-MSE: 0.48395) avg lploss: 0.00000
train epoch 940 avg loss: 0.55783 (A-MSE: 0.48768) avg lploss: 0.00000
==> val epoch 940 avg loss: 1.34243 (A-MSE: 1.11812) avg lploss: 0.00000
==> test epoch 940 avg loss: 1.52641 (A-MSE: 1.29294) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 6 out of 50
train epoch 941 avg loss: 0.54720 (A-MSE: 0.47012) avg lploss: 0.00000
train epoch 942 avg loss: 0.57969 (A-MSE: 0.49802) avg lploss: 0.00000
train epoch 943 avg loss: 0.59604 (A-MSE: 0.51408) avg lploss: 0.00000
train epoch 944 avg loss: 0.60535 (A-MSE: 0.51876) avg lploss: 0.00000
train epoch 945 avg loss: 0.54702 (A-MSE: 0.47033) avg lploss: 0.00000
==> val epoch 945 avg loss: 1.10807 (A-MSE: 0.93492) avg lploss: 0.00000
==> test epoch 945 avg loss: 1.31030 (A-MSE: 1.11568) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 7 out of 50
train epoch 946 avg loss: 0.52546 (A-MSE: 0.45325) avg lploss: 0.00000
train epoch 947 avg loss: 0.51031 (A-MSE: 0.44122) avg lploss: 0.00000
train epoch 948 avg loss: 0.51068 (A-MSE: 0.43854) avg lploss: 0.00000
train epoch 949 avg loss: 0.53658 (A-MSE: 0.46504) avg lploss: 0.00000
train epoch 950 avg loss: 0.55130 (A-MSE: 0.47876) avg lploss: 0.00000
==> val epoch 950 avg loss: 1.10770 (A-MSE: 0.94715) avg lploss: 0.00000
==> test epoch 950 avg loss: 1.33998 (A-MSE: 1.15985) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 8 out of 50
train epoch 951 avg loss: 0.55004 (A-MSE: 0.47777) avg lploss: 0.00000
train epoch 952 avg loss: 0.53355 (A-MSE: 0.46384) avg lploss: 0.00000
train epoch 953 avg loss: 0.56382 (A-MSE: 0.48860) avg lploss: 0.00000
train epoch 954 avg loss: 0.53488 (A-MSE: 0.46209) avg lploss: 0.00000
train epoch 955 avg loss: 0.55510 (A-MSE: 0.47383) avg lploss: 0.00000
==> val epoch 955 avg loss: 1.14794 (A-MSE: 0.98527) avg lploss: 0.00000
==> test epoch 955 avg loss: 1.40319 (A-MSE: 1.21192) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 9 out of 50
train epoch 956 avg loss: 0.55473 (A-MSE: 0.47929) avg lploss: 0.00000
train epoch 957 avg loss: 0.57712 (A-MSE: 0.50257) avg lploss: 0.00000
train epoch 958 avg loss: 0.59311 (A-MSE: 0.51594) avg lploss: 0.00000
train epoch 959 avg loss: 0.53605 (A-MSE: 0.46088) avg lploss: 0.00000
train epoch 960 avg loss: 0.52887 (A-MSE: 0.45696) avg lploss: 0.00000
==> val epoch 960 avg loss: 1.26645 (A-MSE: 1.06057) avg lploss: 0.00000
==> test epoch 960 avg loss: 1.50853 (A-MSE: 1.28352) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 10 out of 50
train epoch 961 avg loss: 0.55689 (A-MSE: 0.47784) avg lploss: 0.00000
train epoch 962 avg loss: 0.50591 (A-MSE: 0.43926) avg lploss: 0.00000
train epoch 963 avg loss: 0.55902 (A-MSE: 0.48859) avg lploss: 0.00000
train epoch 964 avg loss: 0.56747 (A-MSE: 0.48795) avg lploss: 0.00000
train epoch 965 avg loss: 0.53323 (A-MSE: 0.46210) avg lploss: 0.00000
==> val epoch 965 avg loss: 1.35595 (A-MSE: 1.12758) avg lploss: 0.00000
==> test epoch 965 avg loss: 1.53317 (A-MSE: 1.28860) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 11 out of 50
train epoch 966 avg loss: 0.51270 (A-MSE: 0.44375) avg lploss: 0.00000
train epoch 967 avg loss: 0.51431 (A-MSE: 0.44350) avg lploss: 0.00000
train epoch 968 avg loss: 0.49403 (A-MSE: 0.42679) avg lploss: 0.00000
train epoch 969 avg loss: 0.51484 (A-MSE: 0.44503) avg lploss: 0.00000
train epoch 970 avg loss: 0.48947 (A-MSE: 0.42415) avg lploss: 0.00000
==> val epoch 970 avg loss: 1.05313 (A-MSE: 0.89664) avg lploss: 0.00000
==> test epoch 970 avg loss: 1.32589 (A-MSE: 1.14738) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 12 out of 50
train epoch 971 avg loss: 0.51968 (A-MSE: 0.44798) avg lploss: 0.00000
train epoch 972 avg loss: 0.48128 (A-MSE: 0.41450) avg lploss: 0.00000
train epoch 973 avg loss: 0.49464 (A-MSE: 0.42631) avg lploss: 0.00000
train epoch 974 avg loss: 0.49080 (A-MSE: 0.42636) avg lploss: 0.00000
train epoch 975 avg loss: 0.47904 (A-MSE: 0.41578) avg lploss: 0.00000
==> val epoch 975 avg loss: 1.03065 (A-MSE: 0.88053) avg lploss: 0.00000
==> test epoch 975 avg loss: 1.27112 (A-MSE: 1.10811) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 13 out of 50
train epoch 976 avg loss: 0.51863 (A-MSE: 0.44852) avg lploss: 0.00000
train epoch 977 avg loss: 0.52897 (A-MSE: 0.45589) avg lploss: 0.00000
train epoch 978 avg loss: 0.56239 (A-MSE: 0.48347) avg lploss: 0.00000
train epoch 979 avg loss: 0.57800 (A-MSE: 0.49957) avg lploss: 0.00000
train epoch 980 avg loss: 0.54300 (A-MSE: 0.47231) avg lploss: 0.00000
==> val epoch 980 avg loss: 1.37497 (A-MSE: 1.15349) avg lploss: 0.00000
==> test epoch 980 avg loss: 1.60693 (A-MSE: 1.37863) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 14 out of 50
train epoch 981 avg loss: 0.56921 (A-MSE: 0.49264) avg lploss: 0.00000
train epoch 982 avg loss: 0.53186 (A-MSE: 0.46196) avg lploss: 0.00000
train epoch 983 avg loss: 0.53879 (A-MSE: 0.46318) avg lploss: 0.00000
train epoch 984 avg loss: 0.56806 (A-MSE: 0.49178) avg lploss: 0.00000
train epoch 985 avg loss: 0.51064 (A-MSE: 0.43924) avg lploss: 0.00000
==> val epoch 985 avg loss: 1.15162 (A-MSE: 0.99404) avg lploss: 0.00000
==> test epoch 985 avg loss: 1.38884 (A-MSE: 1.20226) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 15 out of 50
train epoch 986 avg loss: 0.50057 (A-MSE: 0.43390) avg lploss: 0.00000
train epoch 987 avg loss: 0.52645 (A-MSE: 0.45041) avg lploss: 0.00000
train epoch 988 avg loss: 0.50421 (A-MSE: 0.43305) avg lploss: 0.00000
train epoch 989 avg loss: 0.53620 (A-MSE: 0.45984) avg lploss: 0.00000
train epoch 990 avg loss: 0.53706 (A-MSE: 0.46664) avg lploss: 0.00000
==> val epoch 990 avg loss: 1.15458 (A-MSE: 0.98815) avg lploss: 0.00000
==> test epoch 990 avg loss: 1.43515 (A-MSE: 1.24242) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 16 out of 50
train epoch 991 avg loss: 0.58352 (A-MSE: 0.50730) avg lploss: 0.00000
train epoch 992 avg loss: 0.54598 (A-MSE: 0.47362) avg lploss: 0.00000
train epoch 993 avg loss: 0.53161 (A-MSE: 0.45953) avg lploss: 0.00000
train epoch 994 avg loss: 0.53133 (A-MSE: 0.46065) avg lploss: 0.00000
train epoch 995 avg loss: 0.51805 (A-MSE: 0.44446) avg lploss: 0.00000
==> val epoch 995 avg loss: 1.15567 (A-MSE: 0.96584) avg lploss: 0.00000
==> test epoch 995 avg loss: 1.39499 (A-MSE: 1.18390) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 17 out of 50
train epoch 996 avg loss: 0.51968 (A-MSE: 0.44754) avg lploss: 0.00000
train epoch 997 avg loss: 0.50635 (A-MSE: 0.43480) avg lploss: 0.00000
train epoch 998 avg loss: 0.56735 (A-MSE: 0.49088) avg lploss: 0.00000
train epoch 999 avg loss: 0.58615 (A-MSE: 0.50373) avg lploss: 0.00000
train epoch 1000 avg loss: 0.53994 (A-MSE: 0.46782) avg lploss: 0.00000
==> val epoch 1000 avg loss: 1.04844 (A-MSE: 0.89768) avg lploss: 0.00000
==> test epoch 1000 avg loss: 1.30697 (A-MSE: 1.12680) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 18 out of 50
train epoch 1001 avg loss: 0.48734 (A-MSE: 0.42316) avg lploss: 0.00000
train epoch 1002 avg loss: 0.47072 (A-MSE: 0.40518) avg lploss: 0.00000
train epoch 1003 avg loss: 0.48976 (A-MSE: 0.42107) avg lploss: 0.00000
train epoch 1004 avg loss: 0.48765 (A-MSE: 0.42409) avg lploss: 0.00000
train epoch 1005 avg loss: 0.50258 (A-MSE: 0.43549) avg lploss: 0.00000
==> val epoch 1005 avg loss: 1.15998 (A-MSE: 1.00181) avg lploss: 0.00000
==> test epoch 1005 avg loss: 1.47148 (A-MSE: 1.28304) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 19 out of 50
train epoch 1006 avg loss: 0.54662 (A-MSE: 0.47322) avg lploss: 0.00000
train epoch 1007 avg loss: 0.56878 (A-MSE: 0.48800) avg lploss: 0.00000
train epoch 1008 avg loss: 0.51081 (A-MSE: 0.43780) avg lploss: 0.00000
train epoch 1009 avg loss: 0.50925 (A-MSE: 0.44080) avg lploss: 0.00000
train epoch 1010 avg loss: 0.49332 (A-MSE: 0.42523) avg lploss: 0.00000
==> val epoch 1010 avg loss: 1.00902 (A-MSE: 0.86338) avg lploss: 0.00000
==> test epoch 1010 avg loss: 1.23528 (A-MSE: 1.07334) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 20 out of 50
train epoch 1011 avg loss: 0.49911 (A-MSE: 0.43177) avg lploss: 0.00000
train epoch 1012 avg loss: 0.49622 (A-MSE: 0.42678) avg lploss: 0.00000
train epoch 1013 avg loss: 0.49757 (A-MSE: 0.42847) avg lploss: 0.00000
train epoch 1014 avg loss: 0.47301 (A-MSE: 0.40492) avg lploss: 0.00000
train epoch 1015 avg loss: 0.50949 (A-MSE: 0.44113) avg lploss: 0.00000
==> val epoch 1015 avg loss: 0.98420 (A-MSE: 0.84099) avg lploss: 0.00000
==> test epoch 1015 avg loss: 1.18363 (A-MSE: 1.02044) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 21 out of 50
train epoch 1016 avg loss: 0.53763 (A-MSE: 0.46492) avg lploss: 0.00000
train epoch 1017 avg loss: 0.49665 (A-MSE: 0.43151) avg lploss: 0.00000
train epoch 1018 avg loss: 0.51679 (A-MSE: 0.44538) avg lploss: 0.00000
train epoch 1019 avg loss: 0.46897 (A-MSE: 0.40453) avg lploss: 0.00000
train epoch 1020 avg loss: 0.45572 (A-MSE: 0.39193) avg lploss: 0.00000
==> val epoch 1020 avg loss: 1.04360 (A-MSE: 0.88716) avg lploss: 0.00000
==> test epoch 1020 avg loss: 1.33979 (A-MSE: 1.16155) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 22 out of 50
train epoch 1021 avg loss: 0.47584 (A-MSE: 0.41335) avg lploss: 0.00000
train epoch 1022 avg loss: 0.49052 (A-MSE: 0.42299) avg lploss: 0.00000
train epoch 1023 avg loss: 0.43622 (A-MSE: 0.37531) avg lploss: 0.00000
train epoch 1024 avg loss: 0.43643 (A-MSE: 0.37887) avg lploss: 0.00000
train epoch 1025 avg loss: 0.52118 (A-MSE: 0.45305) avg lploss: 0.00000
==> val epoch 1025 avg loss: 1.03078 (A-MSE: 0.88520) avg lploss: 0.00000
==> test epoch 1025 avg loss: 1.23893 (A-MSE: 1.07940) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 23 out of 50
train epoch 1026 avg loss: 0.50477 (A-MSE: 0.43490) avg lploss: 0.00000
train epoch 1027 avg loss: 0.49668 (A-MSE: 0.43019) avg lploss: 0.00000
train epoch 1028 avg loss: 0.49161 (A-MSE: 0.42599) avg lploss: 0.00000
train epoch 1029 avg loss: 0.46735 (A-MSE: 0.40419) avg lploss: 0.00000
train epoch 1030 avg loss: 0.47433 (A-MSE: 0.40833) avg lploss: 0.00000
==> val epoch 1030 avg loss: 1.04848 (A-MSE: 0.88586) avg lploss: 0.00000
==> test epoch 1030 avg loss: 1.22010 (A-MSE: 1.04780) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 24 out of 50
train epoch 1031 avg loss: 0.49952 (A-MSE: 0.42939) avg lploss: 0.00000
train epoch 1032 avg loss: 0.52716 (A-MSE: 0.45681) avg lploss: 0.00000
train epoch 1033 avg loss: 0.49552 (A-MSE: 0.42954) avg lploss: 0.00000
train epoch 1034 avg loss: 0.46298 (A-MSE: 0.39793) avg lploss: 0.00000
train epoch 1035 avg loss: 0.46493 (A-MSE: 0.40318) avg lploss: 0.00000
==> val epoch 1035 avg loss: 1.02594 (A-MSE: 0.88199) avg lploss: 0.00000
==> test epoch 1035 avg loss: 1.23850 (A-MSE: 1.07566) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 25 out of 50
train epoch 1036 avg loss: 0.44475 (A-MSE: 0.38317) avg lploss: 0.00000
train epoch 1037 avg loss: 0.44911 (A-MSE: 0.38792) avg lploss: 0.00000
train epoch 1038 avg loss: 0.47003 (A-MSE: 0.40998) avg lploss: 0.00000
train epoch 1039 avg loss: 0.98355 (A-MSE: 0.84469) avg lploss: 0.00000
train epoch 1040 avg loss: 1.00994 (A-MSE: 0.85764) avg lploss: 0.00000
==> val epoch 1040 avg loss: 1.28811 (A-MSE: 1.08948) avg lploss: 0.00000
==> test epoch 1040 avg loss: 1.57328 (A-MSE: 1.34310) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 26 out of 50
train epoch 1041 avg loss: 0.63600 (A-MSE: 0.54625) avg lploss: 0.00000
train epoch 1042 avg loss: 0.52779 (A-MSE: 0.45223) avg lploss: 0.00000
train epoch 1043 avg loss: 0.53469 (A-MSE: 0.46101) avg lploss: 0.00000
train epoch 1044 avg loss: 0.52132 (A-MSE: 0.45004) avg lploss: 0.00000
train epoch 1045 avg loss: 0.54021 (A-MSE: 0.47005) avg lploss: 0.00000
==> val epoch 1045 avg loss: 1.10276 (A-MSE: 0.94203) avg lploss: 0.00000
==> test epoch 1045 avg loss: 1.36483 (A-MSE: 1.18676) avg lploss: 0.00000
*** Best Val Loss: 0.97842 	 Best Test Loss: 1.26169 	 Best epoch 910
EarlyStopping counter: 27 out of 50
train epoch 1046 avg loss: 0.46896 (A-MSE: 0.40196) avg lploss: 0.00000
train epoch 1047 avg loss: 0.49839 (A-MSE: 0.42809) avg lploss: 0.00000
train epoch 1048 avg loss: 0.53982 (A-MSE: 0.46681) avg lploss: 0.00000
train epoch 1049 avg loss: 0.48928 (A-MSE: 0.42341) avg lploss: 0.00000
train epoch 1050 avg loss: 0.44658 (A-MSE: 0.38584) avg lploss: 0.00000
==> val epoch 1050 avg loss: 0.97254 (A-MSE: 0.83310) avg lploss: 0.00000
==> test epoch 1050 avg loss: 1.21946 (A-MSE: 1.06163) avg lploss: 0.00000
*** Best Val Loss: 0.97254 	 Best Test Loss: 1.21946 	 Best epoch 1050
Validation loss decreased (0.978415 --> 0.972538).  Saving model ...
train epoch 1051 avg loss: 0.44920 (A-MSE: 0.38928) avg lploss: 0.00000
train epoch 1052 avg loss: 0.45505 (A-MSE: 0.39143) avg lploss: 0.00000
train epoch 1053 avg loss: 0.43715 (A-MSE: 0.37905) avg lploss: 0.00000
train epoch 1054 avg loss: 0.46722 (A-MSE: 0.40215) avg lploss: 0.00000
train epoch 1055 avg loss: 0.46547 (A-MSE: 0.40082) avg lploss: 0.00000
==> val epoch 1055 avg loss: 0.98206 (A-MSE: 0.83251) avg lploss: 0.00000
==> test epoch 1055 avg loss: 1.15896 (A-MSE: 0.99670) avg lploss: 0.00000
*** Best Val Loss: 0.97254 	 Best Test Loss: 1.21946 	 Best epoch 1050
EarlyStopping counter: 1 out of 50
train epoch 1056 avg loss: 0.50071 (A-MSE: 0.43329) avg lploss: 0.00000
train epoch 1057 avg loss: 0.53176 (A-MSE: 0.45685) avg lploss: 0.00000
train epoch 1058 avg loss: 0.46639 (A-MSE: 0.40198) avg lploss: 0.00000
train epoch 1059 avg loss: 0.44048 (A-MSE: 0.38336) avg lploss: 0.00000
train epoch 1060 avg loss: 0.47419 (A-MSE: 0.41055) avg lploss: 0.00000
==> val epoch 1060 avg loss: 0.93752 (A-MSE: 0.81255) avg lploss: 0.00000
==> test epoch 1060 avg loss: 1.15368 (A-MSE: 1.01404) avg lploss: 0.00000
*** Best Val Loss: 0.93752 	 Best Test Loss: 1.15368 	 Best epoch 1060
Validation loss decreased (0.972538 --> 0.937516).  Saving model ...
train epoch 1061 avg loss: 0.43680 (A-MSE: 0.37625) avg lploss: 0.00000
train epoch 1062 avg loss: 0.43492 (A-MSE: 0.37723) avg lploss: 0.00000
train epoch 1063 avg loss: 0.48179 (A-MSE: 0.41715) avg lploss: 0.00000
train epoch 1064 avg loss: 0.48709 (A-MSE: 0.42022) avg lploss: 0.00000
train epoch 1065 avg loss: 0.46965 (A-MSE: 0.40685) avg lploss: 0.00000
==> val epoch 1065 avg loss: 0.90805 (A-MSE: 0.79103) avg lploss: 0.00000
==> test epoch 1065 avg loss: 1.09270 (A-MSE: 0.96165) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
Validation loss decreased (0.937516 --> 0.908050).  Saving model ...
train epoch 1066 avg loss: 0.50402 (A-MSE: 0.43237) avg lploss: 0.00000
train epoch 1067 avg loss: 0.53113 (A-MSE: 0.46044) avg lploss: 0.00000
train epoch 1068 avg loss: 0.55910 (A-MSE: 0.48303) avg lploss: 0.00000
train epoch 1069 avg loss: 0.47830 (A-MSE: 0.41420) avg lploss: 0.00000
train epoch 1070 avg loss: 0.50384 (A-MSE: 0.43405) avg lploss: 0.00000
==> val epoch 1070 avg loss: 0.98247 (A-MSE: 0.83124) avg lploss: 0.00000
==> test epoch 1070 avg loss: 1.13216 (A-MSE: 0.96871) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 1 out of 50
train epoch 1071 avg loss: 0.52625 (A-MSE: 0.45706) avg lploss: 0.00000
train epoch 1072 avg loss: 0.51952 (A-MSE: 0.44967) avg lploss: 0.00000
train epoch 1073 avg loss: 0.48963 (A-MSE: 0.42295) avg lploss: 0.00000
train epoch 1074 avg loss: 0.47695 (A-MSE: 0.41142) avg lploss: 0.00000
train epoch 1075 avg loss: 0.51561 (A-MSE: 0.44454) avg lploss: 0.00000
==> val epoch 1075 avg loss: 1.06936 (A-MSE: 0.90922) avg lploss: 0.00000
==> test epoch 1075 avg loss: 1.26554 (A-MSE: 1.08846) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 2 out of 50
train epoch 1076 avg loss: 0.51673 (A-MSE: 0.44362) avg lploss: 0.00000
train epoch 1077 avg loss: 0.49830 (A-MSE: 0.43064) avg lploss: 0.00000
train epoch 1078 avg loss: 0.46286 (A-MSE: 0.39787) avg lploss: 0.00000
train epoch 1079 avg loss: 0.50914 (A-MSE: 0.44464) avg lploss: 0.00000
train epoch 1080 avg loss: 0.50537 (A-MSE: 0.43221) avg lploss: 0.00000
==> val epoch 1080 avg loss: 0.92564 (A-MSE: 0.80109) avg lploss: 0.00000
==> test epoch 1080 avg loss: 1.23015 (A-MSE: 1.07506) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 3 out of 50
train epoch 1081 avg loss: 0.47540 (A-MSE: 0.41326) avg lploss: 0.00000
train epoch 1082 avg loss: 0.47065 (A-MSE: 0.40392) avg lploss: 0.00000
train epoch 1083 avg loss: 0.43572 (A-MSE: 0.38112) avg lploss: 0.00000
train epoch 1084 avg loss: 0.44091 (A-MSE: 0.37984) avg lploss: 0.00000
train epoch 1085 avg loss: 0.50358 (A-MSE: 0.43592) avg lploss: 0.00000
==> val epoch 1085 avg loss: 1.07075 (A-MSE: 0.91033) avg lploss: 0.00000
==> test epoch 1085 avg loss: 1.33737 (A-MSE: 1.15330) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 4 out of 50
train epoch 1086 avg loss: 0.47316 (A-MSE: 0.40585) avg lploss: 0.00000
train epoch 1087 avg loss: 0.43365 (A-MSE: 0.37438) avg lploss: 0.00000
train epoch 1088 avg loss: 0.47341 (A-MSE: 0.41326) avg lploss: 0.00000
train epoch 1089 avg loss: 0.47927 (A-MSE: 0.41473) avg lploss: 0.00000
train epoch 1090 avg loss: 0.44801 (A-MSE: 0.38703) avg lploss: 0.00000
==> val epoch 1090 avg loss: 1.20774 (A-MSE: 1.03553) avg lploss: 0.00000
==> test epoch 1090 avg loss: 1.48660 (A-MSE: 1.29579) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 5 out of 50
train epoch 1091 avg loss: 0.46098 (A-MSE: 0.39992) avg lploss: 0.00000
train epoch 1092 avg loss: 0.46096 (A-MSE: 0.39956) avg lploss: 0.00000
train epoch 1093 avg loss: 0.45768 (A-MSE: 0.39580) avg lploss: 0.00000
train epoch 1094 avg loss: 0.49295 (A-MSE: 0.42874) avg lploss: 0.00000
train epoch 1095 avg loss: 0.46924 (A-MSE: 0.40714) avg lploss: 0.00000
==> val epoch 1095 avg loss: 0.93357 (A-MSE: 0.81280) avg lploss: 0.00000
==> test epoch 1095 avg loss: 1.14733 (A-MSE: 1.01048) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 6 out of 50
train epoch 1096 avg loss: 0.44945 (A-MSE: 0.39064) avg lploss: 0.00000
train epoch 1097 avg loss: 0.43800 (A-MSE: 0.37678) avg lploss: 0.00000
train epoch 1098 avg loss: 0.43747 (A-MSE: 0.37656) avg lploss: 0.00000
train epoch 1099 avg loss: 0.48927 (A-MSE: 0.42712) avg lploss: 0.00000
train epoch 1100 avg loss: 0.42561 (A-MSE: 0.36817) avg lploss: 0.00000
==> val epoch 1100 avg loss: 0.91785 (A-MSE: 0.78255) avg lploss: 0.00000
==> test epoch 1100 avg loss: 1.15175 (A-MSE: 0.99567) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 7 out of 50
train epoch 1101 avg loss: 0.45933 (A-MSE: 0.39457) avg lploss: 0.00000
train epoch 1102 avg loss: 0.49669 (A-MSE: 0.42637) avg lploss: 0.00000
train epoch 1103 avg loss: 0.42909 (A-MSE: 0.37325) avg lploss: 0.00000
train epoch 1104 avg loss: 0.47178 (A-MSE: 0.40948) avg lploss: 0.00000
train epoch 1105 avg loss: 0.45615 (A-MSE: 0.39630) avg lploss: 0.00000
==> val epoch 1105 avg loss: 0.94936 (A-MSE: 0.81086) avg lploss: 0.00000
==> test epoch 1105 avg loss: 1.19057 (A-MSE: 1.03004) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 8 out of 50
train epoch 1106 avg loss: 0.44791 (A-MSE: 0.39074) avg lploss: 0.00000
train epoch 1107 avg loss: 0.49668 (A-MSE: 0.42965) avg lploss: 0.00000
train epoch 1108 avg loss: 0.48856 (A-MSE: 0.42142) avg lploss: 0.00000
train epoch 1109 avg loss: 0.49794 (A-MSE: 0.42950) avg lploss: 0.00000
train epoch 1110 avg loss: 0.43460 (A-MSE: 0.37512) avg lploss: 0.00000
==> val epoch 1110 avg loss: 1.02994 (A-MSE: 0.87467) avg lploss: 0.00000
==> test epoch 1110 avg loss: 1.25486 (A-MSE: 1.07861) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 9 out of 50
train epoch 1111 avg loss: 0.42838 (A-MSE: 0.37031) avg lploss: 0.00000
train epoch 1112 avg loss: 0.41393 (A-MSE: 0.36023) avg lploss: 0.00000
train epoch 1113 avg loss: 0.41110 (A-MSE: 0.35630) avg lploss: 0.00000
train epoch 1114 avg loss: 0.41390 (A-MSE: 0.36270) avg lploss: 0.00000
train epoch 1115 avg loss: 0.45337 (A-MSE: 0.39131) avg lploss: 0.00000
==> val epoch 1115 avg loss: 0.97961 (A-MSE: 0.84423) avg lploss: 0.00000
==> test epoch 1115 avg loss: 1.24792 (A-MSE: 1.09767) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 10 out of 50
train epoch 1116 avg loss: 0.45183 (A-MSE: 0.38934) avg lploss: 0.00000
train epoch 1117 avg loss: 0.44255 (A-MSE: 0.38360) avg lploss: 0.00000
train epoch 1118 avg loss: 0.50501 (A-MSE: 0.43627) avg lploss: 0.00000
train epoch 1119 avg loss: 0.54228 (A-MSE: 0.47363) avg lploss: 0.00000
train epoch 1120 avg loss: 0.52808 (A-MSE: 0.45651) avg lploss: 0.00000
==> val epoch 1120 avg loss: 1.12244 (A-MSE: 0.95006) avg lploss: 0.00000
==> test epoch 1120 avg loss: 1.38378 (A-MSE: 1.18695) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 11 out of 50
train epoch 1121 avg loss: 0.44556 (A-MSE: 0.38488) avg lploss: 0.00000
train epoch 1122 avg loss: 0.43556 (A-MSE: 0.37845) avg lploss: 0.00000
train epoch 1123 avg loss: 0.46321 (A-MSE: 0.40380) avg lploss: 0.00000
train epoch 1124 avg loss: 0.41832 (A-MSE: 0.36179) avg lploss: 0.00000
train epoch 1125 avg loss: 0.41125 (A-MSE: 0.35661) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.99422 (A-MSE: 0.84224) avg lploss: 0.00000
==> test epoch 1125 avg loss: 1.19287 (A-MSE: 1.02654) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 12 out of 50
train epoch 1126 avg loss: 0.42390 (A-MSE: 0.36601) avg lploss: 0.00000
train epoch 1127 avg loss: 0.42625 (A-MSE: 0.36640) avg lploss: 0.00000
train epoch 1128 avg loss: 0.44603 (A-MSE: 0.38635) avg lploss: 0.00000
train epoch 1129 avg loss: 0.44437 (A-MSE: 0.38465) avg lploss: 0.00000
train epoch 1130 avg loss: 0.46190 (A-MSE: 0.40103) avg lploss: 0.00000
==> val epoch 1130 avg loss: 1.16662 (A-MSE: 0.97229) avg lploss: 0.00000
==> test epoch 1130 avg loss: 1.34294 (A-MSE: 1.14009) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 13 out of 50
train epoch 1131 avg loss: 0.45177 (A-MSE: 0.39304) avg lploss: 0.00000
train epoch 1132 avg loss: 0.43305 (A-MSE: 0.37404) avg lploss: 0.00000
train epoch 1133 avg loss: 0.41299 (A-MSE: 0.35888) avg lploss: 0.00000
train epoch 1134 avg loss: 0.40868 (A-MSE: 0.35278) avg lploss: 0.00000
train epoch 1135 avg loss: 0.40361 (A-MSE: 0.34965) avg lploss: 0.00000
==> val epoch 1135 avg loss: 1.08140 (A-MSE: 0.91514) avg lploss: 0.00000
==> test epoch 1135 avg loss: 1.29155 (A-MSE: 1.11132) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 14 out of 50
train epoch 1136 avg loss: 0.41699 (A-MSE: 0.35966) avg lploss: 0.00000
train epoch 1137 avg loss: 0.43595 (A-MSE: 0.37656) avg lploss: 0.00000
train epoch 1138 avg loss: 0.47980 (A-MSE: 0.41844) avg lploss: 0.00000
train epoch 1139 avg loss: 0.43542 (A-MSE: 0.37509) avg lploss: 0.00000
train epoch 1140 avg loss: 0.44791 (A-MSE: 0.38831) avg lploss: 0.00000
==> val epoch 1140 avg loss: 1.04344 (A-MSE: 0.88811) avg lploss: 0.00000
==> test epoch 1140 avg loss: 1.18150 (A-MSE: 1.02492) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 15 out of 50
train epoch 1141 avg loss: 0.45100 (A-MSE: 0.39085) avg lploss: 0.00000
train epoch 1142 avg loss: 0.41306 (A-MSE: 0.35842) avg lploss: 0.00000
train epoch 1143 avg loss: 0.42354 (A-MSE: 0.36788) avg lploss: 0.00000
train epoch 1144 avg loss: 0.43870 (A-MSE: 0.37851) avg lploss: 0.00000
train epoch 1145 avg loss: 0.47339 (A-MSE: 0.41650) avg lploss: 0.00000
==> val epoch 1145 avg loss: 1.13543 (A-MSE: 0.95526) avg lploss: 0.00000
==> test epoch 1145 avg loss: 1.36535 (A-MSE: 1.17414) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 16 out of 50
train epoch 1146 avg loss: 0.43334 (A-MSE: 0.37351) avg lploss: 0.00000
train epoch 1147 avg loss: 0.41233 (A-MSE: 0.35647) avg lploss: 0.00000
train epoch 1148 avg loss: 0.41059 (A-MSE: 0.35797) avg lploss: 0.00000
train epoch 1149 avg loss: 0.40538 (A-MSE: 0.34737) avg lploss: 0.00000
train epoch 1150 avg loss: 0.39956 (A-MSE: 0.34588) avg lploss: 0.00000
==> val epoch 1150 avg loss: 0.98001 (A-MSE: 0.84991) avg lploss: 0.00000
==> test epoch 1150 avg loss: 1.22775 (A-MSE: 1.08071) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 17 out of 50
train epoch 1151 avg loss: 0.41030 (A-MSE: 0.35757) avg lploss: 0.00000
train epoch 1152 avg loss: 0.39704 (A-MSE: 0.34343) avg lploss: 0.00000
train epoch 1153 avg loss: 0.39422 (A-MSE: 0.34270) avg lploss: 0.00000
train epoch 1154 avg loss: 0.42057 (A-MSE: 0.37046) avg lploss: 0.00000
train epoch 1155 avg loss: 0.40596 (A-MSE: 0.34959) avg lploss: 0.00000
==> val epoch 1155 avg loss: 0.95480 (A-MSE: 0.82094) avg lploss: 0.00000
==> test epoch 1155 avg loss: 1.24522 (A-MSE: 1.08406) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 18 out of 50
train epoch 1156 avg loss: 0.43890 (A-MSE: 0.38012) avg lploss: 0.00000
train epoch 1157 avg loss: 0.42207 (A-MSE: 0.36333) avg lploss: 0.00000
train epoch 1158 avg loss: 0.45581 (A-MSE: 0.39581) avg lploss: 0.00000
train epoch 1159 avg loss: 0.54431 (A-MSE: 0.47169) avg lploss: 0.00000
train epoch 1160 avg loss: 0.51949 (A-MSE: 0.44951) avg lploss: 0.00000
==> val epoch 1160 avg loss: 1.05914 (A-MSE: 0.91169) avg lploss: 0.00000
==> test epoch 1160 avg loss: 1.31970 (A-MSE: 1.15141) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 19 out of 50
train epoch 1161 avg loss: 0.44641 (A-MSE: 0.38428) avg lploss: 0.00000
train epoch 1162 avg loss: 0.47487 (A-MSE: 0.41600) avg lploss: 0.00000
train epoch 1163 avg loss: 0.39740 (A-MSE: 0.34583) avg lploss: 0.00000
train epoch 1164 avg loss: 0.44786 (A-MSE: 0.38574) avg lploss: 0.00000
train epoch 1165 avg loss: 0.47896 (A-MSE: 0.41654) avg lploss: 0.00000
==> val epoch 1165 avg loss: 0.94792 (A-MSE: 0.81338) avg lploss: 0.00000
==> test epoch 1165 avg loss: 1.18253 (A-MSE: 1.01961) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 20 out of 50
train epoch 1166 avg loss: 0.43323 (A-MSE: 0.37402) avg lploss: 0.00000
train epoch 1167 avg loss: 0.40148 (A-MSE: 0.34712) avg lploss: 0.00000
train epoch 1168 avg loss: 0.39683 (A-MSE: 0.34378) avg lploss: 0.00000
train epoch 1169 avg loss: 0.41497 (A-MSE: 0.36313) avg lploss: 0.00000
train epoch 1170 avg loss: 0.42110 (A-MSE: 0.36225) avg lploss: 0.00000
==> val epoch 1170 avg loss: 1.04733 (A-MSE: 0.88845) avg lploss: 0.00000
==> test epoch 1170 avg loss: 1.22671 (A-MSE: 1.05155) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 21 out of 50
train epoch 1171 avg loss: 0.42956 (A-MSE: 0.37124) avg lploss: 0.00000
train epoch 1172 avg loss: 0.42251 (A-MSE: 0.36662) avg lploss: 0.00000
train epoch 1173 avg loss: 0.41077 (A-MSE: 0.35623) avg lploss: 0.00000
train epoch 1174 avg loss: 0.41076 (A-MSE: 0.35706) avg lploss: 0.00000
train epoch 1175 avg loss: 0.46004 (A-MSE: 0.39796) avg lploss: 0.00000
==> val epoch 1175 avg loss: 1.02624 (A-MSE: 0.87630) avg lploss: 0.00000
==> test epoch 1175 avg loss: 1.25122 (A-MSE: 1.08958) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 22 out of 50
train epoch 1176 avg loss: 0.42461 (A-MSE: 0.36687) avg lploss: 0.00000
train epoch 1177 avg loss: 0.42174 (A-MSE: 0.36583) avg lploss: 0.00000
train epoch 1178 avg loss: 0.40713 (A-MSE: 0.35565) avg lploss: 0.00000
train epoch 1179 avg loss: 0.44804 (A-MSE: 0.38801) avg lploss: 0.00000
train epoch 1180 avg loss: 0.45963 (A-MSE: 0.40064) avg lploss: 0.00000
==> val epoch 1180 avg loss: 1.09487 (A-MSE: 0.92642) avg lploss: 0.00000
==> test epoch 1180 avg loss: 1.30698 (A-MSE: 1.11597) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 23 out of 50
train epoch 1181 avg loss: 0.41200 (A-MSE: 0.35661) avg lploss: 0.00000
train epoch 1182 avg loss: 0.46519 (A-MSE: 0.40605) avg lploss: 0.00000
train epoch 1183 avg loss: 0.45462 (A-MSE: 0.39673) avg lploss: 0.00000
train epoch 1184 avg loss: 0.44124 (A-MSE: 0.38475) avg lploss: 0.00000
train epoch 1185 avg loss: 0.43311 (A-MSE: 0.37671) avg lploss: 0.00000
==> val epoch 1185 avg loss: 1.14755 (A-MSE: 0.96259) avg lploss: 0.00000
==> test epoch 1185 avg loss: 1.35802 (A-MSE: 1.16138) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 24 out of 50
train epoch 1186 avg loss: 0.44194 (A-MSE: 0.37853) avg lploss: 0.00000
train epoch 1187 avg loss: 0.42705 (A-MSE: 0.37155) avg lploss: 0.00000
train epoch 1188 avg loss: 0.39851 (A-MSE: 0.34432) avg lploss: 0.00000
train epoch 1189 avg loss: 0.40373 (A-MSE: 0.34893) avg lploss: 0.00000
train epoch 1190 avg loss: 0.43454 (A-MSE: 0.37834) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.98893 (A-MSE: 0.85500) avg lploss: 0.00000
==> test epoch 1190 avg loss: 1.25448 (A-MSE: 1.10189) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 25 out of 50
train epoch 1191 avg loss: 0.40215 (A-MSE: 0.34912) avg lploss: 0.00000
train epoch 1192 avg loss: 0.40973 (A-MSE: 0.35277) avg lploss: 0.00000
train epoch 1193 avg loss: 0.40350 (A-MSE: 0.34960) avg lploss: 0.00000
train epoch 1194 avg loss: 0.40077 (A-MSE: 0.34856) avg lploss: 0.00000
train epoch 1195 avg loss: 0.37724 (A-MSE: 0.32818) avg lploss: 0.00000
==> val epoch 1195 avg loss: 0.94620 (A-MSE: 0.79847) avg lploss: 0.00000
==> test epoch 1195 avg loss: 1.14967 (A-MSE: 0.98844) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 26 out of 50
train epoch 1196 avg loss: 0.37988 (A-MSE: 0.33042) avg lploss: 0.00000
train epoch 1197 avg loss: 0.36225 (A-MSE: 0.31429) avg lploss: 0.00000
train epoch 1198 avg loss: 0.40676 (A-MSE: 0.35454) avg lploss: 0.00000
train epoch 1199 avg loss: 0.41417 (A-MSE: 0.35927) avg lploss: 0.00000
train epoch 1200 avg loss: 0.39501 (A-MSE: 0.34549) avg lploss: 0.00000
==> val epoch 1200 avg loss: 0.91655 (A-MSE: 0.79060) avg lploss: 0.00000
==> test epoch 1200 avg loss: 1.14225 (A-MSE: 0.99841) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 27 out of 50
train epoch 1201 avg loss: 0.37759 (A-MSE: 0.32988) avg lploss: 0.00000
train epoch 1202 avg loss: 0.38130 (A-MSE: 0.33296) avg lploss: 0.00000
train epoch 1203 avg loss: 0.39133 (A-MSE: 0.34059) avg lploss: 0.00000
train epoch 1204 avg loss: 0.39142 (A-MSE: 0.33994) avg lploss: 0.00000
train epoch 1205 avg loss: 0.38006 (A-MSE: 0.32991) avg lploss: 0.00000
==> val epoch 1205 avg loss: 1.00249 (A-MSE: 0.84509) avg lploss: 0.00000
==> test epoch 1205 avg loss: 1.20437 (A-MSE: 1.03793) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 28 out of 50
train epoch 1206 avg loss: 0.41208 (A-MSE: 0.35830) avg lploss: 0.00000
train epoch 1207 avg loss: 0.39375 (A-MSE: 0.34175) avg lploss: 0.00000
train epoch 1208 avg loss: 0.39875 (A-MSE: 0.34632) avg lploss: 0.00000
train epoch 1209 avg loss: 0.42126 (A-MSE: 0.36409) avg lploss: 0.00000
train epoch 1210 avg loss: 0.42219 (A-MSE: 0.36727) avg lploss: 0.00000
==> val epoch 1210 avg loss: 1.10710 (A-MSE: 0.94724) avg lploss: 0.00000
==> test epoch 1210 avg loss: 1.31934 (A-MSE: 1.14225) avg lploss: 0.00000
*** Best Val Loss: 0.90805 	 Best Test Loss: 1.09270 	 Best epoch 1065
EarlyStopping counter: 29 out of 50
train epoch 1211 avg loss: 0.42656 (A-MSE: 0.37066) avg lploss: 0.00000
train epoch 1212 avg loss: 0.38311 (A-MSE: 0.33165) avg lploss: 0.00000
train epoch 1213 avg loss: 0.46489 (A-MSE: 0.40635) avg lploss: 0.00000
train epoch 1214 avg loss: 0.43758 (A-MSE: 0.38221) avg lploss: 0.00000
train epoch 1215 avg loss: 0.39960 (A-MSE: 0.34727) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.90572 (A-MSE: 0.77280) avg lploss: 0.00000
==> test epoch 1215 avg loss: 1.11444 (A-MSE: 0.96397) avg lploss: 0.00000
*** Best Val Loss: 0.90572 	 Best Test Loss: 1.11444 	 Best epoch 1215
Validation loss decreased (0.908050 --> 0.905725).  Saving model ...
train epoch 1216 avg loss: 0.40202 (A-MSE: 0.35052) avg lploss: 0.00000
train epoch 1217 avg loss: 0.40191 (A-MSE: 0.34684) avg lploss: 0.00000
train epoch 1218 avg loss: 0.39084 (A-MSE: 0.33813) avg lploss: 0.00000
train epoch 1219 avg loss: 0.41066 (A-MSE: 0.35631) avg lploss: 0.00000
train epoch 1220 avg loss: 0.50285 (A-MSE: 0.43723) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.87662 (A-MSE: 0.75074) avg lploss: 0.00000
==> test epoch 1220 avg loss: 1.03346 (A-MSE: 0.90396) avg lploss: 0.00000
*** Best Val Loss: 0.87662 	 Best Test Loss: 1.03346 	 Best epoch 1220
Validation loss decreased (0.905725 --> 0.876618).  Saving model ...
train epoch 1221 avg loss: 0.47438 (A-MSE: 0.41102) avg lploss: 0.00000
train epoch 1222 avg loss: 0.41471 (A-MSE: 0.36053) avg lploss: 0.00000
train epoch 1223 avg loss: 0.38574 (A-MSE: 0.33680) avg lploss: 0.00000
train epoch 1224 avg loss: 0.41669 (A-MSE: 0.35924) avg lploss: 0.00000
train epoch 1225 avg loss: 0.39776 (A-MSE: 0.34611) avg lploss: 0.00000
==> val epoch 1225 avg loss: 1.05295 (A-MSE: 0.89156) avg lploss: 0.00000
==> test epoch 1225 avg loss: 1.23153 (A-MSE: 1.05932) avg lploss: 0.00000
*** Best Val Loss: 0.87662 	 Best Test Loss: 1.03346 	 Best epoch 1220
EarlyStopping counter: 1 out of 50
train epoch 1226 avg loss: 0.37858 (A-MSE: 0.32942) avg lploss: 0.00000
train epoch 1227 avg loss: 0.41987 (A-MSE: 0.36246) avg lploss: 0.00000
train epoch 1228 avg loss: 0.44674 (A-MSE: 0.38789) avg lploss: 0.00000
train epoch 1229 avg loss: 0.41336 (A-MSE: 0.35598) avg lploss: 0.00000
train epoch 1230 avg loss: 0.39232 (A-MSE: 0.34400) avg lploss: 0.00000
==> val epoch 1230 avg loss: 1.02503 (A-MSE: 0.86814) avg lploss: 0.00000
==> test epoch 1230 avg loss: 1.18917 (A-MSE: 1.02596) avg lploss: 0.00000
*** Best Val Loss: 0.87662 	 Best Test Loss: 1.03346 	 Best epoch 1220
EarlyStopping counter: 2 out of 50
train epoch 1231 avg loss: 0.41356 (A-MSE: 0.36157) avg lploss: 0.00000
train epoch 1232 avg loss: 0.42834 (A-MSE: 0.37014) avg lploss: 0.00000
train epoch 1233 avg loss: 0.39410 (A-MSE: 0.34448) avg lploss: 0.00000
train epoch 1234 avg loss: 0.39659 (A-MSE: 0.34353) avg lploss: 0.00000
train epoch 1235 avg loss: 0.42852 (A-MSE: 0.37182) avg lploss: 0.00000
==> val epoch 1235 avg loss: 1.00410 (A-MSE: 0.86391) avg lploss: 0.00000
==> test epoch 1235 avg loss: 1.22561 (A-MSE: 1.07185) avg lploss: 0.00000
*** Best Val Loss: 0.87662 	 Best Test Loss: 1.03346 	 Best epoch 1220
EarlyStopping counter: 3 out of 50
train epoch 1236 avg loss: 0.38935 (A-MSE: 0.33881) avg lploss: 0.00000
train epoch 1237 avg loss: 0.38880 (A-MSE: 0.33780) avg lploss: 0.00000
train epoch 1238 avg loss: 0.37519 (A-MSE: 0.32505) avg lploss: 0.00000
train epoch 1239 avg loss: 0.36188 (A-MSE: 0.31281) avg lploss: 0.00000
train epoch 1240 avg loss: 0.39117 (A-MSE: 0.33885) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.93316 (A-MSE: 0.80197) avg lploss: 0.00000
==> test epoch 1240 avg loss: 1.13378 (A-MSE: 0.98869) avg lploss: 0.00000
*** Best Val Loss: 0.87662 	 Best Test Loss: 1.03346 	 Best epoch 1220
EarlyStopping counter: 4 out of 50
train epoch 1241 avg loss: 0.40878 (A-MSE: 0.35496) avg lploss: 0.00000
train epoch 1242 avg loss: 0.36958 (A-MSE: 0.31975) avg lploss: 0.00000
train epoch 1243 avg loss: 0.43506 (A-MSE: 0.37946) avg lploss: 0.00000
train epoch 1244 avg loss: 0.44954 (A-MSE: 0.38975) avg lploss: 0.00000
train epoch 1245 avg loss: 0.38785 (A-MSE: 0.33649) avg lploss: 0.00000
==> val epoch 1245 avg loss: 0.85597 (A-MSE: 0.73177) avg lploss: 0.00000
==> test epoch 1245 avg loss: 1.04886 (A-MSE: 0.90778) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
Validation loss decreased (0.876618 --> 0.855967).  Saving model ...
train epoch 1246 avg loss: 0.41993 (A-MSE: 0.36730) avg lploss: 0.00000
train epoch 1247 avg loss: 0.40009 (A-MSE: 0.34834) avg lploss: 0.00000
train epoch 1248 avg loss: 0.38340 (A-MSE: 0.33378) avg lploss: 0.00000
train epoch 1249 avg loss: 0.40685 (A-MSE: 0.35622) avg lploss: 0.00000
train epoch 1250 avg loss: 0.40624 (A-MSE: 0.35312) avg lploss: 0.00000
==> val epoch 1250 avg loss: 0.93295 (A-MSE: 0.79605) avg lploss: 0.00000
==> test epoch 1250 avg loss: 1.14186 (A-MSE: 0.98508) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 1 out of 50
train epoch 1251 avg loss: 0.38974 (A-MSE: 0.34184) avg lploss: 0.00000
train epoch 1252 avg loss: 0.37435 (A-MSE: 0.32663) avg lploss: 0.00000
train epoch 1253 avg loss: 0.35492 (A-MSE: 0.30633) avg lploss: 0.00000
train epoch 1254 avg loss: 0.35234 (A-MSE: 0.30704) avg lploss: 0.00000
train epoch 1255 avg loss: 0.36461 (A-MSE: 0.31603) avg lploss: 0.00000
==> val epoch 1255 avg loss: 1.00299 (A-MSE: 0.86281) avg lploss: 0.00000
==> test epoch 1255 avg loss: 1.19932 (A-MSE: 1.04647) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 2 out of 50
train epoch 1256 avg loss: 0.38462 (A-MSE: 0.33705) avg lploss: 0.00000
train epoch 1257 avg loss: 0.43598 (A-MSE: 0.37986) avg lploss: 0.00000
train epoch 1258 avg loss: 0.44035 (A-MSE: 0.37846) avg lploss: 0.00000
train epoch 1259 avg loss: 0.39574 (A-MSE: 0.34449) avg lploss: 0.00000
train epoch 1260 avg loss: 0.36348 (A-MSE: 0.31666) avg lploss: 0.00000
==> val epoch 1260 avg loss: 0.87182 (A-MSE: 0.75593) avg lploss: 0.00000
==> test epoch 1260 avg loss: 1.09575 (A-MSE: 0.95774) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 3 out of 50
train epoch 1261 avg loss: 0.35181 (A-MSE: 0.30574) avg lploss: 0.00000
train epoch 1262 avg loss: 0.36509 (A-MSE: 0.31796) avg lploss: 0.00000
train epoch 1263 avg loss: 0.36619 (A-MSE: 0.32208) avg lploss: 0.00000
train epoch 1264 avg loss: 0.37780 (A-MSE: 0.32997) avg lploss: 0.00000
train epoch 1265 avg loss: 0.37986 (A-MSE: 0.33108) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.88532 (A-MSE: 0.75348) avg lploss: 0.00000
==> test epoch 1265 avg loss: 1.11066 (A-MSE: 0.95899) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 4 out of 50
train epoch 1266 avg loss: 0.39508 (A-MSE: 0.34144) avg lploss: 0.00000
train epoch 1267 avg loss: 0.39504 (A-MSE: 0.34404) avg lploss: 0.00000
train epoch 1268 avg loss: 0.39129 (A-MSE: 0.34010) avg lploss: 0.00000
train epoch 1269 avg loss: 0.35129 (A-MSE: 0.30429) avg lploss: 0.00000
train epoch 1270 avg loss: 0.36508 (A-MSE: 0.32033) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.90630 (A-MSE: 0.76754) avg lploss: 0.00000
==> test epoch 1270 avg loss: 1.12503 (A-MSE: 0.97261) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 5 out of 50
train epoch 1271 avg loss: 0.43105 (A-MSE: 0.37622) avg lploss: 0.00000
train epoch 1272 avg loss: 0.42710 (A-MSE: 0.37490) avg lploss: 0.00000
train epoch 1273 avg loss: 0.41987 (A-MSE: 0.36402) avg lploss: 0.00000
train epoch 1274 avg loss: 0.40899 (A-MSE: 0.35513) avg lploss: 0.00000
train epoch 1275 avg loss: 0.39290 (A-MSE: 0.34086) avg lploss: 0.00000
==> val epoch 1275 avg loss: 1.06621 (A-MSE: 0.91606) avg lploss: 0.00000
==> test epoch 1275 avg loss: 1.31214 (A-MSE: 1.14284) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 6 out of 50
train epoch 1276 avg loss: 0.41557 (A-MSE: 0.36187) avg lploss: 0.00000
train epoch 1277 avg loss: 0.38847 (A-MSE: 0.33667) avg lploss: 0.00000
train epoch 1278 avg loss: 0.37789 (A-MSE: 0.32879) avg lploss: 0.00000
train epoch 1279 avg loss: 0.40924 (A-MSE: 0.35779) avg lploss: 0.00000
train epoch 1280 avg loss: 0.37280 (A-MSE: 0.32443) avg lploss: 0.00000
==> val epoch 1280 avg loss: 1.09397 (A-MSE: 0.93918) avg lploss: 0.00000
==> test epoch 1280 avg loss: 1.33532 (A-MSE: 1.15962) avg lploss: 0.00000
*** Best Val Loss: 0.85597 	 Best Test Loss: 1.04886 	 Best epoch 1245
EarlyStopping counter: 7 out of 50
train epoch 1281 avg loss: 0.36042 (A-MSE: 0.31520) avg lploss: 0.00000
train epoch 1282 avg loss: 0.37310 (A-MSE: 0.32226) avg lploss: 0.00000
train epoch 1283 avg loss: 0.37126 (A-MSE: 0.32411) avg lploss: 0.00000
train epoch 1284 avg loss: 0.38600 (A-MSE: 0.33606) avg lploss: 0.00000
train epoch 1285 avg loss: 0.37194 (A-MSE: 0.32154) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.82434 (A-MSE: 0.71604) avg lploss: 0.00000
==> test epoch 1285 avg loss: 1.01389 (A-MSE: 0.88675) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
Validation loss decreased (0.855967 --> 0.824340).  Saving model ...
train epoch 1286 avg loss: 0.37340 (A-MSE: 0.32613) avg lploss: 0.00000
train epoch 1287 avg loss: 0.39611 (A-MSE: 0.34411) avg lploss: 0.00000
train epoch 1288 avg loss: 0.40910 (A-MSE: 0.35307) avg lploss: 0.00000
train epoch 1289 avg loss: 0.38182 (A-MSE: 0.33164) avg lploss: 0.00000
train epoch 1290 avg loss: 0.37327 (A-MSE: 0.32233) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.96747 (A-MSE: 0.83678) avg lploss: 0.00000
==> test epoch 1290 avg loss: 1.22561 (A-MSE: 1.07768) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 1 out of 50
train epoch 1291 avg loss: 0.33747 (A-MSE: 0.29418) avg lploss: 0.00000
train epoch 1292 avg loss: 0.35367 (A-MSE: 0.30768) avg lploss: 0.00000
train epoch 1293 avg loss: 0.36880 (A-MSE: 0.32180) avg lploss: 0.00000
train epoch 1294 avg loss: 0.36708 (A-MSE: 0.31722) avg lploss: 0.00000
train epoch 1295 avg loss: 0.39031 (A-MSE: 0.33896) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.93906 (A-MSE: 0.80351) avg lploss: 0.00000
==> test epoch 1295 avg loss: 1.18654 (A-MSE: 1.03802) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 2 out of 50
train epoch 1296 avg loss: 0.37101 (A-MSE: 0.32357) avg lploss: 0.00000
train epoch 1297 avg loss: 0.35232 (A-MSE: 0.30612) avg lploss: 0.00000
train epoch 1298 avg loss: 0.35230 (A-MSE: 0.30507) avg lploss: 0.00000
train epoch 1299 avg loss: 0.35549 (A-MSE: 0.30924) avg lploss: 0.00000
train epoch 1300 avg loss: 0.36489 (A-MSE: 0.31861) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.95417 (A-MSE: 0.81787) avg lploss: 0.00000
==> test epoch 1300 avg loss: 1.12712 (A-MSE: 0.97887) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 3 out of 50
train epoch 1301 avg loss: 0.38681 (A-MSE: 0.33592) avg lploss: 0.00000
train epoch 1302 avg loss: 0.35899 (A-MSE: 0.31330) avg lploss: 0.00000
train epoch 1303 avg loss: 0.36250 (A-MSE: 0.31563) avg lploss: 0.00000
train epoch 1304 avg loss: 0.39617 (A-MSE: 0.34907) avg lploss: 0.00000
train epoch 1305 avg loss: 0.38465 (A-MSE: 0.33728) avg lploss: 0.00000
==> val epoch 1305 avg loss: 1.13444 (A-MSE: 0.96346) avg lploss: 0.00000
==> test epoch 1305 avg loss: 1.28480 (A-MSE: 1.10953) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 4 out of 50
train epoch 1306 avg loss: 0.38061 (A-MSE: 0.32858) avg lploss: 0.00000
train epoch 1307 avg loss: 0.37029 (A-MSE: 0.32242) avg lploss: 0.00000
train epoch 1308 avg loss: 0.35788 (A-MSE: 0.31297) avg lploss: 0.00000
train epoch 1309 avg loss: 0.36207 (A-MSE: 0.31438) avg lploss: 0.00000
train epoch 1310 avg loss: 0.37178 (A-MSE: 0.32465) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.88995 (A-MSE: 0.76090) avg lploss: 0.00000
==> test epoch 1310 avg loss: 1.09012 (A-MSE: 0.95249) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 5 out of 50
train epoch 1311 avg loss: 0.37482 (A-MSE: 0.32721) avg lploss: 0.00000
train epoch 1312 avg loss: 0.37552 (A-MSE: 0.32497) avg lploss: 0.00000
train epoch 1313 avg loss: 0.37978 (A-MSE: 0.33175) avg lploss: 0.00000
train epoch 1314 avg loss: 0.43493 (A-MSE: 0.37883) avg lploss: 0.00000
train epoch 1315 avg loss: 0.40270 (A-MSE: 0.34754) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.94740 (A-MSE: 0.80951) avg lploss: 0.00000
==> test epoch 1315 avg loss: 1.10350 (A-MSE: 0.95484) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 6 out of 50
train epoch 1316 avg loss: 0.37056 (A-MSE: 0.32090) avg lploss: 0.00000
train epoch 1317 avg loss: 0.38044 (A-MSE: 0.32952) avg lploss: 0.00000
train epoch 1318 avg loss: 0.33669 (A-MSE: 0.29353) avg lploss: 0.00000
train epoch 1319 avg loss: 0.34093 (A-MSE: 0.29620) avg lploss: 0.00000
train epoch 1320 avg loss: 0.35036 (A-MSE: 0.30285) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.90631 (A-MSE: 0.78480) avg lploss: 0.00000
==> test epoch 1320 avg loss: 1.13929 (A-MSE: 1.00053) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 7 out of 50
train epoch 1321 avg loss: 0.34522 (A-MSE: 0.30129) avg lploss: 0.00000
train epoch 1322 avg loss: 0.35639 (A-MSE: 0.31113) avg lploss: 0.00000
train epoch 1323 avg loss: 0.35917 (A-MSE: 0.31020) avg lploss: 0.00000
train epoch 1324 avg loss: 0.31731 (A-MSE: 0.27817) avg lploss: 0.00000
train epoch 1325 avg loss: 0.32035 (A-MSE: 0.27938) avg lploss: 0.00000
==> val epoch 1325 avg loss: 0.88145 (A-MSE: 0.76051) avg lploss: 0.00000
==> test epoch 1325 avg loss: 1.06721 (A-MSE: 0.93811) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 8 out of 50
train epoch 1326 avg loss: 0.35082 (A-MSE: 0.30579) avg lploss: 0.00000
train epoch 1327 avg loss: 0.36090 (A-MSE: 0.31521) avg lploss: 0.00000
train epoch 1328 avg loss: 0.35340 (A-MSE: 0.30838) avg lploss: 0.00000
train epoch 1329 avg loss: 0.33862 (A-MSE: 0.29515) avg lploss: 0.00000
train epoch 1330 avg loss: 0.36191 (A-MSE: 0.31823) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.89255 (A-MSE: 0.76239) avg lploss: 0.00000
==> test epoch 1330 avg loss: 1.10337 (A-MSE: 0.96213) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 9 out of 50
train epoch 1331 avg loss: 0.36934 (A-MSE: 0.31815) avg lploss: 0.00000
train epoch 1332 avg loss: 0.37031 (A-MSE: 0.32006) avg lploss: 0.00000
train epoch 1333 avg loss: 0.36078 (A-MSE: 0.31594) avg lploss: 0.00000
train epoch 1334 avg loss: 0.36804 (A-MSE: 0.31798) avg lploss: 0.00000
train epoch 1335 avg loss: 0.33198 (A-MSE: 0.28865) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.97954 (A-MSE: 0.83265) avg lploss: 0.00000
==> test epoch 1335 avg loss: 1.19729 (A-MSE: 1.03303) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 10 out of 50
train epoch 1336 avg loss: 0.34980 (A-MSE: 0.30500) avg lploss: 0.00000
train epoch 1337 avg loss: 0.32610 (A-MSE: 0.28432) avg lploss: 0.00000
train epoch 1338 avg loss: 0.34893 (A-MSE: 0.30282) avg lploss: 0.00000
train epoch 1339 avg loss: 0.33879 (A-MSE: 0.29366) avg lploss: 0.00000
train epoch 1340 avg loss: 0.35271 (A-MSE: 0.30716) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.87169 (A-MSE: 0.74455) avg lploss: 0.00000
==> test epoch 1340 avg loss: 1.09139 (A-MSE: 0.94692) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 11 out of 50
train epoch 1341 avg loss: 0.36841 (A-MSE: 0.32261) avg lploss: 0.00000
train epoch 1342 avg loss: 0.39198 (A-MSE: 0.33940) avg lploss: 0.00000
train epoch 1343 avg loss: 0.35401 (A-MSE: 0.30807) avg lploss: 0.00000
train epoch 1344 avg loss: 0.35880 (A-MSE: 0.31453) avg lploss: 0.00000
train epoch 1345 avg loss: 0.36271 (A-MSE: 0.31494) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.91402 (A-MSE: 0.78744) avg lploss: 0.00000
==> test epoch 1345 avg loss: 1.10350 (A-MSE: 0.96883) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 12 out of 50
train epoch 1346 avg loss: 0.34386 (A-MSE: 0.30037) avg lploss: 0.00000
train epoch 1347 avg loss: 0.37306 (A-MSE: 0.32299) avg lploss: 0.00000
train epoch 1348 avg loss: 0.38138 (A-MSE: 0.33195) avg lploss: 0.00000
train epoch 1349 avg loss: 0.34426 (A-MSE: 0.30012) avg lploss: 0.00000
train epoch 1350 avg loss: 0.33417 (A-MSE: 0.29073) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.99331 (A-MSE: 0.84003) avg lploss: 0.00000
==> test epoch 1350 avg loss: 1.18317 (A-MSE: 1.01901) avg lploss: 0.00000
*** Best Val Loss: 0.82434 	 Best Test Loss: 1.01389 	 Best epoch 1285
EarlyStopping counter: 13 out of 50
train epoch 1351 avg loss: 0.31448 (A-MSE: 0.27434) avg lploss: 0.00000
train epoch 1352 avg loss: 0.31677 (A-MSE: 0.27615) avg lploss: 0.00000
train epoch 1353 avg loss: 0.35686 (A-MSE: 0.31234) avg lploss: 0.00000
train epoch 1354 avg loss: 0.32209 (A-MSE: 0.28048) avg lploss: 0.00000
train epoch 1355 avg loss: 0.36954 (A-MSE: 0.32387) avg lploss: 0.00000
==> val epoch 1355 avg loss: 0.82335 (A-MSE: 0.70869) avg lploss: 0.00000
==> test epoch 1355 avg loss: 0.95761 (A-MSE: 0.83365) avg lploss: 0.00000
*** Best Val Loss: 0.82335 	 Best Test Loss: 0.95761 	 Best epoch 1355
Validation loss decreased (0.824340 --> 0.823353).  Saving model ...
train epoch 1356 avg loss: 0.39039 (A-MSE: 0.33622) avg lploss: 0.00000
train epoch 1357 avg loss: 0.36391 (A-MSE: 0.31351) avg lploss: 0.00000
train epoch 1358 avg loss: 0.34384 (A-MSE: 0.29804) avg lploss: 0.00000
train epoch 1359 avg loss: 0.37066 (A-MSE: 0.32401) avg lploss: 0.00000
train epoch 1360 avg loss: 0.38195 (A-MSE: 0.33225) avg lploss: 0.00000
==> val epoch 1360 avg loss: 0.94714 (A-MSE: 0.80724) avg lploss: 0.00000
==> test epoch 1360 avg loss: 1.14450 (A-MSE: 0.99328) avg lploss: 0.00000
*** Best Val Loss: 0.82335 	 Best Test Loss: 0.95761 	 Best epoch 1355
EarlyStopping counter: 1 out of 50
train epoch 1361 avg loss: 0.35168 (A-MSE: 0.30448) avg lploss: 0.00000
train epoch 1362 avg loss: 0.37063 (A-MSE: 0.32220) avg lploss: 0.00000
train epoch 1363 avg loss: 0.40179 (A-MSE: 0.34830) avg lploss: 0.00000
train epoch 1364 avg loss: 0.34996 (A-MSE: 0.30599) avg lploss: 0.00000
train epoch 1365 avg loss: 0.36276 (A-MSE: 0.31693) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.96243 (A-MSE: 0.84092) avg lploss: 0.00000
==> test epoch 1365 avg loss: 1.15334 (A-MSE: 1.01798) avg lploss: 0.00000
*** Best Val Loss: 0.82335 	 Best Test Loss: 0.95761 	 Best epoch 1355
EarlyStopping counter: 2 out of 50
train epoch 1366 avg loss: 0.34139 (A-MSE: 0.29562) avg lploss: 0.00000
train epoch 1367 avg loss: 0.33206 (A-MSE: 0.28844) avg lploss: 0.00000
train epoch 1368 avg loss: 0.33754 (A-MSE: 0.29387) avg lploss: 0.00000
train epoch 1369 avg loss: 0.32894 (A-MSE: 0.28970) avg lploss: 0.00000
train epoch 1370 avg loss: 0.34123 (A-MSE: 0.29653) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.86281 (A-MSE: 0.74656) avg lploss: 0.00000
==> test epoch 1370 avg loss: 1.05701 (A-MSE: 0.92446) avg lploss: 0.00000
*** Best Val Loss: 0.82335 	 Best Test Loss: 0.95761 	 Best epoch 1355
EarlyStopping counter: 3 out of 50
train epoch 1371 avg loss: 0.30917 (A-MSE: 0.26868) avg lploss: 0.00000
train epoch 1372 avg loss: 0.30893 (A-MSE: 0.26906) avg lploss: 0.00000
train epoch 1373 avg loss: 0.31908 (A-MSE: 0.27788) avg lploss: 0.00000
train epoch 1374 avg loss: 0.34457 (A-MSE: 0.29992) avg lploss: 0.00000
train epoch 1375 avg loss: 0.32123 (A-MSE: 0.27952) avg lploss: 0.00000
==> val epoch 1375 avg loss: 0.80985 (A-MSE: 0.69772) avg lploss: 0.00000
==> test epoch 1375 avg loss: 1.00259 (A-MSE: 0.87777) avg lploss: 0.00000
*** Best Val Loss: 0.80985 	 Best Test Loss: 1.00259 	 Best epoch 1375
Validation loss decreased (0.823353 --> 0.809847).  Saving model ...
train epoch 1376 avg loss: 0.33926 (A-MSE: 0.29458) avg lploss: 0.00000
train epoch 1377 avg loss: 0.35083 (A-MSE: 0.30500) avg lploss: 0.00000
train epoch 1378 avg loss: 0.38496 (A-MSE: 0.33259) avg lploss: 0.00000
train epoch 1379 avg loss: 0.34988 (A-MSE: 0.30511) avg lploss: 0.00000
train epoch 1380 avg loss: 0.33334 (A-MSE: 0.28909) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.84207 (A-MSE: 0.71851) avg lploss: 0.00000
==> test epoch 1380 avg loss: 1.02638 (A-MSE: 0.89177) avg lploss: 0.00000
*** Best Val Loss: 0.80985 	 Best Test Loss: 1.00259 	 Best epoch 1375
EarlyStopping counter: 1 out of 50
train epoch 1381 avg loss: 0.31238 (A-MSE: 0.27370) avg lploss: 0.00000
train epoch 1382 avg loss: 0.33620 (A-MSE: 0.29450) avg lploss: 0.00000
train epoch 1383 avg loss: 0.36323 (A-MSE: 0.31582) avg lploss: 0.00000
train epoch 1384 avg loss: 0.32557 (A-MSE: 0.28339) avg lploss: 0.00000
train epoch 1385 avg loss: 0.29844 (A-MSE: 0.25997) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.88915 (A-MSE: 0.76943) avg lploss: 0.00000
==> test epoch 1385 avg loss: 1.06214 (A-MSE: 0.93139) avg lploss: 0.00000
*** Best Val Loss: 0.80985 	 Best Test Loss: 1.00259 	 Best epoch 1375
EarlyStopping counter: 2 out of 50
train epoch 1386 avg loss: 0.31697 (A-MSE: 0.27682) avg lploss: 0.00000
train epoch 1387 avg loss: 0.34204 (A-MSE: 0.29641) avg lploss: 0.00000
train epoch 1388 avg loss: 0.35724 (A-MSE: 0.31100) avg lploss: 0.00000
train epoch 1389 avg loss: 0.36682 (A-MSE: 0.32072) avg lploss: 0.00000
train epoch 1390 avg loss: 0.34867 (A-MSE: 0.30464) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.88985 (A-MSE: 0.75884) avg lploss: 0.00000
==> test epoch 1390 avg loss: 1.09603 (A-MSE: 0.94857) avg lploss: 0.00000
*** Best Val Loss: 0.80985 	 Best Test Loss: 1.00259 	 Best epoch 1375
EarlyStopping counter: 3 out of 50
train epoch 1391 avg loss: 0.38506 (A-MSE: 0.33478) avg lploss: 0.00000
train epoch 1392 avg loss: 0.36840 (A-MSE: 0.31944) avg lploss: 0.00000
train epoch 1393 avg loss: 0.34769 (A-MSE: 0.30106) avg lploss: 0.00000
train epoch 1394 avg loss: 0.36958 (A-MSE: 0.32107) avg lploss: 0.00000
train epoch 1395 avg loss: 0.35564 (A-MSE: 0.31044) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.78788 (A-MSE: 0.68229) avg lploss: 0.00000
==> test epoch 1395 avg loss: 0.99130 (A-MSE: 0.87397) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
Validation loss decreased (0.809847 --> 0.787884).  Saving model ...
train epoch 1396 avg loss: 0.32884 (A-MSE: 0.28641) avg lploss: 0.00000
train epoch 1397 avg loss: 0.34083 (A-MSE: 0.29607) avg lploss: 0.00000
train epoch 1398 avg loss: 0.31681 (A-MSE: 0.27451) avg lploss: 0.00000
train epoch 1399 avg loss: 0.29917 (A-MSE: 0.26122) avg lploss: 0.00000
train epoch 1400 avg loss: 0.31716 (A-MSE: 0.27736) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.87741 (A-MSE: 0.75735) avg lploss: 0.00000
==> test epoch 1400 avg loss: 1.08705 (A-MSE: 0.95154) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 1 out of 50
train epoch 1401 avg loss: 0.32742 (A-MSE: 0.28557) avg lploss: 0.00000
train epoch 1402 avg loss: 0.37495 (A-MSE: 0.32615) avg lploss: 0.00000
train epoch 1403 avg loss: 0.37863 (A-MSE: 0.33007) avg lploss: 0.00000
train epoch 1404 avg loss: 0.35662 (A-MSE: 0.31260) avg lploss: 0.00000
train epoch 1405 avg loss: 0.33791 (A-MSE: 0.29524) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.89974 (A-MSE: 0.77041) avg lploss: 0.00000
==> test epoch 1405 avg loss: 1.09817 (A-MSE: 0.95333) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 2 out of 50
train epoch 1406 avg loss: 0.33047 (A-MSE: 0.28789) avg lploss: 0.00000
train epoch 1407 avg loss: 0.31594 (A-MSE: 0.27520) avg lploss: 0.00000
train epoch 1408 avg loss: 0.34821 (A-MSE: 0.30235) avg lploss: 0.00000
train epoch 1409 avg loss: 0.35149 (A-MSE: 0.30433) avg lploss: 0.00000
train epoch 1410 avg loss: 0.30217 (A-MSE: 0.26351) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.84562 (A-MSE: 0.72300) avg lploss: 0.00000
==> test epoch 1410 avg loss: 1.05525 (A-MSE: 0.91770) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 3 out of 50
train epoch 1411 avg loss: 0.34755 (A-MSE: 0.30279) avg lploss: 0.00000
train epoch 1412 avg loss: 0.35339 (A-MSE: 0.30789) avg lploss: 0.00000
train epoch 1413 avg loss: 0.31423 (A-MSE: 0.27340) avg lploss: 0.00000
train epoch 1414 avg loss: 0.32457 (A-MSE: 0.27993) avg lploss: 0.00000
train epoch 1415 avg loss: 0.32623 (A-MSE: 0.28583) avg lploss: 0.00000
==> val epoch 1415 avg loss: 0.91541 (A-MSE: 0.79096) avg lploss: 0.00000
==> test epoch 1415 avg loss: 1.11968 (A-MSE: 0.98288) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 4 out of 50
train epoch 1416 avg loss: 0.30621 (A-MSE: 0.26757) avg lploss: 0.00000
train epoch 1417 avg loss: 0.31331 (A-MSE: 0.27381) avg lploss: 0.00000
train epoch 1418 avg loss: 0.34275 (A-MSE: 0.29946) avg lploss: 0.00000
train epoch 1419 avg loss: 0.35661 (A-MSE: 0.31161) avg lploss: 0.00000
train epoch 1420 avg loss: 0.34669 (A-MSE: 0.30229) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.99503 (A-MSE: 0.84977) avg lploss: 0.00000
==> test epoch 1420 avg loss: 1.13863 (A-MSE: 0.98752) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 5 out of 50
train epoch 1421 avg loss: 0.32295 (A-MSE: 0.28149) avg lploss: 0.00000
train epoch 1422 avg loss: 0.31449 (A-MSE: 0.27469) avg lploss: 0.00000
train epoch 1423 avg loss: 0.29677 (A-MSE: 0.25789) avg lploss: 0.00000
train epoch 1424 avg loss: 0.32478 (A-MSE: 0.28241) avg lploss: 0.00000
train epoch 1425 avg loss: 0.36159 (A-MSE: 0.31507) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.86966 (A-MSE: 0.75591) avg lploss: 0.00000
==> test epoch 1425 avg loss: 1.04054 (A-MSE: 0.90699) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 6 out of 50
train epoch 1426 avg loss: 0.35438 (A-MSE: 0.30886) avg lploss: 0.00000
train epoch 1427 avg loss: 0.32076 (A-MSE: 0.28154) avg lploss: 0.00000
train epoch 1428 avg loss: 0.32045 (A-MSE: 0.27982) avg lploss: 0.00000
train epoch 1429 avg loss: 0.29802 (A-MSE: 0.25977) avg lploss: 0.00000
train epoch 1430 avg loss: 0.29889 (A-MSE: 0.25932) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.93625 (A-MSE: 0.80847) avg lploss: 0.00000
==> test epoch 1430 avg loss: 1.10351 (A-MSE: 0.96140) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 7 out of 50
train epoch 1431 avg loss: 0.31761 (A-MSE: 0.27705) avg lploss: 0.00000
train epoch 1432 avg loss: 0.31338 (A-MSE: 0.27492) avg lploss: 0.00000
train epoch 1433 avg loss: 0.33126 (A-MSE: 0.28856) avg lploss: 0.00000
train epoch 1434 avg loss: 0.34385 (A-MSE: 0.30191) avg lploss: 0.00000
train epoch 1435 avg loss: 0.36353 (A-MSE: 0.31562) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.84579 (A-MSE: 0.72853) avg lploss: 0.00000
==> test epoch 1435 avg loss: 1.01883 (A-MSE: 0.88972) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 8 out of 50
train epoch 1436 avg loss: 0.32600 (A-MSE: 0.28595) avg lploss: 0.00000
train epoch 1437 avg loss: 0.29396 (A-MSE: 0.25494) avg lploss: 0.00000
train epoch 1438 avg loss: 0.31454 (A-MSE: 0.27646) avg lploss: 0.00000
train epoch 1439 avg loss: 0.36057 (A-MSE: 0.31714) avg lploss: 0.00000
train epoch 1440 avg loss: 0.36044 (A-MSE: 0.31485) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.94514 (A-MSE: 0.81354) avg lploss: 0.00000
==> test epoch 1440 avg loss: 1.08783 (A-MSE: 0.95132) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 9 out of 50
train epoch 1441 avg loss: 0.31848 (A-MSE: 0.27768) avg lploss: 0.00000
train epoch 1442 avg loss: 0.30151 (A-MSE: 0.26198) avg lploss: 0.00000
train epoch 1443 avg loss: 0.29433 (A-MSE: 0.25768) avg lploss: 0.00000
train epoch 1444 avg loss: 0.28562 (A-MSE: 0.24756) avg lploss: 0.00000
train epoch 1445 avg loss: 0.30904 (A-MSE: 0.26964) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.89906 (A-MSE: 0.77355) avg lploss: 0.00000
==> test epoch 1445 avg loss: 1.06684 (A-MSE: 0.93361) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 10 out of 50
train epoch 1446 avg loss: 0.32197 (A-MSE: 0.28190) avg lploss: 0.00000
train epoch 1447 avg loss: 0.32992 (A-MSE: 0.28685) avg lploss: 0.00000
train epoch 1448 avg loss: 0.33058 (A-MSE: 0.28659) avg lploss: 0.00000
train epoch 1449 avg loss: 0.31030 (A-MSE: 0.27092) avg lploss: 0.00000
train epoch 1450 avg loss: 0.30316 (A-MSE: 0.26475) avg lploss: 0.00000
==> val epoch 1450 avg loss: 0.91753 (A-MSE: 0.79311) avg lploss: 0.00000
==> test epoch 1450 avg loss: 1.09933 (A-MSE: 0.96159) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 11 out of 50
train epoch 1451 avg loss: 0.32335 (A-MSE: 0.28020) avg lploss: 0.00000
train epoch 1452 avg loss: 0.30234 (A-MSE: 0.26460) avg lploss: 0.00000
train epoch 1453 avg loss: 0.31381 (A-MSE: 0.27303) avg lploss: 0.00000
train epoch 1454 avg loss: 0.34627 (A-MSE: 0.30162) avg lploss: 0.00000
train epoch 1455 avg loss: 0.35051 (A-MSE: 0.30364) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.94986 (A-MSE: 0.82057) avg lploss: 0.00000
==> test epoch 1455 avg loss: 1.19674 (A-MSE: 1.04971) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 12 out of 50
train epoch 1456 avg loss: 0.34977 (A-MSE: 0.30279) avg lploss: 0.00000
train epoch 1457 avg loss: 0.29808 (A-MSE: 0.25946) avg lploss: 0.00000
train epoch 1458 avg loss: 0.36516 (A-MSE: 0.31654) avg lploss: 0.00000
train epoch 1459 avg loss: 0.31698 (A-MSE: 0.27737) avg lploss: 0.00000
train epoch 1460 avg loss: 0.29743 (A-MSE: 0.26023) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.85532 (A-MSE: 0.73556) avg lploss: 0.00000
==> test epoch 1460 avg loss: 1.04634 (A-MSE: 0.91915) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 13 out of 50
train epoch 1461 avg loss: 0.28043 (A-MSE: 0.24414) avg lploss: 0.00000
train epoch 1462 avg loss: 0.29528 (A-MSE: 0.25662) avg lploss: 0.00000
train epoch 1463 avg loss: 0.29654 (A-MSE: 0.25851) avg lploss: 0.00000
train epoch 1464 avg loss: 0.30642 (A-MSE: 0.26737) avg lploss: 0.00000
train epoch 1465 avg loss: 0.30664 (A-MSE: 0.26675) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.83518 (A-MSE: 0.72240) avg lploss: 0.00000
==> test epoch 1465 avg loss: 1.00241 (A-MSE: 0.87616) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 14 out of 50
train epoch 1466 avg loss: 0.30179 (A-MSE: 0.26460) avg lploss: 0.00000
train epoch 1467 avg loss: 0.31460 (A-MSE: 0.27499) avg lploss: 0.00000
train epoch 1468 avg loss: 0.32365 (A-MSE: 0.28069) avg lploss: 0.00000
train epoch 1469 avg loss: 0.35213 (A-MSE: 0.30792) avg lploss: 0.00000
train epoch 1470 avg loss: 0.31244 (A-MSE: 0.27239) avg lploss: 0.00000
==> val epoch 1470 avg loss: 0.80820 (A-MSE: 0.70425) avg lploss: 0.00000
==> test epoch 1470 avg loss: 1.00152 (A-MSE: 0.87637) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 15 out of 50
train epoch 1471 avg loss: 0.31291 (A-MSE: 0.27237) avg lploss: 0.00000
train epoch 1472 avg loss: 0.34545 (A-MSE: 0.30029) avg lploss: 0.00000
train epoch 1473 avg loss: 0.31128 (A-MSE: 0.27041) avg lploss: 0.00000
train epoch 1474 avg loss: 0.32220 (A-MSE: 0.27888) avg lploss: 0.00000
train epoch 1475 avg loss: 0.29860 (A-MSE: 0.25904) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.86015 (A-MSE: 0.74140) avg lploss: 0.00000
==> test epoch 1475 avg loss: 1.00561 (A-MSE: 0.87704) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 16 out of 50
train epoch 1476 avg loss: 0.30285 (A-MSE: 0.26242) avg lploss: 0.00000
train epoch 1477 avg loss: 0.30477 (A-MSE: 0.26491) avg lploss: 0.00000
train epoch 1478 avg loss: 0.29739 (A-MSE: 0.25920) avg lploss: 0.00000
train epoch 1479 avg loss: 0.30180 (A-MSE: 0.26225) avg lploss: 0.00000
train epoch 1480 avg loss: 0.31098 (A-MSE: 0.27223) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.85801 (A-MSE: 0.73817) avg lploss: 0.00000
==> test epoch 1480 avg loss: 1.00753 (A-MSE: 0.87522) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 17 out of 50
train epoch 1481 avg loss: 0.29642 (A-MSE: 0.25913) avg lploss: 0.00000
train epoch 1482 avg loss: 0.30684 (A-MSE: 0.26958) avg lploss: 0.00000
train epoch 1483 avg loss: 0.34087 (A-MSE: 0.29792) avg lploss: 0.00000
train epoch 1484 avg loss: 0.34948 (A-MSE: 0.30496) avg lploss: 0.00000
train epoch 1485 avg loss: 0.30394 (A-MSE: 0.26575) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.86703 (A-MSE: 0.75015) avg lploss: 0.00000
==> test epoch 1485 avg loss: 1.09575 (A-MSE: 0.96654) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 18 out of 50
train epoch 1486 avg loss: 0.32780 (A-MSE: 0.28452) avg lploss: 0.00000
train epoch 1487 avg loss: 0.29231 (A-MSE: 0.25460) avg lploss: 0.00000
train epoch 1488 avg loss: 0.29469 (A-MSE: 0.25630) avg lploss: 0.00000
train epoch 1489 avg loss: 0.29182 (A-MSE: 0.25412) avg lploss: 0.00000
train epoch 1490 avg loss: 0.28725 (A-MSE: 0.25138) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.88168 (A-MSE: 0.76234) avg lploss: 0.00000
==> test epoch 1490 avg loss: 1.06746 (A-MSE: 0.93116) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 19 out of 50
train epoch 1491 avg loss: 0.28747 (A-MSE: 0.25048) avg lploss: 0.00000
train epoch 1492 avg loss: 0.28173 (A-MSE: 0.24668) avg lploss: 0.00000
train epoch 1493 avg loss: 0.30579 (A-MSE: 0.26548) avg lploss: 0.00000
train epoch 1494 avg loss: 0.32593 (A-MSE: 0.28582) avg lploss: 0.00000
train epoch 1495 avg loss: 0.31098 (A-MSE: 0.27120) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.89009 (A-MSE: 0.75684) avg lploss: 0.00000
==> test epoch 1495 avg loss: 1.08599 (A-MSE: 0.94287) avg lploss: 0.00000
*** Best Val Loss: 0.78788 	 Best Test Loss: 0.99130 	 Best epoch 1395
EarlyStopping counter: 20 out of 50
train epoch 1496 avg loss: 0.28576 (A-MSE: 0.24859) avg lploss: 0.00000
train epoch 1497 avg loss: 0.29519 (A-MSE: 0.25815) avg lploss: 0.00000
train epoch 1498 avg loss: 0.29381 (A-MSE: 0.25474) avg lploss: 0.00000
train epoch 1499 avg loss: 0.29919 (A-MSE: 0.26170) avg lploss: 0.00000
train epoch 1500 avg loss: 0.30609 (A-MSE: 0.26574) avg lploss: 0.00000
==> val epoch 1500 avg loss: 0.78211 (A-MSE: 0.67539) avg lploss: 0.00000
==> test epoch 1500 avg loss: 0.94356 (A-MSE: 0.82477) avg lploss: 0.00000
*** Best Val Loss: 0.78211 	 Best Test Loss: 0.94356 	 Best epoch 1500
Validation loss decreased (0.787884 --> 0.782112).  Saving model ...
train epoch 1501 avg loss: 0.31808 (A-MSE: 0.27913) avg lploss: 0.00000
train epoch 1502 avg loss: 0.34211 (A-MSE: 0.29835) avg lploss: 0.00000
train epoch 1503 avg loss: 0.28488 (A-MSE: 0.24838) avg lploss: 0.00000
train epoch 1504 avg loss: 0.27293 (A-MSE: 0.23722) avg lploss: 0.00000
train epoch 1505 avg loss: 0.30539 (A-MSE: 0.26284) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.81157 (A-MSE: 0.70082) avg lploss: 0.00000
==> test epoch 1505 avg loss: 0.99392 (A-MSE: 0.86816) avg lploss: 0.00000
*** Best Val Loss: 0.78211 	 Best Test Loss: 0.94356 	 Best epoch 1500
EarlyStopping counter: 1 out of 50
train epoch 1506 avg loss: 0.28334 (A-MSE: 0.24604) avg lploss: 0.00000
train epoch 1507 avg loss: 0.30379 (A-MSE: 0.26643) avg lploss: 0.00000
train epoch 1508 avg loss: 0.30640 (A-MSE: 0.26498) avg lploss: 0.00000
train epoch 1509 avg loss: 0.30637 (A-MSE: 0.26815) avg lploss: 0.00000
train epoch 1510 avg loss: 0.29625 (A-MSE: 0.25823) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.82077 (A-MSE: 0.71421) avg lploss: 0.00000
==> test epoch 1510 avg loss: 0.98657 (A-MSE: 0.86065) avg lploss: 0.00000
*** Best Val Loss: 0.78211 	 Best Test Loss: 0.94356 	 Best epoch 1500
EarlyStopping counter: 2 out of 50
train epoch 1511 avg loss: 0.30043 (A-MSE: 0.26113) avg lploss: 0.00000
train epoch 1512 avg loss: 0.27891 (A-MSE: 0.24302) avg lploss: 0.00000
train epoch 1513 avg loss: 0.29226 (A-MSE: 0.25535) avg lploss: 0.00000
train epoch 1514 avg loss: 0.30076 (A-MSE: 0.26129) avg lploss: 0.00000
train epoch 1515 avg loss: 0.29317 (A-MSE: 0.25517) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.73322 (A-MSE: 0.63689) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.93324 (A-MSE: 0.81780) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
Validation loss decreased (0.782112 --> 0.733224).  Saving model ...
train epoch 1516 avg loss: 0.30343 (A-MSE: 0.26454) avg lploss: 0.00000
train epoch 1517 avg loss: 0.27708 (A-MSE: 0.24299) avg lploss: 0.00000
train epoch 1518 avg loss: 0.28617 (A-MSE: 0.24871) avg lploss: 0.00000
train epoch 1519 avg loss: 0.29462 (A-MSE: 0.25666) avg lploss: 0.00000
train epoch 1520 avg loss: 0.32485 (A-MSE: 0.28214) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.99133 (A-MSE: 0.86024) avg lploss: 0.00000
==> test epoch 1520 avg loss: 1.13428 (A-MSE: 0.99281) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 1 out of 50
train epoch 1521 avg loss: 0.30833 (A-MSE: 0.27009) avg lploss: 0.00000
train epoch 1522 avg loss: 0.27284 (A-MSE: 0.23916) avg lploss: 0.00000
train epoch 1523 avg loss: 0.26384 (A-MSE: 0.23078) avg lploss: 0.00000
train epoch 1524 avg loss: 0.27851 (A-MSE: 0.24287) avg lploss: 0.00000
train epoch 1525 avg loss: 0.28628 (A-MSE: 0.25112) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.76147 (A-MSE: 0.66299) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.95904 (A-MSE: 0.84149) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 2 out of 50
train epoch 1526 avg loss: 0.28299 (A-MSE: 0.24772) avg lploss: 0.00000
train epoch 1527 avg loss: 0.28973 (A-MSE: 0.25127) avg lploss: 0.00000
train epoch 1528 avg loss: 0.28752 (A-MSE: 0.25016) avg lploss: 0.00000
train epoch 1529 avg loss: 0.28949 (A-MSE: 0.25059) avg lploss: 0.00000
train epoch 1530 avg loss: 0.28927 (A-MSE: 0.25064) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.80967 (A-MSE: 0.70738) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.97270 (A-MSE: 0.86246) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 3 out of 50
train epoch 1531 avg loss: 0.29653 (A-MSE: 0.25891) avg lploss: 0.00000
train epoch 1532 avg loss: 0.27732 (A-MSE: 0.24241) avg lploss: 0.00000
train epoch 1533 avg loss: 0.27864 (A-MSE: 0.24375) avg lploss: 0.00000
train epoch 1534 avg loss: 0.29135 (A-MSE: 0.25382) avg lploss: 0.00000
train epoch 1535 avg loss: 0.30080 (A-MSE: 0.26273) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.79144 (A-MSE: 0.69386) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.97989 (A-MSE: 0.86331) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 4 out of 50
train epoch 1536 avg loss: 0.34537 (A-MSE: 0.29972) avg lploss: 0.00000
train epoch 1537 avg loss: 0.32469 (A-MSE: 0.28437) avg lploss: 0.00000
train epoch 1538 avg loss: 0.29494 (A-MSE: 0.25511) avg lploss: 0.00000
train epoch 1539 avg loss: 0.29108 (A-MSE: 0.25399) avg lploss: 0.00000
train epoch 1540 avg loss: 0.29156 (A-MSE: 0.25284) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.95144 (A-MSE: 0.80866) avg lploss: 0.00000
==> test epoch 1540 avg loss: 1.13453 (A-MSE: 0.97628) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 5 out of 50
train epoch 1541 avg loss: 0.28401 (A-MSE: 0.24890) avg lploss: 0.00000
train epoch 1542 avg loss: 0.29218 (A-MSE: 0.25678) avg lploss: 0.00000
train epoch 1543 avg loss: 0.29272 (A-MSE: 0.25480) avg lploss: 0.00000
train epoch 1544 avg loss: 0.28270 (A-MSE: 0.24578) avg lploss: 0.00000
train epoch 1545 avg loss: 0.27224 (A-MSE: 0.23625) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.83263 (A-MSE: 0.71730) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.97425 (A-MSE: 0.85032) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 6 out of 50
train epoch 1546 avg loss: 0.36795 (A-MSE: 0.32022) avg lploss: 0.00000
train epoch 1547 avg loss: 0.32413 (A-MSE: 0.28386) avg lploss: 0.00000
train epoch 1548 avg loss: 0.28800 (A-MSE: 0.25346) avg lploss: 0.00000
train epoch 1549 avg loss: 0.29657 (A-MSE: 0.25780) avg lploss: 0.00000
train epoch 1550 avg loss: 0.30270 (A-MSE: 0.26127) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.77063 (A-MSE: 0.67344) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.97300 (A-MSE: 0.85660) avg lploss: 0.00000
*** Best Val Loss: 0.73322 	 Best Test Loss: 0.93324 	 Best epoch 1515
EarlyStopping counter: 7 out of 50
train epoch 1551 avg loss: 0.30263 (A-MSE: 0.26452) avg lploss: 0.00000
train epoch 1552 avg loss: 0.27168 (A-MSE: 0.23749) avg lploss: 0.00000
train epoch 1553 avg loss: 0.27745 (A-MSE: 0.24182) avg lploss: 0.00000
train epoch 1554 avg loss: 0.28337 (A-MSE: 0.24664) avg lploss: 0.00000
train epoch 1555 avg loss: 0.28324 (A-MSE: 0.24717) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.72225 (A-MSE: 0.62406) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.85808 (A-MSE: 0.75065) avg lploss: 0.00000
*** Best Val Loss: 0.72225 	 Best Test Loss: 0.85808 	 Best epoch 1555
Validation loss decreased (0.733224 --> 0.722253).  Saving model ...
train epoch 1556 avg loss: 0.27140 (A-MSE: 0.23805) avg lploss: 0.00000
train epoch 1557 avg loss: 0.27090 (A-MSE: 0.23582) avg lploss: 0.00000
train epoch 1558 avg loss: 0.27831 (A-MSE: 0.24266) avg lploss: 0.00000
train epoch 1559 avg loss: 0.29131 (A-MSE: 0.25456) avg lploss: 0.00000
train epoch 1560 avg loss: 0.30603 (A-MSE: 0.26662) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.83292 (A-MSE: 0.72243) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.96079 (A-MSE: 0.83783) avg lploss: 0.00000
*** Best Val Loss: 0.72225 	 Best Test Loss: 0.85808 	 Best epoch 1555
EarlyStopping counter: 1 out of 50
train epoch 1561 avg loss: 0.32287 (A-MSE: 0.28066) avg lploss: 0.00000
train epoch 1562 avg loss: 0.26918 (A-MSE: 0.23595) avg lploss: 0.00000
train epoch 1563 avg loss: 0.28231 (A-MSE: 0.24496) avg lploss: 0.00000
train epoch 1564 avg loss: 0.31871 (A-MSE: 0.27904) avg lploss: 0.00000
train epoch 1565 avg loss: 0.28355 (A-MSE: 0.24673) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.76792 (A-MSE: 0.66562) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.91902 (A-MSE: 0.80106) avg lploss: 0.00000
*** Best Val Loss: 0.72225 	 Best Test Loss: 0.85808 	 Best epoch 1555
EarlyStopping counter: 2 out of 50
train epoch 1566 avg loss: 0.28098 (A-MSE: 0.24548) avg lploss: 0.00000
train epoch 1567 avg loss: 0.27277 (A-MSE: 0.23851) avg lploss: 0.00000
train epoch 1568 avg loss: 0.27970 (A-MSE: 0.24225) avg lploss: 0.00000
train epoch 1569 avg loss: 0.27863 (A-MSE: 0.23992) avg lploss: 0.00000
train epoch 1570 avg loss: 0.28787 (A-MSE: 0.25166) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.79508 (A-MSE: 0.68776) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.98386 (A-MSE: 0.86159) avg lploss: 0.00000
*** Best Val Loss: 0.72225 	 Best Test Loss: 0.85808 	 Best epoch 1555
EarlyStopping counter: 3 out of 50
train epoch 1571 avg loss: 0.27986 (A-MSE: 0.24573) avg lploss: 0.00000
train epoch 1572 avg loss: 0.26684 (A-MSE: 0.23272) avg lploss: 0.00000
train epoch 1573 avg loss: 0.27071 (A-MSE: 0.23700) avg lploss: 0.00000
train epoch 1574 avg loss: 0.30073 (A-MSE: 0.26154) avg lploss: 0.00000
train epoch 1575 avg loss: 0.29881 (A-MSE: 0.26158) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.69142 (A-MSE: 0.59310) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.83183 (A-MSE: 0.71947) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
Validation loss decreased (0.722253 --> 0.691418).  Saving model ...
train epoch 1576 avg loss: 0.26998 (A-MSE: 0.23822) avg lploss: 0.00000
train epoch 1577 avg loss: 0.31800 (A-MSE: 0.27717) avg lploss: 0.00000
train epoch 1578 avg loss: 0.37340 (A-MSE: 0.32595) avg lploss: 0.00000
train epoch 1579 avg loss: 0.30253 (A-MSE: 0.26328) avg lploss: 0.00000
train epoch 1580 avg loss: 0.28674 (A-MSE: 0.25015) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.75983 (A-MSE: 0.65989) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.91892 (A-MSE: 0.80477) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 1 out of 50
train epoch 1581 avg loss: 0.30784 (A-MSE: 0.26619) avg lploss: 0.00000
train epoch 1582 avg loss: 0.28475 (A-MSE: 0.24852) avg lploss: 0.00000
train epoch 1583 avg loss: 0.27900 (A-MSE: 0.24288) avg lploss: 0.00000
train epoch 1584 avg loss: 0.25697 (A-MSE: 0.22307) avg lploss: 0.00000
train epoch 1585 avg loss: 0.27577 (A-MSE: 0.24097) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.79157 (A-MSE: 0.68244) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.96602 (A-MSE: 0.83808) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 2 out of 50
train epoch 1586 avg loss: 0.26249 (A-MSE: 0.22845) avg lploss: 0.00000
train epoch 1587 avg loss: 0.24351 (A-MSE: 0.21143) avg lploss: 0.00000
train epoch 1588 avg loss: 0.24760 (A-MSE: 0.21589) avg lploss: 0.00000
train epoch 1589 avg loss: 0.26593 (A-MSE: 0.23190) avg lploss: 0.00000
train epoch 1590 avg loss: 0.26541 (A-MSE: 0.23097) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.72270 (A-MSE: 0.62379) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.83629 (A-MSE: 0.72990) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 3 out of 50
train epoch 1591 avg loss: 0.27066 (A-MSE: 0.23729) avg lploss: 0.00000
train epoch 1592 avg loss: 0.28395 (A-MSE: 0.24751) avg lploss: 0.00000
train epoch 1593 avg loss: 0.26034 (A-MSE: 0.22696) avg lploss: 0.00000
train epoch 1594 avg loss: 0.26441 (A-MSE: 0.22867) avg lploss: 0.00000
train epoch 1595 avg loss: 0.26054 (A-MSE: 0.22584) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.79136 (A-MSE: 0.68367) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.91018 (A-MSE: 0.79399) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 4 out of 50
train epoch 1596 avg loss: 0.25341 (A-MSE: 0.22064) avg lploss: 0.00000
train epoch 1597 avg loss: 0.25347 (A-MSE: 0.21970) avg lploss: 0.00000
train epoch 1598 avg loss: 0.26860 (A-MSE: 0.23376) avg lploss: 0.00000
train epoch 1599 avg loss: 0.25846 (A-MSE: 0.22346) avg lploss: 0.00000
train epoch 1600 avg loss: 0.25834 (A-MSE: 0.22616) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.75321 (A-MSE: 0.65387) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.90709 (A-MSE: 0.78991) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 5 out of 50
train epoch 1601 avg loss: 0.27184 (A-MSE: 0.23431) avg lploss: 0.00000
train epoch 1602 avg loss: 0.27114 (A-MSE: 0.23685) avg lploss: 0.00000
train epoch 1603 avg loss: 0.25313 (A-MSE: 0.22032) avg lploss: 0.00000
train epoch 1604 avg loss: 0.26461 (A-MSE: 0.22898) avg lploss: 0.00000
train epoch 1605 avg loss: 0.25766 (A-MSE: 0.22479) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.70887 (A-MSE: 0.60995) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.85879 (A-MSE: 0.75135) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 6 out of 50
train epoch 1606 avg loss: 0.25565 (A-MSE: 0.22215) avg lploss: 0.00000
train epoch 1607 avg loss: 0.26603 (A-MSE: 0.23385) avg lploss: 0.00000
train epoch 1608 avg loss: 0.25850 (A-MSE: 0.22453) avg lploss: 0.00000
train epoch 1609 avg loss: 0.25161 (A-MSE: 0.21840) avg lploss: 0.00000
train epoch 1610 avg loss: 0.22811 (A-MSE: 0.19954) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.76943 (A-MSE: 0.66312) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.89400 (A-MSE: 0.77596) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 7 out of 50
train epoch 1611 avg loss: 0.25424 (A-MSE: 0.22094) avg lploss: 0.00000
train epoch 1612 avg loss: 0.26232 (A-MSE: 0.22730) avg lploss: 0.00000
train epoch 1613 avg loss: 0.25793 (A-MSE: 0.22364) avg lploss: 0.00000
train epoch 1614 avg loss: 0.26944 (A-MSE: 0.23565) avg lploss: 0.00000
train epoch 1615 avg loss: 0.26986 (A-MSE: 0.23411) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.72352 (A-MSE: 0.62825) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.86365 (A-MSE: 0.75635) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 8 out of 50
train epoch 1616 avg loss: 0.27213 (A-MSE: 0.23823) avg lploss: 0.00000
train epoch 1617 avg loss: 0.29689 (A-MSE: 0.25811) avg lploss: 0.00000
train epoch 1618 avg loss: 0.33873 (A-MSE: 0.29353) avg lploss: 0.00000
train epoch 1619 avg loss: 0.31145 (A-MSE: 0.27207) avg lploss: 0.00000
train epoch 1620 avg loss: 0.28991 (A-MSE: 0.25266) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.72791 (A-MSE: 0.62543) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.87916 (A-MSE: 0.76850) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 9 out of 50
train epoch 1621 avg loss: 0.33068 (A-MSE: 0.28649) avg lploss: 0.00000
train epoch 1622 avg loss: 0.29074 (A-MSE: 0.25424) avg lploss: 0.00000
train epoch 1623 avg loss: 0.28297 (A-MSE: 0.24760) avg lploss: 0.00000
train epoch 1624 avg loss: 0.28595 (A-MSE: 0.25068) avg lploss: 0.00000
train epoch 1625 avg loss: 0.27903 (A-MSE: 0.24262) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.73117 (A-MSE: 0.63456) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.89463 (A-MSE: 0.78356) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 10 out of 50
train epoch 1626 avg loss: 0.26929 (A-MSE: 0.23530) avg lploss: 0.00000
train epoch 1627 avg loss: 0.25738 (A-MSE: 0.22810) avg lploss: 0.00000
train epoch 1628 avg loss: 0.31545 (A-MSE: 0.27647) avg lploss: 0.00000
train epoch 1629 avg loss: 0.30764 (A-MSE: 0.26799) avg lploss: 0.00000
train epoch 1630 avg loss: 0.29132 (A-MSE: 0.25373) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.84590 (A-MSE: 0.72267) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.98619 (A-MSE: 0.85485) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 11 out of 50
train epoch 1631 avg loss: 0.28074 (A-MSE: 0.24329) avg lploss: 0.00000
train epoch 1632 avg loss: 0.27983 (A-MSE: 0.24370) avg lploss: 0.00000
train epoch 1633 avg loss: 0.26129 (A-MSE: 0.22771) avg lploss: 0.00000
train epoch 1634 avg loss: 0.26537 (A-MSE: 0.23089) avg lploss: 0.00000
train epoch 1635 avg loss: 0.28426 (A-MSE: 0.24805) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.75203 (A-MSE: 0.64508) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.90932 (A-MSE: 0.78580) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 12 out of 50
train epoch 1636 avg loss: 0.28169 (A-MSE: 0.24527) avg lploss: 0.00000
train epoch 1637 avg loss: 0.25331 (A-MSE: 0.22205) avg lploss: 0.00000
train epoch 1638 avg loss: 0.24583 (A-MSE: 0.21438) avg lploss: 0.00000
train epoch 1639 avg loss: 0.27237 (A-MSE: 0.23817) avg lploss: 0.00000
train epoch 1640 avg loss: 0.27155 (A-MSE: 0.23746) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.84250 (A-MSE: 0.72904) avg lploss: 0.00000
==> test epoch 1640 avg loss: 1.00310 (A-MSE: 0.87350) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 13 out of 50
train epoch 1641 avg loss: 0.25778 (A-MSE: 0.22365) avg lploss: 0.00000
train epoch 1642 avg loss: 0.25753 (A-MSE: 0.22506) avg lploss: 0.00000
train epoch 1643 avg loss: 0.26289 (A-MSE: 0.22730) avg lploss: 0.00000
train epoch 1644 avg loss: 0.27672 (A-MSE: 0.24304) avg lploss: 0.00000
train epoch 1645 avg loss: 0.26415 (A-MSE: 0.22773) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.83785 (A-MSE: 0.71351) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.94156 (A-MSE: 0.80909) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 14 out of 50
train epoch 1646 avg loss: 0.26086 (A-MSE: 0.22619) avg lploss: 0.00000
train epoch 1647 avg loss: 0.23868 (A-MSE: 0.20887) avg lploss: 0.00000
train epoch 1648 avg loss: 0.25486 (A-MSE: 0.22160) avg lploss: 0.00000
train epoch 1649 avg loss: 0.29277 (A-MSE: 0.25553) avg lploss: 0.00000
train epoch 1650 avg loss: 0.29272 (A-MSE: 0.25608) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.70465 (A-MSE: 0.61047) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.87739 (A-MSE: 0.76367) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 15 out of 50
train epoch 1651 avg loss: 0.32263 (A-MSE: 0.27822) avg lploss: 0.00000
train epoch 1652 avg loss: 0.31856 (A-MSE: 0.27561) avg lploss: 0.00000
train epoch 1653 avg loss: 0.29059 (A-MSE: 0.25342) avg lploss: 0.00000
train epoch 1654 avg loss: 0.32197 (A-MSE: 0.28227) avg lploss: 0.00000
train epoch 1655 avg loss: 0.27067 (A-MSE: 0.23724) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.73846 (A-MSE: 0.63225) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.86984 (A-MSE: 0.75272) avg lploss: 0.00000
*** Best Val Loss: 0.69142 	 Best Test Loss: 0.83183 	 Best epoch 1575
EarlyStopping counter: 16 out of 50
train epoch 1656 avg loss: 0.23644 (A-MSE: 0.20754) avg lploss: 0.00000
train epoch 1657 avg loss: 0.24003 (A-MSE: 0.20919) avg lploss: 0.00000
train epoch 1658 avg loss: 0.24912 (A-MSE: 0.21815) avg lploss: 0.00000
train epoch 1659 avg loss: 0.23688 (A-MSE: 0.20695) avg lploss: 0.00000
train epoch 1660 avg loss: 0.24684 (A-MSE: 0.21594) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.68558 (A-MSE: 0.58835) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.82667 (A-MSE: 0.71556) avg lploss: 0.00000
*** Best Val Loss: 0.68558 	 Best Test Loss: 0.82667 	 Best epoch 1660
Validation loss decreased (0.691418 --> 0.685578).  Saving model ...
train epoch 1661 avg loss: 0.23726 (A-MSE: 0.20706) avg lploss: 0.00000
train epoch 1662 avg loss: 0.24896 (A-MSE: 0.21717) avg lploss: 0.00000
train epoch 1663 avg loss: 0.24395 (A-MSE: 0.21386) avg lploss: 0.00000
train epoch 1664 avg loss: 0.26315 (A-MSE: 0.23076) avg lploss: 0.00000
train epoch 1665 avg loss: 0.27881 (A-MSE: 0.24339) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.73437 (A-MSE: 0.63663) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.84531 (A-MSE: 0.73816) avg lploss: 0.00000
*** Best Val Loss: 0.68558 	 Best Test Loss: 0.82667 	 Best epoch 1660
EarlyStopping counter: 1 out of 50
train epoch 1666 avg loss: 0.26203 (A-MSE: 0.22979) avg lploss: 0.00000
train epoch 1667 avg loss: 0.27894 (A-MSE: 0.24307) avg lploss: 0.00000
train epoch 1668 avg loss: 0.24837 (A-MSE: 0.21505) avg lploss: 0.00000
train epoch 1669 avg loss: 0.25134 (A-MSE: 0.21597) avg lploss: 0.00000
train epoch 1670 avg loss: 0.25471 (A-MSE: 0.22347) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.69236 (A-MSE: 0.60353) avg lploss: 0.00000
==> test epoch 1670 avg loss: 0.85322 (A-MSE: 0.74742) avg lploss: 0.00000
*** Best Val Loss: 0.68558 	 Best Test Loss: 0.82667 	 Best epoch 1660
EarlyStopping counter: 2 out of 50
train epoch 1671 avg loss: 0.24151 (A-MSE: 0.21077) avg lploss: 0.00000
train epoch 1672 avg loss: 0.22604 (A-MSE: 0.19705) avg lploss: 0.00000
train epoch 1673 avg loss: 0.23579 (A-MSE: 0.20596) avg lploss: 0.00000
train epoch 1674 avg loss: 0.22852 (A-MSE: 0.19884) avg lploss: 0.00000
train epoch 1675 avg loss: 0.22481 (A-MSE: 0.19706) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.68374 (A-MSE: 0.59188) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.85422 (A-MSE: 0.74485) avg lploss: 0.00000
*** Best Val Loss: 0.68374 	 Best Test Loss: 0.85422 	 Best epoch 1675
Validation loss decreased (0.685578 --> 0.683743).  Saving model ...
train epoch 1676 avg loss: 0.26553 (A-MSE: 0.23113) avg lploss: 0.00000
train epoch 1677 avg loss: 0.26686 (A-MSE: 0.23354) avg lploss: 0.00000
train epoch 1678 avg loss: 0.26383 (A-MSE: 0.22921) avg lploss: 0.00000
train epoch 1679 avg loss: 0.28534 (A-MSE: 0.24713) avg lploss: 0.00000
train epoch 1680 avg loss: 0.24442 (A-MSE: 0.21213) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.69426 (A-MSE: 0.59749) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.83614 (A-MSE: 0.72659) avg lploss: 0.00000
*** Best Val Loss: 0.68374 	 Best Test Loss: 0.85422 	 Best epoch 1675
EarlyStopping counter: 1 out of 50
train epoch 1681 avg loss: 0.25580 (A-MSE: 0.22360) avg lploss: 0.00000
train epoch 1682 avg loss: 0.25581 (A-MSE: 0.22257) avg lploss: 0.00000
train epoch 1683 avg loss: 0.24486 (A-MSE: 0.21397) avg lploss: 0.00000
train epoch 1684 avg loss: 0.24880 (A-MSE: 0.21724) avg lploss: 0.00000
train epoch 1685 avg loss: 0.25157 (A-MSE: 0.21908) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.67035 (A-MSE: 0.58059) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.84720 (A-MSE: 0.73951) avg lploss: 0.00000
*** Best Val Loss: 0.67035 	 Best Test Loss: 0.84720 	 Best epoch 1685
Validation loss decreased (0.683743 --> 0.670345).  Saving model ...
train epoch 1686 avg loss: 0.24552 (A-MSE: 0.21239) avg lploss: 0.00000
train epoch 1687 avg loss: 0.25157 (A-MSE: 0.21971) avg lploss: 0.00000
train epoch 1688 avg loss: 0.26918 (A-MSE: 0.23527) avg lploss: 0.00000
train epoch 1689 avg loss: 0.30300 (A-MSE: 0.25920) avg lploss: 0.00000
train epoch 1690 avg loss: 0.26675 (A-MSE: 0.23444) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.74428 (A-MSE: 0.64999) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.87529 (A-MSE: 0.76363) avg lploss: 0.00000
*** Best Val Loss: 0.67035 	 Best Test Loss: 0.84720 	 Best epoch 1685
EarlyStopping counter: 1 out of 50
train epoch 1691 avg loss: 0.24800 (A-MSE: 0.21567) avg lploss: 0.00000
train epoch 1692 avg loss: 0.23557 (A-MSE: 0.20591) avg lploss: 0.00000
train epoch 1693 avg loss: 0.26671 (A-MSE: 0.23262) avg lploss: 0.00000
train epoch 1694 avg loss: 0.26568 (A-MSE: 0.23113) avg lploss: 0.00000
train epoch 1695 avg loss: 0.26215 (A-MSE: 0.22803) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.80077 (A-MSE: 0.69505) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.90952 (A-MSE: 0.78795) avg lploss: 0.00000
*** Best Val Loss: 0.67035 	 Best Test Loss: 0.84720 	 Best epoch 1685
EarlyStopping counter: 2 out of 50
train epoch 1696 avg loss: 0.24881 (A-MSE: 0.21711) avg lploss: 0.00000
train epoch 1697 avg loss: 0.27613 (A-MSE: 0.23890) avg lploss: 0.00000
train epoch 1698 avg loss: 0.25810 (A-MSE: 0.22593) avg lploss: 0.00000
train epoch 1699 avg loss: 0.25166 (A-MSE: 0.21834) avg lploss: 0.00000
train epoch 1700 avg loss: 0.26629 (A-MSE: 0.23283) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.84607 (A-MSE: 0.72636) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.92957 (A-MSE: 0.80345) avg lploss: 0.00000
*** Best Val Loss: 0.67035 	 Best Test Loss: 0.84720 	 Best epoch 1685
EarlyStopping counter: 3 out of 50
train epoch 1701 avg loss: 0.26092 (A-MSE: 0.22720) avg lploss: 0.00000
train epoch 1702 avg loss: 0.27181 (A-MSE: 0.23814) avg lploss: 0.00000
train epoch 1703 avg loss: 0.28582 (A-MSE: 0.24908) avg lploss: 0.00000
train epoch 1704 avg loss: 0.30513 (A-MSE: 0.26880) avg lploss: 0.00000
train epoch 1705 avg loss: 0.27001 (A-MSE: 0.23478) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.82611 (A-MSE: 0.70354) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.92553 (A-MSE: 0.79986) avg lploss: 0.00000
*** Best Val Loss: 0.67035 	 Best Test Loss: 0.84720 	 Best epoch 1685
EarlyStopping counter: 4 out of 50
train epoch 1706 avg loss: 0.23665 (A-MSE: 0.20586) avg lploss: 0.00000
train epoch 1707 avg loss: 0.22699 (A-MSE: 0.19815) avg lploss: 0.00000
train epoch 1708 avg loss: 0.24326 (A-MSE: 0.21070) avg lploss: 0.00000
train epoch 1709 avg loss: 0.26019 (A-MSE: 0.22941) avg lploss: 0.00000
train epoch 1710 avg loss: 0.22953 (A-MSE: 0.19915) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.80536 (A-MSE: 0.68509) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.95560 (A-MSE: 0.82005) avg lploss: 0.00000
*** Best Val Loss: 0.67035 	 Best Test Loss: 0.84720 	 Best epoch 1685
EarlyStopping counter: 5 out of 50
train epoch 1711 avg loss: 0.21318 (A-MSE: 0.18619) avg lploss: 0.00000
train epoch 1712 avg loss: 0.21746 (A-MSE: 0.18929) avg lploss: 0.00000
train epoch 1713 avg loss: 0.22999 (A-MSE: 0.19938) avg lploss: 0.00000
train epoch 1714 avg loss: 0.22956 (A-MSE: 0.20147) avg lploss: 0.00000
train epoch 1715 avg loss: 0.27588 (A-MSE: 0.24052) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.66164 (A-MSE: 0.56987) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.77536 (A-MSE: 0.67330) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
Validation loss decreased (0.670345 --> 0.661637).  Saving model ...
train epoch 1716 avg loss: 0.28744 (A-MSE: 0.25096) avg lploss: 0.00000
train epoch 1717 avg loss: 0.29705 (A-MSE: 0.25920) avg lploss: 0.00000
train epoch 1718 avg loss: 0.25492 (A-MSE: 0.22281) avg lploss: 0.00000
train epoch 1719 avg loss: 0.26306 (A-MSE: 0.22931) avg lploss: 0.00000
train epoch 1720 avg loss: 0.23542 (A-MSE: 0.20591) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.84787 (A-MSE: 0.73027) avg lploss: 0.00000
==> test epoch 1720 avg loss: 1.00570 (A-MSE: 0.87071) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 1 out of 50
train epoch 1721 avg loss: 0.26427 (A-MSE: 0.23222) avg lploss: 0.00000
train epoch 1722 avg loss: 0.23277 (A-MSE: 0.20252) avg lploss: 0.00000
train epoch 1723 avg loss: 0.25457 (A-MSE: 0.22221) avg lploss: 0.00000
train epoch 1724 avg loss: 0.24590 (A-MSE: 0.21498) avg lploss: 0.00000
train epoch 1725 avg loss: 0.24709 (A-MSE: 0.21541) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.73319 (A-MSE: 0.63371) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.86949 (A-MSE: 0.75718) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 2 out of 50
train epoch 1726 avg loss: 0.21640 (A-MSE: 0.18879) avg lploss: 0.00000
train epoch 1727 avg loss: 0.22256 (A-MSE: 0.19418) avg lploss: 0.00000
train epoch 1728 avg loss: 0.24749 (A-MSE: 0.21498) avg lploss: 0.00000
train epoch 1729 avg loss: 0.32660 (A-MSE: 0.28189) avg lploss: 0.00000
train epoch 1730 avg loss: 0.32464 (A-MSE: 0.28281) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.85306 (A-MSE: 0.72568) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.92647 (A-MSE: 0.79624) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 3 out of 50
train epoch 1731 avg loss: 0.28070 (A-MSE: 0.24545) avg lploss: 0.00000
train epoch 1732 avg loss: 0.23914 (A-MSE: 0.20865) avg lploss: 0.00000
train epoch 1733 avg loss: 0.23049 (A-MSE: 0.20265) avg lploss: 0.00000
train epoch 1734 avg loss: 0.23553 (A-MSE: 0.20451) avg lploss: 0.00000
train epoch 1735 avg loss: 0.21783 (A-MSE: 0.19048) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.67166 (A-MSE: 0.58229) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.79338 (A-MSE: 0.69002) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 4 out of 50
train epoch 1736 avg loss: 0.25036 (A-MSE: 0.21697) avg lploss: 0.00000
train epoch 1737 avg loss: 0.25680 (A-MSE: 0.22382) avg lploss: 0.00000
train epoch 1738 avg loss: 0.24946 (A-MSE: 0.21777) avg lploss: 0.00000
train epoch 1739 avg loss: 0.23189 (A-MSE: 0.20284) avg lploss: 0.00000
train epoch 1740 avg loss: 0.24046 (A-MSE: 0.21090) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.78798 (A-MSE: 0.67577) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.90238 (A-MSE: 0.78140) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 5 out of 50
train epoch 1741 avg loss: 0.27122 (A-MSE: 0.23652) avg lploss: 0.00000
train epoch 1742 avg loss: 0.23439 (A-MSE: 0.20283) avg lploss: 0.00000
train epoch 1743 avg loss: 0.21825 (A-MSE: 0.19139) avg lploss: 0.00000
train epoch 1744 avg loss: 0.21011 (A-MSE: 0.18378) avg lploss: 0.00000
train epoch 1745 avg loss: 0.22663 (A-MSE: 0.19746) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.71110 (A-MSE: 0.61234) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.82964 (A-MSE: 0.71845) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 6 out of 50
train epoch 1746 avg loss: 0.26217 (A-MSE: 0.22921) avg lploss: 0.00000
train epoch 1747 avg loss: 0.27872 (A-MSE: 0.24530) avg lploss: 0.00000
train epoch 1748 avg loss: 0.25801 (A-MSE: 0.22625) avg lploss: 0.00000
train epoch 1749 avg loss: 0.23970 (A-MSE: 0.20953) avg lploss: 0.00000
train epoch 1750 avg loss: 0.22782 (A-MSE: 0.19839) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.72080 (A-MSE: 0.62231) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.84083 (A-MSE: 0.72779) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 7 out of 50
train epoch 1751 avg loss: 0.22583 (A-MSE: 0.19723) avg lploss: 0.00000
train epoch 1752 avg loss: 0.22610 (A-MSE: 0.19650) avg lploss: 0.00000
train epoch 1753 avg loss: 0.24491 (A-MSE: 0.21504) avg lploss: 0.00000
train epoch 1754 avg loss: 0.22139 (A-MSE: 0.19353) avg lploss: 0.00000
train epoch 1755 avg loss: 0.22319 (A-MSE: 0.19484) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.69056 (A-MSE: 0.59380) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.81689 (A-MSE: 0.70976) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 8 out of 50
train epoch 1756 avg loss: 0.26814 (A-MSE: 0.23199) avg lploss: 0.00000
train epoch 1757 avg loss: 0.24474 (A-MSE: 0.21473) avg lploss: 0.00000
train epoch 1758 avg loss: 0.23048 (A-MSE: 0.19908) avg lploss: 0.00000
train epoch 1759 avg loss: 0.22773 (A-MSE: 0.19866) avg lploss: 0.00000
train epoch 1760 avg loss: 0.23403 (A-MSE: 0.20559) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.72801 (A-MSE: 0.62296) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.83256 (A-MSE: 0.71817) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 9 out of 50
train epoch 1761 avg loss: 0.23530 (A-MSE: 0.20425) avg lploss: 0.00000
train epoch 1762 avg loss: 0.23741 (A-MSE: 0.20545) avg lploss: 0.00000
train epoch 1763 avg loss: 0.22135 (A-MSE: 0.19277) avg lploss: 0.00000
train epoch 1764 avg loss: 0.21025 (A-MSE: 0.18397) avg lploss: 0.00000
train epoch 1765 avg loss: 0.22237 (A-MSE: 0.19321) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.77013 (A-MSE: 0.65890) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.88147 (A-MSE: 0.75960) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 10 out of 50
train epoch 1766 avg loss: 0.22461 (A-MSE: 0.19565) avg lploss: 0.00000
train epoch 1767 avg loss: 0.21645 (A-MSE: 0.18646) avg lploss: 0.00000
train epoch 1768 avg loss: 0.22066 (A-MSE: 0.19208) avg lploss: 0.00000
train epoch 1769 avg loss: 0.22372 (A-MSE: 0.19689) avg lploss: 0.00000
train epoch 1770 avg loss: 0.22123 (A-MSE: 0.19383) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.68343 (A-MSE: 0.59212) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.82337 (A-MSE: 0.71317) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 11 out of 50
train epoch 1771 avg loss: 0.23252 (A-MSE: 0.20248) avg lploss: 0.00000
train epoch 1772 avg loss: 0.23527 (A-MSE: 0.20451) avg lploss: 0.00000
train epoch 1773 avg loss: 0.22946 (A-MSE: 0.20111) avg lploss: 0.00000
train epoch 1774 avg loss: 0.21737 (A-MSE: 0.18941) avg lploss: 0.00000
train epoch 1775 avg loss: 0.22475 (A-MSE: 0.19656) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.71189 (A-MSE: 0.62196) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.80726 (A-MSE: 0.70575) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 12 out of 50
train epoch 1776 avg loss: 0.24090 (A-MSE: 0.21166) avg lploss: 0.00000
train epoch 1777 avg loss: 0.24750 (A-MSE: 0.21668) avg lploss: 0.00000
train epoch 1778 avg loss: 0.23270 (A-MSE: 0.20216) avg lploss: 0.00000
train epoch 1779 avg loss: 0.21943 (A-MSE: 0.19055) avg lploss: 0.00000
train epoch 1780 avg loss: 0.23591 (A-MSE: 0.20527) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.71904 (A-MSE: 0.62625) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.82354 (A-MSE: 0.71721) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 13 out of 50
train epoch 1781 avg loss: 0.25291 (A-MSE: 0.22320) avg lploss: 0.00000
train epoch 1782 avg loss: 0.23471 (A-MSE: 0.20510) avg lploss: 0.00000
train epoch 1783 avg loss: 0.21646 (A-MSE: 0.19052) avg lploss: 0.00000
train epoch 1784 avg loss: 0.22302 (A-MSE: 0.19500) avg lploss: 0.00000
train epoch 1785 avg loss: 0.23965 (A-MSE: 0.20912) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.73473 (A-MSE: 0.63008) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.84218 (A-MSE: 0.72804) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 14 out of 50
train epoch 1786 avg loss: 0.23324 (A-MSE: 0.20194) avg lploss: 0.00000
train epoch 1787 avg loss: 0.23987 (A-MSE: 0.20828) avg lploss: 0.00000
train epoch 1788 avg loss: 0.21693 (A-MSE: 0.18859) avg lploss: 0.00000
train epoch 1789 avg loss: 0.21626 (A-MSE: 0.18899) avg lploss: 0.00000
train epoch 1790 avg loss: 0.23541 (A-MSE: 0.20611) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.82336 (A-MSE: 0.70495) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.92059 (A-MSE: 0.79437) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 15 out of 50
train epoch 1791 avg loss: 0.25899 (A-MSE: 0.22598) avg lploss: 0.00000
train epoch 1792 avg loss: 0.26259 (A-MSE: 0.22950) avg lploss: 0.00000
train epoch 1793 avg loss: 0.27281 (A-MSE: 0.23728) avg lploss: 0.00000
train epoch 1794 avg loss: 0.24681 (A-MSE: 0.21716) avg lploss: 0.00000
train epoch 1795 avg loss: 0.23406 (A-MSE: 0.20358) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.70212 (A-MSE: 0.60261) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.78841 (A-MSE: 0.68328) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 16 out of 50
train epoch 1796 avg loss: 0.24210 (A-MSE: 0.21077) avg lploss: 0.00000
train epoch 1797 avg loss: 0.25492 (A-MSE: 0.22479) avg lploss: 0.00000
train epoch 1798 avg loss: 0.24609 (A-MSE: 0.21470) avg lploss: 0.00000
train epoch 1799 avg loss: 0.24106 (A-MSE: 0.20780) avg lploss: 0.00000
train epoch 1800 avg loss: 0.24077 (A-MSE: 0.21033) avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.77757 (A-MSE: 0.67126) avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.88280 (A-MSE: 0.76545) avg lploss: 0.00000
*** Best Val Loss: 0.66164 	 Best Test Loss: 0.77536 	 Best epoch 1715
EarlyStopping counter: 17 out of 50
train epoch 1801 avg loss: 0.23043 (A-MSE: 0.20086) avg lploss: 0.00000
train epoch 1802 avg loss: 0.22350 (A-MSE: 0.19466) avg lploss: 0.00000
train epoch 1803 avg loss: 0.24222 (A-MSE: 0.21156) avg lploss: 0.00000
train epoch 1804 avg loss: 0.24334 (A-MSE: 0.21072) avg lploss: 0.00000
train epoch 1805 avg loss: 0.23971 (A-MSE: 0.20778) avg lploss: 0.00000
==> val epoch 1805 avg loss: 0.64287 (A-MSE: 0.55547) avg lploss: 0.00000
==> test epoch 1805 avg loss: 0.82745 (A-MSE: 0.71971) avg lploss: 0.00000
*** Best Val Loss: 0.64287 	 Best Test Loss: 0.82745 	 Best epoch 1805
Validation loss decreased (0.661637 --> 0.642873).  Saving model ...
train epoch 1806 avg loss: 0.25279 (A-MSE: 0.22051) avg lploss: 0.00000
train epoch 1807 avg loss: 0.22178 (A-MSE: 0.19336) avg lploss: 0.00000
train epoch 1808 avg loss: 0.24048 (A-MSE: 0.21186) avg lploss: 0.00000
train epoch 1809 avg loss: 0.23046 (A-MSE: 0.20083) avg lploss: 0.00000
train epoch 1810 avg loss: 0.25079 (A-MSE: 0.21897) avg lploss: 0.00000
==> val epoch 1810 avg loss: 0.61240 (A-MSE: 0.52847) avg lploss: 0.00000
==> test epoch 1810 avg loss: 0.74519 (A-MSE: 0.64599) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
Validation loss decreased (0.642873 --> 0.612404).  Saving model ...
train epoch 1811 avg loss: 0.23089 (A-MSE: 0.20019) avg lploss: 0.00000
train epoch 1812 avg loss: 0.22562 (A-MSE: 0.19824) avg lploss: 0.00000
train epoch 1813 avg loss: 0.20137 (A-MSE: 0.17704) avg lploss: 0.00000
train epoch 1814 avg loss: 0.22145 (A-MSE: 0.19314) avg lploss: 0.00000
train epoch 1815 avg loss: 0.22487 (A-MSE: 0.19575) avg lploss: 0.00000
==> val epoch 1815 avg loss: 0.70957 (A-MSE: 0.61166) avg lploss: 0.00000
==> test epoch 1815 avg loss: 0.86074 (A-MSE: 0.74025) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 1 out of 50
train epoch 1816 avg loss: 0.25085 (A-MSE: 0.21805) avg lploss: 0.00000
train epoch 1817 avg loss: 0.24266 (A-MSE: 0.21295) avg lploss: 0.00000
train epoch 1818 avg loss: 0.24311 (A-MSE: 0.21202) avg lploss: 0.00000
train epoch 1819 avg loss: 0.23178 (A-MSE: 0.20057) avg lploss: 0.00000
train epoch 1820 avg loss: 0.21099 (A-MSE: 0.18395) avg lploss: 0.00000
==> val epoch 1820 avg loss: 0.77821 (A-MSE: 0.66695) avg lploss: 0.00000
==> test epoch 1820 avg loss: 0.88489 (A-MSE: 0.76238) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 2 out of 50
train epoch 1821 avg loss: 0.21941 (A-MSE: 0.19204) avg lploss: 0.00000
train epoch 1822 avg loss: 0.23634 (A-MSE: 0.20415) avg lploss: 0.00000
train epoch 1823 avg loss: 0.21280 (A-MSE: 0.18624) avg lploss: 0.00000
train epoch 1824 avg loss: 0.21326 (A-MSE: 0.18579) avg lploss: 0.00000
train epoch 1825 avg loss: 0.22538 (A-MSE: 0.19659) avg lploss: 0.00000
==> val epoch 1825 avg loss: 0.73753 (A-MSE: 0.63084) avg lploss: 0.00000
==> test epoch 1825 avg loss: 0.83372 (A-MSE: 0.71929) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 3 out of 50
train epoch 1826 avg loss: 0.22751 (A-MSE: 0.19827) avg lploss: 0.00000
train epoch 1827 avg loss: 0.23256 (A-MSE: 0.20162) avg lploss: 0.00000
train epoch 1828 avg loss: 0.22301 (A-MSE: 0.19516) avg lploss: 0.00000
train epoch 1829 avg loss: 0.26130 (A-MSE: 0.22849) avg lploss: 0.00000
train epoch 1830 avg loss: 0.23188 (A-MSE: 0.20127) avg lploss: 0.00000
==> val epoch 1830 avg loss: 0.75468 (A-MSE: 0.64468) avg lploss: 0.00000
==> test epoch 1830 avg loss: 0.85749 (A-MSE: 0.73670) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 4 out of 50
train epoch 1831 avg loss: 0.23399 (A-MSE: 0.20557) avg lploss: 0.00000
train epoch 1832 avg loss: 0.23950 (A-MSE: 0.20857) avg lploss: 0.00000
train epoch 1833 avg loss: 0.21703 (A-MSE: 0.19017) avg lploss: 0.00000
train epoch 1834 avg loss: 0.21165 (A-MSE: 0.18472) avg lploss: 0.00000
train epoch 1835 avg loss: 0.22179 (A-MSE: 0.19384) avg lploss: 0.00000
==> val epoch 1835 avg loss: 0.73343 (A-MSE: 0.63201) avg lploss: 0.00000
==> test epoch 1835 avg loss: 0.87110 (A-MSE: 0.75701) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 5 out of 50
train epoch 1836 avg loss: 0.21003 (A-MSE: 0.18171) avg lploss: 0.00000
train epoch 1837 avg loss: 0.22114 (A-MSE: 0.19249) avg lploss: 0.00000
train epoch 1838 avg loss: 0.23044 (A-MSE: 0.20167) avg lploss: 0.00000
train epoch 1839 avg loss: 0.21142 (A-MSE: 0.18394) avg lploss: 0.00000
train epoch 1840 avg loss: 0.20857 (A-MSE: 0.18139) avg lploss: 0.00000
==> val epoch 1840 avg loss: 0.67033 (A-MSE: 0.58242) avg lploss: 0.00000
==> test epoch 1840 avg loss: 0.78200 (A-MSE: 0.67871) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 6 out of 50
train epoch 1841 avg loss: 0.20654 (A-MSE: 0.18127) avg lploss: 0.00000
train epoch 1842 avg loss: 0.22911 (A-MSE: 0.20078) avg lploss: 0.00000
train epoch 1843 avg loss: 0.26619 (A-MSE: 0.23283) avg lploss: 0.00000
train epoch 1844 avg loss: 0.22981 (A-MSE: 0.20074) avg lploss: 0.00000
train epoch 1845 avg loss: 0.23272 (A-MSE: 0.20188) avg lploss: 0.00000
==> val epoch 1845 avg loss: 0.68995 (A-MSE: 0.59602) avg lploss: 0.00000
==> test epoch 1845 avg loss: 0.81360 (A-MSE: 0.70521) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 7 out of 50
train epoch 1846 avg loss: 0.21859 (A-MSE: 0.18935) avg lploss: 0.00000
train epoch 1847 avg loss: 0.21962 (A-MSE: 0.19099) avg lploss: 0.00000
train epoch 1848 avg loss: 0.21265 (A-MSE: 0.18457) avg lploss: 0.00000
train epoch 1849 avg loss: 0.21162 (A-MSE: 0.18361) avg lploss: 0.00000
train epoch 1850 avg loss: 0.24356 (A-MSE: 0.21253) avg lploss: 0.00000
==> val epoch 1850 avg loss: 0.82359 (A-MSE: 0.70206) avg lploss: 0.00000
==> test epoch 1850 avg loss: 0.97671 (A-MSE: 0.84034) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 8 out of 50
train epoch 1851 avg loss: 0.24310 (A-MSE: 0.20971) avg lploss: 0.00000
train epoch 1852 avg loss: 0.23982 (A-MSE: 0.20911) avg lploss: 0.00000
train epoch 1853 avg loss: 0.23887 (A-MSE: 0.20858) avg lploss: 0.00000
train epoch 1854 avg loss: 0.25073 (A-MSE: 0.22156) avg lploss: 0.00000
train epoch 1855 avg loss: 0.25059 (A-MSE: 0.21706) avg lploss: 0.00000
==> val epoch 1855 avg loss: 0.68810 (A-MSE: 0.58837) avg lploss: 0.00000
==> test epoch 1855 avg loss: 0.80289 (A-MSE: 0.68932) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 9 out of 50
train epoch 1856 avg loss: 0.21873 (A-MSE: 0.19188) avg lploss: 0.00000
train epoch 1857 avg loss: 0.24355 (A-MSE: 0.21284) avg lploss: 0.00000
train epoch 1858 avg loss: 0.21834 (A-MSE: 0.19033) avg lploss: 0.00000
train epoch 1859 avg loss: 0.21416 (A-MSE: 0.18728) avg lploss: 0.00000
train epoch 1860 avg loss: 0.21773 (A-MSE: 0.18766) avg lploss: 0.00000
==> val epoch 1860 avg loss: 0.76578 (A-MSE: 0.65855) avg lploss: 0.00000
==> test epoch 1860 avg loss: 0.87907 (A-MSE: 0.75591) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 10 out of 50
train epoch 1861 avg loss: 0.19947 (A-MSE: 0.17384) avg lploss: 0.00000
train epoch 1862 avg loss: 0.22508 (A-MSE: 0.19632) avg lploss: 0.00000
train epoch 1863 avg loss: 0.23353 (A-MSE: 0.20416) avg lploss: 0.00000
train epoch 1864 avg loss: 0.19565 (A-MSE: 0.17074) avg lploss: 0.00000
train epoch 1865 avg loss: 0.20469 (A-MSE: 0.17909) avg lploss: 0.00000
==> val epoch 1865 avg loss: 0.66032 (A-MSE: 0.56450) avg lploss: 0.00000
==> test epoch 1865 avg loss: 0.78861 (A-MSE: 0.67640) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 11 out of 50
train epoch 1866 avg loss: 0.19358 (A-MSE: 0.16935) avg lploss: 0.00000
train epoch 1867 avg loss: 0.19886 (A-MSE: 0.17391) avg lploss: 0.00000
train epoch 1868 avg loss: 0.20449 (A-MSE: 0.17791) avg lploss: 0.00000
train epoch 1869 avg loss: 0.21152 (A-MSE: 0.18399) avg lploss: 0.00000
train epoch 1870 avg loss: 0.22198 (A-MSE: 0.19324) avg lploss: 0.00000
==> val epoch 1870 avg loss: 0.66720 (A-MSE: 0.57739) avg lploss: 0.00000
==> test epoch 1870 avg loss: 0.79653 (A-MSE: 0.69292) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 12 out of 50
train epoch 1871 avg loss: 0.21369 (A-MSE: 0.18695) avg lploss: 0.00000
train epoch 1872 avg loss: 0.22898 (A-MSE: 0.19969) avg lploss: 0.00000
train epoch 1873 avg loss: 0.23743 (A-MSE: 0.20759) avg lploss: 0.00000
train epoch 1874 avg loss: 0.22807 (A-MSE: 0.19973) avg lploss: 0.00000
train epoch 1875 avg loss: 0.21401 (A-MSE: 0.18743) avg lploss: 0.00000
==> val epoch 1875 avg loss: 0.71778 (A-MSE: 0.61737) avg lploss: 0.00000
==> test epoch 1875 avg loss: 0.81449 (A-MSE: 0.70328) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 13 out of 50
train epoch 1876 avg loss: 0.22924 (A-MSE: 0.19873) avg lploss: 0.00000
train epoch 1877 avg loss: 0.22140 (A-MSE: 0.19291) avg lploss: 0.00000
train epoch 1878 avg loss: 0.21528 (A-MSE: 0.18848) avg lploss: 0.00000
train epoch 1879 avg loss: 0.19646 (A-MSE: 0.17107) avg lploss: 0.00000
train epoch 1880 avg loss: 0.19718 (A-MSE: 0.17132) avg lploss: 0.00000
==> val epoch 1880 avg loss: 0.68647 (A-MSE: 0.59191) avg lploss: 0.00000
==> test epoch 1880 avg loss: 0.80069 (A-MSE: 0.69439) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 14 out of 50
train epoch 1881 avg loss: 0.21064 (A-MSE: 0.18180) avg lploss: 0.00000
train epoch 1882 avg loss: 0.21917 (A-MSE: 0.18980) avg lploss: 0.00000
train epoch 1883 avg loss: 0.21474 (A-MSE: 0.18680) avg lploss: 0.00000
train epoch 1884 avg loss: 0.22601 (A-MSE: 0.19679) avg lploss: 0.00000
train epoch 1885 avg loss: 0.21691 (A-MSE: 0.18903) avg lploss: 0.00000
==> val epoch 1885 avg loss: 0.74712 (A-MSE: 0.63378) avg lploss: 0.00000
==> test epoch 1885 avg loss: 0.88592 (A-MSE: 0.75738) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 15 out of 50
train epoch 1886 avg loss: 0.21595 (A-MSE: 0.18890) avg lploss: 0.00000
train epoch 1887 avg loss: 0.21092 (A-MSE: 0.18506) avg lploss: 0.00000
train epoch 1888 avg loss: 0.21060 (A-MSE: 0.18282) avg lploss: 0.00000
train epoch 1889 avg loss: 0.20881 (A-MSE: 0.18312) avg lploss: 0.00000
train epoch 1890 avg loss: 0.21990 (A-MSE: 0.19236) avg lploss: 0.00000
==> val epoch 1890 avg loss: 0.75812 (A-MSE: 0.65103) avg lploss: 0.00000
==> test epoch 1890 avg loss: 0.82742 (A-MSE: 0.71210) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 16 out of 50
train epoch 1891 avg loss: 0.21951 (A-MSE: 0.19168) avg lploss: 0.00000
train epoch 1892 avg loss: 0.20373 (A-MSE: 0.17904) avg lploss: 0.00000
train epoch 1893 avg loss: 0.19722 (A-MSE: 0.17146) avg lploss: 0.00000
train epoch 1894 avg loss: 0.18281 (A-MSE: 0.15903) avg lploss: 0.00000
train epoch 1895 avg loss: 0.20132 (A-MSE: 0.17559) avg lploss: 0.00000
==> val epoch 1895 avg loss: 0.69122 (A-MSE: 0.59378) avg lploss: 0.00000
==> test epoch 1895 avg loss: 0.80445 (A-MSE: 0.69511) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 17 out of 50
train epoch 1896 avg loss: 0.20115 (A-MSE: 0.17520) avg lploss: 0.00000
train epoch 1897 avg loss: 0.19925 (A-MSE: 0.17396) avg lploss: 0.00000
train epoch 1898 avg loss: 0.18852 (A-MSE: 0.16350) avg lploss: 0.00000
train epoch 1899 avg loss: 0.19910 (A-MSE: 0.17426) avg lploss: 0.00000
train epoch 1900 avg loss: 0.20405 (A-MSE: 0.17773) avg lploss: 0.00000
==> val epoch 1900 avg loss: 0.78774 (A-MSE: 0.67004) avg lploss: 0.00000
==> test epoch 1900 avg loss: 0.86931 (A-MSE: 0.74138) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 18 out of 50
train epoch 1901 avg loss: 0.24578 (A-MSE: 0.21556) avg lploss: 0.00000
train epoch 1902 avg loss: 0.27324 (A-MSE: 0.23799) avg lploss: 0.00000
train epoch 1903 avg loss: 0.24803 (A-MSE: 0.21565) avg lploss: 0.00000
train epoch 1904 avg loss: 0.24318 (A-MSE: 0.21243) avg lploss: 0.00000
train epoch 1905 avg loss: 0.22186 (A-MSE: 0.19259) avg lploss: 0.00000
==> val epoch 1905 avg loss: 0.68493 (A-MSE: 0.59270) avg lploss: 0.00000
==> test epoch 1905 avg loss: 0.82627 (A-MSE: 0.71515) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 19 out of 50
train epoch 1906 avg loss: 0.19008 (A-MSE: 0.16504) avg lploss: 0.00000
train epoch 1907 avg loss: 0.20865 (A-MSE: 0.18235) avg lploss: 0.00000
train epoch 1908 avg loss: 0.18564 (A-MSE: 0.16204) avg lploss: 0.00000
train epoch 1909 avg loss: 0.19230 (A-MSE: 0.16755) avg lploss: 0.00000
train epoch 1910 avg loss: 0.21508 (A-MSE: 0.18700) avg lploss: 0.00000
==> val epoch 1910 avg loss: 0.73900 (A-MSE: 0.63223) avg lploss: 0.00000
==> test epoch 1910 avg loss: 0.86009 (A-MSE: 0.74131) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 20 out of 50
train epoch 1911 avg loss: 0.21775 (A-MSE: 0.19060) avg lploss: 0.00000
train epoch 1912 avg loss: 0.21309 (A-MSE: 0.18603) avg lploss: 0.00000
train epoch 1913 avg loss: 0.21419 (A-MSE: 0.18719) avg lploss: 0.00000
train epoch 1914 avg loss: 0.21258 (A-MSE: 0.18213) avg lploss: 0.00000
train epoch 1915 avg loss: 0.22251 (A-MSE: 0.19509) avg lploss: 0.00000
==> val epoch 1915 avg loss: 0.74494 (A-MSE: 0.63557) avg lploss: 0.00000
==> test epoch 1915 avg loss: 0.88563 (A-MSE: 0.75965) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 21 out of 50
train epoch 1916 avg loss: 0.22415 (A-MSE: 0.19651) avg lploss: 0.00000
train epoch 1917 avg loss: 0.22726 (A-MSE: 0.19999) avg lploss: 0.00000
train epoch 1918 avg loss: 0.20317 (A-MSE: 0.17714) avg lploss: 0.00000
train epoch 1919 avg loss: 0.19914 (A-MSE: 0.17399) avg lploss: 0.00000
train epoch 1920 avg loss: 0.20274 (A-MSE: 0.17637) avg lploss: 0.00000
==> val epoch 1920 avg loss: 0.70025 (A-MSE: 0.61372) avg lploss: 0.00000
==> test epoch 1920 avg loss: 0.81943 (A-MSE: 0.71460) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 22 out of 50
train epoch 1921 avg loss: 0.20702 (A-MSE: 0.18093) avg lploss: 0.00000
train epoch 1922 avg loss: 0.19080 (A-MSE: 0.16603) avg lploss: 0.00000
train epoch 1923 avg loss: 0.18765 (A-MSE: 0.16414) avg lploss: 0.00000
train epoch 1924 avg loss: 0.20885 (A-MSE: 0.18358) avg lploss: 0.00000
train epoch 1925 avg loss: 0.21823 (A-MSE: 0.18972) avg lploss: 0.00000
==> val epoch 1925 avg loss: 0.73793 (A-MSE: 0.63549) avg lploss: 0.00000
==> test epoch 1925 avg loss: 0.83975 (A-MSE: 0.72107) avg lploss: 0.00000
*** Best Val Loss: 0.61240 	 Best Test Loss: 0.74519 	 Best epoch 1810
EarlyStopping counter: 23 out of 50
train epoch 1926 avg loss: 0.20086 (A-MSE: 0.17735) avg lploss: 0.00000
train epoch 1927 avg loss: 0.22287 (A-MSE: 0.19439) avg lploss: 0.00000
train epoch 1928 avg loss: 0.23326 (A-MSE: 0.20318) avg lploss: 0.00000
train epoch 1929 avg loss: 0.21430 (A-MSE: 0.18638) avg lploss: 0.00000
train epoch 1930 avg loss: 0.19225 (A-MSE: 0.16784) avg lploss: 0.00000
==> val epoch 1930 avg loss: 0.61022 (A-MSE: 0.52738) avg lploss: 0.00000
==> test epoch 1930 avg loss: 0.75557 (A-MSE: 0.65378) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
Validation loss decreased (0.612404 --> 0.610220).  Saving model ...
train epoch 1931 avg loss: 0.20460 (A-MSE: 0.17848) avg lploss: 0.00000
train epoch 1932 avg loss: 0.20937 (A-MSE: 0.18323) avg lploss: 0.00000
train epoch 1933 avg loss: 0.20501 (A-MSE: 0.17819) avg lploss: 0.00000
train epoch 1934 avg loss: 0.19915 (A-MSE: 0.17464) avg lploss: 0.00000
train epoch 1935 avg loss: 0.23341 (A-MSE: 0.20201) avg lploss: 0.00000
==> val epoch 1935 avg loss: 0.78843 (A-MSE: 0.68222) avg lploss: 0.00000
==> test epoch 1935 avg loss: 0.88771 (A-MSE: 0.76370) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 1 out of 50
train epoch 1936 avg loss: 0.23140 (A-MSE: 0.20197) avg lploss: 0.00000
train epoch 1937 avg loss: 0.21315 (A-MSE: 0.18769) avg lploss: 0.00000
train epoch 1938 avg loss: 0.21167 (A-MSE: 0.18568) avg lploss: 0.00000
train epoch 1939 avg loss: 0.20886 (A-MSE: 0.18162) avg lploss: 0.00000
train epoch 1940 avg loss: 0.19539 (A-MSE: 0.17049) avg lploss: 0.00000
==> val epoch 1940 avg loss: 0.69356 (A-MSE: 0.59719) avg lploss: 0.00000
==> test epoch 1940 avg loss: 0.82950 (A-MSE: 0.71769) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 2 out of 50
train epoch 1941 avg loss: 0.18850 (A-MSE: 0.16408) avg lploss: 0.00000
train epoch 1942 avg loss: 0.23385 (A-MSE: 0.20515) avg lploss: 0.00000
train epoch 1943 avg loss: 0.23652 (A-MSE: 0.20449) avg lploss: 0.00000
train epoch 1944 avg loss: 0.20808 (A-MSE: 0.18202) avg lploss: 0.00000
train epoch 1945 avg loss: 0.19669 (A-MSE: 0.17218) avg lploss: 0.00000
==> val epoch 1945 avg loss: 0.70880 (A-MSE: 0.61236) avg lploss: 0.00000
==> test epoch 1945 avg loss: 0.84691 (A-MSE: 0.73262) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 3 out of 50
train epoch 1946 avg loss: 0.21838 (A-MSE: 0.19073) avg lploss: 0.00000
train epoch 1947 avg loss: 0.22808 (A-MSE: 0.19985) avg lploss: 0.00000
train epoch 1948 avg loss: 0.20973 (A-MSE: 0.18307) avg lploss: 0.00000
train epoch 1949 avg loss: 0.19757 (A-MSE: 0.17287) avg lploss: 0.00000
train epoch 1950 avg loss: 0.20862 (A-MSE: 0.18020) avg lploss: 0.00000
==> val epoch 1950 avg loss: 0.77448 (A-MSE: 0.66621) avg lploss: 0.00000
==> test epoch 1950 avg loss: 0.89594 (A-MSE: 0.77303) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 4 out of 50
train epoch 1951 avg loss: 0.21466 (A-MSE: 0.18889) avg lploss: 0.00000
train epoch 1952 avg loss: 0.21162 (A-MSE: 0.18517) avg lploss: 0.00000
train epoch 1953 avg loss: 0.21489 (A-MSE: 0.18628) avg lploss: 0.00000
train epoch 1954 avg loss: 0.19953 (A-MSE: 0.17493) avg lploss: 0.00000
train epoch 1955 avg loss: 0.20306 (A-MSE: 0.17709) avg lploss: 0.00000
==> val epoch 1955 avg loss: 0.76658 (A-MSE: 0.66525) avg lploss: 0.00000
==> test epoch 1955 avg loss: 0.83578 (A-MSE: 0.72257) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 5 out of 50
train epoch 1956 avg loss: 0.20811 (A-MSE: 0.18324) avg lploss: 0.00000
train epoch 1957 avg loss: 0.20159 (A-MSE: 0.17688) avg lploss: 0.00000
train epoch 1958 avg loss: 0.20592 (A-MSE: 0.17905) avg lploss: 0.00000
train epoch 1959 avg loss: 0.21741 (A-MSE: 0.18863) avg lploss: 0.00000
train epoch 1960 avg loss: 0.22692 (A-MSE: 0.19753) avg lploss: 0.00000
==> val epoch 1960 avg loss: 0.61551 (A-MSE: 0.53359) avg lploss: 0.00000
==> test epoch 1960 avg loss: 0.78711 (A-MSE: 0.68541) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 6 out of 50
train epoch 1961 avg loss: 0.22367 (A-MSE: 0.19479) avg lploss: 0.00000
train epoch 1962 avg loss: 0.20581 (A-MSE: 0.17936) avg lploss: 0.00000
train epoch 1963 avg loss: 0.21773 (A-MSE: 0.18920) avg lploss: 0.00000
train epoch 1964 avg loss: 0.21401 (A-MSE: 0.18682) avg lploss: 0.00000
train epoch 1965 avg loss: 0.20366 (A-MSE: 0.17778) avg lploss: 0.00000
==> val epoch 1965 avg loss: 0.73019 (A-MSE: 0.62798) avg lploss: 0.00000
==> test epoch 1965 avg loss: 0.86734 (A-MSE: 0.74758) avg lploss: 0.00000
*** Best Val Loss: 0.61022 	 Best Test Loss: 0.75557 	 Best epoch 1930
EarlyStopping counter: 7 out of 50
train epoch 1966 avg loss: 0.19473 (A-MSE: 0.17115) avg lploss: 0.00000
train epoch 1967 avg loss: 0.21184 (A-MSE: 0.18375) avg lploss: 0.00000
train epoch 1968 avg loss: 0.19208 (A-MSE: 0.16726) avg lploss: 0.00000
train epoch 1969 avg loss: 0.18972 (A-MSE: 0.16626) avg lploss: 0.00000
train epoch 1970 avg loss: 0.19033 (A-MSE: 0.16665) avg lploss: 0.00000
==> val epoch 1970 avg loss: 0.59877 (A-MSE: 0.51917) avg lploss: 0.00000
==> test epoch 1970 avg loss: 0.75055 (A-MSE: 0.64670) avg lploss: 0.00000
*** Best Val Loss: 0.59877 	 Best Test Loss: 0.75055 	 Best epoch 1970
Validation loss decreased (0.610220 --> 0.598774).  Saving model ...
train epoch 1971 avg loss: 0.20298 (A-MSE: 0.17691) avg lploss: 0.00000
train epoch 1972 avg loss: 0.22104 (A-MSE: 0.19343) avg lploss: 0.00000
train epoch 1973 avg loss: 0.20885 (A-MSE: 0.18310) avg lploss: 0.00000
train epoch 1974 avg loss: 0.23260 (A-MSE: 0.20455) avg lploss: 0.00000
train epoch 1975 avg loss: 0.25618 (A-MSE: 0.22301) avg lploss: 0.00000
==> val epoch 1975 avg loss: 0.65929 (A-MSE: 0.56967) avg lploss: 0.00000
==> test epoch 1975 avg loss: 0.78023 (A-MSE: 0.67694) avg lploss: 0.00000
*** Best Val Loss: 0.59877 	 Best Test Loss: 0.75055 	 Best epoch 1970
EarlyStopping counter: 1 out of 50
train epoch 1976 avg loss: 0.22888 (A-MSE: 0.20077) avg lploss: 0.00000
train epoch 1977 avg loss: 0.19047 (A-MSE: 0.16712) avg lploss: 0.00000
train epoch 1978 avg loss: 0.18889 (A-MSE: 0.16466) avg lploss: 0.00000
train epoch 1979 avg loss: 0.19294 (A-MSE: 0.16770) avg lploss: 0.00000
train epoch 1980 avg loss: 0.18997 (A-MSE: 0.16714) avg lploss: 0.00000
==> val epoch 1980 avg loss: 0.71137 (A-MSE: 0.61322) avg lploss: 0.00000
==> test epoch 1980 avg loss: 0.82282 (A-MSE: 0.70894) avg lploss: 0.00000
*** Best Val Loss: 0.59877 	 Best Test Loss: 0.75055 	 Best epoch 1970
EarlyStopping counter: 2 out of 50
train epoch 1981 avg loss: 0.19984 (A-MSE: 0.17300) avg lploss: 0.00000
train epoch 1982 avg loss: 0.19591 (A-MSE: 0.17061) avg lploss: 0.00000
train epoch 1983 avg loss: 0.18439 (A-MSE: 0.16161) avg lploss: 0.00000
train epoch 1984 avg loss: 0.21375 (A-MSE: 0.18721) avg lploss: 0.00000
train epoch 1985 avg loss: 0.18282 (A-MSE: 0.16013) avg lploss: 0.00000
==> val epoch 1985 avg loss: 0.59956 (A-MSE: 0.51878) avg lploss: 0.00000
==> test epoch 1985 avg loss: 0.72143 (A-MSE: 0.62627) avg lploss: 0.00000
*** Best Val Loss: 0.59877 	 Best Test Loss: 0.75055 	 Best epoch 1970
EarlyStopping counter: 3 out of 50
train epoch 1986 avg loss: 0.18249 (A-MSE: 0.15960) avg lploss: 0.00000
train epoch 1987 avg loss: 0.18734 (A-MSE: 0.16501) avg lploss: 0.00000
train epoch 1988 avg loss: 0.19142 (A-MSE: 0.16719) avg lploss: 0.00000
train epoch 1989 avg loss: 0.20455 (A-MSE: 0.17888) avg lploss: 0.00000
train epoch 1990 avg loss: 0.18097 (A-MSE: 0.15838) avg lploss: 0.00000
==> val epoch 1990 avg loss: 0.69122 (A-MSE: 0.59268) avg lploss: 0.00000
==> test epoch 1990 avg loss: 0.81383 (A-MSE: 0.69857) avg lploss: 0.00000
*** Best Val Loss: 0.59877 	 Best Test Loss: 0.75055 	 Best epoch 1970
EarlyStopping counter: 4 out of 50
train epoch 1991 avg loss: 0.19834 (A-MSE: 0.17128) avg lploss: 0.00000
train epoch 1992 avg loss: 0.18946 (A-MSE: 0.16580) avg lploss: 0.00000
train epoch 1993 avg loss: 0.18641 (A-MSE: 0.16329) avg lploss: 0.00000
train epoch 1994 avg loss: 0.19878 (A-MSE: 0.17443) avg lploss: 0.00000
train epoch 1995 avg loss: 0.20697 (A-MSE: 0.18108) avg lploss: 0.00000
==> val epoch 1995 avg loss: 0.68574 (A-MSE: 0.59900) avg lploss: 0.00000
==> test epoch 1995 avg loss: 0.79525 (A-MSE: 0.69357) avg lploss: 0.00000
*** Best Val Loss: 0.59877 	 Best Test Loss: 0.75055 	 Best epoch 1970
EarlyStopping counter: 5 out of 50
train epoch 1996 avg loss: 0.18136 (A-MSE: 0.15920) avg lploss: 0.00000
train epoch 1997 avg loss: 0.18246 (A-MSE: 0.15966) avg lploss: 0.00000
train epoch 1998 avg loss: 0.21276 (A-MSE: 0.18394) avg lploss: 0.00000
train epoch 1999 avg loss: 0.23355 (A-MSE: 0.20301) avg lploss: 0.00000
best_train_f_mse = 0.190329
best_lp = 0.000000
best_val_f_mse = 0.598774
best_test_f_mse = 0.750555
best_test_a_mse = 0.646702
best_epoch = 1970
best_train_f_mse = 0.190329, best_lp = 0.000000, best_val_f_mse = 0.598774, best_test_f_mse = 0.750555, best_test_a_mse = 0.646702, best_epoch = 1970
Job completed at Mon Dec  8 23:31:38 CET 2025
