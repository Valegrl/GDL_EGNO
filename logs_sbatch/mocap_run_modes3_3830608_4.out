Running Mocap-Run with num_modes=3 for seed 4
Job ID: 3831024, Array Task ID: 4
Namespace(batch_size=12, case='run', config_by_file='configs/mocap_run_modes3_seed4.json', cuda=True, data_dir='motion/dataset', decoder_layer=1, delta_frame=30, dropout=0.5, epochs=2000, exp_name='mocap_run_modes3_seed4', flat=False, interaction_layer=3, lambda_link=1, log_interval=1, lr=0.0005, max_training_samples=200, model='egno', n_cluster=3, n_layers=6, nf=128, no_cuda=False, num_modes=3, num_timesteps=5, outf='exp_results', pooling_layer=3, seed=4, test_interval=5, time_emb_dim=32, weight_decay=1e-10)
Got Split!
Got 200 samples!
Got Split!
Got 240 samples!
Got Split!
Got 240 samples!
EGNO(
  (layers): ModuleList(
    (0-5): 6 x EGNN_Layer(
      (edge_message_net): InvariantScalarNet(
        (activation): SiLU()
        (scalar_net): BaseMLP(
          (mlp): Sequential(
            (0): Linear(in_features=259, out_features=128, bias=True)
            (1): SiLU()
            (2): Linear(in_features=128, out_features=128, bias=True)
            (3): SiLU()
          )
        )
      )
      (coord_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_v_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=1, bias=True)
        )
      )
      (node_net): BaseMLP(
        (mlp): Sequential(
          (0): Linear(in_features=256, out_features=128, bias=True)
          (1): SiLU()
          (2): Linear(in_features=128, out_features=128, bias=True)
        )
      )
    )
  )
  (embedding): Linear(in_features=34, out_features=128, bias=True)
  (time_conv_modules): ModuleList(
    (0-5): 6 x TimeConv(
      (t_conv): SpectralConv1d()
      (act): LeakyReLU(negative_slope=0.01)
    )
  )
  (time_conv_x_modules): ModuleList(
    (0-5): 6 x TimeConv_x(
      (t_conv): SpectralConv1d_x()
    )
  )
)
Model saved to exp_results/mocap_run_modes3_seed4/saved_model.pth
train epoch 0 avg loss: 1257422.87942 (A-MSE: 1268081.18256) avg lploss: 0.00000
==> val epoch 0 avg loss: 890.25070 (A-MSE: 830.16931) avg lploss: 0.00000
==> test epoch 0 avg loss: 853.77507 (A-MSE: 797.92794) avg lploss: 0.00000
*** Best Val Loss: 890.25070 	 Best Test Loss: 853.77507 	 Best epoch 0
Validation loss decreased (inf --> 890.250700).  Saving model ...
train epoch 1 avg loss: 13173.51948 (A-MSE: 11672.16481) avg lploss: 0.00000
train epoch 2 avg loss: 254.07856 (A-MSE: 239.49225) avg lploss: 0.00000
train epoch 3 avg loss: 94.82565 (A-MSE: 83.93415) avg lploss: 0.00000
train epoch 4 avg loss: 91.98092 (A-MSE: 81.36462) avg lploss: 0.00000
train epoch 5 avg loss: 87.51294 (A-MSE: 77.45723) avg lploss: 0.00000
==> val epoch 5 avg loss: 85.97939 (A-MSE: 75.93027) avg lploss: 0.00000
==> test epoch 5 avg loss: 81.25185 (A-MSE: 71.74876) avg lploss: 0.00000
*** Best Val Loss: 85.97939 	 Best Test Loss: 81.25185 	 Best epoch 5
Validation loss decreased (890.250700 --> 85.979385).  Saving model ...
train epoch 6 avg loss: 79.29971 (A-MSE: 70.11205) avg lploss: 0.00000
train epoch 7 avg loss: 68.79806 (A-MSE: 60.63219) avg lploss: 0.00000
train epoch 8 avg loss: 61.13142 (A-MSE: 53.70719) avg lploss: 0.00000
train epoch 9 avg loss: 56.49842 (A-MSE: 49.54401) avg lploss: 0.00000
train epoch 10 avg loss: 52.67566 (A-MSE: 46.09794) avg lploss: 0.00000
==> val epoch 10 avg loss: 50.58602 (A-MSE: 44.21137) avg lploss: 0.00000
==> test epoch 10 avg loss: 47.29773 (A-MSE: 41.33995) avg lploss: 0.00000
*** Best Val Loss: 50.58602 	 Best Test Loss: 47.29773 	 Best epoch 10
Validation loss decreased (85.979385 --> 50.586017).  Saving model ...
train epoch 11 avg loss: 48.79839 (A-MSE: 42.53166) avg lploss: 0.00000
train epoch 12 avg loss: 44.08137 (A-MSE: 38.29917) avg lploss: 0.00000
train epoch 13 avg loss: 40.22243 (A-MSE: 34.80514) avg lploss: 0.00000
train epoch 14 avg loss: 36.60777 (A-MSE: 31.70076) avg lploss: 0.00000
train epoch 15 avg loss: 34.55905 (A-MSE: 29.92539) avg lploss: 0.00000
==> val epoch 15 avg loss: 33.60957 (A-MSE: 29.03832) avg lploss: 0.00000
==> test epoch 15 avg loss: 32.14159 (A-MSE: 27.86035) avg lploss: 0.00000
*** Best Val Loss: 33.60957 	 Best Test Loss: 32.14159 	 Best epoch 15
Validation loss decreased (50.586017 --> 33.609572).  Saving model ...
train epoch 16 avg loss: 32.64421 (A-MSE: 28.21833) avg lploss: 0.00000
train epoch 17 avg loss: 30.52664 (A-MSE: 26.37784) avg lploss: 0.00000
train epoch 18 avg loss: 29.27457 (A-MSE: 25.34565) avg lploss: 0.00000
train epoch 19 avg loss: 27.21829 (A-MSE: 23.46108) avg lploss: 0.00000
train epoch 20 avg loss: 25.58308 (A-MSE: 22.14526) avg lploss: 0.00000
==> val epoch 20 avg loss: 25.86460 (A-MSE: 22.29758) avg lploss: 0.00000
==> test epoch 20 avg loss: 23.74325 (A-MSE: 20.38988) avg lploss: 0.00000
*** Best Val Loss: 25.86460 	 Best Test Loss: 23.74325 	 Best epoch 20
Validation loss decreased (33.609572 --> 25.864599).  Saving model ...
train epoch 21 avg loss: 24.84817 (A-MSE: 21.54160) avg lploss: 0.00000
train epoch 22 avg loss: 24.52341 (A-MSE: 21.32239) avg lploss: 0.00000
train epoch 23 avg loss: 23.04607 (A-MSE: 19.92329) avg lploss: 0.00000
train epoch 24 avg loss: 22.43743 (A-MSE: 19.44758) avg lploss: 0.00000
train epoch 25 avg loss: 21.93750 (A-MSE: 19.00342) avg lploss: 0.00000
==> val epoch 25 avg loss: 21.81145 (A-MSE: 19.00631) avg lploss: 0.00000
==> test epoch 25 avg loss: 20.14881 (A-MSE: 17.50413) avg lploss: 0.00000
*** Best Val Loss: 21.81145 	 Best Test Loss: 20.14881 	 Best epoch 25
Validation loss decreased (25.864599 --> 21.811453).  Saving model ...
train epoch 26 avg loss: 21.34841 (A-MSE: 18.49591) avg lploss: 0.00000
train epoch 27 avg loss: 20.92505 (A-MSE: 18.15055) avg lploss: 0.00000
train epoch 28 avg loss: 20.30354 (A-MSE: 17.59173) avg lploss: 0.00000
train epoch 29 avg loss: 19.53140 (A-MSE: 16.91819) avg lploss: 0.00000
train epoch 30 avg loss: 19.71507 (A-MSE: 17.11427) avg lploss: 0.00000
==> val epoch 30 avg loss: 20.24781 (A-MSE: 17.22369) avg lploss: 0.00000
==> test epoch 30 avg loss: 19.11935 (A-MSE: 16.26443) avg lploss: 0.00000
*** Best Val Loss: 20.24781 	 Best Test Loss: 19.11935 	 Best epoch 30
Validation loss decreased (21.811453 --> 20.247813).  Saving model ...
train epoch 31 avg loss: 19.38139 (A-MSE: 16.75524) avg lploss: 0.00000
train epoch 32 avg loss: 19.00489 (A-MSE: 16.49615) avg lploss: 0.00000
train epoch 33 avg loss: 18.91258 (A-MSE: 16.39371) avg lploss: 0.00000
train epoch 34 avg loss: 17.95775 (A-MSE: 15.54598) avg lploss: 0.00000
train epoch 35 avg loss: 18.14370 (A-MSE: 15.71412) avg lploss: 0.00000
==> val epoch 35 avg loss: 18.27351 (A-MSE: 15.71474) avg lploss: 0.00000
==> test epoch 35 avg loss: 17.25454 (A-MSE: 14.83171) avg lploss: 0.00000
*** Best Val Loss: 18.27351 	 Best Test Loss: 17.25454 	 Best epoch 35
Validation loss decreased (20.247813 --> 18.273510).  Saving model ...
train epoch 36 avg loss: 17.48412 (A-MSE: 15.09166) avg lploss: 0.00000
train epoch 37 avg loss: 16.82789 (A-MSE: 14.59454) avg lploss: 0.00000
train epoch 38 avg loss: 16.45968 (A-MSE: 14.23160) avg lploss: 0.00000
train epoch 39 avg loss: 16.33503 (A-MSE: 14.13234) avg lploss: 0.00000
train epoch 40 avg loss: 15.95404 (A-MSE: 13.79729) avg lploss: 0.00000
==> val epoch 40 avg loss: 17.09132 (A-MSE: 14.89206) avg lploss: 0.00000
==> test epoch 40 avg loss: 16.56399 (A-MSE: 14.49467) avg lploss: 0.00000
*** Best Val Loss: 17.09132 	 Best Test Loss: 16.56399 	 Best epoch 40
Validation loss decreased (18.273510 --> 17.091320).  Saving model ...
train epoch 41 avg loss: 16.59443 (A-MSE: 14.36902) avg lploss: 0.00000
train epoch 42 avg loss: 15.69092 (A-MSE: 13.62584) avg lploss: 0.00000
train epoch 43 avg loss: 15.89442 (A-MSE: 13.77369) avg lploss: 0.00000
train epoch 44 avg loss: 14.86410 (A-MSE: 12.84611) avg lploss: 0.00000
train epoch 45 avg loss: 14.45982 (A-MSE: 12.48693) avg lploss: 0.00000
==> val epoch 45 avg loss: 14.64713 (A-MSE: 12.65415) avg lploss: 0.00000
==> test epoch 45 avg loss: 14.27256 (A-MSE: 12.39731) avg lploss: 0.00000
*** Best Val Loss: 14.64713 	 Best Test Loss: 14.27256 	 Best epoch 45
Validation loss decreased (17.091320 --> 14.647128).  Saving model ...
train epoch 46 avg loss: 14.05097 (A-MSE: 12.13966) avg lploss: 0.00000
train epoch 47 avg loss: 14.29950 (A-MSE: 12.37604) avg lploss: 0.00000
train epoch 48 avg loss: 14.04436 (A-MSE: 12.19338) avg lploss: 0.00000
train epoch 49 avg loss: 13.84388 (A-MSE: 11.95318) avg lploss: 0.00000
train epoch 50 avg loss: 13.24121 (A-MSE: 11.45946) avg lploss: 0.00000
==> val epoch 50 avg loss: 13.28405 (A-MSE: 11.44033) avg lploss: 0.00000
==> test epoch 50 avg loss: 13.27371 (A-MSE: 11.50914) avg lploss: 0.00000
*** Best Val Loss: 13.28405 	 Best Test Loss: 13.27371 	 Best epoch 50
Validation loss decreased (14.647128 --> 13.284053).  Saving model ...
train epoch 51 avg loss: 12.89818 (A-MSE: 11.15836) avg lploss: 0.00000
train epoch 52 avg loss: 13.06973 (A-MSE: 11.31265) avg lploss: 0.00000
train epoch 53 avg loss: 13.15157 (A-MSE: 11.39509) avg lploss: 0.00000
train epoch 54 avg loss: 12.73762 (A-MSE: 11.02218) avg lploss: 0.00000
train epoch 55 avg loss: 12.76673 (A-MSE: 11.04528) avg lploss: 0.00000
==> val epoch 55 avg loss: 13.23561 (A-MSE: 11.47007) avg lploss: 0.00000
==> test epoch 55 avg loss: 12.99315 (A-MSE: 11.31120) avg lploss: 0.00000
*** Best Val Loss: 13.23561 	 Best Test Loss: 12.99315 	 Best epoch 55
Validation loss decreased (13.284053 --> 13.235610).  Saving model ...
train epoch 56 avg loss: 11.82808 (A-MSE: 10.18560) avg lploss: 0.00000
train epoch 57 avg loss: 11.99248 (A-MSE: 10.39232) avg lploss: 0.00000
train epoch 58 avg loss: 12.17350 (A-MSE: 10.51514) avg lploss: 0.00000
train epoch 59 avg loss: 11.52801 (A-MSE: 9.96371) avg lploss: 0.00000
train epoch 60 avg loss: 11.38697 (A-MSE: 9.83611) avg lploss: 0.00000
==> val epoch 60 avg loss: 12.02327 (A-MSE: 10.32452) avg lploss: 0.00000
==> test epoch 60 avg loss: 11.94045 (A-MSE: 10.30982) avg lploss: 0.00000
*** Best Val Loss: 12.02327 	 Best Test Loss: 11.94045 	 Best epoch 60
Validation loss decreased (13.235610 --> 12.023268).  Saving model ...
train epoch 61 avg loss: 10.92352 (A-MSE: 9.41376) avg lploss: 0.00000
train epoch 62 avg loss: 10.78722 (A-MSE: 9.30559) avg lploss: 0.00000
train epoch 63 avg loss: 11.33416 (A-MSE: 9.85927) avg lploss: 0.00000
train epoch 64 avg loss: 11.14979 (A-MSE: 9.61907) avg lploss: 0.00000
train epoch 65 avg loss: 10.73399 (A-MSE: 9.23667) avg lploss: 0.00000
==> val epoch 65 avg loss: 11.21346 (A-MSE: 9.76327) avg lploss: 0.00000
==> test epoch 65 avg loss: 10.84188 (A-MSE: 9.43807) avg lploss: 0.00000
*** Best Val Loss: 11.21346 	 Best Test Loss: 10.84188 	 Best epoch 65
Validation loss decreased (12.023268 --> 11.213464).  Saving model ...
train epoch 66 avg loss: 10.90762 (A-MSE: 9.43618) avg lploss: 0.00000
train epoch 67 avg loss: 10.94723 (A-MSE: 9.48678) avg lploss: 0.00000
train epoch 68 avg loss: 10.71418 (A-MSE: 9.23914) avg lploss: 0.00000
train epoch 69 avg loss: 10.12068 (A-MSE: 8.73067) avg lploss: 0.00000
train epoch 70 avg loss: 10.32881 (A-MSE: 8.94443) avg lploss: 0.00000
==> val epoch 70 avg loss: 11.73504 (A-MSE: 10.14473) avg lploss: 0.00000
==> test epoch 70 avg loss: 11.83589 (A-MSE: 10.28858) avg lploss: 0.00000
*** Best Val Loss: 11.21346 	 Best Test Loss: 10.84188 	 Best epoch 65
EarlyStopping counter: 1 out of 50
train epoch 71 avg loss: 9.76771 (A-MSE: 8.41617) avg lploss: 0.00000
train epoch 72 avg loss: 9.54807 (A-MSE: 8.22451) avg lploss: 0.00000
train epoch 73 avg loss: 9.51788 (A-MSE: 8.20636) avg lploss: 0.00000
train epoch 74 avg loss: 9.64056 (A-MSE: 8.35267) avg lploss: 0.00000
train epoch 75 avg loss: 9.75139 (A-MSE: 8.41479) avg lploss: 0.00000
==> val epoch 75 avg loss: 10.72577 (A-MSE: 9.34286) avg lploss: 0.00000
==> test epoch 75 avg loss: 10.46600 (A-MSE: 9.11374) avg lploss: 0.00000
*** Best Val Loss: 10.72577 	 Best Test Loss: 10.46600 	 Best epoch 75
Validation loss decreased (11.213464 --> 10.725766).  Saving model ...
train epoch 76 avg loss: 9.39039 (A-MSE: 8.09536) avg lploss: 0.00000
train epoch 77 avg loss: 9.17300 (A-MSE: 7.90586) avg lploss: 0.00000
train epoch 78 avg loss: 9.11470 (A-MSE: 7.90413) avg lploss: 0.00000
train epoch 79 avg loss: 9.30198 (A-MSE: 8.06612) avg lploss: 0.00000
train epoch 80 avg loss: 9.34432 (A-MSE: 8.07585) avg lploss: 0.00000
==> val epoch 80 avg loss: 10.04045 (A-MSE: 8.53068) avg lploss: 0.00000
==> test epoch 80 avg loss: 9.61184 (A-MSE: 8.14981) avg lploss: 0.00000
*** Best Val Loss: 10.04045 	 Best Test Loss: 9.61184 	 Best epoch 80
Validation loss decreased (10.725766 --> 10.040451).  Saving model ...
train epoch 81 avg loss: 9.00861 (A-MSE: 7.78342) avg lploss: 0.00000
train epoch 82 avg loss: 8.91749 (A-MSE: 7.71494) avg lploss: 0.00000
train epoch 83 avg loss: 8.61630 (A-MSE: 7.41105) avg lploss: 0.00000
train epoch 84 avg loss: 8.66021 (A-MSE: 7.51603) avg lploss: 0.00000
train epoch 85 avg loss: 8.75878 (A-MSE: 7.59222) avg lploss: 0.00000
==> val epoch 85 avg loss: 9.62056 (A-MSE: 8.46534) avg lploss: 0.00000
==> test epoch 85 avg loss: 9.17082 (A-MSE: 8.05329) avg lploss: 0.00000
*** Best Val Loss: 9.62056 	 Best Test Loss: 9.17082 	 Best epoch 85
Validation loss decreased (10.040451 --> 9.620560).  Saving model ...
train epoch 86 avg loss: 8.87678 (A-MSE: 7.68578) avg lploss: 0.00000
train epoch 87 avg loss: 8.63861 (A-MSE: 7.46136) avg lploss: 0.00000
train epoch 88 avg loss: 8.38522 (A-MSE: 7.25717) avg lploss: 0.00000
train epoch 89 avg loss: 8.50439 (A-MSE: 7.38605) avg lploss: 0.00000
train epoch 90 avg loss: 8.56859 (A-MSE: 7.43264) avg lploss: 0.00000
==> val epoch 90 avg loss: 9.29033 (A-MSE: 8.04022) avg lploss: 0.00000
==> test epoch 90 avg loss: 9.17540 (A-MSE: 7.95648) avg lploss: 0.00000
*** Best Val Loss: 9.29033 	 Best Test Loss: 9.17540 	 Best epoch 90
Validation loss decreased (9.620560 --> 9.290327).  Saving model ...
train epoch 91 avg loss: 8.61802 (A-MSE: 7.47768) avg lploss: 0.00000
train epoch 92 avg loss: 8.16012 (A-MSE: 7.08304) avg lploss: 0.00000
train epoch 93 avg loss: 8.19068 (A-MSE: 7.09773) avg lploss: 0.00000
train epoch 94 avg loss: 8.07028 (A-MSE: 6.98045) avg lploss: 0.00000
train epoch 95 avg loss: 8.12577 (A-MSE: 7.04678) avg lploss: 0.00000
==> val epoch 95 avg loss: 9.65635 (A-MSE: 8.51492) avg lploss: 0.00000
==> test epoch 95 avg loss: 9.09092 (A-MSE: 7.98326) avg lploss: 0.00000
*** Best Val Loss: 9.29033 	 Best Test Loss: 9.17540 	 Best epoch 90
EarlyStopping counter: 1 out of 50
train epoch 96 avg loss: 7.81666 (A-MSE: 6.78137) avg lploss: 0.00000
train epoch 97 avg loss: 8.05310 (A-MSE: 7.00471) avg lploss: 0.00000
train epoch 98 avg loss: 8.25787 (A-MSE: 7.19057) avg lploss: 0.00000
train epoch 99 avg loss: 8.18388 (A-MSE: 7.09220) avg lploss: 0.00000
train epoch 100 avg loss: 7.90395 (A-MSE: 6.85893) avg lploss: 0.00000
==> val epoch 100 avg loss: 9.19309 (A-MSE: 8.11427) avg lploss: 0.00000
==> test epoch 100 avg loss: 8.78467 (A-MSE: 7.72787) avg lploss: 0.00000
*** Best Val Loss: 9.19309 	 Best Test Loss: 8.78467 	 Best epoch 100
Validation loss decreased (9.290327 --> 9.193095).  Saving model ...
train epoch 101 avg loss: 7.66636 (A-MSE: 6.65337) avg lploss: 0.00000
train epoch 102 avg loss: 7.67516 (A-MSE: 6.67124) avg lploss: 0.00000
train epoch 103 avg loss: 7.66100 (A-MSE: 6.63915) avg lploss: 0.00000
train epoch 104 avg loss: 7.53500 (A-MSE: 6.52701) avg lploss: 0.00000
train epoch 105 avg loss: 7.64009 (A-MSE: 6.65923) avg lploss: 0.00000
==> val epoch 105 avg loss: 8.49752 (A-MSE: 7.40164) avg lploss: 0.00000
==> test epoch 105 avg loss: 8.09780 (A-MSE: 7.01274) avg lploss: 0.00000
*** Best Val Loss: 8.49752 	 Best Test Loss: 8.09780 	 Best epoch 105
Validation loss decreased (9.193095 --> 8.497522).  Saving model ...
train epoch 106 avg loss: 7.31530 (A-MSE: 6.34709) avg lploss: 0.00000
train epoch 107 avg loss: 7.20609 (A-MSE: 6.26504) avg lploss: 0.00000
train epoch 108 avg loss: 7.54753 (A-MSE: 6.56684) avg lploss: 0.00000
train epoch 109 avg loss: 7.75697 (A-MSE: 6.76376) avg lploss: 0.00000
train epoch 110 avg loss: 7.74725 (A-MSE: 6.74444) avg lploss: 0.00000
==> val epoch 110 avg loss: 9.09321 (A-MSE: 7.83983) avg lploss: 0.00000
==> test epoch 110 avg loss: 8.88577 (A-MSE: 7.65217) avg lploss: 0.00000
*** Best Val Loss: 8.49752 	 Best Test Loss: 8.09780 	 Best epoch 105
EarlyStopping counter: 1 out of 50
train epoch 111 avg loss: 7.62246 (A-MSE: 6.62883) avg lploss: 0.00000
train epoch 112 avg loss: 7.37407 (A-MSE: 6.41131) avg lploss: 0.00000
train epoch 113 avg loss: 7.08019 (A-MSE: 6.17380) avg lploss: 0.00000
train epoch 114 avg loss: 7.13990 (A-MSE: 6.21110) avg lploss: 0.00000
train epoch 115 avg loss: 7.08230 (A-MSE: 6.16566) avg lploss: 0.00000
==> val epoch 115 avg loss: 8.78515 (A-MSE: 7.69938) avg lploss: 0.00000
==> test epoch 115 avg loss: 8.37064 (A-MSE: 7.29406) avg lploss: 0.00000
*** Best Val Loss: 8.49752 	 Best Test Loss: 8.09780 	 Best epoch 105
EarlyStopping counter: 2 out of 50
train epoch 116 avg loss: 7.01774 (A-MSE: 6.11553) avg lploss: 0.00000
train epoch 117 avg loss: 6.99137 (A-MSE: 6.10085) avg lploss: 0.00000
train epoch 118 avg loss: 7.00127 (A-MSE: 6.10996) avg lploss: 0.00000
train epoch 119 avg loss: 7.09444 (A-MSE: 6.18429) avg lploss: 0.00000
train epoch 120 avg loss: 7.50528 (A-MSE: 6.55611) avg lploss: 0.00000
==> val epoch 120 avg loss: 8.80459 (A-MSE: 7.80464) avg lploss: 0.00000
==> test epoch 120 avg loss: 8.41577 (A-MSE: 7.41246) avg lploss: 0.00000
*** Best Val Loss: 8.49752 	 Best Test Loss: 8.09780 	 Best epoch 105
EarlyStopping counter: 3 out of 50
train epoch 121 avg loss: 7.35557 (A-MSE: 6.41854) avg lploss: 0.00000
train epoch 122 avg loss: 7.04780 (A-MSE: 6.14537) avg lploss: 0.00000
train epoch 123 avg loss: 6.92999 (A-MSE: 6.03248) avg lploss: 0.00000
train epoch 124 avg loss: 7.40484 (A-MSE: 6.47934) avg lploss: 0.00000
train epoch 125 avg loss: 6.67190 (A-MSE: 5.80985) avg lploss: 0.00000
==> val epoch 125 avg loss: 7.57650 (A-MSE: 6.62420) avg lploss: 0.00000
==> test epoch 125 avg loss: 7.24140 (A-MSE: 6.29563) avg lploss: 0.00000
*** Best Val Loss: 7.57650 	 Best Test Loss: 7.24140 	 Best epoch 125
Validation loss decreased (8.497522 --> 7.576495).  Saving model ...
train epoch 126 avg loss: 6.51631 (A-MSE: 5.68680) avg lploss: 0.00000
train epoch 127 avg loss: 6.62641 (A-MSE: 5.79754) avg lploss: 0.00000
train epoch 128 avg loss: 6.76011 (A-MSE: 5.89340) avg lploss: 0.00000
train epoch 129 avg loss: 6.71645 (A-MSE: 5.86891) avg lploss: 0.00000
train epoch 130 avg loss: 6.47828 (A-MSE: 5.65664) avg lploss: 0.00000
==> val epoch 130 avg loss: 7.69813 (A-MSE: 6.77488) avg lploss: 0.00000
==> test epoch 130 avg loss: 7.54489 (A-MSE: 6.61438) avg lploss: 0.00000
*** Best Val Loss: 7.57650 	 Best Test Loss: 7.24140 	 Best epoch 125
EarlyStopping counter: 1 out of 50
train epoch 131 avg loss: 6.90332 (A-MSE: 6.04766) avg lploss: 0.00000
train epoch 132 avg loss: 6.75972 (A-MSE: 5.90316) avg lploss: 0.00000
train epoch 133 avg loss: 6.82966 (A-MSE: 5.97395) avg lploss: 0.00000
train epoch 134 avg loss: 7.17689 (A-MSE: 6.29982) avg lploss: 0.00000
train epoch 135 avg loss: 6.57178 (A-MSE: 5.74936) avg lploss: 0.00000
==> val epoch 135 avg loss: 7.59883 (A-MSE: 6.63603) avg lploss: 0.00000
==> test epoch 135 avg loss: 7.31776 (A-MSE: 6.35805) avg lploss: 0.00000
*** Best Val Loss: 7.57650 	 Best Test Loss: 7.24140 	 Best epoch 125
EarlyStopping counter: 2 out of 50
train epoch 136 avg loss: 6.40644 (A-MSE: 5.59603) avg lploss: 0.00000
train epoch 137 avg loss: 6.16288 (A-MSE: 5.38766) avg lploss: 0.00000
train epoch 138 avg loss: 6.31542 (A-MSE: 5.51800) avg lploss: 0.00000
train epoch 139 avg loss: 6.77468 (A-MSE: 5.93977) avg lploss: 0.00000
train epoch 140 avg loss: 6.81440 (A-MSE: 5.97171) avg lploss: 0.00000
==> val epoch 140 avg loss: 8.91729 (A-MSE: 7.87791) avg lploss: 0.00000
==> test epoch 140 avg loss: 8.73363 (A-MSE: 7.67327) avg lploss: 0.00000
*** Best Val Loss: 7.57650 	 Best Test Loss: 7.24140 	 Best epoch 125
EarlyStopping counter: 3 out of 50
train epoch 141 avg loss: 6.51921 (A-MSE: 5.70542) avg lploss: 0.00000
train epoch 142 avg loss: 6.33072 (A-MSE: 5.54935) avg lploss: 0.00000
train epoch 143 avg loss: 6.21658 (A-MSE: 5.44312) avg lploss: 0.00000
train epoch 144 avg loss: 6.23122 (A-MSE: 5.44719) avg lploss: 0.00000
train epoch 145 avg loss: 6.19393 (A-MSE: 5.42873) avg lploss: 0.00000
==> val epoch 145 avg loss: 7.86545 (A-MSE: 6.97668) avg lploss: 0.00000
==> test epoch 145 avg loss: 7.32892 (A-MSE: 6.44823) avg lploss: 0.00000
*** Best Val Loss: 7.57650 	 Best Test Loss: 7.24140 	 Best epoch 125
EarlyStopping counter: 4 out of 50
train epoch 146 avg loss: 6.22080 (A-MSE: 5.43566) avg lploss: 0.00000
train epoch 147 avg loss: 5.97492 (A-MSE: 5.23427) avg lploss: 0.00000
train epoch 148 avg loss: 5.85478 (A-MSE: 5.12337) avg lploss: 0.00000
train epoch 149 avg loss: 5.81057 (A-MSE: 5.07801) avg lploss: 0.00000
train epoch 150 avg loss: 5.75046 (A-MSE: 5.03998) avg lploss: 0.00000
==> val epoch 150 avg loss: 6.80975 (A-MSE: 5.97128) avg lploss: 0.00000
==> test epoch 150 avg loss: 6.58497 (A-MSE: 5.73982) avg lploss: 0.00000
*** Best Val Loss: 6.80975 	 Best Test Loss: 6.58497 	 Best epoch 150
Validation loss decreased (7.576495 --> 6.809746).  Saving model ...
train epoch 151 avg loss: 5.85795 (A-MSE: 5.13124) avg lploss: 0.00000
train epoch 152 avg loss: 5.71916 (A-MSE: 5.00698) avg lploss: 0.00000
train epoch 153 avg loss: 5.64450 (A-MSE: 4.94711) avg lploss: 0.00000
train epoch 154 avg loss: 5.77904 (A-MSE: 5.05904) avg lploss: 0.00000
train epoch 155 avg loss: 5.67478 (A-MSE: 4.97714) avg lploss: 0.00000
==> val epoch 155 avg loss: 6.79760 (A-MSE: 6.02575) avg lploss: 0.00000
==> test epoch 155 avg loss: 6.62228 (A-MSE: 5.83622) avg lploss: 0.00000
*** Best Val Loss: 6.79760 	 Best Test Loss: 6.62228 	 Best epoch 155
Validation loss decreased (6.809746 --> 6.797599).  Saving model ...
train epoch 156 avg loss: 5.62275 (A-MSE: 4.93521) avg lploss: 0.00000
train epoch 157 avg loss: 5.98108 (A-MSE: 5.25199) avg lploss: 0.00000
train epoch 158 avg loss: 6.00725 (A-MSE: 5.28637) avg lploss: 0.00000
train epoch 159 avg loss: 5.75487 (A-MSE: 5.06016) avg lploss: 0.00000
train epoch 160 avg loss: 5.62339 (A-MSE: 4.93403) avg lploss: 0.00000
==> val epoch 160 avg loss: 6.95329 (A-MSE: 6.15117) avg lploss: 0.00000
==> test epoch 160 avg loss: 6.63230 (A-MSE: 5.83144) avg lploss: 0.00000
*** Best Val Loss: 6.79760 	 Best Test Loss: 6.62228 	 Best epoch 155
EarlyStopping counter: 1 out of 50
train epoch 161 avg loss: 5.80216 (A-MSE: 5.11870) avg lploss: 0.00000
train epoch 162 avg loss: 5.45319 (A-MSE: 4.78272) avg lploss: 0.00000
train epoch 163 avg loss: 5.19222 (A-MSE: 4.56212) avg lploss: 0.00000
train epoch 164 avg loss: 5.29963 (A-MSE: 4.66082) avg lploss: 0.00000
train epoch 165 avg loss: 5.26629 (A-MSE: 4.62715) avg lploss: 0.00000
==> val epoch 165 avg loss: 7.02728 (A-MSE: 6.18396) avg lploss: 0.00000
==> test epoch 165 avg loss: 7.11360 (A-MSE: 6.23255) avg lploss: 0.00000
*** Best Val Loss: 6.79760 	 Best Test Loss: 6.62228 	 Best epoch 155
EarlyStopping counter: 2 out of 50
train epoch 166 avg loss: 5.16445 (A-MSE: 4.53703) avg lploss: 0.00000
train epoch 167 avg loss: 5.19454 (A-MSE: 4.57632) avg lploss: 0.00000
train epoch 168 avg loss: 5.06791 (A-MSE: 4.44538) avg lploss: 0.00000
train epoch 169 avg loss: 5.29459 (A-MSE: 4.67131) avg lploss: 0.00000
train epoch 170 avg loss: 5.02343 (A-MSE: 4.42683) avg lploss: 0.00000
==> val epoch 170 avg loss: 6.54004 (A-MSE: 5.77650) avg lploss: 0.00000
==> test epoch 170 avg loss: 6.52880 (A-MSE: 5.72596) avg lploss: 0.00000
*** Best Val Loss: 6.54004 	 Best Test Loss: 6.52880 	 Best epoch 170
Validation loss decreased (6.797599 --> 6.540040).  Saving model ...
train epoch 171 avg loss: 5.07652 (A-MSE: 4.47540) avg lploss: 0.00000
train epoch 172 avg loss: 4.91510 (A-MSE: 4.31498) avg lploss: 0.00000
train epoch 173 avg loss: 4.77426 (A-MSE: 4.20869) avg lploss: 0.00000
train epoch 174 avg loss: 5.01791 (A-MSE: 4.41446) avg lploss: 0.00000
train epoch 175 avg loss: 4.83825 (A-MSE: 4.27317) avg lploss: 0.00000
==> val epoch 175 avg loss: 6.80658 (A-MSE: 6.00745) avg lploss: 0.00000
==> test epoch 175 avg loss: 6.65726 (A-MSE: 5.84105) avg lploss: 0.00000
*** Best Val Loss: 6.54004 	 Best Test Loss: 6.52880 	 Best epoch 170
EarlyStopping counter: 1 out of 50
train epoch 176 avg loss: 4.68924 (A-MSE: 4.12235) avg lploss: 0.00000
train epoch 177 avg loss: 4.59263 (A-MSE: 4.03908) avg lploss: 0.00000
train epoch 178 avg loss: 4.79566 (A-MSE: 4.25302) avg lploss: 0.00000
train epoch 179 avg loss: 4.75359 (A-MSE: 4.18813) avg lploss: 0.00000
train epoch 180 avg loss: 4.69766 (A-MSE: 4.15289) avg lploss: 0.00000
==> val epoch 180 avg loss: 7.25413 (A-MSE: 6.42006) avg lploss: 0.00000
==> test epoch 180 avg loss: 7.15651 (A-MSE: 6.29366) avg lploss: 0.00000
*** Best Val Loss: 6.54004 	 Best Test Loss: 6.52880 	 Best epoch 170
EarlyStopping counter: 2 out of 50
train epoch 181 avg loss: 5.01171 (A-MSE: 4.43262) avg lploss: 0.00000
train epoch 182 avg loss: 4.52388 (A-MSE: 4.01605) avg lploss: 0.00000
train epoch 183 avg loss: 4.42591 (A-MSE: 3.91466) avg lploss: 0.00000
train epoch 184 avg loss: 4.50878 (A-MSE: 3.98457) avg lploss: 0.00000
train epoch 185 avg loss: 4.63684 (A-MSE: 4.11386) avg lploss: 0.00000
==> val epoch 185 avg loss: 5.65789 (A-MSE: 5.02937) avg lploss: 0.00000
==> test epoch 185 avg loss: 5.47971 (A-MSE: 4.85041) avg lploss: 0.00000
*** Best Val Loss: 5.65789 	 Best Test Loss: 5.47971 	 Best epoch 185
Validation loss decreased (6.540040 --> 5.657894).  Saving model ...
train epoch 186 avg loss: 4.57516 (A-MSE: 4.05411) avg lploss: 0.00000
train epoch 187 avg loss: 4.40093 (A-MSE: 3.89345) avg lploss: 0.00000
train epoch 188 avg loss: 4.34365 (A-MSE: 3.85491) avg lploss: 0.00000
train epoch 189 avg loss: 4.53823 (A-MSE: 4.04293) avg lploss: 0.00000
train epoch 190 avg loss: 4.49335 (A-MSE: 3.98658) avg lploss: 0.00000
==> val epoch 190 avg loss: 5.53067 (A-MSE: 4.87034) avg lploss: 0.00000
==> test epoch 190 avg loss: 5.39817 (A-MSE: 4.74497) avg lploss: 0.00000
*** Best Val Loss: 5.53067 	 Best Test Loss: 5.39817 	 Best epoch 190
Validation loss decreased (5.657894 --> 5.530670).  Saving model ...
train epoch 191 avg loss: 4.41289 (A-MSE: 3.92263) avg lploss: 0.00000
train epoch 192 avg loss: 4.14944 (A-MSE: 3.67036) avg lploss: 0.00000
train epoch 193 avg loss: 3.92638 (A-MSE: 3.47603) avg lploss: 0.00000
train epoch 194 avg loss: 3.90302 (A-MSE: 3.45974) avg lploss: 0.00000
train epoch 195 avg loss: 4.08529 (A-MSE: 3.63154) avg lploss: 0.00000
==> val epoch 195 avg loss: 6.63208 (A-MSE: 5.94007) avg lploss: 0.00000
==> test epoch 195 avg loss: 6.60506 (A-MSE: 5.87711) avg lploss: 0.00000
*** Best Val Loss: 5.53067 	 Best Test Loss: 5.39817 	 Best epoch 190
EarlyStopping counter: 1 out of 50
train epoch 196 avg loss: 4.20604 (A-MSE: 3.74548) avg lploss: 0.00000
train epoch 197 avg loss: 4.57390 (A-MSE: 4.07680) avg lploss: 0.00000
train epoch 198 avg loss: 4.15064 (A-MSE: 3.69811) avg lploss: 0.00000
train epoch 199 avg loss: 3.88453 (A-MSE: 3.44731) avg lploss: 0.00000
train epoch 200 avg loss: 3.61064 (A-MSE: 3.20061) avg lploss: 0.00000
==> val epoch 200 avg loss: 4.71000 (A-MSE: 4.16766) avg lploss: 0.00000
==> test epoch 200 avg loss: 4.66966 (A-MSE: 4.11964) avg lploss: 0.00000
*** Best Val Loss: 4.71000 	 Best Test Loss: 4.66966 	 Best epoch 200
Validation loss decreased (5.530670 --> 4.710000).  Saving model ...
train epoch 201 avg loss: 3.48134 (A-MSE: 3.08329) avg lploss: 0.00000
train epoch 202 avg loss: 3.63740 (A-MSE: 3.23459) avg lploss: 0.00000
train epoch 203 avg loss: 3.85391 (A-MSE: 3.42182) avg lploss: 0.00000
train epoch 204 avg loss: 3.66520 (A-MSE: 3.26633) avg lploss: 0.00000
train epoch 205 avg loss: 3.79772 (A-MSE: 3.38023) avg lploss: 0.00000
==> val epoch 205 avg loss: 5.28494 (A-MSE: 4.69266) avg lploss: 0.00000
==> test epoch 205 avg loss: 5.32045 (A-MSE: 4.70639) avg lploss: 0.00000
*** Best Val Loss: 4.71000 	 Best Test Loss: 4.66966 	 Best epoch 200
EarlyStopping counter: 1 out of 50
train epoch 206 avg loss: 3.54877 (A-MSE: 3.14337) avg lploss: 0.00000
train epoch 207 avg loss: 3.43102 (A-MSE: 3.03946) avg lploss: 0.00000
train epoch 208 avg loss: 3.32091 (A-MSE: 2.94221) avg lploss: 0.00000
train epoch 209 avg loss: 3.30908 (A-MSE: 2.92565) avg lploss: 0.00000
train epoch 210 avg loss: 3.25982 (A-MSE: 2.88807) avg lploss: 0.00000
==> val epoch 210 avg loss: 4.25939 (A-MSE: 3.80822) avg lploss: 0.00000
==> test epoch 210 avg loss: 4.38627 (A-MSE: 3.91871) avg lploss: 0.00000
*** Best Val Loss: 4.25939 	 Best Test Loss: 4.38627 	 Best epoch 210
Validation loss decreased (4.710000 --> 4.259393).  Saving model ...
train epoch 211 avg loss: 3.27667 (A-MSE: 2.91138) avg lploss: 0.00000
train epoch 212 avg loss: 3.42441 (A-MSE: 3.04532) avg lploss: 0.00000
train epoch 213 avg loss: 3.55478 (A-MSE: 3.16446) avg lploss: 0.00000
train epoch 214 avg loss: 4.04231 (A-MSE: 3.61873) avg lploss: 0.00000
train epoch 215 avg loss: 3.50847 (A-MSE: 3.12377) avg lploss: 0.00000
==> val epoch 215 avg loss: 4.47082 (A-MSE: 3.95966) avg lploss: 0.00000
==> test epoch 215 avg loss: 4.46228 (A-MSE: 3.94524) avg lploss: 0.00000
*** Best Val Loss: 4.25939 	 Best Test Loss: 4.38627 	 Best epoch 210
EarlyStopping counter: 1 out of 50
train epoch 216 avg loss: 3.35461 (A-MSE: 2.96892) avg lploss: 0.00000
train epoch 217 avg loss: 3.20077 (A-MSE: 2.83709) avg lploss: 0.00000
train epoch 218 avg loss: 3.43718 (A-MSE: 3.05968) avg lploss: 0.00000
train epoch 219 avg loss: 3.22442 (A-MSE: 2.86065) avg lploss: 0.00000
train epoch 220 avg loss: 3.07209 (A-MSE: 2.71907) avg lploss: 0.00000
==> val epoch 220 avg loss: 3.98982 (A-MSE: 3.53219) avg lploss: 0.00000
==> test epoch 220 avg loss: 4.07433 (A-MSE: 3.59811) avg lploss: 0.00000
*** Best Val Loss: 3.98982 	 Best Test Loss: 4.07433 	 Best epoch 220
Validation loss decreased (4.259393 --> 3.989816).  Saving model ...
train epoch 221 avg loss: 3.00583 (A-MSE: 2.65912) avg lploss: 0.00000
train epoch 222 avg loss: 3.13345 (A-MSE: 2.76834) avg lploss: 0.00000
train epoch 223 avg loss: 3.18545 (A-MSE: 2.83251) avg lploss: 0.00000
train epoch 224 avg loss: 3.24627 (A-MSE: 2.87939) avg lploss: 0.00000
train epoch 225 avg loss: 3.06875 (A-MSE: 2.71141) avg lploss: 0.00000
==> val epoch 225 avg loss: 4.06878 (A-MSE: 3.61793) avg lploss: 0.00000
==> test epoch 225 avg loss: 3.99175 (A-MSE: 3.53940) avg lploss: 0.00000
*** Best Val Loss: 3.98982 	 Best Test Loss: 4.07433 	 Best epoch 220
EarlyStopping counter: 1 out of 50
train epoch 226 avg loss: 2.96700 (A-MSE: 2.62790) avg lploss: 0.00000
train epoch 227 avg loss: 3.02887 (A-MSE: 2.68303) avg lploss: 0.00000
train epoch 228 avg loss: 3.05045 (A-MSE: 2.71474) avg lploss: 0.00000
train epoch 229 avg loss: 3.03119 (A-MSE: 2.68564) avg lploss: 0.00000
train epoch 230 avg loss: 2.91771 (A-MSE: 2.58210) avg lploss: 0.00000
==> val epoch 230 avg loss: 4.12629 (A-MSE: 3.67093) avg lploss: 0.00000
==> test epoch 230 avg loss: 3.97515 (A-MSE: 3.52418) avg lploss: 0.00000
*** Best Val Loss: 3.98982 	 Best Test Loss: 4.07433 	 Best epoch 220
EarlyStopping counter: 2 out of 50
train epoch 231 avg loss: 2.95145 (A-MSE: 2.62164) avg lploss: 0.00000
train epoch 232 avg loss: 3.08630 (A-MSE: 2.75502) avg lploss: 0.00000
train epoch 233 avg loss: 3.27976 (A-MSE: 2.91696) avg lploss: 0.00000
train epoch 234 avg loss: 3.45700 (A-MSE: 3.09263) avg lploss: 0.00000
train epoch 235 avg loss: 3.18140 (A-MSE: 2.81632) avg lploss: 0.00000
==> val epoch 235 avg loss: 3.95727 (A-MSE: 3.50292) avg lploss: 0.00000
==> test epoch 235 avg loss: 4.10422 (A-MSE: 3.64154) avg lploss: 0.00000
*** Best Val Loss: 3.95727 	 Best Test Loss: 4.10422 	 Best epoch 235
Validation loss decreased (3.989816 --> 3.957269).  Saving model ...
train epoch 236 avg loss: 2.95820 (A-MSE: 2.61727) avg lploss: 0.00000
train epoch 237 avg loss: 2.99214 (A-MSE: 2.66537) avg lploss: 0.00000
train epoch 238 avg loss: 3.05193 (A-MSE: 2.71122) avg lploss: 0.00000
train epoch 239 avg loss: 2.94710 (A-MSE: 2.61461) avg lploss: 0.00000
train epoch 240 avg loss: 2.90601 (A-MSE: 2.57397) avg lploss: 0.00000
==> val epoch 240 avg loss: 4.09322 (A-MSE: 3.62974) avg lploss: 0.00000
==> test epoch 240 avg loss: 4.04304 (A-MSE: 3.57364) avg lploss: 0.00000
*** Best Val Loss: 3.95727 	 Best Test Loss: 4.10422 	 Best epoch 235
EarlyStopping counter: 1 out of 50
train epoch 241 avg loss: 2.81082 (A-MSE: 2.47895) avg lploss: 0.00000
train epoch 242 avg loss: 2.86078 (A-MSE: 2.54123) avg lploss: 0.00000
train epoch 243 avg loss: 2.79794 (A-MSE: 2.47327) avg lploss: 0.00000
train epoch 244 avg loss: 2.80721 (A-MSE: 2.49056) avg lploss: 0.00000
train epoch 245 avg loss: 3.12372 (A-MSE: 2.78889) avg lploss: 0.00000
==> val epoch 245 avg loss: 3.95793 (A-MSE: 3.48881) avg lploss: 0.00000
==> test epoch 245 avg loss: 3.89510 (A-MSE: 3.43307) avg lploss: 0.00000
*** Best Val Loss: 3.95727 	 Best Test Loss: 4.10422 	 Best epoch 235
EarlyStopping counter: 2 out of 50
train epoch 246 avg loss: 2.73342 (A-MSE: 2.42260) avg lploss: 0.00000
train epoch 247 avg loss: 2.86592 (A-MSE: 2.53866) avg lploss: 0.00000
train epoch 248 avg loss: 2.74932 (A-MSE: 2.43035) avg lploss: 0.00000
train epoch 249 avg loss: 2.91383 (A-MSE: 2.58493) avg lploss: 0.00000
train epoch 250 avg loss: 2.74932 (A-MSE: 2.44233) avg lploss: 0.00000
==> val epoch 250 avg loss: 3.66573 (A-MSE: 3.25065) avg lploss: 0.00000
==> test epoch 250 avg loss: 3.62401 (A-MSE: 3.22036) avg lploss: 0.00000
*** Best Val Loss: 3.66573 	 Best Test Loss: 3.62401 	 Best epoch 250
Validation loss decreased (3.957269 --> 3.665733).  Saving model ...
train epoch 251 avg loss: 2.71363 (A-MSE: 2.40443) avg lploss: 0.00000
train epoch 252 avg loss: 2.74249 (A-MSE: 2.43617) avg lploss: 0.00000
train epoch 253 avg loss: 2.63131 (A-MSE: 2.33463) avg lploss: 0.00000
train epoch 254 avg loss: 2.79775 (A-MSE: 2.48518) avg lploss: 0.00000
train epoch 255 avg loss: 2.65605 (A-MSE: 2.34485) avg lploss: 0.00000
==> val epoch 255 avg loss: 3.91574 (A-MSE: 3.49150) avg lploss: 0.00000
==> test epoch 255 avg loss: 3.86266 (A-MSE: 3.44009) avg lploss: 0.00000
*** Best Val Loss: 3.66573 	 Best Test Loss: 3.62401 	 Best epoch 250
EarlyStopping counter: 1 out of 50
train epoch 256 avg loss: 2.72291 (A-MSE: 2.42458) avg lploss: 0.00000
train epoch 257 avg loss: 2.82137 (A-MSE: 2.50963) avg lploss: 0.00000
train epoch 258 avg loss: 2.60771 (A-MSE: 2.31988) avg lploss: 0.00000
train epoch 259 avg loss: 2.57059 (A-MSE: 2.28229) avg lploss: 0.00000
train epoch 260 avg loss: 2.64107 (A-MSE: 2.34199) avg lploss: 0.00000
==> val epoch 260 avg loss: 3.55592 (A-MSE: 3.15998) avg lploss: 0.00000
==> test epoch 260 avg loss: 3.71839 (A-MSE: 3.29727) avg lploss: 0.00000
*** Best Val Loss: 3.55592 	 Best Test Loss: 3.71839 	 Best epoch 260
Validation loss decreased (3.665733 --> 3.555924).  Saving model ...
train epoch 261 avg loss: 2.73680 (A-MSE: 2.43525) avg lploss: 0.00000
train epoch 262 avg loss: 2.76761 (A-MSE: 2.46355) avg lploss: 0.00000
train epoch 263 avg loss: 2.51767 (A-MSE: 2.23250) avg lploss: 0.00000
train epoch 264 avg loss: 2.70148 (A-MSE: 2.41187) avg lploss: 0.00000
train epoch 265 avg loss: 2.99359 (A-MSE: 2.67935) avg lploss: 0.00000
==> val epoch 265 avg loss: 4.07834 (A-MSE: 3.67529) avg lploss: 0.00000
==> test epoch 265 avg loss: 4.06316 (A-MSE: 3.66250) avg lploss: 0.00000
*** Best Val Loss: 3.55592 	 Best Test Loss: 3.71839 	 Best epoch 260
EarlyStopping counter: 1 out of 50
train epoch 266 avg loss: 2.77770 (A-MSE: 2.46857) avg lploss: 0.00000
train epoch 267 avg loss: 2.61969 (A-MSE: 2.32605) avg lploss: 0.00000
train epoch 268 avg loss: 2.56727 (A-MSE: 2.28134) avg lploss: 0.00000
train epoch 269 avg loss: 2.44954 (A-MSE: 2.16884) avg lploss: 0.00000
train epoch 270 avg loss: 2.57620 (A-MSE: 2.28475) avg lploss: 0.00000
==> val epoch 270 avg loss: 3.61999 (A-MSE: 3.21500) avg lploss: 0.00000
==> test epoch 270 avg loss: 3.51466 (A-MSE: 3.11219) avg lploss: 0.00000
*** Best Val Loss: 3.55592 	 Best Test Loss: 3.71839 	 Best epoch 260
EarlyStopping counter: 2 out of 50
train epoch 271 avg loss: 2.43546 (A-MSE: 2.15842) avg lploss: 0.00000
train epoch 272 avg loss: 2.49212 (A-MSE: 2.21610) avg lploss: 0.00000
train epoch 273 avg loss: 2.58440 (A-MSE: 2.30221) avg lploss: 0.00000
train epoch 274 avg loss: 2.40536 (A-MSE: 2.13823) avg lploss: 0.00000
train epoch 275 avg loss: 2.50860 (A-MSE: 2.22826) avg lploss: 0.00000
==> val epoch 275 avg loss: 3.58845 (A-MSE: 3.20888) avg lploss: 0.00000
==> test epoch 275 avg loss: 3.58468 (A-MSE: 3.20632) avg lploss: 0.00000
*** Best Val Loss: 3.55592 	 Best Test Loss: 3.71839 	 Best epoch 260
EarlyStopping counter: 3 out of 50
train epoch 276 avg loss: 2.38189 (A-MSE: 2.11589) avg lploss: 0.00000
train epoch 277 avg loss: 2.31302 (A-MSE: 2.04905) avg lploss: 0.00000
train epoch 278 avg loss: 2.40286 (A-MSE: 2.13815) avg lploss: 0.00000
train epoch 279 avg loss: 2.49578 (A-MSE: 2.22327) avg lploss: 0.00000
train epoch 280 avg loss: 2.31144 (A-MSE: 2.05368) avg lploss: 0.00000
==> val epoch 280 avg loss: 3.32774 (A-MSE: 2.94568) avg lploss: 0.00000
==> test epoch 280 avg loss: 3.50490 (A-MSE: 3.09847) avg lploss: 0.00000
*** Best Val Loss: 3.32774 	 Best Test Loss: 3.50490 	 Best epoch 280
Validation loss decreased (3.555924 --> 3.327743).  Saving model ...
train epoch 281 avg loss: 2.35925 (A-MSE: 2.10104) avg lploss: 0.00000
train epoch 282 avg loss: 2.28543 (A-MSE: 2.02272) avg lploss: 0.00000
train epoch 283 avg loss: 2.28562 (A-MSE: 2.02480) avg lploss: 0.00000
train epoch 284 avg loss: 2.31003 (A-MSE: 2.05117) avg lploss: 0.00000
train epoch 285 avg loss: 2.36357 (A-MSE: 2.09513) avg lploss: 0.00000
==> val epoch 285 avg loss: 3.20951 (A-MSE: 2.92680) avg lploss: 0.00000
==> test epoch 285 avg loss: 3.26458 (A-MSE: 2.98035) avg lploss: 0.00000
*** Best Val Loss: 3.20951 	 Best Test Loss: 3.26458 	 Best epoch 285
Validation loss decreased (3.327743 --> 3.209505).  Saving model ...
train epoch 286 avg loss: 2.21444 (A-MSE: 1.97075) avg lploss: 0.00000
train epoch 287 avg loss: 2.30349 (A-MSE: 2.04414) avg lploss: 0.00000
train epoch 288 avg loss: 2.46625 (A-MSE: 2.19671) avg lploss: 0.00000
train epoch 289 avg loss: 2.45475 (A-MSE: 2.18220) avg lploss: 0.00000
train epoch 290 avg loss: 2.36121 (A-MSE: 2.09907) avg lploss: 0.00000
==> val epoch 290 avg loss: 3.41176 (A-MSE: 3.03897) avg lploss: 0.00000
==> test epoch 290 avg loss: 3.38953 (A-MSE: 3.01882) avg lploss: 0.00000
*** Best Val Loss: 3.20951 	 Best Test Loss: 3.26458 	 Best epoch 285
EarlyStopping counter: 1 out of 50
train epoch 291 avg loss: 2.35667 (A-MSE: 2.08741) avg lploss: 0.00000
train epoch 292 avg loss: 2.42420 (A-MSE: 2.16025) avg lploss: 0.00000
train epoch 293 avg loss: 2.27845 (A-MSE: 2.02105) avg lploss: 0.00000
train epoch 294 avg loss: 2.36851 (A-MSE: 2.11284) avg lploss: 0.00000
train epoch 295 avg loss: 2.14382 (A-MSE: 1.90574) avg lploss: 0.00000
==> val epoch 295 avg loss: 3.28983 (A-MSE: 2.95441) avg lploss: 0.00000
==> test epoch 295 avg loss: 3.36591 (A-MSE: 3.01890) avg lploss: 0.00000
*** Best Val Loss: 3.20951 	 Best Test Loss: 3.26458 	 Best epoch 285
EarlyStopping counter: 2 out of 50
train epoch 296 avg loss: 2.31032 (A-MSE: 2.05609) avg lploss: 0.00000
train epoch 297 avg loss: 2.22337 (A-MSE: 1.97498) avg lploss: 0.00000
train epoch 298 avg loss: 2.13910 (A-MSE: 1.90026) avg lploss: 0.00000
train epoch 299 avg loss: 2.11878 (A-MSE: 1.88261) avg lploss: 0.00000
train epoch 300 avg loss: 2.20425 (A-MSE: 1.96375) avg lploss: 0.00000
==> val epoch 300 avg loss: 3.12265 (A-MSE: 2.80170) avg lploss: 0.00000
==> test epoch 300 avg loss: 3.16584 (A-MSE: 2.82878) avg lploss: 0.00000
*** Best Val Loss: 3.12265 	 Best Test Loss: 3.16584 	 Best epoch 300
Validation loss decreased (3.209505 --> 3.122646).  Saving model ...
train epoch 301 avg loss: 2.18796 (A-MSE: 1.94207) avg lploss: 0.00000
train epoch 302 avg loss: 2.33668 (A-MSE: 2.07397) avg lploss: 0.00000
train epoch 303 avg loss: 2.32114 (A-MSE: 2.06950) avg lploss: 0.00000
train epoch 304 avg loss: 2.14293 (A-MSE: 1.90119) avg lploss: 0.00000
train epoch 305 avg loss: 2.33239 (A-MSE: 2.07321) avg lploss: 0.00000
==> val epoch 305 avg loss: 3.84508 (A-MSE: 3.43376) avg lploss: 0.00000
==> test epoch 305 avg loss: 3.95759 (A-MSE: 3.53439) avg lploss: 0.00000
*** Best Val Loss: 3.12265 	 Best Test Loss: 3.16584 	 Best epoch 300
EarlyStopping counter: 1 out of 50
train epoch 306 avg loss: 2.20244 (A-MSE: 1.96224) avg lploss: 0.00000
train epoch 307 avg loss: 2.14355 (A-MSE: 1.90572) avg lploss: 0.00000
train epoch 308 avg loss: 2.26846 (A-MSE: 2.02503) avg lploss: 0.00000
train epoch 309 avg loss: 2.08713 (A-MSE: 1.84543) avg lploss: 0.00000
train epoch 310 avg loss: 2.25414 (A-MSE: 2.01485) avg lploss: 0.00000
==> val epoch 310 avg loss: 3.11376 (A-MSE: 2.78682) avg lploss: 0.00000
==> test epoch 310 avg loss: 3.17651 (A-MSE: 2.85523) avg lploss: 0.00000
*** Best Val Loss: 3.11376 	 Best Test Loss: 3.17651 	 Best epoch 310
Validation loss decreased (3.122646 --> 3.113760).  Saving model ...
train epoch 311 avg loss: 2.16339 (A-MSE: 1.92847) avg lploss: 0.00000
train epoch 312 avg loss: 2.13475 (A-MSE: 1.89858) avg lploss: 0.00000
train epoch 313 avg loss: 2.40901 (A-MSE: 2.14982) avg lploss: 0.00000
train epoch 314 avg loss: 2.16124 (A-MSE: 1.92622) avg lploss: 0.00000
train epoch 315 avg loss: 2.03354 (A-MSE: 1.80121) avg lploss: 0.00000
==> val epoch 315 avg loss: 3.41693 (A-MSE: 3.03589) avg lploss: 0.00000
==> test epoch 315 avg loss: 3.55499 (A-MSE: 3.14850) avg lploss: 0.00000
*** Best Val Loss: 3.11376 	 Best Test Loss: 3.17651 	 Best epoch 310
EarlyStopping counter: 1 out of 50
train epoch 316 avg loss: 2.06497 (A-MSE: 1.83236) avg lploss: 0.00000
train epoch 317 avg loss: 2.26904 (A-MSE: 2.01681) avg lploss: 0.00000
train epoch 318 avg loss: 2.13313 (A-MSE: 1.89780) avg lploss: 0.00000
train epoch 319 avg loss: 2.07251 (A-MSE: 1.84247) avg lploss: 0.00000
train epoch 320 avg loss: 2.09687 (A-MSE: 1.87214) avg lploss: 0.00000
==> val epoch 320 avg loss: 2.72256 (A-MSE: 2.43037) avg lploss: 0.00000
==> test epoch 320 avg loss: 2.76078 (A-MSE: 2.46577) avg lploss: 0.00000
*** Best Val Loss: 2.72256 	 Best Test Loss: 2.76078 	 Best epoch 320
Validation loss decreased (3.113760 --> 2.722556).  Saving model ...
train epoch 321 avg loss: 1.96393 (A-MSE: 1.74340) avg lploss: 0.00000
train epoch 322 avg loss: 1.97779 (A-MSE: 1.75790) avg lploss: 0.00000
train epoch 323 avg loss: 1.86308 (A-MSE: 1.65442) avg lploss: 0.00000
train epoch 324 avg loss: 1.96863 (A-MSE: 1.74678) avg lploss: 0.00000
train epoch 325 avg loss: 2.10857 (A-MSE: 1.88010) avg lploss: 0.00000
==> val epoch 325 avg loss: 2.74729 (A-MSE: 2.46159) avg lploss: 0.00000
==> test epoch 325 avg loss: 2.77744 (A-MSE: 2.47444) avg lploss: 0.00000
*** Best Val Loss: 2.72256 	 Best Test Loss: 2.76078 	 Best epoch 320
EarlyStopping counter: 1 out of 50
train epoch 326 avg loss: 1.87795 (A-MSE: 1.66996) avg lploss: 0.00000
train epoch 327 avg loss: 1.95653 (A-MSE: 1.74371) avg lploss: 0.00000
train epoch 328 avg loss: 1.94399 (A-MSE: 1.72549) avg lploss: 0.00000
train epoch 329 avg loss: 1.81035 (A-MSE: 1.60873) avg lploss: 0.00000
train epoch 330 avg loss: 1.78428 (A-MSE: 1.59155) avg lploss: 0.00000
==> val epoch 330 avg loss: 3.11089 (A-MSE: 2.76125) avg lploss: 0.00000
==> test epoch 330 avg loss: 3.05182 (A-MSE: 2.70047) avg lploss: 0.00000
*** Best Val Loss: 2.72256 	 Best Test Loss: 2.76078 	 Best epoch 320
EarlyStopping counter: 2 out of 50
train epoch 331 avg loss: 1.87847 (A-MSE: 1.67194) avg lploss: 0.00000
train epoch 332 avg loss: 1.97455 (A-MSE: 1.76537) avg lploss: 0.00000
train epoch 333 avg loss: 2.01211 (A-MSE: 1.78600) avg lploss: 0.00000
train epoch 334 avg loss: 1.88389 (A-MSE: 1.67364) avg lploss: 0.00000
train epoch 335 avg loss: 1.92217 (A-MSE: 1.70988) avg lploss: 0.00000
==> val epoch 335 avg loss: 2.79778 (A-MSE: 2.50229) avg lploss: 0.00000
==> test epoch 335 avg loss: 2.88677 (A-MSE: 2.57822) avg lploss: 0.00000
*** Best Val Loss: 2.72256 	 Best Test Loss: 2.76078 	 Best epoch 320
EarlyStopping counter: 3 out of 50
train epoch 336 avg loss: 1.84329 (A-MSE: 1.64109) avg lploss: 0.00000
train epoch 337 avg loss: 1.85830 (A-MSE: 1.66512) avg lploss: 0.00000
train epoch 338 avg loss: 2.10950 (A-MSE: 1.88050) avg lploss: 0.00000
train epoch 339 avg loss: 1.87501 (A-MSE: 1.66972) avg lploss: 0.00000
train epoch 340 avg loss: 1.70904 (A-MSE: 1.51943) avg lploss: 0.00000
==> val epoch 340 avg loss: 2.89394 (A-MSE: 2.56992) avg lploss: 0.00000
==> test epoch 340 avg loss: 2.93763 (A-MSE: 2.60207) avg lploss: 0.00000
*** Best Val Loss: 2.72256 	 Best Test Loss: 2.76078 	 Best epoch 320
EarlyStopping counter: 4 out of 50
train epoch 341 avg loss: 1.66941 (A-MSE: 1.48323) avg lploss: 0.00000
train epoch 342 avg loss: 1.79549 (A-MSE: 1.60429) avg lploss: 0.00000
train epoch 343 avg loss: 1.61643 (A-MSE: 1.43213) avg lploss: 0.00000
train epoch 344 avg loss: 1.77275 (A-MSE: 1.58418) avg lploss: 0.00000
train epoch 345 avg loss: 2.01627 (A-MSE: 1.80775) avg lploss: 0.00000
==> val epoch 345 avg loss: 2.78940 (A-MSE: 2.50715) avg lploss: 0.00000
==> test epoch 345 avg loss: 2.81934 (A-MSE: 2.52326) avg lploss: 0.00000
*** Best Val Loss: 2.72256 	 Best Test Loss: 2.76078 	 Best epoch 320
EarlyStopping counter: 5 out of 50
train epoch 346 avg loss: 1.84969 (A-MSE: 1.64779) avg lploss: 0.00000
train epoch 347 avg loss: 1.65559 (A-MSE: 1.47002) avg lploss: 0.00000
train epoch 348 avg loss: 1.85154 (A-MSE: 1.65496) avg lploss: 0.00000
train epoch 349 avg loss: 1.64241 (A-MSE: 1.46259) avg lploss: 0.00000
train epoch 350 avg loss: 1.61193 (A-MSE: 1.43737) avg lploss: 0.00000
==> val epoch 350 avg loss: 2.53789 (A-MSE: 2.27521) avg lploss: 0.00000
==> test epoch 350 avg loss: 2.52998 (A-MSE: 2.27079) avg lploss: 0.00000
*** Best Val Loss: 2.53789 	 Best Test Loss: 2.52998 	 Best epoch 350
Validation loss decreased (2.722556 --> 2.537893).  Saving model ...
train epoch 351 avg loss: 1.65667 (A-MSE: 1.47967) avg lploss: 0.00000
train epoch 352 avg loss: 1.84251 (A-MSE: 1.64868) avg lploss: 0.00000
train epoch 353 avg loss: 1.72367 (A-MSE: 1.53974) avg lploss: 0.00000
train epoch 354 avg loss: 1.70404 (A-MSE: 1.52539) avg lploss: 0.00000
train epoch 355 avg loss: 1.72553 (A-MSE: 1.54346) avg lploss: 0.00000
==> val epoch 355 avg loss: 2.55488 (A-MSE: 2.28215) avg lploss: 0.00000
==> test epoch 355 avg loss: 2.61469 (A-MSE: 2.34039) avg lploss: 0.00000
*** Best Val Loss: 2.53789 	 Best Test Loss: 2.52998 	 Best epoch 350
EarlyStopping counter: 1 out of 50
train epoch 356 avg loss: 1.68641 (A-MSE: 1.51274) avg lploss: 0.00000
train epoch 357 avg loss: 1.58805 (A-MSE: 1.41581) avg lploss: 0.00000
train epoch 358 avg loss: 1.54205 (A-MSE: 1.38264) avg lploss: 0.00000
train epoch 359 avg loss: 1.62267 (A-MSE: 1.45976) avg lploss: 0.00000
train epoch 360 avg loss: 1.50580 (A-MSE: 1.34563) avg lploss: 0.00000
==> val epoch 360 avg loss: 2.40565 (A-MSE: 2.16302) avg lploss: 0.00000
==> test epoch 360 avg loss: 2.47590 (A-MSE: 2.21709) avg lploss: 0.00000
*** Best Val Loss: 2.40565 	 Best Test Loss: 2.47590 	 Best epoch 360
Validation loss decreased (2.537893 --> 2.405648).  Saving model ...
train epoch 361 avg loss: 1.49477 (A-MSE: 1.34037) avg lploss: 0.00000
train epoch 362 avg loss: 1.49738 (A-MSE: 1.33942) avg lploss: 0.00000
train epoch 363 avg loss: 1.55061 (A-MSE: 1.38933) avg lploss: 0.00000
train epoch 364 avg loss: 1.63003 (A-MSE: 1.46049) avg lploss: 0.00000
train epoch 365 avg loss: 1.66569 (A-MSE: 1.49339) avg lploss: 0.00000
==> val epoch 365 avg loss: 2.64397 (A-MSE: 2.35240) avg lploss: 0.00000
==> test epoch 365 avg loss: 2.70387 (A-MSE: 2.39444) avg lploss: 0.00000
*** Best Val Loss: 2.40565 	 Best Test Loss: 2.47590 	 Best epoch 360
EarlyStopping counter: 1 out of 50
train epoch 366 avg loss: 1.65360 (A-MSE: 1.48046) avg lploss: 0.00000
train epoch 367 avg loss: 1.50934 (A-MSE: 1.35454) avg lploss: 0.00000
train epoch 368 avg loss: 1.64494 (A-MSE: 1.46836) avg lploss: 0.00000
train epoch 369 avg loss: 1.69569 (A-MSE: 1.52082) avg lploss: 0.00000
train epoch 370 avg loss: 1.65629 (A-MSE: 1.48402) avg lploss: 0.00000
==> val epoch 370 avg loss: 2.40678 (A-MSE: 2.16837) avg lploss: 0.00000
==> test epoch 370 avg loss: 2.47285 (A-MSE: 2.22894) avg lploss: 0.00000
*** Best Val Loss: 2.40565 	 Best Test Loss: 2.47590 	 Best epoch 360
EarlyStopping counter: 2 out of 50
train epoch 371 avg loss: 1.74998 (A-MSE: 1.56882) avg lploss: 0.00000
train epoch 372 avg loss: 1.79120 (A-MSE: 1.61098) avg lploss: 0.00000
train epoch 373 avg loss: 1.58154 (A-MSE: 1.40886) avg lploss: 0.00000
train epoch 374 avg loss: 1.55860 (A-MSE: 1.39696) avg lploss: 0.00000
train epoch 375 avg loss: 1.71078 (A-MSE: 1.52488) avg lploss: 0.00000
==> val epoch 375 avg loss: 2.52607 (A-MSE: 2.24704) avg lploss: 0.00000
==> test epoch 375 avg loss: 2.59043 (A-MSE: 2.30846) avg lploss: 0.00000
*** Best Val Loss: 2.40565 	 Best Test Loss: 2.47590 	 Best epoch 360
EarlyStopping counter: 3 out of 50
train epoch 376 avg loss: 1.48595 (A-MSE: 1.33263) avg lploss: 0.00000
train epoch 377 avg loss: 1.45324 (A-MSE: 1.30309) avg lploss: 0.00000
train epoch 378 avg loss: 1.45700 (A-MSE: 1.30576) avg lploss: 0.00000
train epoch 379 avg loss: 1.55592 (A-MSE: 1.39212) avg lploss: 0.00000
train epoch 380 avg loss: 1.44522 (A-MSE: 1.29605) avg lploss: 0.00000
==> val epoch 380 avg loss: 2.16167 (A-MSE: 1.93434) avg lploss: 0.00000
==> test epoch 380 avg loss: 2.30704 (A-MSE: 2.05981) avg lploss: 0.00000
*** Best Val Loss: 2.16167 	 Best Test Loss: 2.30704 	 Best epoch 380
Validation loss decreased (2.405648 --> 2.161666).  Saving model ...
train epoch 381 avg loss: 1.42941 (A-MSE: 1.28144) avg lploss: 0.00000
train epoch 382 avg loss: 1.51025 (A-MSE: 1.35155) avg lploss: 0.00000
train epoch 383 avg loss: 1.52289 (A-MSE: 1.36472) avg lploss: 0.00000
train epoch 384 avg loss: 1.44853 (A-MSE: 1.29752) avg lploss: 0.00000
train epoch 385 avg loss: 1.40246 (A-MSE: 1.25778) avg lploss: 0.00000
==> val epoch 385 avg loss: 2.20712 (A-MSE: 1.96360) avg lploss: 0.00000
==> test epoch 385 avg loss: 2.29368 (A-MSE: 2.03051) avg lploss: 0.00000
*** Best Val Loss: 2.16167 	 Best Test Loss: 2.30704 	 Best epoch 380
EarlyStopping counter: 1 out of 50
train epoch 386 avg loss: 1.38673 (A-MSE: 1.24854) avg lploss: 0.00000
train epoch 387 avg loss: 1.47652 (A-MSE: 1.32400) avg lploss: 0.00000
train epoch 388 avg loss: 1.50843 (A-MSE: 1.35473) avg lploss: 0.00000
train epoch 389 avg loss: 1.44621 (A-MSE: 1.30488) avg lploss: 0.00000
train epoch 390 avg loss: 1.36184 (A-MSE: 1.22169) avg lploss: 0.00000
==> val epoch 390 avg loss: 2.11975 (A-MSE: 1.87861) avg lploss: 0.00000
==> test epoch 390 avg loss: 2.11166 (A-MSE: 1.86176) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
Validation loss decreased (2.161666 --> 2.119746).  Saving model ...
train epoch 391 avg loss: 1.24123 (A-MSE: 1.11106) avg lploss: 0.00000
train epoch 392 avg loss: 1.25000 (A-MSE: 1.12678) avg lploss: 0.00000
train epoch 393 avg loss: 1.32385 (A-MSE: 1.18442) avg lploss: 0.00000
train epoch 394 avg loss: 1.36108 (A-MSE: 1.21870) avg lploss: 0.00000
train epoch 395 avg loss: 1.39609 (A-MSE: 1.25178) avg lploss: 0.00000
==> val epoch 395 avg loss: 2.35782 (A-MSE: 2.09604) avg lploss: 0.00000
==> test epoch 395 avg loss: 2.38162 (A-MSE: 2.10745) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 1 out of 50
train epoch 396 avg loss: 1.45623 (A-MSE: 1.30419) avg lploss: 0.00000
train epoch 397 avg loss: 1.49192 (A-MSE: 1.34409) avg lploss: 0.00000
train epoch 398 avg loss: 1.37354 (A-MSE: 1.23272) avg lploss: 0.00000
train epoch 399 avg loss: 1.32183 (A-MSE: 1.18668) avg lploss: 0.00000
train epoch 400 avg loss: 1.26064 (A-MSE: 1.12903) avg lploss: 0.00000
==> val epoch 400 avg loss: 2.36160 (A-MSE: 2.08384) avg lploss: 0.00000
==> test epoch 400 avg loss: 2.39299 (A-MSE: 2.10102) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 2 out of 50
train epoch 401 avg loss: 1.30416 (A-MSE: 1.16727) avg lploss: 0.00000
train epoch 402 avg loss: 1.31566 (A-MSE: 1.17810) avg lploss: 0.00000
train epoch 403 avg loss: 1.33108 (A-MSE: 1.19649) avg lploss: 0.00000
train epoch 404 avg loss: 1.29787 (A-MSE: 1.16512) avg lploss: 0.00000
train epoch 405 avg loss: 1.29687 (A-MSE: 1.16639) avg lploss: 0.00000
==> val epoch 405 avg loss: 2.19380 (A-MSE: 1.93677) avg lploss: 0.00000
==> test epoch 405 avg loss: 2.30729 (A-MSE: 2.02673) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 3 out of 50
train epoch 406 avg loss: 1.26369 (A-MSE: 1.13241) avg lploss: 0.00000
train epoch 407 avg loss: 1.24906 (A-MSE: 1.11575) avg lploss: 0.00000
train epoch 408 avg loss: 1.35154 (A-MSE: 1.21401) avg lploss: 0.00000
train epoch 409 avg loss: 1.31688 (A-MSE: 1.17921) avg lploss: 0.00000
train epoch 410 avg loss: 1.31337 (A-MSE: 1.17615) avg lploss: 0.00000
==> val epoch 410 avg loss: 2.18196 (A-MSE: 1.93077) avg lploss: 0.00000
==> test epoch 410 avg loss: 2.24197 (A-MSE: 1.96281) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 4 out of 50
train epoch 411 avg loss: 1.30127 (A-MSE: 1.16447) avg lploss: 0.00000
train epoch 412 avg loss: 1.35978 (A-MSE: 1.21488) avg lploss: 0.00000
train epoch 413 avg loss: 1.18020 (A-MSE: 1.06230) avg lploss: 0.00000
train epoch 414 avg loss: 1.25263 (A-MSE: 1.12034) avg lploss: 0.00000
train epoch 415 avg loss: 1.33129 (A-MSE: 1.19265) avg lploss: 0.00000
==> val epoch 415 avg loss: 2.29203 (A-MSE: 2.03816) avg lploss: 0.00000
==> test epoch 415 avg loss: 2.29599 (A-MSE: 2.03046) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 5 out of 50
train epoch 416 avg loss: 1.36314 (A-MSE: 1.22698) avg lploss: 0.00000
train epoch 417 avg loss: 1.36474 (A-MSE: 1.22621) avg lploss: 0.00000
train epoch 418 avg loss: 1.24522 (A-MSE: 1.11539) avg lploss: 0.00000
train epoch 419 avg loss: 1.19061 (A-MSE: 1.06651) avg lploss: 0.00000
train epoch 420 avg loss: 1.28470 (A-MSE: 1.15088) avg lploss: 0.00000
==> val epoch 420 avg loss: 2.56430 (A-MSE: 2.25361) avg lploss: 0.00000
==> test epoch 420 avg loss: 2.57062 (A-MSE: 2.24313) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 6 out of 50
train epoch 421 avg loss: 1.22979 (A-MSE: 1.10029) avg lploss: 0.00000
train epoch 422 avg loss: 1.20099 (A-MSE: 1.07237) avg lploss: 0.00000
train epoch 423 avg loss: 1.19400 (A-MSE: 1.06791) avg lploss: 0.00000
train epoch 424 avg loss: 1.15541 (A-MSE: 1.02910) avg lploss: 0.00000
train epoch 425 avg loss: 1.22265 (A-MSE: 1.09611) avg lploss: 0.00000
==> val epoch 425 avg loss: 2.25337 (A-MSE: 1.99727) avg lploss: 0.00000
==> test epoch 425 avg loss: 2.27668 (A-MSE: 2.00412) avg lploss: 0.00000
*** Best Val Loss: 2.11975 	 Best Test Loss: 2.11166 	 Best epoch 390
EarlyStopping counter: 7 out of 50
train epoch 426 avg loss: 1.41952 (A-MSE: 1.27195) avg lploss: 0.00000
train epoch 427 avg loss: 1.24940 (A-MSE: 1.11812) avg lploss: 0.00000
train epoch 428 avg loss: 1.19331 (A-MSE: 1.06851) avg lploss: 0.00000
train epoch 429 avg loss: 1.19097 (A-MSE: 1.06429) avg lploss: 0.00000
train epoch 430 avg loss: 1.24070 (A-MSE: 1.11144) avg lploss: 0.00000
==> val epoch 430 avg loss: 1.98421 (A-MSE: 1.76823) avg lploss: 0.00000
==> test epoch 430 avg loss: 2.07945 (A-MSE: 1.84584) avg lploss: 0.00000
*** Best Val Loss: 1.98421 	 Best Test Loss: 2.07945 	 Best epoch 430
Validation loss decreased (2.119746 --> 1.984215).  Saving model ...
train epoch 431 avg loss: 1.20548 (A-MSE: 1.08095) avg lploss: 0.00000
train epoch 432 avg loss: 1.21191 (A-MSE: 1.07977) avg lploss: 0.00000
train epoch 433 avg loss: 1.20775 (A-MSE: 1.08244) avg lploss: 0.00000
train epoch 434 avg loss: 1.24768 (A-MSE: 1.11783) avg lploss: 0.00000
train epoch 435 avg loss: 1.35019 (A-MSE: 1.21328) avg lploss: 0.00000
==> val epoch 435 avg loss: 2.15587 (A-MSE: 1.91981) avg lploss: 0.00000
==> test epoch 435 avg loss: 2.40411 (A-MSE: 2.13445) avg lploss: 0.00000
*** Best Val Loss: 1.98421 	 Best Test Loss: 2.07945 	 Best epoch 430
EarlyStopping counter: 1 out of 50
train epoch 436 avg loss: 1.35618 (A-MSE: 1.21714) avg lploss: 0.00000
train epoch 437 avg loss: 1.18485 (A-MSE: 1.05978) avg lploss: 0.00000
train epoch 438 avg loss: 1.23454 (A-MSE: 1.10204) avg lploss: 0.00000
train epoch 439 avg loss: 1.12791 (A-MSE: 1.00494) avg lploss: 0.00000
train epoch 440 avg loss: 1.14957 (A-MSE: 1.02790) avg lploss: 0.00000
==> val epoch 440 avg loss: 2.01708 (A-MSE: 1.77581) avg lploss: 0.00000
==> test epoch 440 avg loss: 2.09151 (A-MSE: 1.83210) avg lploss: 0.00000
*** Best Val Loss: 1.98421 	 Best Test Loss: 2.07945 	 Best epoch 430
EarlyStopping counter: 2 out of 50
train epoch 441 avg loss: 1.13968 (A-MSE: 1.01770) avg lploss: 0.00000
train epoch 442 avg loss: 1.17330 (A-MSE: 1.04985) avg lploss: 0.00000
train epoch 443 avg loss: 1.08405 (A-MSE: 0.96567) avg lploss: 0.00000
train epoch 444 avg loss: 1.12510 (A-MSE: 1.00668) avg lploss: 0.00000
train epoch 445 avg loss: 1.12458 (A-MSE: 1.00462) avg lploss: 0.00000
==> val epoch 445 avg loss: 1.92289 (A-MSE: 1.69978) avg lploss: 0.00000
==> test epoch 445 avg loss: 2.10685 (A-MSE: 1.85561) avg lploss: 0.00000
*** Best Val Loss: 1.92289 	 Best Test Loss: 2.10685 	 Best epoch 445
Validation loss decreased (1.984215 --> 1.922894).  Saving model ...
train epoch 446 avg loss: 1.04199 (A-MSE: 0.93247) avg lploss: 0.00000
train epoch 447 avg loss: 1.08635 (A-MSE: 0.96852) avg lploss: 0.00000
train epoch 448 avg loss: 1.20353 (A-MSE: 1.08175) avg lploss: 0.00000
train epoch 449 avg loss: 1.13839 (A-MSE: 1.01874) avg lploss: 0.00000
train epoch 450 avg loss: 1.05302 (A-MSE: 0.94072) avg lploss: 0.00000
==> val epoch 450 avg loss: 2.07514 (A-MSE: 1.82060) avg lploss: 0.00000
==> test epoch 450 avg loss: 2.19371 (A-MSE: 1.90894) avg lploss: 0.00000
*** Best Val Loss: 1.92289 	 Best Test Loss: 2.10685 	 Best epoch 445
EarlyStopping counter: 1 out of 50
train epoch 451 avg loss: 1.09694 (A-MSE: 0.97934) avg lploss: 0.00000
train epoch 452 avg loss: 1.00158 (A-MSE: 0.89417) avg lploss: 0.00000
train epoch 453 avg loss: 1.08531 (A-MSE: 0.96567) avg lploss: 0.00000
train epoch 454 avg loss: 1.08344 (A-MSE: 0.96180) avg lploss: 0.00000
train epoch 455 avg loss: 1.09983 (A-MSE: 0.98188) avg lploss: 0.00000
==> val epoch 455 avg loss: 2.17018 (A-MSE: 1.89845) avg lploss: 0.00000
==> test epoch 455 avg loss: 2.33989 (A-MSE: 2.03333) avg lploss: 0.00000
*** Best Val Loss: 1.92289 	 Best Test Loss: 2.10685 	 Best epoch 445
EarlyStopping counter: 2 out of 50
train epoch 456 avg loss: 1.12302 (A-MSE: 1.00815) avg lploss: 0.00000
train epoch 457 avg loss: 1.21543 (A-MSE: 1.08533) avg lploss: 0.00000
train epoch 458 avg loss: 1.19205 (A-MSE: 1.06783) avg lploss: 0.00000
train epoch 459 avg loss: 1.08659 (A-MSE: 0.96977) avg lploss: 0.00000
train epoch 460 avg loss: 1.00055 (A-MSE: 0.89423) avg lploss: 0.00000
==> val epoch 460 avg loss: 1.94805 (A-MSE: 1.72010) avg lploss: 0.00000
==> test epoch 460 avg loss: 1.97399 (A-MSE: 1.73468) avg lploss: 0.00000
*** Best Val Loss: 1.92289 	 Best Test Loss: 2.10685 	 Best epoch 445
EarlyStopping counter: 3 out of 50
train epoch 461 avg loss: 1.03961 (A-MSE: 0.92717) avg lploss: 0.00000
train epoch 462 avg loss: 1.09762 (A-MSE: 0.98162) avg lploss: 0.00000
train epoch 463 avg loss: 1.05594 (A-MSE: 0.94391) avg lploss: 0.00000
train epoch 464 avg loss: 1.06638 (A-MSE: 0.95128) avg lploss: 0.00000
train epoch 465 avg loss: 1.00015 (A-MSE: 0.89023) avg lploss: 0.00000
==> val epoch 465 avg loss: 1.90103 (A-MSE: 1.67753) avg lploss: 0.00000
==> test epoch 465 avg loss: 2.01294 (A-MSE: 1.76719) avg lploss: 0.00000
*** Best Val Loss: 1.90103 	 Best Test Loss: 2.01294 	 Best epoch 465
Validation loss decreased (1.922894 --> 1.901028).  Saving model ...
train epoch 466 avg loss: 1.05502 (A-MSE: 0.94399) avg lploss: 0.00000
train epoch 467 avg loss: 1.09615 (A-MSE: 0.98035) avg lploss: 0.00000
train epoch 468 avg loss: 1.12372 (A-MSE: 1.00161) avg lploss: 0.00000
train epoch 469 avg loss: 1.03543 (A-MSE: 0.92588) avg lploss: 0.00000
train epoch 470 avg loss: 0.96624 (A-MSE: 0.86147) avg lploss: 0.00000
==> val epoch 470 avg loss: 1.83515 (A-MSE: 1.61354) avg lploss: 0.00000
==> test epoch 470 avg loss: 1.94115 (A-MSE: 1.69705) avg lploss: 0.00000
*** Best Val Loss: 1.83515 	 Best Test Loss: 1.94115 	 Best epoch 470
Validation loss decreased (1.901028 --> 1.835153).  Saving model ...
train epoch 471 avg loss: 0.99947 (A-MSE: 0.88832) avg lploss: 0.00000
train epoch 472 avg loss: 1.05492 (A-MSE: 0.93425) avg lploss: 0.00000
train epoch 473 avg loss: 1.03905 (A-MSE: 0.92834) avg lploss: 0.00000
train epoch 474 avg loss: 1.02085 (A-MSE: 0.91085) avg lploss: 0.00000
train epoch 475 avg loss: 1.07876 (A-MSE: 0.96115) avg lploss: 0.00000
==> val epoch 475 avg loss: 1.92065 (A-MSE: 1.69317) avg lploss: 0.00000
==> test epoch 475 avg loss: 2.04910 (A-MSE: 1.80138) avg lploss: 0.00000
*** Best Val Loss: 1.83515 	 Best Test Loss: 1.94115 	 Best epoch 470
EarlyStopping counter: 1 out of 50
train epoch 476 avg loss: 1.00473 (A-MSE: 0.89683) avg lploss: 0.00000
train epoch 477 avg loss: 1.01388 (A-MSE: 0.90531) avg lploss: 0.00000
train epoch 478 avg loss: 1.05787 (A-MSE: 0.94185) avg lploss: 0.00000
train epoch 479 avg loss: 0.97760 (A-MSE: 0.86758) avg lploss: 0.00000
train epoch 480 avg loss: 0.97935 (A-MSE: 0.87096) avg lploss: 0.00000
==> val epoch 480 avg loss: 2.21617 (A-MSE: 1.92118) avg lploss: 0.00000
==> test epoch 480 avg loss: 2.31871 (A-MSE: 1.98668) avg lploss: 0.00000
*** Best Val Loss: 1.83515 	 Best Test Loss: 1.94115 	 Best epoch 470
EarlyStopping counter: 2 out of 50
train epoch 481 avg loss: 1.17088 (A-MSE: 1.04596) avg lploss: 0.00000
train epoch 482 avg loss: 1.13309 (A-MSE: 1.01268) avg lploss: 0.00000
train epoch 483 avg loss: 1.08515 (A-MSE: 0.96482) avg lploss: 0.00000
train epoch 484 avg loss: 1.05518 (A-MSE: 0.94337) avg lploss: 0.00000
train epoch 485 avg loss: 1.02264 (A-MSE: 0.91175) avg lploss: 0.00000
==> val epoch 485 avg loss: 1.70958 (A-MSE: 1.50770) avg lploss: 0.00000
==> test epoch 485 avg loss: 1.80117 (A-MSE: 1.58179) avg lploss: 0.00000
*** Best Val Loss: 1.70958 	 Best Test Loss: 1.80117 	 Best epoch 485
Validation loss decreased (1.835153 --> 1.709575).  Saving model ...
train epoch 486 avg loss: 1.03033 (A-MSE: 0.91787) avg lploss: 0.00000
train epoch 487 avg loss: 0.95438 (A-MSE: 0.85204) avg lploss: 0.00000
train epoch 488 avg loss: 0.94417 (A-MSE: 0.84353) avg lploss: 0.00000
train epoch 489 avg loss: 0.95845 (A-MSE: 0.85278) avg lploss: 0.00000
train epoch 490 avg loss: 0.96489 (A-MSE: 0.86200) avg lploss: 0.00000
==> val epoch 490 avg loss: 1.80172 (A-MSE: 1.58529) avg lploss: 0.00000
==> test epoch 490 avg loss: 1.85596 (A-MSE: 1.62302) avg lploss: 0.00000
*** Best Val Loss: 1.70958 	 Best Test Loss: 1.80117 	 Best epoch 485
EarlyStopping counter: 1 out of 50
train epoch 491 avg loss: 1.02399 (A-MSE: 0.91337) avg lploss: 0.00000
train epoch 492 avg loss: 1.03309 (A-MSE: 0.92422) avg lploss: 0.00000
train epoch 493 avg loss: 1.07461 (A-MSE: 0.96386) avg lploss: 0.00000
train epoch 494 avg loss: 1.01711 (A-MSE: 0.90729) avg lploss: 0.00000
train epoch 495 avg loss: 1.02575 (A-MSE: 0.91631) avg lploss: 0.00000
==> val epoch 495 avg loss: 1.92382 (A-MSE: 1.70928) avg lploss: 0.00000
==> test epoch 495 avg loss: 2.04530 (A-MSE: 1.81000) avg lploss: 0.00000
*** Best Val Loss: 1.70958 	 Best Test Loss: 1.80117 	 Best epoch 485
EarlyStopping counter: 2 out of 50
train epoch 496 avg loss: 1.03292 (A-MSE: 0.92031) avg lploss: 0.00000
train epoch 497 avg loss: 0.91605 (A-MSE: 0.81871) avg lploss: 0.00000
train epoch 498 avg loss: 0.88075 (A-MSE: 0.78368) avg lploss: 0.00000
train epoch 499 avg loss: 0.89092 (A-MSE: 0.79396) avg lploss: 0.00000
train epoch 500 avg loss: 1.03892 (A-MSE: 0.92624) avg lploss: 0.00000
==> val epoch 500 avg loss: 1.72643 (A-MSE: 1.52533) avg lploss: 0.00000
==> test epoch 500 avg loss: 1.80626 (A-MSE: 1.58419) avg lploss: 0.00000
*** Best Val Loss: 1.70958 	 Best Test Loss: 1.80117 	 Best epoch 485
EarlyStopping counter: 3 out of 50
train epoch 501 avg loss: 1.18990 (A-MSE: 1.06217) avg lploss: 0.00000
train epoch 502 avg loss: 1.03687 (A-MSE: 0.92749) avg lploss: 0.00000
train epoch 503 avg loss: 0.92664 (A-MSE: 0.82524) avg lploss: 0.00000
train epoch 504 avg loss: 0.91775 (A-MSE: 0.81946) avg lploss: 0.00000
train epoch 505 avg loss: 0.86813 (A-MSE: 0.77056) avg lploss: 0.00000
==> val epoch 505 avg loss: 1.67255 (A-MSE: 1.46969) avg lploss: 0.00000
==> test epoch 505 avg loss: 1.82396 (A-MSE: 1.59365) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
Validation loss decreased (1.709575 --> 1.672554).  Saving model ...
train epoch 506 avg loss: 0.88291 (A-MSE: 0.78758) avg lploss: 0.00000
train epoch 507 avg loss: 0.96389 (A-MSE: 0.86320) avg lploss: 0.00000
train epoch 508 avg loss: 1.03818 (A-MSE: 0.92769) avg lploss: 0.00000
train epoch 509 avg loss: 0.95442 (A-MSE: 0.85161) avg lploss: 0.00000
train epoch 510 avg loss: 0.92814 (A-MSE: 0.82789) avg lploss: 0.00000
==> val epoch 510 avg loss: 1.93695 (A-MSE: 1.70526) avg lploss: 0.00000
==> test epoch 510 avg loss: 2.02334 (A-MSE: 1.77349) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 1 out of 50
train epoch 511 avg loss: 1.00026 (A-MSE: 0.89550) avg lploss: 0.00000
train epoch 512 avg loss: 0.92282 (A-MSE: 0.82226) avg lploss: 0.00000
train epoch 513 avg loss: 0.99966 (A-MSE: 0.89293) avg lploss: 0.00000
train epoch 514 avg loss: 1.06131 (A-MSE: 0.94605) avg lploss: 0.00000
train epoch 515 avg loss: 1.00114 (A-MSE: 0.89201) avg lploss: 0.00000
==> val epoch 515 avg loss: 1.92756 (A-MSE: 1.70090) avg lploss: 0.00000
==> test epoch 515 avg loss: 1.98543 (A-MSE: 1.74640) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 2 out of 50
train epoch 516 avg loss: 0.96349 (A-MSE: 0.85481) avg lploss: 0.00000
train epoch 517 avg loss: 0.93897 (A-MSE: 0.83754) avg lploss: 0.00000
train epoch 518 avg loss: 0.94523 (A-MSE: 0.84162) avg lploss: 0.00000
train epoch 519 avg loss: 0.88405 (A-MSE: 0.78830) avg lploss: 0.00000
train epoch 520 avg loss: 0.92319 (A-MSE: 0.82283) avg lploss: 0.00000
==> val epoch 520 avg loss: 1.75357 (A-MSE: 1.54315) avg lploss: 0.00000
==> test epoch 520 avg loss: 1.85698 (A-MSE: 1.62533) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 3 out of 50
train epoch 521 avg loss: 1.28407 (A-MSE: 1.15521) avg lploss: 0.00000
train epoch 522 avg loss: 1.27790 (A-MSE: 1.14337) avg lploss: 0.00000
train epoch 523 avg loss: 1.01232 (A-MSE: 0.90208) avg lploss: 0.00000
train epoch 524 avg loss: 0.93471 (A-MSE: 0.83303) avg lploss: 0.00000
train epoch 525 avg loss: 0.93378 (A-MSE: 0.83500) avg lploss: 0.00000
==> val epoch 525 avg loss: 1.80267 (A-MSE: 1.59021) avg lploss: 0.00000
==> test epoch 525 avg loss: 1.89898 (A-MSE: 1.66291) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 4 out of 50
train epoch 526 avg loss: 0.96573 (A-MSE: 0.85973) avg lploss: 0.00000
train epoch 527 avg loss: 1.11878 (A-MSE: 1.00224) avg lploss: 0.00000
train epoch 528 avg loss: 1.00682 (A-MSE: 0.89854) avg lploss: 0.00000
train epoch 529 avg loss: 0.87048 (A-MSE: 0.77596) avg lploss: 0.00000
train epoch 530 avg loss: 0.88448 (A-MSE: 0.78648) avg lploss: 0.00000
==> val epoch 530 avg loss: 1.67338 (A-MSE: 1.48021) avg lploss: 0.00000
==> test epoch 530 avg loss: 1.77123 (A-MSE: 1.56548) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 5 out of 50
train epoch 531 avg loss: 0.95176 (A-MSE: 0.84959) avg lploss: 0.00000
train epoch 532 avg loss: 1.03218 (A-MSE: 0.92772) avg lploss: 0.00000
train epoch 533 avg loss: 1.07792 (A-MSE: 0.96930) avg lploss: 0.00000
train epoch 534 avg loss: 0.97090 (A-MSE: 0.86632) avg lploss: 0.00000
train epoch 535 avg loss: 0.97081 (A-MSE: 0.86889) avg lploss: 0.00000
==> val epoch 535 avg loss: 1.85876 (A-MSE: 1.63803) avg lploss: 0.00000
==> test epoch 535 avg loss: 1.93871 (A-MSE: 1.70431) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 6 out of 50
train epoch 536 avg loss: 0.90144 (A-MSE: 0.80225) avg lploss: 0.00000
train epoch 537 avg loss: 0.86872 (A-MSE: 0.77111) avg lploss: 0.00000
train epoch 538 avg loss: 0.92405 (A-MSE: 0.82701) avg lploss: 0.00000
train epoch 539 avg loss: 0.85399 (A-MSE: 0.76221) avg lploss: 0.00000
train epoch 540 avg loss: 0.88398 (A-MSE: 0.78964) avg lploss: 0.00000
==> val epoch 540 avg loss: 1.96523 (A-MSE: 1.71510) avg lploss: 0.00000
==> test epoch 540 avg loss: 2.12110 (A-MSE: 1.83676) avg lploss: 0.00000
*** Best Val Loss: 1.67255 	 Best Test Loss: 1.82396 	 Best epoch 505
EarlyStopping counter: 7 out of 50
train epoch 541 avg loss: 0.88530 (A-MSE: 0.78865) avg lploss: 0.00000
train epoch 542 avg loss: 0.87311 (A-MSE: 0.77229) avg lploss: 0.00000
train epoch 543 avg loss: 0.85098 (A-MSE: 0.76000) avg lploss: 0.00000
train epoch 544 avg loss: 0.85993 (A-MSE: 0.76739) avg lploss: 0.00000
train epoch 545 avg loss: 0.79159 (A-MSE: 0.70236) avg lploss: 0.00000
==> val epoch 545 avg loss: 1.60731 (A-MSE: 1.41484) avg lploss: 0.00000
==> test epoch 545 avg loss: 1.79456 (A-MSE: 1.57369) avg lploss: 0.00000
*** Best Val Loss: 1.60731 	 Best Test Loss: 1.79456 	 Best epoch 545
Validation loss decreased (1.672554 --> 1.607309).  Saving model ...
train epoch 546 avg loss: 0.83804 (A-MSE: 0.74533) avg lploss: 0.00000
train epoch 547 avg loss: 0.89960 (A-MSE: 0.80528) avg lploss: 0.00000
train epoch 548 avg loss: 0.92757 (A-MSE: 0.83168) avg lploss: 0.00000
train epoch 549 avg loss: 0.88962 (A-MSE: 0.79355) avg lploss: 0.00000
train epoch 550 avg loss: 0.83132 (A-MSE: 0.74065) avg lploss: 0.00000
==> val epoch 550 avg loss: 1.95047 (A-MSE: 1.71852) avg lploss: 0.00000
==> test epoch 550 avg loss: 2.03543 (A-MSE: 1.78870) avg lploss: 0.00000
*** Best Val Loss: 1.60731 	 Best Test Loss: 1.79456 	 Best epoch 545
EarlyStopping counter: 1 out of 50
train epoch 551 avg loss: 0.87205 (A-MSE: 0.77978) avg lploss: 0.00000
train epoch 552 avg loss: 0.80829 (A-MSE: 0.72237) avg lploss: 0.00000
train epoch 553 avg loss: 0.82341 (A-MSE: 0.73187) avg lploss: 0.00000
train epoch 554 avg loss: 0.88376 (A-MSE: 0.78787) avg lploss: 0.00000
train epoch 555 avg loss: 0.89036 (A-MSE: 0.79751) avg lploss: 0.00000
==> val epoch 555 avg loss: 1.67437 (A-MSE: 1.48877) avg lploss: 0.00000
==> test epoch 555 avg loss: 1.81034 (A-MSE: 1.59898) avg lploss: 0.00000
*** Best Val Loss: 1.60731 	 Best Test Loss: 1.79456 	 Best epoch 545
EarlyStopping counter: 2 out of 50
train epoch 556 avg loss: 0.84205 (A-MSE: 0.75260) avg lploss: 0.00000
train epoch 557 avg loss: 0.85784 (A-MSE: 0.76652) avg lploss: 0.00000
train epoch 558 avg loss: 0.82982 (A-MSE: 0.73910) avg lploss: 0.00000
train epoch 559 avg loss: 0.80436 (A-MSE: 0.71713) avg lploss: 0.00000
train epoch 560 avg loss: 0.89331 (A-MSE: 0.79898) avg lploss: 0.00000
==> val epoch 560 avg loss: 1.61837 (A-MSE: 1.44757) avg lploss: 0.00000
==> test epoch 560 avg loss: 1.67545 (A-MSE: 1.49024) avg lploss: 0.00000
*** Best Val Loss: 1.60731 	 Best Test Loss: 1.79456 	 Best epoch 545
EarlyStopping counter: 3 out of 50
train epoch 561 avg loss: 0.86115 (A-MSE: 0.76810) avg lploss: 0.00000
train epoch 562 avg loss: 0.87339 (A-MSE: 0.78194) avg lploss: 0.00000
train epoch 563 avg loss: 0.83775 (A-MSE: 0.74775) avg lploss: 0.00000
train epoch 564 avg loss: 0.82960 (A-MSE: 0.74041) avg lploss: 0.00000
train epoch 565 avg loss: 0.75072 (A-MSE: 0.66523) avg lploss: 0.00000
==> val epoch 565 avg loss: 1.66327 (A-MSE: 1.46931) avg lploss: 0.00000
==> test epoch 565 avg loss: 1.78546 (A-MSE: 1.57152) avg lploss: 0.00000
*** Best Val Loss: 1.60731 	 Best Test Loss: 1.79456 	 Best epoch 545
EarlyStopping counter: 4 out of 50
train epoch 566 avg loss: 0.82244 (A-MSE: 0.73348) avg lploss: 0.00000
train epoch 567 avg loss: 0.92041 (A-MSE: 0.82369) avg lploss: 0.00000
train epoch 568 avg loss: 0.89262 (A-MSE: 0.79575) avg lploss: 0.00000
train epoch 569 avg loss: 0.82034 (A-MSE: 0.73269) avg lploss: 0.00000
train epoch 570 avg loss: 0.82879 (A-MSE: 0.73851) avg lploss: 0.00000
==> val epoch 570 avg loss: 1.96346 (A-MSE: 1.74037) avg lploss: 0.00000
==> test epoch 570 avg loss: 2.09818 (A-MSE: 1.85969) avg lploss: 0.00000
*** Best Val Loss: 1.60731 	 Best Test Loss: 1.79456 	 Best epoch 545
EarlyStopping counter: 5 out of 50
train epoch 571 avg loss: 0.80865 (A-MSE: 0.72104) avg lploss: 0.00000
train epoch 572 avg loss: 0.86311 (A-MSE: 0.76812) avg lploss: 0.00000
train epoch 573 avg loss: 0.91623 (A-MSE: 0.81754) avg lploss: 0.00000
train epoch 574 avg loss: 0.86858 (A-MSE: 0.77582) avg lploss: 0.00000
train epoch 575 avg loss: 0.77030 (A-MSE: 0.68568) avg lploss: 0.00000
==> val epoch 575 avg loss: 1.59812 (A-MSE: 1.40176) avg lploss: 0.00000
==> test epoch 575 avg loss: 1.76524 (A-MSE: 1.53671) avg lploss: 0.00000
*** Best Val Loss: 1.59812 	 Best Test Loss: 1.76524 	 Best epoch 575
Validation loss decreased (1.607309 --> 1.598116).  Saving model ...
train epoch 576 avg loss: 0.81210 (A-MSE: 0.72618) avg lploss: 0.00000
train epoch 577 avg loss: 0.86754 (A-MSE: 0.77323) avg lploss: 0.00000
train epoch 578 avg loss: 0.95920 (A-MSE: 0.86115) avg lploss: 0.00000
train epoch 579 avg loss: 0.85822 (A-MSE: 0.76299) avg lploss: 0.00000
train epoch 580 avg loss: 0.85150 (A-MSE: 0.75842) avg lploss: 0.00000
==> val epoch 580 avg loss: 1.92574 (A-MSE: 1.70030) avg lploss: 0.00000
==> test epoch 580 avg loss: 2.02505 (A-MSE: 1.77999) avg lploss: 0.00000
*** Best Val Loss: 1.59812 	 Best Test Loss: 1.76524 	 Best epoch 575
EarlyStopping counter: 1 out of 50
train epoch 581 avg loss: 0.92689 (A-MSE: 0.82687) avg lploss: 0.00000
train epoch 582 avg loss: 0.81052 (A-MSE: 0.72472) avg lploss: 0.00000
train epoch 583 avg loss: 0.74143 (A-MSE: 0.66059) avg lploss: 0.00000
train epoch 584 avg loss: 0.80104 (A-MSE: 0.71277) avg lploss: 0.00000
train epoch 585 avg loss: 0.97112 (A-MSE: 0.87043) avg lploss: 0.00000
==> val epoch 585 avg loss: 2.15546 (A-MSE: 1.90917) avg lploss: 0.00000
==> test epoch 585 avg loss: 2.27699 (A-MSE: 2.00817) avg lploss: 0.00000
*** Best Val Loss: 1.59812 	 Best Test Loss: 1.76524 	 Best epoch 575
EarlyStopping counter: 2 out of 50
train epoch 586 avg loss: 1.02448 (A-MSE: 0.91707) avg lploss: 0.00000
train epoch 587 avg loss: 0.90567 (A-MSE: 0.80913) avg lploss: 0.00000
train epoch 588 avg loss: 0.77297 (A-MSE: 0.69169) avg lploss: 0.00000
train epoch 589 avg loss: 0.80099 (A-MSE: 0.71465) avg lploss: 0.00000
train epoch 590 avg loss: 0.77775 (A-MSE: 0.69478) avg lploss: 0.00000
==> val epoch 590 avg loss: 1.87372 (A-MSE: 1.67031) avg lploss: 0.00000
==> test epoch 590 avg loss: 1.99291 (A-MSE: 1.77304) avg lploss: 0.00000
*** Best Val Loss: 1.59812 	 Best Test Loss: 1.76524 	 Best epoch 575
EarlyStopping counter: 3 out of 50
train epoch 591 avg loss: 0.85275 (A-MSE: 0.76724) avg lploss: 0.00000
train epoch 592 avg loss: 0.72787 (A-MSE: 0.64786) avg lploss: 0.00000
train epoch 593 avg loss: 0.78209 (A-MSE: 0.69721) avg lploss: 0.00000
train epoch 594 avg loss: 0.85682 (A-MSE: 0.76827) avg lploss: 0.00000
train epoch 595 avg loss: 0.86058 (A-MSE: 0.76791) avg lploss: 0.00000
==> val epoch 595 avg loss: 2.22897 (A-MSE: 1.95947) avg lploss: 0.00000
==> test epoch 595 avg loss: 2.37754 (A-MSE: 2.08550) avg lploss: 0.00000
*** Best Val Loss: 1.59812 	 Best Test Loss: 1.76524 	 Best epoch 575
EarlyStopping counter: 4 out of 50
train epoch 596 avg loss: 0.86423 (A-MSE: 0.77133) avg lploss: 0.00000
train epoch 597 avg loss: 0.84294 (A-MSE: 0.75375) avg lploss: 0.00000
train epoch 598 avg loss: 0.85677 (A-MSE: 0.76182) avg lploss: 0.00000
train epoch 599 avg loss: 0.78723 (A-MSE: 0.69902) avg lploss: 0.00000
train epoch 600 avg loss: 0.72918 (A-MSE: 0.65129) avg lploss: 0.00000
==> val epoch 600 avg loss: 1.67781 (A-MSE: 1.49722) avg lploss: 0.00000
==> test epoch 600 avg loss: 1.80718 (A-MSE: 1.60133) avg lploss: 0.00000
*** Best Val Loss: 1.59812 	 Best Test Loss: 1.76524 	 Best epoch 575
EarlyStopping counter: 5 out of 50
train epoch 601 avg loss: 0.75377 (A-MSE: 0.67250) avg lploss: 0.00000
train epoch 602 avg loss: 0.83397 (A-MSE: 0.74524) avg lploss: 0.00000
train epoch 603 avg loss: 0.77479 (A-MSE: 0.69244) avg lploss: 0.00000
train epoch 604 avg loss: 0.95753 (A-MSE: 0.85544) avg lploss: 0.00000
train epoch 605 avg loss: 0.78229 (A-MSE: 0.69760) avg lploss: 0.00000
==> val epoch 605 avg loss: 1.53757 (A-MSE: 1.36759) avg lploss: 0.00000
==> test epoch 605 avg loss: 1.64074 (A-MSE: 1.45657) avg lploss: 0.00000
*** Best Val Loss: 1.53757 	 Best Test Loss: 1.64074 	 Best epoch 605
Validation loss decreased (1.598116 --> 1.537566).  Saving model ...
train epoch 606 avg loss: 0.80320 (A-MSE: 0.71644) avg lploss: 0.00000
train epoch 607 avg loss: 0.89743 (A-MSE: 0.80263) avg lploss: 0.00000
train epoch 608 avg loss: 0.86241 (A-MSE: 0.76823) avg lploss: 0.00000
train epoch 609 avg loss: 0.77590 (A-MSE: 0.68993) avg lploss: 0.00000
train epoch 610 avg loss: 0.86814 (A-MSE: 0.77741) avg lploss: 0.00000
==> val epoch 610 avg loss: 1.60924 (A-MSE: 1.42020) avg lploss: 0.00000
==> test epoch 610 avg loss: 1.75944 (A-MSE: 1.55519) avg lploss: 0.00000
*** Best Val Loss: 1.53757 	 Best Test Loss: 1.64074 	 Best epoch 605
EarlyStopping counter: 1 out of 50
train epoch 611 avg loss: 0.80975 (A-MSE: 0.71772) avg lploss: 0.00000
train epoch 612 avg loss: 0.77947 (A-MSE: 0.69678) avg lploss: 0.00000
train epoch 613 avg loss: 0.81252 (A-MSE: 0.72548) avg lploss: 0.00000
train epoch 614 avg loss: 0.78461 (A-MSE: 0.70300) avg lploss: 0.00000
train epoch 615 avg loss: 0.76805 (A-MSE: 0.68721) avg lploss: 0.00000
==> val epoch 615 avg loss: 1.47411 (A-MSE: 1.31112) avg lploss: 0.00000
==> test epoch 615 avg loss: 1.68819 (A-MSE: 1.50368) avg lploss: 0.00000
*** Best Val Loss: 1.47411 	 Best Test Loss: 1.68819 	 Best epoch 615
Validation loss decreased (1.537566 --> 1.474114).  Saving model ...
train epoch 616 avg loss: 0.68305 (A-MSE: 0.60924) avg lploss: 0.00000
train epoch 617 avg loss: 0.78826 (A-MSE: 0.69944) avg lploss: 0.00000
train epoch 618 avg loss: 0.81648 (A-MSE: 0.73046) avg lploss: 0.00000
train epoch 619 avg loss: 0.83421 (A-MSE: 0.74319) avg lploss: 0.00000
train epoch 620 avg loss: 0.81198 (A-MSE: 0.72213) avg lploss: 0.00000
==> val epoch 620 avg loss: 1.67048 (A-MSE: 1.47360) avg lploss: 0.00000
==> test epoch 620 avg loss: 1.84978 (A-MSE: 1.62774) avg lploss: 0.00000
*** Best Val Loss: 1.47411 	 Best Test Loss: 1.68819 	 Best epoch 615
EarlyStopping counter: 1 out of 50
train epoch 621 avg loss: 0.73032 (A-MSE: 0.65355) avg lploss: 0.00000
train epoch 622 avg loss: 0.76464 (A-MSE: 0.68289) avg lploss: 0.00000
train epoch 623 avg loss: 0.84034 (A-MSE: 0.75248) avg lploss: 0.00000
train epoch 624 avg loss: 0.72830 (A-MSE: 0.64963) avg lploss: 0.00000
train epoch 625 avg loss: 0.73004 (A-MSE: 0.65323) avg lploss: 0.00000
==> val epoch 625 avg loss: 1.71106 (A-MSE: 1.51897) avg lploss: 0.00000
==> test epoch 625 avg loss: 1.83439 (A-MSE: 1.62629) avg lploss: 0.00000
*** Best Val Loss: 1.47411 	 Best Test Loss: 1.68819 	 Best epoch 615
EarlyStopping counter: 2 out of 50
train epoch 626 avg loss: 0.70368 (A-MSE: 0.62646) avg lploss: 0.00000
train epoch 627 avg loss: 0.68809 (A-MSE: 0.61116) avg lploss: 0.00000
train epoch 628 avg loss: 0.72433 (A-MSE: 0.64643) avg lploss: 0.00000
train epoch 629 avg loss: 0.73143 (A-MSE: 0.65333) avg lploss: 0.00000
train epoch 630 avg loss: 0.90307 (A-MSE: 0.80662) avg lploss: 0.00000
==> val epoch 630 avg loss: 1.39782 (A-MSE: 1.23829) avg lploss: 0.00000
==> test epoch 630 avg loss: 1.51833 (A-MSE: 1.34256) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
Validation loss decreased (1.474114 --> 1.397815).  Saving model ...
train epoch 631 avg loss: 0.85145 (A-MSE: 0.75616) avg lploss: 0.00000
train epoch 632 avg loss: 0.71650 (A-MSE: 0.63872) avg lploss: 0.00000
train epoch 633 avg loss: 0.77224 (A-MSE: 0.69041) avg lploss: 0.00000
train epoch 634 avg loss: 0.76198 (A-MSE: 0.67985) avg lploss: 0.00000
train epoch 635 avg loss: 0.77194 (A-MSE: 0.69166) avg lploss: 0.00000
==> val epoch 635 avg loss: 1.58304 (A-MSE: 1.39551) avg lploss: 0.00000
==> test epoch 635 avg loss: 1.79063 (A-MSE: 1.58408) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 1 out of 50
train epoch 636 avg loss: 0.77048 (A-MSE: 0.68643) avg lploss: 0.00000
train epoch 637 avg loss: 0.70491 (A-MSE: 0.62835) avg lploss: 0.00000
train epoch 638 avg loss: 0.72495 (A-MSE: 0.64729) avg lploss: 0.00000
train epoch 639 avg loss: 0.69199 (A-MSE: 0.61854) avg lploss: 0.00000
train epoch 640 avg loss: 0.66332 (A-MSE: 0.58818) avg lploss: 0.00000
==> val epoch 640 avg loss: 1.66220 (A-MSE: 1.47443) avg lploss: 0.00000
==> test epoch 640 avg loss: 1.79528 (A-MSE: 1.59262) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 2 out of 50
train epoch 641 avg loss: 0.70326 (A-MSE: 0.63058) avg lploss: 0.00000
train epoch 642 avg loss: 0.67562 (A-MSE: 0.60467) avg lploss: 0.00000
train epoch 643 avg loss: 0.73052 (A-MSE: 0.65481) avg lploss: 0.00000
train epoch 644 avg loss: 0.71340 (A-MSE: 0.63583) avg lploss: 0.00000
train epoch 645 avg loss: 0.68904 (A-MSE: 0.61934) avg lploss: 0.00000
==> val epoch 645 avg loss: 1.54721 (A-MSE: 1.36249) avg lploss: 0.00000
==> test epoch 645 avg loss: 1.72980 (A-MSE: 1.52210) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 3 out of 50
train epoch 646 avg loss: 0.77760 (A-MSE: 0.69470) avg lploss: 0.00000
train epoch 647 avg loss: 0.70976 (A-MSE: 0.63135) avg lploss: 0.00000
train epoch 648 avg loss: 0.70642 (A-MSE: 0.63155) avg lploss: 0.00000
train epoch 649 avg loss: 0.74461 (A-MSE: 0.66646) avg lploss: 0.00000
train epoch 650 avg loss: 0.72272 (A-MSE: 0.64303) avg lploss: 0.00000
==> val epoch 650 avg loss: 1.73184 (A-MSE: 1.53651) avg lploss: 0.00000
==> test epoch 650 avg loss: 1.89666 (A-MSE: 1.67482) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 4 out of 50
train epoch 651 avg loss: 0.67651 (A-MSE: 0.60315) avg lploss: 0.00000
train epoch 652 avg loss: 0.70160 (A-MSE: 0.62500) avg lploss: 0.00000
train epoch 653 avg loss: 0.72273 (A-MSE: 0.64325) avg lploss: 0.00000
train epoch 654 avg loss: 0.69875 (A-MSE: 0.62509) avg lploss: 0.00000
train epoch 655 avg loss: 0.67707 (A-MSE: 0.60142) avg lploss: 0.00000
==> val epoch 655 avg loss: 1.62258 (A-MSE: 1.42457) avg lploss: 0.00000
==> test epoch 655 avg loss: 1.77252 (A-MSE: 1.55049) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 5 out of 50
train epoch 656 avg loss: 0.65607 (A-MSE: 0.58773) avg lploss: 0.00000
train epoch 657 avg loss: 0.73959 (A-MSE: 0.66155) avg lploss: 0.00000
train epoch 658 avg loss: 0.68216 (A-MSE: 0.60682) avg lploss: 0.00000
train epoch 659 avg loss: 0.69988 (A-MSE: 0.62259) avg lploss: 0.00000
train epoch 660 avg loss: 0.69281 (A-MSE: 0.61662) avg lploss: 0.00000
==> val epoch 660 avg loss: 1.86718 (A-MSE: 1.66537) avg lploss: 0.00000
==> test epoch 660 avg loss: 2.08798 (A-MSE: 1.86298) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 6 out of 50
train epoch 661 avg loss: 0.77527 (A-MSE: 0.69055) avg lploss: 0.00000
train epoch 662 avg loss: 0.78226 (A-MSE: 0.70008) avg lploss: 0.00000
train epoch 663 avg loss: 0.71152 (A-MSE: 0.63548) avg lploss: 0.00000
train epoch 664 avg loss: 0.73499 (A-MSE: 0.65419) avg lploss: 0.00000
train epoch 665 avg loss: 0.76231 (A-MSE: 0.68155) avg lploss: 0.00000
==> val epoch 665 avg loss: 1.66493 (A-MSE: 1.47635) avg lploss: 0.00000
==> test epoch 665 avg loss: 1.77890 (A-MSE: 1.57067) avg lploss: 0.00000
*** Best Val Loss: 1.39782 	 Best Test Loss: 1.51833 	 Best epoch 630
EarlyStopping counter: 7 out of 50
train epoch 666 avg loss: 0.71334 (A-MSE: 0.63876) avg lploss: 0.00000
train epoch 667 avg loss: 0.75532 (A-MSE: 0.67340) avg lploss: 0.00000
train epoch 668 avg loss: 0.77453 (A-MSE: 0.69380) avg lploss: 0.00000
train epoch 669 avg loss: 0.73849 (A-MSE: 0.65838) avg lploss: 0.00000
train epoch 670 avg loss: 0.66397 (A-MSE: 0.58967) avg lploss: 0.00000
==> val epoch 670 avg loss: 1.35150 (A-MSE: 1.20086) avg lploss: 0.00000
==> test epoch 670 avg loss: 1.49601 (A-MSE: 1.31792) avg lploss: 0.00000
*** Best Val Loss: 1.35150 	 Best Test Loss: 1.49601 	 Best epoch 670
Validation loss decreased (1.397815 --> 1.351504).  Saving model ...
train epoch 671 avg loss: 0.76824 (A-MSE: 0.68678) avg lploss: 0.00000
train epoch 672 avg loss: 0.67693 (A-MSE: 0.60237) avg lploss: 0.00000
train epoch 673 avg loss: 0.72319 (A-MSE: 0.64487) avg lploss: 0.00000
train epoch 674 avg loss: 0.73628 (A-MSE: 0.65857) avg lploss: 0.00000
train epoch 675 avg loss: 0.66214 (A-MSE: 0.58896) avg lploss: 0.00000
==> val epoch 675 avg loss: 1.51037 (A-MSE: 1.32978) avg lploss: 0.00000
==> test epoch 675 avg loss: 1.64001 (A-MSE: 1.43827) avg lploss: 0.00000
*** Best Val Loss: 1.35150 	 Best Test Loss: 1.49601 	 Best epoch 670
EarlyStopping counter: 1 out of 50
train epoch 676 avg loss: 0.63275 (A-MSE: 0.56416) avg lploss: 0.00000
train epoch 677 avg loss: 0.62228 (A-MSE: 0.55468) avg lploss: 0.00000
train epoch 678 avg loss: 0.68171 (A-MSE: 0.60784) avg lploss: 0.00000
train epoch 679 avg loss: 0.69449 (A-MSE: 0.62057) avg lploss: 0.00000
train epoch 680 avg loss: 0.72818 (A-MSE: 0.64601) avg lploss: 0.00000
==> val epoch 680 avg loss: 1.52078 (A-MSE: 1.34211) avg lploss: 0.00000
==> test epoch 680 avg loss: 1.66194 (A-MSE: 1.46626) avg lploss: 0.00000
*** Best Val Loss: 1.35150 	 Best Test Loss: 1.49601 	 Best epoch 670
EarlyStopping counter: 2 out of 50
train epoch 681 avg loss: 0.71811 (A-MSE: 0.64534) avg lploss: 0.00000
train epoch 682 avg loss: 0.70566 (A-MSE: 0.63168) avg lploss: 0.00000
train epoch 683 avg loss: 0.76456 (A-MSE: 0.68354) avg lploss: 0.00000
train epoch 684 avg loss: 0.71684 (A-MSE: 0.64277) avg lploss: 0.00000
train epoch 685 avg loss: 0.61455 (A-MSE: 0.54776) avg lploss: 0.00000
==> val epoch 685 avg loss: 1.55998 (A-MSE: 1.37459) avg lploss: 0.00000
==> test epoch 685 avg loss: 1.70896 (A-MSE: 1.49842) avg lploss: 0.00000
*** Best Val Loss: 1.35150 	 Best Test Loss: 1.49601 	 Best epoch 670
EarlyStopping counter: 3 out of 50
train epoch 686 avg loss: 0.65564 (A-MSE: 0.58727) avg lploss: 0.00000
train epoch 687 avg loss: 0.72079 (A-MSE: 0.64436) avg lploss: 0.00000
train epoch 688 avg loss: 0.68285 (A-MSE: 0.60946) avg lploss: 0.00000
train epoch 689 avg loss: 0.63690 (A-MSE: 0.56674) avg lploss: 0.00000
train epoch 690 avg loss: 0.71468 (A-MSE: 0.64149) avg lploss: 0.00000
==> val epoch 690 avg loss: 1.54771 (A-MSE: 1.37143) avg lploss: 0.00000
==> test epoch 690 avg loss: 1.69378 (A-MSE: 1.49830) avg lploss: 0.00000
*** Best Val Loss: 1.35150 	 Best Test Loss: 1.49601 	 Best epoch 670
EarlyStopping counter: 4 out of 50
train epoch 691 avg loss: 0.66330 (A-MSE: 0.59197) avg lploss: 0.00000
train epoch 692 avg loss: 0.64451 (A-MSE: 0.57631) avg lploss: 0.00000
train epoch 693 avg loss: 0.60372 (A-MSE: 0.53787) avg lploss: 0.00000
train epoch 694 avg loss: 0.66420 (A-MSE: 0.59219) avg lploss: 0.00000
train epoch 695 avg loss: 0.71642 (A-MSE: 0.64107) avg lploss: 0.00000
==> val epoch 695 avg loss: 1.57183 (A-MSE: 1.38604) avg lploss: 0.00000
==> test epoch 695 avg loss: 1.77192 (A-MSE: 1.56353) avg lploss: 0.00000
*** Best Val Loss: 1.35150 	 Best Test Loss: 1.49601 	 Best epoch 670
EarlyStopping counter: 5 out of 50
train epoch 696 avg loss: 0.67162 (A-MSE: 0.60204) avg lploss: 0.00000
train epoch 697 avg loss: 0.65264 (A-MSE: 0.57992) avg lploss: 0.00000
train epoch 698 avg loss: 0.66562 (A-MSE: 0.59275) avg lploss: 0.00000
train epoch 699 avg loss: 0.59477 (A-MSE: 0.53002) avg lploss: 0.00000
train epoch 700 avg loss: 0.63816 (A-MSE: 0.56940) avg lploss: 0.00000
==> val epoch 700 avg loss: 1.27500 (A-MSE: 1.13655) avg lploss: 0.00000
==> test epoch 700 avg loss: 1.42157 (A-MSE: 1.25780) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
Validation loss decreased (1.351504 --> 1.275003).  Saving model ...
train epoch 701 avg loss: 0.64804 (A-MSE: 0.57769) avg lploss: 0.00000
train epoch 702 avg loss: 0.65875 (A-MSE: 0.59179) avg lploss: 0.00000
train epoch 703 avg loss: 0.70155 (A-MSE: 0.62600) avg lploss: 0.00000
train epoch 704 avg loss: 0.78086 (A-MSE: 0.69559) avg lploss: 0.00000
train epoch 705 avg loss: 0.79120 (A-MSE: 0.70632) avg lploss: 0.00000
==> val epoch 705 avg loss: 1.49150 (A-MSE: 1.34742) avg lploss: 0.00000
==> test epoch 705 avg loss: 1.62833 (A-MSE: 1.46665) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 1 out of 50
train epoch 706 avg loss: 0.67771 (A-MSE: 0.60702) avg lploss: 0.00000
train epoch 707 avg loss: 0.70810 (A-MSE: 0.63102) avg lploss: 0.00000
train epoch 708 avg loss: 0.68709 (A-MSE: 0.61299) avg lploss: 0.00000
train epoch 709 avg loss: 0.61108 (A-MSE: 0.54517) avg lploss: 0.00000
train epoch 710 avg loss: 0.60136 (A-MSE: 0.53899) avg lploss: 0.00000
==> val epoch 710 avg loss: 1.61230 (A-MSE: 1.40834) avg lploss: 0.00000
==> test epoch 710 avg loss: 1.79172 (A-MSE: 1.56861) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 2 out of 50
train epoch 711 avg loss: 0.64409 (A-MSE: 0.57427) avg lploss: 0.00000
train epoch 712 avg loss: 0.65311 (A-MSE: 0.58196) avg lploss: 0.00000
train epoch 713 avg loss: 0.64384 (A-MSE: 0.57485) avg lploss: 0.00000
train epoch 714 avg loss: 0.75044 (A-MSE: 0.66986) avg lploss: 0.00000
train epoch 715 avg loss: 0.71839 (A-MSE: 0.64556) avg lploss: 0.00000
==> val epoch 715 avg loss: 1.53836 (A-MSE: 1.34761) avg lploss: 0.00000
==> test epoch 715 avg loss: 1.70839 (A-MSE: 1.49642) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 3 out of 50
train epoch 716 avg loss: 0.68490 (A-MSE: 0.61119) avg lploss: 0.00000
train epoch 717 avg loss: 0.76162 (A-MSE: 0.68062) avg lploss: 0.00000
train epoch 718 avg loss: 0.62837 (A-MSE: 0.56005) avg lploss: 0.00000
train epoch 719 avg loss: 0.63463 (A-MSE: 0.56603) avg lploss: 0.00000
train epoch 720 avg loss: 0.76809 (A-MSE: 0.68476) avg lploss: 0.00000
==> val epoch 720 avg loss: 1.65291 (A-MSE: 1.45319) avg lploss: 0.00000
==> test epoch 720 avg loss: 1.83218 (A-MSE: 1.61069) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 4 out of 50
train epoch 721 avg loss: 0.71918 (A-MSE: 0.64324) avg lploss: 0.00000
train epoch 722 avg loss: 0.70302 (A-MSE: 0.62494) avg lploss: 0.00000
train epoch 723 avg loss: 0.69441 (A-MSE: 0.61828) avg lploss: 0.00000
train epoch 724 avg loss: 0.66108 (A-MSE: 0.58938) avg lploss: 0.00000
train epoch 725 avg loss: 0.61572 (A-MSE: 0.54680) avg lploss: 0.00000
==> val epoch 725 avg loss: 1.38367 (A-MSE: 1.21221) avg lploss: 0.00000
==> test epoch 725 avg loss: 1.49202 (A-MSE: 1.31126) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 5 out of 50
train epoch 726 avg loss: 0.57255 (A-MSE: 0.51164) avg lploss: 0.00000
train epoch 727 avg loss: 0.62549 (A-MSE: 0.55678) avg lploss: 0.00000
train epoch 728 avg loss: 0.63447 (A-MSE: 0.56700) avg lploss: 0.00000
train epoch 729 avg loss: 0.59671 (A-MSE: 0.53145) avg lploss: 0.00000
train epoch 730 avg loss: 0.60240 (A-MSE: 0.53644) avg lploss: 0.00000
==> val epoch 730 avg loss: 1.57321 (A-MSE: 1.36735) avg lploss: 0.00000
==> test epoch 730 avg loss: 1.71684 (A-MSE: 1.49792) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 6 out of 50
train epoch 731 avg loss: 0.58418 (A-MSE: 0.51838) avg lploss: 0.00000
train epoch 732 avg loss: 0.55758 (A-MSE: 0.49706) avg lploss: 0.00000
train epoch 733 avg loss: 0.60599 (A-MSE: 0.54026) avg lploss: 0.00000
train epoch 734 avg loss: 0.67649 (A-MSE: 0.60443) avg lploss: 0.00000
train epoch 735 avg loss: 1.13571 (A-MSE: 1.01675) avg lploss: 0.00000
==> val epoch 735 avg loss: 2.65550 (A-MSE: 2.28678) avg lploss: 0.00000
==> test epoch 735 avg loss: 2.83053 (A-MSE: 2.45599) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 7 out of 50
train epoch 736 avg loss: 1.38966 (A-MSE: 1.24088) avg lploss: 0.00000
train epoch 737 avg loss: 0.83517 (A-MSE: 0.74749) avg lploss: 0.00000
train epoch 738 avg loss: 0.64583 (A-MSE: 0.57460) avg lploss: 0.00000
train epoch 739 avg loss: 0.58573 (A-MSE: 0.52161) avg lploss: 0.00000
train epoch 740 avg loss: 0.65832 (A-MSE: 0.58791) avg lploss: 0.00000
==> val epoch 740 avg loss: 1.42810 (A-MSE: 1.25087) avg lploss: 0.00000
==> test epoch 740 avg loss: 1.59684 (A-MSE: 1.40248) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 8 out of 50
train epoch 741 avg loss: 0.62919 (A-MSE: 0.56188) avg lploss: 0.00000
train epoch 742 avg loss: 0.67964 (A-MSE: 0.60471) avg lploss: 0.00000
train epoch 743 avg loss: 0.59807 (A-MSE: 0.53089) avg lploss: 0.00000
train epoch 744 avg loss: 0.60329 (A-MSE: 0.53664) avg lploss: 0.00000
train epoch 745 avg loss: 0.65480 (A-MSE: 0.58465) avg lploss: 0.00000
==> val epoch 745 avg loss: 1.34872 (A-MSE: 1.21054) avg lploss: 0.00000
==> test epoch 745 avg loss: 1.45715 (A-MSE: 1.29831) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 9 out of 50
train epoch 746 avg loss: 0.64987 (A-MSE: 0.58157) avg lploss: 0.00000
train epoch 747 avg loss: 0.60489 (A-MSE: 0.53886) avg lploss: 0.00000
train epoch 748 avg loss: 0.76802 (A-MSE: 0.68587) avg lploss: 0.00000
train epoch 749 avg loss: 0.66871 (A-MSE: 0.59487) avg lploss: 0.00000
train epoch 750 avg loss: 0.62999 (A-MSE: 0.55971) avg lploss: 0.00000
==> val epoch 750 avg loss: 1.30448 (A-MSE: 1.14705) avg lploss: 0.00000
==> test epoch 750 avg loss: 1.42643 (A-MSE: 1.25596) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 10 out of 50
train epoch 751 avg loss: 0.55360 (A-MSE: 0.49490) avg lploss: 0.00000
train epoch 752 avg loss: 0.58194 (A-MSE: 0.51836) avg lploss: 0.00000
train epoch 753 avg loss: 0.54169 (A-MSE: 0.48172) avg lploss: 0.00000
train epoch 754 avg loss: 0.60350 (A-MSE: 0.53553) avg lploss: 0.00000
train epoch 755 avg loss: 0.63294 (A-MSE: 0.56070) avg lploss: 0.00000
==> val epoch 755 avg loss: 1.37674 (A-MSE: 1.22514) avg lploss: 0.00000
==> test epoch 755 avg loss: 1.54305 (A-MSE: 1.37044) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 11 out of 50
train epoch 756 avg loss: 0.66575 (A-MSE: 0.59570) avg lploss: 0.00000
train epoch 757 avg loss: 0.60822 (A-MSE: 0.54182) avg lploss: 0.00000
train epoch 758 avg loss: 0.59481 (A-MSE: 0.53007) avg lploss: 0.00000
train epoch 759 avg loss: 0.55717 (A-MSE: 0.49474) avg lploss: 0.00000
train epoch 760 avg loss: 0.59255 (A-MSE: 0.52679) avg lploss: 0.00000
==> val epoch 760 avg loss: 1.30174 (A-MSE: 1.15400) avg lploss: 0.00000
==> test epoch 760 avg loss: 1.39088 (A-MSE: 1.23568) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 12 out of 50
train epoch 761 avg loss: 0.54626 (A-MSE: 0.48636) avg lploss: 0.00000
train epoch 762 avg loss: 0.55458 (A-MSE: 0.49151) avg lploss: 0.00000
train epoch 763 avg loss: 0.55749 (A-MSE: 0.49386) avg lploss: 0.00000
train epoch 764 avg loss: 0.57053 (A-MSE: 0.50669) avg lploss: 0.00000
train epoch 765 avg loss: 0.53195 (A-MSE: 0.47250) avg lploss: 0.00000
==> val epoch 765 avg loss: 1.45612 (A-MSE: 1.27358) avg lploss: 0.00000
==> test epoch 765 avg loss: 1.59691 (A-MSE: 1.40772) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 13 out of 50
train epoch 766 avg loss: 0.55343 (A-MSE: 0.49028) avg lploss: 0.00000
train epoch 767 avg loss: 0.65113 (A-MSE: 0.58166) avg lploss: 0.00000
train epoch 768 avg loss: 0.64288 (A-MSE: 0.57494) avg lploss: 0.00000
train epoch 769 avg loss: 0.61641 (A-MSE: 0.55275) avg lploss: 0.00000
train epoch 770 avg loss: 0.54400 (A-MSE: 0.48482) avg lploss: 0.00000
==> val epoch 770 avg loss: 1.29577 (A-MSE: 1.15121) avg lploss: 0.00000
==> test epoch 770 avg loss: 1.38938 (A-MSE: 1.23218) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 14 out of 50
train epoch 771 avg loss: 0.56972 (A-MSE: 0.50824) avg lploss: 0.00000
train epoch 772 avg loss: 0.51039 (A-MSE: 0.45531) avg lploss: 0.00000
train epoch 773 avg loss: 0.52388 (A-MSE: 0.46613) avg lploss: 0.00000
train epoch 774 avg loss: 0.57416 (A-MSE: 0.51052) avg lploss: 0.00000
train epoch 775 avg loss: 0.55283 (A-MSE: 0.49367) avg lploss: 0.00000
==> val epoch 775 avg loss: 1.47534 (A-MSE: 1.31733) avg lploss: 0.00000
==> test epoch 775 avg loss: 1.66705 (A-MSE: 1.48844) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 15 out of 50
train epoch 776 avg loss: 0.54688 (A-MSE: 0.48693) avg lploss: 0.00000
train epoch 777 avg loss: 0.58749 (A-MSE: 0.52150) avg lploss: 0.00000
train epoch 778 avg loss: 0.52987 (A-MSE: 0.47125) avg lploss: 0.00000
train epoch 779 avg loss: 0.55444 (A-MSE: 0.49467) avg lploss: 0.00000
train epoch 780 avg loss: 0.61512 (A-MSE: 0.55158) avg lploss: 0.00000
==> val epoch 780 avg loss: 1.38281 (A-MSE: 1.22104) avg lploss: 0.00000
==> test epoch 780 avg loss: 1.54591 (A-MSE: 1.36548) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 16 out of 50
train epoch 781 avg loss: 0.58399 (A-MSE: 0.51844) avg lploss: 0.00000
train epoch 782 avg loss: 0.55524 (A-MSE: 0.49501) avg lploss: 0.00000
train epoch 783 avg loss: 0.51603 (A-MSE: 0.45983) avg lploss: 0.00000
train epoch 784 avg loss: 0.53161 (A-MSE: 0.47209) avg lploss: 0.00000
train epoch 785 avg loss: 0.58953 (A-MSE: 0.52394) avg lploss: 0.00000
==> val epoch 785 avg loss: 1.29721 (A-MSE: 1.14647) avg lploss: 0.00000
==> test epoch 785 avg loss: 1.41466 (A-MSE: 1.25738) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 17 out of 50
train epoch 786 avg loss: 0.53546 (A-MSE: 0.47619) avg lploss: 0.00000
train epoch 787 avg loss: 0.62002 (A-MSE: 0.54942) avg lploss: 0.00000
train epoch 788 avg loss: 0.57507 (A-MSE: 0.51112) avg lploss: 0.00000
train epoch 789 avg loss: 0.57860 (A-MSE: 0.51508) avg lploss: 0.00000
train epoch 790 avg loss: 0.56261 (A-MSE: 0.50051) avg lploss: 0.00000
==> val epoch 790 avg loss: 1.38263 (A-MSE: 1.22252) avg lploss: 0.00000
==> test epoch 790 avg loss: 1.55559 (A-MSE: 1.38488) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 18 out of 50
train epoch 791 avg loss: 0.56161 (A-MSE: 0.49910) avg lploss: 0.00000
train epoch 792 avg loss: 0.58546 (A-MSE: 0.51946) avg lploss: 0.00000
train epoch 793 avg loss: 0.59285 (A-MSE: 0.52764) avg lploss: 0.00000
train epoch 794 avg loss: 0.57499 (A-MSE: 0.51210) avg lploss: 0.00000
train epoch 795 avg loss: 0.63866 (A-MSE: 0.57158) avg lploss: 0.00000
==> val epoch 795 avg loss: 1.81280 (A-MSE: 1.57739) avg lploss: 0.00000
==> test epoch 795 avg loss: 1.97929 (A-MSE: 1.74056) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 19 out of 50
train epoch 796 avg loss: 0.90509 (A-MSE: 0.80436) avg lploss: 0.00000
train epoch 797 avg loss: 0.68566 (A-MSE: 0.60938) avg lploss: 0.00000
train epoch 798 avg loss: 0.56781 (A-MSE: 0.50622) avg lploss: 0.00000
train epoch 799 avg loss: 0.49283 (A-MSE: 0.43922) avg lploss: 0.00000
train epoch 800 avg loss: 0.52633 (A-MSE: 0.46667) avg lploss: 0.00000
==> val epoch 800 avg loss: 1.54725 (A-MSE: 1.36086) avg lploss: 0.00000
==> test epoch 800 avg loss: 1.67703 (A-MSE: 1.48617) avg lploss: 0.00000
*** Best Val Loss: 1.27500 	 Best Test Loss: 1.42157 	 Best epoch 700
EarlyStopping counter: 20 out of 50
train epoch 801 avg loss: 0.51742 (A-MSE: 0.46028) avg lploss: 0.00000
train epoch 802 avg loss: 0.50298 (A-MSE: 0.44690) avg lploss: 0.00000
train epoch 803 avg loss: 0.53059 (A-MSE: 0.47150) avg lploss: 0.00000
train epoch 804 avg loss: 0.55036 (A-MSE: 0.48974) avg lploss: 0.00000
train epoch 805 avg loss: 0.56038 (A-MSE: 0.50144) avg lploss: 0.00000
==> val epoch 805 avg loss: 1.24804 (A-MSE: 1.10311) avg lploss: 0.00000
==> test epoch 805 avg loss: 1.42433 (A-MSE: 1.26808) avg lploss: 0.00000
*** Best Val Loss: 1.24804 	 Best Test Loss: 1.42433 	 Best epoch 805
Validation loss decreased (1.275003 --> 1.248044).  Saving model ...
train epoch 806 avg loss: 0.50196 (A-MSE: 0.44659) avg lploss: 0.00000
train epoch 807 avg loss: 0.63862 (A-MSE: 0.57040) avg lploss: 0.00000
train epoch 808 avg loss: 0.60868 (A-MSE: 0.54161) avg lploss: 0.00000
train epoch 809 avg loss: 0.54474 (A-MSE: 0.48959) avg lploss: 0.00000
train epoch 810 avg loss: 0.53796 (A-MSE: 0.47884) avg lploss: 0.00000
==> val epoch 810 avg loss: 1.35357 (A-MSE: 1.18830) avg lploss: 0.00000
==> test epoch 810 avg loss: 1.53496 (A-MSE: 1.36451) avg lploss: 0.00000
*** Best Val Loss: 1.24804 	 Best Test Loss: 1.42433 	 Best epoch 805
EarlyStopping counter: 1 out of 50
train epoch 811 avg loss: 0.46170 (A-MSE: 0.41057) avg lploss: 0.00000
train epoch 812 avg loss: 0.49433 (A-MSE: 0.44031) avg lploss: 0.00000
train epoch 813 avg loss: 0.57406 (A-MSE: 0.51285) avg lploss: 0.00000
train epoch 814 avg loss: 0.51710 (A-MSE: 0.46085) avg lploss: 0.00000
train epoch 815 avg loss: 0.61277 (A-MSE: 0.54737) avg lploss: 0.00000
==> val epoch 815 avg loss: 1.29251 (A-MSE: 1.15273) avg lploss: 0.00000
==> test epoch 815 avg loss: 1.46178 (A-MSE: 1.30899) avg lploss: 0.00000
*** Best Val Loss: 1.24804 	 Best Test Loss: 1.42433 	 Best epoch 805
EarlyStopping counter: 2 out of 50
train epoch 816 avg loss: 0.61045 (A-MSE: 0.54345) avg lploss: 0.00000
train epoch 817 avg loss: 0.60233 (A-MSE: 0.53486) avg lploss: 0.00000
train epoch 818 avg loss: 0.55335 (A-MSE: 0.49388) avg lploss: 0.00000
train epoch 819 avg loss: 0.51042 (A-MSE: 0.45385) avg lploss: 0.00000
train epoch 820 avg loss: 0.54439 (A-MSE: 0.48565) avg lploss: 0.00000
==> val epoch 820 avg loss: 1.45343 (A-MSE: 1.27968) avg lploss: 0.00000
==> test epoch 820 avg loss: 1.60829 (A-MSE: 1.42926) avg lploss: 0.00000
*** Best Val Loss: 1.24804 	 Best Test Loss: 1.42433 	 Best epoch 805
EarlyStopping counter: 3 out of 50
train epoch 821 avg loss: 0.59181 (A-MSE: 0.52713) avg lploss: 0.00000
train epoch 822 avg loss: 0.58917 (A-MSE: 0.52696) avg lploss: 0.00000
train epoch 823 avg loss: 0.51182 (A-MSE: 0.45599) avg lploss: 0.00000
train epoch 824 avg loss: 0.51595 (A-MSE: 0.45843) avg lploss: 0.00000
train epoch 825 avg loss: 0.52597 (A-MSE: 0.46663) avg lploss: 0.00000
==> val epoch 825 avg loss: 1.24792 (A-MSE: 1.11140) avg lploss: 0.00000
==> test epoch 825 avg loss: 1.39147 (A-MSE: 1.24540) avg lploss: 0.00000
*** Best Val Loss: 1.24792 	 Best Test Loss: 1.39147 	 Best epoch 825
Validation loss decreased (1.248044 --> 1.247922).  Saving model ...
train epoch 826 avg loss: 0.58649 (A-MSE: 0.52496) avg lploss: 0.00000
train epoch 827 avg loss: 0.79286 (A-MSE: 0.70826) avg lploss: 0.00000
train epoch 828 avg loss: 0.56962 (A-MSE: 0.51293) avg lploss: 0.00000
train epoch 829 avg loss: 0.61601 (A-MSE: 0.55003) avg lploss: 0.00000
train epoch 830 avg loss: 0.60668 (A-MSE: 0.54195) avg lploss: 0.00000
==> val epoch 830 avg loss: 1.39326 (A-MSE: 1.22552) avg lploss: 0.00000
==> test epoch 830 avg loss: 1.56096 (A-MSE: 1.38332) avg lploss: 0.00000
*** Best Val Loss: 1.24792 	 Best Test Loss: 1.39147 	 Best epoch 825
EarlyStopping counter: 1 out of 50
train epoch 831 avg loss: 0.55758 (A-MSE: 0.49509) avg lploss: 0.00000
train epoch 832 avg loss: 0.54423 (A-MSE: 0.48663) avg lploss: 0.00000
train epoch 833 avg loss: 0.51139 (A-MSE: 0.45607) avg lploss: 0.00000
train epoch 834 avg loss: 0.47599 (A-MSE: 0.42287) avg lploss: 0.00000
train epoch 835 avg loss: 0.50041 (A-MSE: 0.44677) avg lploss: 0.00000
==> val epoch 835 avg loss: 1.40902 (A-MSE: 1.24988) avg lploss: 0.00000
==> test epoch 835 avg loss: 1.56520 (A-MSE: 1.39802) avg lploss: 0.00000
*** Best Val Loss: 1.24792 	 Best Test Loss: 1.39147 	 Best epoch 825
EarlyStopping counter: 2 out of 50
train epoch 836 avg loss: 0.52907 (A-MSE: 0.47366) avg lploss: 0.00000
train epoch 837 avg loss: 0.54126 (A-MSE: 0.48116) avg lploss: 0.00000
train epoch 838 avg loss: 0.53309 (A-MSE: 0.47567) avg lploss: 0.00000
train epoch 839 avg loss: 0.52806 (A-MSE: 0.47071) avg lploss: 0.00000
train epoch 840 avg loss: 0.64202 (A-MSE: 0.57504) avg lploss: 0.00000
==> val epoch 840 avg loss: 1.26118 (A-MSE: 1.11784) avg lploss: 0.00000
==> test epoch 840 avg loss: 1.38599 (A-MSE: 1.23642) avg lploss: 0.00000
*** Best Val Loss: 1.24792 	 Best Test Loss: 1.39147 	 Best epoch 825
EarlyStopping counter: 3 out of 50
train epoch 841 avg loss: 0.55503 (A-MSE: 0.49598) avg lploss: 0.00000
train epoch 842 avg loss: 0.50650 (A-MSE: 0.45093) avg lploss: 0.00000
train epoch 843 avg loss: 0.52706 (A-MSE: 0.46819) avg lploss: 0.00000
train epoch 844 avg loss: 0.53037 (A-MSE: 0.47286) avg lploss: 0.00000
train epoch 845 avg loss: 0.55701 (A-MSE: 0.49589) avg lploss: 0.00000
==> val epoch 845 avg loss: 1.54180 (A-MSE: 1.34533) avg lploss: 0.00000
==> test epoch 845 avg loss: 1.63964 (A-MSE: 1.44878) avg lploss: 0.00000
*** Best Val Loss: 1.24792 	 Best Test Loss: 1.39147 	 Best epoch 825
EarlyStopping counter: 4 out of 50
train epoch 846 avg loss: 0.54674 (A-MSE: 0.48629) avg lploss: 0.00000
train epoch 847 avg loss: 0.51914 (A-MSE: 0.46197) avg lploss: 0.00000
train epoch 848 avg loss: 0.54702 (A-MSE: 0.48681) avg lploss: 0.00000
train epoch 849 avg loss: 0.49548 (A-MSE: 0.44044) avg lploss: 0.00000
train epoch 850 avg loss: 0.55164 (A-MSE: 0.49257) avg lploss: 0.00000
==> val epoch 850 avg loss: 1.46183 (A-MSE: 1.28183) avg lploss: 0.00000
==> test epoch 850 avg loss: 1.64540 (A-MSE: 1.44847) avg lploss: 0.00000
*** Best Val Loss: 1.24792 	 Best Test Loss: 1.39147 	 Best epoch 825
EarlyStopping counter: 5 out of 50
train epoch 851 avg loss: 0.52397 (A-MSE: 0.46800) avg lploss: 0.00000
train epoch 852 avg loss: 0.51906 (A-MSE: 0.46237) avg lploss: 0.00000
train epoch 853 avg loss: 0.46845 (A-MSE: 0.41565) avg lploss: 0.00000
train epoch 854 avg loss: 0.53052 (A-MSE: 0.47351) avg lploss: 0.00000
train epoch 855 avg loss: 0.52485 (A-MSE: 0.46794) avg lploss: 0.00000
==> val epoch 855 avg loss: 1.21277 (A-MSE: 1.06346) avg lploss: 0.00000
==> test epoch 855 avg loss: 1.33563 (A-MSE: 1.18420) avg lploss: 0.00000
*** Best Val Loss: 1.21277 	 Best Test Loss: 1.33563 	 Best epoch 855
Validation loss decreased (1.247922 --> 1.212769).  Saving model ...
train epoch 856 avg loss: 0.46804 (A-MSE: 0.41650) avg lploss: 0.00000
train epoch 857 avg loss: 0.46625 (A-MSE: 0.41543) avg lploss: 0.00000
train epoch 858 avg loss: 0.52989 (A-MSE: 0.47277) avg lploss: 0.00000
train epoch 859 avg loss: 0.46501 (A-MSE: 0.41114) avg lploss: 0.00000
train epoch 860 avg loss: 0.49608 (A-MSE: 0.44113) avg lploss: 0.00000
==> val epoch 860 avg loss: 1.41716 (A-MSE: 1.23508) avg lploss: 0.00000
==> test epoch 860 avg loss: 1.55626 (A-MSE: 1.37393) avg lploss: 0.00000
*** Best Val Loss: 1.21277 	 Best Test Loss: 1.33563 	 Best epoch 855
EarlyStopping counter: 1 out of 50
train epoch 861 avg loss: 0.54565 (A-MSE: 0.48828) avg lploss: 0.00000
train epoch 862 avg loss: 0.52326 (A-MSE: 0.46712) avg lploss: 0.00000
train epoch 863 avg loss: 0.50291 (A-MSE: 0.44798) avg lploss: 0.00000
train epoch 864 avg loss: 0.47462 (A-MSE: 0.42350) avg lploss: 0.00000
train epoch 865 avg loss: 0.52290 (A-MSE: 0.46627) avg lploss: 0.00000
==> val epoch 865 avg loss: 1.26512 (A-MSE: 1.11720) avg lploss: 0.00000
==> test epoch 865 avg loss: 1.37623 (A-MSE: 1.21870) avg lploss: 0.00000
*** Best Val Loss: 1.21277 	 Best Test Loss: 1.33563 	 Best epoch 855
EarlyStopping counter: 2 out of 50
train epoch 866 avg loss: 0.51729 (A-MSE: 0.46318) avg lploss: 0.00000
train epoch 867 avg loss: 0.48625 (A-MSE: 0.43560) avg lploss: 0.00000
train epoch 868 avg loss: 0.52138 (A-MSE: 0.46732) avg lploss: 0.00000
train epoch 869 avg loss: 0.53137 (A-MSE: 0.47390) avg lploss: 0.00000
train epoch 870 avg loss: 0.48468 (A-MSE: 0.43123) avg lploss: 0.00000
==> val epoch 870 avg loss: 1.27303 (A-MSE: 1.13000) avg lploss: 0.00000
==> test epoch 870 avg loss: 1.36666 (A-MSE: 1.22283) avg lploss: 0.00000
*** Best Val Loss: 1.21277 	 Best Test Loss: 1.33563 	 Best epoch 855
EarlyStopping counter: 3 out of 50
train epoch 871 avg loss: 0.50826 (A-MSE: 0.45557) avg lploss: 0.00000
train epoch 872 avg loss: 0.54663 (A-MSE: 0.48872) avg lploss: 0.00000
train epoch 873 avg loss: 0.59047 (A-MSE: 0.52621) avg lploss: 0.00000
train epoch 874 avg loss: 0.60959 (A-MSE: 0.54446) avg lploss: 0.00000
train epoch 875 avg loss: 0.58319 (A-MSE: 0.51737) avg lploss: 0.00000
==> val epoch 875 avg loss: 1.35453 (A-MSE: 1.19331) avg lploss: 0.00000
==> test epoch 875 avg loss: 1.52318 (A-MSE: 1.34906) avg lploss: 0.00000
*** Best Val Loss: 1.21277 	 Best Test Loss: 1.33563 	 Best epoch 855
EarlyStopping counter: 4 out of 50
train epoch 876 avg loss: 0.48134 (A-MSE: 0.42932) avg lploss: 0.00000
train epoch 877 avg loss: 0.46532 (A-MSE: 0.41391) avg lploss: 0.00000
train epoch 878 avg loss: 0.44225 (A-MSE: 0.39223) avg lploss: 0.00000
train epoch 879 avg loss: 0.45111 (A-MSE: 0.40150) avg lploss: 0.00000
train epoch 880 avg loss: 0.47914 (A-MSE: 0.42769) avg lploss: 0.00000
==> val epoch 880 avg loss: 1.19266 (A-MSE: 1.05824) avg lploss: 0.00000
==> test epoch 880 avg loss: 1.31815 (A-MSE: 1.16783) avg lploss: 0.00000
*** Best Val Loss: 1.19266 	 Best Test Loss: 1.31815 	 Best epoch 880
Validation loss decreased (1.212769 --> 1.192662).  Saving model ...
train epoch 881 avg loss: 0.49290 (A-MSE: 0.44131) avg lploss: 0.00000
train epoch 882 avg loss: 0.49582 (A-MSE: 0.44135) avg lploss: 0.00000
train epoch 883 avg loss: 0.47612 (A-MSE: 0.42585) avg lploss: 0.00000
train epoch 884 avg loss: 0.43365 (A-MSE: 0.38677) avg lploss: 0.00000
train epoch 885 avg loss: 0.50404 (A-MSE: 0.45057) avg lploss: 0.00000
==> val epoch 885 avg loss: 1.28916 (A-MSE: 1.12436) avg lploss: 0.00000
==> test epoch 885 avg loss: 1.39981 (A-MSE: 1.23683) avg lploss: 0.00000
*** Best Val Loss: 1.19266 	 Best Test Loss: 1.31815 	 Best epoch 880
EarlyStopping counter: 1 out of 50
train epoch 886 avg loss: 0.46726 (A-MSE: 0.41548) avg lploss: 0.00000
train epoch 887 avg loss: 0.53387 (A-MSE: 0.47312) avg lploss: 0.00000
train epoch 888 avg loss: 0.53955 (A-MSE: 0.48192) avg lploss: 0.00000
train epoch 889 avg loss: 0.51889 (A-MSE: 0.46126) avg lploss: 0.00000
train epoch 890 avg loss: 0.44426 (A-MSE: 0.39334) avg lploss: 0.00000
==> val epoch 890 avg loss: 1.42527 (A-MSE: 1.24857) avg lploss: 0.00000
==> test epoch 890 avg loss: 1.58368 (A-MSE: 1.39687) avg lploss: 0.00000
*** Best Val Loss: 1.19266 	 Best Test Loss: 1.31815 	 Best epoch 880
EarlyStopping counter: 2 out of 50
train epoch 891 avg loss: 0.59234 (A-MSE: 0.52807) avg lploss: 0.00000
train epoch 892 avg loss: 0.57469 (A-MSE: 0.51615) avg lploss: 0.00000
train epoch 893 avg loss: 0.48298 (A-MSE: 0.42984) avg lploss: 0.00000
train epoch 894 avg loss: 0.50812 (A-MSE: 0.45434) avg lploss: 0.00000
train epoch 895 avg loss: 0.48646 (A-MSE: 0.43086) avg lploss: 0.00000
==> val epoch 895 avg loss: 1.33084 (A-MSE: 1.17031) avg lploss: 0.00000
==> test epoch 895 avg loss: 1.51212 (A-MSE: 1.34052) avg lploss: 0.00000
*** Best Val Loss: 1.19266 	 Best Test Loss: 1.31815 	 Best epoch 880
EarlyStopping counter: 3 out of 50
train epoch 896 avg loss: 0.49228 (A-MSE: 0.43831) avg lploss: 0.00000
train epoch 897 avg loss: 0.50860 (A-MSE: 0.45266) avg lploss: 0.00000
train epoch 898 avg loss: 0.50692 (A-MSE: 0.45275) avg lploss: 0.00000
train epoch 899 avg loss: 0.48661 (A-MSE: 0.43392) avg lploss: 0.00000
train epoch 900 avg loss: 0.48562 (A-MSE: 0.43365) avg lploss: 0.00000
==> val epoch 900 avg loss: 1.44544 (A-MSE: 1.25578) avg lploss: 0.00000
==> test epoch 900 avg loss: 1.62951 (A-MSE: 1.41871) avg lploss: 0.00000
*** Best Val Loss: 1.19266 	 Best Test Loss: 1.31815 	 Best epoch 880
EarlyStopping counter: 4 out of 50
train epoch 901 avg loss: 0.43133 (A-MSE: 0.38357) avg lploss: 0.00000
train epoch 902 avg loss: 0.43003 (A-MSE: 0.38321) avg lploss: 0.00000
train epoch 903 avg loss: 0.48101 (A-MSE: 0.42834) avg lploss: 0.00000
train epoch 904 avg loss: 0.46271 (A-MSE: 0.41164) avg lploss: 0.00000
train epoch 905 avg loss: 0.46621 (A-MSE: 0.41524) avg lploss: 0.00000
==> val epoch 905 avg loss: 1.14390 (A-MSE: 1.01277) avg lploss: 0.00000
==> test epoch 905 avg loss: 1.31740 (A-MSE: 1.18182) avg lploss: 0.00000
*** Best Val Loss: 1.14390 	 Best Test Loss: 1.31740 	 Best epoch 905
Validation loss decreased (1.192662 --> 1.143895).  Saving model ...
train epoch 906 avg loss: 0.50223 (A-MSE: 0.44892) avg lploss: 0.00000
train epoch 907 avg loss: 0.43552 (A-MSE: 0.38776) avg lploss: 0.00000
train epoch 908 avg loss: 0.42192 (A-MSE: 0.37629) avg lploss: 0.00000
train epoch 909 avg loss: 0.46702 (A-MSE: 0.41883) avg lploss: 0.00000
train epoch 910 avg loss: 0.41999 (A-MSE: 0.37368) avg lploss: 0.00000
==> val epoch 910 avg loss: 1.13207 (A-MSE: 1.01139) avg lploss: 0.00000
==> test epoch 910 avg loss: 1.30152 (A-MSE: 1.16799) avg lploss: 0.00000
*** Best Val Loss: 1.13207 	 Best Test Loss: 1.30152 	 Best epoch 910
Validation loss decreased (1.143895 --> 1.132066).  Saving model ...
train epoch 911 avg loss: 0.45517 (A-MSE: 0.40688) avg lploss: 0.00000
train epoch 912 avg loss: 0.45825 (A-MSE: 0.41070) avg lploss: 0.00000
train epoch 913 avg loss: 0.43832 (A-MSE: 0.39011) avg lploss: 0.00000
train epoch 914 avg loss: 0.46942 (A-MSE: 0.41834) avg lploss: 0.00000
train epoch 915 avg loss: 0.46424 (A-MSE: 0.41416) avg lploss: 0.00000
==> val epoch 915 avg loss: 1.28405 (A-MSE: 1.12380) avg lploss: 0.00000
==> test epoch 915 avg loss: 1.36251 (A-MSE: 1.20584) avg lploss: 0.00000
*** Best Val Loss: 1.13207 	 Best Test Loss: 1.30152 	 Best epoch 910
EarlyStopping counter: 1 out of 50
train epoch 916 avg loss: 0.44541 (A-MSE: 0.39783) avg lploss: 0.00000
train epoch 917 avg loss: 0.49075 (A-MSE: 0.43814) avg lploss: 0.00000
train epoch 918 avg loss: 0.47746 (A-MSE: 0.42526) avg lploss: 0.00000
train epoch 919 avg loss: 0.45129 (A-MSE: 0.40302) avg lploss: 0.00000
train epoch 920 avg loss: 0.48768 (A-MSE: 0.43571) avg lploss: 0.00000
==> val epoch 920 avg loss: 1.21051 (A-MSE: 1.06622) avg lploss: 0.00000
==> test epoch 920 avg loss: 1.35836 (A-MSE: 1.20734) avg lploss: 0.00000
*** Best Val Loss: 1.13207 	 Best Test Loss: 1.30152 	 Best epoch 910
EarlyStopping counter: 2 out of 50
train epoch 921 avg loss: 0.48226 (A-MSE: 0.43044) avg lploss: 0.00000
train epoch 922 avg loss: 0.45628 (A-MSE: 0.40804) avg lploss: 0.00000
train epoch 923 avg loss: 0.52911 (A-MSE: 0.47252) avg lploss: 0.00000
train epoch 924 avg loss: 0.43906 (A-MSE: 0.39195) avg lploss: 0.00000
train epoch 925 avg loss: 0.47065 (A-MSE: 0.41979) avg lploss: 0.00000
==> val epoch 925 avg loss: 1.09404 (A-MSE: 0.96468) avg lploss: 0.00000
==> test epoch 925 avg loss: 1.24258 (A-MSE: 1.10801) avg lploss: 0.00000
*** Best Val Loss: 1.09404 	 Best Test Loss: 1.24258 	 Best epoch 925
Validation loss decreased (1.132066 --> 1.094041).  Saving model ...
train epoch 926 avg loss: 0.47943 (A-MSE: 0.42981) avg lploss: 0.00000
train epoch 927 avg loss: 0.44248 (A-MSE: 0.39477) avg lploss: 0.00000
train epoch 928 avg loss: 0.44117 (A-MSE: 0.39349) avg lploss: 0.00000
train epoch 929 avg loss: 0.49673 (A-MSE: 0.44538) avg lploss: 0.00000
train epoch 930 avg loss: 0.46254 (A-MSE: 0.41288) avg lploss: 0.00000
==> val epoch 930 avg loss: 1.12992 (A-MSE: 1.00124) avg lploss: 0.00000
==> test epoch 930 avg loss: 1.34596 (A-MSE: 1.19979) avg lploss: 0.00000
*** Best Val Loss: 1.09404 	 Best Test Loss: 1.24258 	 Best epoch 925
EarlyStopping counter: 1 out of 50
train epoch 931 avg loss: 0.46763 (A-MSE: 0.41766) avg lploss: 0.00000
train epoch 932 avg loss: 0.56343 (A-MSE: 0.50332) avg lploss: 0.00000
train epoch 933 avg loss: 0.47218 (A-MSE: 0.42317) avg lploss: 0.00000
train epoch 934 avg loss: 0.43361 (A-MSE: 0.38729) avg lploss: 0.00000
train epoch 935 avg loss: 0.44316 (A-MSE: 0.39422) avg lploss: 0.00000
==> val epoch 935 avg loss: 1.29526 (A-MSE: 1.15176) avg lploss: 0.00000
==> test epoch 935 avg loss: 1.42015 (A-MSE: 1.26775) avg lploss: 0.00000
*** Best Val Loss: 1.09404 	 Best Test Loss: 1.24258 	 Best epoch 925
EarlyStopping counter: 2 out of 50
train epoch 936 avg loss: 0.43640 (A-MSE: 0.39011) avg lploss: 0.00000
train epoch 937 avg loss: 0.45197 (A-MSE: 0.40279) avg lploss: 0.00000
train epoch 938 avg loss: 0.46631 (A-MSE: 0.41519) avg lploss: 0.00000
train epoch 939 avg loss: 0.48418 (A-MSE: 0.43094) avg lploss: 0.00000
train epoch 940 avg loss: 0.47362 (A-MSE: 0.42199) avg lploss: 0.00000
==> val epoch 940 avg loss: 1.20770 (A-MSE: 1.06330) avg lploss: 0.00000
==> test epoch 940 avg loss: 1.33124 (A-MSE: 1.18540) avg lploss: 0.00000
*** Best Val Loss: 1.09404 	 Best Test Loss: 1.24258 	 Best epoch 925
EarlyStopping counter: 3 out of 50
train epoch 941 avg loss: 0.42237 (A-MSE: 0.37472) avg lploss: 0.00000
train epoch 942 avg loss: 0.42819 (A-MSE: 0.38217) avg lploss: 0.00000
train epoch 943 avg loss: 0.45273 (A-MSE: 0.40448) avg lploss: 0.00000
train epoch 944 avg loss: 0.49925 (A-MSE: 0.44347) avg lploss: 0.00000
train epoch 945 avg loss: 0.58897 (A-MSE: 0.52442) avg lploss: 0.00000
==> val epoch 945 avg loss: 1.24168 (A-MSE: 1.11036) avg lploss: 0.00000
==> test epoch 945 avg loss: 1.45222 (A-MSE: 1.30213) avg lploss: 0.00000
*** Best Val Loss: 1.09404 	 Best Test Loss: 1.24258 	 Best epoch 925
EarlyStopping counter: 4 out of 50
train epoch 946 avg loss: 0.57066 (A-MSE: 0.51098) avg lploss: 0.00000
train epoch 947 avg loss: 0.52249 (A-MSE: 0.46779) avg lploss: 0.00000
train epoch 948 avg loss: 0.45696 (A-MSE: 0.40867) avg lploss: 0.00000
train epoch 949 avg loss: 0.41821 (A-MSE: 0.37165) avg lploss: 0.00000
train epoch 950 avg loss: 0.47717 (A-MSE: 0.42626) avg lploss: 0.00000
==> val epoch 950 avg loss: 1.58257 (A-MSE: 1.41914) avg lploss: 0.00000
==> test epoch 950 avg loss: 1.73257 (A-MSE: 1.55854) avg lploss: 0.00000
*** Best Val Loss: 1.09404 	 Best Test Loss: 1.24258 	 Best epoch 925
EarlyStopping counter: 5 out of 50
train epoch 951 avg loss: 0.43072 (A-MSE: 0.38489) avg lploss: 0.00000
train epoch 952 avg loss: 0.44103 (A-MSE: 0.39309) avg lploss: 0.00000
train epoch 953 avg loss: 0.45011 (A-MSE: 0.40299) avg lploss: 0.00000
train epoch 954 avg loss: 0.47535 (A-MSE: 0.42511) avg lploss: 0.00000
train epoch 955 avg loss: 0.42133 (A-MSE: 0.37535) avg lploss: 0.00000
==> val epoch 955 avg loss: 1.07923 (A-MSE: 0.96386) avg lploss: 0.00000
==> test epoch 955 avg loss: 1.28849 (A-MSE: 1.14944) avg lploss: 0.00000
*** Best Val Loss: 1.07923 	 Best Test Loss: 1.28849 	 Best epoch 955
Validation loss decreased (1.094041 --> 1.079228).  Saving model ...
train epoch 956 avg loss: 0.40844 (A-MSE: 0.36403) avg lploss: 0.00000
train epoch 957 avg loss: 0.40295 (A-MSE: 0.35924) avg lploss: 0.00000
train epoch 958 avg loss: 0.39756 (A-MSE: 0.35489) avg lploss: 0.00000
train epoch 959 avg loss: 0.39629 (A-MSE: 0.35185) avg lploss: 0.00000
train epoch 960 avg loss: 0.40177 (A-MSE: 0.35818) avg lploss: 0.00000
==> val epoch 960 avg loss: 1.37749 (A-MSE: 1.21938) avg lploss: 0.00000
==> test epoch 960 avg loss: 1.52480 (A-MSE: 1.35342) avg lploss: 0.00000
*** Best Val Loss: 1.07923 	 Best Test Loss: 1.28849 	 Best epoch 955
EarlyStopping counter: 1 out of 50
train epoch 961 avg loss: 0.44059 (A-MSE: 0.39403) avg lploss: 0.00000
train epoch 962 avg loss: 0.43518 (A-MSE: 0.38731) avg lploss: 0.00000
train epoch 963 avg loss: 0.42949 (A-MSE: 0.38313) avg lploss: 0.00000
train epoch 964 avg loss: 0.39125 (A-MSE: 0.34994) avg lploss: 0.00000
train epoch 965 avg loss: 0.41386 (A-MSE: 0.37165) avg lploss: 0.00000
==> val epoch 965 avg loss: 1.35514 (A-MSE: 1.20153) avg lploss: 0.00000
==> test epoch 965 avg loss: 1.46377 (A-MSE: 1.31086) avg lploss: 0.00000
*** Best Val Loss: 1.07923 	 Best Test Loss: 1.28849 	 Best epoch 955
EarlyStopping counter: 2 out of 50
train epoch 966 avg loss: 0.44719 (A-MSE: 0.39926) avg lploss: 0.00000
train epoch 967 avg loss: 0.44848 (A-MSE: 0.39924) avg lploss: 0.00000
train epoch 968 avg loss: 0.49742 (A-MSE: 0.44254) avg lploss: 0.00000
train epoch 969 avg loss: 0.52504 (A-MSE: 0.47015) avg lploss: 0.00000
train epoch 970 avg loss: 0.42935 (A-MSE: 0.38157) avg lploss: 0.00000
==> val epoch 970 avg loss: 1.29759 (A-MSE: 1.14363) avg lploss: 0.00000
==> test epoch 970 avg loss: 1.40346 (A-MSE: 1.24342) avg lploss: 0.00000
*** Best Val Loss: 1.07923 	 Best Test Loss: 1.28849 	 Best epoch 955
EarlyStopping counter: 3 out of 50
train epoch 971 avg loss: 0.41009 (A-MSE: 0.36677) avg lploss: 0.00000
train epoch 972 avg loss: 0.41030 (A-MSE: 0.36714) avg lploss: 0.00000
train epoch 973 avg loss: 0.41625 (A-MSE: 0.37408) avg lploss: 0.00000
train epoch 974 avg loss: 0.45268 (A-MSE: 0.40402) avg lploss: 0.00000
train epoch 975 avg loss: 0.46709 (A-MSE: 0.41715) avg lploss: 0.00000
==> val epoch 975 avg loss: 1.29331 (A-MSE: 1.15239) avg lploss: 0.00000
==> test epoch 975 avg loss: 1.38291 (A-MSE: 1.23516) avg lploss: 0.00000
*** Best Val Loss: 1.07923 	 Best Test Loss: 1.28849 	 Best epoch 955
EarlyStopping counter: 4 out of 50
train epoch 976 avg loss: 0.46261 (A-MSE: 0.41325) avg lploss: 0.00000
train epoch 977 avg loss: 0.45291 (A-MSE: 0.40021) avg lploss: 0.00000
train epoch 978 avg loss: 0.45897 (A-MSE: 0.41102) avg lploss: 0.00000
train epoch 979 avg loss: 0.44260 (A-MSE: 0.39753) avg lploss: 0.00000
train epoch 980 avg loss: 0.41993 (A-MSE: 0.37551) avg lploss: 0.00000
==> val epoch 980 avg loss: 1.22010 (A-MSE: 1.08481) avg lploss: 0.00000
==> test epoch 980 avg loss: 1.32085 (A-MSE: 1.17923) avg lploss: 0.00000
*** Best Val Loss: 1.07923 	 Best Test Loss: 1.28849 	 Best epoch 955
EarlyStopping counter: 5 out of 50
train epoch 981 avg loss: 0.41478 (A-MSE: 0.37049) avg lploss: 0.00000
train epoch 982 avg loss: 0.38304 (A-MSE: 0.34299) avg lploss: 0.00000
train epoch 983 avg loss: 0.39596 (A-MSE: 0.35363) avg lploss: 0.00000
train epoch 984 avg loss: 0.40367 (A-MSE: 0.35916) avg lploss: 0.00000
train epoch 985 avg loss: 0.38126 (A-MSE: 0.33990) avg lploss: 0.00000
==> val epoch 985 avg loss: 1.02392 (A-MSE: 0.91437) avg lploss: 0.00000
==> test epoch 985 avg loss: 1.21791 (A-MSE: 1.08749) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
Validation loss decreased (1.079228 --> 1.023919).  Saving model ...
train epoch 986 avg loss: 0.38628 (A-MSE: 0.34358) avg lploss: 0.00000
train epoch 987 avg loss: 0.47045 (A-MSE: 0.41740) avg lploss: 0.00000
train epoch 988 avg loss: 0.43040 (A-MSE: 0.38585) avg lploss: 0.00000
train epoch 989 avg loss: 0.42810 (A-MSE: 0.38330) avg lploss: 0.00000
train epoch 990 avg loss: 0.47593 (A-MSE: 0.42453) avg lploss: 0.00000
==> val epoch 990 avg loss: 1.27007 (A-MSE: 1.12169) avg lploss: 0.00000
==> test epoch 990 avg loss: 1.39365 (A-MSE: 1.23882) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 1 out of 50
train epoch 991 avg loss: 0.44151 (A-MSE: 0.39404) avg lploss: 0.00000
train epoch 992 avg loss: 0.46654 (A-MSE: 0.41426) avg lploss: 0.00000
train epoch 993 avg loss: 0.46833 (A-MSE: 0.42046) avg lploss: 0.00000
train epoch 994 avg loss: 0.54767 (A-MSE: 0.48503) avg lploss: 0.00000
train epoch 995 avg loss: 0.46657 (A-MSE: 0.41766) avg lploss: 0.00000
==> val epoch 995 avg loss: 1.25260 (A-MSE: 1.10057) avg lploss: 0.00000
==> test epoch 995 avg loss: 1.44380 (A-MSE: 1.27498) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 2 out of 50
train epoch 996 avg loss: 0.40365 (A-MSE: 0.36314) avg lploss: 0.00000
train epoch 997 avg loss: 0.42133 (A-MSE: 0.37693) avg lploss: 0.00000
train epoch 998 avg loss: 0.40689 (A-MSE: 0.35994) avg lploss: 0.00000
train epoch 999 avg loss: 0.40843 (A-MSE: 0.36433) avg lploss: 0.00000
train epoch 1000 avg loss: 0.40815 (A-MSE: 0.36678) avg lploss: 0.00000
==> val epoch 1000 avg loss: 1.03013 (A-MSE: 0.92214) avg lploss: 0.00000
==> test epoch 1000 avg loss: 1.19150 (A-MSE: 1.06802) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 3 out of 50
train epoch 1001 avg loss: 0.41738 (A-MSE: 0.37397) avg lploss: 0.00000
train epoch 1002 avg loss: 0.40393 (A-MSE: 0.35931) avg lploss: 0.00000
train epoch 1003 avg loss: 0.38292 (A-MSE: 0.34058) avg lploss: 0.00000
train epoch 1004 avg loss: 0.39363 (A-MSE: 0.35260) avg lploss: 0.00000
train epoch 1005 avg loss: 0.44610 (A-MSE: 0.39853) avg lploss: 0.00000
==> val epoch 1005 avg loss: 1.15626 (A-MSE: 1.01973) avg lploss: 0.00000
==> test epoch 1005 avg loss: 1.28511 (A-MSE: 1.14145) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 4 out of 50
train epoch 1006 avg loss: 0.38073 (A-MSE: 0.33797) avg lploss: 0.00000
train epoch 1007 avg loss: 0.44412 (A-MSE: 0.39750) avg lploss: 0.00000
train epoch 1008 avg loss: 0.42937 (A-MSE: 0.37994) avg lploss: 0.00000
train epoch 1009 avg loss: 0.43589 (A-MSE: 0.38969) avg lploss: 0.00000
train epoch 1010 avg loss: 0.43825 (A-MSE: 0.39292) avg lploss: 0.00000
==> val epoch 1010 avg loss: 1.20227 (A-MSE: 1.07343) avg lploss: 0.00000
==> test epoch 1010 avg loss: 1.28663 (A-MSE: 1.14558) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 5 out of 50
train epoch 1011 avg loss: 0.38257 (A-MSE: 0.33878) avg lploss: 0.00000
train epoch 1012 avg loss: 0.41266 (A-MSE: 0.36726) avg lploss: 0.00000
train epoch 1013 avg loss: 0.37311 (A-MSE: 0.33344) avg lploss: 0.00000
train epoch 1014 avg loss: 0.35124 (A-MSE: 0.31316) avg lploss: 0.00000
train epoch 1015 avg loss: 0.80798 (A-MSE: 0.72108) avg lploss: 0.00000
==> val epoch 1015 avg loss: 1.43181 (A-MSE: 1.26542) avg lploss: 0.00000
==> test epoch 1015 avg loss: 1.49640 (A-MSE: 1.32732) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 6 out of 50
train epoch 1016 avg loss: 0.55162 (A-MSE: 0.49377) avg lploss: 0.00000
train epoch 1017 avg loss: 0.43387 (A-MSE: 0.38844) avg lploss: 0.00000
train epoch 1018 avg loss: 0.44365 (A-MSE: 0.39470) avg lploss: 0.00000
train epoch 1019 avg loss: 0.41096 (A-MSE: 0.36518) avg lploss: 0.00000
train epoch 1020 avg loss: 0.37046 (A-MSE: 0.33170) avg lploss: 0.00000
==> val epoch 1020 avg loss: 1.17938 (A-MSE: 1.05038) avg lploss: 0.00000
==> test epoch 1020 avg loss: 1.30325 (A-MSE: 1.16141) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 7 out of 50
train epoch 1021 avg loss: 0.40413 (A-MSE: 0.36062) avg lploss: 0.00000
train epoch 1022 avg loss: 0.38835 (A-MSE: 0.34729) avg lploss: 0.00000
train epoch 1023 avg loss: 0.39378 (A-MSE: 0.35238) avg lploss: 0.00000
train epoch 1024 avg loss: 0.44318 (A-MSE: 0.39260) avg lploss: 0.00000
train epoch 1025 avg loss: 0.37375 (A-MSE: 0.33391) avg lploss: 0.00000
==> val epoch 1025 avg loss: 1.10177 (A-MSE: 0.98295) avg lploss: 0.00000
==> test epoch 1025 avg loss: 1.24713 (A-MSE: 1.11343) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 8 out of 50
train epoch 1026 avg loss: 0.35075 (A-MSE: 0.31367) avg lploss: 0.00000
train epoch 1027 avg loss: 0.40128 (A-MSE: 0.35726) avg lploss: 0.00000
train epoch 1028 avg loss: 0.46879 (A-MSE: 0.41672) avg lploss: 0.00000
train epoch 1029 avg loss: 0.41666 (A-MSE: 0.37300) avg lploss: 0.00000
train epoch 1030 avg loss: 0.43413 (A-MSE: 0.38735) avg lploss: 0.00000
==> val epoch 1030 avg loss: 1.26768 (A-MSE: 1.12938) avg lploss: 0.00000
==> test epoch 1030 avg loss: 1.41168 (A-MSE: 1.25613) avg lploss: 0.00000
*** Best Val Loss: 1.02392 	 Best Test Loss: 1.21791 	 Best epoch 985
EarlyStopping counter: 9 out of 50
train epoch 1031 avg loss: 0.46678 (A-MSE: 0.41662) avg lploss: 0.00000
train epoch 1032 avg loss: 0.50180 (A-MSE: 0.44743) avg lploss: 0.00000
train epoch 1033 avg loss: 0.41690 (A-MSE: 0.37188) avg lploss: 0.00000
train epoch 1034 avg loss: 0.35010 (A-MSE: 0.31395) avg lploss: 0.00000
train epoch 1035 avg loss: 0.34346 (A-MSE: 0.30491) avg lploss: 0.00000
==> val epoch 1035 avg loss: 1.01298 (A-MSE: 0.89818) avg lploss: 0.00000
==> test epoch 1035 avg loss: 1.21593 (A-MSE: 1.08461) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
Validation loss decreased (1.023919 --> 1.012977).  Saving model ...
train epoch 1036 avg loss: 0.40036 (A-MSE: 0.35916) avg lploss: 0.00000
train epoch 1037 avg loss: 0.42028 (A-MSE: 0.37426) avg lploss: 0.00000
train epoch 1038 avg loss: 0.35353 (A-MSE: 0.31703) avg lploss: 0.00000
train epoch 1039 avg loss: 0.34012 (A-MSE: 0.30369) avg lploss: 0.00000
train epoch 1040 avg loss: 0.40096 (A-MSE: 0.35862) avg lploss: 0.00000
==> val epoch 1040 avg loss: 1.24785 (A-MSE: 1.10366) avg lploss: 0.00000
==> test epoch 1040 avg loss: 1.36581 (A-MSE: 1.21259) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 1 out of 50
train epoch 1041 avg loss: 0.44919 (A-MSE: 0.40040) avg lploss: 0.00000
train epoch 1042 avg loss: 0.41449 (A-MSE: 0.37105) avg lploss: 0.00000
train epoch 1043 avg loss: 0.38139 (A-MSE: 0.34127) avg lploss: 0.00000
train epoch 1044 avg loss: 0.32055 (A-MSE: 0.28750) avg lploss: 0.00000
train epoch 1045 avg loss: 0.32973 (A-MSE: 0.29550) avg lploss: 0.00000
==> val epoch 1045 avg loss: 1.15218 (A-MSE: 1.00917) avg lploss: 0.00000
==> test epoch 1045 avg loss: 1.33284 (A-MSE: 1.17906) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 2 out of 50
train epoch 1046 avg loss: 0.37859 (A-MSE: 0.33860) avg lploss: 0.00000
train epoch 1047 avg loss: 0.37434 (A-MSE: 0.33329) avg lploss: 0.00000
train epoch 1048 avg loss: 0.36279 (A-MSE: 0.32379) avg lploss: 0.00000
train epoch 1049 avg loss: 0.38948 (A-MSE: 0.34613) avg lploss: 0.00000
train epoch 1050 avg loss: 0.44920 (A-MSE: 0.39989) avg lploss: 0.00000
==> val epoch 1050 avg loss: 1.05448 (A-MSE: 0.94258) avg lploss: 0.00000
==> test epoch 1050 avg loss: 1.18360 (A-MSE: 1.05883) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 3 out of 50
train epoch 1051 avg loss: 0.37977 (A-MSE: 0.33904) avg lploss: 0.00000
train epoch 1052 avg loss: 0.37658 (A-MSE: 0.33703) avg lploss: 0.00000
train epoch 1053 avg loss: 0.41789 (A-MSE: 0.37647) avg lploss: 0.00000
train epoch 1054 avg loss: 0.38133 (A-MSE: 0.34076) avg lploss: 0.00000
train epoch 1055 avg loss: 0.38857 (A-MSE: 0.34528) avg lploss: 0.00000
==> val epoch 1055 avg loss: 1.03368 (A-MSE: 0.91434) avg lploss: 0.00000
==> test epoch 1055 avg loss: 1.21238 (A-MSE: 1.07567) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 4 out of 50
train epoch 1056 avg loss: 0.38599 (A-MSE: 0.34629) avg lploss: 0.00000
train epoch 1057 avg loss: 0.35344 (A-MSE: 0.31563) avg lploss: 0.00000
train epoch 1058 avg loss: 0.35872 (A-MSE: 0.32062) avg lploss: 0.00000
train epoch 1059 avg loss: 0.32504 (A-MSE: 0.29136) avg lploss: 0.00000
train epoch 1060 avg loss: 0.38815 (A-MSE: 0.34576) avg lploss: 0.00000
==> val epoch 1060 avg loss: 1.33482 (A-MSE: 1.17870) avg lploss: 0.00000
==> test epoch 1060 avg loss: 1.47414 (A-MSE: 1.30217) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 5 out of 50
train epoch 1061 avg loss: 0.39374 (A-MSE: 0.35041) avg lploss: 0.00000
train epoch 1062 avg loss: 0.36297 (A-MSE: 0.32434) avg lploss: 0.00000
train epoch 1063 avg loss: 0.35020 (A-MSE: 0.31291) avg lploss: 0.00000
train epoch 1064 avg loss: 0.37749 (A-MSE: 0.33931) avg lploss: 0.00000
train epoch 1065 avg loss: 0.42930 (A-MSE: 0.38391) avg lploss: 0.00000
==> val epoch 1065 avg loss: 1.08512 (A-MSE: 0.96578) avg lploss: 0.00000
==> test epoch 1065 avg loss: 1.25238 (A-MSE: 1.11263) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 6 out of 50
train epoch 1066 avg loss: 0.39810 (A-MSE: 0.35957) avg lploss: 0.00000
train epoch 1067 avg loss: 0.40798 (A-MSE: 0.36523) avg lploss: 0.00000
train epoch 1068 avg loss: 0.36897 (A-MSE: 0.33219) avg lploss: 0.00000
train epoch 1069 avg loss: 0.33980 (A-MSE: 0.30478) avg lploss: 0.00000
train epoch 1070 avg loss: 0.33729 (A-MSE: 0.30190) avg lploss: 0.00000
==> val epoch 1070 avg loss: 1.24052 (A-MSE: 1.10786) avg lploss: 0.00000
==> test epoch 1070 avg loss: 1.36906 (A-MSE: 1.22031) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 7 out of 50
train epoch 1071 avg loss: 0.33723 (A-MSE: 0.30461) avg lploss: 0.00000
train epoch 1072 avg loss: 0.34452 (A-MSE: 0.30695) avg lploss: 0.00000
train epoch 1073 avg loss: 0.36430 (A-MSE: 0.32645) avg lploss: 0.00000
train epoch 1074 avg loss: 0.40351 (A-MSE: 0.35949) avg lploss: 0.00000
train epoch 1075 avg loss: 0.38457 (A-MSE: 0.34430) avg lploss: 0.00000
==> val epoch 1075 avg loss: 1.14451 (A-MSE: 1.01457) avg lploss: 0.00000
==> test epoch 1075 avg loss: 1.27879 (A-MSE: 1.12985) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 8 out of 50
train epoch 1076 avg loss: 0.33077 (A-MSE: 0.29646) avg lploss: 0.00000
train epoch 1077 avg loss: 0.32765 (A-MSE: 0.29254) avg lploss: 0.00000
train epoch 1078 avg loss: 0.33453 (A-MSE: 0.30062) avg lploss: 0.00000
train epoch 1079 avg loss: 0.33600 (A-MSE: 0.30012) avg lploss: 0.00000
train epoch 1080 avg loss: 0.36349 (A-MSE: 0.32528) avg lploss: 0.00000
==> val epoch 1080 avg loss: 1.07683 (A-MSE: 0.96717) avg lploss: 0.00000
==> test epoch 1080 avg loss: 1.26989 (A-MSE: 1.14032) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 9 out of 50
train epoch 1081 avg loss: 0.35804 (A-MSE: 0.32196) avg lploss: 0.00000
train epoch 1082 avg loss: 0.39726 (A-MSE: 0.35461) avg lploss: 0.00000
train epoch 1083 avg loss: 0.40395 (A-MSE: 0.36136) avg lploss: 0.00000
train epoch 1084 avg loss: 0.38665 (A-MSE: 0.34511) avg lploss: 0.00000
train epoch 1085 avg loss: 0.36496 (A-MSE: 0.32540) avg lploss: 0.00000
==> val epoch 1085 avg loss: 1.06538 (A-MSE: 0.94139) avg lploss: 0.00000
==> test epoch 1085 avg loss: 1.18982 (A-MSE: 1.05058) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 10 out of 50
train epoch 1086 avg loss: 0.33049 (A-MSE: 0.29638) avg lploss: 0.00000
train epoch 1087 avg loss: 0.33645 (A-MSE: 0.30187) avg lploss: 0.00000
train epoch 1088 avg loss: 0.39601 (A-MSE: 0.35574) avg lploss: 0.00000
train epoch 1089 avg loss: 0.41258 (A-MSE: 0.36778) avg lploss: 0.00000
train epoch 1090 avg loss: 0.36826 (A-MSE: 0.32995) avg lploss: 0.00000
==> val epoch 1090 avg loss: 1.11731 (A-MSE: 0.98899) avg lploss: 0.00000
==> test epoch 1090 avg loss: 1.29362 (A-MSE: 1.14864) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 11 out of 50
train epoch 1091 avg loss: 0.37355 (A-MSE: 0.33319) avg lploss: 0.00000
train epoch 1092 avg loss: 0.37186 (A-MSE: 0.33366) avg lploss: 0.00000
train epoch 1093 avg loss: 0.33945 (A-MSE: 0.30548) avg lploss: 0.00000
train epoch 1094 avg loss: 0.31924 (A-MSE: 0.28462) avg lploss: 0.00000
train epoch 1095 avg loss: 0.31296 (A-MSE: 0.27861) avg lploss: 0.00000
==> val epoch 1095 avg loss: 1.05277 (A-MSE: 0.94066) avg lploss: 0.00000
==> test epoch 1095 avg loss: 1.23789 (A-MSE: 1.10893) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 12 out of 50
train epoch 1096 avg loss: 0.29042 (A-MSE: 0.26123) avg lploss: 0.00000
train epoch 1097 avg loss: 0.31173 (A-MSE: 0.27677) avg lploss: 0.00000
train epoch 1098 avg loss: 0.35794 (A-MSE: 0.32093) avg lploss: 0.00000
train epoch 1099 avg loss: 0.38054 (A-MSE: 0.34105) avg lploss: 0.00000
train epoch 1100 avg loss: 0.37748 (A-MSE: 0.33730) avg lploss: 0.00000
==> val epoch 1100 avg loss: 1.09079 (A-MSE: 0.96911) avg lploss: 0.00000
==> test epoch 1100 avg loss: 1.19357 (A-MSE: 1.06208) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 13 out of 50
train epoch 1101 avg loss: 0.32016 (A-MSE: 0.28725) avg lploss: 0.00000
train epoch 1102 avg loss: 0.34558 (A-MSE: 0.30844) avg lploss: 0.00000
train epoch 1103 avg loss: 0.38106 (A-MSE: 0.34065) avg lploss: 0.00000
train epoch 1104 avg loss: 0.40308 (A-MSE: 0.36002) avg lploss: 0.00000
train epoch 1105 avg loss: 0.32892 (A-MSE: 0.29508) avg lploss: 0.00000
==> val epoch 1105 avg loss: 1.15356 (A-MSE: 1.02637) avg lploss: 0.00000
==> test epoch 1105 avg loss: 1.34173 (A-MSE: 1.19413) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 14 out of 50
train epoch 1106 avg loss: 0.32176 (A-MSE: 0.28588) avg lploss: 0.00000
train epoch 1107 avg loss: 0.34555 (A-MSE: 0.31110) avg lploss: 0.00000
train epoch 1108 avg loss: 0.36330 (A-MSE: 0.32598) avg lploss: 0.00000
train epoch 1109 avg loss: 0.32129 (A-MSE: 0.28788) avg lploss: 0.00000
train epoch 1110 avg loss: 0.31811 (A-MSE: 0.28438) avg lploss: 0.00000
==> val epoch 1110 avg loss: 1.12776 (A-MSE: 1.00098) avg lploss: 0.00000
==> test epoch 1110 avg loss: 1.27304 (A-MSE: 1.13631) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 15 out of 50
train epoch 1111 avg loss: 0.32110 (A-MSE: 0.28733) avg lploss: 0.00000
train epoch 1112 avg loss: 0.32227 (A-MSE: 0.29034) avg lploss: 0.00000
train epoch 1113 avg loss: 0.33143 (A-MSE: 0.29484) avg lploss: 0.00000
train epoch 1114 avg loss: 0.31790 (A-MSE: 0.28474) avg lploss: 0.00000
train epoch 1115 avg loss: 0.37954 (A-MSE: 0.33920) avg lploss: 0.00000
==> val epoch 1115 avg loss: 1.07431 (A-MSE: 0.94533) avg lploss: 0.00000
==> test epoch 1115 avg loss: 1.22998 (A-MSE: 1.08130) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 16 out of 50
train epoch 1116 avg loss: 0.44356 (A-MSE: 0.40008) avg lploss: 0.00000
train epoch 1117 avg loss: 0.36307 (A-MSE: 0.32417) avg lploss: 0.00000
train epoch 1118 avg loss: 0.33318 (A-MSE: 0.29676) avg lploss: 0.00000
train epoch 1119 avg loss: 0.33512 (A-MSE: 0.29965) avg lploss: 0.00000
train epoch 1120 avg loss: 0.29269 (A-MSE: 0.26253) avg lploss: 0.00000
==> val epoch 1120 avg loss: 1.04671 (A-MSE: 0.93337) avg lploss: 0.00000
==> test epoch 1120 avg loss: 1.25437 (A-MSE: 1.11845) avg lploss: 0.00000
*** Best Val Loss: 1.01298 	 Best Test Loss: 1.21593 	 Best epoch 1035
EarlyStopping counter: 17 out of 50
train epoch 1121 avg loss: 0.38609 (A-MSE: 0.34537) avg lploss: 0.00000
train epoch 1122 avg loss: 0.39820 (A-MSE: 0.35464) avg lploss: 0.00000
train epoch 1123 avg loss: 0.32386 (A-MSE: 0.29230) avg lploss: 0.00000
train epoch 1124 avg loss: 0.28016 (A-MSE: 0.24999) avg lploss: 0.00000
train epoch 1125 avg loss: 0.30640 (A-MSE: 0.27406) avg lploss: 0.00000
==> val epoch 1125 avg loss: 0.99269 (A-MSE: 0.87693) avg lploss: 0.00000
==> test epoch 1125 avg loss: 1.15996 (A-MSE: 1.03509) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
Validation loss decreased (1.012977 --> 0.992691).  Saving model ...
train epoch 1126 avg loss: 0.31182 (A-MSE: 0.27901) avg lploss: 0.00000
train epoch 1127 avg loss: 0.31042 (A-MSE: 0.27749) avg lploss: 0.00000
train epoch 1128 avg loss: 0.33663 (A-MSE: 0.30083) avg lploss: 0.00000
train epoch 1129 avg loss: 0.32807 (A-MSE: 0.29168) avg lploss: 0.00000
train epoch 1130 avg loss: 0.37184 (A-MSE: 0.33257) avg lploss: 0.00000
==> val epoch 1130 avg loss: 1.08803 (A-MSE: 0.95999) avg lploss: 0.00000
==> test epoch 1130 avg loss: 1.24271 (A-MSE: 1.10566) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 1 out of 50
train epoch 1131 avg loss: 0.34759 (A-MSE: 0.31226) avg lploss: 0.00000
train epoch 1132 avg loss: 0.34417 (A-MSE: 0.30946) avg lploss: 0.00000
train epoch 1133 avg loss: 0.33851 (A-MSE: 0.30225) avg lploss: 0.00000
train epoch 1134 avg loss: 0.34934 (A-MSE: 0.31288) avg lploss: 0.00000
train epoch 1135 avg loss: 0.35231 (A-MSE: 0.31577) avg lploss: 0.00000
==> val epoch 1135 avg loss: 1.15521 (A-MSE: 1.02982) avg lploss: 0.00000
==> test epoch 1135 avg loss: 1.23233 (A-MSE: 1.09469) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 2 out of 50
train epoch 1136 avg loss: 0.35421 (A-MSE: 0.31560) avg lploss: 0.00000
train epoch 1137 avg loss: 0.30951 (A-MSE: 0.27769) avg lploss: 0.00000
train epoch 1138 avg loss: 0.30400 (A-MSE: 0.27420) avg lploss: 0.00000
train epoch 1139 avg loss: 0.27490 (A-MSE: 0.24604) avg lploss: 0.00000
train epoch 1140 avg loss: 0.27429 (A-MSE: 0.24580) avg lploss: 0.00000
==> val epoch 1140 avg loss: 0.99743 (A-MSE: 0.88071) avg lploss: 0.00000
==> test epoch 1140 avg loss: 1.19994 (A-MSE: 1.07170) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 3 out of 50
train epoch 1141 avg loss: 0.27717 (A-MSE: 0.24724) avg lploss: 0.00000
train epoch 1142 avg loss: 0.30404 (A-MSE: 0.27267) avg lploss: 0.00000
train epoch 1143 avg loss: 0.32286 (A-MSE: 0.29087) avg lploss: 0.00000
train epoch 1144 avg loss: 0.33411 (A-MSE: 0.29825) avg lploss: 0.00000
train epoch 1145 avg loss: 0.35684 (A-MSE: 0.31906) avg lploss: 0.00000
==> val epoch 1145 avg loss: 1.08519 (A-MSE: 0.96310) avg lploss: 0.00000
==> test epoch 1145 avg loss: 1.16363 (A-MSE: 1.03464) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 4 out of 50
train epoch 1146 avg loss: 0.52216 (A-MSE: 0.47226) avg lploss: 0.00000
train epoch 1147 avg loss: 0.43496 (A-MSE: 0.39171) avg lploss: 0.00000
train epoch 1148 avg loss: 0.33488 (A-MSE: 0.30051) avg lploss: 0.00000
train epoch 1149 avg loss: 0.30655 (A-MSE: 0.27491) avg lploss: 0.00000
train epoch 1150 avg loss: 0.34317 (A-MSE: 0.30614) avg lploss: 0.00000
==> val epoch 1150 avg loss: 1.03201 (A-MSE: 0.90638) avg lploss: 0.00000
==> test epoch 1150 avg loss: 1.18451 (A-MSE: 1.04516) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 5 out of 50
train epoch 1151 avg loss: 0.37148 (A-MSE: 0.33171) avg lploss: 0.00000
train epoch 1152 avg loss: 0.33033 (A-MSE: 0.29759) avg lploss: 0.00000
train epoch 1153 avg loss: 0.30603 (A-MSE: 0.27221) avg lploss: 0.00000
train epoch 1154 avg loss: 0.31462 (A-MSE: 0.28134) avg lploss: 0.00000
train epoch 1155 avg loss: 0.28218 (A-MSE: 0.25347) avg lploss: 0.00000
==> val epoch 1155 avg loss: 1.01403 (A-MSE: 0.90232) avg lploss: 0.00000
==> test epoch 1155 avg loss: 1.13826 (A-MSE: 1.01319) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 6 out of 50
train epoch 1156 avg loss: 0.29289 (A-MSE: 0.26224) avg lploss: 0.00000
train epoch 1157 avg loss: 0.30910 (A-MSE: 0.27780) avg lploss: 0.00000
train epoch 1158 avg loss: 0.28695 (A-MSE: 0.25629) avg lploss: 0.00000
train epoch 1159 avg loss: 0.27054 (A-MSE: 0.24176) avg lploss: 0.00000
train epoch 1160 avg loss: 0.28048 (A-MSE: 0.25072) avg lploss: 0.00000
==> val epoch 1160 avg loss: 1.00893 (A-MSE: 0.88207) avg lploss: 0.00000
==> test epoch 1160 avg loss: 1.16625 (A-MSE: 1.02269) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 7 out of 50
train epoch 1161 avg loss: 0.30412 (A-MSE: 0.27101) avg lploss: 0.00000
train epoch 1162 avg loss: 0.34214 (A-MSE: 0.30669) avg lploss: 0.00000
train epoch 1163 avg loss: 0.33840 (A-MSE: 0.30271) avg lploss: 0.00000
train epoch 1164 avg loss: 0.33785 (A-MSE: 0.30387) avg lploss: 0.00000
train epoch 1165 avg loss: 0.32574 (A-MSE: 0.29000) avg lploss: 0.00000
==> val epoch 1165 avg loss: 1.01620 (A-MSE: 0.89708) avg lploss: 0.00000
==> test epoch 1165 avg loss: 1.16425 (A-MSE: 1.03881) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 8 out of 50
train epoch 1166 avg loss: 0.25797 (A-MSE: 0.23117) avg lploss: 0.00000
train epoch 1167 avg loss: 0.26747 (A-MSE: 0.23793) avg lploss: 0.00000
train epoch 1168 avg loss: 0.28629 (A-MSE: 0.25564) avg lploss: 0.00000
train epoch 1169 avg loss: 0.32476 (A-MSE: 0.29071) avg lploss: 0.00000
train epoch 1170 avg loss: 0.28879 (A-MSE: 0.25880) avg lploss: 0.00000
==> val epoch 1170 avg loss: 1.06617 (A-MSE: 0.93278) avg lploss: 0.00000
==> test epoch 1170 avg loss: 1.29626 (A-MSE: 1.14212) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 9 out of 50
train epoch 1171 avg loss: 0.30448 (A-MSE: 0.27209) avg lploss: 0.00000
train epoch 1172 avg loss: 0.40207 (A-MSE: 0.35863) avg lploss: 0.00000
train epoch 1173 avg loss: 0.42033 (A-MSE: 0.37551) avg lploss: 0.00000
train epoch 1174 avg loss: 0.40668 (A-MSE: 0.36397) avg lploss: 0.00000
train epoch 1175 avg loss: 0.45190 (A-MSE: 0.40525) avg lploss: 0.00000
==> val epoch 1175 avg loss: 2.31015 (A-MSE: 2.01943) avg lploss: 0.00000
==> test epoch 1175 avg loss: 2.50766 (A-MSE: 2.19828) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 10 out of 50
train epoch 1176 avg loss: 0.78828 (A-MSE: 0.69577) avg lploss: 0.00000
train epoch 1177 avg loss: 0.49163 (A-MSE: 0.43823) avg lploss: 0.00000
train epoch 1178 avg loss: 0.35037 (A-MSE: 0.31240) avg lploss: 0.00000
train epoch 1179 avg loss: 0.34708 (A-MSE: 0.31211) avg lploss: 0.00000
train epoch 1180 avg loss: 0.30515 (A-MSE: 0.27521) avg lploss: 0.00000
==> val epoch 1180 avg loss: 1.02049 (A-MSE: 0.91017) avg lploss: 0.00000
==> test epoch 1180 avg loss: 1.14009 (A-MSE: 1.01816) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 11 out of 50
train epoch 1181 avg loss: 0.25507 (A-MSE: 0.22956) avg lploss: 0.00000
train epoch 1182 avg loss: 0.28815 (A-MSE: 0.25801) avg lploss: 0.00000
train epoch 1183 avg loss: 0.27433 (A-MSE: 0.24558) avg lploss: 0.00000
train epoch 1184 avg loss: 0.26761 (A-MSE: 0.24049) avg lploss: 0.00000
train epoch 1185 avg loss: 0.28655 (A-MSE: 0.25665) avg lploss: 0.00000
==> val epoch 1185 avg loss: 1.20517 (A-MSE: 1.05184) avg lploss: 0.00000
==> test epoch 1185 avg loss: 1.32356 (A-MSE: 1.15695) avg lploss: 0.00000
*** Best Val Loss: 0.99269 	 Best Test Loss: 1.15996 	 Best epoch 1125
EarlyStopping counter: 12 out of 50
train epoch 1186 avg loss: 0.30504 (A-MSE: 0.27317) avg lploss: 0.00000
train epoch 1187 avg loss: 0.33724 (A-MSE: 0.29933) avg lploss: 0.00000
train epoch 1188 avg loss: 0.29134 (A-MSE: 0.26038) avg lploss: 0.00000
train epoch 1189 avg loss: 0.26938 (A-MSE: 0.24064) avg lploss: 0.00000
train epoch 1190 avg loss: 0.27754 (A-MSE: 0.24826) avg lploss: 0.00000
==> val epoch 1190 avg loss: 0.87825 (A-MSE: 0.78344) avg lploss: 0.00000
==> test epoch 1190 avg loss: 1.04045 (A-MSE: 0.93404) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
Validation loss decreased (0.992691 --> 0.878254).  Saving model ...
train epoch 1191 avg loss: 0.25481 (A-MSE: 0.22756) avg lploss: 0.00000
train epoch 1192 avg loss: 0.29429 (A-MSE: 0.26481) avg lploss: 0.00000
train epoch 1193 avg loss: 0.29079 (A-MSE: 0.26230) avg lploss: 0.00000
train epoch 1194 avg loss: 0.29464 (A-MSE: 0.26316) avg lploss: 0.00000
train epoch 1195 avg loss: 0.28156 (A-MSE: 0.25150) avg lploss: 0.00000
==> val epoch 1195 avg loss: 1.08871 (A-MSE: 0.95778) avg lploss: 0.00000
==> test epoch 1195 avg loss: 1.22310 (A-MSE: 1.07937) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 1 out of 50
train epoch 1196 avg loss: 0.28345 (A-MSE: 0.25323) avg lploss: 0.00000
train epoch 1197 avg loss: 0.28201 (A-MSE: 0.25427) avg lploss: 0.00000
train epoch 1198 avg loss: 0.35005 (A-MSE: 0.31539) avg lploss: 0.00000
train epoch 1199 avg loss: 0.31633 (A-MSE: 0.28218) avg lploss: 0.00000
train epoch 1200 avg loss: 0.28153 (A-MSE: 0.25112) avg lploss: 0.00000
==> val epoch 1200 avg loss: 1.04555 (A-MSE: 0.91039) avg lploss: 0.00000
==> test epoch 1200 avg loss: 1.16567 (A-MSE: 1.02666) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 2 out of 50
train epoch 1201 avg loss: 0.25886 (A-MSE: 0.23297) avg lploss: 0.00000
train epoch 1202 avg loss: 0.24252 (A-MSE: 0.21688) avg lploss: 0.00000
train epoch 1203 avg loss: 0.26564 (A-MSE: 0.23966) avg lploss: 0.00000
train epoch 1204 avg loss: 0.24687 (A-MSE: 0.22153) avg lploss: 0.00000
train epoch 1205 avg loss: 0.26634 (A-MSE: 0.23742) avg lploss: 0.00000
==> val epoch 1205 avg loss: 0.89901 (A-MSE: 0.79720) avg lploss: 0.00000
==> test epoch 1205 avg loss: 1.15785 (A-MSE: 1.03524) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 3 out of 50
train epoch 1206 avg loss: 0.25279 (A-MSE: 0.22662) avg lploss: 0.00000
train epoch 1207 avg loss: 0.24973 (A-MSE: 0.22413) avg lploss: 0.00000
train epoch 1208 avg loss: 0.28539 (A-MSE: 0.25617) avg lploss: 0.00000
train epoch 1209 avg loss: 0.26002 (A-MSE: 0.23290) avg lploss: 0.00000
train epoch 1210 avg loss: 0.25889 (A-MSE: 0.23310) avg lploss: 0.00000
==> val epoch 1210 avg loss: 1.04271 (A-MSE: 0.91251) avg lploss: 0.00000
==> test epoch 1210 avg loss: 1.17065 (A-MSE: 1.02967) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 4 out of 50
train epoch 1211 avg loss: 0.26063 (A-MSE: 0.23457) avg lploss: 0.00000
train epoch 1212 avg loss: 0.31656 (A-MSE: 0.28162) avg lploss: 0.00000
train epoch 1213 avg loss: 0.30651 (A-MSE: 0.27378) avg lploss: 0.00000
train epoch 1214 avg loss: 0.27832 (A-MSE: 0.24896) avg lploss: 0.00000
train epoch 1215 avg loss: 0.29935 (A-MSE: 0.26804) avg lploss: 0.00000
==> val epoch 1215 avg loss: 0.96755 (A-MSE: 0.86097) avg lploss: 0.00000
==> test epoch 1215 avg loss: 1.17421 (A-MSE: 1.05567) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 5 out of 50
train epoch 1216 avg loss: 0.29401 (A-MSE: 0.26298) avg lploss: 0.00000
train epoch 1217 avg loss: 0.27579 (A-MSE: 0.24674) avg lploss: 0.00000
train epoch 1218 avg loss: 0.28030 (A-MSE: 0.25110) avg lploss: 0.00000
train epoch 1219 avg loss: 0.29011 (A-MSE: 0.25816) avg lploss: 0.00000
train epoch 1220 avg loss: 0.28833 (A-MSE: 0.25843) avg lploss: 0.00000
==> val epoch 1220 avg loss: 0.98415 (A-MSE: 0.87811) avg lploss: 0.00000
==> test epoch 1220 avg loss: 1.18547 (A-MSE: 1.04904) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 6 out of 50
train epoch 1221 avg loss: 0.27883 (A-MSE: 0.24958) avg lploss: 0.00000
train epoch 1222 avg loss: 0.23542 (A-MSE: 0.21103) avg lploss: 0.00000
train epoch 1223 avg loss: 0.23776 (A-MSE: 0.21228) avg lploss: 0.00000
train epoch 1224 avg loss: 0.24584 (A-MSE: 0.22000) avg lploss: 0.00000
train epoch 1225 avg loss: 0.29375 (A-MSE: 0.26453) avg lploss: 0.00000
==> val epoch 1225 avg loss: 1.00285 (A-MSE: 0.89442) avg lploss: 0.00000
==> test epoch 1225 avg loss: 1.15207 (A-MSE: 1.03104) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 7 out of 50
train epoch 1226 avg loss: 0.27115 (A-MSE: 0.24293) avg lploss: 0.00000
train epoch 1227 avg loss: 0.26256 (A-MSE: 0.23588) avg lploss: 0.00000
train epoch 1228 avg loss: 0.26879 (A-MSE: 0.23926) avg lploss: 0.00000
train epoch 1229 avg loss: 0.28512 (A-MSE: 0.25501) avg lploss: 0.00000
train epoch 1230 avg loss: 0.27549 (A-MSE: 0.24629) avg lploss: 0.00000
==> val epoch 1230 avg loss: 1.03840 (A-MSE: 0.91998) avg lploss: 0.00000
==> test epoch 1230 avg loss: 1.15806 (A-MSE: 1.03254) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 8 out of 50
train epoch 1231 avg loss: 0.25890 (A-MSE: 0.23180) avg lploss: 0.00000
train epoch 1232 avg loss: 0.27634 (A-MSE: 0.24646) avg lploss: 0.00000
train epoch 1233 avg loss: 0.26558 (A-MSE: 0.23756) avg lploss: 0.00000
train epoch 1234 avg loss: 0.25299 (A-MSE: 0.22640) avg lploss: 0.00000
train epoch 1235 avg loss: 0.24279 (A-MSE: 0.21676) avg lploss: 0.00000
==> val epoch 1235 avg loss: 1.12325 (A-MSE: 0.97859) avg lploss: 0.00000
==> test epoch 1235 avg loss: 1.21802 (A-MSE: 1.07068) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 9 out of 50
train epoch 1236 avg loss: 0.28064 (A-MSE: 0.25175) avg lploss: 0.00000
train epoch 1237 avg loss: 0.29673 (A-MSE: 0.26450) avg lploss: 0.00000
train epoch 1238 avg loss: 0.34245 (A-MSE: 0.30354) avg lploss: 0.00000
train epoch 1239 avg loss: 0.32494 (A-MSE: 0.29109) avg lploss: 0.00000
train epoch 1240 avg loss: 0.27613 (A-MSE: 0.24606) avg lploss: 0.00000
==> val epoch 1240 avg loss: 0.88005 (A-MSE: 0.77052) avg lploss: 0.00000
==> test epoch 1240 avg loss: 1.02248 (A-MSE: 0.90294) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 10 out of 50
train epoch 1241 avg loss: 0.25758 (A-MSE: 0.23199) avg lploss: 0.00000
train epoch 1242 avg loss: 0.25586 (A-MSE: 0.22938) avg lploss: 0.00000
train epoch 1243 avg loss: 0.29846 (A-MSE: 0.26612) avg lploss: 0.00000
train epoch 1244 avg loss: 0.24345 (A-MSE: 0.21866) avg lploss: 0.00000
train epoch 1245 avg loss: 0.28045 (A-MSE: 0.25277) avg lploss: 0.00000
==> val epoch 1245 avg loss: 1.18491 (A-MSE: 1.03035) avg lploss: 0.00000
==> test epoch 1245 avg loss: 1.28958 (A-MSE: 1.13307) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 11 out of 50
train epoch 1246 avg loss: 0.29221 (A-MSE: 0.26037) avg lploss: 0.00000
train epoch 1247 avg loss: 0.26118 (A-MSE: 0.23476) avg lploss: 0.00000
train epoch 1248 avg loss: 0.25489 (A-MSE: 0.22882) avg lploss: 0.00000
train epoch 1249 avg loss: 0.34633 (A-MSE: 0.30799) avg lploss: 0.00000
train epoch 1250 avg loss: 0.35767 (A-MSE: 0.32319) avg lploss: 0.00000
==> val epoch 1250 avg loss: 1.40572 (A-MSE: 1.21339) avg lploss: 0.00000
==> test epoch 1250 avg loss: 1.51489 (A-MSE: 1.31609) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 12 out of 50
train epoch 1251 avg loss: 0.33080 (A-MSE: 0.29415) avg lploss: 0.00000
train epoch 1252 avg loss: 0.26357 (A-MSE: 0.23643) avg lploss: 0.00000
train epoch 1253 avg loss: 0.29734 (A-MSE: 0.26651) avg lploss: 0.00000
train epoch 1254 avg loss: 0.31043 (A-MSE: 0.27654) avg lploss: 0.00000
train epoch 1255 avg loss: 0.27884 (A-MSE: 0.25039) avg lploss: 0.00000
==> val epoch 1255 avg loss: 0.96307 (A-MSE: 0.85289) avg lploss: 0.00000
==> test epoch 1255 avg loss: 1.13048 (A-MSE: 1.00556) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 13 out of 50
train epoch 1256 avg loss: 0.26197 (A-MSE: 0.23313) avg lploss: 0.00000
train epoch 1257 avg loss: 0.26468 (A-MSE: 0.23608) avg lploss: 0.00000
train epoch 1258 avg loss: 0.26995 (A-MSE: 0.24133) avg lploss: 0.00000
train epoch 1259 avg loss: 0.31483 (A-MSE: 0.28211) avg lploss: 0.00000
train epoch 1260 avg loss: 0.28166 (A-MSE: 0.25183) avg lploss: 0.00000
==> val epoch 1260 avg loss: 1.05138 (A-MSE: 0.91756) avg lploss: 0.00000
==> test epoch 1260 avg loss: 1.17819 (A-MSE: 1.03468) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 14 out of 50
train epoch 1261 avg loss: 0.27748 (A-MSE: 0.24723) avg lploss: 0.00000
train epoch 1262 avg loss: 0.29272 (A-MSE: 0.25927) avg lploss: 0.00000
train epoch 1263 avg loss: 0.25949 (A-MSE: 0.23139) avg lploss: 0.00000
train epoch 1264 avg loss: 0.27720 (A-MSE: 0.24956) avg lploss: 0.00000
train epoch 1265 avg loss: 0.24472 (A-MSE: 0.21944) avg lploss: 0.00000
==> val epoch 1265 avg loss: 0.89675 (A-MSE: 0.78487) avg lploss: 0.00000
==> test epoch 1265 avg loss: 1.01805 (A-MSE: 0.89735) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 15 out of 50
train epoch 1266 avg loss: 0.23981 (A-MSE: 0.21516) avg lploss: 0.00000
train epoch 1267 avg loss: 0.22478 (A-MSE: 0.20001) avg lploss: 0.00000
train epoch 1268 avg loss: 0.23087 (A-MSE: 0.20548) avg lploss: 0.00000
train epoch 1269 avg loss: 0.22446 (A-MSE: 0.19899) avg lploss: 0.00000
train epoch 1270 avg loss: 0.24448 (A-MSE: 0.21783) avg lploss: 0.00000
==> val epoch 1270 avg loss: 0.99230 (A-MSE: 0.88351) avg lploss: 0.00000
==> test epoch 1270 avg loss: 1.13860 (A-MSE: 1.01824) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 16 out of 50
train epoch 1271 avg loss: 0.21771 (A-MSE: 0.19507) avg lploss: 0.00000
train epoch 1272 avg loss: 0.21987 (A-MSE: 0.19748) avg lploss: 0.00000
train epoch 1273 avg loss: 0.22136 (A-MSE: 0.20026) avg lploss: 0.00000
train epoch 1274 avg loss: 0.29157 (A-MSE: 0.26088) avg lploss: 0.00000
train epoch 1275 avg loss: 0.27955 (A-MSE: 0.24945) avg lploss: 0.00000
==> val epoch 1275 avg loss: 0.97509 (A-MSE: 0.86820) avg lploss: 0.00000
==> test epoch 1275 avg loss: 1.13853 (A-MSE: 1.02047) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 17 out of 50
train epoch 1276 avg loss: 0.27917 (A-MSE: 0.25024) avg lploss: 0.00000
train epoch 1277 avg loss: 0.26178 (A-MSE: 0.23424) avg lploss: 0.00000
train epoch 1278 avg loss: 0.26393 (A-MSE: 0.23851) avg lploss: 0.00000
train epoch 1279 avg loss: 0.28475 (A-MSE: 0.25460) avg lploss: 0.00000
train epoch 1280 avg loss: 0.24508 (A-MSE: 0.21897) avg lploss: 0.00000
==> val epoch 1280 avg loss: 1.19378 (A-MSE: 1.06663) avg lploss: 0.00000
==> test epoch 1280 avg loss: 1.33635 (A-MSE: 1.20327) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 18 out of 50
train epoch 1281 avg loss: 0.31226 (A-MSE: 0.27812) avg lploss: 0.00000
train epoch 1282 avg loss: 0.33221 (A-MSE: 0.29670) avg lploss: 0.00000
train epoch 1283 avg loss: 0.31102 (A-MSE: 0.27851) avg lploss: 0.00000
train epoch 1284 avg loss: 0.27250 (A-MSE: 0.24530) avg lploss: 0.00000
train epoch 1285 avg loss: 0.24506 (A-MSE: 0.21781) avg lploss: 0.00000
==> val epoch 1285 avg loss: 0.95846 (A-MSE: 0.85181) avg lploss: 0.00000
==> test epoch 1285 avg loss: 1.12626 (A-MSE: 1.00169) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 19 out of 50
train epoch 1286 avg loss: 0.28896 (A-MSE: 0.25664) avg lploss: 0.00000
train epoch 1287 avg loss: 0.26349 (A-MSE: 0.23384) avg lploss: 0.00000
train epoch 1288 avg loss: 0.26101 (A-MSE: 0.23336) avg lploss: 0.00000
train epoch 1289 avg loss: 0.25834 (A-MSE: 0.23275) avg lploss: 0.00000
train epoch 1290 avg loss: 0.26404 (A-MSE: 0.23711) avg lploss: 0.00000
==> val epoch 1290 avg loss: 0.89934 (A-MSE: 0.78677) avg lploss: 0.00000
==> test epoch 1290 avg loss: 1.08469 (A-MSE: 0.95446) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 20 out of 50
train epoch 1291 avg loss: 0.25673 (A-MSE: 0.22981) avg lploss: 0.00000
train epoch 1292 avg loss: 0.23247 (A-MSE: 0.20744) avg lploss: 0.00000
train epoch 1293 avg loss: 0.24503 (A-MSE: 0.21905) avg lploss: 0.00000
train epoch 1294 avg loss: 0.23980 (A-MSE: 0.21305) avg lploss: 0.00000
train epoch 1295 avg loss: 0.23620 (A-MSE: 0.21129) avg lploss: 0.00000
==> val epoch 1295 avg loss: 0.98786 (A-MSE: 0.87409) avg lploss: 0.00000
==> test epoch 1295 avg loss: 1.07124 (A-MSE: 0.95359) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 21 out of 50
train epoch 1296 avg loss: 0.23707 (A-MSE: 0.21341) avg lploss: 0.00000
train epoch 1297 avg loss: 0.30354 (A-MSE: 0.27069) avg lploss: 0.00000
train epoch 1298 avg loss: 0.23393 (A-MSE: 0.20937) avg lploss: 0.00000
train epoch 1299 avg loss: 0.26065 (A-MSE: 0.23299) avg lploss: 0.00000
train epoch 1300 avg loss: 0.24132 (A-MSE: 0.21495) avg lploss: 0.00000
==> val epoch 1300 avg loss: 0.95344 (A-MSE: 0.83947) avg lploss: 0.00000
==> test epoch 1300 avg loss: 1.10153 (A-MSE: 0.97341) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 22 out of 50
train epoch 1301 avg loss: 0.21888 (A-MSE: 0.19723) avg lploss: 0.00000
train epoch 1302 avg loss: 0.21414 (A-MSE: 0.19187) avg lploss: 0.00000
train epoch 1303 avg loss: 0.21488 (A-MSE: 0.19226) avg lploss: 0.00000
train epoch 1304 avg loss: 0.23320 (A-MSE: 0.20763) avg lploss: 0.00000
train epoch 1305 avg loss: 0.22973 (A-MSE: 0.20686) avg lploss: 0.00000
==> val epoch 1305 avg loss: 1.07215 (A-MSE: 0.94095) avg lploss: 0.00000
==> test epoch 1305 avg loss: 1.21953 (A-MSE: 1.07498) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 23 out of 50
train epoch 1306 avg loss: 0.22811 (A-MSE: 0.20404) avg lploss: 0.00000
train epoch 1307 avg loss: 0.21966 (A-MSE: 0.19522) avg lploss: 0.00000
train epoch 1308 avg loss: 0.27114 (A-MSE: 0.24103) avg lploss: 0.00000
train epoch 1309 avg loss: 0.26297 (A-MSE: 0.23401) avg lploss: 0.00000
train epoch 1310 avg loss: 0.22875 (A-MSE: 0.20356) avg lploss: 0.00000
==> val epoch 1310 avg loss: 0.99244 (A-MSE: 0.88303) avg lploss: 0.00000
==> test epoch 1310 avg loss: 1.12921 (A-MSE: 1.00666) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 24 out of 50
train epoch 1311 avg loss: 0.21766 (A-MSE: 0.19486) avg lploss: 0.00000
train epoch 1312 avg loss: 0.24127 (A-MSE: 0.21359) avg lploss: 0.00000
train epoch 1313 avg loss: 0.22564 (A-MSE: 0.20112) avg lploss: 0.00000
train epoch 1314 avg loss: 0.23802 (A-MSE: 0.21348) avg lploss: 0.00000
train epoch 1315 avg loss: 0.25517 (A-MSE: 0.22752) avg lploss: 0.00000
==> val epoch 1315 avg loss: 0.93045 (A-MSE: 0.82454) avg lploss: 0.00000
==> test epoch 1315 avg loss: 1.04382 (A-MSE: 0.92900) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 25 out of 50
train epoch 1316 avg loss: 0.26181 (A-MSE: 0.23505) avg lploss: 0.00000
train epoch 1317 avg loss: 0.28480 (A-MSE: 0.25666) avg lploss: 0.00000
train epoch 1318 avg loss: 0.29165 (A-MSE: 0.26079) avg lploss: 0.00000
train epoch 1319 avg loss: 0.25148 (A-MSE: 0.22383) avg lploss: 0.00000
train epoch 1320 avg loss: 0.20169 (A-MSE: 0.18134) avg lploss: 0.00000
==> val epoch 1320 avg loss: 0.98011 (A-MSE: 0.86138) avg lploss: 0.00000
==> test epoch 1320 avg loss: 1.07879 (A-MSE: 0.95456) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 26 out of 50
train epoch 1321 avg loss: 0.21429 (A-MSE: 0.19067) avg lploss: 0.00000
train epoch 1322 avg loss: 0.20984 (A-MSE: 0.18721) avg lploss: 0.00000
train epoch 1323 avg loss: 0.24238 (A-MSE: 0.21749) avg lploss: 0.00000
train epoch 1324 avg loss: 0.26678 (A-MSE: 0.23899) avg lploss: 0.00000
train epoch 1325 avg loss: 0.21920 (A-MSE: 0.19576) avg lploss: 0.00000
==> val epoch 1325 avg loss: 1.04824 (A-MSE: 0.93577) avg lploss: 0.00000
==> test epoch 1325 avg loss: 1.13330 (A-MSE: 1.00893) avg lploss: 0.00000
*** Best Val Loss: 0.87825 	 Best Test Loss: 1.04045 	 Best epoch 1190
EarlyStopping counter: 27 out of 50
train epoch 1326 avg loss: 0.21748 (A-MSE: 0.19357) avg lploss: 0.00000
train epoch 1327 avg loss: 0.20076 (A-MSE: 0.17976) avg lploss: 0.00000
train epoch 1328 avg loss: 0.27779 (A-MSE: 0.24735) avg lploss: 0.00000
train epoch 1329 avg loss: 0.27218 (A-MSE: 0.24274) avg lploss: 0.00000
train epoch 1330 avg loss: 0.25380 (A-MSE: 0.22844) avg lploss: 0.00000
==> val epoch 1330 avg loss: 0.86132 (A-MSE: 0.77402) avg lploss: 0.00000
==> test epoch 1330 avg loss: 1.03419 (A-MSE: 0.93194) avg lploss: 0.00000
*** Best Val Loss: 0.86132 	 Best Test Loss: 1.03419 	 Best epoch 1330
Validation loss decreased (0.878254 --> 0.861323).  Saving model ...
train epoch 1331 avg loss: 0.24364 (A-MSE: 0.21728) avg lploss: 0.00000
train epoch 1332 avg loss: 0.21680 (A-MSE: 0.19546) avg lploss: 0.00000
train epoch 1333 avg loss: 0.21665 (A-MSE: 0.19308) avg lploss: 0.00000
train epoch 1334 avg loss: 0.21093 (A-MSE: 0.18844) avg lploss: 0.00000
train epoch 1335 avg loss: 0.21028 (A-MSE: 0.18794) avg lploss: 0.00000
==> val epoch 1335 avg loss: 0.98401 (A-MSE: 0.86163) avg lploss: 0.00000
==> test epoch 1335 avg loss: 1.05836 (A-MSE: 0.93726) avg lploss: 0.00000
*** Best Val Loss: 0.86132 	 Best Test Loss: 1.03419 	 Best epoch 1330
EarlyStopping counter: 1 out of 50
train epoch 1336 avg loss: 0.19487 (A-MSE: 0.17357) avg lploss: 0.00000
train epoch 1337 avg loss: 0.18638 (A-MSE: 0.16589) avg lploss: 0.00000
train epoch 1338 avg loss: 0.19560 (A-MSE: 0.17547) avg lploss: 0.00000
train epoch 1339 avg loss: 0.21411 (A-MSE: 0.19092) avg lploss: 0.00000
train epoch 1340 avg loss: 0.20127 (A-MSE: 0.18077) avg lploss: 0.00000
==> val epoch 1340 avg loss: 0.90484 (A-MSE: 0.79544) avg lploss: 0.00000
==> test epoch 1340 avg loss: 1.03111 (A-MSE: 0.91408) avg lploss: 0.00000
*** Best Val Loss: 0.86132 	 Best Test Loss: 1.03419 	 Best epoch 1330
EarlyStopping counter: 2 out of 50
train epoch 1341 avg loss: 0.19879 (A-MSE: 0.17714) avg lploss: 0.00000
train epoch 1342 avg loss: 0.22182 (A-MSE: 0.19779) avg lploss: 0.00000
train epoch 1343 avg loss: 0.24258 (A-MSE: 0.21477) avg lploss: 0.00000
train epoch 1344 avg loss: 0.23174 (A-MSE: 0.20687) avg lploss: 0.00000
train epoch 1345 avg loss: 0.22847 (A-MSE: 0.20577) avg lploss: 0.00000
==> val epoch 1345 avg loss: 0.98502 (A-MSE: 0.86831) avg lploss: 0.00000
==> test epoch 1345 avg loss: 1.08891 (A-MSE: 0.96361) avg lploss: 0.00000
*** Best Val Loss: 0.86132 	 Best Test Loss: 1.03419 	 Best epoch 1330
EarlyStopping counter: 3 out of 50
train epoch 1346 avg loss: 0.24237 (A-MSE: 0.21434) avg lploss: 0.00000
train epoch 1347 avg loss: 0.28025 (A-MSE: 0.25198) avg lploss: 0.00000
train epoch 1348 avg loss: 0.25690 (A-MSE: 0.22996) avg lploss: 0.00000
train epoch 1349 avg loss: 0.22361 (A-MSE: 0.20028) avg lploss: 0.00000
train epoch 1350 avg loss: 0.22061 (A-MSE: 0.19717) avg lploss: 0.00000
==> val epoch 1350 avg loss: 0.85369 (A-MSE: 0.75529) avg lploss: 0.00000
==> test epoch 1350 avg loss: 0.98639 (A-MSE: 0.87818) avg lploss: 0.00000
*** Best Val Loss: 0.85369 	 Best Test Loss: 0.98639 	 Best epoch 1350
Validation loss decreased (0.861323 --> 0.853694).  Saving model ...
train epoch 1351 avg loss: 0.21814 (A-MSE: 0.19402) avg lploss: 0.00000
train epoch 1352 avg loss: 0.24013 (A-MSE: 0.21280) avg lploss: 0.00000
train epoch 1353 avg loss: 0.23279 (A-MSE: 0.20773) avg lploss: 0.00000
train epoch 1354 avg loss: 0.22868 (A-MSE: 0.20570) avg lploss: 0.00000
train epoch 1355 avg loss: 0.32643 (A-MSE: 0.29180) avg lploss: 0.00000
==> val epoch 1355 avg loss: 1.14441 (A-MSE: 1.02339) avg lploss: 0.00000
==> test epoch 1355 avg loss: 1.22470 (A-MSE: 1.10695) avg lploss: 0.00000
*** Best Val Loss: 0.85369 	 Best Test Loss: 0.98639 	 Best epoch 1350
EarlyStopping counter: 1 out of 50
train epoch 1356 avg loss: 0.28032 (A-MSE: 0.25214) avg lploss: 0.00000
train epoch 1357 avg loss: 0.22200 (A-MSE: 0.19899) avg lploss: 0.00000
train epoch 1358 avg loss: 0.20059 (A-MSE: 0.17986) avg lploss: 0.00000
train epoch 1359 avg loss: 0.21762 (A-MSE: 0.19506) avg lploss: 0.00000
train epoch 1360 avg loss: 0.19480 (A-MSE: 0.17377) avg lploss: 0.00000
==> val epoch 1360 avg loss: 1.03075 (A-MSE: 0.90518) avg lploss: 0.00000
==> test epoch 1360 avg loss: 1.12418 (A-MSE: 0.99371) avg lploss: 0.00000
*** Best Val Loss: 0.85369 	 Best Test Loss: 0.98639 	 Best epoch 1350
EarlyStopping counter: 2 out of 50
train epoch 1361 avg loss: 0.21583 (A-MSE: 0.19212) avg lploss: 0.00000
train epoch 1362 avg loss: 0.21083 (A-MSE: 0.18799) avg lploss: 0.00000
train epoch 1363 avg loss: 0.20882 (A-MSE: 0.18761) avg lploss: 0.00000
train epoch 1364 avg loss: 0.23304 (A-MSE: 0.20645) avg lploss: 0.00000
train epoch 1365 avg loss: 0.24616 (A-MSE: 0.21885) avg lploss: 0.00000
==> val epoch 1365 avg loss: 0.96191 (A-MSE: 0.84590) avg lploss: 0.00000
==> test epoch 1365 avg loss: 1.08073 (A-MSE: 0.95896) avg lploss: 0.00000
*** Best Val Loss: 0.85369 	 Best Test Loss: 0.98639 	 Best epoch 1350
EarlyStopping counter: 3 out of 50
train epoch 1366 avg loss: 0.22957 (A-MSE: 0.20527) avg lploss: 0.00000
train epoch 1367 avg loss: 0.19870 (A-MSE: 0.17801) avg lploss: 0.00000
train epoch 1368 avg loss: 0.20835 (A-MSE: 0.18740) avg lploss: 0.00000
train epoch 1369 avg loss: 0.22301 (A-MSE: 0.20014) avg lploss: 0.00000
train epoch 1370 avg loss: 0.22279 (A-MSE: 0.19758) avg lploss: 0.00000
==> val epoch 1370 avg loss: 0.83867 (A-MSE: 0.74146) avg lploss: 0.00000
==> test epoch 1370 avg loss: 1.01141 (A-MSE: 0.90006) avg lploss: 0.00000
*** Best Val Loss: 0.83867 	 Best Test Loss: 1.01141 	 Best epoch 1370
Validation loss decreased (0.853694 --> 0.838673).  Saving model ...
train epoch 1371 avg loss: 0.22124 (A-MSE: 0.19709) avg lploss: 0.00000
train epoch 1372 avg loss: 0.21754 (A-MSE: 0.19431) avg lploss: 0.00000
train epoch 1373 avg loss: 0.25518 (A-MSE: 0.22815) avg lploss: 0.00000
train epoch 1374 avg loss: 0.23908 (A-MSE: 0.21336) avg lploss: 0.00000
train epoch 1375 avg loss: 0.23520 (A-MSE: 0.20950) avg lploss: 0.00000
==> val epoch 1375 avg loss: 1.00962 (A-MSE: 0.89111) avg lploss: 0.00000
==> test epoch 1375 avg loss: 1.13288 (A-MSE: 1.01276) avg lploss: 0.00000
*** Best Val Loss: 0.83867 	 Best Test Loss: 1.01141 	 Best epoch 1370
EarlyStopping counter: 1 out of 50
train epoch 1376 avg loss: 0.21040 (A-MSE: 0.18809) avg lploss: 0.00000
train epoch 1377 avg loss: 0.22568 (A-MSE: 0.20113) avg lploss: 0.00000
train epoch 1378 avg loss: 0.22392 (A-MSE: 0.20113) avg lploss: 0.00000
train epoch 1379 avg loss: 0.21551 (A-MSE: 0.19289) avg lploss: 0.00000
train epoch 1380 avg loss: 0.23737 (A-MSE: 0.21185) avg lploss: 0.00000
==> val epoch 1380 avg loss: 0.79371 (A-MSE: 0.70609) avg lploss: 0.00000
==> test epoch 1380 avg loss: 0.95346 (A-MSE: 0.85693) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
Validation loss decreased (0.838673 --> 0.793705).  Saving model ...
train epoch 1381 avg loss: 0.24107 (A-MSE: 0.21571) avg lploss: 0.00000
train epoch 1382 avg loss: 0.22285 (A-MSE: 0.19833) avg lploss: 0.00000
train epoch 1383 avg loss: 0.20609 (A-MSE: 0.18265) avg lploss: 0.00000
train epoch 1384 avg loss: 0.18542 (A-MSE: 0.16636) avg lploss: 0.00000
train epoch 1385 avg loss: 0.20229 (A-MSE: 0.18033) avg lploss: 0.00000
==> val epoch 1385 avg loss: 0.95501 (A-MSE: 0.84218) avg lploss: 0.00000
==> test epoch 1385 avg loss: 1.00207 (A-MSE: 0.89220) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 1 out of 50
train epoch 1386 avg loss: 0.21707 (A-MSE: 0.19264) avg lploss: 0.00000
train epoch 1387 avg loss: 0.20551 (A-MSE: 0.18418) avg lploss: 0.00000
train epoch 1388 avg loss: 0.18574 (A-MSE: 0.16674) avg lploss: 0.00000
train epoch 1389 avg loss: 0.20154 (A-MSE: 0.18062) avg lploss: 0.00000
train epoch 1390 avg loss: 0.20756 (A-MSE: 0.18546) avg lploss: 0.00000
==> val epoch 1390 avg loss: 0.81152 (A-MSE: 0.72166) avg lploss: 0.00000
==> test epoch 1390 avg loss: 0.92201 (A-MSE: 0.82587) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 2 out of 50
train epoch 1391 avg loss: 0.19314 (A-MSE: 0.17377) avg lploss: 0.00000
train epoch 1392 avg loss: 0.19301 (A-MSE: 0.17339) avg lploss: 0.00000
train epoch 1393 avg loss: 0.19864 (A-MSE: 0.17688) avg lploss: 0.00000
train epoch 1394 avg loss: 0.20836 (A-MSE: 0.18513) avg lploss: 0.00000
train epoch 1395 avg loss: 0.21414 (A-MSE: 0.19037) avg lploss: 0.00000
==> val epoch 1395 avg loss: 0.89873 (A-MSE: 0.79659) avg lploss: 0.00000
==> test epoch 1395 avg loss: 1.04655 (A-MSE: 0.93611) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 3 out of 50
train epoch 1396 avg loss: 0.21564 (A-MSE: 0.19325) avg lploss: 0.00000
train epoch 1397 avg loss: 0.20902 (A-MSE: 0.18775) avg lploss: 0.00000
train epoch 1398 avg loss: 0.20731 (A-MSE: 0.18519) avg lploss: 0.00000
train epoch 1399 avg loss: 0.20962 (A-MSE: 0.18567) avg lploss: 0.00000
train epoch 1400 avg loss: 0.19710 (A-MSE: 0.17637) avg lploss: 0.00000
==> val epoch 1400 avg loss: 0.94692 (A-MSE: 0.83350) avg lploss: 0.00000
==> test epoch 1400 avg loss: 1.07885 (A-MSE: 0.96192) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 4 out of 50
train epoch 1401 avg loss: 0.19097 (A-MSE: 0.17006) avg lploss: 0.00000
train epoch 1402 avg loss: 0.20386 (A-MSE: 0.18220) avg lploss: 0.00000
train epoch 1403 avg loss: 0.23905 (A-MSE: 0.21479) avg lploss: 0.00000
train epoch 1404 avg loss: 0.22494 (A-MSE: 0.20015) avg lploss: 0.00000
train epoch 1405 avg loss: 0.21941 (A-MSE: 0.19737) avg lploss: 0.00000
==> val epoch 1405 avg loss: 0.92528 (A-MSE: 0.82699) avg lploss: 0.00000
==> test epoch 1405 avg loss: 1.05012 (A-MSE: 0.94684) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 5 out of 50
train epoch 1406 avg loss: 0.24876 (A-MSE: 0.22291) avg lploss: 0.00000
train epoch 1407 avg loss: 0.24423 (A-MSE: 0.21848) avg lploss: 0.00000
train epoch 1408 avg loss: 0.22984 (A-MSE: 0.20513) avg lploss: 0.00000
train epoch 1409 avg loss: 0.22668 (A-MSE: 0.20248) avg lploss: 0.00000
train epoch 1410 avg loss: 0.19980 (A-MSE: 0.17932) avg lploss: 0.00000
==> val epoch 1410 avg loss: 0.82615 (A-MSE: 0.73984) avg lploss: 0.00000
==> test epoch 1410 avg loss: 0.96041 (A-MSE: 0.86229) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 6 out of 50
train epoch 1411 avg loss: 0.18796 (A-MSE: 0.16654) avg lploss: 0.00000
train epoch 1412 avg loss: 0.20267 (A-MSE: 0.18088) avg lploss: 0.00000
train epoch 1413 avg loss: 0.20229 (A-MSE: 0.18212) avg lploss: 0.00000
train epoch 1414 avg loss: 0.20030 (A-MSE: 0.17875) avg lploss: 0.00000
train epoch 1415 avg loss: 0.22731 (A-MSE: 0.20288) avg lploss: 0.00000
==> val epoch 1415 avg loss: 1.01181 (A-MSE: 0.90992) avg lploss: 0.00000
==> test epoch 1415 avg loss: 1.12321 (A-MSE: 1.01956) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 7 out of 50
train epoch 1416 avg loss: 0.25432 (A-MSE: 0.22761) avg lploss: 0.00000
train epoch 1417 avg loss: 0.23034 (A-MSE: 0.20464) avg lploss: 0.00000
train epoch 1418 avg loss: 0.20609 (A-MSE: 0.18365) avg lploss: 0.00000
train epoch 1419 avg loss: 0.21777 (A-MSE: 0.19474) avg lploss: 0.00000
train epoch 1420 avg loss: 0.20179 (A-MSE: 0.18010) avg lploss: 0.00000
==> val epoch 1420 avg loss: 0.89038 (A-MSE: 0.78886) avg lploss: 0.00000
==> test epoch 1420 avg loss: 0.98459 (A-MSE: 0.87831) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 8 out of 50
train epoch 1421 avg loss: 0.18458 (A-MSE: 0.16443) avg lploss: 0.00000
train epoch 1422 avg loss: 0.21978 (A-MSE: 0.19659) avg lploss: 0.00000
train epoch 1423 avg loss: 0.18168 (A-MSE: 0.16177) avg lploss: 0.00000
train epoch 1424 avg loss: 0.17598 (A-MSE: 0.15785) avg lploss: 0.00000
train epoch 1425 avg loss: 0.18015 (A-MSE: 0.16142) avg lploss: 0.00000
==> val epoch 1425 avg loss: 0.91855 (A-MSE: 0.81484) avg lploss: 0.00000
==> test epoch 1425 avg loss: 1.01272 (A-MSE: 0.91190) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 9 out of 50
train epoch 1426 avg loss: 0.20969 (A-MSE: 0.18554) avg lploss: 0.00000
train epoch 1427 avg loss: 0.23960 (A-MSE: 0.21490) avg lploss: 0.00000
train epoch 1428 avg loss: 0.20900 (A-MSE: 0.18668) avg lploss: 0.00000
train epoch 1429 avg loss: 0.21445 (A-MSE: 0.19177) avg lploss: 0.00000
train epoch 1430 avg loss: 0.20260 (A-MSE: 0.18062) avg lploss: 0.00000
==> val epoch 1430 avg loss: 0.86174 (A-MSE: 0.75902) avg lploss: 0.00000
==> test epoch 1430 avg loss: 0.99344 (A-MSE: 0.88807) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 10 out of 50
train epoch 1431 avg loss: 0.19110 (A-MSE: 0.17114) avg lploss: 0.00000
train epoch 1432 avg loss: 0.18135 (A-MSE: 0.16144) avg lploss: 0.00000
train epoch 1433 avg loss: 0.17884 (A-MSE: 0.15985) avg lploss: 0.00000
train epoch 1434 avg loss: 0.17720 (A-MSE: 0.15758) avg lploss: 0.00000
train epoch 1435 avg loss: 0.17002 (A-MSE: 0.15092) avg lploss: 0.00000
==> val epoch 1435 avg loss: 0.81196 (A-MSE: 0.72068) avg lploss: 0.00000
==> test epoch 1435 avg loss: 0.96062 (A-MSE: 0.86073) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 11 out of 50
train epoch 1436 avg loss: 0.17673 (A-MSE: 0.15803) avg lploss: 0.00000
train epoch 1437 avg loss: 0.19786 (A-MSE: 0.17534) avg lploss: 0.00000
train epoch 1438 avg loss: 0.17483 (A-MSE: 0.15516) avg lploss: 0.00000
train epoch 1439 avg loss: 0.18852 (A-MSE: 0.16897) avg lploss: 0.00000
train epoch 1440 avg loss: 0.20623 (A-MSE: 0.18374) avg lploss: 0.00000
==> val epoch 1440 avg loss: 0.84357 (A-MSE: 0.74802) avg lploss: 0.00000
==> test epoch 1440 avg loss: 0.93320 (A-MSE: 0.84016) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 12 out of 50
train epoch 1441 avg loss: 0.28132 (A-MSE: 0.24901) avg lploss: 0.00000
train epoch 1442 avg loss: 0.27683 (A-MSE: 0.24707) avg lploss: 0.00000
train epoch 1443 avg loss: 0.30052 (A-MSE: 0.26861) avg lploss: 0.00000
train epoch 1444 avg loss: 0.17794 (A-MSE: 0.15937) avg lploss: 0.00000
train epoch 1445 avg loss: 0.20452 (A-MSE: 0.18042) avg lploss: 0.00000
==> val epoch 1445 avg loss: 0.90959 (A-MSE: 0.81102) avg lploss: 0.00000
==> test epoch 1445 avg loss: 0.95917 (A-MSE: 0.84951) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 13 out of 50
train epoch 1446 avg loss: 0.21292 (A-MSE: 0.18941) avg lploss: 0.00000
train epoch 1447 avg loss: 0.19424 (A-MSE: 0.17427) avg lploss: 0.00000
train epoch 1448 avg loss: 0.21303 (A-MSE: 0.19033) avg lploss: 0.00000
train epoch 1449 avg loss: 0.21668 (A-MSE: 0.19251) avg lploss: 0.00000
train epoch 1450 avg loss: 0.21527 (A-MSE: 0.19450) avg lploss: 0.00000
==> val epoch 1450 avg loss: 1.06429 (A-MSE: 0.94125) avg lploss: 0.00000
==> test epoch 1450 avg loss: 1.09282 (A-MSE: 0.96677) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 14 out of 50
train epoch 1451 avg loss: 0.20806 (A-MSE: 0.18365) avg lploss: 0.00000
train epoch 1452 avg loss: 0.18044 (A-MSE: 0.16133) avg lploss: 0.00000
train epoch 1453 avg loss: 0.20221 (A-MSE: 0.17995) avg lploss: 0.00000
train epoch 1454 avg loss: 0.21975 (A-MSE: 0.19528) avg lploss: 0.00000
train epoch 1455 avg loss: 0.21657 (A-MSE: 0.19372) avg lploss: 0.00000
==> val epoch 1455 avg loss: 0.82926 (A-MSE: 0.73488) avg lploss: 0.00000
==> test epoch 1455 avg loss: 0.93710 (A-MSE: 0.83574) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 15 out of 50
train epoch 1456 avg loss: 0.19688 (A-MSE: 0.17548) avg lploss: 0.00000
train epoch 1457 avg loss: 0.18111 (A-MSE: 0.16205) avg lploss: 0.00000
train epoch 1458 avg loss: 0.19194 (A-MSE: 0.17079) avg lploss: 0.00000
train epoch 1459 avg loss: 0.20817 (A-MSE: 0.18725) avg lploss: 0.00000
train epoch 1460 avg loss: 0.18404 (A-MSE: 0.16395) avg lploss: 0.00000
==> val epoch 1460 avg loss: 0.81458 (A-MSE: 0.71478) avg lploss: 0.00000
==> test epoch 1460 avg loss: 0.92801 (A-MSE: 0.82557) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 16 out of 50
train epoch 1461 avg loss: 0.17560 (A-MSE: 0.15666) avg lploss: 0.00000
train epoch 1462 avg loss: 0.18130 (A-MSE: 0.16193) avg lploss: 0.00000
train epoch 1463 avg loss: 0.15981 (A-MSE: 0.14283) avg lploss: 0.00000
train epoch 1464 avg loss: 0.17124 (A-MSE: 0.15312) avg lploss: 0.00000
train epoch 1465 avg loss: 0.16879 (A-MSE: 0.15006) avg lploss: 0.00000
==> val epoch 1465 avg loss: 0.86666 (A-MSE: 0.77506) avg lploss: 0.00000
==> test epoch 1465 avg loss: 0.95687 (A-MSE: 0.85694) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 17 out of 50
train epoch 1466 avg loss: 0.16649 (A-MSE: 0.14822) avg lploss: 0.00000
train epoch 1467 avg loss: 0.21983 (A-MSE: 0.19593) avg lploss: 0.00000
train epoch 1468 avg loss: 0.24309 (A-MSE: 0.21774) avg lploss: 0.00000
train epoch 1469 avg loss: 0.23093 (A-MSE: 0.20445) avg lploss: 0.00000
train epoch 1470 avg loss: 0.22060 (A-MSE: 0.19521) avg lploss: 0.00000
==> val epoch 1470 avg loss: 1.18360 (A-MSE: 1.05891) avg lploss: 0.00000
==> test epoch 1470 avg loss: 1.26778 (A-MSE: 1.14273) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 18 out of 50
train epoch 1471 avg loss: 0.25957 (A-MSE: 0.23234) avg lploss: 0.00000
train epoch 1472 avg loss: 0.22306 (A-MSE: 0.20121) avg lploss: 0.00000
train epoch 1473 avg loss: 0.19916 (A-MSE: 0.17784) avg lploss: 0.00000
train epoch 1474 avg loss: 0.19199 (A-MSE: 0.17028) avg lploss: 0.00000
train epoch 1475 avg loss: 0.17242 (A-MSE: 0.15553) avg lploss: 0.00000
==> val epoch 1475 avg loss: 0.83034 (A-MSE: 0.73474) avg lploss: 0.00000
==> test epoch 1475 avg loss: 0.88961 (A-MSE: 0.79692) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 19 out of 50
train epoch 1476 avg loss: 0.16927 (A-MSE: 0.15047) avg lploss: 0.00000
train epoch 1477 avg loss: 0.16550 (A-MSE: 0.14797) avg lploss: 0.00000
train epoch 1478 avg loss: 0.14806 (A-MSE: 0.13121) avg lploss: 0.00000
train epoch 1479 avg loss: 0.14119 (A-MSE: 0.12643) avg lploss: 0.00000
train epoch 1480 avg loss: 0.14583 (A-MSE: 0.12945) avg lploss: 0.00000
==> val epoch 1480 avg loss: 0.80866 (A-MSE: 0.71573) avg lploss: 0.00000
==> test epoch 1480 avg loss: 0.88630 (A-MSE: 0.78935) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 20 out of 50
train epoch 1481 avg loss: 0.18538 (A-MSE: 0.16522) avg lploss: 0.00000
train epoch 1482 avg loss: 0.21992 (A-MSE: 0.19783) avg lploss: 0.00000
train epoch 1483 avg loss: 0.19935 (A-MSE: 0.17689) avg lploss: 0.00000
train epoch 1484 avg loss: 0.17173 (A-MSE: 0.15141) avg lploss: 0.00000
train epoch 1485 avg loss: 0.15860 (A-MSE: 0.14194) avg lploss: 0.00000
==> val epoch 1485 avg loss: 0.81429 (A-MSE: 0.72335) avg lploss: 0.00000
==> test epoch 1485 avg loss: 0.94874 (A-MSE: 0.85710) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 21 out of 50
train epoch 1486 avg loss: 0.17645 (A-MSE: 0.15640) avg lploss: 0.00000
train epoch 1487 avg loss: 0.17145 (A-MSE: 0.15071) avg lploss: 0.00000
train epoch 1488 avg loss: 0.16767 (A-MSE: 0.14985) avg lploss: 0.00000
train epoch 1489 avg loss: 0.18538 (A-MSE: 0.16429) avg lploss: 0.00000
train epoch 1490 avg loss: 0.19658 (A-MSE: 0.17700) avg lploss: 0.00000
==> val epoch 1490 avg loss: 0.84887 (A-MSE: 0.74834) avg lploss: 0.00000
==> test epoch 1490 avg loss: 0.96541 (A-MSE: 0.85690) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 22 out of 50
train epoch 1491 avg loss: 0.20289 (A-MSE: 0.18015) avg lploss: 0.00000
train epoch 1492 avg loss: 0.20825 (A-MSE: 0.18509) avg lploss: 0.00000
train epoch 1493 avg loss: 0.21301 (A-MSE: 0.18977) avg lploss: 0.00000
train epoch 1494 avg loss: 0.20529 (A-MSE: 0.18384) avg lploss: 0.00000
train epoch 1495 avg loss: 0.16673 (A-MSE: 0.14883) avg lploss: 0.00000
==> val epoch 1495 avg loss: 0.87160 (A-MSE: 0.76134) avg lploss: 0.00000
==> test epoch 1495 avg loss: 0.93688 (A-MSE: 0.83411) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 23 out of 50
train epoch 1496 avg loss: 0.17888 (A-MSE: 0.15971) avg lploss: 0.00000
train epoch 1497 avg loss: 0.17323 (A-MSE: 0.15497) avg lploss: 0.00000
train epoch 1498 avg loss: 0.18464 (A-MSE: 0.16392) avg lploss: 0.00000
train epoch 1499 avg loss: 0.15148 (A-MSE: 0.13656) avg lploss: 0.00000
train epoch 1500 avg loss: 0.16670 (A-MSE: 0.14895) avg lploss: 0.00000
==> val epoch 1500 avg loss: 1.06716 (A-MSE: 0.93474) avg lploss: 0.00000
==> test epoch 1500 avg loss: 1.10351 (A-MSE: 0.97952) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 24 out of 50
train epoch 1501 avg loss: 0.16505 (A-MSE: 0.14676) avg lploss: 0.00000
train epoch 1502 avg loss: 0.18468 (A-MSE: 0.16412) avg lploss: 0.00000
train epoch 1503 avg loss: 0.17232 (A-MSE: 0.15392) avg lploss: 0.00000
train epoch 1504 avg loss: 0.19804 (A-MSE: 0.17618) avg lploss: 0.00000
train epoch 1505 avg loss: 0.23842 (A-MSE: 0.21088) avg lploss: 0.00000
==> val epoch 1505 avg loss: 0.91851 (A-MSE: 0.81803) avg lploss: 0.00000
==> test epoch 1505 avg loss: 1.02351 (A-MSE: 0.91478) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 25 out of 50
train epoch 1506 avg loss: 0.19173 (A-MSE: 0.16993) avg lploss: 0.00000
train epoch 1507 avg loss: 0.18051 (A-MSE: 0.16068) avg lploss: 0.00000
train epoch 1508 avg loss: 0.20347 (A-MSE: 0.18214) avg lploss: 0.00000
train epoch 1509 avg loss: 0.20194 (A-MSE: 0.18128) avg lploss: 0.00000
train epoch 1510 avg loss: 0.17976 (A-MSE: 0.16073) avg lploss: 0.00000
==> val epoch 1510 avg loss: 0.93502 (A-MSE: 0.83247) avg lploss: 0.00000
==> test epoch 1510 avg loss: 1.02210 (A-MSE: 0.92303) avg lploss: 0.00000
*** Best Val Loss: 0.79371 	 Best Test Loss: 0.95346 	 Best epoch 1380
EarlyStopping counter: 26 out of 50
train epoch 1511 avg loss: 0.17201 (A-MSE: 0.15285) avg lploss: 0.00000
train epoch 1512 avg loss: 0.18413 (A-MSE: 0.16381) avg lploss: 0.00000
train epoch 1513 avg loss: 0.16623 (A-MSE: 0.14850) avg lploss: 0.00000
train epoch 1514 avg loss: 0.16421 (A-MSE: 0.14678) avg lploss: 0.00000
train epoch 1515 avg loss: 0.18958 (A-MSE: 0.16879) avg lploss: 0.00000
==> val epoch 1515 avg loss: 0.77587 (A-MSE: 0.68963) avg lploss: 0.00000
==> test epoch 1515 avg loss: 0.86282 (A-MSE: 0.77328) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
Validation loss decreased (0.793705 --> 0.775872).  Saving model ...
train epoch 1516 avg loss: 0.22799 (A-MSE: 0.20273) avg lploss: 0.00000
train epoch 1517 avg loss: 0.19134 (A-MSE: 0.17168) avg lploss: 0.00000
train epoch 1518 avg loss: 0.17300 (A-MSE: 0.15353) avg lploss: 0.00000
train epoch 1519 avg loss: 0.19881 (A-MSE: 0.17793) avg lploss: 0.00000
train epoch 1520 avg loss: 0.20094 (A-MSE: 0.17726) avg lploss: 0.00000
==> val epoch 1520 avg loss: 0.81480 (A-MSE: 0.73272) avg lploss: 0.00000
==> test epoch 1520 avg loss: 0.86784 (A-MSE: 0.78685) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
EarlyStopping counter: 1 out of 50
train epoch 1521 avg loss: 0.17459 (A-MSE: 0.15508) avg lploss: 0.00000
train epoch 1522 avg loss: 0.14055 (A-MSE: 0.12623) avg lploss: 0.00000
train epoch 1523 avg loss: 0.14023 (A-MSE: 0.12410) avg lploss: 0.00000
train epoch 1524 avg loss: 0.14795 (A-MSE: 0.13202) avg lploss: 0.00000
train epoch 1525 avg loss: 0.15236 (A-MSE: 0.13637) avg lploss: 0.00000
==> val epoch 1525 avg loss: 0.85138 (A-MSE: 0.75238) avg lploss: 0.00000
==> test epoch 1525 avg loss: 0.98977 (A-MSE: 0.88781) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
EarlyStopping counter: 2 out of 50
train epoch 1526 avg loss: 0.16662 (A-MSE: 0.14935) avg lploss: 0.00000
train epoch 1527 avg loss: 0.16001 (A-MSE: 0.14325) avg lploss: 0.00000
train epoch 1528 avg loss: 0.16010 (A-MSE: 0.14290) avg lploss: 0.00000
train epoch 1529 avg loss: 0.15256 (A-MSE: 0.13783) avg lploss: 0.00000
train epoch 1530 avg loss: 0.17127 (A-MSE: 0.15303) avg lploss: 0.00000
==> val epoch 1530 avg loss: 0.89387 (A-MSE: 0.78931) avg lploss: 0.00000
==> test epoch 1530 avg loss: 0.96126 (A-MSE: 0.85965) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
EarlyStopping counter: 3 out of 50
train epoch 1531 avg loss: 0.15761 (A-MSE: 0.14022) avg lploss: 0.00000
train epoch 1532 avg loss: 0.15334 (A-MSE: 0.13719) avg lploss: 0.00000
train epoch 1533 avg loss: 0.14757 (A-MSE: 0.13195) avg lploss: 0.00000
train epoch 1534 avg loss: 0.14357 (A-MSE: 0.12814) avg lploss: 0.00000
train epoch 1535 avg loss: 0.14798 (A-MSE: 0.13091) avg lploss: 0.00000
==> val epoch 1535 avg loss: 0.77991 (A-MSE: 0.69187) avg lploss: 0.00000
==> test epoch 1535 avg loss: 0.86235 (A-MSE: 0.77116) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
EarlyStopping counter: 4 out of 50
train epoch 1536 avg loss: 0.16190 (A-MSE: 0.14346) avg lploss: 0.00000
train epoch 1537 avg loss: 0.15153 (A-MSE: 0.13464) avg lploss: 0.00000
train epoch 1538 avg loss: 0.17724 (A-MSE: 0.15769) avg lploss: 0.00000
train epoch 1539 avg loss: 0.18421 (A-MSE: 0.16310) avg lploss: 0.00000
train epoch 1540 avg loss: 0.17346 (A-MSE: 0.15382) avg lploss: 0.00000
==> val epoch 1540 avg loss: 0.79651 (A-MSE: 0.70604) avg lploss: 0.00000
==> test epoch 1540 avg loss: 0.90061 (A-MSE: 0.81024) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
EarlyStopping counter: 5 out of 50
train epoch 1541 avg loss: 0.19788 (A-MSE: 0.17549) avg lploss: 0.00000
train epoch 1542 avg loss: 0.19720 (A-MSE: 0.17470) avg lploss: 0.00000
train epoch 1543 avg loss: 0.18958 (A-MSE: 0.16769) avg lploss: 0.00000
train epoch 1544 avg loss: 0.17195 (A-MSE: 0.15223) avg lploss: 0.00000
train epoch 1545 avg loss: 0.16867 (A-MSE: 0.15085) avg lploss: 0.00000
==> val epoch 1545 avg loss: 0.79233 (A-MSE: 0.70516) avg lploss: 0.00000
==> test epoch 1545 avg loss: 0.86679 (A-MSE: 0.77772) avg lploss: 0.00000
*** Best Val Loss: 0.77587 	 Best Test Loss: 0.86282 	 Best epoch 1515
EarlyStopping counter: 6 out of 50
train epoch 1546 avg loss: 0.14326 (A-MSE: 0.12715) avg lploss: 0.00000
train epoch 1547 avg loss: 0.16491 (A-MSE: 0.14630) avg lploss: 0.00000
train epoch 1548 avg loss: 0.17197 (A-MSE: 0.15410) avg lploss: 0.00000
train epoch 1549 avg loss: 0.17007 (A-MSE: 0.15355) avg lploss: 0.00000
train epoch 1550 avg loss: 0.16112 (A-MSE: 0.14331) avg lploss: 0.00000
==> val epoch 1550 avg loss: 0.74040 (A-MSE: 0.65488) avg lploss: 0.00000
==> test epoch 1550 avg loss: 0.85055 (A-MSE: 0.77256) avg lploss: 0.00000
*** Best Val Loss: 0.74040 	 Best Test Loss: 0.85055 	 Best epoch 1550
Validation loss decreased (0.775872 --> 0.740397).  Saving model ...
train epoch 1551 avg loss: 0.16921 (A-MSE: 0.15083) avg lploss: 0.00000
train epoch 1552 avg loss: 0.19056 (A-MSE: 0.16942) avg lploss: 0.00000
train epoch 1553 avg loss: 0.15712 (A-MSE: 0.13903) avg lploss: 0.00000
train epoch 1554 avg loss: 0.15152 (A-MSE: 0.13453) avg lploss: 0.00000
train epoch 1555 avg loss: 0.15330 (A-MSE: 0.13752) avg lploss: 0.00000
==> val epoch 1555 avg loss: 0.88182 (A-MSE: 0.76633) avg lploss: 0.00000
==> test epoch 1555 avg loss: 0.96331 (A-MSE: 0.85152) avg lploss: 0.00000
*** Best Val Loss: 0.74040 	 Best Test Loss: 0.85055 	 Best epoch 1550
EarlyStopping counter: 1 out of 50
train epoch 1556 avg loss: 0.16296 (A-MSE: 0.14493) avg lploss: 0.00000
train epoch 1557 avg loss: 0.18632 (A-MSE: 0.16615) avg lploss: 0.00000
train epoch 1558 avg loss: 0.17446 (A-MSE: 0.15583) avg lploss: 0.00000
train epoch 1559 avg loss: 0.17608 (A-MSE: 0.15683) avg lploss: 0.00000
train epoch 1560 avg loss: 0.16525 (A-MSE: 0.14723) avg lploss: 0.00000
==> val epoch 1560 avg loss: 0.70182 (A-MSE: 0.61965) avg lploss: 0.00000
==> test epoch 1560 avg loss: 0.78225 (A-MSE: 0.69911) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
Validation loss decreased (0.740397 --> 0.701821).  Saving model ...
train epoch 1561 avg loss: 0.15025 (A-MSE: 0.13362) avg lploss: 0.00000
train epoch 1562 avg loss: 0.16535 (A-MSE: 0.14581) avg lploss: 0.00000
train epoch 1563 avg loss: 0.16377 (A-MSE: 0.14618) avg lploss: 0.00000
train epoch 1564 avg loss: 0.16177 (A-MSE: 0.14417) avg lploss: 0.00000
train epoch 1565 avg loss: 0.14755 (A-MSE: 0.13166) avg lploss: 0.00000
==> val epoch 1565 avg loss: 0.81650 (A-MSE: 0.73187) avg lploss: 0.00000
==> test epoch 1565 avg loss: 0.91535 (A-MSE: 0.82840) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 1 out of 50
train epoch 1566 avg loss: 0.13675 (A-MSE: 0.12171) avg lploss: 0.00000
train epoch 1567 avg loss: 0.15251 (A-MSE: 0.13652) avg lploss: 0.00000
train epoch 1568 avg loss: 0.15545 (A-MSE: 0.13758) avg lploss: 0.00000
train epoch 1569 avg loss: 0.14506 (A-MSE: 0.12926) avg lploss: 0.00000
train epoch 1570 avg loss: 0.14569 (A-MSE: 0.13097) avg lploss: 0.00000
==> val epoch 1570 avg loss: 0.80740 (A-MSE: 0.71461) avg lploss: 0.00000
==> test epoch 1570 avg loss: 0.89021 (A-MSE: 0.80469) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 2 out of 50
train epoch 1571 avg loss: 0.14746 (A-MSE: 0.13125) avg lploss: 0.00000
train epoch 1572 avg loss: 0.15171 (A-MSE: 0.13560) avg lploss: 0.00000
train epoch 1573 avg loss: 0.15959 (A-MSE: 0.14262) avg lploss: 0.00000
train epoch 1574 avg loss: 0.16474 (A-MSE: 0.14734) avg lploss: 0.00000
train epoch 1575 avg loss: 0.15490 (A-MSE: 0.13849) avg lploss: 0.00000
==> val epoch 1575 avg loss: 0.82998 (A-MSE: 0.72613) avg lploss: 0.00000
==> test epoch 1575 avg loss: 0.90669 (A-MSE: 0.81033) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 3 out of 50
train epoch 1576 avg loss: 0.17750 (A-MSE: 0.15762) avg lploss: 0.00000
train epoch 1577 avg loss: 0.23932 (A-MSE: 0.21551) avg lploss: 0.00000
train epoch 1578 avg loss: 0.29749 (A-MSE: 0.26497) avg lploss: 0.00000
train epoch 1579 avg loss: 0.20797 (A-MSE: 0.18405) avg lploss: 0.00000
train epoch 1580 avg loss: 0.15979 (A-MSE: 0.14311) avg lploss: 0.00000
==> val epoch 1580 avg loss: 0.76358 (A-MSE: 0.67153) avg lploss: 0.00000
==> test epoch 1580 avg loss: 0.87699 (A-MSE: 0.79063) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 4 out of 50
train epoch 1581 avg loss: 0.14941 (A-MSE: 0.13403) avg lploss: 0.00000
train epoch 1582 avg loss: 0.15257 (A-MSE: 0.13504) avg lploss: 0.00000
train epoch 1583 avg loss: 0.18115 (A-MSE: 0.16105) avg lploss: 0.00000
train epoch 1584 avg loss: 0.17550 (A-MSE: 0.15630) avg lploss: 0.00000
train epoch 1585 avg loss: 0.16270 (A-MSE: 0.14531) avg lploss: 0.00000
==> val epoch 1585 avg loss: 0.84935 (A-MSE: 0.75453) avg lploss: 0.00000
==> test epoch 1585 avg loss: 0.93809 (A-MSE: 0.83895) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 5 out of 50
train epoch 1586 avg loss: 0.14917 (A-MSE: 0.13308) avg lploss: 0.00000
train epoch 1587 avg loss: 0.14282 (A-MSE: 0.12828) avg lploss: 0.00000
train epoch 1588 avg loss: 0.14321 (A-MSE: 0.12724) avg lploss: 0.00000
train epoch 1589 avg loss: 0.14185 (A-MSE: 0.12560) avg lploss: 0.00000
train epoch 1590 avg loss: 0.14380 (A-MSE: 0.12799) avg lploss: 0.00000
==> val epoch 1590 avg loss: 0.82795 (A-MSE: 0.72567) avg lploss: 0.00000
==> test epoch 1590 avg loss: 0.84244 (A-MSE: 0.75193) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 6 out of 50
train epoch 1591 avg loss: 0.16815 (A-MSE: 0.14917) avg lploss: 0.00000
train epoch 1592 avg loss: 0.19946 (A-MSE: 0.17717) avg lploss: 0.00000
train epoch 1593 avg loss: 0.17244 (A-MSE: 0.15249) avg lploss: 0.00000
train epoch 1594 avg loss: 0.16376 (A-MSE: 0.14496) avg lploss: 0.00000
train epoch 1595 avg loss: 0.20454 (A-MSE: 0.18292) avg lploss: 0.00000
==> val epoch 1595 avg loss: 0.94449 (A-MSE: 0.84384) avg lploss: 0.00000
==> test epoch 1595 avg loss: 0.94513 (A-MSE: 0.85701) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 7 out of 50
train epoch 1596 avg loss: 0.17011 (A-MSE: 0.15139) avg lploss: 0.00000
train epoch 1597 avg loss: 0.15437 (A-MSE: 0.13735) avg lploss: 0.00000
train epoch 1598 avg loss: 0.14769 (A-MSE: 0.13296) avg lploss: 0.00000
train epoch 1599 avg loss: 0.15108 (A-MSE: 0.13337) avg lploss: 0.00000
train epoch 1600 avg loss: 0.13280 (A-MSE: 0.11820) avg lploss: 0.00000
==> val epoch 1600 avg loss: 0.84511 (A-MSE: 0.74295) avg lploss: 0.00000
==> test epoch 1600 avg loss: 0.90959 (A-MSE: 0.81163) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 8 out of 50
train epoch 1601 avg loss: 0.13468 (A-MSE: 0.11997) avg lploss: 0.00000
train epoch 1602 avg loss: 0.17255 (A-MSE: 0.15290) avg lploss: 0.00000
train epoch 1603 avg loss: 0.15284 (A-MSE: 0.13653) avg lploss: 0.00000
train epoch 1604 avg loss: 0.15578 (A-MSE: 0.13790) avg lploss: 0.00000
train epoch 1605 avg loss: 0.13613 (A-MSE: 0.12136) avg lploss: 0.00000
==> val epoch 1605 avg loss: 0.78952 (A-MSE: 0.69285) avg lploss: 0.00000
==> test epoch 1605 avg loss: 0.89161 (A-MSE: 0.79725) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 9 out of 50
train epoch 1606 avg loss: 0.13483 (A-MSE: 0.11964) avg lploss: 0.00000
train epoch 1607 avg loss: 0.12185 (A-MSE: 0.10810) avg lploss: 0.00000
train epoch 1608 avg loss: 0.14790 (A-MSE: 0.13083) avg lploss: 0.00000
train epoch 1609 avg loss: 0.15085 (A-MSE: 0.13476) avg lploss: 0.00000
train epoch 1610 avg loss: 0.15388 (A-MSE: 0.13686) avg lploss: 0.00000
==> val epoch 1610 avg loss: 0.81427 (A-MSE: 0.71954) avg lploss: 0.00000
==> test epoch 1610 avg loss: 0.85098 (A-MSE: 0.75867) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 10 out of 50
train epoch 1611 avg loss: 0.15697 (A-MSE: 0.14065) avg lploss: 0.00000
train epoch 1612 avg loss: 0.14594 (A-MSE: 0.12962) avg lploss: 0.00000
train epoch 1613 avg loss: 0.13493 (A-MSE: 0.11988) avg lploss: 0.00000
train epoch 1614 avg loss: 0.13845 (A-MSE: 0.12426) avg lploss: 0.00000
train epoch 1615 avg loss: 0.14826 (A-MSE: 0.13233) avg lploss: 0.00000
==> val epoch 1615 avg loss: 0.85865 (A-MSE: 0.76386) avg lploss: 0.00000
==> test epoch 1615 avg loss: 0.91989 (A-MSE: 0.82982) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 11 out of 50
train epoch 1616 avg loss: 0.13847 (A-MSE: 0.12188) avg lploss: 0.00000
train epoch 1617 avg loss: 0.14996 (A-MSE: 0.13359) avg lploss: 0.00000
train epoch 1618 avg loss: 0.17887 (A-MSE: 0.15864) avg lploss: 0.00000
train epoch 1619 avg loss: 0.17834 (A-MSE: 0.15780) avg lploss: 0.00000
train epoch 1620 avg loss: 0.16009 (A-MSE: 0.14286) avg lploss: 0.00000
==> val epoch 1620 avg loss: 0.74774 (A-MSE: 0.66460) avg lploss: 0.00000
==> test epoch 1620 avg loss: 0.80982 (A-MSE: 0.73464) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 12 out of 50
train epoch 1621 avg loss: 0.13010 (A-MSE: 0.11556) avg lploss: 0.00000
train epoch 1622 avg loss: 0.13338 (A-MSE: 0.11962) avg lploss: 0.00000
train epoch 1623 avg loss: 0.15652 (A-MSE: 0.13763) avg lploss: 0.00000
train epoch 1624 avg loss: 0.14507 (A-MSE: 0.12860) avg lploss: 0.00000
train epoch 1625 avg loss: 0.13902 (A-MSE: 0.12336) avg lploss: 0.00000
==> val epoch 1625 avg loss: 0.82715 (A-MSE: 0.72647) avg lploss: 0.00000
==> test epoch 1625 avg loss: 0.91351 (A-MSE: 0.81835) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 13 out of 50
train epoch 1626 avg loss: 0.13948 (A-MSE: 0.12338) avg lploss: 0.00000
train epoch 1627 avg loss: 0.13336 (A-MSE: 0.11782) avg lploss: 0.00000
train epoch 1628 avg loss: 0.14895 (A-MSE: 0.13254) avg lploss: 0.00000
train epoch 1629 avg loss: 0.16509 (A-MSE: 0.14753) avg lploss: 0.00000
train epoch 1630 avg loss: 0.13563 (A-MSE: 0.12099) avg lploss: 0.00000
==> val epoch 1630 avg loss: 0.77962 (A-MSE: 0.67870) avg lploss: 0.00000
==> test epoch 1630 avg loss: 0.83175 (A-MSE: 0.73360) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 14 out of 50
train epoch 1631 avg loss: 0.12460 (A-MSE: 0.11015) avg lploss: 0.00000
train epoch 1632 avg loss: 0.13849 (A-MSE: 0.12302) avg lploss: 0.00000
train epoch 1633 avg loss: 0.15016 (A-MSE: 0.13325) avg lploss: 0.00000
train epoch 1634 avg loss: 0.14180 (A-MSE: 0.12479) avg lploss: 0.00000
train epoch 1635 avg loss: 0.12607 (A-MSE: 0.11253) avg lploss: 0.00000
==> val epoch 1635 avg loss: 0.79091 (A-MSE: 0.70097) avg lploss: 0.00000
==> test epoch 1635 avg loss: 0.84232 (A-MSE: 0.75691) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 15 out of 50
train epoch 1636 avg loss: 0.13822 (A-MSE: 0.12311) avg lploss: 0.00000
train epoch 1637 avg loss: 0.14163 (A-MSE: 0.12639) avg lploss: 0.00000
train epoch 1638 avg loss: 0.13276 (A-MSE: 0.11907) avg lploss: 0.00000
train epoch 1639 avg loss: 0.13799 (A-MSE: 0.12233) avg lploss: 0.00000
train epoch 1640 avg loss: 0.14981 (A-MSE: 0.13436) avg lploss: 0.00000
==> val epoch 1640 avg loss: 0.73842 (A-MSE: 0.65655) avg lploss: 0.00000
==> test epoch 1640 avg loss: 0.79539 (A-MSE: 0.72147) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 16 out of 50
train epoch 1641 avg loss: 0.14219 (A-MSE: 0.12683) avg lploss: 0.00000
train epoch 1642 avg loss: 0.16425 (A-MSE: 0.14529) avg lploss: 0.00000
train epoch 1643 avg loss: 0.15465 (A-MSE: 0.13795) avg lploss: 0.00000
train epoch 1644 avg loss: 0.14473 (A-MSE: 0.12937) avg lploss: 0.00000
train epoch 1645 avg loss: 0.13465 (A-MSE: 0.11939) avg lploss: 0.00000
==> val epoch 1645 avg loss: 0.74233 (A-MSE: 0.65823) avg lploss: 0.00000
==> test epoch 1645 avg loss: 0.81452 (A-MSE: 0.73432) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 17 out of 50
train epoch 1646 avg loss: 0.11118 (A-MSE: 0.09819) avg lploss: 0.00000
train epoch 1647 avg loss: 0.13010 (A-MSE: 0.11568) avg lploss: 0.00000
train epoch 1648 avg loss: 0.13031 (A-MSE: 0.11617) avg lploss: 0.00000
train epoch 1649 avg loss: 0.13401 (A-MSE: 0.12069) avg lploss: 0.00000
train epoch 1650 avg loss: 0.17137 (A-MSE: 0.15317) avg lploss: 0.00000
==> val epoch 1650 avg loss: 0.88847 (A-MSE: 0.77724) avg lploss: 0.00000
==> test epoch 1650 avg loss: 0.96633 (A-MSE: 0.85758) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 18 out of 50
train epoch 1651 avg loss: 0.17394 (A-MSE: 0.15426) avg lploss: 0.00000
train epoch 1652 avg loss: 0.17706 (A-MSE: 0.15716) avg lploss: 0.00000
train epoch 1653 avg loss: 0.16287 (A-MSE: 0.14468) avg lploss: 0.00000
train epoch 1654 avg loss: 0.20770 (A-MSE: 0.18360) avg lploss: 0.00000
train epoch 1655 avg loss: 0.17100 (A-MSE: 0.15042) avg lploss: 0.00000
==> val epoch 1655 avg loss: 0.79284 (A-MSE: 0.69539) avg lploss: 0.00000
==> test epoch 1655 avg loss: 0.86099 (A-MSE: 0.77245) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 19 out of 50
train epoch 1656 avg loss: 0.14121 (A-MSE: 0.12571) avg lploss: 0.00000
train epoch 1657 avg loss: 0.14101 (A-MSE: 0.12600) avg lploss: 0.00000
train epoch 1658 avg loss: 0.13127 (A-MSE: 0.11667) avg lploss: 0.00000
train epoch 1659 avg loss: 0.13367 (A-MSE: 0.11924) avg lploss: 0.00000
train epoch 1660 avg loss: 0.13462 (A-MSE: 0.12082) avg lploss: 0.00000
==> val epoch 1660 avg loss: 0.83193 (A-MSE: 0.74548) avg lploss: 0.00000
==> test epoch 1660 avg loss: 0.89913 (A-MSE: 0.80399) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 20 out of 50
train epoch 1661 avg loss: 0.13313 (A-MSE: 0.11884) avg lploss: 0.00000
train epoch 1662 avg loss: 0.14084 (A-MSE: 0.12464) avg lploss: 0.00000
train epoch 1663 avg loss: 0.14521 (A-MSE: 0.12970) avg lploss: 0.00000
train epoch 1664 avg loss: 0.13771 (A-MSE: 0.12165) avg lploss: 0.00000
train epoch 1665 avg loss: 0.14026 (A-MSE: 0.12447) avg lploss: 0.00000
==> val epoch 1665 avg loss: 0.80480 (A-MSE: 0.70908) avg lploss: 0.00000
==> test epoch 1665 avg loss: 0.84725 (A-MSE: 0.76141) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 21 out of 50
train epoch 1666 avg loss: 0.16667 (A-MSE: 0.14794) avg lploss: 0.00000
train epoch 1667 avg loss: 0.18002 (A-MSE: 0.16117) avg lploss: 0.00000
train epoch 1668 avg loss: 0.16583 (A-MSE: 0.14645) avg lploss: 0.00000
train epoch 1669 avg loss: 0.15407 (A-MSE: 0.13690) avg lploss: 0.00000
train epoch 1670 avg loss: 0.17097 (A-MSE: 0.15153) avg lploss: 0.00000
==> val epoch 1670 avg loss: 0.94459 (A-MSE: 0.83297) avg lploss: 0.00000
==> test epoch 1670 avg loss: 1.02023 (A-MSE: 0.91438) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 22 out of 50
train epoch 1671 avg loss: 0.21287 (A-MSE: 0.18895) avg lploss: 0.00000
train epoch 1672 avg loss: 0.19823 (A-MSE: 0.17674) avg lploss: 0.00000
train epoch 1673 avg loss: 0.14449 (A-MSE: 0.12663) avg lploss: 0.00000
train epoch 1674 avg loss: 0.11863 (A-MSE: 0.10513) avg lploss: 0.00000
train epoch 1675 avg loss: 0.13275 (A-MSE: 0.11781) avg lploss: 0.00000
==> val epoch 1675 avg loss: 0.81171 (A-MSE: 0.71674) avg lploss: 0.00000
==> test epoch 1675 avg loss: 0.90307 (A-MSE: 0.80859) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 23 out of 50
train epoch 1676 avg loss: 0.11434 (A-MSE: 0.10127) avg lploss: 0.00000
train epoch 1677 avg loss: 0.10737 (A-MSE: 0.09515) avg lploss: 0.00000
train epoch 1678 avg loss: 0.11135 (A-MSE: 0.09905) avg lploss: 0.00000
train epoch 1679 avg loss: 0.12077 (A-MSE: 0.10800) avg lploss: 0.00000
train epoch 1680 avg loss: 0.12174 (A-MSE: 0.10871) avg lploss: 0.00000
==> val epoch 1680 avg loss: 0.79561 (A-MSE: 0.70519) avg lploss: 0.00000
==> test epoch 1680 avg loss: 0.85584 (A-MSE: 0.77227) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 24 out of 50
train epoch 1681 avg loss: 0.12349 (A-MSE: 0.10966) avg lploss: 0.00000
train epoch 1682 avg loss: 0.12685 (A-MSE: 0.11201) avg lploss: 0.00000
train epoch 1683 avg loss: 0.14516 (A-MSE: 0.12876) avg lploss: 0.00000
train epoch 1684 avg loss: 0.17668 (A-MSE: 0.15664) avg lploss: 0.00000
train epoch 1685 avg loss: 0.20757 (A-MSE: 0.18263) avg lploss: 0.00000
==> val epoch 1685 avg loss: 0.77267 (A-MSE: 0.68783) avg lploss: 0.00000
==> test epoch 1685 avg loss: 0.89145 (A-MSE: 0.81293) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 25 out of 50
train epoch 1686 avg loss: 0.18615 (A-MSE: 0.16510) avg lploss: 0.00000
train epoch 1687 avg loss: 0.13471 (A-MSE: 0.12154) avg lploss: 0.00000
train epoch 1688 avg loss: 0.11982 (A-MSE: 0.10703) avg lploss: 0.00000
train epoch 1689 avg loss: 0.11678 (A-MSE: 0.10452) avg lploss: 0.00000
train epoch 1690 avg loss: 0.12181 (A-MSE: 0.10739) avg lploss: 0.00000
==> val epoch 1690 avg loss: 0.81930 (A-MSE: 0.73358) avg lploss: 0.00000
==> test epoch 1690 avg loss: 0.90397 (A-MSE: 0.82130) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 26 out of 50
train epoch 1691 avg loss: 0.14886 (A-MSE: 0.13063) avg lploss: 0.00000
train epoch 1692 avg loss: 0.13320 (A-MSE: 0.11831) avg lploss: 0.00000
train epoch 1693 avg loss: 0.14699 (A-MSE: 0.13112) avg lploss: 0.00000
train epoch 1694 avg loss: 0.16410 (A-MSE: 0.14600) avg lploss: 0.00000
train epoch 1695 avg loss: 0.17043 (A-MSE: 0.15109) avg lploss: 0.00000
==> val epoch 1695 avg loss: 0.73697 (A-MSE: 0.65410) avg lploss: 0.00000
==> test epoch 1695 avg loss: 0.77893 (A-MSE: 0.70591) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 27 out of 50
train epoch 1696 avg loss: 0.16202 (A-MSE: 0.14496) avg lploss: 0.00000
train epoch 1697 avg loss: 0.12115 (A-MSE: 0.10811) avg lploss: 0.00000
train epoch 1698 avg loss: 0.12095 (A-MSE: 0.10741) avg lploss: 0.00000
train epoch 1699 avg loss: 0.12327 (A-MSE: 0.11070) avg lploss: 0.00000
train epoch 1700 avg loss: 0.11828 (A-MSE: 0.10399) avg lploss: 0.00000
==> val epoch 1700 avg loss: 0.71576 (A-MSE: 0.63870) avg lploss: 0.00000
==> test epoch 1700 avg loss: 0.79706 (A-MSE: 0.72009) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 28 out of 50
train epoch 1701 avg loss: 0.11463 (A-MSE: 0.10164) avg lploss: 0.00000
train epoch 1702 avg loss: 0.12040 (A-MSE: 0.10623) avg lploss: 0.00000
train epoch 1703 avg loss: 0.17249 (A-MSE: 0.15428) avg lploss: 0.00000
train epoch 1704 avg loss: 0.15136 (A-MSE: 0.13457) avg lploss: 0.00000
train epoch 1705 avg loss: 0.13091 (A-MSE: 0.11604) avg lploss: 0.00000
==> val epoch 1705 avg loss: 0.79245 (A-MSE: 0.70873) avg lploss: 0.00000
==> test epoch 1705 avg loss: 0.84448 (A-MSE: 0.76579) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 29 out of 50
train epoch 1706 avg loss: 0.11773 (A-MSE: 0.10446) avg lploss: 0.00000
train epoch 1707 avg loss: 0.11340 (A-MSE: 0.10155) avg lploss: 0.00000
train epoch 1708 avg loss: 0.10146 (A-MSE: 0.09023) avg lploss: 0.00000
train epoch 1709 avg loss: 0.10904 (A-MSE: 0.09564) avg lploss: 0.00000
train epoch 1710 avg loss: 0.11245 (A-MSE: 0.10020) avg lploss: 0.00000
==> val epoch 1710 avg loss: 0.77779 (A-MSE: 0.68217) avg lploss: 0.00000
==> test epoch 1710 avg loss: 0.79922 (A-MSE: 0.71389) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 30 out of 50
train epoch 1711 avg loss: 0.11920 (A-MSE: 0.10611) avg lploss: 0.00000
train epoch 1712 avg loss: 0.13119 (A-MSE: 0.11639) avg lploss: 0.00000
train epoch 1713 avg loss: 0.12211 (A-MSE: 0.10769) avg lploss: 0.00000
train epoch 1714 avg loss: 0.12617 (A-MSE: 0.11284) avg lploss: 0.00000
train epoch 1715 avg loss: 0.13316 (A-MSE: 0.11894) avg lploss: 0.00000
==> val epoch 1715 avg loss: 0.72956 (A-MSE: 0.65477) avg lploss: 0.00000
==> test epoch 1715 avg loss: 0.79377 (A-MSE: 0.72239) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 31 out of 50
train epoch 1716 avg loss: 0.11009 (A-MSE: 0.09767) avg lploss: 0.00000
train epoch 1717 avg loss: 0.10932 (A-MSE: 0.09773) avg lploss: 0.00000
train epoch 1718 avg loss: 0.10649 (A-MSE: 0.09488) avg lploss: 0.00000
train epoch 1719 avg loss: 0.10177 (A-MSE: 0.08981) avg lploss: 0.00000
train epoch 1720 avg loss: 0.11051 (A-MSE: 0.09803) avg lploss: 0.00000
==> val epoch 1720 avg loss: 0.71725 (A-MSE: 0.63135) avg lploss: 0.00000
==> test epoch 1720 avg loss: 0.76214 (A-MSE: 0.68346) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 32 out of 50
train epoch 1721 avg loss: 0.11420 (A-MSE: 0.10116) avg lploss: 0.00000
train epoch 1722 avg loss: 0.13307 (A-MSE: 0.11841) avg lploss: 0.00000
train epoch 1723 avg loss: 0.18397 (A-MSE: 0.16225) avg lploss: 0.00000
train epoch 1724 avg loss: 0.18443 (A-MSE: 0.16369) avg lploss: 0.00000
train epoch 1725 avg loss: 0.22587 (A-MSE: 0.19989) avg lploss: 0.00000
==> val epoch 1725 avg loss: 0.79938 (A-MSE: 0.69005) avg lploss: 0.00000
==> test epoch 1725 avg loss: 0.87347 (A-MSE: 0.76244) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 33 out of 50
train epoch 1726 avg loss: 0.17186 (A-MSE: 0.15161) avg lploss: 0.00000
train epoch 1727 avg loss: 0.14094 (A-MSE: 0.12520) avg lploss: 0.00000
train epoch 1728 avg loss: 0.13628 (A-MSE: 0.12168) avg lploss: 0.00000
train epoch 1729 avg loss: 0.11970 (A-MSE: 0.10642) avg lploss: 0.00000
train epoch 1730 avg loss: 0.12891 (A-MSE: 0.11421) avg lploss: 0.00000
==> val epoch 1730 avg loss: 0.78022 (A-MSE: 0.67752) avg lploss: 0.00000
==> test epoch 1730 avg loss: 0.83397 (A-MSE: 0.73229) avg lploss: 0.00000
*** Best Val Loss: 0.70182 	 Best Test Loss: 0.78225 	 Best epoch 1560
EarlyStopping counter: 34 out of 50
train epoch 1731 avg loss: 0.11557 (A-MSE: 0.10198) avg lploss: 0.00000
train epoch 1732 avg loss: 0.13621 (A-MSE: 0.12059) avg lploss: 0.00000
train epoch 1733 avg loss: 0.14958 (A-MSE: 0.13255) avg lploss: 0.00000
train epoch 1734 avg loss: 0.14170 (A-MSE: 0.12463) avg lploss: 0.00000
train epoch 1735 avg loss: 0.15313 (A-MSE: 0.13633) avg lploss: 0.00000
==> val epoch 1735 avg loss: 0.69772 (A-MSE: 0.62203) avg lploss: 0.00000
==> test epoch 1735 avg loss: 0.77442 (A-MSE: 0.70563) avg lploss: 0.00000
*** Best Val Loss: 0.69772 	 Best Test Loss: 0.77442 	 Best epoch 1735
Validation loss decreased (0.701821 --> 0.697720).  Saving model ...
train epoch 1736 avg loss: 0.14837 (A-MSE: 0.13217) avg lploss: 0.00000
train epoch 1737 avg loss: 0.15598 (A-MSE: 0.13874) avg lploss: 0.00000
train epoch 1738 avg loss: 0.17854 (A-MSE: 0.15876) avg lploss: 0.00000
train epoch 1739 avg loss: 0.15426 (A-MSE: 0.13727) avg lploss: 0.00000
train epoch 1740 avg loss: 0.14779 (A-MSE: 0.13162) avg lploss: 0.00000
==> val epoch 1740 avg loss: 0.86835 (A-MSE: 0.76366) avg lploss: 0.00000
==> test epoch 1740 avg loss: 0.91729 (A-MSE: 0.81617) avg lploss: 0.00000
*** Best Val Loss: 0.69772 	 Best Test Loss: 0.77442 	 Best epoch 1735
EarlyStopping counter: 1 out of 50
train epoch 1741 avg loss: 0.14048 (A-MSE: 0.12493) avg lploss: 0.00000
train epoch 1742 avg loss: 0.14837 (A-MSE: 0.13144) avg lploss: 0.00000
train epoch 1743 avg loss: 0.14272 (A-MSE: 0.12644) avg lploss: 0.00000
train epoch 1744 avg loss: 0.13664 (A-MSE: 0.12052) avg lploss: 0.00000
train epoch 1745 avg loss: 0.11979 (A-MSE: 0.10511) avg lploss: 0.00000
==> val epoch 1745 avg loss: 0.68108 (A-MSE: 0.60627) avg lploss: 0.00000
==> test epoch 1745 avg loss: 0.71655 (A-MSE: 0.64811) avg lploss: 0.00000
*** Best Val Loss: 0.68108 	 Best Test Loss: 0.71655 	 Best epoch 1745
Validation loss decreased (0.697720 --> 0.681076).  Saving model ...
train epoch 1746 avg loss: 0.11839 (A-MSE: 0.10475) avg lploss: 0.00000
train epoch 1747 avg loss: 0.11138 (A-MSE: 0.10018) avg lploss: 0.00000
train epoch 1748 avg loss: 0.10340 (A-MSE: 0.09179) avg lploss: 0.00000
train epoch 1749 avg loss: 0.10370 (A-MSE: 0.09157) avg lploss: 0.00000
train epoch 1750 avg loss: 0.10462 (A-MSE: 0.09282) avg lploss: 0.00000
==> val epoch 1750 avg loss: 0.78820 (A-MSE: 0.70267) avg lploss: 0.00000
==> test epoch 1750 avg loss: 0.85128 (A-MSE: 0.76996) avg lploss: 0.00000
*** Best Val Loss: 0.68108 	 Best Test Loss: 0.71655 	 Best epoch 1745
EarlyStopping counter: 1 out of 50
train epoch 1751 avg loss: 0.11031 (A-MSE: 0.09858) avg lploss: 0.00000
train epoch 1752 avg loss: 0.10049 (A-MSE: 0.08914) avg lploss: 0.00000
train epoch 1753 avg loss: 0.11104 (A-MSE: 0.09822) avg lploss: 0.00000
train epoch 1754 avg loss: 0.12688 (A-MSE: 0.11211) avg lploss: 0.00000
train epoch 1755 avg loss: 0.12169 (A-MSE: 0.10861) avg lploss: 0.00000
==> val epoch 1755 avg loss: 0.81502 (A-MSE: 0.72018) avg lploss: 0.00000
==> test epoch 1755 avg loss: 0.88817 (A-MSE: 0.79293) avg lploss: 0.00000
*** Best Val Loss: 0.68108 	 Best Test Loss: 0.71655 	 Best epoch 1745
EarlyStopping counter: 2 out of 50
train epoch 1756 avg loss: 0.10267 (A-MSE: 0.09115) avg lploss: 0.00000
train epoch 1757 avg loss: 0.09843 (A-MSE: 0.08829) avg lploss: 0.00000
train epoch 1758 avg loss: 0.09651 (A-MSE: 0.08570) avg lploss: 0.00000
train epoch 1759 avg loss: 0.10509 (A-MSE: 0.09343) avg lploss: 0.00000
train epoch 1760 avg loss: 0.10550 (A-MSE: 0.09300) avg lploss: 0.00000
==> val epoch 1760 avg loss: 0.66718 (A-MSE: 0.59116) avg lploss: 0.00000
==> test epoch 1760 avg loss: 0.73882 (A-MSE: 0.66369) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
Validation loss decreased (0.681076 --> 0.667176).  Saving model ...
train epoch 1761 avg loss: 0.11769 (A-MSE: 0.10451) avg lploss: 0.00000
train epoch 1762 avg loss: 0.10816 (A-MSE: 0.09606) avg lploss: 0.00000
train epoch 1763 avg loss: 0.10491 (A-MSE: 0.09334) avg lploss: 0.00000
train epoch 1764 avg loss: 0.12099 (A-MSE: 0.10731) avg lploss: 0.00000
train epoch 1765 avg loss: 0.13389 (A-MSE: 0.11821) avg lploss: 0.00000
==> val epoch 1765 avg loss: 0.78819 (A-MSE: 0.69687) avg lploss: 0.00000
==> test epoch 1765 avg loss: 0.86065 (A-MSE: 0.76684) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 1 out of 50
train epoch 1766 avg loss: 0.11313 (A-MSE: 0.10090) avg lploss: 0.00000
train epoch 1767 avg loss: 0.10297 (A-MSE: 0.09076) avg lploss: 0.00000
train epoch 1768 avg loss: 0.10478 (A-MSE: 0.09329) avg lploss: 0.00000
train epoch 1769 avg loss: 0.11384 (A-MSE: 0.10128) avg lploss: 0.00000
train epoch 1770 avg loss: 0.11323 (A-MSE: 0.09990) avg lploss: 0.00000
==> val epoch 1770 avg loss: 0.74665 (A-MSE: 0.66364) avg lploss: 0.00000
==> test epoch 1770 avg loss: 0.80940 (A-MSE: 0.72514) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 2 out of 50
train epoch 1771 avg loss: 0.10332 (A-MSE: 0.09159) avg lploss: 0.00000
train epoch 1772 avg loss: 0.09401 (A-MSE: 0.08389) avg lploss: 0.00000
train epoch 1773 avg loss: 0.09569 (A-MSE: 0.08517) avg lploss: 0.00000
train epoch 1774 avg loss: 0.10872 (A-MSE: 0.09704) avg lploss: 0.00000
train epoch 1775 avg loss: 0.14253 (A-MSE: 0.12626) avg lploss: 0.00000
==> val epoch 1775 avg loss: 0.78339 (A-MSE: 0.69513) avg lploss: 0.00000
==> test epoch 1775 avg loss: 0.84355 (A-MSE: 0.76435) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 3 out of 50
train epoch 1776 avg loss: 0.12715 (A-MSE: 0.11282) avg lploss: 0.00000
train epoch 1777 avg loss: 0.10596 (A-MSE: 0.09454) avg lploss: 0.00000
train epoch 1778 avg loss: 0.10488 (A-MSE: 0.09393) avg lploss: 0.00000
train epoch 1779 avg loss: 0.10298 (A-MSE: 0.09128) avg lploss: 0.00000
train epoch 1780 avg loss: 0.10463 (A-MSE: 0.09241) avg lploss: 0.00000
==> val epoch 1780 avg loss: 0.70203 (A-MSE: 0.62636) avg lploss: 0.00000
==> test epoch 1780 avg loss: 0.75353 (A-MSE: 0.68137) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 4 out of 50
train epoch 1781 avg loss: 0.12549 (A-MSE: 0.11041) avg lploss: 0.00000
train epoch 1782 avg loss: 0.11488 (A-MSE: 0.10211) avg lploss: 0.00000
train epoch 1783 avg loss: 0.11054 (A-MSE: 0.09968) avg lploss: 0.00000
train epoch 1784 avg loss: 0.11277 (A-MSE: 0.10008) avg lploss: 0.00000
train epoch 1785 avg loss: 0.11382 (A-MSE: 0.10120) avg lploss: 0.00000
==> val epoch 1785 avg loss: 0.75311 (A-MSE: 0.67343) avg lploss: 0.00000
==> test epoch 1785 avg loss: 0.85479 (A-MSE: 0.77687) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 5 out of 50
train epoch 1786 avg loss: 0.12233 (A-MSE: 0.10885) avg lploss: 0.00000
train epoch 1787 avg loss: 0.13899 (A-MSE: 0.12404) avg lploss: 0.00000
train epoch 1788 avg loss: 0.13060 (A-MSE: 0.11491) avg lploss: 0.00000
train epoch 1789 avg loss: 0.10686 (A-MSE: 0.09425) avg lploss: 0.00000
train epoch 1790 avg loss: 0.11377 (A-MSE: 0.10158) avg lploss: 0.00000
==> val epoch 1790 avg loss: 0.75104 (A-MSE: 0.67941) avg lploss: 0.00000
==> test epoch 1790 avg loss: 0.82024 (A-MSE: 0.74790) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 6 out of 50
train epoch 1791 avg loss: 0.09757 (A-MSE: 0.08670) avg lploss: 0.00000
train epoch 1792 avg loss: 0.11035 (A-MSE: 0.09770) avg lploss: 0.00000
train epoch 1793 avg loss: 0.11870 (A-MSE: 0.10564) avg lploss: 0.00000
train epoch 1794 avg loss: 0.11638 (A-MSE: 0.10460) avg lploss: 0.00000
train epoch 1795 avg loss: 0.13045 (A-MSE: 0.11625) avg lploss: 0.00000
==> val epoch 1795 avg loss: 0.70053 (A-MSE: 0.61694) avg lploss: 0.00000
==> test epoch 1795 avg loss: 0.75698 (A-MSE: 0.67735) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 7 out of 50
train epoch 1796 avg loss: 0.12595 (A-MSE: 0.11263) avg lploss: 0.00000
train epoch 1797 avg loss: 0.12166 (A-MSE: 0.10825) avg lploss: 0.00000
train epoch 1798 avg loss: 0.12011 (A-MSE: 0.10649) avg lploss: 0.00000
train epoch 1799 avg loss: 0.12257 (A-MSE: 0.10950) avg lploss: 0.00000
train epoch 1800 avg loss: 0.12738 (A-MSE: 0.11335) avg lploss: 0.00000
==> val epoch 1800 avg loss: 0.66830 (A-MSE: 0.59158) avg lploss: 0.00000
==> test epoch 1800 avg loss: 0.76254 (A-MSE: 0.69080) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 8 out of 50
train epoch 1801 avg loss: 0.13551 (A-MSE: 0.11956) avg lploss: 0.00000
train epoch 1802 avg loss: 0.12127 (A-MSE: 0.10882) avg lploss: 0.00000
train epoch 1803 avg loss: 0.11617 (A-MSE: 0.10326) avg lploss: 0.00000
train epoch 1804 avg loss: 0.11438 (A-MSE: 0.10168) avg lploss: 0.00000
train epoch 1805 avg loss: 0.10252 (A-MSE: 0.09063) avg lploss: 0.00000
==> val epoch 1805 avg loss: 0.66737 (A-MSE: 0.59045) avg lploss: 0.00000
==> test epoch 1805 avg loss: 0.73816 (A-MSE: 0.66707) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 9 out of 50
train epoch 1806 avg loss: 0.09374 (A-MSE: 0.08299) avg lploss: 0.00000
train epoch 1807 avg loss: 0.10221 (A-MSE: 0.09088) avg lploss: 0.00000
train epoch 1808 avg loss: 0.12155 (A-MSE: 0.10739) avg lploss: 0.00000
train epoch 1809 avg loss: 0.12055 (A-MSE: 0.10706) avg lploss: 0.00000
train epoch 1810 avg loss: 0.12161 (A-MSE: 0.10820) avg lploss: 0.00000
==> val epoch 1810 avg loss: 0.66729 (A-MSE: 0.60409) avg lploss: 0.00000
==> test epoch 1810 avg loss: 0.77436 (A-MSE: 0.71689) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 10 out of 50
train epoch 1811 avg loss: 0.11115 (A-MSE: 0.09946) avg lploss: 0.00000
train epoch 1812 avg loss: 0.09466 (A-MSE: 0.08454) avg lploss: 0.00000
train epoch 1813 avg loss: 0.10829 (A-MSE: 0.09621) avg lploss: 0.00000
train epoch 1814 avg loss: 0.20412 (A-MSE: 0.19085) avg lploss: 0.00000
train epoch 1815 avg loss: 12.49999 (A-MSE: 11.22670) avg lploss: 0.00000
==> val epoch 1815 avg loss: 7.63684 (A-MSE: 6.43776) avg lploss: 0.00000
==> test epoch 1815 avg loss: 7.18936 (A-MSE: 6.15131) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 11 out of 50
train epoch 1816 avg loss: 6.16668 (A-MSE: 5.28282) avg lploss: 0.00000
train epoch 1817 avg loss: 3.13156 (A-MSE: 2.72708) avg lploss: 0.00000
train epoch 1818 avg loss: 2.02397 (A-MSE: 1.73204) avg lploss: 0.00000
train epoch 1819 avg loss: 1.49098 (A-MSE: 1.27698) avg lploss: 0.00000
train epoch 1820 avg loss: 1.35422 (A-MSE: 1.16011) avg lploss: 0.00000
==> val epoch 1820 avg loss: 1.64848 (A-MSE: 1.38845) avg lploss: 0.00000
==> test epoch 1820 avg loss: 1.65994 (A-MSE: 1.43904) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 12 out of 50
train epoch 1821 avg loss: 1.26639 (A-MSE: 1.07888) avg lploss: 0.00000
train epoch 1822 avg loss: 1.05278 (A-MSE: 0.90404) avg lploss: 0.00000
train epoch 1823 avg loss: 0.89220 (A-MSE: 0.77202) avg lploss: 0.00000
train epoch 1824 avg loss: 0.86749 (A-MSE: 0.74647) avg lploss: 0.00000
train epoch 1825 avg loss: 0.73737 (A-MSE: 0.63471) avg lploss: 0.00000
==> val epoch 1825 avg loss: 0.93433 (A-MSE: 0.81846) avg lploss: 0.00000
==> test epoch 1825 avg loss: 0.99597 (A-MSE: 0.88766) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 13 out of 50
train epoch 1826 avg loss: 0.73810 (A-MSE: 0.63883) avg lploss: 0.00000
train epoch 1827 avg loss: 0.66564 (A-MSE: 0.57532) avg lploss: 0.00000
train epoch 1828 avg loss: 0.60971 (A-MSE: 0.53063) avg lploss: 0.00000
train epoch 1829 avg loss: 0.57584 (A-MSE: 0.49988) avg lploss: 0.00000
train epoch 1830 avg loss: 0.57878 (A-MSE: 0.50141) avg lploss: 0.00000
==> val epoch 1830 avg loss: 0.83231 (A-MSE: 0.72531) avg lploss: 0.00000
==> test epoch 1830 avg loss: 0.86209 (A-MSE: 0.76870) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 14 out of 50
train epoch 1831 avg loss: 0.59773 (A-MSE: 0.52055) avg lploss: 0.00000
train epoch 1832 avg loss: 0.54757 (A-MSE: 0.47480) avg lploss: 0.00000
train epoch 1833 avg loss: 0.50774 (A-MSE: 0.44142) avg lploss: 0.00000
train epoch 1834 avg loss: 0.49118 (A-MSE: 0.42710) avg lploss: 0.00000
train epoch 1835 avg loss: 0.48429 (A-MSE: 0.42034) avg lploss: 0.00000
==> val epoch 1835 avg loss: 0.71329 (A-MSE: 0.62439) avg lploss: 0.00000
==> test epoch 1835 avg loss: 0.76785 (A-MSE: 0.68417) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 15 out of 50
train epoch 1836 avg loss: 0.45161 (A-MSE: 0.39184) avg lploss: 0.00000
train epoch 1837 avg loss: 0.45087 (A-MSE: 0.39277) avg lploss: 0.00000
train epoch 1838 avg loss: 0.46157 (A-MSE: 0.40226) avg lploss: 0.00000
train epoch 1839 avg loss: 0.49604 (A-MSE: 0.42570) avg lploss: 0.00000
train epoch 1840 avg loss: 0.47508 (A-MSE: 0.41824) avg lploss: 0.00000
==> val epoch 1840 avg loss: 0.80921 (A-MSE: 0.70651) avg lploss: 0.00000
==> test epoch 1840 avg loss: 0.87039 (A-MSE: 0.77727) avg lploss: 0.00000
*** Best Val Loss: 0.66718 	 Best Test Loss: 0.73882 	 Best epoch 1760
EarlyStopping counter: 16 out of 50
train epoch 1841 avg loss: 0.42104 (A-MSE: 0.36706) avg lploss: 0.00000
train epoch 1842 avg loss: 0.39407 (A-MSE: 0.33886) avg lploss: 0.00000
train epoch 1843 avg loss: 0.38024 (A-MSE: 0.33124) avg lploss: 0.00000
train epoch 1844 avg loss: 0.35190 (A-MSE: 0.30569) avg lploss: 0.00000
train epoch 1845 avg loss: 0.34578 (A-MSE: 0.30016) avg lploss: 0.00000
==> val epoch 1845 avg loss: 0.65628 (A-MSE: 0.57768) avg lploss: 0.00000
==> test epoch 1845 avg loss: 0.71467 (A-MSE: 0.63613) avg lploss: 0.00000
*** Best Val Loss: 0.65628 	 Best Test Loss: 0.71467 	 Best epoch 1845
Validation loss decreased (0.667176 --> 0.656279).  Saving model ...
train epoch 1846 avg loss: 0.34975 (A-MSE: 0.30542) avg lploss: 0.00000
train epoch 1847 avg loss: 0.34696 (A-MSE: 0.30162) avg lploss: 0.00000
train epoch 1848 avg loss: 0.34957 (A-MSE: 0.30434) avg lploss: 0.00000
train epoch 1849 avg loss: 0.35410 (A-MSE: 0.30981) avg lploss: 0.00000
train epoch 1850 avg loss: 0.33314 (A-MSE: 0.29105) avg lploss: 0.00000
==> val epoch 1850 avg loss: 0.62107 (A-MSE: 0.54387) avg lploss: 0.00000
==> test epoch 1850 avg loss: 0.68222 (A-MSE: 0.60479) avg lploss: 0.00000
*** Best Val Loss: 0.62107 	 Best Test Loss: 0.68222 	 Best epoch 1850
Validation loss decreased (0.656279 --> 0.621072).  Saving model ...
train epoch 1851 avg loss: 0.35528 (A-MSE: 0.30755) avg lploss: 0.00000
train epoch 1852 avg loss: 0.29688 (A-MSE: 0.25964) avg lploss: 0.00000
train epoch 1853 avg loss: 0.28965 (A-MSE: 0.25182) avg lploss: 0.00000
train epoch 1854 avg loss: 0.30236 (A-MSE: 0.26415) avg lploss: 0.00000
train epoch 1855 avg loss: 0.30209 (A-MSE: 0.26381) avg lploss: 0.00000
==> val epoch 1855 avg loss: 0.55883 (A-MSE: 0.48839) avg lploss: 0.00000
==> test epoch 1855 avg loss: 0.61387 (A-MSE: 0.54333) avg lploss: 0.00000
*** Best Val Loss: 0.55883 	 Best Test Loss: 0.61387 	 Best epoch 1855
Validation loss decreased (0.621072 --> 0.558825).  Saving model ...
train epoch 1856 avg loss: 0.28634 (A-MSE: 0.24981) avg lploss: 0.00000
train epoch 1857 avg loss: 0.28454 (A-MSE: 0.24992) avg lploss: 0.00000
train epoch 1858 avg loss: 0.30301 (A-MSE: 0.26638) avg lploss: 0.00000
train epoch 1859 avg loss: 0.27903 (A-MSE: 0.24211) avg lploss: 0.00000
train epoch 1860 avg loss: 0.27830 (A-MSE: 0.24042) avg lploss: 0.00000
==> val epoch 1860 avg loss: 0.58901 (A-MSE: 0.51375) avg lploss: 0.00000
==> test epoch 1860 avg loss: 0.60121 (A-MSE: 0.53526) avg lploss: 0.00000
*** Best Val Loss: 0.55883 	 Best Test Loss: 0.61387 	 Best epoch 1855
EarlyStopping counter: 1 out of 50
train epoch 1861 avg loss: 0.27963 (A-MSE: 0.24468) avg lploss: 0.00000
train epoch 1862 avg loss: 0.27007 (A-MSE: 0.23542) avg lploss: 0.00000
train epoch 1863 avg loss: 0.25712 (A-MSE: 0.22611) avg lploss: 0.00000
train epoch 1864 avg loss: 0.26717 (A-MSE: 0.23443) avg lploss: 0.00000
train epoch 1865 avg loss: 0.25867 (A-MSE: 0.22567) avg lploss: 0.00000
==> val epoch 1865 avg loss: 0.63915 (A-MSE: 0.55379) avg lploss: 0.00000
==> test epoch 1865 avg loss: 0.68384 (A-MSE: 0.60590) avg lploss: 0.00000
*** Best Val Loss: 0.55883 	 Best Test Loss: 0.61387 	 Best epoch 1855
EarlyStopping counter: 2 out of 50
train epoch 1866 avg loss: 0.26069 (A-MSE: 0.22831) avg lploss: 0.00000
train epoch 1867 avg loss: 0.24796 (A-MSE: 0.21699) avg lploss: 0.00000
train epoch 1868 avg loss: 0.25216 (A-MSE: 0.22259) avg lploss: 0.00000
train epoch 1869 avg loss: 0.23608 (A-MSE: 0.20616) avg lploss: 0.00000
train epoch 1870 avg loss: 0.24301 (A-MSE: 0.21215) avg lploss: 0.00000
==> val epoch 1870 avg loss: 0.56808 (A-MSE: 0.49606) avg lploss: 0.00000
==> test epoch 1870 avg loss: 0.60781 (A-MSE: 0.53474) avg lploss: 0.00000
*** Best Val Loss: 0.55883 	 Best Test Loss: 0.61387 	 Best epoch 1855
EarlyStopping counter: 3 out of 50
train epoch 1871 avg loss: 0.27471 (A-MSE: 0.24134) avg lploss: 0.00000
train epoch 1872 avg loss: 0.23566 (A-MSE: 0.20681) avg lploss: 0.00000
train epoch 1873 avg loss: 0.23159 (A-MSE: 0.20274) avg lploss: 0.00000
train epoch 1874 avg loss: 0.22382 (A-MSE: 0.19472) avg lploss: 0.00000
train epoch 1875 avg loss: 0.21726 (A-MSE: 0.18997) avg lploss: 0.00000
==> val epoch 1875 avg loss: 0.53793 (A-MSE: 0.47048) avg lploss: 0.00000
==> test epoch 1875 avg loss: 0.57778 (A-MSE: 0.51505) avg lploss: 0.00000
*** Best Val Loss: 0.53793 	 Best Test Loss: 0.57778 	 Best epoch 1875
Validation loss decreased (0.558825 --> 0.537934).  Saving model ...
train epoch 1876 avg loss: 0.23033 (A-MSE: 0.20118) avg lploss: 0.00000
train epoch 1877 avg loss: 0.22477 (A-MSE: 0.19865) avg lploss: 0.00000
train epoch 1878 avg loss: 0.24534 (A-MSE: 0.21661) avg lploss: 0.00000
train epoch 1879 avg loss: 0.24130 (A-MSE: 0.21078) avg lploss: 0.00000
train epoch 1880 avg loss: 0.23866 (A-MSE: 0.20766) avg lploss: 0.00000
==> val epoch 1880 avg loss: 0.55277 (A-MSE: 0.48189) avg lploss: 0.00000
==> test epoch 1880 avg loss: 0.56796 (A-MSE: 0.50515) avg lploss: 0.00000
*** Best Val Loss: 0.53793 	 Best Test Loss: 0.57778 	 Best epoch 1875
EarlyStopping counter: 1 out of 50
train epoch 1881 avg loss: 0.20471 (A-MSE: 0.17943) avg lploss: 0.00000
train epoch 1882 avg loss: 0.19624 (A-MSE: 0.17099) avg lploss: 0.00000
train epoch 1883 avg loss: 0.19406 (A-MSE: 0.17122) avg lploss: 0.00000
train epoch 1884 avg loss: 0.18690 (A-MSE: 0.16328) avg lploss: 0.00000
train epoch 1885 avg loss: 0.19839 (A-MSE: 0.17393) avg lploss: 0.00000
==> val epoch 1885 avg loss: 0.58157 (A-MSE: 0.51479) avg lploss: 0.00000
==> test epoch 1885 avg loss: 0.62256 (A-MSE: 0.55960) avg lploss: 0.00000
*** Best Val Loss: 0.53793 	 Best Test Loss: 0.57778 	 Best epoch 1875
EarlyStopping counter: 2 out of 50
train epoch 1886 avg loss: 0.19733 (A-MSE: 0.17324) avg lploss: 0.00000
train epoch 1887 avg loss: 0.21337 (A-MSE: 0.18918) avg lploss: 0.00000
train epoch 1888 avg loss: 0.23914 (A-MSE: 0.20704) avg lploss: 0.00000
train epoch 1889 avg loss: 0.23553 (A-MSE: 0.20621) avg lploss: 0.00000
train epoch 1890 avg loss: 0.22556 (A-MSE: 0.19775) avg lploss: 0.00000
==> val epoch 1890 avg loss: 0.51703 (A-MSE: 0.45125) avg lploss: 0.00000
==> test epoch 1890 avg loss: 0.56048 (A-MSE: 0.50030) avg lploss: 0.00000
*** Best Val Loss: 0.51703 	 Best Test Loss: 0.56048 	 Best epoch 1890
Validation loss decreased (0.537934 --> 0.517030).  Saving model ...
train epoch 1891 avg loss: 0.25190 (A-MSE: 0.21954) avg lploss: 0.00000
train epoch 1892 avg loss: 0.23322 (A-MSE: 0.20447) avg lploss: 0.00000
train epoch 1893 avg loss: 0.20419 (A-MSE: 0.17834) avg lploss: 0.00000
train epoch 1894 avg loss: 0.18948 (A-MSE: 0.16549) avg lploss: 0.00000
train epoch 1895 avg loss: 0.18470 (A-MSE: 0.16086) avg lploss: 0.00000
==> val epoch 1895 avg loss: 0.53654 (A-MSE: 0.46982) avg lploss: 0.00000
==> test epoch 1895 avg loss: 0.56636 (A-MSE: 0.50000) avg lploss: 0.00000
*** Best Val Loss: 0.51703 	 Best Test Loss: 0.56048 	 Best epoch 1890
EarlyStopping counter: 1 out of 50
train epoch 1896 avg loss: 0.19016 (A-MSE: 0.16583) avg lploss: 0.00000
train epoch 1897 avg loss: 0.17798 (A-MSE: 0.15508) avg lploss: 0.00000
train epoch 1898 avg loss: 0.19427 (A-MSE: 0.17025) avg lploss: 0.00000
train epoch 1899 avg loss: 0.18968 (A-MSE: 0.16575) avg lploss: 0.00000
train epoch 1900 avg loss: 0.17743 (A-MSE: 0.15587) avg lploss: 0.00000
==> val epoch 1900 avg loss: 0.49041 (A-MSE: 0.43061) avg lploss: 0.00000
==> test epoch 1900 avg loss: 0.51536 (A-MSE: 0.46266) avg lploss: 0.00000
*** Best Val Loss: 0.49041 	 Best Test Loss: 0.51536 	 Best epoch 1900
Validation loss decreased (0.517030 --> 0.490408).  Saving model ...
train epoch 1901 avg loss: 0.16740 (A-MSE: 0.14700) avg lploss: 0.00000
train epoch 1902 avg loss: 0.17324 (A-MSE: 0.15171) avg lploss: 0.00000
train epoch 1903 avg loss: 0.18526 (A-MSE: 0.16280) avg lploss: 0.00000
train epoch 1904 avg loss: 0.17365 (A-MSE: 0.15171) avg lploss: 0.00000
train epoch 1905 avg loss: 0.16583 (A-MSE: 0.14576) avg lploss: 0.00000
==> val epoch 1905 avg loss: 0.53523 (A-MSE: 0.46621) avg lploss: 0.00000
==> test epoch 1905 avg loss: 0.54549 (A-MSE: 0.48509) avg lploss: 0.00000
*** Best Val Loss: 0.49041 	 Best Test Loss: 0.51536 	 Best epoch 1900
EarlyStopping counter: 1 out of 50
train epoch 1906 avg loss: 0.16424 (A-MSE: 0.14405) avg lploss: 0.00000
train epoch 1907 avg loss: 0.17795 (A-MSE: 0.15593) avg lploss: 0.00000
train epoch 1908 avg loss: 0.19820 (A-MSE: 0.17410) avg lploss: 0.00000
train epoch 1909 avg loss: 0.17542 (A-MSE: 0.15474) avg lploss: 0.00000
train epoch 1910 avg loss: 0.16616 (A-MSE: 0.14658) avg lploss: 0.00000
==> val epoch 1910 avg loss: 0.47507 (A-MSE: 0.42335) avg lploss: 0.00000
==> test epoch 1910 avg loss: 0.50279 (A-MSE: 0.44938) avg lploss: 0.00000
*** Best Val Loss: 0.47507 	 Best Test Loss: 0.50279 	 Best epoch 1910
Validation loss decreased (0.490408 --> 0.475075).  Saving model ...
train epoch 1911 avg loss: 0.16487 (A-MSE: 0.14448) avg lploss: 0.00000
train epoch 1912 avg loss: 0.16883 (A-MSE: 0.14763) avg lploss: 0.00000
train epoch 1913 avg loss: 0.17617 (A-MSE: 0.15535) avg lploss: 0.00000
train epoch 1914 avg loss: 0.17960 (A-MSE: 0.15729) avg lploss: 0.00000
train epoch 1915 avg loss: 0.17476 (A-MSE: 0.15301) avg lploss: 0.00000
==> val epoch 1915 avg loss: 0.49876 (A-MSE: 0.44215) avg lploss: 0.00000
==> test epoch 1915 avg loss: 0.53125 (A-MSE: 0.48292) avg lploss: 0.00000
*** Best Val Loss: 0.47507 	 Best Test Loss: 0.50279 	 Best epoch 1910
EarlyStopping counter: 1 out of 50
train epoch 1916 avg loss: 0.16622 (A-MSE: 0.14595) avg lploss: 0.00000
train epoch 1917 avg loss: 0.17487 (A-MSE: 0.15315) avg lploss: 0.00000
train epoch 1918 avg loss: 0.20010 (A-MSE: 0.17693) avg lploss: 0.00000
train epoch 1919 avg loss: 0.19132 (A-MSE: 0.16922) avg lploss: 0.00000
train epoch 1920 avg loss: 0.17138 (A-MSE: 0.15033) avg lploss: 0.00000
==> val epoch 1920 avg loss: 0.54921 (A-MSE: 0.47551) avg lploss: 0.00000
==> test epoch 1920 avg loss: 0.57049 (A-MSE: 0.50258) avg lploss: 0.00000
*** Best Val Loss: 0.47507 	 Best Test Loss: 0.50279 	 Best epoch 1910
EarlyStopping counter: 2 out of 50
train epoch 1921 avg loss: 0.16019 (A-MSE: 0.14013) avg lploss: 0.00000
train epoch 1922 avg loss: 0.15219 (A-MSE: 0.13423) avg lploss: 0.00000
train epoch 1923 avg loss: 0.15897 (A-MSE: 0.13961) avg lploss: 0.00000
train epoch 1924 avg loss: 0.14695 (A-MSE: 0.12841) avg lploss: 0.00000
train epoch 1925 avg loss: 0.14126 (A-MSE: 0.12416) avg lploss: 0.00000
==> val epoch 1925 avg loss: 0.45261 (A-MSE: 0.40055) avg lploss: 0.00000
==> test epoch 1925 avg loss: 0.50667 (A-MSE: 0.45045) avg lploss: 0.00000
*** Best Val Loss: 0.45261 	 Best Test Loss: 0.50667 	 Best epoch 1925
Validation loss decreased (0.475075 --> 0.452613).  Saving model ...
train epoch 1926 avg loss: 0.16136 (A-MSE: 0.14235) avg lploss: 0.00000
train epoch 1927 avg loss: 0.17703 (A-MSE: 0.15505) avg lploss: 0.00000
train epoch 1928 avg loss: 0.16426 (A-MSE: 0.14519) avg lploss: 0.00000
train epoch 1929 avg loss: 0.15271 (A-MSE: 0.13374) avg lploss: 0.00000
train epoch 1930 avg loss: 0.15374 (A-MSE: 0.13426) avg lploss: 0.00000
==> val epoch 1930 avg loss: 0.49788 (A-MSE: 0.43322) avg lploss: 0.00000
==> test epoch 1930 avg loss: 0.51057 (A-MSE: 0.45498) avg lploss: 0.00000
*** Best Val Loss: 0.45261 	 Best Test Loss: 0.50667 	 Best epoch 1925
EarlyStopping counter: 1 out of 50
train epoch 1931 avg loss: 0.14600 (A-MSE: 0.12707) avg lploss: 0.00000
train epoch 1932 avg loss: 0.14361 (A-MSE: 0.12607) avg lploss: 0.00000
train epoch 1933 avg loss: 0.14935 (A-MSE: 0.13072) avg lploss: 0.00000
train epoch 1934 avg loss: 0.14332 (A-MSE: 0.12720) avg lploss: 0.00000
train epoch 1935 avg loss: 0.13746 (A-MSE: 0.12096) avg lploss: 0.00000
==> val epoch 1935 avg loss: 0.51792 (A-MSE: 0.45031) avg lploss: 0.00000
==> test epoch 1935 avg loss: 0.53278 (A-MSE: 0.47271) avg lploss: 0.00000
*** Best Val Loss: 0.45261 	 Best Test Loss: 0.50667 	 Best epoch 1925
EarlyStopping counter: 2 out of 50
train epoch 1936 avg loss: 0.14428 (A-MSE: 0.12714) avg lploss: 0.00000
train epoch 1937 avg loss: 0.13515 (A-MSE: 0.11788) avg lploss: 0.00000
train epoch 1938 avg loss: 0.14333 (A-MSE: 0.12630) avg lploss: 0.00000
train epoch 1939 avg loss: 0.14831 (A-MSE: 0.13044) avg lploss: 0.00000
train epoch 1940 avg loss: 0.15129 (A-MSE: 0.13339) avg lploss: 0.00000
==> val epoch 1940 avg loss: 0.51091 (A-MSE: 0.45079) avg lploss: 0.00000
==> test epoch 1940 avg loss: 0.53427 (A-MSE: 0.47382) avg lploss: 0.00000
*** Best Val Loss: 0.45261 	 Best Test Loss: 0.50667 	 Best epoch 1925
EarlyStopping counter: 3 out of 50
train epoch 1941 avg loss: 0.18292 (A-MSE: 0.16109) avg lploss: 0.00000
train epoch 1942 avg loss: 0.18881 (A-MSE: 0.16487) avg lploss: 0.00000
train epoch 1943 avg loss: 0.15958 (A-MSE: 0.14037) avg lploss: 0.00000
train epoch 1944 avg loss: 0.15171 (A-MSE: 0.13413) avg lploss: 0.00000
train epoch 1945 avg loss: 0.14645 (A-MSE: 0.12867) avg lploss: 0.00000
==> val epoch 1945 avg loss: 0.59949 (A-MSE: 0.52492) avg lploss: 0.00000
==> test epoch 1945 avg loss: 0.59504 (A-MSE: 0.52883) avg lploss: 0.00000
*** Best Val Loss: 0.45261 	 Best Test Loss: 0.50667 	 Best epoch 1925
EarlyStopping counter: 4 out of 50
train epoch 1946 avg loss: 0.15768 (A-MSE: 0.13936) avg lploss: 0.00000
train epoch 1947 avg loss: 0.15839 (A-MSE: 0.13974) avg lploss: 0.00000
train epoch 1948 avg loss: 0.16922 (A-MSE: 0.14932) avg lploss: 0.00000
train epoch 1949 avg loss: 0.16622 (A-MSE: 0.14592) avg lploss: 0.00000
train epoch 1950 avg loss: 0.15880 (A-MSE: 0.13924) avg lploss: 0.00000
==> val epoch 1950 avg loss: 0.52083 (A-MSE: 0.46425) avg lploss: 0.00000
==> test epoch 1950 avg loss: 0.53052 (A-MSE: 0.47371) avg lploss: 0.00000
*** Best Val Loss: 0.45261 	 Best Test Loss: 0.50667 	 Best epoch 1925
EarlyStopping counter: 5 out of 50
train epoch 1951 avg loss: 0.16426 (A-MSE: 0.14593) avg lploss: 0.00000
train epoch 1952 avg loss: 0.15471 (A-MSE: 0.13548) avg lploss: 0.00000
train epoch 1953 avg loss: 0.15432 (A-MSE: 0.13549) avg lploss: 0.00000
train epoch 1954 avg loss: 0.14640 (A-MSE: 0.12785) avg lploss: 0.00000
train epoch 1955 avg loss: 0.14441 (A-MSE: 0.12626) avg lploss: 0.00000
==> val epoch 1955 avg loss: 0.44911 (A-MSE: 0.39781) avg lploss: 0.00000
==> test epoch 1955 avg loss: 0.48910 (A-MSE: 0.43621) avg lploss: 0.00000
*** Best Val Loss: 0.44911 	 Best Test Loss: 0.48910 	 Best epoch 1955
Validation loss decreased (0.452613 --> 0.449106).  Saving model ...
train epoch 1956 avg loss: 0.15515 (A-MSE: 0.13634) avg lploss: 0.00000
train epoch 1957 avg loss: 0.16477 (A-MSE: 0.14386) avg lploss: 0.00000
train epoch 1958 avg loss: 0.17381 (A-MSE: 0.15458) avg lploss: 0.00000
train epoch 1959 avg loss: 0.18859 (A-MSE: 0.16727) avg lploss: 0.00000
train epoch 1960 avg loss: 0.18941 (A-MSE: 0.16603) avg lploss: 0.00000
==> val epoch 1960 avg loss: 0.48037 (A-MSE: 0.42038) avg lploss: 0.00000
==> test epoch 1960 avg loss: 0.50034 (A-MSE: 0.44235) avg lploss: 0.00000
*** Best Val Loss: 0.44911 	 Best Test Loss: 0.48910 	 Best epoch 1955
EarlyStopping counter: 1 out of 50
train epoch 1961 avg loss: 0.14750 (A-MSE: 0.12909) avg lploss: 0.00000
train epoch 1962 avg loss: 0.13287 (A-MSE: 0.11691) avg lploss: 0.00000
train epoch 1963 avg loss: 0.15064 (A-MSE: 0.13244) avg lploss: 0.00000
train epoch 1964 avg loss: 0.14365 (A-MSE: 0.12621) avg lploss: 0.00000
train epoch 1965 avg loss: 0.14293 (A-MSE: 0.12535) avg lploss: 0.00000
==> val epoch 1965 avg loss: 0.46988 (A-MSE: 0.41245) avg lploss: 0.00000
==> test epoch 1965 avg loss: 0.49294 (A-MSE: 0.44057) avg lploss: 0.00000
*** Best Val Loss: 0.44911 	 Best Test Loss: 0.48910 	 Best epoch 1955
EarlyStopping counter: 2 out of 50
train epoch 1966 avg loss: 0.15691 (A-MSE: 0.13898) avg lploss: 0.00000
train epoch 1967 avg loss: 0.14177 (A-MSE: 0.12471) avg lploss: 0.00000
train epoch 1968 avg loss: 0.14045 (A-MSE: 0.12362) avg lploss: 0.00000
train epoch 1969 avg loss: 0.13097 (A-MSE: 0.11463) avg lploss: 0.00000
train epoch 1970 avg loss: 0.13111 (A-MSE: 0.11573) avg lploss: 0.00000
==> val epoch 1970 avg loss: 0.42857 (A-MSE: 0.37698) avg lploss: 0.00000
==> test epoch 1970 avg loss: 0.47529 (A-MSE: 0.42310) avg lploss: 0.00000
*** Best Val Loss: 0.42857 	 Best Test Loss: 0.47529 	 Best epoch 1970
Validation loss decreased (0.449106 --> 0.428570).  Saving model ...
train epoch 1971 avg loss: 0.14776 (A-MSE: 0.13025) avg lploss: 0.00000
train epoch 1972 avg loss: 0.15371 (A-MSE: 0.13636) avg lploss: 0.00000
train epoch 1973 avg loss: 0.14616 (A-MSE: 0.12831) avg lploss: 0.00000
train epoch 1974 avg loss: 0.14758 (A-MSE: 0.12988) avg lploss: 0.00000
train epoch 1975 avg loss: 0.13211 (A-MSE: 0.11602) avg lploss: 0.00000
==> val epoch 1975 avg loss: 0.55026 (A-MSE: 0.48445) avg lploss: 0.00000
==> test epoch 1975 avg loss: 0.57789 (A-MSE: 0.51891) avg lploss: 0.00000
*** Best Val Loss: 0.42857 	 Best Test Loss: 0.47529 	 Best epoch 1970
EarlyStopping counter: 1 out of 50
train epoch 1976 avg loss: 0.14824 (A-MSE: 0.13029) avg lploss: 0.00000
train epoch 1977 avg loss: 0.14415 (A-MSE: 0.12791) avg lploss: 0.00000
train epoch 1978 avg loss: 0.13239 (A-MSE: 0.11582) avg lploss: 0.00000
train epoch 1979 avg loss: 0.12895 (A-MSE: 0.11436) avg lploss: 0.00000
train epoch 1980 avg loss: 0.12889 (A-MSE: 0.11422) avg lploss: 0.00000
==> val epoch 1980 avg loss: 0.45179 (A-MSE: 0.39609) avg lploss: 0.00000
==> test epoch 1980 avg loss: 0.49458 (A-MSE: 0.43908) avg lploss: 0.00000
*** Best Val Loss: 0.42857 	 Best Test Loss: 0.47529 	 Best epoch 1970
EarlyStopping counter: 2 out of 50
train epoch 1981 avg loss: 0.13586 (A-MSE: 0.11894) avg lploss: 0.00000
train epoch 1982 avg loss: 0.14215 (A-MSE: 0.12495) avg lploss: 0.00000
train epoch 1983 avg loss: 0.14237 (A-MSE: 0.12517) avg lploss: 0.00000
train epoch 1984 avg loss: 0.13316 (A-MSE: 0.11716) avg lploss: 0.00000
train epoch 1985 avg loss: 0.14122 (A-MSE: 0.12424) avg lploss: 0.00000
==> val epoch 1985 avg loss: 0.47169 (A-MSE: 0.41706) avg lploss: 0.00000
==> test epoch 1985 avg loss: 0.49405 (A-MSE: 0.44537) avg lploss: 0.00000
*** Best Val Loss: 0.42857 	 Best Test Loss: 0.47529 	 Best epoch 1970
EarlyStopping counter: 3 out of 50
train epoch 1986 avg loss: 0.13950 (A-MSE: 0.12267) avg lploss: 0.00000
train epoch 1987 avg loss: 0.12514 (A-MSE: 0.11082) avg lploss: 0.00000
train epoch 1988 avg loss: 0.12175 (A-MSE: 0.10802) avg lploss: 0.00000
train epoch 1989 avg loss: 0.13052 (A-MSE: 0.11479) avg lploss: 0.00000
train epoch 1990 avg loss: 0.11595 (A-MSE: 0.10184) avg lploss: 0.00000
==> val epoch 1990 avg loss: 0.49356 (A-MSE: 0.43173) avg lploss: 0.00000
==> test epoch 1990 avg loss: 0.49000 (A-MSE: 0.43527) avg lploss: 0.00000
*** Best Val Loss: 0.42857 	 Best Test Loss: 0.47529 	 Best epoch 1970
EarlyStopping counter: 4 out of 50
train epoch 1991 avg loss: 0.13476 (A-MSE: 0.11868) avg lploss: 0.00000
train epoch 1992 avg loss: 0.14907 (A-MSE: 0.13027) avg lploss: 0.00000
train epoch 1993 avg loss: 0.13024 (A-MSE: 0.11477) avg lploss: 0.00000
train epoch 1994 avg loss: 0.11759 (A-MSE: 0.10352) avg lploss: 0.00000
train epoch 1995 avg loss: 0.11245 (A-MSE: 0.09913) avg lploss: 0.00000
==> val epoch 1995 avg loss: 0.43382 (A-MSE: 0.38196) avg lploss: 0.00000
==> test epoch 1995 avg loss: 0.46633 (A-MSE: 0.41564) avg lploss: 0.00000
*** Best Val Loss: 0.42857 	 Best Test Loss: 0.47529 	 Best epoch 1970
EarlyStopping counter: 5 out of 50
train epoch 1996 avg loss: 0.10640 (A-MSE: 0.09255) avg lploss: 0.00000
train epoch 1997 avg loss: 0.10652 (A-MSE: 0.09411) avg lploss: 0.00000
train epoch 1998 avg loss: 0.11845 (A-MSE: 0.10450) avg lploss: 0.00000
train epoch 1999 avg loss: 0.11296 (A-MSE: 0.09939) avg lploss: 0.00000
best_train = 0.131108
best_lp = 0.000000
best_val = 0.428570
best_test = 0.475295
best_epoch = 1970
best_train = 0.131108, best_lp = 0.000000, best_val = 0.428570, best_test = 0.475295, best_epoch = 1970
Training completed for seed 4 with num_modes=3
